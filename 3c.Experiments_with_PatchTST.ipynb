{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No Patching](#3-no-patching)\n",
    "- [4. Time series decomposition](#4-ts-decomposition)\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2566070\n",
      "\tspeed: 0.0532s/iter; left time: 1186.9556s\n",
      "\titers: 200, epoch: 1 | loss: 0.2419528\n",
      "\tspeed: 0.0264s/iter; left time: 586.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.2636380 Vali Loss: 0.2222575 Test Loss: 0.2204070\n",
      "Validation loss decreased (inf --> 0.222257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1490381\n",
      "\tspeed: 0.0511s/iter; left time: 1127.0547s\n",
      "\titers: 200, epoch: 2 | loss: 0.1197937\n",
      "\tspeed: 0.0264s/iter; left time: 580.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.1535841 Vali Loss: 0.1151092 Test Loss: 0.1171536\n",
      "Validation loss decreased (0.222257 --> 0.115109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1010839\n",
      "\tspeed: 0.0512s/iter; left time: 1118.3096s\n",
      "\titers: 200, epoch: 3 | loss: 0.0979355\n",
      "\tspeed: 0.0265s/iter; left time: 575.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.1034884 Vali Loss: 0.1062425 Test Loss: 0.1076204\n",
      "Validation loss decreased (0.115109 --> 0.106242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974420\n",
      "\tspeed: 0.0511s/iter; left time: 1105.8981s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977694\n",
      "\tspeed: 0.0264s/iter; left time: 568.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0933482 Vali Loss: 0.0992072 Test Loss: 0.1010505\n",
      "Validation loss decreased (0.106242 --> 0.099207).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909457\n",
      "\tspeed: 0.0501s/iter; left time: 1071.7958s\n",
      "\titers: 200, epoch: 5 | loss: 0.0860357\n",
      "\tspeed: 0.0267s/iter; left time: 568.7304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0887532 Vali Loss: 0.0971549 Test Loss: 0.0991021\n",
      "Validation loss decreased (0.099207 --> 0.097155).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950104\n",
      "\tspeed: 0.0508s/iter; left time: 1075.6494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841039\n",
      "\tspeed: 0.0266s/iter; left time: 560.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0859246 Vali Loss: 0.0970220 Test Loss: 0.0979300\n",
      "Validation loss decreased (0.097155 --> 0.097022).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830651\n",
      "\tspeed: 0.0506s/iter; left time: 1060.1059s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861730\n",
      "\tspeed: 0.0266s/iter; left time: 554.3986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0841975 Vali Loss: 0.0949431 Test Loss: 0.0963822\n",
      "Validation loss decreased (0.097022 --> 0.094943).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834699\n",
      "\tspeed: 0.0510s/iter; left time: 1058.0602s\n",
      "\titers: 200, epoch: 8 | loss: 0.0826666\n",
      "\tspeed: 0.0266s/iter; left time: 549.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0832470 Vali Loss: 0.0940332 Test Loss: 0.0951022\n",
      "Validation loss decreased (0.094943 --> 0.094033).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867406\n",
      "\tspeed: 0.0510s/iter; left time: 1046.0574s\n",
      "\titers: 200, epoch: 9 | loss: 0.0859180\n",
      "\tspeed: 0.0269s/iter; left time: 549.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0822038 Vali Loss: 0.0939286 Test Loss: 0.0947163\n",
      "Validation loss decreased (0.094033 --> 0.093929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839390\n",
      "\tspeed: 0.0511s/iter; left time: 1037.1268s\n",
      "\titers: 200, epoch: 10 | loss: 0.0786523\n",
      "\tspeed: 0.0266s/iter; left time: 536.8034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0808735 Vali Loss: 0.0932474 Test Loss: 0.0947599\n",
      "Validation loss decreased (0.093929 --> 0.093247).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754465\n",
      "\tspeed: 0.0522s/iter; left time: 1047.4553s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798902\n",
      "\tspeed: 0.0272s/iter; left time: 542.5924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0805028 Vali Loss: 0.0930160 Test Loss: 0.0942361\n",
      "Validation loss decreased (0.093247 --> 0.093016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777061\n",
      "\tspeed: 0.0515s/iter; left time: 1021.7330s\n",
      "\titers: 200, epoch: 12 | loss: 0.0808789\n",
      "\tspeed: 0.0265s/iter; left time: 523.4146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0801001 Vali Loss: 0.0921757 Test Loss: 0.0932652\n",
      "Validation loss decreased (0.093016 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751510\n",
      "\tspeed: 0.0514s/iter; left time: 1008.9151s\n",
      "\titers: 200, epoch: 13 | loss: 0.0770847\n",
      "\tspeed: 0.0265s/iter; left time: 517.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0791738 Vali Loss: 0.0924514 Test Loss: 0.0932204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0782727\n",
      "\tspeed: 0.0501s/iter; left time: 971.1566s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786983\n",
      "\tspeed: 0.0265s/iter; left time: 511.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0787759 Vali Loss: 0.0920219 Test Loss: 0.0935162\n",
      "Validation loss decreased (0.092176 --> 0.092022).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0777310\n",
      "\tspeed: 0.0506s/iter; left time: 968.8588s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735414\n",
      "\tspeed: 0.0265s/iter; left time: 504.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0786300 Vali Loss: 0.0917478 Test Loss: 0.0926336\n",
      "Validation loss decreased (0.092022 --> 0.091748).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785231\n",
      "\tspeed: 0.0516s/iter; left time: 976.5916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0768834\n",
      "\tspeed: 0.0268s/iter; left time: 504.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0784725 Vali Loss: 0.0918264 Test Loss: 0.0926172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798664\n",
      "\tspeed: 0.0509s/iter; left time: 952.5160s\n",
      "\titers: 200, epoch: 17 | loss: 0.0797044\n",
      "\tspeed: 0.0267s/iter; left time: 496.1904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0783037 Vali Loss: 0.0910420 Test Loss: 0.0925358\n",
      "Validation loss decreased (0.091748 --> 0.091042).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781114\n",
      "\tspeed: 0.0517s/iter; left time: 956.2847s\n",
      "\titers: 200, epoch: 18 | loss: 0.0855012\n",
      "\tspeed: 0.0267s/iter; left time: 490.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0779318 Vali Loss: 0.0907866 Test Loss: 0.0921505\n",
      "Validation loss decreased (0.091042 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0735422\n",
      "\tspeed: 0.0510s/iter; left time: 931.0906s\n",
      "\titers: 200, epoch: 19 | loss: 0.0740805\n",
      "\tspeed: 0.0262s/iter; left time: 476.3598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0774609 Vali Loss: 0.0919343 Test Loss: 0.0928579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746833\n",
      "\tspeed: 0.0508s/iter; left time: 916.9543s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807188\n",
      "\tspeed: 0.0265s/iter; left time: 475.6114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0773912 Vali Loss: 0.0916482 Test Loss: 0.0923388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0721470\n",
      "\tspeed: 0.0507s/iter; left time: 903.8251s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779014\n",
      "\tspeed: 0.0264s/iter; left time: 467.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0773700 Vali Loss: 0.0906744 Test Loss: 0.0923040\n",
      "Validation loss decreased (0.090787 --> 0.090674).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0702513\n",
      "\tspeed: 0.0505s/iter; left time: 889.1419s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733673\n",
      "\tspeed: 0.0265s/iter; left time: 462.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0772820 Vali Loss: 0.0907303 Test Loss: 0.0918452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767162\n",
      "\tspeed: 0.0503s/iter; left time: 873.2458s\n",
      "\titers: 200, epoch: 23 | loss: 0.0720851\n",
      "\tspeed: 0.0266s/iter; left time: 459.2972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0770278 Vali Loss: 0.0907926 Test Loss: 0.0918527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754888\n",
      "\tspeed: 0.0506s/iter; left time: 866.9338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0748333\n",
      "\tspeed: 0.0270s/iter; left time: 459.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0768529 Vali Loss: 0.0908272 Test Loss: 0.0918088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0754161\n",
      "\tspeed: 0.0507s/iter; left time: 858.4506s\n",
      "\titers: 200, epoch: 25 | loss: 0.0849064\n",
      "\tspeed: 0.0265s/iter; left time: 445.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0768403 Vali Loss: 0.0907090 Test Loss: 0.0916022\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0744077\n",
      "\tspeed: 0.0504s/iter; left time: 841.0716s\n",
      "\titers: 200, epoch: 26 | loss: 0.0762815\n",
      "\tspeed: 0.0262s/iter; left time: 435.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0767571 Vali Loss: 0.0906516 Test Loss: 0.0917031\n",
      "Validation loss decreased (0.090674 --> 0.090652).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0812616\n",
      "\tspeed: 0.0512s/iter; left time: 843.3900s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799414\n",
      "\tspeed: 0.0267s/iter; left time: 436.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0765723 Vali Loss: 0.0903748 Test Loss: 0.0915898\n",
      "Validation loss decreased (0.090652 --> 0.090375).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0726214\n",
      "\tspeed: 0.0505s/iter; left time: 820.6343s\n",
      "\titers: 200, epoch: 28 | loss: 0.0789795\n",
      "\tspeed: 0.0265s/iter; left time: 427.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0765280 Vali Loss: 0.0905175 Test Loss: 0.0916367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0772127\n",
      "\tspeed: 0.0508s/iter; left time: 814.9108s\n",
      "\titers: 200, epoch: 29 | loss: 0.0697870\n",
      "\tspeed: 0.0263s/iter; left time: 418.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0765321 Vali Loss: 0.0904983 Test Loss: 0.0915829\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811062\n",
      "\tspeed: 0.0504s/iter; left time: 796.4451s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780678\n",
      "\tspeed: 0.0266s/iter; left time: 418.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0765154 Vali Loss: 0.0902160 Test Loss: 0.0915959\n",
      "Validation loss decreased (0.090375 --> 0.090216).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0766579\n",
      "\tspeed: 0.0504s/iter; left time: 785.6363s\n",
      "\titers: 200, epoch: 31 | loss: 0.0730054\n",
      "\tspeed: 0.0264s/iter; left time: 408.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0764262 Vali Loss: 0.0905278 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0711051\n",
      "\tspeed: 0.0503s/iter; left time: 772.1789s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803683\n",
      "\tspeed: 0.0264s/iter; left time: 402.9564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0763533 Vali Loss: 0.0901207 Test Loss: 0.0914401\n",
      "Validation loss decreased (0.090216 --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0823469\n",
      "\tspeed: 0.0512s/iter; left time: 775.0922s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713614\n",
      "\tspeed: 0.0263s/iter; left time: 394.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0763147 Vali Loss: 0.0905146 Test Loss: 0.0916492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0752804\n",
      "\tspeed: 0.0506s/iter; left time: 754.7313s\n",
      "\titers: 200, epoch: 34 | loss: 0.0791326\n",
      "\tspeed: 0.0265s/iter; left time: 392.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0762617 Vali Loss: 0.0903647 Test Loss: 0.0914449\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0792777\n",
      "\tspeed: 0.0506s/iter; left time: 742.4060s\n",
      "\titers: 200, epoch: 35 | loss: 0.0719633\n",
      "\tspeed: 0.0266s/iter; left time: 388.5645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0761660 Vali Loss: 0.0903345 Test Loss: 0.0914848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769392\n",
      "\tspeed: 0.0510s/iter; left time: 737.3572s\n",
      "\titers: 200, epoch: 36 | loss: 0.0812033\n",
      "\tspeed: 0.0266s/iter; left time: 381.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0762252 Vali Loss: 0.0910000 Test Loss: 0.0918637\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0839674\n",
      "\tspeed: 0.0504s/iter; left time: 717.6566s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782146\n",
      "\tspeed: 0.0265s/iter; left time: 375.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0761717 Vali Loss: 0.0904660 Test Loss: 0.0915176\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0749981\n",
      "\tspeed: 0.0511s/iter; left time: 715.5154s\n",
      "\titers: 200, epoch: 38 | loss: 0.0715419\n",
      "\tspeed: 0.0269s/iter; left time: 374.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0761763 Vali Loss: 0.0906010 Test Loss: 0.0916540\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0792945\n",
      "\tspeed: 0.0503s/iter; left time: 694.0618s\n",
      "\titers: 200, epoch: 39 | loss: 0.0729343\n",
      "\tspeed: 0.0268s/iter; left time: 366.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0762594 Vali Loss: 0.0901306 Test Loss: 0.0913918\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0725834\n",
      "\tspeed: 0.0503s/iter; left time: 681.7558s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821638\n",
      "\tspeed: 0.0265s/iter; left time: 357.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0761080 Vali Loss: 0.0901505 Test Loss: 0.0913605\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0714317\n",
      "\tspeed: 0.0510s/iter; left time: 681.0408s\n",
      "\titers: 200, epoch: 41 | loss: 0.0747623\n",
      "\tspeed: 0.0267s/iter; left time: 353.4224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0761157 Vali Loss: 0.0900619 Test Loss: 0.0915041\n",
      "Validation loss decreased (0.090121 --> 0.090062).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0739755\n",
      "\tspeed: 0.0516s/iter; left time: 677.1821s\n",
      "\titers: 200, epoch: 42 | loss: 0.0810414\n",
      "\tspeed: 0.0268s/iter; left time: 348.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0761380 Vali Loss: 0.0903147 Test Loss: 0.0914038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0811172\n",
      "\tspeed: 0.0507s/iter; left time: 653.3830s\n",
      "\titers: 200, epoch: 43 | loss: 0.0779029\n",
      "\tspeed: 0.0265s/iter; left time: 339.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0760796 Vali Loss: 0.0902422 Test Loss: 0.0914716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0723317\n",
      "\tspeed: 0.0508s/iter; left time: 643.8286s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762026\n",
      "\tspeed: 0.0266s/iter; left time: 334.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0759945 Vali Loss: 0.0902213 Test Loss: 0.0914703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0768227\n",
      "\tspeed: 0.0508s/iter; left time: 631.6453s\n",
      "\titers: 200, epoch: 45 | loss: 0.0778465\n",
      "\tspeed: 0.0265s/iter; left time: 327.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0760749 Vali Loss: 0.0902847 Test Loss: 0.0914034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757674\n",
      "\tspeed: 0.0499s/iter; left time: 610.1826s\n",
      "\titers: 200, epoch: 46 | loss: 0.0817664\n",
      "\tspeed: 0.0267s/iter; left time: 323.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0760586 Vali Loss: 0.0901711 Test Loss: 0.0912951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0757344\n",
      "\tspeed: 0.0508s/iter; left time: 610.0356s\n",
      "\titers: 200, epoch: 47 | loss: 0.0739751\n",
      "\tspeed: 0.0266s/iter; left time: 316.8831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0760620 Vali Loss: 0.0903189 Test Loss: 0.0914689\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769868\n",
      "\tspeed: 0.0509s/iter; left time: 598.9188s\n",
      "\titers: 200, epoch: 48 | loss: 0.0761500\n",
      "\tspeed: 0.0264s/iter; left time: 308.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0760214 Vali Loss: 0.0901692 Test Loss: 0.0913794\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0779364\n",
      "\tspeed: 0.0509s/iter; left time: 587.8916s\n",
      "\titers: 200, epoch: 49 | loss: 0.0800145\n",
      "\tspeed: 0.0266s/iter; left time: 304.3929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0760802 Vali Loss: 0.0900943 Test Loss: 0.0913661\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0724418\n",
      "\tspeed: 0.0508s/iter; left time: 574.8073s\n",
      "\titers: 200, epoch: 50 | loss: 0.0738002\n",
      "\tspeed: 0.0264s/iter; left time: 296.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0759310 Vali Loss: 0.0905732 Test Loss: 0.0915211\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0714924\n",
      "\tspeed: 0.0506s/iter; left time: 561.2670s\n",
      "\titers: 200, epoch: 51 | loss: 0.0791853\n",
      "\tspeed: 0.0264s/iter; left time: 290.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0759803 Vali Loss: 0.0902920 Test Loss: 0.0913586\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021748371422290802, rmse:0.1474732905626297, mae:0.0915040671825409, rse:0.5204536318778992\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2623934\n",
      "\tspeed: 0.0291s/iter; left time: 648.2670s\n",
      "\titers: 200, epoch: 1 | loss: 0.2396158\n",
      "\tspeed: 0.0265s/iter; left time: 588.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.2633231 Vali Loss: 0.2145368 Test Loss: 0.2137502\n",
      "Validation loss decreased (inf --> 0.214537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1374790\n",
      "\tspeed: 0.0520s/iter; left time: 1148.1994s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093387\n",
      "\tspeed: 0.0265s/iter; left time: 581.7916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.1501679 Vali Loss: 0.1194519 Test Loss: 0.1199035\n",
      "Validation loss decreased (0.214537 --> 0.119452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0990194\n",
      "\tspeed: 0.0511s/iter; left time: 1117.7147s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039781\n",
      "\tspeed: 0.0265s/iter; left time: 575.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.1039293 Vali Loss: 0.1051352 Test Loss: 0.1071176\n",
      "Validation loss decreased (0.119452 --> 0.105135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944413\n",
      "\tspeed: 0.0514s/iter; left time: 1111.5284s\n",
      "\titers: 200, epoch: 4 | loss: 0.0901303\n",
      "\tspeed: 0.0264s/iter; left time: 568.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0936006 Vali Loss: 0.0998318 Test Loss: 0.1013047\n",
      "Validation loss decreased (0.105135 --> 0.099832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0877668\n",
      "\tspeed: 0.0514s/iter; left time: 1101.2320s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928216\n",
      "\tspeed: 0.0265s/iter; left time: 563.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0888237 Vali Loss: 0.0964812 Test Loss: 0.0980058\n",
      "Validation loss decreased (0.099832 --> 0.096481).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0847580\n",
      "\tspeed: 0.0513s/iter; left time: 1087.4706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826628\n",
      "\tspeed: 0.0264s/iter; left time: 556.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0858948 Vali Loss: 0.0959795 Test Loss: 0.0970195\n",
      "Validation loss decreased (0.096481 --> 0.095980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0905109\n",
      "\tspeed: 0.0516s/iter; left time: 1081.4807s\n",
      "\titers: 200, epoch: 7 | loss: 0.0828156\n",
      "\tspeed: 0.0264s/iter; left time: 550.7738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0842266 Vali Loss: 0.0946363 Test Loss: 0.0962865\n",
      "Validation loss decreased (0.095980 --> 0.094636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775391\n",
      "\tspeed: 0.0514s/iter; left time: 1065.6817s\n",
      "\titers: 200, epoch: 8 | loss: 0.0855141\n",
      "\tspeed: 0.0264s/iter; left time: 545.3546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0828761 Vali Loss: 0.0938537 Test Loss: 0.0953314\n",
      "Validation loss decreased (0.094636 --> 0.093854).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816690\n",
      "\tspeed: 0.0519s/iter; left time: 1064.9083s\n",
      "\titers: 200, epoch: 9 | loss: 0.0851879\n",
      "\tspeed: 0.0267s/iter; left time: 545.1764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0829858 Vali Loss: 0.0947143 Test Loss: 0.0958647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0823175\n",
      "\tspeed: 0.0513s/iter; left time: 1040.4598s\n",
      "\titers: 200, epoch: 10 | loss: 0.0796459\n",
      "\tspeed: 0.0264s/iter; left time: 532.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0809271 Vali Loss: 0.0935037 Test Loss: 0.0946443\n",
      "Validation loss decreased (0.093854 --> 0.093504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768127\n",
      "\tspeed: 0.0516s/iter; left time: 1034.3691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761531\n",
      "\tspeed: 0.0266s/iter; left time: 530.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0801934 Vali Loss: 0.0916781 Test Loss: 0.0932157\n",
      "Validation loss decreased (0.093504 --> 0.091678).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837837\n",
      "\tspeed: 0.0517s/iter; left time: 1025.0865s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775089\n",
      "\tspeed: 0.0265s/iter; left time: 522.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0802700 Vali Loss: 0.0934207 Test Loss: 0.0943639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784073\n",
      "\tspeed: 0.0514s/iter; left time: 1007.9049s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782698\n",
      "\tspeed: 0.0264s/iter; left time: 514.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0792549 Vali Loss: 0.0911230 Test Loss: 0.0926930\n",
      "Validation loss decreased (0.091678 --> 0.091123).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0733982\n",
      "\tspeed: 0.0516s/iter; left time: 999.9662s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791362\n",
      "\tspeed: 0.0268s/iter; left time: 516.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0786626 Vali Loss: 0.0918051 Test Loss: 0.0929869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759531\n",
      "\tspeed: 0.0511s/iter; left time: 979.1617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776807\n",
      "\tspeed: 0.0263s/iter; left time: 502.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0783810 Vali Loss: 0.0908538 Test Loss: 0.0923476\n",
      "Validation loss decreased (0.091123 --> 0.090854).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0793302\n",
      "\tspeed: 0.0515s/iter; left time: 975.7433s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803491\n",
      "\tspeed: 0.0265s/iter; left time: 499.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0782527 Vali Loss: 0.0906397 Test Loss: 0.0923295\n",
      "Validation loss decreased (0.090854 --> 0.090640).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744852\n",
      "\tspeed: 0.0509s/iter; left time: 953.1146s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786489\n",
      "\tspeed: 0.0264s/iter; left time: 491.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0779015 Vali Loss: 0.0903674 Test Loss: 0.0920459\n",
      "Validation loss decreased (0.090640 --> 0.090367).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812337\n",
      "\tspeed: 0.0517s/iter; left time: 956.0485s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783246\n",
      "\tspeed: 0.0265s/iter; left time: 486.8890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0775950 Vali Loss: 0.0926962 Test Loss: 0.0936254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784258\n",
      "\tspeed: 0.0518s/iter; left time: 945.8514s\n",
      "\titers: 200, epoch: 19 | loss: 0.0762034\n",
      "\tspeed: 0.0265s/iter; left time: 480.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0777468 Vali Loss: 0.0910056 Test Loss: 0.0922556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0757184\n",
      "\tspeed: 0.0525s/iter; left time: 947.1240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0782048\n",
      "\tspeed: 0.0265s/iter; left time: 475.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0774940 Vali Loss: 0.0901802 Test Loss: 0.0919014\n",
      "Validation loss decreased (0.090367 --> 0.090180).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752977\n",
      "\tspeed: 0.0519s/iter; left time: 924.6541s\n",
      "\titers: 200, epoch: 21 | loss: 0.0739630\n",
      "\tspeed: 0.0264s/iter; left time: 467.5208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0772572 Vali Loss: 0.0915566 Test Loss: 0.0928652\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0792587\n",
      "\tspeed: 0.0519s/iter; left time: 912.7213s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784705\n",
      "\tspeed: 0.0269s/iter; left time: 469.9750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0769730 Vali Loss: 0.0908989 Test Loss: 0.0921991\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772055\n",
      "\tspeed: 0.0516s/iter; left time: 896.0212s\n",
      "\titers: 200, epoch: 23 | loss: 0.0812640\n",
      "\tspeed: 0.0264s/iter; left time: 456.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0770093 Vali Loss: 0.0900116 Test Loss: 0.0918345\n",
      "Validation loss decreased (0.090180 --> 0.090012).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0803091\n",
      "\tspeed: 0.0508s/iter; left time: 871.6293s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759364\n",
      "\tspeed: 0.0264s/iter; left time: 449.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0770596 Vali Loss: 0.0899609 Test Loss: 0.0916573\n",
      "Validation loss decreased (0.090012 --> 0.089961).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758617\n",
      "\tspeed: 0.0517s/iter; left time: 874.5700s\n",
      "\titers: 200, epoch: 25 | loss: 0.0737996\n",
      "\tspeed: 0.0269s/iter; left time: 452.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0769033 Vali Loss: 0.0899511 Test Loss: 0.0915681\n",
      "Validation loss decreased (0.089961 --> 0.089951).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0765661\n",
      "\tspeed: 0.0522s/iter; left time: 872.2105s\n",
      "\titers: 200, epoch: 26 | loss: 0.0763971\n",
      "\tspeed: 0.0264s/iter; left time: 437.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0765872 Vali Loss: 0.0900413 Test Loss: 0.0916204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0758144\n",
      "\tspeed: 0.0518s/iter; left time: 853.8591s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757976\n",
      "\tspeed: 0.0270s/iter; left time: 442.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0764685 Vali Loss: 0.0906311 Test Loss: 0.0921329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0758253\n",
      "\tspeed: 0.0508s/iter; left time: 825.5056s\n",
      "\titers: 200, epoch: 28 | loss: 0.0753282\n",
      "\tspeed: 0.0262s/iter; left time: 423.2454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0765909 Vali Loss: 0.0898152 Test Loss: 0.0914769\n",
      "Validation loss decreased (0.089951 --> 0.089815).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0749874\n",
      "\tspeed: 0.0516s/iter; left time: 827.0840s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735045\n",
      "\tspeed: 0.0263s/iter; left time: 419.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0764512 Vali Loss: 0.0897418 Test Loss: 0.0915002\n",
      "Validation loss decreased (0.089815 --> 0.089742).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0812473\n",
      "\tspeed: 0.0509s/iter; left time: 803.7272s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751119\n",
      "\tspeed: 0.0265s/iter; left time: 416.2900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0764347 Vali Loss: 0.0904919 Test Loss: 0.0919945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0783717\n",
      "\tspeed: 0.0511s/iter; left time: 796.6079s\n",
      "\titers: 200, epoch: 31 | loss: 0.0838023\n",
      "\tspeed: 0.0263s/iter; left time: 407.2658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0763518 Vali Loss: 0.0900647 Test Loss: 0.0916321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0714996\n",
      "\tspeed: 0.0508s/iter; left time: 780.8560s\n",
      "\titers: 200, epoch: 32 | loss: 0.0752642\n",
      "\tspeed: 0.0265s/iter; left time: 404.2121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0763182 Vali Loss: 0.0899387 Test Loss: 0.0916039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0770082\n",
      "\tspeed: 0.0517s/iter; left time: 782.5797s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753402\n",
      "\tspeed: 0.0264s/iter; left time: 396.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0896231 Test Loss: 0.0914508\n",
      "Validation loss decreased (0.089742 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0725115\n",
      "\tspeed: 0.0518s/iter; left time: 771.5771s\n",
      "\titers: 200, epoch: 34 | loss: 0.0776233\n",
      "\tspeed: 0.0264s/iter; left time: 391.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0762119 Vali Loss: 0.0895975 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.089623 --> 0.089597).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0771235\n",
      "\tspeed: 0.0512s/iter; left time: 751.4118s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781061\n",
      "\tspeed: 0.0264s/iter; left time: 384.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0761741 Vali Loss: 0.0895915 Test Loss: 0.0913442\n",
      "Validation loss decreased (0.089597 --> 0.089591).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0696032\n",
      "\tspeed: 0.0512s/iter; left time: 739.9131s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770035\n",
      "\tspeed: 0.0264s/iter; left time: 379.4754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0760867 Vali Loss: 0.0900567 Test Loss: 0.0917049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0778791\n",
      "\tspeed: 0.0505s/iter; left time: 719.5481s\n",
      "\titers: 200, epoch: 37 | loss: 0.0745140\n",
      "\tspeed: 0.0264s/iter; left time: 372.6496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0762562 Vali Loss: 0.0897121 Test Loss: 0.0913620\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0783371\n",
      "\tspeed: 0.0511s/iter; left time: 716.0441s\n",
      "\titers: 200, epoch: 38 | loss: 0.0818648\n",
      "\tspeed: 0.0266s/iter; left time: 369.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0761213 Vali Loss: 0.0900666 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803079\n",
      "\tspeed: 0.0518s/iter; left time: 714.8789s\n",
      "\titers: 200, epoch: 39 | loss: 0.0745575\n",
      "\tspeed: 0.0266s/iter; left time: 364.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0760805 Vali Loss: 0.0901203 Test Loss: 0.0916768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0744408\n",
      "\tspeed: 0.0513s/iter; left time: 696.1614s\n",
      "\titers: 200, epoch: 40 | loss: 0.0698902\n",
      "\tspeed: 0.0268s/iter; left time: 360.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0760944 Vali Loss: 0.0897818 Test Loss: 0.0915024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0756303\n",
      "\tspeed: 0.0514s/iter; left time: 685.3262s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757952\n",
      "\tspeed: 0.0264s/iter; left time: 349.6103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0760046 Vali Loss: 0.0898426 Test Loss: 0.0915377\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0779208\n",
      "\tspeed: 0.0510s/iter; left time: 669.5759s\n",
      "\titers: 200, epoch: 42 | loss: 0.0747404\n",
      "\tspeed: 0.0265s/iter; left time: 345.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0761344 Vali Loss: 0.0901287 Test Loss: 0.0917811\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0771934\n",
      "\tspeed: 0.0508s/iter; left time: 654.6272s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749607\n",
      "\tspeed: 0.0264s/iter; left time: 337.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0759900 Vali Loss: 0.0897255 Test Loss: 0.0914727\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0743435\n",
      "\tspeed: 0.0510s/iter; left time: 646.1299s\n",
      "\titers: 200, epoch: 44 | loss: 0.0800619\n",
      "\tspeed: 0.0264s/iter; left time: 331.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0760069 Vali Loss: 0.0894995 Test Loss: 0.0912929\n",
      "Validation loss decreased (0.089591 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0732608\n",
      "\tspeed: 0.0514s/iter; left time: 639.3487s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766907\n",
      "\tspeed: 0.0264s/iter; left time: 325.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0759964 Vali Loss: 0.0898933 Test Loss: 0.0914188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0741571\n",
      "\tspeed: 0.0508s/iter; left time: 620.4704s\n",
      "\titers: 200, epoch: 46 | loss: 0.0754467\n",
      "\tspeed: 0.0264s/iter; left time: 319.8579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0760600 Vali Loss: 0.0897355 Test Loss: 0.0913146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0713772\n",
      "\tspeed: 0.0511s/iter; left time: 612.7077s\n",
      "\titers: 200, epoch: 47 | loss: 0.0743333\n",
      "\tspeed: 0.0264s/iter; left time: 314.0654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758811 Vali Loss: 0.0899609 Test Loss: 0.0915293\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0764152\n",
      "\tspeed: 0.0508s/iter; left time: 598.5441s\n",
      "\titers: 200, epoch: 48 | loss: 0.0770819\n",
      "\tspeed: 0.0263s/iter; left time: 307.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0759072 Vali Loss: 0.0899988 Test Loss: 0.0916863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0743392\n",
      "\tspeed: 0.0514s/iter; left time: 593.3161s\n",
      "\titers: 200, epoch: 49 | loss: 0.0781718\n",
      "\tspeed: 0.0264s/iter; left time: 302.1229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759080 Vali Loss: 0.0899594 Test Loss: 0.0915774\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756658\n",
      "\tspeed: 0.0515s/iter; left time: 582.9967s\n",
      "\titers: 200, epoch: 50 | loss: 0.0756160\n",
      "\tspeed: 0.0265s/iter; left time: 297.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0759219 Vali Loss: 0.0898047 Test Loss: 0.0914517\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815681\n",
      "\tspeed: 0.0510s/iter; left time: 565.7757s\n",
      "\titers: 200, epoch: 51 | loss: 0.0765514\n",
      "\tspeed: 0.0268s/iter; left time: 294.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759615 Vali Loss: 0.0896021 Test Loss: 0.0913982\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0764843\n",
      "\tspeed: 0.0508s/iter; left time: 552.8893s\n",
      "\titers: 200, epoch: 52 | loss: 0.0764052\n",
      "\tspeed: 0.0263s/iter; left time: 283.6687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0758922 Vali Loss: 0.0901767 Test Loss: 0.0917404\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0747740\n",
      "\tspeed: 0.0511s/iter; left time: 544.3491s\n",
      "\titers: 200, epoch: 53 | loss: 0.0760180\n",
      "\tspeed: 0.0266s/iter; left time: 280.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0758861 Vali Loss: 0.0898443 Test Loss: 0.0914755\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0749051\n",
      "\tspeed: 0.0508s/iter; left time: 529.6588s\n",
      "\titers: 200, epoch: 54 | loss: 0.0723748\n",
      "\tspeed: 0.0263s/iter; left time: 271.8668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0899249 Test Loss: 0.0915471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021651936694979668, rmse:0.14714597165584564, mae:0.09129294008016586, rse:0.5192984938621521\n",
      "Intermediate time for DE and pred_len 24: 00h:13m:47.28s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2630768\n",
      "\tspeed: 0.0542s/iter; left time: 1207.9141s\n",
      "\titers: 200, epoch: 1 | loss: 0.2523208\n",
      "\tspeed: 0.0267s/iter; left time: 592.7196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.2658288 Vali Loss: 0.2251827 Test Loss: 0.2259640\n",
      "Validation loss decreased (inf --> 0.225183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566545\n",
      "\tspeed: 0.0547s/iter; left time: 1206.5166s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344758\n",
      "\tspeed: 0.0270s/iter; left time: 594.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1630470 Vali Loss: 0.1419773 Test Loss: 0.1463934\n",
      "Validation loss decreased (0.225183 --> 0.141977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1215972\n",
      "\tspeed: 0.0547s/iter; left time: 1195.0206s\n",
      "\titers: 200, epoch: 3 | loss: 0.1200278\n",
      "\tspeed: 0.0271s/iter; left time: 588.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1237614 Vali Loss: 0.1315045 Test Loss: 0.1411074\n",
      "Validation loss decreased (0.141977 --> 0.131504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162965\n",
      "\tspeed: 0.0543s/iter; left time: 1175.0955s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118230\n",
      "\tspeed: 0.0268s/iter; left time: 577.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1159266 Vali Loss: 0.1265297 Test Loss: 0.1361486\n",
      "Validation loss decreased (0.131504 --> 0.126530).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1119742\n",
      "\tspeed: 0.0548s/iter; left time: 1172.4131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1024615\n",
      "\tspeed: 0.0272s/iter; left time: 578.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1114667 Vali Loss: 0.1237297 Test Loss: 0.1319537\n",
      "Validation loss decreased (0.126530 --> 0.123730).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1169698\n",
      "\tspeed: 0.0545s/iter; left time: 1154.8920s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130258\n",
      "\tspeed: 0.0269s/iter; left time: 567.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1092667 Vali Loss: 0.1252045 Test Loss: 0.1344381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1088223\n",
      "\tspeed: 0.0541s/iter; left time: 1134.3021s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025394\n",
      "\tspeed: 0.0268s/iter; left time: 559.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1081086 Vali Loss: 0.1233292 Test Loss: 0.1324626\n",
      "Validation loss decreased (0.123730 --> 0.123329).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1078237\n",
      "\tspeed: 0.0539s/iter; left time: 1117.8815s\n",
      "\titers: 200, epoch: 8 | loss: 0.1050049\n",
      "\tspeed: 0.0269s/iter; left time: 554.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1069662 Vali Loss: 0.1241076 Test Loss: 0.1364119\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043864\n",
      "\tspeed: 0.0536s/iter; left time: 1099.1176s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087614\n",
      "\tspeed: 0.0268s/iter; left time: 546.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1064280 Vali Loss: 0.1238246 Test Loss: 0.1345607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1045793\n",
      "\tspeed: 0.0534s/iter; left time: 1083.4344s\n",
      "\titers: 200, epoch: 10 | loss: 0.1018358\n",
      "\tspeed: 0.0268s/iter; left time: 540.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1057379 Vali Loss: 0.1222734 Test Loss: 0.1342183\n",
      "Validation loss decreased (0.123329 --> 0.122273).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1041998\n",
      "\tspeed: 0.0544s/iter; left time: 1091.7696s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064309\n",
      "\tspeed: 0.0268s/iter; left time: 535.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1052918 Vali Loss: 0.1218130 Test Loss: 0.1341903\n",
      "Validation loss decreased (0.122273 --> 0.121813).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1075441\n",
      "\tspeed: 0.0550s/iter; left time: 1091.1220s\n",
      "\titers: 200, epoch: 12 | loss: 0.1031930\n",
      "\tspeed: 0.0268s/iter; left time: 529.7916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.1050196 Vali Loss: 0.1237139 Test Loss: 0.1364160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1033154\n",
      "\tspeed: 0.0535s/iter; left time: 1048.3443s\n",
      "\titers: 200, epoch: 13 | loss: 0.1055321\n",
      "\tspeed: 0.0268s/iter; left time: 523.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1045794 Vali Loss: 0.1209626 Test Loss: 0.1324102\n",
      "Validation loss decreased (0.121813 --> 0.120963).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1063844\n",
      "\tspeed: 0.0544s/iter; left time: 1054.4512s\n",
      "\titers: 200, epoch: 14 | loss: 0.0993380\n",
      "\tspeed: 0.0268s/iter; left time: 517.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1041206 Vali Loss: 0.1223020 Test Loss: 0.1336385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1000154\n",
      "\tspeed: 0.0545s/iter; left time: 1045.2792s\n",
      "\titers: 200, epoch: 15 | loss: 0.1074960\n",
      "\tspeed: 0.0268s/iter; left time: 510.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1039088 Vali Loss: 0.1211749 Test Loss: 0.1334180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1062298\n",
      "\tspeed: 0.0543s/iter; left time: 1029.3910s\n",
      "\titers: 200, epoch: 16 | loss: 0.1089683\n",
      "\tspeed: 0.0268s/iter; left time: 505.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1037323 Vali Loss: 0.1214976 Test Loss: 0.1345197\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1044505\n",
      "\tspeed: 0.0540s/iter; left time: 1010.1687s\n",
      "\titers: 200, epoch: 17 | loss: 0.1032697\n",
      "\tspeed: 0.0269s/iter; left time: 500.6301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1033718 Vali Loss: 0.1213387 Test Loss: 0.1326196\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1037102\n",
      "\tspeed: 0.0536s/iter; left time: 992.0721s\n",
      "\titers: 200, epoch: 18 | loss: 0.0965601\n",
      "\tspeed: 0.0268s/iter; left time: 493.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1032211 Vali Loss: 0.1220027 Test Loss: 0.1338869\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1047857\n",
      "\tspeed: 0.0533s/iter; left time: 973.6991s\n",
      "\titers: 200, epoch: 19 | loss: 0.1013042\n",
      "\tspeed: 0.0266s/iter; left time: 482.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1032059 Vali Loss: 0.1214463 Test Loss: 0.1339297\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1024989\n",
      "\tspeed: 0.0530s/iter; left time: 956.8924s\n",
      "\titers: 200, epoch: 20 | loss: 0.1063105\n",
      "\tspeed: 0.0268s/iter; left time: 480.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1028468 Vali Loss: 0.1211054 Test Loss: 0.1342192\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1037339\n",
      "\tspeed: 0.0536s/iter; left time: 955.2516s\n",
      "\titers: 200, epoch: 21 | loss: 0.1006454\n",
      "\tspeed: 0.0267s/iter; left time: 473.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1026506 Vali Loss: 0.1204992 Test Loss: 0.1325146\n",
      "Validation loss decreased (0.120963 --> 0.120499).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1000729\n",
      "\tspeed: 0.0540s/iter; left time: 950.0677s\n",
      "\titers: 200, epoch: 22 | loss: 0.1034170\n",
      "\tspeed: 0.0268s/iter; left time: 468.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1025371 Vali Loss: 0.1214155 Test Loss: 0.1330793\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1027614\n",
      "\tspeed: 0.0540s/iter; left time: 938.3108s\n",
      "\titers: 200, epoch: 23 | loss: 0.1070890\n",
      "\tspeed: 0.0268s/iter; left time: 463.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1025378 Vali Loss: 0.1209115 Test Loss: 0.1327856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1087525\n",
      "\tspeed: 0.0534s/iter; left time: 915.3060s\n",
      "\titers: 200, epoch: 24 | loss: 0.1019634\n",
      "\tspeed: 0.0268s/iter; left time: 456.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1023301 Vali Loss: 0.1208278 Test Loss: 0.1334575\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1021076\n",
      "\tspeed: 0.0541s/iter; left time: 916.2209s\n",
      "\titers: 200, epoch: 25 | loss: 0.0962020\n",
      "\tspeed: 0.0268s/iter; left time: 451.0519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1022461 Vali Loss: 0.1214957 Test Loss: 0.1320013\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1025795\n",
      "\tspeed: 0.0538s/iter; left time: 898.0434s\n",
      "\titers: 200, epoch: 26 | loss: 0.1094282\n",
      "\tspeed: 0.0268s/iter; left time: 445.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1022684 Vali Loss: 0.1208365 Test Loss: 0.1331772\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1048568\n",
      "\tspeed: 0.0540s/iter; left time: 890.0040s\n",
      "\titers: 200, epoch: 27 | loss: 0.0978019\n",
      "\tspeed: 0.0269s/iter; left time: 440.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1021241 Vali Loss: 0.1205537 Test Loss: 0.1334286\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1058979\n",
      "\tspeed: 0.0539s/iter; left time: 876.0864s\n",
      "\titers: 200, epoch: 28 | loss: 0.0972636\n",
      "\tspeed: 0.0270s/iter; left time: 435.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.1019857 Vali Loss: 0.1211016 Test Loss: 0.1341732\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0994898\n",
      "\tspeed: 0.0527s/iter; left time: 844.8960s\n",
      "\titers: 200, epoch: 29 | loss: 0.1098837\n",
      "\tspeed: 0.0266s/iter; left time: 423.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.1019027 Vali Loss: 0.1206129 Test Loss: 0.1327567\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0969293\n",
      "\tspeed: 0.0523s/iter; left time: 826.5597s\n",
      "\titers: 200, epoch: 30 | loss: 0.1035311\n",
      "\tspeed: 0.0266s/iter; left time: 417.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.1019406 Vali Loss: 0.1203134 Test Loss: 0.1327153\n",
      "Validation loss decreased (0.120499 --> 0.120313).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1005189\n",
      "\tspeed: 0.0549s/iter; left time: 855.1103s\n",
      "\titers: 200, epoch: 31 | loss: 0.0965765\n",
      "\tspeed: 0.0269s/iter; left time: 416.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1018233 Vali Loss: 0.1209129 Test Loss: 0.1321092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1016091\n",
      "\tspeed: 0.0541s/iter; left time: 830.5493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0999834\n",
      "\tspeed: 0.0268s/iter; left time: 409.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1017181 Vali Loss: 0.1205590 Test Loss: 0.1335080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1027758\n",
      "\tspeed: 0.0536s/iter; left time: 811.2318s\n",
      "\titers: 200, epoch: 33 | loss: 0.1013042\n",
      "\tspeed: 0.0268s/iter; left time: 403.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1018047 Vali Loss: 0.1199106 Test Loss: 0.1315414\n",
      "Validation loss decreased (0.120313 --> 0.119911).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1062437\n",
      "\tspeed: 0.0541s/iter; left time: 807.1133s\n",
      "\titers: 200, epoch: 34 | loss: 0.1017529\n",
      "\tspeed: 0.0268s/iter; left time: 397.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1017372 Vali Loss: 0.1207020 Test Loss: 0.1334199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0940395\n",
      "\tspeed: 0.0539s/iter; left time: 791.9974s\n",
      "\titers: 200, epoch: 35 | loss: 0.1029754\n",
      "\tspeed: 0.0268s/iter; left time: 391.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1016491 Vali Loss: 0.1203779 Test Loss: 0.1315859\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0991473\n",
      "\tspeed: 0.0540s/iter; left time: 780.7937s\n",
      "\titers: 200, epoch: 36 | loss: 0.0991397\n",
      "\tspeed: 0.0275s/iter; left time: 394.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1016296 Vali Loss: 0.1205082 Test Loss: 0.1332344\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1093032\n",
      "\tspeed: 0.0540s/iter; left time: 768.5256s\n",
      "\titers: 200, epoch: 37 | loss: 0.1040935\n",
      "\tspeed: 0.0272s/iter; left time: 384.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1015898 Vali Loss: 0.1202581 Test Loss: 0.1331425\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1015609\n",
      "\tspeed: 0.0537s/iter; left time: 753.0022s\n",
      "\titers: 200, epoch: 38 | loss: 0.1085721\n",
      "\tspeed: 0.0267s/iter; left time: 371.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1015484 Vali Loss: 0.1200872 Test Loss: 0.1324675\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1009265\n",
      "\tspeed: 0.0540s/iter; left time: 745.0839s\n",
      "\titers: 200, epoch: 39 | loss: 0.1050294\n",
      "\tspeed: 0.0269s/iter; left time: 368.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1014567 Vali Loss: 0.1208096 Test Loss: 0.1335476\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1040717\n",
      "\tspeed: 0.0533s/iter; left time: 722.8202s\n",
      "\titers: 200, epoch: 40 | loss: 0.1048451\n",
      "\tspeed: 0.0268s/iter; left time: 360.2835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1016315 Vali Loss: 0.1201720 Test Loss: 0.1320668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1029412\n",
      "\tspeed: 0.0540s/iter; left time: 720.7618s\n",
      "\titers: 200, epoch: 41 | loss: 0.0981407\n",
      "\tspeed: 0.0268s/iter; left time: 355.4190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1014452 Vali Loss: 0.1203151 Test Loss: 0.1331452\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1041843\n",
      "\tspeed: 0.0534s/iter; left time: 700.3534s\n",
      "\titers: 200, epoch: 42 | loss: 0.1030122\n",
      "\tspeed: 0.0268s/iter; left time: 348.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1014580 Vali Loss: 0.1201773 Test Loss: 0.1325983\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1003520\n",
      "\tspeed: 0.0534s/iter; left time: 688.5246s\n",
      "\titers: 200, epoch: 43 | loss: 0.0968324\n",
      "\tspeed: 0.0268s/iter; left time: 343.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1014142 Vali Loss: 0.1205596 Test Loss: 0.1329429\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.039896149188280106, rmse:0.1997402012348175, mae:0.131541445851326, rse:0.7073204517364502\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2669973\n",
      "\tspeed: 0.0291s/iter; left time: 648.2990s\n",
      "\titers: 200, epoch: 1 | loss: 0.2499191\n",
      "\tspeed: 0.0268s/iter; left time: 594.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.2689866 Vali Loss: 0.2273162 Test Loss: 0.2270883\n",
      "Validation loss decreased (inf --> 0.227316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1548644\n",
      "\tspeed: 0.0549s/iter; left time: 1212.0782s\n",
      "\titers: 200, epoch: 2 | loss: 0.1396128\n",
      "\tspeed: 0.0272s/iter; left time: 597.6643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.1645374 Vali Loss: 0.1408917 Test Loss: 0.1471085\n",
      "Validation loss decreased (0.227316 --> 0.140892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1251144\n",
      "\tspeed: 0.0544s/iter; left time: 1189.4396s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199172\n",
      "\tspeed: 0.0268s/iter; left time: 582.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1237215 Vali Loss: 0.1293459 Test Loss: 0.1392646\n",
      "Validation loss decreased (0.140892 --> 0.129346).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1163457\n",
      "\tspeed: 0.0545s/iter; left time: 1179.4749s\n",
      "\titers: 200, epoch: 4 | loss: 0.1112435\n",
      "\tspeed: 0.0268s/iter; left time: 576.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1150312 Vali Loss: 0.1266522 Test Loss: 0.1362955\n",
      "Validation loss decreased (0.129346 --> 0.126652).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1040357\n",
      "\tspeed: 0.0537s/iter; left time: 1148.7079s\n",
      "\titers: 200, epoch: 5 | loss: 0.1130875\n",
      "\tspeed: 0.0268s/iter; left time: 570.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1114461 Vali Loss: 0.1241973 Test Loss: 0.1328583\n",
      "Validation loss decreased (0.126652 --> 0.124197).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1117986\n",
      "\tspeed: 0.0541s/iter; left time: 1146.6777s\n",
      "\titers: 200, epoch: 6 | loss: 0.1089615\n",
      "\tspeed: 0.0266s/iter; left time: 560.8301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1095231 Vali Loss: 0.1235853 Test Loss: 0.1330164\n",
      "Validation loss decreased (0.124197 --> 0.123585).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1080385\n",
      "\tspeed: 0.0541s/iter; left time: 1132.8421s\n",
      "\titers: 200, epoch: 7 | loss: 0.1036248\n",
      "\tspeed: 0.0266s/iter; left time: 555.7006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1082786 Vali Loss: 0.1228077 Test Loss: 0.1324385\n",
      "Validation loss decreased (0.123585 --> 0.122808).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1041789\n",
      "\tspeed: 0.0542s/iter; left time: 1124.7235s\n",
      "\titers: 200, epoch: 8 | loss: 0.1064302\n",
      "\tspeed: 0.0268s/iter; left time: 553.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1075046 Vali Loss: 0.1221856 Test Loss: 0.1321981\n",
      "Validation loss decreased (0.122808 --> 0.122186).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1060224\n",
      "\tspeed: 0.0539s/iter; left time: 1105.5875s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037400\n",
      "\tspeed: 0.0266s/iter; left time: 543.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1067069 Vali Loss: 0.1222393 Test Loss: 0.1330903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1100116\n",
      "\tspeed: 0.0539s/iter; left time: 1093.4243s\n",
      "\titers: 200, epoch: 10 | loss: 0.1031807\n",
      "\tspeed: 0.0266s/iter; left time: 536.8010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1061626 Vali Loss: 0.1216754 Test Loss: 0.1323753\n",
      "Validation loss decreased (0.122186 --> 0.121675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025820\n",
      "\tspeed: 0.0538s/iter; left time: 1079.0492s\n",
      "\titers: 200, epoch: 11 | loss: 0.1052802\n",
      "\tspeed: 0.0269s/iter; left time: 536.2703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1057314 Vali Loss: 0.1224910 Test Loss: 0.1328006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1058313\n",
      "\tspeed: 0.0534s/iter; left time: 1060.2226s\n",
      "\titers: 200, epoch: 12 | loss: 0.1041818\n",
      "\tspeed: 0.0267s/iter; left time: 526.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1052416 Vali Loss: 0.1243058 Test Loss: 0.1365962\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032766\n",
      "\tspeed: 0.0534s/iter; left time: 1046.9839s\n",
      "\titers: 200, epoch: 13 | loss: 0.1077306\n",
      "\tspeed: 0.0268s/iter; left time: 523.7595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1050440 Vali Loss: 0.1220603 Test Loss: 0.1344615\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1021536\n",
      "\tspeed: 0.0534s/iter; left time: 1035.5258s\n",
      "\titers: 200, epoch: 14 | loss: 0.1046405\n",
      "\tspeed: 0.0267s/iter; left time: 515.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1047762 Vali Loss: 0.1225811 Test Loss: 0.1338924\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1044356\n",
      "\tspeed: 0.0545s/iter; left time: 1044.8756s\n",
      "\titers: 200, epoch: 15 | loss: 0.1005543\n",
      "\tspeed: 0.0269s/iter; left time: 512.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1043475 Vali Loss: 0.1213009 Test Loss: 0.1326865\n",
      "Validation loss decreased (0.121675 --> 0.121301).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1048859\n",
      "\tspeed: 0.0540s/iter; left time: 1022.8323s\n",
      "\titers: 200, epoch: 16 | loss: 0.1073394\n",
      "\tspeed: 0.0269s/iter; left time: 507.4309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1039374 Vali Loss: 0.1212771 Test Loss: 0.1320987\n",
      "Validation loss decreased (0.121301 --> 0.121277).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1051285\n",
      "\tspeed: 0.0549s/iter; left time: 1027.4564s\n",
      "\titers: 200, epoch: 17 | loss: 0.1010679\n",
      "\tspeed: 0.0269s/iter; left time: 500.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1038081 Vali Loss: 0.1213366 Test Loss: 0.1325993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0991897\n",
      "\tspeed: 0.0545s/iter; left time: 1008.4405s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046743\n",
      "\tspeed: 0.0269s/iter; left time: 494.8963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.1034109 Vali Loss: 0.1218144 Test Loss: 0.1340982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0968954\n",
      "\tspeed: 0.0537s/iter; left time: 981.9191s\n",
      "\titers: 200, epoch: 19 | loss: 0.1019711\n",
      "\tspeed: 0.0269s/iter; left time: 488.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1033139 Vali Loss: 0.1208791 Test Loss: 0.1313206\n",
      "Validation loss decreased (0.121277 --> 0.120879).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1070008\n",
      "\tspeed: 0.0543s/iter; left time: 979.2531s\n",
      "\titers: 200, epoch: 20 | loss: 0.1064007\n",
      "\tspeed: 0.0268s/iter; left time: 480.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1032069 Vali Loss: 0.1206882 Test Loss: 0.1321557\n",
      "Validation loss decreased (0.120879 --> 0.120688).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1015853\n",
      "\tspeed: 0.0545s/iter; left time: 971.9514s\n",
      "\titers: 200, epoch: 21 | loss: 0.1097577\n",
      "\tspeed: 0.0265s/iter; left time: 470.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1029773 Vali Loss: 0.1212966 Test Loss: 0.1336874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1017909\n",
      "\tspeed: 0.0540s/iter; left time: 950.4521s\n",
      "\titers: 200, epoch: 22 | loss: 0.1038301\n",
      "\tspeed: 0.0267s/iter; left time: 466.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1027577 Vali Loss: 0.1214426 Test Loss: 0.1345916\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0982991\n",
      "\tspeed: 0.0535s/iter; left time: 929.2058s\n",
      "\titers: 200, epoch: 23 | loss: 0.1047580\n",
      "\tspeed: 0.0269s/iter; left time: 464.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1027925 Vali Loss: 0.1207157 Test Loss: 0.1328590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1034600\n",
      "\tspeed: 0.0528s/iter; left time: 905.5511s\n",
      "\titers: 200, epoch: 24 | loss: 0.1051510\n",
      "\tspeed: 0.0267s/iter; left time: 455.4818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1025946 Vali Loss: 0.1216530 Test Loss: 0.1352093\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1028438\n",
      "\tspeed: 0.0524s/iter; left time: 886.5080s\n",
      "\titers: 200, epoch: 25 | loss: 0.0966356\n",
      "\tspeed: 0.0269s/iter; left time: 452.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1026048 Vali Loss: 0.1210366 Test Loss: 0.1333753\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1035642\n",
      "\tspeed: 0.0541s/iter; left time: 903.3394s\n",
      "\titers: 200, epoch: 26 | loss: 0.1013549\n",
      "\tspeed: 0.0268s/iter; left time: 445.6060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1023992 Vali Loss: 0.1216036 Test Loss: 0.1348441\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1081149\n",
      "\tspeed: 0.0540s/iter; left time: 890.5193s\n",
      "\titers: 200, epoch: 27 | loss: 0.1037228\n",
      "\tspeed: 0.0268s/iter; left time: 438.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1024023 Vali Loss: 0.1204499 Test Loss: 0.1331628\n",
      "Validation loss decreased (0.120688 --> 0.120450).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1005158\n",
      "\tspeed: 0.0541s/iter; left time: 878.6005s\n",
      "\titers: 200, epoch: 28 | loss: 0.1030452\n",
      "\tspeed: 0.0267s/iter; left time: 430.9146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1023325 Vali Loss: 0.1203885 Test Loss: 0.1324828\n",
      "Validation loss decreased (0.120450 --> 0.120388).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1038010\n",
      "\tspeed: 0.0544s/iter; left time: 871.5227s\n",
      "\titers: 200, epoch: 29 | loss: 0.0961380\n",
      "\tspeed: 0.0268s/iter; left time: 427.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1022584 Vali Loss: 0.1205274 Test Loss: 0.1322376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0989264\n",
      "\tspeed: 0.0537s/iter; left time: 848.0358s\n",
      "\titers: 200, epoch: 30 | loss: 0.1042494\n",
      "\tspeed: 0.0266s/iter; left time: 418.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1021098 Vali Loss: 0.1208396 Test Loss: 0.1335907\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1034334\n",
      "\tspeed: 0.0534s/iter; left time: 832.7826s\n",
      "\titers: 200, epoch: 31 | loss: 0.1014686\n",
      "\tspeed: 0.0269s/iter; left time: 416.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1020975 Vali Loss: 0.1210884 Test Loss: 0.1335009\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1016325\n",
      "\tspeed: 0.0534s/iter; left time: 819.5112s\n",
      "\titers: 200, epoch: 32 | loss: 0.1032996\n",
      "\tspeed: 0.0267s/iter; left time: 407.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1019933 Vali Loss: 0.1205121 Test Loss: 0.1333751\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1052899\n",
      "\tspeed: 0.0540s/iter; left time: 817.5288s\n",
      "\titers: 200, epoch: 33 | loss: 0.0988395\n",
      "\tspeed: 0.0268s/iter; left time: 403.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.1020614 Vali Loss: 0.1206313 Test Loss: 0.1333139\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1053393\n",
      "\tspeed: 0.0541s/iter; left time: 807.0602s\n",
      "\titers: 200, epoch: 34 | loss: 0.1010254\n",
      "\tspeed: 0.0266s/iter; left time: 393.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1019011 Vali Loss: 0.1207969 Test Loss: 0.1332408\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1035039\n",
      "\tspeed: 0.0542s/iter; left time: 796.0329s\n",
      "\titers: 200, epoch: 35 | loss: 0.1049854\n",
      "\tspeed: 0.0267s/iter; left time: 389.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1019402 Vali Loss: 0.1208092 Test Loss: 0.1337095\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1013041\n",
      "\tspeed: 0.0525s/iter; left time: 758.7460s\n",
      "\titers: 200, epoch: 36 | loss: 0.0980874\n",
      "\tspeed: 0.0265s/iter; left time: 381.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.1018536 Vali Loss: 0.1204284 Test Loss: 0.1332987\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1045307\n",
      "\tspeed: 0.0539s/iter; left time: 766.9765s\n",
      "\titers: 200, epoch: 37 | loss: 0.0954375\n",
      "\tspeed: 0.0269s/iter; left time: 379.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1018151 Vali Loss: 0.1215746 Test Loss: 0.1352356\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1059201\n",
      "\tspeed: 0.0533s/iter; left time: 746.3598s\n",
      "\titers: 200, epoch: 38 | loss: 0.1002588\n",
      "\tspeed: 0.0266s/iter; left time: 369.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1018667 Vali Loss: 0.1203720 Test Loss: 0.1324616\n",
      "Validation loss decreased (0.120388 --> 0.120372).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1054295\n",
      "\tspeed: 0.0541s/iter; left time: 746.1437s\n",
      "\titers: 200, epoch: 39 | loss: 0.1024275\n",
      "\tspeed: 0.0267s/iter; left time: 365.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1018485 Vali Loss: 0.1205335 Test Loss: 0.1327809\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1032095\n",
      "\tspeed: 0.0531s/iter; left time: 719.7531s\n",
      "\titers: 200, epoch: 40 | loss: 0.1009113\n",
      "\tspeed: 0.0265s/iter; left time: 357.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1018323 Vali Loss: 0.1206866 Test Loss: 0.1337668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1007862\n",
      "\tspeed: 0.0533s/iter; left time: 711.3404s\n",
      "\titers: 200, epoch: 41 | loss: 0.1018894\n",
      "\tspeed: 0.0266s/iter; left time: 352.1950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1017909 Vali Loss: 0.1210196 Test Loss: 0.1332831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1013647\n",
      "\tspeed: 0.0541s/iter; left time: 710.2563s\n",
      "\titers: 200, epoch: 42 | loss: 0.1019138\n",
      "\tspeed: 0.0266s/iter; left time: 346.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.1017286 Vali Loss: 0.1206163 Test Loss: 0.1335710\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0992487\n",
      "\tspeed: 0.0528s/iter; left time: 681.3525s\n",
      "\titers: 200, epoch: 43 | loss: 0.1036323\n",
      "\tspeed: 0.0265s/iter; left time: 338.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.1017129 Vali Loss: 0.1208370 Test Loss: 0.1340242\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1043643\n",
      "\tspeed: 0.0525s/iter; left time: 664.4967s\n",
      "\titers: 200, epoch: 44 | loss: 0.1003388\n",
      "\tspeed: 0.0265s/iter; left time: 333.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.1017266 Vali Loss: 0.1208941 Test Loss: 0.1337463\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0952285\n",
      "\tspeed: 0.0535s/iter; left time: 666.1059s\n",
      "\titers: 200, epoch: 45 | loss: 0.0951335\n",
      "\tspeed: 0.0270s/iter; left time: 333.0809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1016882 Vali Loss: 0.1207762 Test Loss: 0.1334585\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0998819\n",
      "\tspeed: 0.0534s/iter; left time: 652.0819s\n",
      "\titers: 200, epoch: 46 | loss: 0.1063564\n",
      "\tspeed: 0.0266s/iter; left time: 322.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1016775 Vali Loss: 0.1205455 Test Loss: 0.1334468\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1025925\n",
      "\tspeed: 0.0534s/iter; left time: 640.1678s\n",
      "\titers: 200, epoch: 47 | loss: 0.1063050\n",
      "\tspeed: 0.0267s/iter; left time: 317.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1016528 Vali Loss: 0.1207108 Test Loss: 0.1335262\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1062247\n",
      "\tspeed: 0.0539s/iter; left time: 634.4334s\n",
      "\titers: 200, epoch: 48 | loss: 0.1005530\n",
      "\tspeed: 0.0268s/iter; left time: 312.7111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.1016578 Vali Loss: 0.1206686 Test Loss: 0.1333757\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04114912077784538, rmse:0.20285245776176453, mae:0.13246160745620728, rse:0.718341588973999\n",
      "Intermediate time for DE and pred_len 96: 00h:12m:26.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2694588\n",
      "\tspeed: 0.0552s/iter; left time: 1224.7381s\n",
      "\titers: 200, epoch: 1 | loss: 0.2494408\n",
      "\tspeed: 0.0271s/iter; left time: 598.0186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.2678130 Vali Loss: 0.2256625 Test Loss: 0.2271173\n",
      "Validation loss decreased (inf --> 0.225662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1588242\n",
      "\tspeed: 0.0538s/iter; left time: 1182.2961s\n",
      "\titers: 200, epoch: 2 | loss: 0.1380554\n",
      "\tspeed: 0.0270s/iter; left time: 591.3112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1643799 Vali Loss: 0.1423661 Test Loss: 0.1508600\n",
      "Validation loss decreased (0.225662 --> 0.142366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1310375\n",
      "\tspeed: 0.0547s/iter; left time: 1189.6865s\n",
      "\titers: 200, epoch: 3 | loss: 0.1250534\n",
      "\tspeed: 0.0272s/iter; left time: 589.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1280863 Vali Loss: 0.1337826 Test Loss: 0.1466388\n",
      "Validation loss decreased (0.142366 --> 0.133783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1168175\n",
      "\tspeed: 0.0558s/iter; left time: 1201.8038s\n",
      "\titers: 200, epoch: 4 | loss: 0.1242551\n",
      "\tspeed: 0.0271s/iter; left time: 581.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1204302 Vali Loss: 0.1299775 Test Loss: 0.1410140\n",
      "Validation loss decreased (0.133783 --> 0.129977).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1135532\n",
      "\tspeed: 0.0549s/iter; left time: 1170.3497s\n",
      "\titers: 200, epoch: 5 | loss: 0.1206374\n",
      "\tspeed: 0.0271s/iter; left time: 575.1671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1170739 Vali Loss: 0.1344015 Test Loss: 0.1487388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1135251\n",
      "\tspeed: 0.0537s/iter; left time: 1131.7627s\n",
      "\titers: 200, epoch: 6 | loss: 0.1191229\n",
      "\tspeed: 0.0271s/iter; left time: 568.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1156737 Vali Loss: 0.1268869 Test Loss: 0.1388794\n",
      "Validation loss decreased (0.129977 --> 0.126887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1148158\n",
      "\tspeed: 0.0568s/iter; left time: 1184.1567s\n",
      "\titers: 200, epoch: 7 | loss: 0.1113933\n",
      "\tspeed: 0.0275s/iter; left time: 571.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.1136320 Vali Loss: 0.1272786 Test Loss: 0.1386431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1087779\n",
      "\tspeed: 0.0543s/iter; left time: 1121.3235s\n",
      "\titers: 200, epoch: 8 | loss: 0.1179757\n",
      "\tspeed: 0.0270s/iter; left time: 554.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1128987 Vali Loss: 0.1260758 Test Loss: 0.1385074\n",
      "Validation loss decreased (0.126887 --> 0.126076).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1112111\n",
      "\tspeed: 0.0562s/iter; left time: 1147.8760s\n",
      "\titers: 200, epoch: 9 | loss: 0.1040103\n",
      "\tspeed: 0.0271s/iter; left time: 550.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1120882 Vali Loss: 0.1248956 Test Loss: 0.1389382\n",
      "Validation loss decreased (0.126076 --> 0.124896).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1084555\n",
      "\tspeed: 0.0540s/iter; left time: 1090.7371s\n",
      "\titers: 200, epoch: 10 | loss: 0.1098599\n",
      "\tspeed: 0.0269s/iter; left time: 541.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.1114377 Vali Loss: 0.1259496 Test Loss: 0.1390752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1112702\n",
      "\tspeed: 0.0532s/iter; left time: 1062.3973s\n",
      "\titers: 200, epoch: 11 | loss: 0.1071776\n",
      "\tspeed: 0.0270s/iter; left time: 535.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1108791 Vali Loss: 0.1254558 Test Loss: 0.1400634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1060586\n",
      "\tspeed: 0.0544s/iter; left time: 1073.7341s\n",
      "\titers: 200, epoch: 12 | loss: 0.1133663\n",
      "\tspeed: 0.0271s/iter; left time: 531.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1103929 Vali Loss: 0.1251655 Test Loss: 0.1393932\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1157562\n",
      "\tspeed: 0.0548s/iter; left time: 1069.7461s\n",
      "\titers: 200, epoch: 13 | loss: 0.1112933\n",
      "\tspeed: 0.0270s/iter; left time: 524.8407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1099508 Vali Loss: 0.1248499 Test Loss: 0.1389184\n",
      "Validation loss decreased (0.124896 --> 0.124850).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1031506\n",
      "\tspeed: 0.0547s/iter; left time: 1056.6042s\n",
      "\titers: 200, epoch: 14 | loss: 0.1168942\n",
      "\tspeed: 0.0272s/iter; left time: 522.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1096748 Vali Loss: 0.1241475 Test Loss: 0.1385670\n",
      "Validation loss decreased (0.124850 --> 0.124147).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1090125\n",
      "\tspeed: 0.0588s/iter; left time: 1122.7144s\n",
      "\titers: 200, epoch: 15 | loss: 0.1169378\n",
      "\tspeed: 0.0271s/iter; left time: 513.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1092719 Vali Loss: 0.1249807 Test Loss: 0.1392617\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1112845\n",
      "\tspeed: 0.0547s/iter; left time: 1030.9061s\n",
      "\titers: 200, epoch: 16 | loss: 0.1171693\n",
      "\tspeed: 0.0271s/iter; left time: 507.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1090011 Vali Loss: 0.1237507 Test Loss: 0.1397156\n",
      "Validation loss decreased (0.124147 --> 0.123751).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085970\n",
      "\tspeed: 0.0552s/iter; left time: 1027.7934s\n",
      "\titers: 200, epoch: 17 | loss: 0.1124511\n",
      "\tspeed: 0.0271s/iter; left time: 502.2944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1088298 Vali Loss: 0.1237531 Test Loss: 0.1388248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1071712\n",
      "\tspeed: 0.0542s/iter; left time: 997.9987s\n",
      "\titers: 200, epoch: 18 | loss: 0.1117891\n",
      "\tspeed: 0.0271s/iter; left time: 496.0025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1085106 Vali Loss: 0.1250654 Test Loss: 0.1391321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1095252\n",
      "\tspeed: 0.0543s/iter; left time: 986.8619s\n",
      "\titers: 200, epoch: 19 | loss: 0.1084045\n",
      "\tspeed: 0.0271s/iter; left time: 489.5136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1083448 Vali Loss: 0.1253616 Test Loss: 0.1393350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1102001\n",
      "\tspeed: 0.0546s/iter; left time: 981.6163s\n",
      "\titers: 200, epoch: 20 | loss: 0.1061500\n",
      "\tspeed: 0.0270s/iter; left time: 482.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1081657 Vali Loss: 0.1245547 Test Loss: 0.1393294\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1117846\n",
      "\tspeed: 0.0545s/iter; left time: 966.7442s\n",
      "\titers: 200, epoch: 21 | loss: 0.1123026\n",
      "\tspeed: 0.0270s/iter; left time: 476.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1079122 Vali Loss: 0.1238274 Test Loss: 0.1397963\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1029315\n",
      "\tspeed: 0.0542s/iter; left time: 949.4588s\n",
      "\titers: 200, epoch: 22 | loss: 0.1159650\n",
      "\tspeed: 0.0270s/iter; left time: 469.7862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1077999 Vali Loss: 0.1237673 Test Loss: 0.1400765\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1040981\n",
      "\tspeed: 0.0549s/iter; left time: 949.2440s\n",
      "\titers: 200, epoch: 23 | loss: 0.1068356\n",
      "\tspeed: 0.0273s/iter; left time: 468.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1077011 Vali Loss: 0.1238438 Test Loss: 0.1395416\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1130653\n",
      "\tspeed: 0.0545s/iter; left time: 929.7970s\n",
      "\titers: 200, epoch: 24 | loss: 0.1057272\n",
      "\tspeed: 0.0271s/iter; left time: 459.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1076156 Vali Loss: 0.1240128 Test Loss: 0.1398824\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1053374\n",
      "\tspeed: 0.0574s/iter; left time: 967.4682s\n",
      "\titers: 200, epoch: 25 | loss: 0.1097853\n",
      "\tspeed: 0.0274s/iter; left time: 458.1337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 223 | Train Loss: 0.1075735 Vali Loss: 0.1251452 Test Loss: 0.1397400\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1110702\n",
      "\tspeed: 0.0545s/iter; left time: 906.2075s\n",
      "\titers: 200, epoch: 26 | loss: 0.1068365\n",
      "\tspeed: 0.0273s/iter; left time: 450.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1074012 Vali Loss: 0.1236224 Test Loss: 0.1401185\n",
      "Validation loss decreased (0.123751 --> 0.123622).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1045682\n",
      "\tspeed: 0.0552s/iter; left time: 905.0831s\n",
      "\titers: 200, epoch: 27 | loss: 0.1105434\n",
      "\tspeed: 0.0270s/iter; left time: 440.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1073121 Vali Loss: 0.1244636 Test Loss: 0.1406418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1013705\n",
      "\tspeed: 0.0537s/iter; left time: 868.1799s\n",
      "\titers: 200, epoch: 28 | loss: 0.1062632\n",
      "\tspeed: 0.0270s/iter; left time: 434.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1071771 Vali Loss: 0.1245068 Test Loss: 0.1402753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1071039\n",
      "\tspeed: 0.0542s/iter; left time: 864.4046s\n",
      "\titers: 200, epoch: 29 | loss: 0.1107840\n",
      "\tspeed: 0.0269s/iter; left time: 427.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1071781 Vali Loss: 0.1247383 Test Loss: 0.1401076\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1089579\n",
      "\tspeed: 0.0541s/iter; left time: 851.6652s\n",
      "\titers: 200, epoch: 30 | loss: 0.1040116\n",
      "\tspeed: 0.0270s/iter; left time: 421.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1070503 Vali Loss: 0.1241704 Test Loss: 0.1408251\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1058714\n",
      "\tspeed: 0.0551s/iter; left time: 853.9583s\n",
      "\titers: 200, epoch: 31 | loss: 0.1062244\n",
      "\tspeed: 0.0271s/iter; left time: 417.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1070863 Vali Loss: 0.1242928 Test Loss: 0.1399416\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1062264\n",
      "\tspeed: 0.0548s/iter; left time: 838.3116s\n",
      "\titers: 200, epoch: 32 | loss: 0.1099966\n",
      "\tspeed: 0.0270s/iter; left time: 410.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1069084 Vali Loss: 0.1242390 Test Loss: 0.1404155\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1034179\n",
      "\tspeed: 0.0549s/iter; left time: 827.4123s\n",
      "\titers: 200, epoch: 33 | loss: 0.1076491\n",
      "\tspeed: 0.0270s/iter; left time: 403.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1068814 Vali Loss: 0.1246129 Test Loss: 0.1405573\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1070711\n",
      "\tspeed: 0.0549s/iter; left time: 815.2384s\n",
      "\titers: 200, epoch: 34 | loss: 0.1085021\n",
      "\tspeed: 0.0271s/iter; left time: 398.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1069560 Vali Loss: 0.1244370 Test Loss: 0.1408949\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1049294\n",
      "\tspeed: 0.0545s/iter; left time: 797.3256s\n",
      "\titers: 200, epoch: 35 | loss: 0.1038471\n",
      "\tspeed: 0.0271s/iter; left time: 393.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1068299 Vali Loss: 0.1241320 Test Loss: 0.1411497\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1098494\n",
      "\tspeed: 0.0543s/iter; left time: 782.0134s\n",
      "\titers: 200, epoch: 36 | loss: 0.1050852\n",
      "\tspeed: 0.0269s/iter; left time: 385.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1068699 Vali Loss: 0.1244320 Test Loss: 0.1406202\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04431525990366936, rmse:0.21051189303398132, mae:0.1401185244321823, rse:0.745650053024292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2717605\n",
      "\tspeed: 0.0295s/iter; left time: 654.4038s\n",
      "\titers: 200, epoch: 1 | loss: 0.2497348\n",
      "\tspeed: 0.0272s/iter; left time: 600.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.2706402 Vali Loss: 0.2244382 Test Loss: 0.2255183\n",
      "Validation loss decreased (inf --> 0.224438).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1527811\n",
      "\tspeed: 0.0557s/iter; left time: 1224.9892s\n",
      "\titers: 200, epoch: 2 | loss: 0.1387502\n",
      "\tspeed: 0.0271s/iter; left time: 592.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1653805 Vali Loss: 0.1436438 Test Loss: 0.1523493\n",
      "Validation loss decreased (0.224438 --> 0.143644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1230632\n",
      "\tspeed: 0.0557s/iter; left time: 1212.0715s\n",
      "\titers: 200, epoch: 3 | loss: 0.1206774\n",
      "\tspeed: 0.0270s/iter; left time: 583.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1282984 Vali Loss: 0.1361505 Test Loss: 0.1495952\n",
      "Validation loss decreased (0.143644 --> 0.136151).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1197004\n",
      "\tspeed: 0.0550s/iter; left time: 1185.1254s\n",
      "\titers: 200, epoch: 4 | loss: 0.1239574\n",
      "\tspeed: 0.0270s/iter; left time: 578.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1201374 Vali Loss: 0.1296212 Test Loss: 0.1417666\n",
      "Validation loss decreased (0.136151 --> 0.129621).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1169373\n",
      "\tspeed: 0.0556s/iter; left time: 1184.0687s\n",
      "\titers: 200, epoch: 5 | loss: 0.1243026\n",
      "\tspeed: 0.0271s/iter; left time: 575.5743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1167164 Vali Loss: 0.1283937 Test Loss: 0.1403232\n",
      "Validation loss decreased (0.129621 --> 0.128394).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118112\n",
      "\tspeed: 0.0564s/iter; left time: 1188.5351s\n",
      "\titers: 200, epoch: 6 | loss: 0.1142436\n",
      "\tspeed: 0.0271s/iter; left time: 568.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1147682 Vali Loss: 0.1283294 Test Loss: 0.1415380\n",
      "Validation loss decreased (0.128394 --> 0.128329).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1179367\n",
      "\tspeed: 0.0561s/iter; left time: 1171.1309s\n",
      "\titers: 200, epoch: 7 | loss: 0.1164256\n",
      "\tspeed: 0.0274s/iter; left time: 567.9589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1136461 Vali Loss: 0.1264505 Test Loss: 0.1372013\n",
      "Validation loss decreased (0.128329 --> 0.126451).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1085146\n",
      "\tspeed: 0.0555s/iter; left time: 1146.3352s\n",
      "\titers: 200, epoch: 8 | loss: 0.1157306\n",
      "\tspeed: 0.0270s/iter; left time: 554.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1126392 Vali Loss: 0.1277611 Test Loss: 0.1413333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1089189\n",
      "\tspeed: 0.0547s/iter; left time: 1116.3828s\n",
      "\titers: 200, epoch: 9 | loss: 0.1077685\n",
      "\tspeed: 0.0270s/iter; left time: 549.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1121741 Vali Loss: 0.1275626 Test Loss: 0.1438202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1066347\n",
      "\tspeed: 0.0557s/iter; left time: 1123.8937s\n",
      "\titers: 200, epoch: 10 | loss: 0.1085937\n",
      "\tspeed: 0.0270s/iter; left time: 543.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1113941 Vali Loss: 0.1272142 Test Loss: 0.1444350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1123278\n",
      "\tspeed: 0.0551s/iter; left time: 1101.0992s\n",
      "\titers: 200, epoch: 11 | loss: 0.1101279\n",
      "\tspeed: 0.0269s/iter; left time: 534.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1109960 Vali Loss: 0.1259657 Test Loss: 0.1395051\n",
      "Validation loss decreased (0.126451 --> 0.125966).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1070488\n",
      "\tspeed: 0.0550s/iter; left time: 1086.2275s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095819\n",
      "\tspeed: 0.0270s/iter; left time: 531.2348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1104357 Vali Loss: 0.1272518 Test Loss: 0.1414926\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1036251\n",
      "\tspeed: 0.0554s/iter; left time: 1080.9484s\n",
      "\titers: 200, epoch: 13 | loss: 0.1088385\n",
      "\tspeed: 0.0271s/iter; left time: 526.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1099431 Vali Loss: 0.1252747 Test Loss: 0.1399227\n",
      "Validation loss decreased (0.125966 --> 0.125275).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1030467\n",
      "\tspeed: 0.0563s/iter; left time: 1087.3423s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086750\n",
      "\tspeed: 0.0271s/iter; left time: 519.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1096007 Vali Loss: 0.1251468 Test Loss: 0.1390274\n",
      "Validation loss decreased (0.125275 --> 0.125147).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1130099\n",
      "\tspeed: 0.0553s/iter; left time: 1054.7983s\n",
      "\titers: 200, epoch: 15 | loss: 0.1032722\n",
      "\tspeed: 0.0271s/iter; left time: 514.9943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1093529 Vali Loss: 0.1260432 Test Loss: 0.1412244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1124173\n",
      "\tspeed: 0.0547s/iter; left time: 1031.7254s\n",
      "\titers: 200, epoch: 16 | loss: 0.1127571\n",
      "\tspeed: 0.0270s/iter; left time: 506.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1091081 Vali Loss: 0.1250219 Test Loss: 0.1372206\n",
      "Validation loss decreased (0.125147 --> 0.125022).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1095243\n",
      "\tspeed: 0.0562s/iter; left time: 1047.0096s\n",
      "\titers: 200, epoch: 17 | loss: 0.1056836\n",
      "\tspeed: 0.0270s/iter; left time: 500.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1088649 Vali Loss: 0.1250639 Test Loss: 0.1414303\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073400\n",
      "\tspeed: 0.0554s/iter; left time: 1019.8852s\n",
      "\titers: 200, epoch: 18 | loss: 0.1063695\n",
      "\tspeed: 0.0270s/iter; left time: 494.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1084461 Vali Loss: 0.1252620 Test Loss: 0.1424867\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1156768\n",
      "\tspeed: 0.0545s/iter; left time: 991.4157s\n",
      "\titers: 200, epoch: 19 | loss: 0.1058337\n",
      "\tspeed: 0.0270s/iter; left time: 488.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1083064 Vali Loss: 0.1245592 Test Loss: 0.1410565\n",
      "Validation loss decreased (0.125022 --> 0.124559).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1095986\n",
      "\tspeed: 0.0549s/iter; left time: 986.9857s\n",
      "\titers: 200, epoch: 20 | loss: 0.1091317\n",
      "\tspeed: 0.0270s/iter; left time: 482.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1080848 Vali Loss: 0.1245383 Test Loss: 0.1408349\n",
      "Validation loss decreased (0.124559 --> 0.124538).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1101300\n",
      "\tspeed: 0.0553s/iter; left time: 981.7747s\n",
      "\titers: 200, epoch: 21 | loss: 0.1040779\n",
      "\tspeed: 0.0270s/iter; left time: 476.9504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1079569 Vali Loss: 0.1243153 Test Loss: 0.1404460\n",
      "Validation loss decreased (0.124538 --> 0.124315).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1128185\n",
      "\tspeed: 0.0568s/iter; left time: 995.7225s\n",
      "\titers: 200, epoch: 22 | loss: 0.1128093\n",
      "\tspeed: 0.0271s/iter; left time: 471.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.1076719 Vali Loss: 0.1247798 Test Loss: 0.1418921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1050721\n",
      "\tspeed: 0.0555s/iter; left time: 959.1245s\n",
      "\titers: 200, epoch: 23 | loss: 0.1063960\n",
      "\tspeed: 0.0270s/iter; left time: 463.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1075455 Vali Loss: 0.1248229 Test Loss: 0.1425713\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1091020\n",
      "\tspeed: 0.0544s/iter; left time: 928.7713s\n",
      "\titers: 200, epoch: 24 | loss: 0.1096076\n",
      "\tspeed: 0.0270s/iter; left time: 458.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1073950 Vali Loss: 0.1245639 Test Loss: 0.1406815\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1097365\n",
      "\tspeed: 0.0542s/iter; left time: 913.7001s\n",
      "\titers: 200, epoch: 25 | loss: 0.1018156\n",
      "\tspeed: 0.0270s/iter; left time: 451.3987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1073257 Vali Loss: 0.1250512 Test Loss: 0.1418965\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1078187\n",
      "\tspeed: 0.0549s/iter; left time: 912.7843s\n",
      "\titers: 200, epoch: 26 | loss: 0.1050411\n",
      "\tspeed: 0.0273s/iter; left time: 450.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1071412 Vali Loss: 0.1250405 Test Loss: 0.1421759\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1098222\n",
      "\tspeed: 0.0550s/iter; left time: 901.3794s\n",
      "\titers: 200, epoch: 27 | loss: 0.1058681\n",
      "\tspeed: 0.0270s/iter; left time: 440.7958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1070719 Vali Loss: 0.1245344 Test Loss: 0.1412885\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1065511\n",
      "\tspeed: 0.0553s/iter; left time: 894.4245s\n",
      "\titers: 200, epoch: 28 | loss: 0.1106282\n",
      "\tspeed: 0.0270s/iter; left time: 434.8052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1069628 Vali Loss: 0.1253483 Test Loss: 0.1421668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1023793\n",
      "\tspeed: 0.0545s/iter; left time: 870.1654s\n",
      "\titers: 200, epoch: 29 | loss: 0.1069401\n",
      "\tspeed: 0.0270s/iter; left time: 428.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1069073 Vali Loss: 0.1242450 Test Loss: 0.1414697\n",
      "Validation loss decreased (0.124315 --> 0.124245).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1019570\n",
      "\tspeed: 0.0557s/iter; left time: 876.1648s\n",
      "\titers: 200, epoch: 30 | loss: 0.1062927\n",
      "\tspeed: 0.0269s/iter; left time: 421.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1068318 Vali Loss: 0.1248964 Test Loss: 0.1429121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1077381\n",
      "\tspeed: 0.0546s/iter; left time: 846.6325s\n",
      "\titers: 200, epoch: 31 | loss: 0.1063283\n",
      "\tspeed: 0.0270s/iter; left time: 416.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1067886 Vali Loss: 0.1251295 Test Loss: 0.1429515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1073042\n",
      "\tspeed: 0.0544s/iter; left time: 831.3801s\n",
      "\titers: 200, epoch: 32 | loss: 0.1063897\n",
      "\tspeed: 0.0270s/iter; left time: 410.4489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1067653 Vali Loss: 0.1244331 Test Loss: 0.1432744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1053505\n",
      "\tspeed: 0.0554s/iter; left time: 834.1189s\n",
      "\titers: 200, epoch: 33 | loss: 0.1072904\n",
      "\tspeed: 0.0280s/iter; left time: 419.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.1065941 Vali Loss: 0.1245723 Test Loss: 0.1420990\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1058740\n",
      "\tspeed: 0.0553s/iter; left time: 820.2343s\n",
      "\titers: 200, epoch: 34 | loss: 0.1065225\n",
      "\tspeed: 0.0273s/iter; left time: 402.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1065375 Vali Loss: 0.1245974 Test Loss: 0.1424081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1051413\n",
      "\tspeed: 0.0553s/iter; left time: 807.9574s\n",
      "\titers: 200, epoch: 35 | loss: 0.0990082\n",
      "\tspeed: 0.0275s/iter; left time: 398.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1066114 Vali Loss: 0.1243352 Test Loss: 0.1414857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1041255\n",
      "\tspeed: 0.0558s/iter; left time: 803.5647s\n",
      "\titers: 200, epoch: 36 | loss: 0.1066304\n",
      "\tspeed: 0.0272s/iter; left time: 389.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1064593 Vali Loss: 0.1244077 Test Loss: 0.1428552\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1080189\n",
      "\tspeed: 0.0553s/iter; left time: 783.4120s\n",
      "\titers: 200, epoch: 37 | loss: 0.1072931\n",
      "\tspeed: 0.0272s/iter; left time: 382.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1064730 Vali Loss: 0.1247789 Test Loss: 0.1439544\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1067841\n",
      "\tspeed: 0.0558s/iter; left time: 778.7763s\n",
      "\titers: 200, epoch: 38 | loss: 0.1071450\n",
      "\tspeed: 0.0272s/iter; left time: 376.7000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1064397 Vali Loss: 0.1247913 Test Loss: 0.1433378\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1057215\n",
      "\tspeed: 0.0550s/iter; left time: 755.6179s\n",
      "\titers: 200, epoch: 39 | loss: 0.1080193\n",
      "\tspeed: 0.0272s/iter; left time: 370.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1064028 Vali Loss: 0.1242686 Test Loss: 0.1419638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04567323625087738, rmse:0.21371297538280487, mae:0.14146965742111206, rse:0.7569885849952698\n",
      "Intermediate time for DE and pred_len 168: 00h:10m:30.76s\n",
      "Intermediate time for DE: 00h:36m:45.02s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2768023\n",
      "\tspeed: 0.0520s/iter; left time: 1160.3643s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690596\n",
      "\tspeed: 0.0263s/iter; left time: 584.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.2826750 Vali Loss: 0.2354308 Test Loss: 0.2522551\n",
      "Validation loss decreased (inf --> 0.235431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1396006\n",
      "\tspeed: 0.0511s/iter; left time: 1127.8921s\n",
      "\titers: 200, epoch: 2 | loss: 0.1164763\n",
      "\tspeed: 0.0264s/iter; left time: 579.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.1529604 Vali Loss: 0.1122059 Test Loss: 0.1267973\n",
      "Validation loss decreased (0.235431 --> 0.112206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0966394\n",
      "\tspeed: 0.0526s/iter; left time: 1149.1262s\n",
      "\titers: 200, epoch: 3 | loss: 0.0966364\n",
      "\tspeed: 0.0265s/iter; left time: 575.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1003180 Vali Loss: 0.0975877 Test Loss: 0.1097753\n",
      "Validation loss decreased (0.112206 --> 0.097588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853399\n",
      "\tspeed: 0.0513s/iter; left time: 1109.6436s\n",
      "\titers: 200, epoch: 4 | loss: 0.0865217\n",
      "\tspeed: 0.0264s/iter; left time: 569.2754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0909225 Vali Loss: 0.0965700 Test Loss: 0.1102376\n",
      "Validation loss decreased (0.097588 --> 0.096570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861233\n",
      "\tspeed: 0.0511s/iter; left time: 1093.1139s\n",
      "\titers: 200, epoch: 5 | loss: 0.0854768\n",
      "\tspeed: 0.0264s/iter; left time: 562.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0870366 Vali Loss: 0.0945423 Test Loss: 0.1075835\n",
      "Validation loss decreased (0.096570 --> 0.094542).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0900608\n",
      "\tspeed: 0.0511s/iter; left time: 1081.4984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898061\n",
      "\tspeed: 0.0265s/iter; left time: 557.9827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0854425 Vali Loss: 0.0940791 Test Loss: 0.1066109\n",
      "Validation loss decreased (0.094542 --> 0.094079).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0848851\n",
      "\tspeed: 0.0524s/iter; left time: 1098.2402s\n",
      "\titers: 200, epoch: 7 | loss: 0.0917123\n",
      "\tspeed: 0.0265s/iter; left time: 553.0558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0843855 Vali Loss: 0.0945964 Test Loss: 0.1069779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0866622\n",
      "\tspeed: 0.0512s/iter; left time: 1061.4857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893530\n",
      "\tspeed: 0.0263s/iter; left time: 543.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0836836 Vali Loss: 0.0930915 Test Loss: 0.1061764\n",
      "Validation loss decreased (0.094079 --> 0.093092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0803224\n",
      "\tspeed: 0.0511s/iter; left time: 1049.0163s\n",
      "\titers: 200, epoch: 9 | loss: 0.0854001\n",
      "\tspeed: 0.0263s/iter; left time: 535.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0823254 Vali Loss: 0.0925307 Test Loss: 0.1057673\n",
      "Validation loss decreased (0.093092 --> 0.092531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0864102\n",
      "\tspeed: 0.0513s/iter; left time: 1041.6057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792464\n",
      "\tspeed: 0.0264s/iter; left time: 532.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0817801 Vali Loss: 0.0928679 Test Loss: 0.1055995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0835089\n",
      "\tspeed: 0.0510s/iter; left time: 1022.8234s\n",
      "\titers: 200, epoch: 11 | loss: 0.0814737\n",
      "\tspeed: 0.0271s/iter; left time: 541.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0812240 Vali Loss: 0.0922058 Test Loss: 0.1056192\n",
      "Validation loss decreased (0.092531 --> 0.092206).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0846820\n",
      "\tspeed: 0.0516s/iter; left time: 1023.9693s\n",
      "\titers: 200, epoch: 12 | loss: 0.0766829\n",
      "\tspeed: 0.0265s/iter; left time: 522.5596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0808361 Vali Loss: 0.0920979 Test Loss: 0.1049938\n",
      "Validation loss decreased (0.092206 --> 0.092098).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0781128\n",
      "\tspeed: 0.0523s/iter; left time: 1026.0289s\n",
      "\titers: 200, epoch: 13 | loss: 0.0791380\n",
      "\tspeed: 0.0266s/iter; left time: 519.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0807068 Vali Loss: 0.0919241 Test Loss: 0.1046759\n",
      "Validation loss decreased (0.092098 --> 0.091924).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0847301\n",
      "\tspeed: 0.0527s/iter; left time: 1022.6688s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746568\n",
      "\tspeed: 0.0268s/iter; left time: 517.3736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0801385 Vali Loss: 0.0931495 Test Loss: 0.1059648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733164\n",
      "\tspeed: 0.0512s/iter; left time: 981.9909s\n",
      "\titers: 200, epoch: 15 | loss: 0.0755852\n",
      "\tspeed: 0.0263s/iter; left time: 502.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0798146 Vali Loss: 0.0925728 Test Loss: 0.1053378\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780552\n",
      "\tspeed: 0.0515s/iter; left time: 976.2470s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810713\n",
      "\tspeed: 0.0268s/iter; left time: 504.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0796394 Vali Loss: 0.0917714 Test Loss: 0.1051183\n",
      "Validation loss decreased (0.091924 --> 0.091771).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0804468\n",
      "\tspeed: 0.0523s/iter; left time: 979.7383s\n",
      "\titers: 200, epoch: 17 | loss: 0.0858267\n",
      "\tspeed: 0.0265s/iter; left time: 493.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0794315 Vali Loss: 0.0931107 Test Loss: 0.1060146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0788002\n",
      "\tspeed: 0.0510s/iter; left time: 943.6644s\n",
      "\titers: 200, epoch: 18 | loss: 0.0785697\n",
      "\tspeed: 0.0266s/iter; left time: 489.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0792040 Vali Loss: 0.0925627 Test Loss: 0.1054443\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758029\n",
      "\tspeed: 0.0516s/iter; left time: 942.0671s\n",
      "\titers: 200, epoch: 19 | loss: 0.0807317\n",
      "\tspeed: 0.0267s/iter; left time: 484.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0789865 Vali Loss: 0.0916071 Test Loss: 0.1051683\n",
      "Validation loss decreased (0.091771 --> 0.091607).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0712235\n",
      "\tspeed: 0.0524s/iter; left time: 945.7370s\n",
      "\titers: 200, epoch: 20 | loss: 0.0769432\n",
      "\tspeed: 0.0265s/iter; left time: 475.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0791350 Vali Loss: 0.0927929 Test Loss: 0.1058215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0816098\n",
      "\tspeed: 0.0516s/iter; left time: 919.1630s\n",
      "\titers: 200, epoch: 21 | loss: 0.0770771\n",
      "\tspeed: 0.0266s/iter; left time: 470.8147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0786526 Vali Loss: 0.0916404 Test Loss: 0.1053026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0810547\n",
      "\tspeed: 0.0512s/iter; left time: 900.2478s\n",
      "\titers: 200, epoch: 22 | loss: 0.0723379\n",
      "\tspeed: 0.0267s/iter; left time: 466.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0786124 Vali Loss: 0.0915176 Test Loss: 0.1052929\n",
      "Validation loss decreased (0.091607 --> 0.091518).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0762598\n",
      "\tspeed: 0.0515s/iter; left time: 895.3479s\n",
      "\titers: 200, epoch: 23 | loss: 0.0729632\n",
      "\tspeed: 0.0267s/iter; left time: 460.6804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0783870 Vali Loss: 0.0918097 Test Loss: 0.1056085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0758494\n",
      "\tspeed: 0.0519s/iter; left time: 890.3174s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774529\n",
      "\tspeed: 0.0266s/iter; left time: 453.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0783730 Vali Loss: 0.0919080 Test Loss: 0.1053921\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0797093\n",
      "\tspeed: 0.0507s/iter; left time: 858.3683s\n",
      "\titers: 200, epoch: 25 | loss: 0.0817427\n",
      "\tspeed: 0.0265s/iter; left time: 446.1017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0782914 Vali Loss: 0.0914279 Test Loss: 0.1051226\n",
      "Validation loss decreased (0.091518 --> 0.091428).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797179\n",
      "\tspeed: 0.0520s/iter; left time: 868.1012s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738131\n",
      "\tspeed: 0.0264s/iter; left time: 437.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0780965 Vali Loss: 0.0915349 Test Loss: 0.1052917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776839\n",
      "\tspeed: 0.0510s/iter; left time: 840.6260s\n",
      "\titers: 200, epoch: 27 | loss: 0.0815676\n",
      "\tspeed: 0.0266s/iter; left time: 436.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0779962 Vali Loss: 0.0915907 Test Loss: 0.1057428\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0834855\n",
      "\tspeed: 0.0515s/iter; left time: 836.5873s\n",
      "\titers: 200, epoch: 28 | loss: 0.0779398\n",
      "\tspeed: 0.0263s/iter; left time: 424.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0780605 Vali Loss: 0.0914833 Test Loss: 0.1049431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0809719\n",
      "\tspeed: 0.0509s/iter; left time: 815.9558s\n",
      "\titers: 200, epoch: 29 | loss: 0.0730176\n",
      "\tspeed: 0.0266s/iter; left time: 423.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0779959 Vali Loss: 0.0912019 Test Loss: 0.1048643\n",
      "Validation loss decreased (0.091428 --> 0.091202).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792539\n",
      "\tspeed: 0.0513s/iter; left time: 810.8188s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805271\n",
      "\tspeed: 0.0265s/iter; left time: 415.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0779152 Vali Loss: 0.0916280 Test Loss: 0.1053808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0727329\n",
      "\tspeed: 0.0507s/iter; left time: 789.5886s\n",
      "\titers: 200, epoch: 31 | loss: 0.0777411\n",
      "\tspeed: 0.0264s/iter; left time: 408.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0778470 Vali Loss: 0.0914851 Test Loss: 0.1049981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0777380\n",
      "\tspeed: 0.0507s/iter; left time: 778.8636s\n",
      "\titers: 200, epoch: 32 | loss: 0.0824563\n",
      "\tspeed: 0.0264s/iter; left time: 402.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0779417 Vali Loss: 0.0913363 Test Loss: 0.1053300\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774576\n",
      "\tspeed: 0.0507s/iter; left time: 767.8918s\n",
      "\titers: 200, epoch: 33 | loss: 0.0775550\n",
      "\tspeed: 0.0264s/iter; left time: 396.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0778261 Vali Loss: 0.0914713 Test Loss: 0.1053499\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0793290\n",
      "\tspeed: 0.0505s/iter; left time: 752.6819s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801169\n",
      "\tspeed: 0.0265s/iter; left time: 392.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0778284 Vali Loss: 0.0916595 Test Loss: 0.1053581\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0834418\n",
      "\tspeed: 0.0512s/iter; left time: 751.3283s\n",
      "\titers: 200, epoch: 35 | loss: 0.0801361\n",
      "\tspeed: 0.0266s/iter; left time: 387.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0777533 Vali Loss: 0.0913651 Test Loss: 0.1053995\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0738646\n",
      "\tspeed: 0.0507s/iter; left time: 733.5634s\n",
      "\titers: 200, epoch: 36 | loss: 0.0822736\n",
      "\tspeed: 0.0265s/iter; left time: 380.8086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0777149 Vali Loss: 0.0918364 Test Loss: 0.1053436\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0805845\n",
      "\tspeed: 0.0507s/iter; left time: 722.0075s\n",
      "\titers: 200, epoch: 37 | loss: 0.0764420\n",
      "\tspeed: 0.0271s/iter; left time: 383.0728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0777972 Vali Loss: 0.0913822 Test Loss: 0.1050786\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802590\n",
      "\tspeed: 0.0512s/iter; left time: 718.0743s\n",
      "\titers: 200, epoch: 38 | loss: 0.0745805\n",
      "\tspeed: 0.0264s/iter; left time: 367.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0777992 Vali Loss: 0.0911898 Test Loss: 0.1048385\n",
      "Validation loss decreased (0.091202 --> 0.091190).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0808173\n",
      "\tspeed: 0.0519s/iter; left time: 715.7601s\n",
      "\titers: 200, epoch: 39 | loss: 0.0738091\n",
      "\tspeed: 0.0266s/iter; left time: 364.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0777701 Vali Loss: 0.0913999 Test Loss: 0.1052986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0709983\n",
      "\tspeed: 0.0507s/iter; left time: 687.1930s\n",
      "\titers: 200, epoch: 40 | loss: 0.0794273\n",
      "\tspeed: 0.0263s/iter; left time: 354.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0777075 Vali Loss: 0.0913741 Test Loss: 0.1051616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762141\n",
      "\tspeed: 0.0508s/iter; left time: 677.8248s\n",
      "\titers: 200, epoch: 41 | loss: 0.0792581\n",
      "\tspeed: 0.0264s/iter; left time: 349.8896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0776347 Vali Loss: 0.0914643 Test Loss: 0.1055149\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765117\n",
      "\tspeed: 0.0505s/iter; left time: 662.6103s\n",
      "\titers: 200, epoch: 42 | loss: 0.0817911\n",
      "\tspeed: 0.0266s/iter; left time: 346.0235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0777820 Vali Loss: 0.0912480 Test Loss: 0.1051673\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0792320\n",
      "\tspeed: 0.0520s/iter; left time: 670.1390s\n",
      "\titers: 200, epoch: 43 | loss: 0.0746386\n",
      "\tspeed: 0.0264s/iter; left time: 337.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0775621 Vali Loss: 0.0913317 Test Loss: 0.1051571\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0815854\n",
      "\tspeed: 0.0512s/iter; left time: 648.6464s\n",
      "\titers: 200, epoch: 44 | loss: 0.0786278\n",
      "\tspeed: 0.0265s/iter; left time: 332.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0775377 Vali Loss: 0.0915934 Test Loss: 0.1054193\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0750691\n",
      "\tspeed: 0.0516s/iter; left time: 642.0950s\n",
      "\titers: 200, epoch: 45 | loss: 0.0801307\n",
      "\tspeed: 0.0268s/iter; left time: 330.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0775832 Vali Loss: 0.0914495 Test Loss: 0.1055241\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0750430\n",
      "\tspeed: 0.0510s/iter; left time: 622.7631s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785095\n",
      "\tspeed: 0.0264s/iter; left time: 320.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0776136 Vali Loss: 0.0912142 Test Loss: 0.1048869\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0809008\n",
      "\tspeed: 0.0508s/iter; left time: 609.0180s\n",
      "\titers: 200, epoch: 47 | loss: 0.0786260\n",
      "\tspeed: 0.0263s/iter; left time: 312.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0776177 Vali Loss: 0.0914550 Test Loss: 0.1052804\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0809292\n",
      "\tspeed: 0.0507s/iter; left time: 596.8191s\n",
      "\titers: 200, epoch: 48 | loss: 0.0802007\n",
      "\tspeed: 0.0265s/iter; left time: 309.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0776070 Vali Loss: 0.0912948 Test Loss: 0.1048513\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026396317407488823, rmse:0.16246943175792694, mae:0.10483850538730621, rse:0.5604735016822815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2831325\n",
      "\tspeed: 0.0285s/iter; left time: 634.9854s\n",
      "\titers: 200, epoch: 1 | loss: 0.2748790\n",
      "\tspeed: 0.0263s/iter; left time: 584.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.2827698 Vali Loss: 0.2247546 Test Loss: 0.2389833\n",
      "Validation loss decreased (inf --> 0.224755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1392212\n",
      "\tspeed: 0.0527s/iter; left time: 1162.4602s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127653\n",
      "\tspeed: 0.0263s/iter; left time: 578.9710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.1509554 Vali Loss: 0.1069294 Test Loss: 0.1218970\n",
      "Validation loss decreased (0.224755 --> 0.106929).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1035824\n",
      "\tspeed: 0.0514s/iter; left time: 1123.9124s\n",
      "\titers: 200, epoch: 3 | loss: 0.0969158\n",
      "\tspeed: 0.0263s/iter; left time: 571.9503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.1004396 Vali Loss: 0.0970727 Test Loss: 0.1099363\n",
      "Validation loss decreased (0.106929 --> 0.097073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0924200\n",
      "\tspeed: 0.0515s/iter; left time: 1113.3622s\n",
      "\titers: 200, epoch: 4 | loss: 0.0912534\n",
      "\tspeed: 0.0264s/iter; left time: 567.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0904126 Vali Loss: 0.0982219 Test Loss: 0.1102611\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849355\n",
      "\tspeed: 0.0517s/iter; left time: 1107.6642s\n",
      "\titers: 200, epoch: 5 | loss: 0.0868860\n",
      "\tspeed: 0.0264s/iter; left time: 562.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0871105 Vali Loss: 0.0962601 Test Loss: 0.1084892\n",
      "Validation loss decreased (0.097073 --> 0.096260).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0850953\n",
      "\tspeed: 0.0527s/iter; left time: 1115.3089s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857744\n",
      "\tspeed: 0.0270s/iter; left time: 569.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0857400 Vali Loss: 0.0939873 Test Loss: 0.1071745\n",
      "Validation loss decreased (0.096260 --> 0.093987).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0826016\n",
      "\tspeed: 0.0530s/iter; left time: 1110.1893s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799290\n",
      "\tspeed: 0.0272s/iter; left time: 567.4804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0844087 Vali Loss: 0.0949427 Test Loss: 0.1075168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0785458\n",
      "\tspeed: 0.0516s/iter; left time: 1069.1487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0849302\n",
      "\tspeed: 0.0264s/iter; left time: 544.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0831335 Vali Loss: 0.0931183 Test Loss: 0.1061979\n",
      "Validation loss decreased (0.093987 --> 0.093118).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0863896\n",
      "\tspeed: 0.0514s/iter; left time: 1054.8210s\n",
      "\titers: 200, epoch: 9 | loss: 0.0786775\n",
      "\tspeed: 0.0264s/iter; left time: 538.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0824960 Vali Loss: 0.0940065 Test Loss: 0.1063517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0834831\n",
      "\tspeed: 0.0517s/iter; left time: 1048.3422s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846980\n",
      "\tspeed: 0.0265s/iter; left time: 534.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0817676 Vali Loss: 0.0926972 Test Loss: 0.1058642\n",
      "Validation loss decreased (0.093118 --> 0.092697).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0831312\n",
      "\tspeed: 0.0521s/iter; left time: 1044.6435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0779260\n",
      "\tspeed: 0.0265s/iter; left time: 528.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0816162 Vali Loss: 0.0923844 Test Loss: 0.1052562\n",
      "Validation loss decreased (0.092697 --> 0.092384).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0804793\n",
      "\tspeed: 0.0521s/iter; left time: 1033.8849s\n",
      "\titers: 200, epoch: 12 | loss: 0.0829738\n",
      "\tspeed: 0.0263s/iter; left time: 518.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0814688 Vali Loss: 0.0933902 Test Loss: 0.1054446\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0787470\n",
      "\tspeed: 0.0509s/iter; left time: 997.9265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0772950\n",
      "\tspeed: 0.0263s/iter; left time: 512.8757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0805543 Vali Loss: 0.0942995 Test Loss: 0.1063472\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0808383\n",
      "\tspeed: 0.0518s/iter; left time: 1003.4389s\n",
      "\titers: 200, epoch: 14 | loss: 0.0837163\n",
      "\tspeed: 0.0264s/iter; left time: 508.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0808124 Vali Loss: 0.0934229 Test Loss: 0.1068777\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0774124\n",
      "\tspeed: 0.0512s/iter; left time: 981.4122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799625\n",
      "\tspeed: 0.0263s/iter; left time: 500.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0800025 Vali Loss: 0.0928943 Test Loss: 0.1049107\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0760297\n",
      "\tspeed: 0.0513s/iter; left time: 970.9940s\n",
      "\titers: 200, epoch: 16 | loss: 0.0811618\n",
      "\tspeed: 0.0264s/iter; left time: 496.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0799718 Vali Loss: 0.0917975 Test Loss: 0.1047251\n",
      "Validation loss decreased (0.092384 --> 0.091797).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0785883\n",
      "\tspeed: 0.0518s/iter; left time: 970.3528s\n",
      "\titers: 200, epoch: 17 | loss: 0.0792641\n",
      "\tspeed: 0.0263s/iter; left time: 489.3725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0796954 Vali Loss: 0.0927667 Test Loss: 0.1048445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0823887\n",
      "\tspeed: 0.0519s/iter; left time: 960.0942s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842160\n",
      "\tspeed: 0.0264s/iter; left time: 486.0793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0795874 Vali Loss: 0.0918494 Test Loss: 0.1048132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0840449\n",
      "\tspeed: 0.0510s/iter; left time: 931.9776s\n",
      "\titers: 200, epoch: 19 | loss: 0.0781681\n",
      "\tspeed: 0.0264s/iter; left time: 479.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0795493 Vali Loss: 0.0929090 Test Loss: 0.1050895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0819640\n",
      "\tspeed: 0.0518s/iter; left time: 934.8575s\n",
      "\titers: 200, epoch: 20 | loss: 0.0777349\n",
      "\tspeed: 0.0270s/iter; left time: 484.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0791481 Vali Loss: 0.0918442 Test Loss: 0.1043831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0832979\n",
      "\tspeed: 0.0522s/iter; left time: 930.0349s\n",
      "\titers: 200, epoch: 21 | loss: 0.0786715\n",
      "\tspeed: 0.0267s/iter; left time: 473.4174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0789646 Vali Loss: 0.0917289 Test Loss: 0.1042227\n",
      "Validation loss decreased (0.091797 --> 0.091729).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0795581\n",
      "\tspeed: 0.0516s/iter; left time: 908.4547s\n",
      "\titers: 200, epoch: 22 | loss: 0.0778644\n",
      "\tspeed: 0.0263s/iter; left time: 460.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0788485 Vali Loss: 0.0922574 Test Loss: 0.1046677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0764752\n",
      "\tspeed: 0.0512s/iter; left time: 889.9035s\n",
      "\titers: 200, epoch: 23 | loss: 0.0785109\n",
      "\tspeed: 0.0263s/iter; left time: 454.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0787337 Vali Loss: 0.0916821 Test Loss: 0.1044795\n",
      "Validation loss decreased (0.091729 --> 0.091682).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0790807\n",
      "\tspeed: 0.0519s/iter; left time: 890.5109s\n",
      "\titers: 200, epoch: 24 | loss: 0.0744595\n",
      "\tspeed: 0.0264s/iter; left time: 449.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0786183 Vali Loss: 0.0923451 Test Loss: 0.1047116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0769751\n",
      "\tspeed: 0.0514s/iter; left time: 869.3717s\n",
      "\titers: 200, epoch: 25 | loss: 0.0824329\n",
      "\tspeed: 0.0263s/iter; left time: 442.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0786068 Vali Loss: 0.0919198 Test Loss: 0.1043650\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0814634\n",
      "\tspeed: 0.0518s/iter; left time: 865.7523s\n",
      "\titers: 200, epoch: 26 | loss: 0.0791285\n",
      "\tspeed: 0.0263s/iter; left time: 437.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0784842 Vali Loss: 0.0912537 Test Loss: 0.1041023\n",
      "Validation loss decreased (0.091682 --> 0.091254).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0782784\n",
      "\tspeed: 0.0519s/iter; left time: 855.9210s\n",
      "\titers: 200, epoch: 27 | loss: 0.0819619\n",
      "\tspeed: 0.0264s/iter; left time: 431.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0785140 Vali Loss: 0.0914912 Test Loss: 0.1041647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0745717\n",
      "\tspeed: 0.0510s/iter; left time: 828.2621s\n",
      "\titers: 200, epoch: 28 | loss: 0.0787156\n",
      "\tspeed: 0.0265s/iter; left time: 427.7901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0785302 Vali Loss: 0.0916318 Test Loss: 0.1041128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0762582\n",
      "\tspeed: 0.0514s/iter; left time: 824.3721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0878928\n",
      "\tspeed: 0.0264s/iter; left time: 420.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0784402 Vali Loss: 0.0915924 Test Loss: 0.1043333\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0758294\n",
      "\tspeed: 0.0512s/iter; left time: 809.3834s\n",
      "\titers: 200, epoch: 30 | loss: 0.0773198\n",
      "\tspeed: 0.0264s/iter; left time: 414.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0781407 Vali Loss: 0.0916876 Test Loss: 0.1042017\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0804063\n",
      "\tspeed: 0.0507s/iter; left time: 790.4607s\n",
      "\titers: 200, epoch: 31 | loss: 0.0762394\n",
      "\tspeed: 0.0264s/iter; left time: 407.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0782146 Vali Loss: 0.0916409 Test Loss: 0.1041947\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0734557\n",
      "\tspeed: 0.0512s/iter; left time: 787.0077s\n",
      "\titers: 200, epoch: 32 | loss: 0.0786449\n",
      "\tspeed: 0.0267s/iter; left time: 407.0253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0781491 Vali Loss: 0.0913309 Test Loss: 0.1041235\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0799010\n",
      "\tspeed: 0.0511s/iter; left time: 772.9220s\n",
      "\titers: 200, epoch: 33 | loss: 0.0813502\n",
      "\tspeed: 0.0263s/iter; left time: 394.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0781196 Vali Loss: 0.0915800 Test Loss: 0.1043300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0787300\n",
      "\tspeed: 0.0517s/iter; left time: 770.1646s\n",
      "\titers: 200, epoch: 34 | loss: 0.0830562\n",
      "\tspeed: 0.0266s/iter; left time: 394.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0780620 Vali Loss: 0.0923515 Test Loss: 0.1049419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0719172\n",
      "\tspeed: 0.0513s/iter; left time: 753.7581s\n",
      "\titers: 200, epoch: 35 | loss: 0.0790544\n",
      "\tspeed: 0.0266s/iter; left time: 387.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0780186 Vali Loss: 0.0913748 Test Loss: 0.1041244\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0840530\n",
      "\tspeed: 0.0513s/iter; left time: 741.9974s\n",
      "\titers: 200, epoch: 36 | loss: 0.0817567\n",
      "\tspeed: 0.0268s/iter; left time: 384.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0780826 Vali Loss: 0.0917967 Test Loss: 0.1043762\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025816407054662704, rmse:0.16067485511302948, mae:0.10410226881504059, rse:0.5542826652526855\n",
      "Intermediate time for GB and pred_len 24: 00h:11m:07.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2814036\n",
      "\tspeed: 0.0521s/iter; left time: 1161.3120s\n",
      "\titers: 200, epoch: 1 | loss: 0.2753287\n",
      "\tspeed: 0.0267s/iter; left time: 593.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.2828317 Vali Loss: 0.2363253 Test Loss: 0.2565018\n",
      "Validation loss decreased (inf --> 0.236325).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474670\n",
      "\tspeed: 0.0527s/iter; left time: 1162.4719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273948\n",
      "\tspeed: 0.0267s/iter; left time: 587.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1595674 Vali Loss: 0.1317870 Test Loss: 0.1517740\n",
      "Validation loss decreased (0.236325 --> 0.131787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161193\n",
      "\tspeed: 0.0527s/iter; left time: 1151.7672s\n",
      "\titers: 200, epoch: 3 | loss: 0.1116192\n",
      "\tspeed: 0.0268s/iter; left time: 582.9938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1176064 Vali Loss: 0.1224016 Test Loss: 0.1461472\n",
      "Validation loss decreased (0.131787 --> 0.122402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1084016\n",
      "\tspeed: 0.0529s/iter; left time: 1143.3399s\n",
      "\titers: 200, epoch: 4 | loss: 0.1096157\n",
      "\tspeed: 0.0268s/iter; left time: 576.2966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1117506 Vali Loss: 0.1229639 Test Loss: 0.1461970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1102678\n",
      "\tspeed: 0.0530s/iter; left time: 1133.5948s\n",
      "\titers: 200, epoch: 5 | loss: 0.1033464\n",
      "\tspeed: 0.0267s/iter; left time: 569.2240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1091738 Vali Loss: 0.1245078 Test Loss: 0.1500876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1108893\n",
      "\tspeed: 0.0526s/iter; left time: 1114.3905s\n",
      "\titers: 200, epoch: 6 | loss: 0.1105880\n",
      "\tspeed: 0.0268s/iter; left time: 564.4466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1074941 Vali Loss: 0.1217878 Test Loss: 0.1453244\n",
      "Validation loss decreased (0.122402 --> 0.121788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1112695\n",
      "\tspeed: 0.0532s/iter; left time: 1114.2485s\n",
      "\titers: 200, epoch: 7 | loss: 0.1039074\n",
      "\tspeed: 0.0268s/iter; left time: 559.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1066327 Vali Loss: 0.1223853 Test Loss: 0.1476428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1067520\n",
      "\tspeed: 0.0530s/iter; left time: 1098.8605s\n",
      "\titers: 200, epoch: 8 | loss: 0.1073765\n",
      "\tspeed: 0.0267s/iter; left time: 551.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1057427 Vali Loss: 0.1224101 Test Loss: 0.1475627\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1046958\n",
      "\tspeed: 0.0521s/iter; left time: 1068.5893s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060490\n",
      "\tspeed: 0.0270s/iter; left time: 550.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1051168 Vali Loss: 0.1220276 Test Loss: 0.1466655\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1066586\n",
      "\tspeed: 0.0525s/iter; left time: 1064.2395s\n",
      "\titers: 200, epoch: 10 | loss: 0.1026679\n",
      "\tspeed: 0.0272s/iter; left time: 548.6985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1048020 Vali Loss: 0.1225210 Test Loss: 0.1481434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1041008\n",
      "\tspeed: 0.0526s/iter; left time: 1054.8852s\n",
      "\titers: 200, epoch: 11 | loss: 0.1051459\n",
      "\tspeed: 0.0267s/iter; left time: 533.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.1043860 Vali Loss: 0.1220439 Test Loss: 0.1479996\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1071432\n",
      "\tspeed: 0.0517s/iter; left time: 1026.4725s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028520\n",
      "\tspeed: 0.0267s/iter; left time: 526.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.1038470 Vali Loss: 0.1223071 Test Loss: 0.1481694\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1030630\n",
      "\tspeed: 0.0516s/iter; left time: 1012.7252s\n",
      "\titers: 200, epoch: 13 | loss: 0.1053017\n",
      "\tspeed: 0.0267s/iter; left time: 520.5989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.1033771 Vali Loss: 0.1219326 Test Loss: 0.1481578\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1018425\n",
      "\tspeed: 0.0519s/iter; left time: 1005.4070s\n",
      "\titers: 200, epoch: 14 | loss: 0.1015304\n",
      "\tspeed: 0.0267s/iter; left time: 515.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.1031317 Vali Loss: 0.1236653 Test Loss: 0.1483163\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0979186\n",
      "\tspeed: 0.0518s/iter; left time: 992.5996s\n",
      "\titers: 200, epoch: 15 | loss: 0.1018396\n",
      "\tspeed: 0.0267s/iter; left time: 509.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1031128 Vali Loss: 0.1220715 Test Loss: 0.1481973\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1082179\n",
      "\tspeed: 0.0519s/iter; left time: 982.5411s\n",
      "\titers: 200, epoch: 16 | loss: 0.1085084\n",
      "\tspeed: 0.0267s/iter; left time: 503.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.1026982 Vali Loss: 0.1227267 Test Loss: 0.1496199\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04409452900290489, rmse:0.20998696982860565, mae:0.14532437920570374, rse:0.7261641621589661\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2846584\n",
      "\tspeed: 0.0292s/iter; left time: 650.1794s\n",
      "\titers: 200, epoch: 1 | loss: 0.2699768\n",
      "\tspeed: 0.0268s/iter; left time: 595.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.2836303 Vali Loss: 0.2366667 Test Loss: 0.2559556\n",
      "Validation loss decreased (inf --> 0.236667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1467806\n",
      "\tspeed: 0.0536s/iter; left time: 1183.9823s\n",
      "\titers: 200, epoch: 2 | loss: 0.1212378\n",
      "\tspeed: 0.0267s/iter; left time: 586.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1587569 Vali Loss: 0.1335573 Test Loss: 0.1563327\n",
      "Validation loss decreased (0.236667 --> 0.133557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1182128\n",
      "\tspeed: 0.0531s/iter; left time: 1159.8147s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108566\n",
      "\tspeed: 0.0267s/iter; left time: 580.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1174105 Vali Loss: 0.1239376 Test Loss: 0.1492593\n",
      "Validation loss decreased (0.133557 --> 0.123938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1095036\n",
      "\tspeed: 0.0537s/iter; left time: 1161.5073s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127791\n",
      "\tspeed: 0.0267s/iter; left time: 573.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1116511 Vali Loss: 0.1268119 Test Loss: 0.1492081\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1085521\n",
      "\tspeed: 0.0527s/iter; left time: 1127.8519s\n",
      "\titers: 200, epoch: 5 | loss: 0.1101375\n",
      "\tspeed: 0.0270s/iter; left time: 574.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1089843 Vali Loss: 0.1230369 Test Loss: 0.1471350\n",
      "Validation loss decreased (0.123938 --> 0.123037).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1056317\n",
      "\tspeed: 0.0537s/iter; left time: 1136.3907s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103429\n",
      "\tspeed: 0.0267s/iter; left time: 562.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1079973 Vali Loss: 0.1220587 Test Loss: 0.1466280\n",
      "Validation loss decreased (0.123037 --> 0.122059).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1001976\n",
      "\tspeed: 0.0535s/iter; left time: 1121.5434s\n",
      "\titers: 200, epoch: 7 | loss: 0.1116034\n",
      "\tspeed: 0.0267s/iter; left time: 556.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1067057 Vali Loss: 0.1223284 Test Loss: 0.1477152\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1038238\n",
      "\tspeed: 0.0528s/iter; left time: 1095.2135s\n",
      "\titers: 200, epoch: 8 | loss: 0.1031946\n",
      "\tspeed: 0.0268s/iter; left time: 552.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1062257 Vali Loss: 0.1221051 Test Loss: 0.1471668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042598\n",
      "\tspeed: 0.0530s/iter; left time: 1087.5716s\n",
      "\titers: 200, epoch: 9 | loss: 0.1046804\n",
      "\tspeed: 0.0267s/iter; left time: 544.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.1050419 Vali Loss: 0.1221812 Test Loss: 0.1481853\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037594\n",
      "\tspeed: 0.0530s/iter; left time: 1074.6176s\n",
      "\titers: 200, epoch: 10 | loss: 0.1060991\n",
      "\tspeed: 0.0267s/iter; left time: 539.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.1045060 Vali Loss: 0.1221735 Test Loss: 0.1489151\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025115\n",
      "\tspeed: 0.0537s/iter; left time: 1076.2830s\n",
      "\titers: 200, epoch: 11 | loss: 0.1044383\n",
      "\tspeed: 0.0267s/iter; left time: 532.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.1040485 Vali Loss: 0.1244292 Test Loss: 0.1488840\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1007124\n",
      "\tspeed: 0.0524s/iter; left time: 1039.9118s\n",
      "\titers: 200, epoch: 12 | loss: 0.0999209\n",
      "\tspeed: 0.0265s/iter; left time: 522.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.1041343 Vali Loss: 0.1233486 Test Loss: 0.1491758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1018817\n",
      "\tspeed: 0.0534s/iter; left time: 1048.2999s\n",
      "\titers: 200, epoch: 13 | loss: 0.1073372\n",
      "\tspeed: 0.0266s/iter; left time: 519.4013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1034051 Vali Loss: 0.1221586 Test Loss: 0.1487453\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0980571\n",
      "\tspeed: 0.0536s/iter; left time: 1039.5974s\n",
      "\titers: 200, epoch: 14 | loss: 0.0966746\n",
      "\tspeed: 0.0269s/iter; left time: 519.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1033476 Vali Loss: 0.1220342 Test Loss: 0.1475085\n",
      "Validation loss decreased (0.122059 --> 0.122034).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1018572\n",
      "\tspeed: 0.0539s/iter; left time: 1032.0988s\n",
      "\titers: 200, epoch: 15 | loss: 0.1013139\n",
      "\tspeed: 0.0269s/iter; left time: 512.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1029051 Vali Loss: 0.1224381 Test Loss: 0.1489764\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1042031\n",
      "\tspeed: 0.0535s/iter; left time: 1012.6724s\n",
      "\titers: 200, epoch: 16 | loss: 0.1017121\n",
      "\tspeed: 0.0266s/iter; left time: 500.4321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1027763 Vali Loss: 0.1224150 Test Loss: 0.1491477\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1016523\n",
      "\tspeed: 0.0529s/iter; left time: 989.2444s\n",
      "\titers: 200, epoch: 17 | loss: 0.1017423\n",
      "\tspeed: 0.0267s/iter; left time: 497.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1026483 Vali Loss: 0.1224918 Test Loss: 0.1497179\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0996995\n",
      "\tspeed: 0.0546s/iter; left time: 1010.5751s\n",
      "\titers: 200, epoch: 18 | loss: 0.0996360\n",
      "\tspeed: 0.0267s/iter; left time: 491.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1022454 Vali Loss: 0.1228503 Test Loss: 0.1507155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1015451\n",
      "\tspeed: 0.0533s/iter; left time: 973.9086s\n",
      "\titers: 200, epoch: 19 | loss: 0.1031634\n",
      "\tspeed: 0.0267s/iter; left time: 484.6144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1021936 Vali Loss: 0.1234197 Test Loss: 0.1504315\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1040580\n",
      "\tspeed: 0.0536s/iter; left time: 966.4951s\n",
      "\titers: 200, epoch: 20 | loss: 0.1058707\n",
      "\tspeed: 0.0266s/iter; left time: 477.9318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1020462 Vali Loss: 0.1223244 Test Loss: 0.1498982\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0979514\n",
      "\tspeed: 0.0533s/iter; left time: 949.1253s\n",
      "\titers: 200, epoch: 21 | loss: 0.1028729\n",
      "\tspeed: 0.0267s/iter; left time: 472.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1021163 Vali Loss: 0.1223535 Test Loss: 0.1498355\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1017197\n",
      "\tspeed: 0.0531s/iter; left time: 934.0271s\n",
      "\titers: 200, epoch: 22 | loss: 0.1024606\n",
      "\tspeed: 0.0265s/iter; left time: 463.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.1019055 Vali Loss: 0.1225047 Test Loss: 0.1504854\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0987281\n",
      "\tspeed: 0.0527s/iter; left time: 914.7572s\n",
      "\titers: 200, epoch: 23 | loss: 0.0985532\n",
      "\tspeed: 0.0266s/iter; left time: 459.9213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1016765 Vali Loss: 0.1227167 Test Loss: 0.1502586\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0983642\n",
      "\tspeed: 0.0534s/iter; left time: 915.5519s\n",
      "\titers: 200, epoch: 24 | loss: 0.1002519\n",
      "\tspeed: 0.0266s/iter; left time: 454.2678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1015580 Vali Loss: 0.1238900 Test Loss: 0.1516141\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04726178199052811, rmse:0.2173977494239807, mae:0.1475084275007248, rse:0.751791775226593\n",
      "Intermediate time for GB and pred_len 96: 00h:05m:31.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2818827\n",
      "\tspeed: 0.0516s/iter; left time: 1145.7299s\n",
      "\titers: 200, epoch: 1 | loss: 0.2665040\n",
      "\tspeed: 0.0270s/iter; left time: 596.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 223 | Train Loss: 0.2841303 Vali Loss: 0.2368239 Test Loss: 0.2563688\n",
      "Validation loss decreased (inf --> 0.236824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1424722\n",
      "\tspeed: 0.0540s/iter; left time: 1187.1126s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319111\n",
      "\tspeed: 0.0271s/iter; left time: 592.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1594881 Vali Loss: 0.1341513 Test Loss: 0.1558863\n",
      "Validation loss decreased (0.236824 --> 0.134151).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1212322\n",
      "\tspeed: 0.0541s/iter; left time: 1177.9296s\n",
      "\titers: 200, epoch: 3 | loss: 0.1163176\n",
      "\tspeed: 0.0269s/iter; left time: 582.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1208286 Vali Loss: 0.1281839 Test Loss: 0.1570600\n",
      "Validation loss decreased (0.134151 --> 0.128184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1163680\n",
      "\tspeed: 0.0550s/iter; left time: 1183.3326s\n",
      "\titers: 200, epoch: 4 | loss: 0.1215556\n",
      "\tspeed: 0.0268s/iter; left time: 575.3869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1158307 Vali Loss: 0.1278227 Test Loss: 0.1549095\n",
      "Validation loss decreased (0.128184 --> 0.127823).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1092537\n",
      "\tspeed: 0.0543s/iter; left time: 1156.0976s\n",
      "\titers: 200, epoch: 5 | loss: 0.1196612\n",
      "\tspeed: 0.0269s/iter; left time: 570.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1134607 Vali Loss: 0.1279475 Test Loss: 0.1562080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1147250\n",
      "\tspeed: 0.0528s/iter; left time: 1112.8738s\n",
      "\titers: 200, epoch: 6 | loss: 0.1129685\n",
      "\tspeed: 0.0269s/iter; left time: 563.9213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.1122165 Vali Loss: 0.1273455 Test Loss: 0.1527181\n",
      "Validation loss decreased (0.127823 --> 0.127345).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1098032\n",
      "\tspeed: 0.0528s/iter; left time: 1101.0993s\n",
      "\titers: 200, epoch: 7 | loss: 0.1037844\n",
      "\tspeed: 0.0269s/iter; left time: 558.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.1107435 Vali Loss: 0.1265944 Test Loss: 0.1525330\n",
      "Validation loss decreased (0.127345 --> 0.126594).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1080589\n",
      "\tspeed: 0.0538s/iter; left time: 1110.8850s\n",
      "\titers: 200, epoch: 8 | loss: 0.1135441\n",
      "\tspeed: 0.0269s/iter; left time: 551.7355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.1100194 Vali Loss: 0.1267046 Test Loss: 0.1521989\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1114064\n",
      "\tspeed: 0.0535s/iter; left time: 1092.1450s\n",
      "\titers: 200, epoch: 9 | loss: 0.1044170\n",
      "\tspeed: 0.0270s/iter; left time: 548.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1092463 Vali Loss: 0.1267319 Test Loss: 0.1544835\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1059442\n",
      "\tspeed: 0.0527s/iter; left time: 1064.1076s\n",
      "\titers: 200, epoch: 10 | loss: 0.1071255\n",
      "\tspeed: 0.0269s/iter; left time: 541.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1092395 Vali Loss: 0.1275749 Test Loss: 0.1536383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1064268\n",
      "\tspeed: 0.0523s/iter; left time: 1043.8998s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085364\n",
      "\tspeed: 0.0270s/iter; left time: 536.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1086081 Vali Loss: 0.1268966 Test Loss: 0.1543059\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1044744\n",
      "\tspeed: 0.0523s/iter; left time: 1033.4242s\n",
      "\titers: 200, epoch: 12 | loss: 0.1057234\n",
      "\tspeed: 0.0268s/iter; left time: 526.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.1079693 Vali Loss: 0.1271530 Test Loss: 0.1547495\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1104869\n",
      "\tspeed: 0.0533s/iter; left time: 1040.7659s\n",
      "\titers: 200, epoch: 13 | loss: 0.1099807\n",
      "\tspeed: 0.0269s/iter; left time: 523.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1076578 Vali Loss: 0.1258683 Test Loss: 0.1548358\n",
      "Validation loss decreased (0.126594 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1087319\n",
      "\tspeed: 0.0538s/iter; left time: 1038.9436s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076828\n",
      "\tspeed: 0.0270s/iter; left time: 518.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1073149 Vali Loss: 0.1271001 Test Loss: 0.1564167\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1079066\n",
      "\tspeed: 0.0533s/iter; left time: 1017.3473s\n",
      "\titers: 200, epoch: 15 | loss: 0.1118923\n",
      "\tspeed: 0.0270s/iter; left time: 512.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1070774 Vali Loss: 0.1279857 Test Loss: 0.1554484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058325\n",
      "\tspeed: 0.0532s/iter; left time: 1002.6135s\n",
      "\titers: 200, epoch: 16 | loss: 0.1115175\n",
      "\tspeed: 0.0270s/iter; left time: 506.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1067632 Vali Loss: 0.1271370 Test Loss: 0.1564911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1060647\n",
      "\tspeed: 0.0529s/iter; left time: 984.8497s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118538\n",
      "\tspeed: 0.0270s/iter; left time: 500.2927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1066689 Vali Loss: 0.1275171 Test Loss: 0.1562652\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1085790\n",
      "\tspeed: 0.0533s/iter; left time: 981.5909s\n",
      "\titers: 200, epoch: 18 | loss: 0.1064080\n",
      "\tspeed: 0.0270s/iter; left time: 494.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1064147 Vali Loss: 0.1272083 Test Loss: 0.1565073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1063684\n",
      "\tspeed: 0.0528s/iter; left time: 961.0433s\n",
      "\titers: 200, epoch: 19 | loss: 0.1050237\n",
      "\tspeed: 0.0269s/iter; left time: 487.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1064823 Vali Loss: 0.1276555 Test Loss: 0.1556628\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1101118\n",
      "\tspeed: 0.0529s/iter; left time: 950.0410s\n",
      "\titers: 200, epoch: 20 | loss: 0.1062415\n",
      "\tspeed: 0.0269s/iter; left time: 481.3326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1061652 Vali Loss: 0.1275631 Test Loss: 0.1559166\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1057082\n",
      "\tspeed: 0.0533s/iter; left time: 946.3014s\n",
      "\titers: 200, epoch: 21 | loss: 0.1068663\n",
      "\tspeed: 0.0269s/iter; left time: 474.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1059219 Vali Loss: 0.1272919 Test Loss: 0.1561544\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1041760\n",
      "\tspeed: 0.0527s/iter; left time: 922.3411s\n",
      "\titers: 200, epoch: 22 | loss: 0.1125320\n",
      "\tspeed: 0.0270s/iter; left time: 469.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1058360 Vali Loss: 0.1276802 Test Loss: 0.1565375\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1073441\n",
      "\tspeed: 0.0527s/iter; left time: 910.6097s\n",
      "\titers: 200, epoch: 23 | loss: 0.1092194\n",
      "\tspeed: 0.0270s/iter; left time: 464.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1057776 Vali Loss: 0.1272340 Test Loss: 0.1571711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.049206092953681946, rmse:0.22182446718215942, mae:0.15483571588993073, rse:0.7690972685813904\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2795618\n",
      "\tspeed: 0.0292s/iter; left time: 647.4021s\n",
      "\titers: 200, epoch: 1 | loss: 0.2796665\n",
      "\tspeed: 0.0270s/iter; left time: 596.5963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.2873887 Vali Loss: 0.2419844 Test Loss: 0.2583843\n",
      "Validation loss decreased (inf --> 0.241984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1467684\n",
      "\tspeed: 0.0542s/iter; left time: 1190.1795s\n",
      "\titers: 200, epoch: 2 | loss: 0.1370764\n",
      "\tspeed: 0.0268s/iter; left time: 585.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1619935 Vali Loss: 0.1329342 Test Loss: 0.1557617\n",
      "Validation loss decreased (0.241984 --> 0.132934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1239461\n",
      "\tspeed: 0.0547s/iter; left time: 1190.1673s\n",
      "\titers: 200, epoch: 3 | loss: 0.1191477\n",
      "\tspeed: 0.0268s/iter; left time: 579.9736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.1212261 Vali Loss: 0.1291059 Test Loss: 0.1607811\n",
      "Validation loss decreased (0.132934 --> 0.129106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1183607\n",
      "\tspeed: 0.0543s/iter; left time: 1168.2171s\n",
      "\titers: 200, epoch: 4 | loss: 0.1134157\n",
      "\tspeed: 0.0268s/iter; left time: 574.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1153331 Vali Loss: 0.1264300 Test Loss: 0.1516634\n",
      "Validation loss decreased (0.129106 --> 0.126430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1158319\n",
      "\tspeed: 0.0552s/iter; left time: 1175.8985s\n",
      "\titers: 200, epoch: 5 | loss: 0.1141421\n",
      "\tspeed: 0.0270s/iter; left time: 572.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1133761 Vali Loss: 0.1266857 Test Loss: 0.1515137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114554\n",
      "\tspeed: 0.0542s/iter; left time: 1143.5219s\n",
      "\titers: 200, epoch: 6 | loss: 0.1133449\n",
      "\tspeed: 0.0269s/iter; left time: 565.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1120483 Vali Loss: 0.1270977 Test Loss: 0.1518112\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1107215\n",
      "\tspeed: 0.0548s/iter; left time: 1142.8942s\n",
      "\titers: 200, epoch: 7 | loss: 0.1120520\n",
      "\tspeed: 0.0271s/iter; left time: 562.8978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1109283 Vali Loss: 0.1266328 Test Loss: 0.1500296\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1137405\n",
      "\tspeed: 0.0540s/iter; left time: 1113.9764s\n",
      "\titers: 200, epoch: 8 | loss: 0.1111502\n",
      "\tspeed: 0.0271s/iter; left time: 555.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1102262 Vali Loss: 0.1283991 Test Loss: 0.1520599\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1074144\n",
      "\tspeed: 0.0545s/iter; left time: 1112.1959s\n",
      "\titers: 200, epoch: 9 | loss: 0.1080249\n",
      "\tspeed: 0.0270s/iter; left time: 548.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1095048 Vali Loss: 0.1269158 Test Loss: 0.1524674\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1141485\n",
      "\tspeed: 0.0539s/iter; left time: 1088.3401s\n",
      "\titers: 200, epoch: 10 | loss: 0.1097387\n",
      "\tspeed: 0.0270s/iter; left time: 542.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.1087921 Vali Loss: 0.1275121 Test Loss: 0.1524081\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1074808\n",
      "\tspeed: 0.0545s/iter; left time: 1088.7350s\n",
      "\titers: 200, epoch: 11 | loss: 0.1133830\n",
      "\tspeed: 0.0271s/iter; left time: 537.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1082795 Vali Loss: 0.1264917 Test Loss: 0.1526808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1047437\n",
      "\tspeed: 0.0538s/iter; left time: 1062.3840s\n",
      "\titers: 200, epoch: 12 | loss: 0.1077340\n",
      "\tspeed: 0.0270s/iter; left time: 530.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1078610 Vali Loss: 0.1269894 Test Loss: 0.1548681\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1090030\n",
      "\tspeed: 0.0546s/iter; left time: 1065.6033s\n",
      "\titers: 200, epoch: 13 | loss: 0.1128828\n",
      "\tspeed: 0.0270s/iter; left time: 524.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1076234 Vali Loss: 0.1268795 Test Loss: 0.1549348\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1104816\n",
      "\tspeed: 0.0544s/iter; left time: 1050.3553s\n",
      "\titers: 200, epoch: 14 | loss: 0.1079465\n",
      "\tspeed: 0.0270s/iter; left time: 518.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1073064 Vali Loss: 0.1277648 Test Loss: 0.1556179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04769879952073097, rmse:0.21840055286884308, mae:0.1516633927822113, rse:0.7572260499000549\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:11.16s\n",
      "Intermediate time for GB: 00h:21m:49.81s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2708257\n",
      "\tspeed: 0.0431s/iter; left time: 961.8683s\n",
      "\titers: 200, epoch: 1 | loss: 0.2622724\n",
      "\tspeed: 0.0172s/iter; left time: 382.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.2779982 Vali Loss: 0.2074505 Test Loss: 0.2332473\n",
      "Validation loss decreased (inf --> 0.207451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1510847\n",
      "\tspeed: 0.0377s/iter; left time: 832.8636s\n",
      "\titers: 200, epoch: 2 | loss: 0.1117425\n",
      "\tspeed: 0.0178s/iter; left time: 390.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1574519 Vali Loss: 0.0915035 Test Loss: 0.0991069\n",
      "Validation loss decreased (0.207451 --> 0.091504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1003834\n",
      "\tspeed: 0.0362s/iter; left time: 790.3797s\n",
      "\titers: 200, epoch: 3 | loss: 0.0931744\n",
      "\tspeed: 0.0178s/iter; left time: 388.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1002942 Vali Loss: 0.0830410 Test Loss: 0.0912976\n",
      "Validation loss decreased (0.091504 --> 0.083041).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863603\n",
      "\tspeed: 0.0375s/iter; left time: 812.0179s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836940\n",
      "\tspeed: 0.0174s/iter; left time: 374.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0864073 Vali Loss: 0.0718561 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.083041 --> 0.071856).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736417\n",
      "\tspeed: 0.0362s/iter; left time: 774.3423s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762774\n",
      "\tspeed: 0.0172s/iter; left time: 367.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0774616 Vali Loss: 0.0680598 Test Loss: 0.0780765\n",
      "Validation loss decreased (0.071856 --> 0.068060).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711824\n",
      "\tspeed: 0.0370s/iter; left time: 783.2915s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742073\n",
      "\tspeed: 0.0172s/iter; left time: 363.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0727056 Vali Loss: 0.0657509 Test Loss: 0.0764956\n",
      "Validation loss decreased (0.068060 --> 0.065751).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758830\n",
      "\tspeed: 0.0363s/iter; left time: 759.8080s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721870\n",
      "\tspeed: 0.0172s/iter; left time: 358.6724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0708751 Vali Loss: 0.0660416 Test Loss: 0.0778710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0714698\n",
      "\tspeed: 0.0356s/iter; left time: 738.7222s\n",
      "\titers: 200, epoch: 8 | loss: 0.0658485\n",
      "\tspeed: 0.0174s/iter; left time: 359.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0689583 Vali Loss: 0.0642446 Test Loss: 0.0767666\n",
      "Validation loss decreased (0.065751 --> 0.064245).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0694290\n",
      "\tspeed: 0.0374s/iter; left time: 766.3435s\n",
      "\titers: 200, epoch: 9 | loss: 0.0644000\n",
      "\tspeed: 0.0175s/iter; left time: 356.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0676455 Vali Loss: 0.0636601 Test Loss: 0.0770834\n",
      "Validation loss decreased (0.064245 --> 0.063660).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700247\n",
      "\tspeed: 0.0396s/iter; left time: 803.6515s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655249\n",
      "\tspeed: 0.0172s/iter; left time: 347.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0667840 Vali Loss: 0.0626065 Test Loss: 0.0754004\n",
      "Validation loss decreased (0.063660 --> 0.062607).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672422\n",
      "\tspeed: 0.0398s/iter; left time: 797.4488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0646161\n",
      "\tspeed: 0.0172s/iter; left time: 344.2409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0662278 Vali Loss: 0.0625945 Test Loss: 0.0761153\n",
      "Validation loss decreased (0.062607 --> 0.062595).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0648139\n",
      "\tspeed: 0.0360s/iter; left time: 714.0072s\n",
      "\titers: 200, epoch: 12 | loss: 0.0664951\n",
      "\tspeed: 0.0193s/iter; left time: 380.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0654111 Vali Loss: 0.0617924 Test Loss: 0.0757005\n",
      "Validation loss decreased (0.062595 --> 0.061792).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0622444\n",
      "\tspeed: 0.0369s/iter; left time: 724.5179s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599254\n",
      "\tspeed: 0.0174s/iter; left time: 338.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0647105 Vali Loss: 0.0609597 Test Loss: 0.0746203\n",
      "Validation loss decreased (0.061792 --> 0.060960).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0647993\n",
      "\tspeed: 0.0363s/iter; left time: 702.9770s\n",
      "\titers: 200, epoch: 14 | loss: 0.0610652\n",
      "\tspeed: 0.0175s/iter; left time: 337.2731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0643186 Vali Loss: 0.0609952 Test Loss: 0.0744172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0624425\n",
      "\tspeed: 0.0359s/iter; left time: 687.0738s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644481\n",
      "\tspeed: 0.0173s/iter; left time: 330.1042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0640143 Vali Loss: 0.0605438 Test Loss: 0.0741187\n",
      "Validation loss decreased (0.060960 --> 0.060544).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0600056\n",
      "\tspeed: 0.0369s/iter; left time: 698.4483s\n",
      "\titers: 200, epoch: 16 | loss: 0.0635128\n",
      "\tspeed: 0.0174s/iter; left time: 327.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0634908 Vali Loss: 0.0608249 Test Loss: 0.0749933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0606074\n",
      "\tspeed: 0.0401s/iter; left time: 750.1237s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622914\n",
      "\tspeed: 0.0175s/iter; left time: 324.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0630818 Vali Loss: 0.0603432 Test Loss: 0.0748148\n",
      "Validation loss decreased (0.060544 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0615552\n",
      "\tspeed: 0.0376s/iter; left time: 696.0776s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634372\n",
      "\tspeed: 0.0175s/iter; left time: 321.4361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0628284 Vali Loss: 0.0602996 Test Loss: 0.0743554\n",
      "Validation loss decreased (0.060343 --> 0.060300).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0640946\n",
      "\tspeed: 0.0389s/iter; left time: 709.9305s\n",
      "\titers: 200, epoch: 19 | loss: 0.0632057\n",
      "\tspeed: 0.0186s/iter; left time: 337.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0628115 Vali Loss: 0.0604891 Test Loss: 0.0746229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0630374\n",
      "\tspeed: 0.0374s/iter; left time: 674.6480s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633529\n",
      "\tspeed: 0.0203s/iter; left time: 364.4162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0625326 Vali Loss: 0.0596575 Test Loss: 0.0737812\n",
      "Validation loss decreased (0.060300 --> 0.059657).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0616223\n",
      "\tspeed: 0.0387s/iter; left time: 689.1233s\n",
      "\titers: 200, epoch: 21 | loss: 0.0649464\n",
      "\tspeed: 0.0176s/iter; left time: 311.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0621714 Vali Loss: 0.0597556 Test Loss: 0.0742557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0627824\n",
      "\tspeed: 0.0374s/iter; left time: 658.9723s\n",
      "\titers: 200, epoch: 22 | loss: 0.0598262\n",
      "\tspeed: 0.0179s/iter; left time: 313.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0622700 Vali Loss: 0.0598124 Test Loss: 0.0740635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619051\n",
      "\tspeed: 0.0364s/iter; left time: 632.9487s\n",
      "\titers: 200, epoch: 23 | loss: 0.0605921\n",
      "\tspeed: 0.0218s/iter; left time: 376.1183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0617665 Vali Loss: 0.0594863 Test Loss: 0.0737347\n",
      "Validation loss decreased (0.059657 --> 0.059486).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0607017\n",
      "\tspeed: 0.0374s/iter; left time: 640.6185s\n",
      "\titers: 200, epoch: 24 | loss: 0.0636367\n",
      "\tspeed: 0.0174s/iter; left time: 297.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0617854 Vali Loss: 0.0594426 Test Loss: 0.0740125\n",
      "Validation loss decreased (0.059486 --> 0.059443).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673195\n",
      "\tspeed: 0.0370s/iter; left time: 627.0664s\n",
      "\titers: 200, epoch: 25 | loss: 0.0601358\n",
      "\tspeed: 0.0173s/iter; left time: 291.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0616259 Vali Loss: 0.0594604 Test Loss: 0.0745333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0618991\n",
      "\tspeed: 0.0359s/iter; left time: 599.4528s\n",
      "\titers: 200, epoch: 26 | loss: 0.0608135\n",
      "\tspeed: 0.0174s/iter; left time: 289.2792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0614542 Vali Loss: 0.0593405 Test Loss: 0.0739550\n",
      "Validation loss decreased (0.059443 --> 0.059341).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0631193\n",
      "\tspeed: 0.0378s/iter; left time: 622.9195s\n",
      "\titers: 200, epoch: 27 | loss: 0.0657145\n",
      "\tspeed: 0.0175s/iter; left time: 285.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0616794 Vali Loss: 0.0594699 Test Loss: 0.0737223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0565359\n",
      "\tspeed: 0.0352s/iter; left time: 572.6145s\n",
      "\titers: 200, epoch: 28 | loss: 0.0595181\n",
      "\tspeed: 0.0176s/iter; left time: 284.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0612757 Vali Loss: 0.0591323 Test Loss: 0.0734891\n",
      "Validation loss decreased (0.059341 --> 0.059132).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0586638\n",
      "\tspeed: 0.0377s/iter; left time: 603.9051s\n",
      "\titers: 200, epoch: 29 | loss: 0.0608017\n",
      "\tspeed: 0.0176s/iter; left time: 280.1487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0612530 Vali Loss: 0.0590975 Test Loss: 0.0735919\n",
      "Validation loss decreased (0.059132 --> 0.059097).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0592039\n",
      "\tspeed: 0.0378s/iter; left time: 598.1524s\n",
      "\titers: 200, epoch: 30 | loss: 0.0614624\n",
      "\tspeed: 0.0172s/iter; left time: 270.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0612326 Vali Loss: 0.0595413 Test Loss: 0.0739768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0617800\n",
      "\tspeed: 0.0353s/iter; left time: 550.1535s\n",
      "\titers: 200, epoch: 31 | loss: 0.0633619\n",
      "\tspeed: 0.0172s/iter; left time: 267.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0611033 Vali Loss: 0.0588847 Test Loss: 0.0730694\n",
      "Validation loss decreased (0.059097 --> 0.058885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0632723\n",
      "\tspeed: 0.0362s/iter; left time: 555.4123s\n",
      "\titers: 200, epoch: 32 | loss: 0.0576704\n",
      "\tspeed: 0.0176s/iter; left time: 269.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0609722 Vali Loss: 0.0589661 Test Loss: 0.0733982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0627338\n",
      "\tspeed: 0.0366s/iter; left time: 553.6994s\n",
      "\titers: 200, epoch: 33 | loss: 0.0608308\n",
      "\tspeed: 0.0175s/iter; left time: 262.5274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0609542 Vali Loss: 0.0587706 Test Loss: 0.0731882\n",
      "Validation loss decreased (0.058885 --> 0.058771).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0627589\n",
      "\tspeed: 0.0357s/iter; left time: 532.3419s\n",
      "\titers: 200, epoch: 34 | loss: 0.0576832\n",
      "\tspeed: 0.0189s/iter; left time: 279.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0610260 Vali Loss: 0.0588217 Test Loss: 0.0729814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0592602\n",
      "\tspeed: 0.0388s/iter; left time: 570.0832s\n",
      "\titers: 200, epoch: 35 | loss: 0.0609397\n",
      "\tspeed: 0.0189s/iter; left time: 275.6954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0608695 Vali Loss: 0.0589980 Test Loss: 0.0734148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0628913\n",
      "\tspeed: 0.0379s/iter; left time: 548.7383s\n",
      "\titers: 200, epoch: 36 | loss: 0.0595104\n",
      "\tspeed: 0.0175s/iter; left time: 251.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0607886 Vali Loss: 0.0588238 Test Loss: 0.0731824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592520\n",
      "\tspeed: 0.0364s/iter; left time: 518.4111s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619801\n",
      "\tspeed: 0.0174s/iter; left time: 246.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0608522 Vali Loss: 0.0588781 Test Loss: 0.0733389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0571876\n",
      "\tspeed: 0.0387s/iter; left time: 541.9268s\n",
      "\titers: 200, epoch: 38 | loss: 0.0626874\n",
      "\tspeed: 0.0180s/iter; left time: 249.9739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0609661 Vali Loss: 0.0588733 Test Loss: 0.0733372\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0603451\n",
      "\tspeed: 0.0379s/iter; left time: 522.7241s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607890\n",
      "\tspeed: 0.0204s/iter; left time: 279.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0607698 Vali Loss: 0.0588193 Test Loss: 0.0732570\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0569031\n",
      "\tspeed: 0.0362s/iter; left time: 491.4571s\n",
      "\titers: 200, epoch: 40 | loss: 0.0604230\n",
      "\tspeed: 0.0173s/iter; left time: 232.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0607826 Vali Loss: 0.0588016 Test Loss: 0.0730469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0587654\n",
      "\tspeed: 0.0353s/iter; left time: 470.5666s\n",
      "\titers: 200, epoch: 41 | loss: 0.0610591\n",
      "\tspeed: 0.0174s/iter; left time: 230.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0606978 Vali Loss: 0.0587396 Test Loss: 0.0732739\n",
      "Validation loss decreased (0.058771 --> 0.058740).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0635448\n",
      "\tspeed: 0.0374s/iter; left time: 490.6760s\n",
      "\titers: 200, epoch: 42 | loss: 0.0613662\n",
      "\tspeed: 0.0177s/iter; left time: 229.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0607116 Vali Loss: 0.0586978 Test Loss: 0.0730936\n",
      "Validation loss decreased (0.058740 --> 0.058698).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0577063\n",
      "\tspeed: 0.0375s/iter; left time: 482.9128s\n",
      "\titers: 200, epoch: 43 | loss: 0.0591121\n",
      "\tspeed: 0.0179s/iter; left time: 228.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0606261 Vali Loss: 0.0589224 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0624545\n",
      "\tspeed: 0.0374s/iter; left time: 473.2334s\n",
      "\titers: 200, epoch: 44 | loss: 0.0616844\n",
      "\tspeed: 0.0177s/iter; left time: 222.8918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0611692 Vali Loss: 0.0586782 Test Loss: 0.0729012\n",
      "Validation loss decreased (0.058698 --> 0.058678).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0593653\n",
      "\tspeed: 0.0367s/iter; left time: 456.1249s\n",
      "\titers: 200, epoch: 45 | loss: 0.0636859\n",
      "\tspeed: 0.0180s/iter; left time: 222.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0605644 Vali Loss: 0.0586519 Test Loss: 0.0729312\n",
      "Validation loss decreased (0.058678 --> 0.058652).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0588403\n",
      "\tspeed: 0.0367s/iter; left time: 447.9213s\n",
      "\titers: 200, epoch: 46 | loss: 0.0612193\n",
      "\tspeed: 0.0173s/iter; left time: 209.3276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0606294 Vali Loss: 0.0587211 Test Loss: 0.0729838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612823\n",
      "\tspeed: 0.0371s/iter; left time: 444.5024s\n",
      "\titers: 200, epoch: 47 | loss: 0.0574999\n",
      "\tspeed: 0.0213s/iter; left time: 253.7182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0608826 Vali Loss: 0.0586566 Test Loss: 0.0730382\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0617604\n",
      "\tspeed: 0.0408s/iter; left time: 479.9069s\n",
      "\titers: 200, epoch: 48 | loss: 0.0574106\n",
      "\tspeed: 0.0184s/iter; left time: 215.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0606421 Vali Loss: 0.0585935 Test Loss: 0.0729641\n",
      "Validation loss decreased (0.058652 --> 0.058594).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0595661\n",
      "\tspeed: 0.0370s/iter; left time: 427.1111s\n",
      "\titers: 200, epoch: 49 | loss: 0.0651810\n",
      "\tspeed: 0.0210s/iter; left time: 240.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0605826 Vali Loss: 0.0586438 Test Loss: 0.0729285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0635316\n",
      "\tspeed: 0.0403s/iter; left time: 455.9508s\n",
      "\titers: 200, epoch: 50 | loss: 0.0610907\n",
      "\tspeed: 0.0192s/iter; left time: 215.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0609660 Vali Loss: 0.0588212 Test Loss: 0.0732808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0592435\n",
      "\tspeed: 0.0364s/iter; left time: 403.8199s\n",
      "\titers: 200, epoch: 51 | loss: 0.0632765\n",
      "\tspeed: 0.0172s/iter; left time: 189.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0606898 Vali Loss: 0.0586598 Test Loss: 0.0730526\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0635184\n",
      "\tspeed: 0.0355s/iter; left time: 386.0589s\n",
      "\titers: 200, epoch: 52 | loss: 0.0610863\n",
      "\tspeed: 0.0174s/iter; left time: 187.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0605371 Vali Loss: 0.0588704 Test Loss: 0.0736128\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0603129\n",
      "\tspeed: 0.0368s/iter; left time: 392.5245s\n",
      "\titers: 200, epoch: 53 | loss: 0.0641348\n",
      "\tspeed: 0.0174s/iter; left time: 183.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0606629 Vali Loss: 0.0587345 Test Loss: 0.0732306\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0610451\n",
      "\tspeed: 0.0396s/iter; left time: 413.3096s\n",
      "\titers: 200, epoch: 54 | loss: 0.0583071\n",
      "\tspeed: 0.0227s/iter; left time: 234.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0608471 Vali Loss: 0.0588552 Test Loss: 0.0735912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600205\n",
      "\tspeed: 0.0401s/iter; left time: 409.7278s\n",
      "\titers: 200, epoch: 55 | loss: 0.0605740\n",
      "\tspeed: 0.0172s/iter; left time: 174.2211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0605078 Vali Loss: 0.0587326 Test Loss: 0.0732537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0583362\n",
      "\tspeed: 0.0396s/iter; left time: 395.6195s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632899\n",
      "\tspeed: 0.0220s/iter; left time: 217.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0586046 Test Loss: 0.0729888\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0592648\n",
      "\tspeed: 0.0368s/iter; left time: 359.5028s\n",
      "\titers: 200, epoch: 57 | loss: 0.0603010\n",
      "\tspeed: 0.0172s/iter; left time: 166.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0605897 Vali Loss: 0.0587299 Test Loss: 0.0734092\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0576204\n",
      "\tspeed: 0.0404s/iter; left time: 385.3957s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604421\n",
      "\tspeed: 0.0172s/iter; left time: 162.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0606295 Vali Loss: 0.0587746 Test Loss: 0.0731275\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012697300873696804, rmse:0.1126822978258133, mae:0.07296409457921982, rse:0.33161038160324097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2723186\n",
      "\tspeed: 0.0221s/iter; left time: 492.4084s\n",
      "\titers: 200, epoch: 1 | loss: 0.2594370\n",
      "\tspeed: 0.0175s/iter; left time: 388.9339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.2804108 Vali Loss: 0.2111473 Test Loss: 0.2331517\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487849\n",
      "\tspeed: 0.0380s/iter; left time: 838.0859s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122121\n",
      "\tspeed: 0.0178s/iter; left time: 392.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1569681 Vali Loss: 0.0871886 Test Loss: 0.0957581\n",
      "Validation loss decreased (0.211147 --> 0.087189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0998303\n",
      "\tspeed: 0.0372s/iter; left time: 814.0209s\n",
      "\titers: 200, epoch: 3 | loss: 0.0900539\n",
      "\tspeed: 0.0225s/iter; left time: 489.4117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0995899 Vali Loss: 0.0780850 Test Loss: 0.0863740\n",
      "Validation loss decreased (0.087189 --> 0.078085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0908242\n",
      "\tspeed: 0.0389s/iter; left time: 840.8064s\n",
      "\titers: 200, epoch: 4 | loss: 0.0860295\n",
      "\tspeed: 0.0174s/iter; left time: 374.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0868707 Vali Loss: 0.0739030 Test Loss: 0.0811787\n",
      "Validation loss decreased (0.078085 --> 0.073903).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0818111\n",
      "\tspeed: 0.0365s/iter; left time: 782.2635s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754183\n",
      "\tspeed: 0.0173s/iter; left time: 367.6941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0790223 Vali Loss: 0.0694488 Test Loss: 0.0807753\n",
      "Validation loss decreased (0.073903 --> 0.069449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741047\n",
      "\tspeed: 0.0364s/iter; left time: 770.4307s\n",
      "\titers: 200, epoch: 6 | loss: 0.0749590\n",
      "\tspeed: 0.0174s/iter; left time: 367.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0735093 Vali Loss: 0.0666800 Test Loss: 0.0808575\n",
      "Validation loss decreased (0.069449 --> 0.066680).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0736243\n",
      "\tspeed: 0.0368s/iter; left time: 770.3161s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661629\n",
      "\tspeed: 0.0173s/iter; left time: 359.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0714205 Vali Loss: 0.0655510 Test Loss: 0.0802032\n",
      "Validation loss decreased (0.066680 --> 0.065551).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729664\n",
      "\tspeed: 0.0362s/iter; left time: 750.8221s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714460\n",
      "\tspeed: 0.0187s/iter; left time: 386.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0694222 Vali Loss: 0.0644655 Test Loss: 0.0811112\n",
      "Validation loss decreased (0.065551 --> 0.064465).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0659208\n",
      "\tspeed: 0.0385s/iter; left time: 789.5922s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711732\n",
      "\tspeed: 0.0180s/iter; left time: 366.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0683030 Vali Loss: 0.0633331 Test Loss: 0.0808911\n",
      "Validation loss decreased (0.064465 --> 0.063333).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658178\n",
      "\tspeed: 0.0370s/iter; left time: 750.0383s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632657\n",
      "\tspeed: 0.0174s/iter; left time: 352.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0671876 Vali Loss: 0.0626942 Test Loss: 0.0810161\n",
      "Validation loss decreased (0.063333 --> 0.062694).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675375\n",
      "\tspeed: 0.0384s/iter; left time: 770.6675s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656089\n",
      "\tspeed: 0.0185s/iter; left time: 368.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0663821 Vali Loss: 0.0650089 Test Loss: 0.0835631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698378\n",
      "\tspeed: 0.0362s/iter; left time: 717.3985s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709315\n",
      "\tspeed: 0.0173s/iter; left time: 341.4758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0658216 Vali Loss: 0.0622524 Test Loss: 0.0804868\n",
      "Validation loss decreased (0.062694 --> 0.062252).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0702056\n",
      "\tspeed: 0.0378s/iter; left time: 742.1324s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646744\n",
      "\tspeed: 0.0178s/iter; left time: 347.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0651245 Vali Loss: 0.0614892 Test Loss: 0.0798468\n",
      "Validation loss decreased (0.062252 --> 0.061489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0666263\n",
      "\tspeed: 0.0365s/iter; left time: 706.8843s\n",
      "\titers: 200, epoch: 14 | loss: 0.0637792\n",
      "\tspeed: 0.0172s/iter; left time: 331.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0645446 Vali Loss: 0.0609676 Test Loss: 0.0781604\n",
      "Validation loss decreased (0.061489 --> 0.060968).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713808\n",
      "\tspeed: 0.0359s/iter; left time: 687.0857s\n",
      "\titers: 200, epoch: 15 | loss: 0.0672789\n",
      "\tspeed: 0.0172s/iter; left time: 327.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0644304 Vali Loss: 0.0603074 Test Loss: 0.0764001\n",
      "Validation loss decreased (0.060968 --> 0.060307).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0611395\n",
      "\tspeed: 0.0399s/iter; left time: 755.9626s\n",
      "\titers: 200, epoch: 16 | loss: 0.0639924\n",
      "\tspeed: 0.0185s/iter; left time: 347.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0638584 Vali Loss: 0.0604877 Test Loss: 0.0751136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645290\n",
      "\tspeed: 0.0364s/iter; left time: 680.8836s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622595\n",
      "\tspeed: 0.0175s/iter; left time: 324.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0634671 Vali Loss: 0.0599232 Test Loss: 0.0762809\n",
      "Validation loss decreased (0.060307 --> 0.059923).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624876\n",
      "\tspeed: 0.0362s/iter; left time: 670.0254s\n",
      "\titers: 200, epoch: 18 | loss: 0.0637171\n",
      "\tspeed: 0.0174s/iter; left time: 320.8195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0630357 Vali Loss: 0.0595618 Test Loss: 0.0750244\n",
      "Validation loss decreased (0.059923 --> 0.059562).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0617419\n",
      "\tspeed: 0.0364s/iter; left time: 664.9845s\n",
      "\titers: 200, epoch: 19 | loss: 0.0608804\n",
      "\tspeed: 0.0181s/iter; left time: 329.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0629090 Vali Loss: 0.0596770 Test Loss: 0.0742886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0633113\n",
      "\tspeed: 0.0355s/iter; left time: 640.7500s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655701\n",
      "\tspeed: 0.0172s/iter; left time: 308.7671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0625126 Vali Loss: 0.0595197 Test Loss: 0.0756664\n",
      "Validation loss decreased (0.059562 --> 0.059520).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0628558\n",
      "\tspeed: 0.0360s/iter; left time: 641.1518s\n",
      "\titers: 200, epoch: 21 | loss: 0.0602739\n",
      "\tspeed: 0.0175s/iter; left time: 309.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0623610 Vali Loss: 0.0591243 Test Loss: 0.0753350\n",
      "Validation loss decreased (0.059520 --> 0.059124).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0651103\n",
      "\tspeed: 0.0360s/iter; left time: 634.1747s\n",
      "\titers: 200, epoch: 22 | loss: 0.0575442\n",
      "\tspeed: 0.0172s/iter; left time: 300.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0621670 Vali Loss: 0.0592054 Test Loss: 0.0741855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0664264\n",
      "\tspeed: 0.0383s/iter; left time: 665.3958s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587535\n",
      "\tspeed: 0.0204s/iter; left time: 352.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0620225 Vali Loss: 0.0589292 Test Loss: 0.0742925\n",
      "Validation loss decreased (0.059124 --> 0.058929).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0641541\n",
      "\tspeed: 0.0411s/iter; left time: 704.7218s\n",
      "\titers: 200, epoch: 24 | loss: 0.0634813\n",
      "\tspeed: 0.0192s/iter; left time: 326.6584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0621247 Vali Loss: 0.0589253 Test Loss: 0.0734498\n",
      "Validation loss decreased (0.058929 --> 0.058925).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0564462\n",
      "\tspeed: 0.0393s/iter; left time: 664.4384s\n",
      "\titers: 200, epoch: 25 | loss: 0.0637565\n",
      "\tspeed: 0.0179s/iter; left time: 301.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0617372 Vali Loss: 0.0589466 Test Loss: 0.0749519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0636609\n",
      "\tspeed: 0.0386s/iter; left time: 645.4398s\n",
      "\titers: 200, epoch: 26 | loss: 0.0584842\n",
      "\tspeed: 0.0197s/iter; left time: 327.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0616560 Vali Loss: 0.0590757 Test Loss: 0.0742946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0581466\n",
      "\tspeed: 0.0381s/iter; left time: 627.2260s\n",
      "\titers: 200, epoch: 27 | loss: 0.0603953\n",
      "\tspeed: 0.0173s/iter; left time: 283.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0616052 Vali Loss: 0.0585262 Test Loss: 0.0741448\n",
      "Validation loss decreased (0.058925 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0577278\n",
      "\tspeed: 0.0414s/iter; left time: 672.7993s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644682\n",
      "\tspeed: 0.0191s/iter; left time: 308.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0618389 Vali Loss: 0.0587341 Test Loss: 0.0739767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625474\n",
      "\tspeed: 0.0374s/iter; left time: 600.0340s\n",
      "\titers: 200, epoch: 29 | loss: 0.0580867\n",
      "\tspeed: 0.0173s/iter; left time: 275.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0613939 Vali Loss: 0.0586087 Test Loss: 0.0742347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0590229\n",
      "\tspeed: 0.0360s/iter; left time: 569.2042s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606227\n",
      "\tspeed: 0.0177s/iter; left time: 277.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0611694 Vali Loss: 0.0584188 Test Loss: 0.0739610\n",
      "Validation loss decreased (0.058526 --> 0.058419).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0643775\n",
      "\tspeed: 0.0365s/iter; left time: 568.8613s\n",
      "\titers: 200, epoch: 31 | loss: 0.0578023\n",
      "\tspeed: 0.0175s/iter; left time: 270.8767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0611918 Vali Loss: 0.0583375 Test Loss: 0.0744160\n",
      "Validation loss decreased (0.058419 --> 0.058337).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0579711\n",
      "\tspeed: 0.0386s/iter; left time: 593.2586s\n",
      "\titers: 200, epoch: 32 | loss: 0.0620027\n",
      "\tspeed: 0.0217s/iter; left time: 330.9704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0612068 Vali Loss: 0.0583986 Test Loss: 0.0742417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0653523\n",
      "\tspeed: 0.0377s/iter; left time: 570.6031s\n",
      "\titers: 200, epoch: 33 | loss: 0.0614485\n",
      "\tspeed: 0.0174s/iter; left time: 261.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0611182 Vali Loss: 0.0582882 Test Loss: 0.0733675\n",
      "Validation loss decreased (0.058337 --> 0.058288).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647610\n",
      "\tspeed: 0.0373s/iter; left time: 556.1559s\n",
      "\titers: 200, epoch: 34 | loss: 0.0633823\n",
      "\tspeed: 0.0172s/iter; left time: 255.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0610971 Vali Loss: 0.0584576 Test Loss: 0.0729061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0626284\n",
      "\tspeed: 0.0370s/iter; left time: 543.8397s\n",
      "\titers: 200, epoch: 35 | loss: 0.0601387\n",
      "\tspeed: 0.0174s/iter; left time: 253.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0610140 Vali Loss: 0.0582965 Test Loss: 0.0737146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639531\n",
      "\tspeed: 0.0383s/iter; left time: 554.4759s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608174\n",
      "\tspeed: 0.0234s/iter; left time: 335.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0611647 Vali Loss: 0.0582508 Test Loss: 0.0736249\n",
      "Validation loss decreased (0.058288 --> 0.058251).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0602419\n",
      "\tspeed: 0.0379s/iter; left time: 538.8731s\n",
      "\titers: 200, epoch: 37 | loss: 0.0581153\n",
      "\tspeed: 0.0173s/iter; left time: 244.8450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0610484 Vali Loss: 0.0583448 Test Loss: 0.0732000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0600050\n",
      "\tspeed: 0.0365s/iter; left time: 511.9540s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618239\n",
      "\tspeed: 0.0201s/iter; left time: 280.1040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0609829 Vali Loss: 0.0584209 Test Loss: 0.0728817\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601002\n",
      "\tspeed: 0.0364s/iter; left time: 502.0879s\n",
      "\titers: 200, epoch: 39 | loss: 0.0637596\n",
      "\tspeed: 0.0172s/iter; left time: 235.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0608545 Vali Loss: 0.0582400 Test Loss: 0.0727859\n",
      "Validation loss decreased (0.058251 --> 0.058240).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0579164\n",
      "\tspeed: 0.0365s/iter; left time: 495.6784s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646479\n",
      "\tspeed: 0.0174s/iter; left time: 234.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0608278 Vali Loss: 0.0582177 Test Loss: 0.0733635\n",
      "Validation loss decreased (0.058240 --> 0.058218).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0616952\n",
      "\tspeed: 0.0365s/iter; left time: 486.6934s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571715\n",
      "\tspeed: 0.0172s/iter; left time: 228.3225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0608960 Vali Loss: 0.0581996 Test Loss: 0.0732759\n",
      "Validation loss decreased (0.058218 --> 0.058200).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0631871\n",
      "\tspeed: 0.0396s/iter; left time: 519.5681s\n",
      "\titers: 200, epoch: 42 | loss: 0.0568571\n",
      "\tspeed: 0.0202s/iter; left time: 262.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0608211 Vali Loss: 0.0580944 Test Loss: 0.0728690\n",
      "Validation loss decreased (0.058200 --> 0.058094).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0618066\n",
      "\tspeed: 0.0367s/iter; left time: 473.7841s\n",
      "\titers: 200, epoch: 43 | loss: 0.0615122\n",
      "\tspeed: 0.0173s/iter; left time: 220.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0611374 Vali Loss: 0.0583234 Test Loss: 0.0724586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0589104\n",
      "\tspeed: 0.0361s/iter; left time: 457.3284s\n",
      "\titers: 200, epoch: 44 | loss: 0.0627911\n",
      "\tspeed: 0.0176s/iter; left time: 221.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0609306 Vali Loss: 0.0582577 Test Loss: 0.0726218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0628825\n",
      "\tspeed: 0.0363s/iter; left time: 451.2431s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587390\n",
      "\tspeed: 0.0175s/iter; left time: 215.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0613185 Vali Loss: 0.0582871 Test Loss: 0.0725785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0598876\n",
      "\tspeed: 0.0362s/iter; left time: 442.6862s\n",
      "\titers: 200, epoch: 46 | loss: 0.0615125\n",
      "\tspeed: 0.0172s/iter; left time: 208.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0608629 Vali Loss: 0.0581948 Test Loss: 0.0726809\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0631883\n",
      "\tspeed: 0.0368s/iter; left time: 441.1357s\n",
      "\titers: 200, epoch: 47 | loss: 0.0606678\n",
      "\tspeed: 0.0180s/iter; left time: 214.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0607024 Vali Loss: 0.0582297 Test Loss: 0.0723210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0599459\n",
      "\tspeed: 0.0377s/iter; left time: 443.7037s\n",
      "\titers: 200, epoch: 48 | loss: 0.0553894\n",
      "\tspeed: 0.0195s/iter; left time: 227.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0608386 Vali Loss: 0.0579962 Test Loss: 0.0727201\n",
      "Validation loss decreased (0.058094 --> 0.057996).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0578657\n",
      "\tspeed: 0.0419s/iter; left time: 483.6811s\n",
      "\titers: 200, epoch: 49 | loss: 0.0608033\n",
      "\tspeed: 0.0197s/iter; left time: 225.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0609807 Vali Loss: 0.0581391 Test Loss: 0.0725509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0621150\n",
      "\tspeed: 0.0378s/iter; left time: 427.7616s\n",
      "\titers: 200, epoch: 50 | loss: 0.0631911\n",
      "\tspeed: 0.0172s/iter; left time: 193.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0607364 Vali Loss: 0.0581990 Test Loss: 0.0728008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0609419\n",
      "\tspeed: 0.0377s/iter; left time: 418.7132s\n",
      "\titers: 200, epoch: 51 | loss: 0.0609045\n",
      "\tspeed: 0.0180s/iter; left time: 198.2711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0605976 Vali Loss: 0.0580235 Test Loss: 0.0729227\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0613372\n",
      "\tspeed: 0.0361s/iter; left time: 392.1944s\n",
      "\titers: 200, epoch: 52 | loss: 0.0578110\n",
      "\tspeed: 0.0174s/iter; left time: 187.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0606016 Vali Loss: 0.0580805 Test Loss: 0.0728458\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597081\n",
      "\tspeed: 0.0395s/iter; left time: 420.8255s\n",
      "\titers: 200, epoch: 53 | loss: 0.0599167\n",
      "\tspeed: 0.0176s/iter; left time: 185.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0606716 Vali Loss: 0.0581069 Test Loss: 0.0723052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0602916\n",
      "\tspeed: 0.0366s/iter; left time: 381.8918s\n",
      "\titers: 200, epoch: 54 | loss: 0.0620375\n",
      "\tspeed: 0.0183s/iter; left time: 188.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0607120 Vali Loss: 0.0583016 Test Loss: 0.0727637\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623368\n",
      "\tspeed: 0.0356s/iter; left time: 363.1763s\n",
      "\titers: 200, epoch: 55 | loss: 0.0654304\n",
      "\tspeed: 0.0172s/iter; left time: 173.6876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0606441 Vali Loss: 0.0581952 Test Loss: 0.0731348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0625696\n",
      "\tspeed: 0.0362s/iter; left time: 361.7058s\n",
      "\titers: 200, epoch: 56 | loss: 0.0563569\n",
      "\tspeed: 0.0196s/iter; left time: 193.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0607840 Vali Loss: 0.0580681 Test Loss: 0.0729142\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0616411\n",
      "\tspeed: 0.0371s/iter; left time: 361.9640s\n",
      "\titers: 200, epoch: 57 | loss: 0.0601746\n",
      "\tspeed: 0.0191s/iter; left time: 184.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0605397 Vali Loss: 0.0581108 Test Loss: 0.0730427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0618836\n",
      "\tspeed: 0.0388s/iter; left time: 369.5926s\n",
      "\titers: 200, epoch: 58 | loss: 0.0594452\n",
      "\tspeed: 0.0175s/iter; left time: 165.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0606900 Vali Loss: 0.0581163 Test Loss: 0.0726102\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01282523199915886, rmse:0.1132485419511795, mae:0.07272014766931534, rse:0.33327677845954895\n",
      "Intermediate time for ES and pred_len 24: 00h:10m:55.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2699923\n",
      "\tspeed: 0.0448s/iter; left time: 997.9702s\n",
      "\titers: 200, epoch: 1 | loss: 0.2550710\n",
      "\tspeed: 0.0179s/iter; left time: 396.6636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.2779176 Vali Loss: 0.2090562 Test Loss: 0.2344670\n",
      "Validation loss decreased (inf --> 0.209056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451056\n",
      "\tspeed: 0.0402s/iter; left time: 886.8529s\n",
      "\titers: 200, epoch: 2 | loss: 0.1162974\n",
      "\tspeed: 0.0176s/iter; left time: 387.2512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.1551280 Vali Loss: 0.1042353 Test Loss: 0.1172750\n",
      "Validation loss decreased (0.209056 --> 0.104235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089795\n",
      "\tspeed: 0.0390s/iter; left time: 851.2131s\n",
      "\titers: 200, epoch: 3 | loss: 0.1037570\n",
      "\tspeed: 0.0182s/iter; left time: 394.8534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1090032 Vali Loss: 0.0926297 Test Loss: 0.1092328\n",
      "Validation loss decreased (0.104235 --> 0.092630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0931839\n",
      "\tspeed: 0.0442s/iter; left time: 957.0213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0921412\n",
      "\tspeed: 0.0193s/iter; left time: 415.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0958092 Vali Loss: 0.0869654 Test Loss: 0.1052669\n",
      "Validation loss decreased (0.092630 --> 0.086965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0885624\n",
      "\tspeed: 0.0423s/iter; left time: 905.8974s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861385\n",
      "\tspeed: 0.0231s/iter; left time: 493.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0911318 Vali Loss: 0.0844819 Test Loss: 0.1059624\n",
      "Validation loss decreased (0.086965 --> 0.084482).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0869646\n",
      "\tspeed: 0.0396s/iter; left time: 837.8166s\n",
      "\titers: 200, epoch: 6 | loss: 0.0883404\n",
      "\tspeed: 0.0179s/iter; left time: 377.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0878641 Vali Loss: 0.0837793 Test Loss: 0.1088766\n",
      "Validation loss decreased (0.084482 --> 0.083779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0886907\n",
      "\tspeed: 0.0388s/iter; left time: 812.1509s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817665\n",
      "\tspeed: 0.0177s/iter; left time: 369.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0862188 Vali Loss: 0.0827717 Test Loss: 0.1055454\n",
      "Validation loss decreased (0.083779 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847801\n",
      "\tspeed: 0.0390s/iter; left time: 809.1093s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820215\n",
      "\tspeed: 0.0176s/iter; left time: 363.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0846143 Vali Loss: 0.0810567 Test Loss: 0.1060755\n",
      "Validation loss decreased (0.082772 --> 0.081057).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844776\n",
      "\tspeed: 0.0400s/iter; left time: 820.7257s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794606\n",
      "\tspeed: 0.0188s/iter; left time: 383.0678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0838625 Vali Loss: 0.0811782 Test Loss: 0.1076061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0855363\n",
      "\tspeed: 0.0382s/iter; left time: 773.8898s\n",
      "\titers: 200, epoch: 10 | loss: 0.0853410\n",
      "\tspeed: 0.0177s/iter; left time: 358.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0832864 Vali Loss: 0.0808300 Test Loss: 0.1084978\n",
      "Validation loss decreased (0.081057 --> 0.080830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816533\n",
      "\tspeed: 0.0384s/iter; left time: 771.2038s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852584\n",
      "\tspeed: 0.0175s/iter; left time: 349.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0824372 Vali Loss: 0.0800179 Test Loss: 0.1059387\n",
      "Validation loss decreased (0.080830 --> 0.080018).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0845546\n",
      "\tspeed: 0.0380s/iter; left time: 753.7459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818359\n",
      "\tspeed: 0.0219s/iter; left time: 432.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0820708 Vali Loss: 0.0797471 Test Loss: 0.1046065\n",
      "Validation loss decreased (0.080018 --> 0.079747).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0820495\n",
      "\tspeed: 0.0404s/iter; left time: 791.8239s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821259\n",
      "\tspeed: 0.0187s/iter; left time: 365.2692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0817390 Vali Loss: 0.0797309 Test Loss: 0.1047793\n",
      "Validation loss decreased (0.079747 --> 0.079731).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771034\n",
      "\tspeed: 0.0379s/iter; left time: 735.2599s\n",
      "\titers: 200, epoch: 14 | loss: 0.0803334\n",
      "\tspeed: 0.0185s/iter; left time: 356.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0816818 Vali Loss: 0.0795235 Test Loss: 0.1054109\n",
      "Validation loss decreased (0.079731 --> 0.079524).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790244\n",
      "\tspeed: 0.0381s/iter; left time: 729.6871s\n",
      "\titers: 200, epoch: 15 | loss: 0.0830677\n",
      "\tspeed: 0.0176s/iter; left time: 335.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0809772 Vali Loss: 0.0793998 Test Loss: 0.1049986\n",
      "Validation loss decreased (0.079524 --> 0.079400).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790241\n",
      "\tspeed: 0.0379s/iter; left time: 718.0002s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845467\n",
      "\tspeed: 0.0176s/iter; left time: 330.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0810577 Vali Loss: 0.0812501 Test Loss: 0.1041506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794203\n",
      "\tspeed: 0.0368s/iter; left time: 688.2631s\n",
      "\titers: 200, epoch: 17 | loss: 0.0831470\n",
      "\tspeed: 0.0178s/iter; left time: 331.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0806764 Vali Loss: 0.0792494 Test Loss: 0.1062545\n",
      "Validation loss decreased (0.079400 --> 0.079249).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804426\n",
      "\tspeed: 0.0426s/iter; left time: 787.6370s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796953\n",
      "\tspeed: 0.0236s/iter; left time: 433.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0806038 Vali Loss: 0.0788590 Test Loss: 0.1040276\n",
      "Validation loss decreased (0.079249 --> 0.078859).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0802150\n",
      "\tspeed: 0.0386s/iter; left time: 705.5230s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840697\n",
      "\tspeed: 0.0174s/iter; left time: 315.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0800741 Vali Loss: 0.0789752 Test Loss: 0.1047164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0799749\n",
      "\tspeed: 0.0367s/iter; left time: 662.0051s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796723\n",
      "\tspeed: 0.0175s/iter; left time: 314.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0799620 Vali Loss: 0.0787971 Test Loss: 0.1043757\n",
      "Validation loss decreased (0.078859 --> 0.078797).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814895\n",
      "\tspeed: 0.0422s/iter; left time: 751.8593s\n",
      "\titers: 200, epoch: 21 | loss: 0.0775726\n",
      "\tspeed: 0.0231s/iter; left time: 408.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0799304 Vali Loss: 0.0786215 Test Loss: 0.1053541\n",
      "Validation loss decreased (0.078797 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0822030\n",
      "\tspeed: 0.0386s/iter; left time: 679.1259s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822271\n",
      "\tspeed: 0.0176s/iter; left time: 308.0636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0797733 Vali Loss: 0.0788172 Test Loss: 0.1050946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0782094\n",
      "\tspeed: 0.0380s/iter; left time: 660.4837s\n",
      "\titers: 200, epoch: 23 | loss: 0.0817364\n",
      "\tspeed: 0.0178s/iter; left time: 307.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0796080 Vali Loss: 0.0783708 Test Loss: 0.1048175\n",
      "Validation loss decreased (0.078622 --> 0.078371).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0782946\n",
      "\tspeed: 0.0445s/iter; left time: 762.6778s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759547\n",
      "\tspeed: 0.0176s/iter; left time: 300.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0795476 Vali Loss: 0.0784284 Test Loss: 0.1046700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781184\n",
      "\tspeed: 0.0380s/iter; left time: 642.4495s\n",
      "\titers: 200, epoch: 25 | loss: 0.0811927\n",
      "\tspeed: 0.0176s/iter; left time: 296.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0799517 Vali Loss: 0.0786431 Test Loss: 0.1045798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0762303\n",
      "\tspeed: 0.0371s/iter; left time: 620.2186s\n",
      "\titers: 200, epoch: 26 | loss: 0.0799544\n",
      "\tspeed: 0.0188s/iter; left time: 312.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0793796 Vali Loss: 0.0786190 Test Loss: 0.1051480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789374\n",
      "\tspeed: 0.0389s/iter; left time: 640.2158s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780281\n",
      "\tspeed: 0.0220s/iter; left time: 360.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0792773 Vali Loss: 0.0784299 Test Loss: 0.1052233\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0814020\n",
      "\tspeed: 0.0388s/iter; left time: 630.4335s\n",
      "\titers: 200, epoch: 28 | loss: 0.0798138\n",
      "\tspeed: 0.0177s/iter; left time: 285.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0791199 Vali Loss: 0.0783501 Test Loss: 0.1047811\n",
      "Validation loss decreased (0.078371 --> 0.078350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0820562\n",
      "\tspeed: 0.0375s/iter; left time: 601.5273s\n",
      "\titers: 200, epoch: 29 | loss: 0.0808358\n",
      "\tspeed: 0.0183s/iter; left time: 291.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0791596 Vali Loss: 0.0785035 Test Loss: 0.1055300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0763969\n",
      "\tspeed: 0.0397s/iter; left time: 627.3603s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771363\n",
      "\tspeed: 0.0263s/iter; left time: 413.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0791952 Vali Loss: 0.0784093 Test Loss: 0.1051583\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785842\n",
      "\tspeed: 0.0382s/iter; left time: 594.4761s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813041\n",
      "\tspeed: 0.0176s/iter; left time: 272.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0790166 Vali Loss: 0.0783721 Test Loss: 0.1051348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0805069\n",
      "\tspeed: 0.0378s/iter; left time: 580.9724s\n",
      "\titers: 200, epoch: 32 | loss: 0.0800453\n",
      "\tspeed: 0.0174s/iter; left time: 264.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0790431 Vali Loss: 0.0783341 Test Loss: 0.1047582\n",
      "Validation loss decreased (0.078350 --> 0.078334).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0781617\n",
      "\tspeed: 0.0392s/iter; left time: 593.6105s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795569\n",
      "\tspeed: 0.0182s/iter; left time: 273.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0790344 Vali Loss: 0.0783522 Test Loss: 0.1054242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754284\n",
      "\tspeed: 0.0376s/iter; left time: 560.2990s\n",
      "\titers: 200, epoch: 34 | loss: 0.0840273\n",
      "\tspeed: 0.0177s/iter; left time: 262.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0790746 Vali Loss: 0.0782857 Test Loss: 0.1051250\n",
      "Validation loss decreased (0.078334 --> 0.078286).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0800861\n",
      "\tspeed: 0.0375s/iter; left time: 550.3961s\n",
      "\titers: 200, epoch: 35 | loss: 0.0839135\n",
      "\tspeed: 0.0177s/iter; left time: 258.3323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0789047 Vali Loss: 0.0782892 Test Loss: 0.1051449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0803963\n",
      "\tspeed: 0.0397s/iter; left time: 574.3842s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774545\n",
      "\tspeed: 0.0178s/iter; left time: 255.7070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0788350 Vali Loss: 0.0783046 Test Loss: 0.1055788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0808286\n",
      "\tspeed: 0.0378s/iter; left time: 537.7878s\n",
      "\titers: 200, epoch: 37 | loss: 0.0770837\n",
      "\tspeed: 0.0179s/iter; left time: 253.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0788810 Vali Loss: 0.0783464 Test Loss: 0.1056055\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0771653\n",
      "\tspeed: 0.0376s/iter; left time: 527.1019s\n",
      "\titers: 200, epoch: 38 | loss: 0.0761486\n",
      "\tspeed: 0.0177s/iter; left time: 246.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0791125 Vali Loss: 0.0782723 Test Loss: 0.1056459\n",
      "Validation loss decreased (0.078286 --> 0.078272).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0771597\n",
      "\tspeed: 0.0374s/iter; left time: 516.3477s\n",
      "\titers: 200, epoch: 39 | loss: 0.0795766\n",
      "\tspeed: 0.0178s/iter; left time: 244.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0789243 Vali Loss: 0.0781249 Test Loss: 0.1045209\n",
      "Validation loss decreased (0.078272 --> 0.078125).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0800514\n",
      "\tspeed: 0.0378s/iter; left time: 512.8787s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769166\n",
      "\tspeed: 0.0178s/iter; left time: 239.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0787367 Vali Loss: 0.0781777 Test Loss: 0.1055735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0788939\n",
      "\tspeed: 0.0372s/iter; left time: 496.6777s\n",
      "\titers: 200, epoch: 41 | loss: 0.0796120\n",
      "\tspeed: 0.0173s/iter; left time: 229.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0787654 Vali Loss: 0.0783776 Test Loss: 0.1058984\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0801310\n",
      "\tspeed: 0.0411s/iter; left time: 538.4760s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760927\n",
      "\tspeed: 0.0193s/iter; left time: 250.7222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0787919 Vali Loss: 0.0782467 Test Loss: 0.1052588\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0780973\n",
      "\tspeed: 0.0388s/iter; left time: 500.4722s\n",
      "\titers: 200, epoch: 43 | loss: 0.0798386\n",
      "\tspeed: 0.0177s/iter; left time: 226.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0787492 Vali Loss: 0.0781928 Test Loss: 0.1050963\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0823438\n",
      "\tspeed: 0.0380s/iter; left time: 481.9794s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814990\n",
      "\tspeed: 0.0173s/iter; left time: 217.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0787495 Vali Loss: 0.0783943 Test Loss: 0.1058547\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0747283\n",
      "\tspeed: 0.0375s/iter; left time: 467.0660s\n",
      "\titers: 200, epoch: 45 | loss: 0.0808855\n",
      "\tspeed: 0.0178s/iter; left time: 219.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0786864 Vali Loss: 0.0781960 Test Loss: 0.1050198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0759459\n",
      "\tspeed: 0.0395s/iter; left time: 483.0345s\n",
      "\titers: 200, epoch: 46 | loss: 0.0787885\n",
      "\tspeed: 0.0197s/iter; left time: 238.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0786618 Vali Loss: 0.0782442 Test Loss: 0.1055460\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0770903\n",
      "\tspeed: 0.0394s/iter; left time: 472.3410s\n",
      "\titers: 200, epoch: 47 | loss: 0.0741980\n",
      "\tspeed: 0.0192s/iter; left time: 228.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0786734 Vali Loss: 0.0782155 Test Loss: 0.1053684\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0808809\n",
      "\tspeed: 0.0368s/iter; left time: 433.0627s\n",
      "\titers: 200, epoch: 48 | loss: 0.0765063\n",
      "\tspeed: 0.0182s/iter; left time: 212.1640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0787458 Vali Loss: 0.0782955 Test Loss: 0.1055569\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0781761\n",
      "\tspeed: 0.0378s/iter; left time: 435.9825s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780755\n",
      "\tspeed: 0.0177s/iter; left time: 202.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0785175 Vali Loss: 0.0782023 Test Loss: 0.1054485\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02427673526108265, rmse:0.1558099389076233, mae:0.10452089458703995, rse:0.4577226936817169\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2807732\n",
      "\tspeed: 0.0206s/iter; left time: 459.5975s\n",
      "\titers: 200, epoch: 1 | loss: 0.2653032\n",
      "\tspeed: 0.0179s/iter; left time: 397.4262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.2841145 Vali Loss: 0.2130373 Test Loss: 0.2379890\n",
      "Validation loss decreased (inf --> 0.213037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1392819\n",
      "\tspeed: 0.0402s/iter; left time: 886.4672s\n",
      "\titers: 200, epoch: 2 | loss: 0.1165387\n",
      "\tspeed: 0.0187s/iter; left time: 410.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1551139 Vali Loss: 0.1124424 Test Loss: 0.1264123\n",
      "Validation loss decreased (0.213037 --> 0.112442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1126997\n",
      "\tspeed: 0.0390s/iter; left time: 853.2412s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035556\n",
      "\tspeed: 0.0208s/iter; left time: 452.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1085227 Vali Loss: 0.0961990 Test Loss: 0.1101242\n",
      "Validation loss decreased (0.112442 --> 0.096199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962838\n",
      "\tspeed: 0.0414s/iter; left time: 895.3841s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969591\n",
      "\tspeed: 0.0178s/iter; left time: 383.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0975332 Vali Loss: 0.0874930 Test Loss: 0.1175036\n",
      "Validation loss decreased (0.096199 --> 0.087493).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0933458\n",
      "\tspeed: 0.0385s/iter; left time: 823.3431s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946651\n",
      "\tspeed: 0.0176s/iter; left time: 374.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0918568 Vali Loss: 0.0853591 Test Loss: 0.1164506\n",
      "Validation loss decreased (0.087493 --> 0.085359).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0905998\n",
      "\tspeed: 0.0378s/iter; left time: 799.6482s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834064\n",
      "\tspeed: 0.0175s/iter; left time: 369.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0886637 Vali Loss: 0.0833173 Test Loss: 0.1190308\n",
      "Validation loss decreased (0.085359 --> 0.083317).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859550\n",
      "\tspeed: 0.0422s/iter; left time: 883.7168s\n",
      "\titers: 200, epoch: 7 | loss: 0.0857930\n",
      "\tspeed: 0.0200s/iter; left time: 417.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0870941 Vali Loss: 0.0824725 Test Loss: 0.1289645\n",
      "Validation loss decreased (0.083317 --> 0.082472).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0835487\n",
      "\tspeed: 0.0394s/iter; left time: 816.2403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800077\n",
      "\tspeed: 0.0174s/iter; left time: 359.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0859448 Vali Loss: 0.0809953 Test Loss: 0.1246080\n",
      "Validation loss decreased (0.082472 --> 0.080995).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829436\n",
      "\tspeed: 0.0419s/iter; left time: 859.9700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795209\n",
      "\tspeed: 0.0220s/iter; left time: 447.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0850060 Vali Loss: 0.0815726 Test Loss: 0.1122439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0820003\n",
      "\tspeed: 0.0468s/iter; left time: 948.6396s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848408\n",
      "\tspeed: 0.0194s/iter; left time: 391.8755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0839826 Vali Loss: 0.0810251 Test Loss: 0.1215878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819815\n",
      "\tspeed: 0.0383s/iter; left time: 769.2619s\n",
      "\titers: 200, epoch: 11 | loss: 0.0843423\n",
      "\tspeed: 0.0177s/iter; left time: 352.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0837573 Vali Loss: 0.0803522 Test Loss: 0.1226014\n",
      "Validation loss decreased (0.080995 --> 0.080352).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821579\n",
      "\tspeed: 0.0391s/iter; left time: 776.3223s\n",
      "\titers: 200, epoch: 12 | loss: 0.0825495\n",
      "\tspeed: 0.0176s/iter; left time: 348.2790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0829496 Vali Loss: 0.0797525 Test Loss: 0.1239641\n",
      "Validation loss decreased (0.080352 --> 0.079753).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0780287\n",
      "\tspeed: 0.0379s/iter; left time: 744.1807s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800011\n",
      "\tspeed: 0.0193s/iter; left time: 376.1003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0824018 Vali Loss: 0.0796889 Test Loss: 0.1207599\n",
      "Validation loss decreased (0.079753 --> 0.079689).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0824617\n",
      "\tspeed: 0.0382s/iter; left time: 740.5484s\n",
      "\titers: 200, epoch: 14 | loss: 0.0812564\n",
      "\tspeed: 0.0183s/iter; left time: 352.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0819560 Vali Loss: 0.0796502 Test Loss: 0.1245411\n",
      "Validation loss decreased (0.079689 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0830183\n",
      "\tspeed: 0.0404s/iter; left time: 773.3778s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822272\n",
      "\tspeed: 0.0174s/iter; left time: 332.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0817088 Vali Loss: 0.0795031 Test Loss: 0.1285043\n",
      "Validation loss decreased (0.079650 --> 0.079503).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823791\n",
      "\tspeed: 0.0423s/iter; left time: 800.6043s\n",
      "\titers: 200, epoch: 16 | loss: 0.0843695\n",
      "\tspeed: 0.0216s/iter; left time: 406.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0813237 Vali Loss: 0.0790901 Test Loss: 0.1307180\n",
      "Validation loss decreased (0.079503 --> 0.079090).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792187\n",
      "\tspeed: 0.0381s/iter; left time: 712.6779s\n",
      "\titers: 200, epoch: 17 | loss: 0.0829362\n",
      "\tspeed: 0.0176s/iter; left time: 326.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0812568 Vali Loss: 0.0794295 Test Loss: 0.1282273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0772294\n",
      "\tspeed: 0.0377s/iter; left time: 697.5757s\n",
      "\titers: 200, epoch: 18 | loss: 0.0806995\n",
      "\tspeed: 0.0175s/iter; left time: 321.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0811110 Vali Loss: 0.0793635 Test Loss: 0.1272759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784017\n",
      "\tspeed: 0.0380s/iter; left time: 694.8510s\n",
      "\titers: 200, epoch: 19 | loss: 0.0811006\n",
      "\tspeed: 0.0176s/iter; left time: 320.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0807204 Vali Loss: 0.0791787 Test Loss: 0.1262407\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806236\n",
      "\tspeed: 0.0407s/iter; left time: 733.6630s\n",
      "\titers: 200, epoch: 20 | loss: 0.0801287\n",
      "\tspeed: 0.0178s/iter; left time: 319.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0805928 Vali Loss: 0.0788154 Test Loss: 0.1241784\n",
      "Validation loss decreased (0.079090 --> 0.078815).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814793\n",
      "\tspeed: 0.0377s/iter; left time: 672.4910s\n",
      "\titers: 200, epoch: 21 | loss: 0.0794477\n",
      "\tspeed: 0.0174s/iter; left time: 308.9184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0805322 Vali Loss: 0.0791230 Test Loss: 0.1281666\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802228\n",
      "\tspeed: 0.0378s/iter; left time: 665.2633s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822596\n",
      "\tspeed: 0.0189s/iter; left time: 330.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0803095 Vali Loss: 0.0789785 Test Loss: 0.1211020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0813869\n",
      "\tspeed: 0.0385s/iter; left time: 669.5588s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802233\n",
      "\tspeed: 0.0174s/iter; left time: 300.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0803901 Vali Loss: 0.0790809 Test Loss: 0.1202924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0823530\n",
      "\tspeed: 0.0371s/iter; left time: 636.8709s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754244\n",
      "\tspeed: 0.0176s/iter; left time: 300.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0799929 Vali Loss: 0.0786709 Test Loss: 0.1282071\n",
      "Validation loss decreased (0.078815 --> 0.078671).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0769625\n",
      "\tspeed: 0.0387s/iter; left time: 654.2461s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787524\n",
      "\tspeed: 0.0179s/iter; left time: 301.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0799626 Vali Loss: 0.0787696 Test Loss: 0.1272044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821803\n",
      "\tspeed: 0.0377s/iter; left time: 629.3065s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780077\n",
      "\tspeed: 0.0177s/iter; left time: 293.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0799785 Vali Loss: 0.0786442 Test Loss: 0.1239915\n",
      "Validation loss decreased (0.078671 --> 0.078644).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0795876\n",
      "\tspeed: 0.0385s/iter; left time: 633.7366s\n",
      "\titers: 200, epoch: 27 | loss: 0.0790085\n",
      "\tspeed: 0.0180s/iter; left time: 295.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0797704 Vali Loss: 0.0786359 Test Loss: 0.1259093\n",
      "Validation loss decreased (0.078644 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0818633\n",
      "\tspeed: 0.0389s/iter; left time: 631.4870s\n",
      "\titers: 200, epoch: 28 | loss: 0.0793344\n",
      "\tspeed: 0.0177s/iter; left time: 285.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0797060 Vali Loss: 0.0784768 Test Loss: 0.1269663\n",
      "Validation loss decreased (0.078636 --> 0.078477).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0812629\n",
      "\tspeed: 0.0401s/iter; left time: 641.9916s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797160\n",
      "\tspeed: 0.0187s/iter; left time: 298.5312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0796613 Vali Loss: 0.0785777 Test Loss: 0.1275836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0785135\n",
      "\tspeed: 0.0408s/iter; left time: 644.4706s\n",
      "\titers: 200, epoch: 30 | loss: 0.0747149\n",
      "\tspeed: 0.0200s/iter; left time: 314.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0795775 Vali Loss: 0.0786406 Test Loss: 0.1256996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0790730\n",
      "\tspeed: 0.0390s/iter; left time: 608.3640s\n",
      "\titers: 200, epoch: 31 | loss: 0.0801010\n",
      "\tspeed: 0.0182s/iter; left time: 282.0768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0794757 Vali Loss: 0.0785512 Test Loss: 0.1254068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0801477\n",
      "\tspeed: 0.0413s/iter; left time: 634.2224s\n",
      "\titers: 200, epoch: 32 | loss: 0.0805202\n",
      "\tspeed: 0.0215s/iter; left time: 328.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0794999 Vali Loss: 0.0785085 Test Loss: 0.1251069\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760565\n",
      "\tspeed: 0.0380s/iter; left time: 574.3085s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793328\n",
      "\tspeed: 0.0175s/iter; left time: 263.3110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0795171 Vali Loss: 0.0785686 Test Loss: 0.1274197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0773843\n",
      "\tspeed: 0.0382s/iter; left time: 569.6855s\n",
      "\titers: 200, epoch: 34 | loss: 0.0792592\n",
      "\tspeed: 0.0174s/iter; left time: 258.2988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0794413 Vali Loss: 0.0782065 Test Loss: 0.1235717\n",
      "Validation loss decreased (0.078477 --> 0.078206).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0784409\n",
      "\tspeed: 0.0406s/iter; left time: 595.8480s\n",
      "\titers: 200, epoch: 35 | loss: 0.0783178\n",
      "\tspeed: 0.0184s/iter; left time: 268.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0795024 Vali Loss: 0.0784416 Test Loss: 0.1234996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0821839\n",
      "\tspeed: 0.0389s/iter; left time: 562.5106s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777974\n",
      "\tspeed: 0.0175s/iter; left time: 251.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0781588 Test Loss: 0.1211270\n",
      "Validation loss decreased (0.078206 --> 0.078159).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0747080\n",
      "\tspeed: 0.0386s/iter; left time: 549.7333s\n",
      "\titers: 200, epoch: 37 | loss: 0.0795331\n",
      "\tspeed: 0.0176s/iter; left time: 248.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0792608 Vali Loss: 0.0784312 Test Loss: 0.1257160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0776572\n",
      "\tspeed: 0.0392s/iter; left time: 549.2437s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762254\n",
      "\tspeed: 0.0229s/iter; left time: 318.2909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0794165 Vali Loss: 0.0782640 Test Loss: 0.1224292\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0813769\n",
      "\tspeed: 0.0409s/iter; left time: 564.1603s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792352\n",
      "\tspeed: 0.0187s/iter; left time: 256.2299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0793261 Vali Loss: 0.0783679 Test Loss: 0.1225942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799571\n",
      "\tspeed: 0.0379s/iter; left time: 513.7359s\n",
      "\titers: 200, epoch: 40 | loss: 0.0804243\n",
      "\tspeed: 0.0198s/iter; left time: 267.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0792455 Vali Loss: 0.0784150 Test Loss: 0.1252133\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0813761\n",
      "\tspeed: 0.0407s/iter; left time: 542.5395s\n",
      "\titers: 200, epoch: 41 | loss: 0.0816666\n",
      "\tspeed: 0.0181s/iter; left time: 239.8034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0792573 Vali Loss: 0.0782532 Test Loss: 0.1225800\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0778905\n",
      "\tspeed: 0.0373s/iter; left time: 488.8481s\n",
      "\titers: 200, epoch: 42 | loss: 0.0788236\n",
      "\tspeed: 0.0192s/iter; left time: 250.4762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0792435 Vali Loss: 0.0781906 Test Loss: 0.1238133\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0783627\n",
      "\tspeed: 0.0406s/iter; left time: 523.9880s\n",
      "\titers: 200, epoch: 43 | loss: 0.0787241\n",
      "\tspeed: 0.0176s/iter; left time: 224.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0793239 Vali Loss: 0.0781083 Test Loss: 0.1231488\n",
      "Validation loss decreased (0.078159 --> 0.078108).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0763025\n",
      "\tspeed: 0.0382s/iter; left time: 484.4711s\n",
      "\titers: 200, epoch: 44 | loss: 0.0738823\n",
      "\tspeed: 0.0174s/iter; left time: 218.9517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0792564 Vali Loss: 0.0784912 Test Loss: 0.1267495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0757882\n",
      "\tspeed: 0.0386s/iter; left time: 479.8134s\n",
      "\titers: 200, epoch: 45 | loss: 0.0789459\n",
      "\tspeed: 0.0203s/iter; left time: 250.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0793981 Vali Loss: 0.0783084 Test Loss: 0.1237282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0772759\n",
      "\tspeed: 0.0379s/iter; left time: 463.5877s\n",
      "\titers: 200, epoch: 46 | loss: 0.0767787\n",
      "\tspeed: 0.0179s/iter; left time: 216.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0790786 Vali Loss: 0.0783964 Test Loss: 0.1239477\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0750165\n",
      "\tspeed: 0.0378s/iter; left time: 453.3052s\n",
      "\titers: 200, epoch: 47 | loss: 0.0791191\n",
      "\tspeed: 0.0218s/iter; left time: 259.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0791732 Vali Loss: 0.0784350 Test Loss: 0.1260129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0822771\n",
      "\tspeed: 0.0430s/iter; left time: 506.5437s\n",
      "\titers: 200, epoch: 48 | loss: 0.0833114\n",
      "\tspeed: 0.0229s/iter; left time: 266.9940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0792517 Vali Loss: 0.0783070 Test Loss: 0.1245301\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0782012\n",
      "\tspeed: 0.0421s/iter; left time: 486.6283s\n",
      "\titers: 200, epoch: 49 | loss: 0.0790513\n",
      "\tspeed: 0.0176s/iter; left time: 201.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0790816 Vali Loss: 0.0784223 Test Loss: 0.1252991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0769528\n",
      "\tspeed: 0.0379s/iter; left time: 429.3553s\n",
      "\titers: 200, epoch: 50 | loss: 0.0796110\n",
      "\tspeed: 0.0176s/iter; left time: 197.8750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0792062 Vali Loss: 0.0781806 Test Loss: 0.1240269\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0821458\n",
      "\tspeed: 0.0373s/iter; left time: 414.2755s\n",
      "\titers: 200, epoch: 51 | loss: 0.0748606\n",
      "\tspeed: 0.0175s/iter; left time: 192.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0791860 Vali Loss: 0.0783969 Test Loss: 0.1252220\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0788861\n",
      "\tspeed: 0.0379s/iter; left time: 412.2790s\n",
      "\titers: 200, epoch: 52 | loss: 0.0744792\n",
      "\tspeed: 0.0178s/iter; left time: 191.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0791129 Vali Loss: 0.0783578 Test Loss: 0.1260209\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0779445\n",
      "\tspeed: 0.0388s/iter; left time: 413.3772s\n",
      "\titers: 200, epoch: 53 | loss: 0.0807185\n",
      "\tspeed: 0.0182s/iter; left time: 192.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0790737 Vali Loss: 0.0782593 Test Loss: 0.1245420\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04175650700926781, rmse:0.20434409379959106, mae:0.1231488287448883, rse:0.6003013849258423\n",
      "Intermediate time for ES and pred_len 96: 00h:10m:01.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2749318\n",
      "\tspeed: 0.0438s/iter; left time: 973.3953s\n",
      "\titers: 200, epoch: 1 | loss: 0.2637250\n",
      "\tspeed: 0.0179s/iter; left time: 395.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.2789764 Vali Loss: 0.2100756 Test Loss: 0.2343825\n",
      "Validation loss decreased (inf --> 0.210076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1421229\n",
      "\tspeed: 0.0391s/iter; left time: 860.0037s\n",
      "\titers: 200, epoch: 2 | loss: 0.1207080\n",
      "\tspeed: 0.0178s/iter; left time: 390.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1543833 Vali Loss: 0.1086527 Test Loss: 0.1232387\n",
      "Validation loss decreased (0.210076 --> 0.108653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1143583\n",
      "\tspeed: 0.0403s/iter; left time: 876.4387s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035095\n",
      "\tspeed: 0.0179s/iter; left time: 386.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1096992 Vali Loss: 0.0961292 Test Loss: 0.1119838\n",
      "Validation loss decreased (0.108653 --> 0.096129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991537\n",
      "\tspeed: 0.0404s/iter; left time: 870.3899s\n",
      "\titers: 200, epoch: 4 | loss: 0.0941834\n",
      "\tspeed: 0.0199s/iter; left time: 425.7368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0979566 Vali Loss: 0.0913458 Test Loss: 0.1117256\n",
      "Validation loss decreased (0.096129 --> 0.091346).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948883\n",
      "\tspeed: 0.0382s/iter; left time: 813.5286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0904951\n",
      "\tspeed: 0.0178s/iter; left time: 377.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0934428 Vali Loss: 0.0899405 Test Loss: 0.1138975\n",
      "Validation loss decreased (0.091346 --> 0.089940).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889967\n",
      "\tspeed: 0.0388s/iter; left time: 817.6555s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896095\n",
      "\tspeed: 0.0179s/iter; left time: 376.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0908615 Vali Loss: 0.0874881 Test Loss: 0.1135529\n",
      "Validation loss decreased (0.089940 --> 0.087488).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891786\n",
      "\tspeed: 0.0392s/iter; left time: 816.9278s\n",
      "\titers: 200, epoch: 7 | loss: 0.0887473\n",
      "\tspeed: 0.0184s/iter; left time: 381.1705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0893473 Vali Loss: 0.0867286 Test Loss: 0.1134460\n",
      "Validation loss decreased (0.087488 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847037\n",
      "\tspeed: 0.0384s/iter; left time: 793.5267s\n",
      "\titers: 200, epoch: 8 | loss: 0.0879599\n",
      "\tspeed: 0.0178s/iter; left time: 364.8447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0882717 Vali Loss: 0.0867410 Test Loss: 0.1150925\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0870168\n",
      "\tspeed: 0.0411s/iter; left time: 838.1825s\n",
      "\titers: 200, epoch: 9 | loss: 0.0849715\n",
      "\tspeed: 0.0191s/iter; left time: 387.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0878216 Vali Loss: 0.0872022 Test Loss: 0.1176080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0875702\n",
      "\tspeed: 0.0423s/iter; left time: 854.7382s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899240\n",
      "\tspeed: 0.0176s/iter; left time: 354.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0869609 Vali Loss: 0.0860930 Test Loss: 0.1131297\n",
      "Validation loss decreased (0.086729 --> 0.086093).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0882442\n",
      "\tspeed: 0.0381s/iter; left time: 761.3512s\n",
      "\titers: 200, epoch: 11 | loss: 0.0836711\n",
      "\tspeed: 0.0178s/iter; left time: 354.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0865654 Vali Loss: 0.0859699 Test Loss: 0.1132639\n",
      "Validation loss decreased (0.086093 --> 0.085970).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0827679\n",
      "\tspeed: 0.0405s/iter; left time: 799.5681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866363\n",
      "\tspeed: 0.0189s/iter; left time: 370.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0860623 Vali Loss: 0.0858304 Test Loss: 0.1128382\n",
      "Validation loss decreased (0.085970 --> 0.085830).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0829732\n",
      "\tspeed: 0.0411s/iter; left time: 801.9210s\n",
      "\titers: 200, epoch: 13 | loss: 0.0850765\n",
      "\tspeed: 0.0205s/iter; left time: 398.4228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0856914 Vali Loss: 0.0856651 Test Loss: 0.1135978\n",
      "Validation loss decreased (0.085830 --> 0.085665).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841183\n",
      "\tspeed: 0.0388s/iter; left time: 748.0326s\n",
      "\titers: 200, epoch: 14 | loss: 0.0859597\n",
      "\tspeed: 0.0182s/iter; left time: 350.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0852342 Vali Loss: 0.0856685 Test Loss: 0.1136733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842968\n",
      "\tspeed: 0.0398s/iter; left time: 760.1188s\n",
      "\titers: 200, epoch: 15 | loss: 0.0909677\n",
      "\tspeed: 0.0195s/iter; left time: 370.2253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0852555 Vali Loss: 0.0855243 Test Loss: 0.1138341\n",
      "Validation loss decreased (0.085665 --> 0.085524).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0852345\n",
      "\tspeed: 0.0411s/iter; left time: 775.2726s\n",
      "\titers: 200, epoch: 16 | loss: 0.0851248\n",
      "\tspeed: 0.0200s/iter; left time: 375.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0847901 Vali Loss: 0.0851691 Test Loss: 0.1139723\n",
      "Validation loss decreased (0.085524 --> 0.085169).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0839362\n",
      "\tspeed: 0.0413s/iter; left time: 768.8718s\n",
      "\titers: 200, epoch: 17 | loss: 0.0833548\n",
      "\tspeed: 0.0181s/iter; left time: 334.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0845173 Vali Loss: 0.0850614 Test Loss: 0.1140275\n",
      "Validation loss decreased (0.085169 --> 0.085061).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0813416\n",
      "\tspeed: 0.0378s/iter; left time: 695.3286s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866940\n",
      "\tspeed: 0.0176s/iter; left time: 322.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0843307 Vali Loss: 0.0847981 Test Loss: 0.1144203\n",
      "Validation loss decreased (0.085061 --> 0.084798).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0843313\n",
      "\tspeed: 0.0429s/iter; left time: 779.3747s\n",
      "\titers: 200, epoch: 19 | loss: 0.0832647\n",
      "\tspeed: 0.0194s/iter; left time: 349.9905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0842799 Vali Loss: 0.0846771 Test Loss: 0.1141960\n",
      "Validation loss decreased (0.084798 --> 0.084677).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0862335\n",
      "\tspeed: 0.0393s/iter; left time: 706.1303s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817612\n",
      "\tspeed: 0.0180s/iter; left time: 321.6322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0838804 Vali Loss: 0.0843563 Test Loss: 0.1145415\n",
      "Validation loss decreased (0.084677 --> 0.084356).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0837195\n",
      "\tspeed: 0.0380s/iter; left time: 674.5413s\n",
      "\titers: 200, epoch: 21 | loss: 0.1031141\n",
      "\tspeed: 0.0176s/iter; left time: 310.9999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0839049 Vali Loss: 0.0849667 Test Loss: 0.1150237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0836587\n",
      "\tspeed: 0.0372s/iter; left time: 651.5937s\n",
      "\titers: 200, epoch: 22 | loss: 0.0852197\n",
      "\tspeed: 0.0206s/iter; left time: 358.8810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0837684 Vali Loss: 0.0846416 Test Loss: 0.1158141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0795333\n",
      "\tspeed: 0.0416s/iter; left time: 719.3145s\n",
      "\titers: 200, epoch: 23 | loss: 0.0865810\n",
      "\tspeed: 0.0195s/iter; left time: 335.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0835962 Vali Loss: 0.0847980 Test Loss: 0.1160617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0831024\n",
      "\tspeed: 0.0409s/iter; left time: 698.0340s\n",
      "\titers: 200, epoch: 24 | loss: 0.0805572\n",
      "\tspeed: 0.0177s/iter; left time: 300.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0839736 Vali Loss: 0.0847975 Test Loss: 0.1165650\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0849554\n",
      "\tspeed: 0.0380s/iter; left time: 639.5161s\n",
      "\titers: 200, epoch: 25 | loss: 0.0840587\n",
      "\tspeed: 0.0176s/iter; left time: 294.8000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0834544 Vali Loss: 0.0845328 Test Loss: 0.1162506\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0892217\n",
      "\tspeed: 0.0388s/iter; left time: 644.8478s\n",
      "\titers: 200, epoch: 26 | loss: 0.0807220\n",
      "\tspeed: 0.0211s/iter; left time: 348.0118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0833992 Vali Loss: 0.0846728 Test Loss: 0.1164240\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810502\n",
      "\tspeed: 0.0372s/iter; left time: 610.3947s\n",
      "\titers: 200, epoch: 27 | loss: 0.0854318\n",
      "\tspeed: 0.0209s/iter; left time: 341.3486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0833067 Vali Loss: 0.0845248 Test Loss: 0.1158283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0797867\n",
      "\tspeed: 0.0376s/iter; left time: 607.8944s\n",
      "\titers: 200, epoch: 28 | loss: 0.0819262\n",
      "\tspeed: 0.0176s/iter; left time: 282.4657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0833002 Vali Loss: 0.0843592 Test Loss: 0.1163825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0846014\n",
      "\tspeed: 0.0383s/iter; left time: 610.5661s\n",
      "\titers: 200, epoch: 29 | loss: 0.0876969\n",
      "\tspeed: 0.0184s/iter; left time: 291.4180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0833116 Vali Loss: 0.0845298 Test Loss: 0.1166252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0819796\n",
      "\tspeed: 0.0379s/iter; left time: 597.0009s\n",
      "\titers: 200, epoch: 30 | loss: 0.0857283\n",
      "\tspeed: 0.0178s/iter; left time: 278.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0831343 Vali Loss: 0.0845026 Test Loss: 0.1163839\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0290948748588562, rmse:0.1705721914768219, mae:0.11454156041145325, rse:0.5011257529258728\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2807395\n",
      "\tspeed: 0.0203s/iter; left time: 450.8486s\n",
      "\titers: 200, epoch: 1 | loss: 0.2651633\n",
      "\tspeed: 0.0179s/iter; left time: 395.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.2830992 Vali Loss: 0.2142654 Test Loss: 0.2370222\n",
      "Validation loss decreased (inf --> 0.214265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453094\n",
      "\tspeed: 0.0386s/iter; left time: 847.3696s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242578\n",
      "\tspeed: 0.0177s/iter; left time: 386.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1572299 Vali Loss: 0.1083790 Test Loss: 0.1231012\n",
      "Validation loss decreased (0.214265 --> 0.108379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1133961\n",
      "\tspeed: 0.0401s/iter; left time: 871.8265s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982893\n",
      "\tspeed: 0.0177s/iter; left time: 382.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.1100277 Vali Loss: 0.0972046 Test Loss: 0.1224924\n",
      "Validation loss decreased (0.108379 --> 0.097205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974868\n",
      "\tspeed: 0.0390s/iter; left time: 840.0239s\n",
      "\titers: 200, epoch: 4 | loss: 0.0972847\n",
      "\tspeed: 0.0176s/iter; left time: 377.0333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0984315 Vali Loss: 0.0914870 Test Loss: 0.1193569\n",
      "Validation loss decreased (0.097205 --> 0.091487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0947529\n",
      "\tspeed: 0.0387s/iter; left time: 824.6876s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937127\n",
      "\tspeed: 0.0222s/iter; left time: 471.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0946569 Vali Loss: 0.0894347 Test Loss: 0.1191490\n",
      "Validation loss decreased (0.091487 --> 0.089435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918505\n",
      "\tspeed: 0.0398s/iter; left time: 840.0801s\n",
      "\titers: 200, epoch: 6 | loss: 0.0901247\n",
      "\tspeed: 0.0193s/iter; left time: 404.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0917058 Vali Loss: 0.0881212 Test Loss: 0.1236080\n",
      "Validation loss decreased (0.089435 --> 0.088121).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917704\n",
      "\tspeed: 0.0433s/iter; left time: 903.8441s\n",
      "\titers: 200, epoch: 7 | loss: 0.0922219\n",
      "\tspeed: 0.0191s/iter; left time: 396.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0899804 Vali Loss: 0.0864551 Test Loss: 0.1166708\n",
      "Validation loss decreased (0.088121 --> 0.086455).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0917562\n",
      "\tspeed: 0.0384s/iter; left time: 792.5316s\n",
      "\titers: 200, epoch: 8 | loss: 0.0877953\n",
      "\tspeed: 0.0183s/iter; left time: 375.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0890128 Vali Loss: 0.0861659 Test Loss: 0.1123231\n",
      "Validation loss decreased (0.086455 --> 0.086166).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919937\n",
      "\tspeed: 0.0438s/iter; left time: 894.8178s\n",
      "\titers: 200, epoch: 9 | loss: 0.0899467\n",
      "\tspeed: 0.0192s/iter; left time: 390.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0910410 Vali Loss: 0.0899233 Test Loss: 0.1119124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0895764\n",
      "\tspeed: 0.0384s/iter; left time: 774.9918s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906453\n",
      "\tspeed: 0.0176s/iter; left time: 354.5463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0887168 Vali Loss: 0.0859634 Test Loss: 0.1185711\n",
      "Validation loss decreased (0.086166 --> 0.085963).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0892631\n",
      "\tspeed: 0.0399s/iter; left time: 796.3830s\n",
      "\titers: 200, epoch: 11 | loss: 0.0895315\n",
      "\tspeed: 0.0190s/iter; left time: 377.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0871117 Vali Loss: 0.0853329 Test Loss: 0.1164193\n",
      "Validation loss decreased (0.085963 --> 0.085333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0869905\n",
      "\tspeed: 0.0397s/iter; left time: 784.2642s\n",
      "\titers: 200, epoch: 12 | loss: 0.0848289\n",
      "\tspeed: 0.0177s/iter; left time: 347.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0865530 Vali Loss: 0.0852942 Test Loss: 0.1179176\n",
      "Validation loss decreased (0.085333 --> 0.085294).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0864150\n",
      "\tspeed: 0.0393s/iter; left time: 767.6902s\n",
      "\titers: 200, epoch: 13 | loss: 0.0838847\n",
      "\tspeed: 0.0177s/iter; left time: 344.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0862789 Vali Loss: 0.0850571 Test Loss: 0.1164684\n",
      "Validation loss decreased (0.085294 --> 0.085057).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0867992\n",
      "\tspeed: 0.0396s/iter; left time: 764.5853s\n",
      "\titers: 200, epoch: 14 | loss: 0.0845527\n",
      "\tspeed: 0.0177s/iter; left time: 339.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0858124 Vali Loss: 0.0850595 Test Loss: 0.1153065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0845146\n",
      "\tspeed: 0.0444s/iter; left time: 847.3245s\n",
      "\titers: 200, epoch: 15 | loss: 0.0846549\n",
      "\tspeed: 0.0201s/iter; left time: 381.9025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0856219 Vali Loss: 0.0849426 Test Loss: 0.1166757\n",
      "Validation loss decreased (0.085057 --> 0.084943).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0845102\n",
      "\tspeed: 0.0405s/iter; left time: 764.5244s\n",
      "\titers: 200, epoch: 16 | loss: 0.0888782\n",
      "\tspeed: 0.0179s/iter; left time: 335.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0858942 Vali Loss: 0.0853336 Test Loss: 0.1119651\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0912922\n",
      "\tspeed: 0.0399s/iter; left time: 742.7110s\n",
      "\titers: 200, epoch: 17 | loss: 0.0889382\n",
      "\tspeed: 0.0177s/iter; left time: 328.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0856840 Vali Loss: 0.0851839 Test Loss: 0.1192388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0845657\n",
      "\tspeed: 0.0412s/iter; left time: 758.4120s\n",
      "\titers: 200, epoch: 18 | loss: 0.0815924\n",
      "\tspeed: 0.0202s/iter; left time: 369.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0849107 Vali Loss: 0.0853217 Test Loss: 0.1206380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0849029\n",
      "\tspeed: 0.0443s/iter; left time: 805.2851s\n",
      "\titers: 200, epoch: 19 | loss: 0.0853960\n",
      "\tspeed: 0.0178s/iter; left time: 322.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0848261 Vali Loss: 0.0846747 Test Loss: 0.1192671\n",
      "Validation loss decreased (0.084943 --> 0.084675).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811674\n",
      "\tspeed: 0.0393s/iter; left time: 705.1242s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817534\n",
      "\tspeed: 0.0178s/iter; left time: 318.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0845942 Vali Loss: 0.0847365 Test Loss: 0.1183660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0826207\n",
      "\tspeed: 0.0443s/iter; left time: 786.5047s\n",
      "\titers: 200, epoch: 21 | loss: 0.0816803\n",
      "\tspeed: 0.0214s/iter; left time: 377.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0843873 Vali Loss: 0.0846548 Test Loss: 0.1183502\n",
      "Validation loss decreased (0.084675 --> 0.084655).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834691\n",
      "\tspeed: 0.0410s/iter; left time: 717.6705s\n",
      "\titers: 200, epoch: 22 | loss: 0.0883418\n",
      "\tspeed: 0.0179s/iter; left time: 312.5777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0843994 Vali Loss: 0.0845420 Test Loss: 0.1178532\n",
      "Validation loss decreased (0.084655 --> 0.084542).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0847441\n",
      "\tspeed: 0.0397s/iter; left time: 686.2741s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805724\n",
      "\tspeed: 0.0176s/iter; left time: 303.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0841674 Vali Loss: 0.0844933 Test Loss: 0.1170921\n",
      "Validation loss decreased (0.084542 --> 0.084493).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0839649\n",
      "\tspeed: 0.0396s/iter; left time: 676.2839s\n",
      "\titers: 200, epoch: 24 | loss: 0.0834868\n",
      "\tspeed: 0.0178s/iter; left time: 301.6561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0841976 Vali Loss: 0.0846161 Test Loss: 0.1172125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0881067\n",
      "\tspeed: 0.0391s/iter; left time: 658.7945s\n",
      "\titers: 200, epoch: 25 | loss: 0.0828818\n",
      "\tspeed: 0.0178s/iter; left time: 297.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0841515 Vali Loss: 0.0843772 Test Loss: 0.1175339\n",
      "Validation loss decreased (0.084493 --> 0.084377).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0825793\n",
      "\tspeed: 0.0403s/iter; left time: 670.3831s\n",
      "\titers: 200, epoch: 26 | loss: 0.0856509\n",
      "\tspeed: 0.0180s/iter; left time: 296.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0842238 Vali Loss: 0.0844084 Test Loss: 0.1173107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819396\n",
      "\tspeed: 0.0404s/iter; left time: 661.9741s\n",
      "\titers: 200, epoch: 27 | loss: 0.0869512\n",
      "\tspeed: 0.0193s/iter; left time: 313.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0840297 Vali Loss: 0.0846008 Test Loss: 0.1175796\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0859564\n",
      "\tspeed: 0.0400s/iter; left time: 647.4605s\n",
      "\titers: 200, epoch: 28 | loss: 0.0873584\n",
      "\tspeed: 0.0176s/iter; left time: 283.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0837992 Vali Loss: 0.0845674 Test Loss: 0.1199782\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0821546\n",
      "\tspeed: 0.0394s/iter; left time: 628.3312s\n",
      "\titers: 200, epoch: 29 | loss: 0.0846214\n",
      "\tspeed: 0.0176s/iter; left time: 278.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0837742 Vali Loss: 0.0844055 Test Loss: 0.1191112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0844201\n",
      "\tspeed: 0.0392s/iter; left time: 616.1672s\n",
      "\titers: 200, epoch: 30 | loss: 0.0841895\n",
      "\tspeed: 0.0176s/iter; left time: 275.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0837221 Vali Loss: 0.0842772 Test Loss: 0.1190496\n",
      "Validation loss decreased (0.084377 --> 0.084277).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0870948\n",
      "\tspeed: 0.0390s/iter; left time: 604.7622s\n",
      "\titers: 200, epoch: 31 | loss: 0.0821873\n",
      "\tspeed: 0.0176s/iter; left time: 270.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0836353 Vali Loss: 0.0842929 Test Loss: 0.1206920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0848337\n",
      "\tspeed: 0.0402s/iter; left time: 614.4786s\n",
      "\titers: 200, epoch: 32 | loss: 0.0830336\n",
      "\tspeed: 0.0208s/iter; left time: 315.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0837642 Vali Loss: 0.0842275 Test Loss: 0.1182323\n",
      "Validation loss decreased (0.084277 --> 0.084228).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0846711\n",
      "\tspeed: 0.0411s/iter; left time: 619.1505s\n",
      "\titers: 200, epoch: 33 | loss: 0.0801985\n",
      "\tspeed: 0.0181s/iter; left time: 270.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0836584 Vali Loss: 0.0844522 Test Loss: 0.1194240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836901\n",
      "\tspeed: 0.0406s/iter; left time: 602.9054s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838794\n",
      "\tspeed: 0.0177s/iter; left time: 261.5917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0836737 Vali Loss: 0.0843503 Test Loss: 0.1194371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0843293\n",
      "\tspeed: 0.0386s/iter; left time: 564.5556s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848211\n",
      "\tspeed: 0.0177s/iter; left time: 257.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0835618 Vali Loss: 0.0844821 Test Loss: 0.1200642\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0810826\n",
      "\tspeed: 0.0378s/iter; left time: 544.4553s\n",
      "\titers: 200, epoch: 36 | loss: 0.0852567\n",
      "\tspeed: 0.0176s/iter; left time: 251.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0838000 Vali Loss: 0.0845061 Test Loss: 0.1194763\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803306\n",
      "\tspeed: 0.0385s/iter; left time: 545.4165s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833322\n",
      "\tspeed: 0.0176s/iter; left time: 247.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0835411 Vali Loss: 0.0843955 Test Loss: 0.1186716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0823816\n",
      "\tspeed: 0.0390s/iter; left time: 544.7125s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843670\n",
      "\tspeed: 0.0183s/iter; left time: 253.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0834298 Vali Loss: 0.0843624 Test Loss: 0.1192587\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0864377\n",
      "\tspeed: 0.0414s/iter; left time: 568.6201s\n",
      "\titers: 200, epoch: 39 | loss: 0.0857570\n",
      "\tspeed: 0.0189s/iter; left time: 256.9373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0836104 Vali Loss: 0.0843764 Test Loss: 0.1198429\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0814850\n",
      "\tspeed: 0.0386s/iter; left time: 521.7193s\n",
      "\titers: 200, epoch: 40 | loss: 0.0841378\n",
      "\tspeed: 0.0182s/iter; left time: 243.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0839965 Vali Loss: 0.0844893 Test Loss: 0.1194120\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799215\n",
      "\tspeed: 0.0399s/iter; left time: 530.0786s\n",
      "\titers: 200, epoch: 41 | loss: 0.0783022\n",
      "\tspeed: 0.0179s/iter; left time: 235.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0834080 Vali Loss: 0.0841839 Test Loss: 0.1189149\n",
      "Validation loss decreased (0.084228 --> 0.084184).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0835249\n",
      "\tspeed: 0.0396s/iter; left time: 517.6016s\n",
      "\titers: 200, epoch: 42 | loss: 0.0811903\n",
      "\tspeed: 0.0177s/iter; left time: 228.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0834037 Vali Loss: 0.0844404 Test Loss: 0.1207593\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0831517\n",
      "\tspeed: 0.0390s/iter; left time: 500.6978s\n",
      "\titers: 200, epoch: 43 | loss: 0.0815078\n",
      "\tspeed: 0.0176s/iter; left time: 224.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0834141 Vali Loss: 0.0845041 Test Loss: 0.1203174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0865642\n",
      "\tspeed: 0.0387s/iter; left time: 487.8656s\n",
      "\titers: 200, epoch: 44 | loss: 0.0847886\n",
      "\tspeed: 0.0178s/iter; left time: 222.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0835477 Vali Loss: 0.0844085 Test Loss: 0.1198660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0788437\n",
      "\tspeed: 0.0382s/iter; left time: 472.8884s\n",
      "\titers: 200, epoch: 45 | loss: 0.0816742\n",
      "\tspeed: 0.0176s/iter; left time: 216.6890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0834426 Vali Loss: 0.0842027 Test Loss: 0.1195737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830794\n",
      "\tspeed: 0.0399s/iter; left time: 485.2382s\n",
      "\titers: 200, epoch: 46 | loss: 0.0839437\n",
      "\tspeed: 0.0176s/iter; left time: 212.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0833704 Vali Loss: 0.0842480 Test Loss: 0.1193747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0823590\n",
      "\tspeed: 0.0386s/iter; left time: 461.1781s\n",
      "\titers: 200, epoch: 47 | loss: 0.0856680\n",
      "\tspeed: 0.0176s/iter; left time: 208.9305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0832862 Vali Loss: 0.0841228 Test Loss: 0.1197550\n",
      "Validation loss decreased (0.084184 --> 0.084123).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0883429\n",
      "\tspeed: 0.0453s/iter; left time: 530.7049s\n",
      "\titers: 200, epoch: 48 | loss: 0.0826623\n",
      "\tspeed: 0.0187s/iter; left time: 217.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0833737 Vali Loss: 0.0842797 Test Loss: 0.1200274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0815217\n",
      "\tspeed: 0.0405s/iter; left time: 465.1589s\n",
      "\titers: 200, epoch: 49 | loss: 0.0848437\n",
      "\tspeed: 0.0208s/iter; left time: 237.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0833760 Vali Loss: 0.0841590 Test Loss: 0.1200445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0827644\n",
      "\tspeed: 0.0400s/iter; left time: 451.0382s\n",
      "\titers: 200, epoch: 50 | loss: 0.0767582\n",
      "\tspeed: 0.0185s/iter; left time: 206.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0832877 Vali Loss: 0.0839660 Test Loss: 0.1184397\n",
      "Validation loss decreased (0.084123 --> 0.083966).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0835075\n",
      "\tspeed: 0.0434s/iter; left time: 480.0762s\n",
      "\titers: 200, epoch: 51 | loss: 0.0817596\n",
      "\tspeed: 0.0180s/iter; left time: 197.4372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0832505 Vali Loss: 0.0842132 Test Loss: 0.1197245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0808008\n",
      "\tspeed: 0.0384s/iter; left time: 416.1238s\n",
      "\titers: 200, epoch: 52 | loss: 0.0849158\n",
      "\tspeed: 0.0178s/iter; left time: 190.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0834962 Vali Loss: 0.0841127 Test Loss: 0.1192776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800299\n",
      "\tspeed: 0.0389s/iter; left time: 412.1408s\n",
      "\titers: 200, epoch: 53 | loss: 0.0820698\n",
      "\tspeed: 0.0177s/iter; left time: 185.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0832694 Vali Loss: 0.0842121 Test Loss: 0.1194684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802618\n",
      "\tspeed: 0.0386s/iter; left time: 400.3582s\n",
      "\titers: 200, epoch: 54 | loss: 0.0827059\n",
      "\tspeed: 0.0185s/iter; left time: 190.4180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0833176 Vali Loss: 0.0842278 Test Loss: 0.1203044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0861164\n",
      "\tspeed: 0.0390s/iter; left time: 396.3525s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852268\n",
      "\tspeed: 0.0176s/iter; left time: 177.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0833072 Vali Loss: 0.0842820 Test Loss: 0.1206407\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0806998\n",
      "\tspeed: 0.0392s/iter; left time: 389.7057s\n",
      "\titers: 200, epoch: 56 | loss: 0.0823214\n",
      "\tspeed: 0.0177s/iter; left time: 174.2658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0834395 Vali Loss: 0.0842447 Test Loss: 0.1202066\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0837483\n",
      "\tspeed: 0.0389s/iter; left time: 378.1445s\n",
      "\titers: 200, epoch: 57 | loss: 0.0801571\n",
      "\tspeed: 0.0178s/iter; left time: 171.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0833268 Vali Loss: 0.0842674 Test Loss: 0.1203132\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0821808\n",
      "\tspeed: 0.0387s/iter; left time: 367.6385s\n",
      "\titers: 200, epoch: 58 | loss: 0.0829196\n",
      "\tspeed: 0.0177s/iter; left time: 166.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0832269 Vali Loss: 0.0843088 Test Loss: 0.1198582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0822175\n",
      "\tspeed: 0.0403s/iter; left time: 373.6472s\n",
      "\titers: 200, epoch: 59 | loss: 0.0831296\n",
      "\tspeed: 0.0176s/iter; left time: 161.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0833064 Vali Loss: 0.0840443 Test Loss: 0.1194816\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0843803\n",
      "\tspeed: 0.0407s/iter; left time: 368.4259s\n",
      "\titers: 200, epoch: 60 | loss: 0.0825238\n",
      "\tspeed: 0.0177s/iter; left time: 158.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0836524 Vali Loss: 0.0842534 Test Loss: 0.1202688\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03208500146865845, rmse:0.17912286520004272, mae:0.1184396892786026, rse:0.5262468457221985\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:56.15s\n",
      "Intermediate time for ES: 00h:29m:52.64s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2189905\n",
      "\tspeed: 0.0447s/iter; left time: 997.8993s\n",
      "\titers: 200, epoch: 1 | loss: 0.2094398\n",
      "\tspeed: 0.0173s/iter; left time: 383.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.2283985 Vali Loss: 0.1756238 Test Loss: 0.1780087\n",
      "Validation loss decreased (inf --> 0.175624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1347274\n",
      "\tspeed: 0.0367s/iter; left time: 810.4678s\n",
      "\titers: 200, epoch: 2 | loss: 0.1058855\n",
      "\tspeed: 0.0173s/iter; left time: 379.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1412683 Vali Loss: 0.0861683 Test Loss: 0.0953128\n",
      "Validation loss decreased (0.175624 --> 0.086168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0858258\n",
      "\tspeed: 0.0366s/iter; left time: 799.0799s\n",
      "\titers: 200, epoch: 3 | loss: 0.0784642\n",
      "\tspeed: 0.0173s/iter; left time: 375.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0877591 Vali Loss: 0.0783186 Test Loss: 0.0834705\n",
      "Validation loss decreased (0.086168 --> 0.078319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0740882\n",
      "\tspeed: 0.0363s/iter; left time: 786.1294s\n",
      "\titers: 200, epoch: 4 | loss: 0.0751335\n",
      "\tspeed: 0.0191s/iter; left time: 411.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0729271 Vali Loss: 0.0701618 Test Loss: 0.0721456\n",
      "Validation loss decreased (0.078319 --> 0.070162).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0732238\n",
      "\tspeed: 0.0365s/iter; left time: 781.9660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0658085\n",
      "\tspeed: 0.0180s/iter; left time: 384.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0662810 Vali Loss: 0.0654406 Test Loss: 0.0673504\n",
      "Validation loss decreased (0.070162 --> 0.065441).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640738\n",
      "\tspeed: 0.0357s/iter; left time: 756.4553s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585620\n",
      "\tspeed: 0.0192s/iter; left time: 405.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0619704 Vali Loss: 0.0635439 Test Loss: 0.0665006\n",
      "Validation loss decreased (0.065441 --> 0.063544).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0728307\n",
      "\tspeed: 0.0392s/iter; left time: 821.9312s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582666\n",
      "\tspeed: 0.0192s/iter; left time: 401.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0588843 Vali Loss: 0.0620328 Test Loss: 0.0647599\n",
      "Validation loss decreased (0.063544 --> 0.062033).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576182\n",
      "\tspeed: 0.0366s/iter; left time: 758.6566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0582239\n",
      "\tspeed: 0.0175s/iter; left time: 361.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0563831 Vali Loss: 0.0620485 Test Loss: 0.0640849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0529686\n",
      "\tspeed: 0.0361s/iter; left time: 739.6494s\n",
      "\titers: 200, epoch: 9 | loss: 0.0567693\n",
      "\tspeed: 0.0172s/iter; left time: 351.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0552574 Vali Loss: 0.0612383 Test Loss: 0.0637068\n",
      "Validation loss decreased (0.062033 --> 0.061238).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0530840\n",
      "\tspeed: 0.0370s/iter; left time: 749.5542s\n",
      "\titers: 200, epoch: 10 | loss: 0.0547498\n",
      "\tspeed: 0.0174s/iter; left time: 351.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0539950 Vali Loss: 0.0601991 Test Loss: 0.0627014\n",
      "Validation loss decreased (0.061238 --> 0.060199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0550270\n",
      "\tspeed: 0.0361s/iter; left time: 723.3991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529360\n",
      "\tspeed: 0.0175s/iter; left time: 348.7186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0536804 Vali Loss: 0.0596398 Test Loss: 0.0623860\n",
      "Validation loss decreased (0.060199 --> 0.059640).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0509884\n",
      "\tspeed: 0.0367s/iter; left time: 727.4579s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549822\n",
      "\tspeed: 0.0182s/iter; left time: 359.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0531124 Vali Loss: 0.0593827 Test Loss: 0.0619096\n",
      "Validation loss decreased (0.059640 --> 0.059383).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0497535\n",
      "\tspeed: 0.0378s/iter; left time: 740.5790s\n",
      "\titers: 200, epoch: 13 | loss: 0.0497219\n",
      "\tspeed: 0.0173s/iter; left time: 337.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0523422 Vali Loss: 0.0598866 Test Loss: 0.0626116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0506681\n",
      "\tspeed: 0.0383s/iter; left time: 741.8863s\n",
      "\titers: 200, epoch: 14 | loss: 0.0503455\n",
      "\tspeed: 0.0177s/iter; left time: 341.0834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0518808 Vali Loss: 0.0589341 Test Loss: 0.0617417\n",
      "Validation loss decreased (0.059383 --> 0.058934).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0516162\n",
      "\tspeed: 0.0365s/iter; left time: 699.9821s\n",
      "\titers: 200, epoch: 15 | loss: 0.0477661\n",
      "\tspeed: 0.0180s/iter; left time: 343.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0518157 Vali Loss: 0.0586784 Test Loss: 0.0613603\n",
      "Validation loss decreased (0.058934 --> 0.058678).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0483342\n",
      "\tspeed: 0.0360s/iter; left time: 681.1734s\n",
      "\titers: 200, epoch: 16 | loss: 0.0493364\n",
      "\tspeed: 0.0173s/iter; left time: 326.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0512816 Vali Loss: 0.0602284 Test Loss: 0.0628952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0539204\n",
      "\tspeed: 0.0401s/iter; left time: 749.9528s\n",
      "\titers: 200, epoch: 17 | loss: 0.0494316\n",
      "\tspeed: 0.0190s/iter; left time: 354.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0510176 Vali Loss: 0.0584819 Test Loss: 0.0611233\n",
      "Validation loss decreased (0.058678 --> 0.058482).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0500257\n",
      "\tspeed: 0.0361s/iter; left time: 668.3985s\n",
      "\titers: 200, epoch: 18 | loss: 0.0504019\n",
      "\tspeed: 0.0210s/iter; left time: 387.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0508184 Vali Loss: 0.0582690 Test Loss: 0.0609066\n",
      "Validation loss decreased (0.058482 --> 0.058269).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0475260\n",
      "\tspeed: 0.0372s/iter; left time: 679.7461s\n",
      "\titers: 200, epoch: 19 | loss: 0.0503758\n",
      "\tspeed: 0.0175s/iter; left time: 317.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0506279 Vali Loss: 0.0581391 Test Loss: 0.0607202\n",
      "Validation loss decreased (0.058269 --> 0.058139).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0505285\n",
      "\tspeed: 0.0379s/iter; left time: 684.7220s\n",
      "\titers: 200, epoch: 20 | loss: 0.0497725\n",
      "\tspeed: 0.0175s/iter; left time: 313.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0506970 Vali Loss: 0.0583651 Test Loss: 0.0609205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0512311\n",
      "\tspeed: 0.0356s/iter; left time: 634.2959s\n",
      "\titers: 200, epoch: 21 | loss: 0.0495510\n",
      "\tspeed: 0.0174s/iter; left time: 308.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0501595 Vali Loss: 0.0580995 Test Loss: 0.0606243\n",
      "Validation loss decreased (0.058139 --> 0.058099).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0473480\n",
      "\tspeed: 0.0359s/iter; left time: 632.5131s\n",
      "\titers: 200, epoch: 22 | loss: 0.0477828\n",
      "\tspeed: 0.0175s/iter; left time: 305.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0504072 Vali Loss: 0.0587346 Test Loss: 0.0612521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0500846\n",
      "\tspeed: 0.0360s/iter; left time: 624.9034s\n",
      "\titers: 200, epoch: 23 | loss: 0.0525214\n",
      "\tspeed: 0.0179s/iter; left time: 309.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0504408 Vali Loss: 0.0579735 Test Loss: 0.0607307\n",
      "Validation loss decreased (0.058099 --> 0.057974).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0480558\n",
      "\tspeed: 0.0354s/iter; left time: 607.1094s\n",
      "\titers: 200, epoch: 24 | loss: 0.0507211\n",
      "\tspeed: 0.0173s/iter; left time: 295.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0502628 Vali Loss: 0.0580043 Test Loss: 0.0605459\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0504762\n",
      "\tspeed: 0.0385s/iter; left time: 652.3293s\n",
      "\titers: 200, epoch: 25 | loss: 0.0537197\n",
      "\tspeed: 0.0182s/iter; left time: 305.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0498962 Vali Loss: 0.0578188 Test Loss: 0.0603671\n",
      "Validation loss decreased (0.057974 --> 0.057819).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0486984\n",
      "\tspeed: 0.0365s/iter; left time: 608.8245s\n",
      "\titers: 200, epoch: 26 | loss: 0.0455609\n",
      "\tspeed: 0.0188s/iter; left time: 312.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0503198 Vali Loss: 0.0577315 Test Loss: 0.0603220\n",
      "Validation loss decreased (0.057819 --> 0.057732).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0486343\n",
      "\tspeed: 0.0401s/iter; left time: 660.7798s\n",
      "\titers: 200, epoch: 27 | loss: 0.0508078\n",
      "\tspeed: 0.0214s/iter; left time: 350.9652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0495923 Vali Loss: 0.0578376 Test Loss: 0.0603566\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0503271\n",
      "\tspeed: 0.0386s/iter; left time: 626.8296s\n",
      "\titers: 200, epoch: 28 | loss: 0.0459004\n",
      "\tspeed: 0.0200s/iter; left time: 323.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0495713 Vali Loss: 0.0577886 Test Loss: 0.0602553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0524027\n",
      "\tspeed: 0.0393s/iter; left time: 630.0518s\n",
      "\titers: 200, epoch: 29 | loss: 0.0464738\n",
      "\tspeed: 0.0190s/iter; left time: 302.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0498332 Vali Loss: 0.0576925 Test Loss: 0.0602051\n",
      "Validation loss decreased (0.057732 --> 0.057692).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516865\n",
      "\tspeed: 0.0374s/iter; left time: 590.6686s\n",
      "\titers: 200, epoch: 30 | loss: 0.0477378\n",
      "\tspeed: 0.0174s/iter; left time: 273.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0494292 Vali Loss: 0.0579241 Test Loss: 0.0604471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0495388\n",
      "\tspeed: 0.0361s/iter; left time: 562.1820s\n",
      "\titers: 200, epoch: 31 | loss: 0.0503760\n",
      "\tspeed: 0.0183s/iter; left time: 283.9992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0496792 Vali Loss: 0.0575059 Test Loss: 0.0599858\n",
      "Validation loss decreased (0.057692 --> 0.057506).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0482864\n",
      "\tspeed: 0.0424s/iter; left time: 650.5668s\n",
      "\titers: 200, epoch: 32 | loss: 0.0502361\n",
      "\tspeed: 0.0208s/iter; left time: 316.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0494227 Vali Loss: 0.0574768 Test Loss: 0.0599407\n",
      "Validation loss decreased (0.057506 --> 0.057477).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0517188\n",
      "\tspeed: 0.0425s/iter; left time: 643.2173s\n",
      "\titers: 200, epoch: 33 | loss: 0.0492935\n",
      "\tspeed: 0.0172s/iter; left time: 259.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0496386 Vali Loss: 0.0577618 Test Loss: 0.0601959\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0497171\n",
      "\tspeed: 0.0375s/iter; left time: 558.5965s\n",
      "\titers: 200, epoch: 34 | loss: 0.1120931\n",
      "\tspeed: 0.0193s/iter; left time: 285.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0495713 Vali Loss: 0.0575163 Test Loss: 0.0601913\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0492985\n",
      "\tspeed: 0.0381s/iter; left time: 559.5225s\n",
      "\titers: 200, epoch: 35 | loss: 0.0487842\n",
      "\tspeed: 0.0187s/iter; left time: 273.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0493602 Vali Loss: 0.0576364 Test Loss: 0.0601227\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0468738\n",
      "\tspeed: 0.0378s/iter; left time: 547.0831s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486434\n",
      "\tspeed: 0.0172s/iter; left time: 247.1983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0493726 Vali Loss: 0.0575348 Test Loss: 0.0600171\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0508832\n",
      "\tspeed: 0.0357s/iter; left time: 508.4945s\n",
      "\titers: 200, epoch: 37 | loss: 0.0465933\n",
      "\tspeed: 0.0172s/iter; left time: 243.6972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0493064 Vali Loss: 0.0574129 Test Loss: 0.0599025\n",
      "Validation loss decreased (0.057477 --> 0.057413).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0512414\n",
      "\tspeed: 0.0373s/iter; left time: 523.0214s\n",
      "\titers: 200, epoch: 38 | loss: 0.0495993\n",
      "\tspeed: 0.0172s/iter; left time: 239.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0496147 Vali Loss: 0.0575160 Test Loss: 0.0600982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0481962\n",
      "\tspeed: 0.0380s/iter; left time: 524.0205s\n",
      "\titers: 200, epoch: 39 | loss: 0.0456776\n",
      "\tspeed: 0.0209s/iter; left time: 285.5316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0493605 Vali Loss: 0.0575157 Test Loss: 0.0600691\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0459758\n",
      "\tspeed: 0.0361s/iter; left time: 489.3920s\n",
      "\titers: 200, epoch: 40 | loss: 0.0505996\n",
      "\tspeed: 0.0174s/iter; left time: 234.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0492454 Vali Loss: 0.0574911 Test Loss: 0.0600893\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0497500\n",
      "\tspeed: 0.0409s/iter; left time: 545.8449s\n",
      "\titers: 200, epoch: 41 | loss: 0.0457567\n",
      "\tspeed: 0.0219s/iter; left time: 290.0590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0492883 Vali Loss: 0.0575777 Test Loss: 0.0600463\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0492255\n",
      "\tspeed: 0.0421s/iter; left time: 551.7524s\n",
      "\titers: 200, epoch: 42 | loss: 0.0519431\n",
      "\tspeed: 0.0221s/iter; left time: 287.4615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0492720 Vali Loss: 0.0573690 Test Loss: 0.0599045\n",
      "Validation loss decreased (0.057413 --> 0.057369).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0481818\n",
      "\tspeed: 0.0395s/iter; left time: 509.2732s\n",
      "\titers: 200, epoch: 43 | loss: 0.0480127\n",
      "\tspeed: 0.0173s/iter; left time: 220.9924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0491732 Vali Loss: 0.0574247 Test Loss: 0.0599618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0485913\n",
      "\tspeed: 0.0354s/iter; left time: 448.8938s\n",
      "\titers: 200, epoch: 44 | loss: 0.0524267\n",
      "\tspeed: 0.0172s/iter; left time: 216.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0491129 Vali Loss: 0.0573343 Test Loss: 0.0597940\n",
      "Validation loss decreased (0.057369 --> 0.057334).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0492738\n",
      "\tspeed: 0.0379s/iter; left time: 471.7080s\n",
      "\titers: 200, epoch: 45 | loss: 0.0507723\n",
      "\tspeed: 0.0185s/iter; left time: 228.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0493416 Vali Loss: 0.0573820 Test Loss: 0.0598268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0466329\n",
      "\tspeed: 0.0359s/iter; left time: 438.6723s\n",
      "\titers: 200, epoch: 46 | loss: 0.0478777\n",
      "\tspeed: 0.0174s/iter; left time: 210.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0491535 Vali Loss: 0.0577590 Test Loss: 0.0602383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0475169\n",
      "\tspeed: 0.0360s/iter; left time: 431.9920s\n",
      "\titers: 200, epoch: 47 | loss: 0.0476974\n",
      "\tspeed: 0.0174s/iter; left time: 207.1603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0492178 Vali Loss: 0.0573777 Test Loss: 0.0598855\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0472250\n",
      "\tspeed: 0.0355s/iter; left time: 417.9496s\n",
      "\titers: 200, epoch: 48 | loss: 0.0502291\n",
      "\tspeed: 0.0175s/iter; left time: 203.9946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0496917 Vali Loss: 0.0574500 Test Loss: 0.0599635\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0496751\n",
      "\tspeed: 0.0373s/iter; left time: 430.8747s\n",
      "\titers: 200, epoch: 49 | loss: 0.0517711\n",
      "\tspeed: 0.0190s/iter; left time: 218.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0491967 Vali Loss: 0.0574847 Test Loss: 0.0599832\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0506651\n",
      "\tspeed: 0.0395s/iter; left time: 447.4884s\n",
      "\titers: 200, epoch: 50 | loss: 0.0472021\n",
      "\tspeed: 0.0217s/iter; left time: 243.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0491663 Vali Loss: 0.0576522 Test Loss: 0.0602551\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0474933\n",
      "\tspeed: 0.0439s/iter; left time: 487.1982s\n",
      "\titers: 200, epoch: 51 | loss: 0.0453514\n",
      "\tspeed: 0.0240s/iter; left time: 264.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0491722 Vali Loss: 0.0573052 Test Loss: 0.0598379\n",
      "Validation loss decreased (0.057334 --> 0.057305).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0489133\n",
      "\tspeed: 0.0409s/iter; left time: 444.8613s\n",
      "\titers: 200, epoch: 52 | loss: 0.0550193\n",
      "\tspeed: 0.0174s/iter; left time: 187.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0494006 Vali Loss: 0.0574015 Test Loss: 0.0600319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0497700\n",
      "\tspeed: 0.0360s/iter; left time: 383.0731s\n",
      "\titers: 200, epoch: 53 | loss: 0.0514682\n",
      "\tspeed: 0.0179s/iter; left time: 189.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0492078 Vali Loss: 0.0575005 Test Loss: 0.0599812\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0472670\n",
      "\tspeed: 0.0381s/iter; left time: 397.7214s\n",
      "\titers: 200, epoch: 54 | loss: 0.0458579\n",
      "\tspeed: 0.0172s/iter; left time: 177.7982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0490864 Vali Loss: 0.0575138 Test Loss: 0.0601399\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0475249\n",
      "\tspeed: 0.0398s/iter; left time: 406.4096s\n",
      "\titers: 200, epoch: 55 | loss: 0.0529579\n",
      "\tspeed: 0.0203s/iter; left time: 204.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0491312 Vali Loss: 0.0574530 Test Loss: 0.0599372\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0514820\n",
      "\tspeed: 0.0356s/iter; left time: 355.5929s\n",
      "\titers: 200, epoch: 56 | loss: 0.0481791\n",
      "\tspeed: 0.0172s/iter; left time: 170.2678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0491052 Vali Loss: 0.0574432 Test Loss: 0.0599785\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0493848\n",
      "\tspeed: 0.0401s/iter; left time: 391.7294s\n",
      "\titers: 200, epoch: 57 | loss: 0.0465032\n",
      "\tspeed: 0.0226s/iter; left time: 218.3561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0491957 Vali Loss: 0.0573411 Test Loss: 0.0598234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0511922\n",
      "\tspeed: 0.0386s/iter; left time: 367.5829s\n",
      "\titers: 200, epoch: 58 | loss: 0.0503263\n",
      "\tspeed: 0.0183s/iter; left time: 172.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0490021 Vali Loss: 0.0575003 Test Loss: 0.0599627\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0506980\n",
      "\tspeed: 0.0362s/iter; left time: 337.2117s\n",
      "\titers: 200, epoch: 59 | loss: 0.0491531\n",
      "\tspeed: 0.0176s/iter; left time: 162.0777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0491681 Vali Loss: 0.0573054 Test Loss: 0.0598622\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0476131\n",
      "\tspeed: 0.0360s/iter; left time: 327.3956s\n",
      "\titers: 200, epoch: 60 | loss: 0.0460834\n",
      "\tspeed: 0.0192s/iter; left time: 172.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0491034 Vali Loss: 0.0572696 Test Loss: 0.0598422\n",
      "Validation loss decreased (0.057305 --> 0.057270).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0492449\n",
      "\tspeed: 0.0383s/iter; left time: 338.9422s\n",
      "\titers: 200, epoch: 61 | loss: 0.0475657\n",
      "\tspeed: 0.0209s/iter; left time: 182.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0497441 Vali Loss: 0.0574630 Test Loss: 0.0599516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0489767\n",
      "\tspeed: 0.0378s/iter; left time: 326.1079s\n",
      "\titers: 200, epoch: 62 | loss: 0.0438914\n",
      "\tspeed: 0.0175s/iter; left time: 149.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0491614 Vali Loss: 0.0575841 Test Loss: 0.0600992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0485266\n",
      "\tspeed: 0.0364s/iter; left time: 306.3704s\n",
      "\titers: 200, epoch: 63 | loss: 0.0485745\n",
      "\tspeed: 0.0202s/iter; left time: 167.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0490892 Vali Loss: 0.0574127 Test Loss: 0.0598990\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0500127\n",
      "\tspeed: 0.0385s/iter; left time: 314.9289s\n",
      "\titers: 200, epoch: 64 | loss: 0.0486416\n",
      "\tspeed: 0.0206s/iter; left time: 166.2779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0492301 Vali Loss: 0.0573969 Test Loss: 0.0599315\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0514936\n",
      "\tspeed: 0.0397s/iter; left time: 316.5102s\n",
      "\titers: 200, epoch: 65 | loss: 0.0519952\n",
      "\tspeed: 0.0209s/iter; left time: 164.3907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0490190 Vali Loss: 0.0574190 Test Loss: 0.0599423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0482965\n",
      "\tspeed: 0.0391s/iter; left time: 302.5245s\n",
      "\titers: 200, epoch: 66 | loss: 0.0458699\n",
      "\tspeed: 0.0175s/iter; left time: 133.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0490600 Vali Loss: 0.0575020 Test Loss: 0.0600639\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0507162\n",
      "\tspeed: 0.0361s/iter; left time: 271.7122s\n",
      "\titers: 200, epoch: 67 | loss: 0.0494047\n",
      "\tspeed: 0.0172s/iter; left time: 127.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0491147 Vali Loss: 0.0573377 Test Loss: 0.0598302\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0515755\n",
      "\tspeed: 0.0363s/iter; left time: 265.0690s\n",
      "\titers: 200, epoch: 68 | loss: 0.0506050\n",
      "\tspeed: 0.0175s/iter; left time: 125.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0491012 Vali Loss: 0.0574193 Test Loss: 0.0599533\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0500110\n",
      "\tspeed: 0.0365s/iter; left time: 257.7478s\n",
      "\titers: 200, epoch: 69 | loss: 0.0475658\n",
      "\tspeed: 0.0174s/iter; left time: 121.3719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0490177 Vali Loss: 0.0573800 Test Loss: 0.0600168\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0488470\n",
      "\tspeed: 0.0368s/iter; left time: 251.9017s\n",
      "\titers: 200, epoch: 70 | loss: 0.0483024\n",
      "\tspeed: 0.0202s/iter; left time: 136.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0491240 Vali Loss: 0.0573181 Test Loss: 0.0598424\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010684304870665073, rmse:0.10336491465568542, mae:0.05984216183423996, rse:0.3987789750099182\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2283663\n",
      "\tspeed: 0.0249s/iter; left time: 554.4766s\n",
      "\titers: 200, epoch: 1 | loss: 0.2152799\n",
      "\tspeed: 0.0223s/iter; left time: 495.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.2290822 Vali Loss: 0.1706432 Test Loss: 0.1762997\n",
      "Validation loss decreased (inf --> 0.170643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1328232\n",
      "\tspeed: 0.0410s/iter; left time: 904.7223s\n",
      "\titers: 200, epoch: 2 | loss: 0.0982406\n",
      "\tspeed: 0.0197s/iter; left time: 433.0558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.1371360 Vali Loss: 0.0832083 Test Loss: 0.0899777\n",
      "Validation loss decreased (0.170643 --> 0.083208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0842378\n",
      "\tspeed: 0.0362s/iter; left time: 791.0964s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776716\n",
      "\tspeed: 0.0182s/iter; left time: 396.3139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0840879 Vali Loss: 0.0742344 Test Loss: 0.0786118\n",
      "Validation loss decreased (0.083208 --> 0.074234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0748460\n",
      "\tspeed: 0.0395s/iter; left time: 854.7550s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699650\n",
      "\tspeed: 0.0208s/iter; left time: 446.9618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0715947 Vali Loss: 0.0694890 Test Loss: 0.0728493\n",
      "Validation loss decreased (0.074234 --> 0.069489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635823\n",
      "\tspeed: 0.0374s/iter; left time: 800.1831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0625224\n",
      "\tspeed: 0.0190s/iter; left time: 405.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0642759 Vali Loss: 0.0649201 Test Loss: 0.0670199\n",
      "Validation loss decreased (0.069489 --> 0.064920).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616188\n",
      "\tspeed: 0.0367s/iter; left time: 777.4081s\n",
      "\titers: 200, epoch: 6 | loss: 0.0563325\n",
      "\tspeed: 0.0176s/iter; left time: 370.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0610357 Vali Loss: 0.0635758 Test Loss: 0.0660962\n",
      "Validation loss decreased (0.064920 --> 0.063576).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0604849\n",
      "\tspeed: 0.0377s/iter; left time: 789.2933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595101\n",
      "\tspeed: 0.0172s/iter; left time: 359.1129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0582681 Vali Loss: 0.0630666 Test Loss: 0.0653816\n",
      "Validation loss decreased (0.063576 --> 0.063067).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0534247\n",
      "\tspeed: 0.0357s/iter; left time: 740.8882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0546402\n",
      "\tspeed: 0.0172s/iter; left time: 355.1349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0561636 Vali Loss: 0.0619535 Test Loss: 0.0645303\n",
      "Validation loss decreased (0.063067 --> 0.061954).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0576266\n",
      "\tspeed: 0.0369s/iter; left time: 756.8943s\n",
      "\titers: 200, epoch: 9 | loss: 0.0535413\n",
      "\tspeed: 0.0173s/iter; left time: 353.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0548653 Vali Loss: 0.0609104 Test Loss: 0.0631791\n",
      "Validation loss decreased (0.061954 --> 0.060910).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0540497\n",
      "\tspeed: 0.0391s/iter; left time: 792.7855s\n",
      "\titers: 200, epoch: 10 | loss: 0.0524245\n",
      "\tspeed: 0.0174s/iter; left time: 351.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0538714 Vali Loss: 0.0613841 Test Loss: 0.0634718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0538256\n",
      "\tspeed: 0.0356s/iter; left time: 714.8931s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564994\n",
      "\tspeed: 0.0178s/iter; left time: 354.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0530556 Vali Loss: 0.0599989 Test Loss: 0.0622630\n",
      "Validation loss decreased (0.060910 --> 0.059999).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0528109\n",
      "\tspeed: 0.0360s/iter; left time: 713.2821s\n",
      "\titers: 200, epoch: 12 | loss: 0.0582618\n",
      "\tspeed: 0.0172s/iter; left time: 339.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0527736 Vali Loss: 0.0610509 Test Loss: 0.0630525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496846\n",
      "\tspeed: 0.0361s/iter; left time: 708.1250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0500449\n",
      "\tspeed: 0.0182s/iter; left time: 354.6745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0522214 Vali Loss: 0.0594596 Test Loss: 0.0616471\n",
      "Validation loss decreased (0.059999 --> 0.059460).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0569025\n",
      "\tspeed: 0.0391s/iter; left time: 758.4405s\n",
      "\titers: 200, epoch: 14 | loss: 0.0515646\n",
      "\tspeed: 0.0188s/iter; left time: 361.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0515061 Vali Loss: 0.0588724 Test Loss: 0.0612824\n",
      "Validation loss decreased (0.059460 --> 0.058872).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0528493\n",
      "\tspeed: 0.0402s/iter; left time: 770.6906s\n",
      "\titers: 200, epoch: 15 | loss: 0.0525881\n",
      "\tspeed: 0.0236s/iter; left time: 449.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0512514 Vali Loss: 0.0588800 Test Loss: 0.0610992\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0520019\n",
      "\tspeed: 0.0392s/iter; left time: 742.4410s\n",
      "\titers: 200, epoch: 16 | loss: 0.0495123\n",
      "\tspeed: 0.0195s/iter; left time: 366.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0511952 Vali Loss: 0.0588662 Test Loss: 0.0610870\n",
      "Validation loss decreased (0.058872 --> 0.058866).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0465449\n",
      "\tspeed: 0.0387s/iter; left time: 723.7301s\n",
      "\titers: 200, epoch: 17 | loss: 0.0471932\n",
      "\tspeed: 0.0174s/iter; left time: 323.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0508977 Vali Loss: 0.0585394 Test Loss: 0.0608667\n",
      "Validation loss decreased (0.058866 --> 0.058539).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0489227\n",
      "\tspeed: 0.0397s/iter; left time: 734.0641s\n",
      "\titers: 200, epoch: 18 | loss: 0.0511102\n",
      "\tspeed: 0.0179s/iter; left time: 328.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0506655 Vali Loss: 0.0581182 Test Loss: 0.0605069\n",
      "Validation loss decreased (0.058539 --> 0.058118).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0540787\n",
      "\tspeed: 0.0394s/iter; left time: 719.1443s\n",
      "\titers: 200, epoch: 19 | loss: 0.0497480\n",
      "\tspeed: 0.0211s/iter; left time: 383.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0507588 Vali Loss: 0.0584153 Test Loss: 0.0607866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0504777\n",
      "\tspeed: 0.0360s/iter; left time: 650.3326s\n",
      "\titers: 200, epoch: 20 | loss: 0.0506826\n",
      "\tspeed: 0.0173s/iter; left time: 311.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0506910 Vali Loss: 0.0583143 Test Loss: 0.0605581\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0482379\n",
      "\tspeed: 0.0366s/iter; left time: 651.6398s\n",
      "\titers: 200, epoch: 21 | loss: 0.0489982\n",
      "\tspeed: 0.0172s/iter; left time: 304.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0507082 Vali Loss: 0.0580792 Test Loss: 0.0604281\n",
      "Validation loss decreased (0.058118 --> 0.058079).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0487917\n",
      "\tspeed: 0.0429s/iter; left time: 754.9433s\n",
      "\titers: 200, epoch: 22 | loss: 0.0470085\n",
      "\tspeed: 0.0231s/iter; left time: 403.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0500168 Vali Loss: 0.0580225 Test Loss: 0.0605449\n",
      "Validation loss decreased (0.058079 --> 0.058023).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0590072\n",
      "\tspeed: 0.0378s/iter; left time: 657.0053s\n",
      "\titers: 200, epoch: 23 | loss: 0.0518484\n",
      "\tspeed: 0.0209s/iter; left time: 360.6087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0499528 Vali Loss: 0.0576724 Test Loss: 0.0602709\n",
      "Validation loss decreased (0.058023 --> 0.057672).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0509322\n",
      "\tspeed: 0.0375s/iter; left time: 642.6042s\n",
      "\titers: 200, epoch: 24 | loss: 0.0513161\n",
      "\tspeed: 0.0187s/iter; left time: 318.5876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0498988 Vali Loss: 0.0579281 Test Loss: 0.0604220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508513\n",
      "\tspeed: 0.0373s/iter; left time: 631.8427s\n",
      "\titers: 200, epoch: 25 | loss: 0.0553270\n",
      "\tspeed: 0.0211s/iter; left time: 354.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0499958 Vali Loss: 0.0580391 Test Loss: 0.0603604\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0489895\n",
      "\tspeed: 0.0376s/iter; left time: 628.1109s\n",
      "\titers: 200, epoch: 26 | loss: 0.0511790\n",
      "\tspeed: 0.0173s/iter; left time: 287.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0497630 Vali Loss: 0.0579244 Test Loss: 0.0602479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0486151\n",
      "\tspeed: 0.0384s/iter; left time: 632.6095s\n",
      "\titers: 200, epoch: 27 | loss: 0.0506114\n",
      "\tspeed: 0.0175s/iter; left time: 286.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0498856 Vali Loss: 0.0577455 Test Loss: 0.0601126\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0446018\n",
      "\tspeed: 0.0367s/iter; left time: 596.6074s\n",
      "\titers: 200, epoch: 28 | loss: 0.0462449\n",
      "\tspeed: 0.0195s/iter; left time: 314.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0497051 Vali Loss: 0.0577175 Test Loss: 0.0601918\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0520386\n",
      "\tspeed: 0.0375s/iter; left time: 601.7198s\n",
      "\titers: 200, epoch: 29 | loss: 0.0481251\n",
      "\tspeed: 0.0202s/iter; left time: 321.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0495512 Vali Loss: 0.0576138 Test Loss: 0.0600061\n",
      "Validation loss decreased (0.057672 --> 0.057614).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0497224\n",
      "\tspeed: 0.0424s/iter; left time: 669.7863s\n",
      "\titers: 200, epoch: 30 | loss: 0.0503757\n",
      "\tspeed: 0.0203s/iter; left time: 318.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0493888 Vali Loss: 0.0581249 Test Loss: 0.0604352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0504061\n",
      "\tspeed: 0.0367s/iter; left time: 571.0777s\n",
      "\titers: 200, epoch: 31 | loss: 0.0497857\n",
      "\tspeed: 0.0179s/iter; left time: 277.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0493865 Vali Loss: 0.0575889 Test Loss: 0.0599255\n",
      "Validation loss decreased (0.057614 --> 0.057589).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0520289\n",
      "\tspeed: 0.0361s/iter; left time: 554.0145s\n",
      "\titers: 200, epoch: 32 | loss: 0.0470548\n",
      "\tspeed: 0.0175s/iter; left time: 266.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0493500 Vali Loss: 0.0574853 Test Loss: 0.0598739\n",
      "Validation loss decreased (0.057589 --> 0.057485).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0489791\n",
      "\tspeed: 0.0372s/iter; left time: 563.0859s\n",
      "\titers: 200, epoch: 33 | loss: 0.0510819\n",
      "\tspeed: 0.0174s/iter; left time: 261.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0493776 Vali Loss: 0.0573947 Test Loss: 0.0598598\n",
      "Validation loss decreased (0.057485 --> 0.057395).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0449547\n",
      "\tspeed: 0.0381s/iter; left time: 567.9186s\n",
      "\titers: 200, epoch: 34 | loss: 0.0496961\n",
      "\tspeed: 0.0175s/iter; left time: 258.6109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0492386 Vali Loss: 0.0574011 Test Loss: 0.0597518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0499091\n",
      "\tspeed: 0.0351s/iter; left time: 516.1472s\n",
      "\titers: 200, epoch: 35 | loss: 0.0491820\n",
      "\tspeed: 0.0183s/iter; left time: 266.5762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0491809 Vali Loss: 0.0574168 Test Loss: 0.0597811\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0526245\n",
      "\tspeed: 0.0371s/iter; left time: 535.8339s\n",
      "\titers: 200, epoch: 36 | loss: 0.0488593\n",
      "\tspeed: 0.0178s/iter; left time: 255.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0491984 Vali Loss: 0.0574023 Test Loss: 0.0598615\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0492538\n",
      "\tspeed: 0.0355s/iter; left time: 504.8853s\n",
      "\titers: 200, epoch: 37 | loss: 0.0506678\n",
      "\tspeed: 0.0172s/iter; left time: 243.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0492787 Vali Loss: 0.0574776 Test Loss: 0.0598653\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0519817\n",
      "\tspeed: 0.0360s/iter; left time: 504.3952s\n",
      "\titers: 200, epoch: 38 | loss: 0.0477081\n",
      "\tspeed: 0.0180s/iter; left time: 250.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0491747 Vali Loss: 0.0573329 Test Loss: 0.0597114\n",
      "Validation loss decreased (0.057395 --> 0.057333).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0495917\n",
      "\tspeed: 0.0377s/iter; left time: 519.8914s\n",
      "\titers: 200, epoch: 39 | loss: 0.0463310\n",
      "\tspeed: 0.0173s/iter; left time: 236.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0490367 Vali Loss: 0.0573715 Test Loss: 0.0596787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0481286\n",
      "\tspeed: 0.0383s/iter; left time: 520.0067s\n",
      "\titers: 200, epoch: 40 | loss: 0.0492089\n",
      "\tspeed: 0.0172s/iter; left time: 231.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0490243 Vali Loss: 0.0572552 Test Loss: 0.0596854\n",
      "Validation loss decreased (0.057333 --> 0.057255).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0489064\n",
      "\tspeed: 0.0391s/iter; left time: 522.2394s\n",
      "\titers: 200, epoch: 41 | loss: 0.0486024\n",
      "\tspeed: 0.0189s/iter; left time: 249.8162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0491074 Vali Loss: 0.0573465 Test Loss: 0.0596638\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0542865\n",
      "\tspeed: 0.0354s/iter; left time: 464.5191s\n",
      "\titers: 200, epoch: 42 | loss: 0.0508040\n",
      "\tspeed: 0.0180s/iter; left time: 234.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0491071 Vali Loss: 0.0572566 Test Loss: 0.0596496\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0509735\n",
      "\tspeed: 0.0407s/iter; left time: 525.1014s\n",
      "\titers: 200, epoch: 43 | loss: 0.0494964\n",
      "\tspeed: 0.0174s/iter; left time: 222.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0491612 Vali Loss: 0.0572893 Test Loss: 0.0597281\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0502248\n",
      "\tspeed: 0.0364s/iter; left time: 461.4337s\n",
      "\titers: 200, epoch: 44 | loss: 0.0443589\n",
      "\tspeed: 0.0223s/iter; left time: 280.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0490794 Vali Loss: 0.0572941 Test Loss: 0.0596752\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495226\n",
      "\tspeed: 0.0376s/iter; left time: 468.0482s\n",
      "\titers: 200, epoch: 45 | loss: 0.0487141\n",
      "\tspeed: 0.0172s/iter; left time: 212.4430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0490192 Vali Loss: 0.0573532 Test Loss: 0.0596827\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0493966\n",
      "\tspeed: 0.0429s/iter; left time: 524.3831s\n",
      "\titers: 200, epoch: 46 | loss: 0.0463138\n",
      "\tspeed: 0.0224s/iter; left time: 271.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0492276 Vali Loss: 0.0576674 Test Loss: 0.0599896\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0485500\n",
      "\tspeed: 0.0396s/iter; left time: 475.0283s\n",
      "\titers: 200, epoch: 47 | loss: 0.0474930\n",
      "\tspeed: 0.0174s/iter; left time: 207.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0489630 Vali Loss: 0.0575855 Test Loss: 0.0599361\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0476843\n",
      "\tspeed: 0.0389s/iter; left time: 458.4570s\n",
      "\titers: 200, epoch: 48 | loss: 0.0503357\n",
      "\tspeed: 0.0175s/iter; left time: 203.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0490957 Vali Loss: 0.0572898 Test Loss: 0.0596848\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0546042\n",
      "\tspeed: 0.0359s/iter; left time: 414.4026s\n",
      "\titers: 200, epoch: 49 | loss: 0.0484213\n",
      "\tspeed: 0.0205s/iter; left time: 235.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0491670 Vali Loss: 0.0572665 Test Loss: 0.0596485\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0510215\n",
      "\tspeed: 0.0408s/iter; left time: 462.1339s\n",
      "\titers: 200, epoch: 50 | loss: 0.0490253\n",
      "\tspeed: 0.0194s/iter; left time: 218.2440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0489847 Vali Loss: 0.0573010 Test Loss: 0.0596603\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010642945766448975, rmse:0.10316465049982071, mae:0.059685416519641876, rse:0.3980063796043396\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:29.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2247583\n",
      "\tspeed: 0.0441s/iter; left time: 983.2509s\n",
      "\titers: 200, epoch: 1 | loss: 0.2110642\n",
      "\tspeed: 0.0176s/iter; left time: 391.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.2283931 Vali Loss: 0.1739245 Test Loss: 0.1796148\n",
      "Validation loss decreased (inf --> 0.173925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1307912\n",
      "\tspeed: 0.0381s/iter; left time: 840.4995s\n",
      "\titers: 200, epoch: 2 | loss: 0.0952648\n",
      "\tspeed: 0.0177s/iter; left time: 388.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1318476 Vali Loss: 0.0961500 Test Loss: 0.1068681\n",
      "Validation loss decreased (0.173925 --> 0.096150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878664\n",
      "\tspeed: 0.0387s/iter; left time: 846.0929s\n",
      "\titers: 200, epoch: 3 | loss: 0.0826205\n",
      "\tspeed: 0.0176s/iter; left time: 382.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0886377 Vali Loss: 0.0875749 Test Loss: 0.0960391\n",
      "Validation loss decreased (0.096150 --> 0.087575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0775627\n",
      "\tspeed: 0.0376s/iter; left time: 812.6053s\n",
      "\titers: 200, epoch: 4 | loss: 0.0800580\n",
      "\tspeed: 0.0176s/iter; left time: 378.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0805322 Vali Loss: 0.0821570 Test Loss: 0.0895570\n",
      "Validation loss decreased (0.087575 --> 0.082157).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765028\n",
      "\tspeed: 0.0381s/iter; left time: 816.1289s\n",
      "\titers: 200, epoch: 5 | loss: 0.0727876\n",
      "\tspeed: 0.0176s/iter; left time: 373.9181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0753626 Vali Loss: 0.0803998 Test Loss: 0.0879519\n",
      "Validation loss decreased (0.082157 --> 0.080400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774372\n",
      "\tspeed: 0.0383s/iter; left time: 811.4563s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735677\n",
      "\tspeed: 0.0175s/iter; left time: 369.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0726207 Vali Loss: 0.0797703 Test Loss: 0.0875197\n",
      "Validation loss decreased (0.080400 --> 0.079770).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0743370\n",
      "\tspeed: 0.0381s/iter; left time: 798.1986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0678488\n",
      "\tspeed: 0.0185s/iter; left time: 386.3393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0706009 Vali Loss: 0.0782221 Test Loss: 0.0855775\n",
      "Validation loss decreased (0.079770 --> 0.078222).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0727910\n",
      "\tspeed: 0.0396s/iter; left time: 820.7160s\n",
      "\titers: 200, epoch: 8 | loss: 0.0646456\n",
      "\tspeed: 0.0202s/iter; left time: 416.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0691813 Vali Loss: 0.0775231 Test Loss: 0.0844578\n",
      "Validation loss decreased (0.078222 --> 0.077523).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0674671\n",
      "\tspeed: 0.0388s/iter; left time: 795.2426s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665397\n",
      "\tspeed: 0.0181s/iter; left time: 369.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0683832 Vali Loss: 0.0776606 Test Loss: 0.0849660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0729846\n",
      "\tspeed: 0.0390s/iter; left time: 790.4316s\n",
      "\titers: 200, epoch: 10 | loss: 0.0656892\n",
      "\tspeed: 0.0180s/iter; left time: 363.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0674439 Vali Loss: 0.0762555 Test Loss: 0.0836048\n",
      "Validation loss decreased (0.077523 --> 0.076255).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0676251\n",
      "\tspeed: 0.0415s/iter; left time: 831.7014s\n",
      "\titers: 200, epoch: 11 | loss: 0.0668655\n",
      "\tspeed: 0.0176s/iter; left time: 352.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0665991 Vali Loss: 0.0755719 Test Loss: 0.0840431\n",
      "Validation loss decreased (0.076255 --> 0.075572).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0662990\n",
      "\tspeed: 0.0403s/iter; left time: 800.3438s\n",
      "\titers: 200, epoch: 12 | loss: 0.0658202\n",
      "\tspeed: 0.0186s/iter; left time: 366.9118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0661504 Vali Loss: 0.0767297 Test Loss: 0.0833037\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0653353\n",
      "\tspeed: 0.0384s/iter; left time: 752.3992s\n",
      "\titers: 200, epoch: 13 | loss: 0.0644610\n",
      "\tspeed: 0.0175s/iter; left time: 341.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0657464 Vali Loss: 0.0751664 Test Loss: 0.0825177\n",
      "Validation loss decreased (0.075572 --> 0.075166).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0647618\n",
      "\tspeed: 0.0407s/iter; left time: 788.2741s\n",
      "\titers: 200, epoch: 14 | loss: 0.0649751\n",
      "\tspeed: 0.0174s/iter; left time: 336.3461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0654680 Vali Loss: 0.0749129 Test Loss: 0.0827685\n",
      "Validation loss decreased (0.075166 --> 0.074913).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605934\n",
      "\tspeed: 0.0378s/iter; left time: 724.9586s\n",
      "\titers: 200, epoch: 15 | loss: 0.0671939\n",
      "\tspeed: 0.0205s/iter; left time: 391.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0650269 Vali Loss: 0.0746628 Test Loss: 0.0827791\n",
      "Validation loss decreased (0.074913 --> 0.074663).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0647860\n",
      "\tspeed: 0.0473s/iter; left time: 895.9576s\n",
      "\titers: 200, epoch: 16 | loss: 0.0672728\n",
      "\tspeed: 0.0223s/iter; left time: 420.5385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0646335 Vali Loss: 0.0746252 Test Loss: 0.0836227\n",
      "Validation loss decreased (0.074663 --> 0.074625).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0634853\n",
      "\tspeed: 0.0394s/iter; left time: 737.0697s\n",
      "\titers: 200, epoch: 17 | loss: 0.0662486\n",
      "\tspeed: 0.0174s/iter; left time: 324.0408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0650164 Vali Loss: 0.0747181 Test Loss: 0.0829482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0650601\n",
      "\tspeed: 0.0384s/iter; left time: 710.6017s\n",
      "\titers: 200, epoch: 18 | loss: 0.0635075\n",
      "\tspeed: 0.0211s/iter; left time: 387.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0644976 Vali Loss: 0.0743944 Test Loss: 0.0835960\n",
      "Validation loss decreased (0.074625 --> 0.074394).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0655558\n",
      "\tspeed: 0.0412s/iter; left time: 752.7291s\n",
      "\titers: 200, epoch: 19 | loss: 0.0673271\n",
      "\tspeed: 0.0190s/iter; left time: 345.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0643014 Vali Loss: 0.0742977 Test Loss: 0.0832769\n",
      "Validation loss decreased (0.074394 --> 0.074298).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0649739\n",
      "\tspeed: 0.0418s/iter; left time: 753.6531s\n",
      "\titers: 200, epoch: 20 | loss: 0.0651673\n",
      "\tspeed: 0.0200s/iter; left time: 358.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0643234 Vali Loss: 0.0742534 Test Loss: 0.0832492\n",
      "Validation loss decreased (0.074298 --> 0.074253).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683060\n",
      "\tspeed: 0.0419s/iter; left time: 746.7093s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584680\n",
      "\tspeed: 0.0193s/iter; left time: 342.0173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0640115 Vali Loss: 0.0740189 Test Loss: 0.0823374\n",
      "Validation loss decreased (0.074253 --> 0.074019).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0640669\n",
      "\tspeed: 0.0410s/iter; left time: 722.1082s\n",
      "\titers: 200, epoch: 22 | loss: 0.0680301\n",
      "\tspeed: 0.0189s/iter; left time: 330.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0636955 Vali Loss: 0.0740751 Test Loss: 0.0825475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0641997\n",
      "\tspeed: 0.0394s/iter; left time: 684.0788s\n",
      "\titers: 200, epoch: 23 | loss: 0.0647988\n",
      "\tspeed: 0.0180s/iter; left time: 311.5136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0636366 Vali Loss: 0.0740381 Test Loss: 0.0825958\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0642621\n",
      "\tspeed: 0.0434s/iter; left time: 744.2203s\n",
      "\titers: 200, epoch: 24 | loss: 0.0604572\n",
      "\tspeed: 0.0176s/iter; left time: 299.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0634552 Vali Loss: 0.0742615 Test Loss: 0.0832317\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0624321\n",
      "\tspeed: 0.0376s/iter; left time: 636.5003s\n",
      "\titers: 200, epoch: 25 | loss: 0.0617251\n",
      "\tspeed: 0.0176s/iter; left time: 296.5901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0633835 Vali Loss: 0.0741187 Test Loss: 0.0830197\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0612301\n",
      "\tspeed: 0.0377s/iter; left time: 630.0752s\n",
      "\titers: 200, epoch: 26 | loss: 0.0659279\n",
      "\tspeed: 0.0181s/iter; left time: 301.2018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0633406 Vali Loss: 0.0738879 Test Loss: 0.0828041\n",
      "Validation loss decreased (0.074019 --> 0.073888).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0613242\n",
      "\tspeed: 0.0381s/iter; left time: 627.0067s\n",
      "\titers: 200, epoch: 27 | loss: 0.0652461\n",
      "\tspeed: 0.0176s/iter; left time: 287.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0635310 Vali Loss: 0.0738510 Test Loss: 0.0825673\n",
      "Validation loss decreased (0.073888 --> 0.073851).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0632376\n",
      "\tspeed: 0.0399s/iter; left time: 648.5459s\n",
      "\titers: 200, epoch: 28 | loss: 0.0636772\n",
      "\tspeed: 0.0173s/iter; left time: 280.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0633069 Vali Loss: 0.0738611 Test Loss: 0.0824119\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0618980\n",
      "\tspeed: 0.0385s/iter; left time: 617.7237s\n",
      "\titers: 200, epoch: 29 | loss: 0.0679610\n",
      "\tspeed: 0.0198s/iter; left time: 315.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0633181 Vali Loss: 0.0739335 Test Loss: 0.0823843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0639477\n",
      "\tspeed: 0.0387s/iter; left time: 612.0914s\n",
      "\titers: 200, epoch: 30 | loss: 0.0601007\n",
      "\tspeed: 0.0175s/iter; left time: 274.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0633556 Vali Loss: 0.0741023 Test Loss: 0.0828930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0651662\n",
      "\tspeed: 0.0374s/iter; left time: 582.4796s\n",
      "\titers: 200, epoch: 31 | loss: 0.0620232\n",
      "\tspeed: 0.0174s/iter; left time: 269.4802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0631821 Vali Loss: 0.0740046 Test Loss: 0.0828805\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0624187\n",
      "\tspeed: 0.0379s/iter; left time: 581.6493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0643874\n",
      "\tspeed: 0.0177s/iter; left time: 270.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0631632 Vali Loss: 0.0739178 Test Loss: 0.0826334\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0638696\n",
      "\tspeed: 0.0372s/iter; left time: 563.0954s\n",
      "\titers: 200, epoch: 33 | loss: 0.0637890\n",
      "\tspeed: 0.0174s/iter; left time: 261.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0630920 Vali Loss: 0.0739848 Test Loss: 0.0825740\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0630978\n",
      "\tspeed: 0.0394s/iter; left time: 586.9319s\n",
      "\titers: 200, epoch: 34 | loss: 0.0630619\n",
      "\tspeed: 0.0206s/iter; left time: 305.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0631138 Vali Loss: 0.0739563 Test Loss: 0.0827014\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0606765\n",
      "\tspeed: 0.0377s/iter; left time: 554.3040s\n",
      "\titers: 200, epoch: 35 | loss: 0.0647627\n",
      "\tspeed: 0.0179s/iter; left time: 260.4236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0630331 Vali Loss: 0.0736615 Test Loss: 0.0821839\n",
      "Validation loss decreased (0.073851 --> 0.073662).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0611204\n",
      "\tspeed: 0.0436s/iter; left time: 630.0488s\n",
      "\titers: 200, epoch: 36 | loss: 0.0601015\n",
      "\tspeed: 0.0176s/iter; left time: 252.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0629634 Vali Loss: 0.0738245 Test Loss: 0.0824375\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0645292\n",
      "\tspeed: 0.0386s/iter; left time: 550.0190s\n",
      "\titers: 200, epoch: 37 | loss: 0.0631087\n",
      "\tspeed: 0.0186s/iter; left time: 262.5134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0629622 Vali Loss: 0.0739686 Test Loss: 0.0829979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0614005\n",
      "\tspeed: 0.0416s/iter; left time: 582.9921s\n",
      "\titers: 200, epoch: 38 | loss: 0.0646622\n",
      "\tspeed: 0.0177s/iter; left time: 245.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0629720 Vali Loss: 0.0738572 Test Loss: 0.0826879\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0592805\n",
      "\tspeed: 0.0411s/iter; left time: 567.1784s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682494\n",
      "\tspeed: 0.0263s/iter; left time: 360.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0628646 Vali Loss: 0.0737171 Test Loss: 0.0822277\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0636136\n",
      "\tspeed: 0.0395s/iter; left time: 536.1692s\n",
      "\titers: 200, epoch: 40 | loss: 0.0640101\n",
      "\tspeed: 0.0176s/iter; left time: 236.5435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0630662 Vali Loss: 0.0738709 Test Loss: 0.0826220\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0667536\n",
      "\tspeed: 0.0413s/iter; left time: 550.6096s\n",
      "\titers: 200, epoch: 41 | loss: 0.0584305\n",
      "\tspeed: 0.0193s/iter; left time: 255.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0628251 Vali Loss: 0.0740194 Test Loss: 0.0829386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0631080\n",
      "\tspeed: 0.0378s/iter; left time: 496.4576s\n",
      "\titers: 200, epoch: 42 | loss: 0.0638256\n",
      "\tspeed: 0.0176s/iter; left time: 229.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0629956 Vali Loss: 0.0738227 Test Loss: 0.0824970\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646805\n",
      "\tspeed: 0.0378s/iter; left time: 487.1329s\n",
      "\titers: 200, epoch: 43 | loss: 0.0633970\n",
      "\tspeed: 0.0176s/iter; left time: 225.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0628065 Vali Loss: 0.0737748 Test Loss: 0.0824351\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0663955\n",
      "\tspeed: 0.0372s/iter; left time: 471.8630s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614184\n",
      "\tspeed: 0.0174s/iter; left time: 218.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0629094 Vali Loss: 0.0738258 Test Loss: 0.0826319\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0646778\n",
      "\tspeed: 0.0371s/iter; left time: 461.2824s\n",
      "\titers: 200, epoch: 45 | loss: 0.0636121\n",
      "\tspeed: 0.0176s/iter; left time: 216.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0628988 Vali Loss: 0.0737582 Test Loss: 0.0824334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019680019468069077, rmse:0.14028549194335938, mae:0.08218392729759216, rse:0.5426615476608276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2284414\n",
      "\tspeed: 0.0245s/iter; left time: 545.3045s\n",
      "\titers: 200, epoch: 1 | loss: 0.2151139\n",
      "\tspeed: 0.0199s/iter; left time: 441.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.2333744 Vali Loss: 0.1724914 Test Loss: 0.1774697\n",
      "Validation loss decreased (inf --> 0.172491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1269303\n",
      "\tspeed: 0.0415s/iter; left time: 916.2325s\n",
      "\titers: 200, epoch: 2 | loss: 0.1001725\n",
      "\tspeed: 0.0191s/iter; left time: 419.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.1325294 Vali Loss: 0.0990750 Test Loss: 0.1096021\n",
      "Validation loss decreased (0.172491 --> 0.099075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0865366\n",
      "\tspeed: 0.0401s/iter; left time: 875.7817s\n",
      "\titers: 200, epoch: 3 | loss: 0.0872007\n",
      "\tspeed: 0.0180s/iter; left time: 390.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0884579 Vali Loss: 0.0861872 Test Loss: 0.0937232\n",
      "Validation loss decreased (0.099075 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809731\n",
      "\tspeed: 0.0394s/iter; left time: 852.0079s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770818\n",
      "\tspeed: 0.0176s/iter; left time: 379.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0796711 Vali Loss: 0.0844280 Test Loss: 0.0910993\n",
      "Validation loss decreased (0.086187 --> 0.084428).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759911\n",
      "\tspeed: 0.0392s/iter; left time: 838.3852s\n",
      "\titers: 200, epoch: 5 | loss: 0.0739146\n",
      "\tspeed: 0.0177s/iter; left time: 376.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0753532 Vali Loss: 0.0798179 Test Loss: 0.0870115\n",
      "Validation loss decreased (0.084428 --> 0.079818).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0676676\n",
      "\tspeed: 0.0414s/iter; left time: 876.8319s\n",
      "\titers: 200, epoch: 6 | loss: 0.0717228\n",
      "\tspeed: 0.0177s/iter; left time: 373.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0722853 Vali Loss: 0.0791006 Test Loss: 0.0863080\n",
      "Validation loss decreased (0.079818 --> 0.079101).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0678237\n",
      "\tspeed: 0.0426s/iter; left time: 893.6780s\n",
      "\titers: 200, epoch: 7 | loss: 0.0696619\n",
      "\tspeed: 0.0237s/iter; left time: 493.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0703334 Vali Loss: 0.0780156 Test Loss: 0.0856910\n",
      "Validation loss decreased (0.079101 --> 0.078016).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0655424\n",
      "\tspeed: 0.0419s/iter; left time: 868.0402s\n",
      "\titers: 200, epoch: 8 | loss: 0.0672451\n",
      "\tspeed: 0.0175s/iter; left time: 362.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0693712 Vali Loss: 0.0775701 Test Loss: 0.0851063\n",
      "Validation loss decreased (0.078016 --> 0.077570).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726505\n",
      "\tspeed: 0.0415s/iter; left time: 850.8317s\n",
      "\titers: 200, epoch: 9 | loss: 0.0755221\n",
      "\tspeed: 0.0180s/iter; left time: 368.3225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0682698 Vali Loss: 0.0767766 Test Loss: 0.0837281\n",
      "Validation loss decreased (0.077570 --> 0.076777).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0696447\n",
      "\tspeed: 0.0384s/iter; left time: 778.0057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655050\n",
      "\tspeed: 0.0176s/iter; left time: 355.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0672856 Vali Loss: 0.0774400 Test Loss: 0.0852725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0677388\n",
      "\tspeed: 0.0389s/iter; left time: 780.2298s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660179\n",
      "\tspeed: 0.0176s/iter; left time: 351.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0668714 Vali Loss: 0.0757332 Test Loss: 0.0832309\n",
      "Validation loss decreased (0.076777 --> 0.075733).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0627297\n",
      "\tspeed: 0.0399s/iter; left time: 791.1354s\n",
      "\titers: 200, epoch: 12 | loss: 0.0637292\n",
      "\tspeed: 0.0198s/iter; left time: 390.4583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0662595 Vali Loss: 0.0762811 Test Loss: 0.0833561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0679668\n",
      "\tspeed: 0.0424s/iter; left time: 831.2221s\n",
      "\titers: 200, epoch: 13 | loss: 0.0620509\n",
      "\tspeed: 0.0189s/iter; left time: 369.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0656262 Vali Loss: 0.0755052 Test Loss: 0.0833319\n",
      "Validation loss decreased (0.075733 --> 0.075505).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0637436\n",
      "\tspeed: 0.0380s/iter; left time: 737.2326s\n",
      "\titers: 200, epoch: 14 | loss: 0.0679394\n",
      "\tspeed: 0.0174s/iter; left time: 335.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0654845 Vali Loss: 0.0749590 Test Loss: 0.0828288\n",
      "Validation loss decreased (0.075505 --> 0.074959).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0673762\n",
      "\tspeed: 0.0389s/iter; left time: 745.1107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0637540\n",
      "\tspeed: 0.0176s/iter; left time: 336.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0651479 Vali Loss: 0.0747173 Test Loss: 0.0833911\n",
      "Validation loss decreased (0.074959 --> 0.074717).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0621715\n",
      "\tspeed: 0.0389s/iter; left time: 737.4282s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673409\n",
      "\tspeed: 0.0207s/iter; left time: 389.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0647666 Vali Loss: 0.0745301 Test Loss: 0.0828806\n",
      "Validation loss decreased (0.074717 --> 0.074530).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645612\n",
      "\tspeed: 0.0386s/iter; left time: 722.2511s\n",
      "\titers: 200, epoch: 17 | loss: 0.0596500\n",
      "\tspeed: 0.0175s/iter; left time: 326.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0648331 Vali Loss: 0.0742863 Test Loss: 0.0828043\n",
      "Validation loss decreased (0.074530 --> 0.074286).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0642966\n",
      "\tspeed: 0.0391s/iter; left time: 722.3137s\n",
      "\titers: 200, epoch: 18 | loss: 0.0643684\n",
      "\tspeed: 0.0206s/iter; left time: 378.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0642719 Vali Loss: 0.0739853 Test Loss: 0.0824876\n",
      "Validation loss decreased (0.074286 --> 0.073985).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0682903\n",
      "\tspeed: 0.0389s/iter; left time: 710.4045s\n",
      "\titers: 200, epoch: 19 | loss: 0.0667571\n",
      "\tspeed: 0.0175s/iter; left time: 317.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0642246 Vali Loss: 0.0740721 Test Loss: 0.0826298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0613630\n",
      "\tspeed: 0.0384s/iter; left time: 692.7923s\n",
      "\titers: 200, epoch: 20 | loss: 0.0639390\n",
      "\tspeed: 0.0190s/iter; left time: 341.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0640536 Vali Loss: 0.0737642 Test Loss: 0.0826450\n",
      "Validation loss decreased (0.073985 --> 0.073764).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0625804\n",
      "\tspeed: 0.0396s/iter; left time: 705.4584s\n",
      "\titers: 200, epoch: 21 | loss: 0.0654177\n",
      "\tspeed: 0.0184s/iter; left time: 325.6939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0640878 Vali Loss: 0.0737960 Test Loss: 0.0825673\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0607531\n",
      "\tspeed: 0.0380s/iter; left time: 668.1070s\n",
      "\titers: 200, epoch: 22 | loss: 0.0649099\n",
      "\tspeed: 0.0174s/iter; left time: 304.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0638094 Vali Loss: 0.0736277 Test Loss: 0.0830579\n",
      "Validation loss decreased (0.073764 --> 0.073628).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0616302\n",
      "\tspeed: 0.0382s/iter; left time: 662.9623s\n",
      "\titers: 200, epoch: 23 | loss: 0.0592529\n",
      "\tspeed: 0.0177s/iter; left time: 306.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0637394 Vali Loss: 0.0735366 Test Loss: 0.0823405\n",
      "Validation loss decreased (0.073628 --> 0.073537).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0646890\n",
      "\tspeed: 0.0403s/iter; left time: 691.1626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0634022\n",
      "\tspeed: 0.0222s/iter; left time: 379.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0636263 Vali Loss: 0.0734140 Test Loss: 0.0824214\n",
      "Validation loss decreased (0.073537 --> 0.073414).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0623656\n",
      "\tspeed: 0.0406s/iter; left time: 687.8228s\n",
      "\titers: 200, epoch: 25 | loss: 0.0630045\n",
      "\tspeed: 0.0177s/iter; left time: 297.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0635586 Vali Loss: 0.0734150 Test Loss: 0.0823226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0644196\n",
      "\tspeed: 0.0436s/iter; left time: 728.6859s\n",
      "\titers: 200, epoch: 26 | loss: 0.0642436\n",
      "\tspeed: 0.0202s/iter; left time: 335.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0634620 Vali Loss: 0.0738082 Test Loss: 0.0823546\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0621702\n",
      "\tspeed: 0.0381s/iter; left time: 627.6604s\n",
      "\titers: 200, epoch: 27 | loss: 0.0636371\n",
      "\tspeed: 0.0191s/iter; left time: 312.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0633896 Vali Loss: 0.0733780 Test Loss: 0.0819248\n",
      "Validation loss decreased (0.073414 --> 0.073378).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0670925\n",
      "\tspeed: 0.0398s/iter; left time: 646.4603s\n",
      "\titers: 200, epoch: 28 | loss: 0.0628431\n",
      "\tspeed: 0.0175s/iter; left time: 283.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0634301 Vali Loss: 0.0733993 Test Loss: 0.0823185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0612113\n",
      "\tspeed: 0.0390s/iter; left time: 625.7341s\n",
      "\titers: 200, epoch: 29 | loss: 0.0665068\n",
      "\tspeed: 0.0176s/iter; left time: 280.8766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0633498 Vali Loss: 0.0734619 Test Loss: 0.0819948\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0626834\n",
      "\tspeed: 0.0385s/iter; left time: 607.7644s\n",
      "\titers: 200, epoch: 30 | loss: 0.0615458\n",
      "\tspeed: 0.0174s/iter; left time: 273.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0633269 Vali Loss: 0.0732484 Test Loss: 0.0825042\n",
      "Validation loss decreased (0.073378 --> 0.073248).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0625415\n",
      "\tspeed: 0.0388s/iter; left time: 603.8948s\n",
      "\titers: 200, epoch: 31 | loss: 0.0673994\n",
      "\tspeed: 0.0177s/iter; left time: 273.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0632653 Vali Loss: 0.0733413 Test Loss: 0.0826836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0583663\n",
      "\tspeed: 0.0398s/iter; left time: 610.5682s\n",
      "\titers: 200, epoch: 32 | loss: 0.0625218\n",
      "\tspeed: 0.0198s/iter; left time: 302.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0632355 Vali Loss: 0.0732359 Test Loss: 0.0821653\n",
      "Validation loss decreased (0.073248 --> 0.073236).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630707\n",
      "\tspeed: 0.0394s/iter; left time: 595.6786s\n",
      "\titers: 200, epoch: 33 | loss: 0.0647555\n",
      "\tspeed: 0.0176s/iter; left time: 263.8631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0631756 Vali Loss: 0.0732615 Test Loss: 0.0824250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0610265\n",
      "\tspeed: 0.0381s/iter; left time: 568.5660s\n",
      "\titers: 200, epoch: 34 | loss: 0.0629594\n",
      "\tspeed: 0.0176s/iter; left time: 261.2516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0630419 Vali Loss: 0.0731823 Test Loss: 0.0821405\n",
      "Validation loss decreased (0.073236 --> 0.073182).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0651123\n",
      "\tspeed: 0.0408s/iter; left time: 598.6879s\n",
      "\titers: 200, epoch: 35 | loss: 0.0626166\n",
      "\tspeed: 0.0176s/iter; left time: 256.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0630429 Vali Loss: 0.0731572 Test Loss: 0.0825000\n",
      "Validation loss decreased (0.073182 --> 0.073157).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0676148\n",
      "\tspeed: 0.0393s/iter; left time: 568.0607s\n",
      "\titers: 200, epoch: 36 | loss: 0.0607777\n",
      "\tspeed: 0.0176s/iter; left time: 253.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0629283 Vali Loss: 0.0731764 Test Loss: 0.0821953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0638510\n",
      "\tspeed: 0.0378s/iter; left time: 537.5346s\n",
      "\titers: 200, epoch: 37 | loss: 0.0606790\n",
      "\tspeed: 0.0175s/iter; left time: 248.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0629828 Vali Loss: 0.0731762 Test Loss: 0.0823688\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0626185\n",
      "\tspeed: 0.0379s/iter; left time: 530.9683s\n",
      "\titers: 200, epoch: 38 | loss: 0.0677540\n",
      "\tspeed: 0.0186s/iter; left time: 258.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0630360 Vali Loss: 0.0731249 Test Loss: 0.0822642\n",
      "Validation loss decreased (0.073157 --> 0.073125).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0594267\n",
      "\tspeed: 0.0420s/iter; left time: 579.4960s\n",
      "\titers: 200, epoch: 39 | loss: 0.0592867\n",
      "\tspeed: 0.0183s/iter; left time: 249.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0629004 Vali Loss: 0.0731309 Test Loss: 0.0823867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0624202\n",
      "\tspeed: 0.0398s/iter; left time: 539.8608s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626078\n",
      "\tspeed: 0.0206s/iter; left time: 276.7819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0629448 Vali Loss: 0.0730758 Test Loss: 0.0823547\n",
      "Validation loss decreased (0.073125 --> 0.073076).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0585274\n",
      "\tspeed: 0.0409s/iter; left time: 545.1142s\n",
      "\titers: 200, epoch: 41 | loss: 0.0654995\n",
      "\tspeed: 0.0183s/iter; left time: 241.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0629022 Vali Loss: 0.0731006 Test Loss: 0.0824329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0662732\n",
      "\tspeed: 0.0389s/iter; left time: 510.7989s\n",
      "\titers: 200, epoch: 42 | loss: 0.0638925\n",
      "\tspeed: 0.0175s/iter; left time: 227.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0629260 Vali Loss: 0.0731194 Test Loss: 0.0822936\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0624809\n",
      "\tspeed: 0.0402s/iter; left time: 518.3971s\n",
      "\titers: 200, epoch: 43 | loss: 0.0598410\n",
      "\tspeed: 0.0214s/iter; left time: 273.6937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0628966 Vali Loss: 0.0730038 Test Loss: 0.0820691\n",
      "Validation loss decreased (0.073076 --> 0.073004).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0637282\n",
      "\tspeed: 0.0437s/iter; left time: 553.6389s\n",
      "\titers: 200, epoch: 44 | loss: 0.0634378\n",
      "\tspeed: 0.0193s/iter; left time: 242.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0628899 Vali Loss: 0.0729619 Test Loss: 0.0821936\n",
      "Validation loss decreased (0.073004 --> 0.072962).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0644619\n",
      "\tspeed: 0.0399s/iter; left time: 495.9471s\n",
      "\titers: 200, epoch: 45 | loss: 0.0628364\n",
      "\tspeed: 0.0178s/iter; left time: 219.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0628545 Vali Loss: 0.0729947 Test Loss: 0.0822399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0642725\n",
      "\tspeed: 0.0377s/iter; left time: 460.8121s\n",
      "\titers: 200, epoch: 46 | loss: 0.0629762\n",
      "\tspeed: 0.0174s/iter; left time: 210.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0629435 Vali Loss: 0.0730896 Test Loss: 0.0822521\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0616131\n",
      "\tspeed: 0.0415s/iter; left time: 497.7589s\n",
      "\titers: 200, epoch: 47 | loss: 0.0646186\n",
      "\tspeed: 0.0195s/iter; left time: 232.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0630293 Vali Loss: 0.0731405 Test Loss: 0.0821996\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0608085\n",
      "\tspeed: 0.0394s/iter; left time: 463.3427s\n",
      "\titers: 200, epoch: 48 | loss: 0.0619352\n",
      "\tspeed: 0.0177s/iter; left time: 206.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0629598 Vali Loss: 0.0731355 Test Loss: 0.0823273\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0595867\n",
      "\tspeed: 0.0378s/iter; left time: 436.5124s\n",
      "\titers: 200, epoch: 49 | loss: 0.0611303\n",
      "\tspeed: 0.0183s/iter; left time: 209.2064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0628467 Vali Loss: 0.0730247 Test Loss: 0.0825256\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0653134\n",
      "\tspeed: 0.0436s/iter; left time: 494.3080s\n",
      "\titers: 200, epoch: 50 | loss: 0.0591919\n",
      "\tspeed: 0.0177s/iter; left time: 199.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0628510 Vali Loss: 0.0731374 Test Loss: 0.0824137\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0623601\n",
      "\tspeed: 0.0387s/iter; left time: 430.0506s\n",
      "\titers: 200, epoch: 51 | loss: 0.0633687\n",
      "\tspeed: 0.0177s/iter; left time: 194.5603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0628592 Vali Loss: 0.0729967 Test Loss: 0.0822993\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0676762\n",
      "\tspeed: 0.0379s/iter; left time: 412.1308s\n",
      "\titers: 200, epoch: 52 | loss: 0.0648613\n",
      "\tspeed: 0.0175s/iter; left time: 189.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0627263 Vali Loss: 0.0732131 Test Loss: 0.0825580\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0645146\n",
      "\tspeed: 0.0416s/iter; left time: 443.1645s\n",
      "\titers: 200, epoch: 53 | loss: 0.0648449\n",
      "\tspeed: 0.0174s/iter; left time: 183.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0629098 Vali Loss: 0.0730307 Test Loss: 0.0825109\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0656283\n",
      "\tspeed: 0.0384s/iter; left time: 400.0912s\n",
      "\titers: 200, epoch: 54 | loss: 0.0613380\n",
      "\tspeed: 0.0198s/iter; left time: 204.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0628620 Vali Loss: 0.0730089 Test Loss: 0.0822609\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01964399963617325, rmse:0.1401570588350296, mae:0.08219358325004578, rse:0.5421647429466248\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:47.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2331251\n",
      "\tspeed: 0.0348s/iter; left time: 772.0667s\n",
      "\titers: 200, epoch: 1 | loss: 0.2124415\n",
      "\tspeed: 0.0183s/iter; left time: 403.4618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.2301618 Vali Loss: 0.1742980 Test Loss: 0.1785990\n",
      "Validation loss decreased (inf --> 0.174298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1321372\n",
      "\tspeed: 0.0404s/iter; left time: 887.4506s\n",
      "\titers: 200, epoch: 2 | loss: 0.0986593\n",
      "\tspeed: 0.0181s/iter; left time: 395.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1298941 Vali Loss: 0.0991115 Test Loss: 0.1104057\n",
      "Validation loss decreased (0.174298 --> 0.099111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0942273\n",
      "\tspeed: 0.0412s/iter; left time: 895.6911s\n",
      "\titers: 200, epoch: 3 | loss: 0.0837540\n",
      "\tspeed: 0.0181s/iter; left time: 391.4723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0901285 Vali Loss: 0.0897258 Test Loss: 0.0991279\n",
      "Validation loss decreased (0.099111 --> 0.089726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836681\n",
      "\tspeed: 0.0399s/iter; left time: 859.5682s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837559\n",
      "\tspeed: 0.0181s/iter; left time: 388.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0824823 Vali Loss: 0.0846098 Test Loss: 0.0920205\n",
      "Validation loss decreased (0.089726 --> 0.084610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0822264\n",
      "\tspeed: 0.0394s/iter; left time: 840.3433s\n",
      "\titers: 200, epoch: 5 | loss: 0.0768700\n",
      "\tspeed: 0.0177s/iter; left time: 375.0812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0782840 Vali Loss: 0.0833012 Test Loss: 0.0921557\n",
      "Validation loss decreased (0.084610 --> 0.083301).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0719065\n",
      "\tspeed: 0.0412s/iter; left time: 869.4494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762894\n",
      "\tspeed: 0.0180s/iter; left time: 378.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0751740 Vali Loss: 0.0819572 Test Loss: 0.0909903\n",
      "Validation loss decreased (0.083301 --> 0.081957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0761901\n",
      "\tspeed: 0.0422s/iter; left time: 880.3028s\n",
      "\titers: 200, epoch: 7 | loss: 0.0726519\n",
      "\tspeed: 0.0201s/iter; left time: 417.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0736603 Vali Loss: 0.0814691 Test Loss: 0.0893811\n",
      "Validation loss decreased (0.081957 --> 0.081469).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0669216\n",
      "\tspeed: 0.0424s/iter; left time: 875.1552s\n",
      "\titers: 200, epoch: 8 | loss: 0.0754231\n",
      "\tspeed: 0.0180s/iter; left time: 369.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0723458 Vali Loss: 0.0809321 Test Loss: 0.0924311\n",
      "Validation loss decreased (0.081469 --> 0.080932).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0727989\n",
      "\tspeed: 0.0388s/iter; left time: 792.1490s\n",
      "\titers: 200, epoch: 9 | loss: 0.0671195\n",
      "\tspeed: 0.0177s/iter; left time: 359.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0713408 Vali Loss: 0.0797568 Test Loss: 0.0923679\n",
      "Validation loss decreased (0.080932 --> 0.079757).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0683972\n",
      "\tspeed: 0.0405s/iter; left time: 817.1563s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688428\n",
      "\tspeed: 0.0189s/iter; left time: 380.3301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0704662 Vali Loss: 0.0788295 Test Loss: 0.0906416\n",
      "Validation loss decreased (0.079757 --> 0.078830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0760151\n",
      "\tspeed: 0.0393s/iter; left time: 783.9271s\n",
      "\titers: 200, epoch: 11 | loss: 0.0659735\n",
      "\tspeed: 0.0205s/iter; left time: 407.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0698830 Vali Loss: 0.0787371 Test Loss: 0.0913422\n",
      "Validation loss decreased (0.078830 --> 0.078737).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0676855\n",
      "\tspeed: 0.0389s/iter; left time: 767.7499s\n",
      "\titers: 200, epoch: 12 | loss: 0.0701122\n",
      "\tspeed: 0.0195s/iter; left time: 383.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0692690 Vali Loss: 0.0787894 Test Loss: 0.0932875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0701766\n",
      "\tspeed: 0.0392s/iter; left time: 764.9497s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692856\n",
      "\tspeed: 0.0178s/iter; left time: 345.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0691316 Vali Loss: 0.0783091 Test Loss: 0.0898682\n",
      "Validation loss decreased (0.078737 --> 0.078309).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0690016\n",
      "\tspeed: 0.0406s/iter; left time: 784.3569s\n",
      "\titers: 200, epoch: 14 | loss: 0.0711716\n",
      "\tspeed: 0.0181s/iter; left time: 347.1951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0685913 Vali Loss: 0.0783116 Test Loss: 0.0919532\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0656164\n",
      "\tspeed: 0.0390s/iter; left time: 744.0563s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713738\n",
      "\tspeed: 0.0180s/iter; left time: 342.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0685032 Vali Loss: 0.0786223 Test Loss: 0.0913661\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0695635\n",
      "\tspeed: 0.0379s/iter; left time: 715.5347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691783\n",
      "\tspeed: 0.0177s/iter; left time: 332.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0680074 Vali Loss: 0.0780811 Test Loss: 0.0919043\n",
      "Validation loss decreased (0.078309 --> 0.078081).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0680425\n",
      "\tspeed: 0.0395s/iter; left time: 736.1828s\n",
      "\titers: 200, epoch: 17 | loss: 0.0696930\n",
      "\tspeed: 0.0195s/iter; left time: 361.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0678470 Vali Loss: 0.0775457 Test Loss: 0.0893896\n",
      "Validation loss decreased (0.078081 --> 0.077546).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0698916\n",
      "\tspeed: 0.0397s/iter; left time: 730.7978s\n",
      "\titers: 200, epoch: 18 | loss: 0.0676719\n",
      "\tspeed: 0.0184s/iter; left time: 337.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0677600 Vali Loss: 0.0777570 Test Loss: 0.0909423\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0653757\n",
      "\tspeed: 0.0391s/iter; left time: 711.2592s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676356\n",
      "\tspeed: 0.0182s/iter; left time: 329.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0675428 Vali Loss: 0.0773521 Test Loss: 0.0890149\n",
      "Validation loss decreased (0.077546 --> 0.077352).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0683559\n",
      "\tspeed: 0.0398s/iter; left time: 714.4407s\n",
      "\titers: 200, epoch: 20 | loss: 0.0639949\n",
      "\tspeed: 0.0180s/iter; left time: 320.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0676722 Vali Loss: 0.0775077 Test Loss: 0.0910440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0646337\n",
      "\tspeed: 0.0384s/iter; left time: 680.4631s\n",
      "\titers: 200, epoch: 21 | loss: 0.0659115\n",
      "\tspeed: 0.0176s/iter; left time: 311.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0672509 Vali Loss: 0.0776907 Test Loss: 0.0908001\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0670489\n",
      "\tspeed: 0.0382s/iter; left time: 669.3835s\n",
      "\titers: 200, epoch: 22 | loss: 0.0742496\n",
      "\tspeed: 0.0183s/iter; left time: 318.5510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0671914 Vali Loss: 0.0771561 Test Loss: 0.0883760\n",
      "Validation loss decreased (0.077352 --> 0.077156).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0651396\n",
      "\tspeed: 0.0397s/iter; left time: 687.0519s\n",
      "\titers: 200, epoch: 23 | loss: 0.0670115\n",
      "\tspeed: 0.0178s/iter; left time: 305.7846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0670595 Vali Loss: 0.0775332 Test Loss: 0.0899414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0732589\n",
      "\tspeed: 0.0391s/iter; left time: 667.1251s\n",
      "\titers: 200, epoch: 24 | loss: 0.0654945\n",
      "\tspeed: 0.0178s/iter; left time: 301.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0669309 Vali Loss: 0.0774002 Test Loss: 0.0899760\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0684945\n",
      "\tspeed: 0.0430s/iter; left time: 724.8585s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701072\n",
      "\tspeed: 0.0183s/iter; left time: 306.3342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0669362 Vali Loss: 0.0772586 Test Loss: 0.0891542\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0694126\n",
      "\tspeed: 0.0392s/iter; left time: 650.9989s\n",
      "\titers: 200, epoch: 26 | loss: 0.0657393\n",
      "\tspeed: 0.0179s/iter; left time: 295.2251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0668841 Vali Loss: 0.0774661 Test Loss: 0.0903360\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0636524\n",
      "\tspeed: 0.0428s/iter; left time: 701.9727s\n",
      "\titers: 200, epoch: 27 | loss: 0.0675355\n",
      "\tspeed: 0.0183s/iter; left time: 298.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0667550 Vali Loss: 0.0773848 Test Loss: 0.0904554\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0638153\n",
      "\tspeed: 0.0392s/iter; left time: 634.4178s\n",
      "\titers: 200, epoch: 28 | loss: 0.0673073\n",
      "\tspeed: 0.0188s/iter; left time: 301.6964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0667330 Vali Loss: 0.0773026 Test Loss: 0.0881627\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0657105\n",
      "\tspeed: 0.0424s/iter; left time: 676.9987s\n",
      "\titers: 200, epoch: 29 | loss: 0.0671053\n",
      "\tspeed: 0.0182s/iter; left time: 289.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0667498 Vali Loss: 0.0774495 Test Loss: 0.0902981\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0669222\n",
      "\tspeed: 0.0401s/iter; left time: 631.0496s\n",
      "\titers: 200, epoch: 30 | loss: 0.0673720\n",
      "\tspeed: 0.0181s/iter; left time: 282.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0666635 Vali Loss: 0.0774009 Test Loss: 0.0905739\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0634968\n",
      "\tspeed: 0.0389s/iter; left time: 603.3196s\n",
      "\titers: 200, epoch: 31 | loss: 0.0644372\n",
      "\tspeed: 0.0176s/iter; left time: 271.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0667213 Vali Loss: 0.0772319 Test Loss: 0.0896221\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0664342\n",
      "\tspeed: 0.0404s/iter; left time: 617.8321s\n",
      "\titers: 200, epoch: 32 | loss: 0.0692329\n",
      "\tspeed: 0.0180s/iter; left time: 274.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0664226 Vali Loss: 0.0772566 Test Loss: 0.0898893\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022333160042762756, rmse:0.14944283664226532, mae:0.0883760005235672, rse:0.5788062810897827\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2338009\n",
      "\tspeed: 0.0201s/iter; left time: 446.0482s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113497\n",
      "\tspeed: 0.0178s/iter; left time: 393.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.2351485 Vali Loss: 0.1777055 Test Loss: 0.1820173\n",
      "Validation loss decreased (inf --> 0.177705).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1296885\n",
      "\tspeed: 0.0404s/iter; left time: 888.7276s\n",
      "\titers: 200, epoch: 2 | loss: 0.1060445\n",
      "\tspeed: 0.0175s/iter; left time: 383.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1309497 Vali Loss: 0.1010024 Test Loss: 0.1117636\n",
      "Validation loss decreased (0.177705 --> 0.101002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898933\n",
      "\tspeed: 0.0445s/iter; left time: 968.0530s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850986\n",
      "\tspeed: 0.0180s/iter; left time: 390.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0903900 Vali Loss: 0.0884563 Test Loss: 0.0977771\n",
      "Validation loss decreased (0.101002 --> 0.088456).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0851167\n",
      "\tspeed: 0.0404s/iter; left time: 869.0622s\n",
      "\titers: 200, epoch: 4 | loss: 0.0821580\n",
      "\tspeed: 0.0177s/iter; left time: 379.3091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0821500 Vali Loss: 0.0849737 Test Loss: 0.0932884\n",
      "Validation loss decreased (0.088456 --> 0.084974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0837977\n",
      "\tspeed: 0.0413s/iter; left time: 880.7097s\n",
      "\titers: 200, epoch: 5 | loss: 0.0703436\n",
      "\tspeed: 0.0178s/iter; left time: 378.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0775127 Vali Loss: 0.0828958 Test Loss: 0.0914282\n",
      "Validation loss decreased (0.084974 --> 0.082896).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0745545\n",
      "\tspeed: 0.0410s/iter; left time: 863.7999s\n",
      "\titers: 200, epoch: 6 | loss: 0.0744729\n",
      "\tspeed: 0.0179s/iter; left time: 375.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0745978 Vali Loss: 0.0821939 Test Loss: 0.0909900\n",
      "Validation loss decreased (0.082896 --> 0.082194).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731700\n",
      "\tspeed: 0.0425s/iter; left time: 886.7511s\n",
      "\titers: 200, epoch: 7 | loss: 0.0701108\n",
      "\tspeed: 0.0201s/iter; left time: 416.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0730689 Vali Loss: 0.0816647 Test Loss: 0.0913772\n",
      "Validation loss decreased (0.082194 --> 0.081665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0700859\n",
      "\tspeed: 0.0437s/iter; left time: 900.9994s\n",
      "\titers: 200, epoch: 8 | loss: 0.0771661\n",
      "\tspeed: 0.0186s/iter; left time: 381.6433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0716500 Vali Loss: 0.0805202 Test Loss: 0.0901807\n",
      "Validation loss decreased (0.081665 --> 0.080520).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721290\n",
      "\tspeed: 0.0404s/iter; left time: 824.8038s\n",
      "\titers: 200, epoch: 9 | loss: 0.0726074\n",
      "\tspeed: 0.0179s/iter; left time: 364.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0708523 Vali Loss: 0.0799291 Test Loss: 0.0895342\n",
      "Validation loss decreased (0.080520 --> 0.079929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0701376\n",
      "\tspeed: 0.0430s/iter; left time: 868.5910s\n",
      "\titers: 200, epoch: 10 | loss: 0.0696241\n",
      "\tspeed: 0.0179s/iter; left time: 358.7377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0701862 Vali Loss: 0.0797360 Test Loss: 0.0909912\n",
      "Validation loss decreased (0.079929 --> 0.079736).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727235\n",
      "\tspeed: 0.0442s/iter; left time: 882.4450s\n",
      "\titers: 200, epoch: 11 | loss: 0.0719530\n",
      "\tspeed: 0.0210s/iter; left time: 418.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0696189 Vali Loss: 0.0792079 Test Loss: 0.0916442\n",
      "Validation loss decreased (0.079736 --> 0.079208).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0694411\n",
      "\tspeed: 0.0397s/iter; left time: 784.4346s\n",
      "\titers: 200, epoch: 12 | loss: 0.0701601\n",
      "\tspeed: 0.0177s/iter; left time: 347.1533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0691945 Vali Loss: 0.0792702 Test Loss: 0.0921250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0706597\n",
      "\tspeed: 0.0387s/iter; left time: 756.1448s\n",
      "\titers: 200, epoch: 13 | loss: 0.0664091\n",
      "\tspeed: 0.0177s/iter; left time: 344.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0686682 Vali Loss: 0.0784566 Test Loss: 0.0906340\n",
      "Validation loss decreased (0.079208 --> 0.078457).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0664055\n",
      "\tspeed: 0.0405s/iter; left time: 782.2171s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713549\n",
      "\tspeed: 0.0185s/iter; left time: 355.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0684731 Vali Loss: 0.0782182 Test Loss: 0.0892464\n",
      "Validation loss decreased (0.078457 --> 0.078218).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0699410\n",
      "\tspeed: 0.0424s/iter; left time: 809.3043s\n",
      "\titers: 200, epoch: 15 | loss: 0.0682169\n",
      "\tspeed: 0.0211s/iter; left time: 399.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0684699 Vali Loss: 0.0780147 Test Loss: 0.0898599\n",
      "Validation loss decreased (0.078218 --> 0.078015).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0680146\n",
      "\tspeed: 0.0397s/iter; left time: 747.6787s\n",
      "\titers: 200, epoch: 16 | loss: 0.0677583\n",
      "\tspeed: 0.0177s/iter; left time: 332.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0680419 Vali Loss: 0.0782818 Test Loss: 0.0908714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0671236\n",
      "\tspeed: 0.0390s/iter; left time: 725.9557s\n",
      "\titers: 200, epoch: 17 | loss: 0.0664326\n",
      "\tspeed: 0.0178s/iter; left time: 329.8612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0679523 Vali Loss: 0.0789498 Test Loss: 0.0928031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0618326\n",
      "\tspeed: 0.0393s/iter; left time: 724.1540s\n",
      "\titers: 200, epoch: 18 | loss: 0.0646246\n",
      "\tspeed: 0.0177s/iter; left time: 323.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0678683 Vali Loss: 0.0786893 Test Loss: 0.0923784\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0697901\n",
      "\tspeed: 0.0403s/iter; left time: 732.7224s\n",
      "\titers: 200, epoch: 19 | loss: 0.0634456\n",
      "\tspeed: 0.0181s/iter; left time: 327.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0675773 Vali Loss: 0.0775630 Test Loss: 0.0896100\n",
      "Validation loss decreased (0.078015 --> 0.077563).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0713500\n",
      "\tspeed: 0.0420s/iter; left time: 754.6242s\n",
      "\titers: 200, epoch: 20 | loss: 0.0695355\n",
      "\tspeed: 0.0212s/iter; left time: 377.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0675087 Vali Loss: 0.0786587 Test Loss: 0.0923917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0657799\n",
      "\tspeed: 0.0433s/iter; left time: 767.9694s\n",
      "\titers: 200, epoch: 21 | loss: 0.0677098\n",
      "\tspeed: 0.0177s/iter; left time: 312.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0672962 Vali Loss: 0.0777801 Test Loss: 0.0899067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0690822\n",
      "\tspeed: 0.0385s/iter; left time: 674.6683s\n",
      "\titers: 200, epoch: 22 | loss: 0.0640728\n",
      "\tspeed: 0.0176s/iter; left time: 307.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0672103 Vali Loss: 0.0775899 Test Loss: 0.0897816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0701658\n",
      "\tspeed: 0.0426s/iter; left time: 737.0696s\n",
      "\titers: 200, epoch: 23 | loss: 0.0661751\n",
      "\tspeed: 0.0180s/iter; left time: 309.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0670811 Vali Loss: 0.0779882 Test Loss: 0.0916405\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0700050\n",
      "\tspeed: 0.0426s/iter; left time: 726.5921s\n",
      "\titers: 200, epoch: 24 | loss: 0.0684151\n",
      "\tspeed: 0.0180s/iter; left time: 306.0768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0671400 Vali Loss: 0.0772222 Test Loss: 0.0890531\n",
      "Validation loss decreased (0.077563 --> 0.077222).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0648551\n",
      "\tspeed: 0.0425s/iter; left time: 716.7336s\n",
      "\titers: 200, epoch: 25 | loss: 0.0685759\n",
      "\tspeed: 0.0183s/iter; left time: 305.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0671076 Vali Loss: 0.0775080 Test Loss: 0.0902300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0675120\n",
      "\tspeed: 0.0394s/iter; left time: 655.7062s\n",
      "\titers: 200, epoch: 26 | loss: 0.0694718\n",
      "\tspeed: 0.0177s/iter; left time: 292.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0669079 Vali Loss: 0.0777307 Test Loss: 0.0908990\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0634031\n",
      "\tspeed: 0.0381s/iter; left time: 625.6566s\n",
      "\titers: 200, epoch: 27 | loss: 0.0635816\n",
      "\tspeed: 0.0177s/iter; left time: 288.7122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0668347 Vali Loss: 0.0775759 Test Loss: 0.0907329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0687936\n",
      "\tspeed: 0.0401s/iter; left time: 648.8057s\n",
      "\titers: 200, epoch: 28 | loss: 0.0681904\n",
      "\tspeed: 0.0177s/iter; left time: 285.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0668545 Vali Loss: 0.0777343 Test Loss: 0.0911858\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0675881\n",
      "\tspeed: 0.0416s/iter; left time: 664.1756s\n",
      "\titers: 200, epoch: 29 | loss: 0.0632508\n",
      "\tspeed: 0.0197s/iter; left time: 312.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0667225 Vali Loss: 0.0780558 Test Loss: 0.0921468\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0664763\n",
      "\tspeed: 0.0387s/iter; left time: 609.6658s\n",
      "\titers: 200, epoch: 30 | loss: 0.0651597\n",
      "\tspeed: 0.0179s/iter; left time: 279.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0666217 Vali Loss: 0.0772186 Test Loss: 0.0897463\n",
      "Validation loss decreased (0.077222 --> 0.077219).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0678580\n",
      "\tspeed: 0.0407s/iter; left time: 631.5925s\n",
      "\titers: 200, epoch: 31 | loss: 0.0678781\n",
      "\tspeed: 0.0185s/iter; left time: 284.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0666143 Vali Loss: 0.0780442 Test Loss: 0.0923045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0662480\n",
      "\tspeed: 0.0398s/iter; left time: 608.8923s\n",
      "\titers: 200, epoch: 32 | loss: 0.0668110\n",
      "\tspeed: 0.0179s/iter; left time: 271.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0668373 Vali Loss: 0.0774316 Test Loss: 0.0905306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0657418\n",
      "\tspeed: 0.0394s/iter; left time: 593.4808s\n",
      "\titers: 200, epoch: 33 | loss: 0.0670040\n",
      "\tspeed: 0.0178s/iter; left time: 266.7652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0665792 Vali Loss: 0.0772628 Test Loss: 0.0899137\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0633922\n",
      "\tspeed: 0.0398s/iter; left time: 590.6545s\n",
      "\titers: 200, epoch: 34 | loss: 0.0681318\n",
      "\tspeed: 0.0207s/iter; left time: 304.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0665149 Vali Loss: 0.0776413 Test Loss: 0.0905718\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645623\n",
      "\tspeed: 0.0439s/iter; left time: 641.5640s\n",
      "\titers: 200, epoch: 35 | loss: 0.0610137\n",
      "\tspeed: 0.0195s/iter; left time: 282.4944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0667504 Vali Loss: 0.0775892 Test Loss: 0.0910387\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0649652\n",
      "\tspeed: 0.0396s/iter; left time: 570.7519s\n",
      "\titers: 200, epoch: 36 | loss: 0.0659663\n",
      "\tspeed: 0.0182s/iter; left time: 260.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0664823 Vali Loss: 0.0775485 Test Loss: 0.0911583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0650879\n",
      "\tspeed: 0.0396s/iter; left time: 561.7855s\n",
      "\titers: 200, epoch: 37 | loss: 0.0669365\n",
      "\tspeed: 0.0178s/iter; left time: 249.9567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0665093 Vali Loss: 0.0773734 Test Loss: 0.0903130\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0664747\n",
      "\tspeed: 0.0404s/iter; left time: 564.1421s\n",
      "\titers: 200, epoch: 38 | loss: 0.0678473\n",
      "\tspeed: 0.0191s/iter; left time: 263.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0665654 Vali Loss: 0.0774224 Test Loss: 0.0905910\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0640347\n",
      "\tspeed: 0.0406s/iter; left time: 557.8665s\n",
      "\titers: 200, epoch: 39 | loss: 0.0625794\n",
      "\tspeed: 0.0179s/iter; left time: 243.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0666471 Vali Loss: 0.0774096 Test Loss: 0.0905216\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0646422\n",
      "\tspeed: 0.0419s/iter; left time: 566.2285s\n",
      "\titers: 200, epoch: 40 | loss: 0.0696381\n",
      "\tspeed: 0.0179s/iter; left time: 239.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0665738 Vali Loss: 0.0775945 Test Loss: 0.0911420\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023340126499533653, rmse:0.15277475118637085, mae:0.08974632620811462, rse:0.5917111039161682\n",
      "Intermediate time for FR and pred_len 168: 00h:07m:13.42s\n",
      "Intermediate time for FR: 00h:28m:30.81s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2560055\n",
      "\tspeed: 0.0304s/iter; left time: 676.9225s\n",
      "\titers: 200, epoch: 1 | loss: 0.2423811\n",
      "\tspeed: 0.0175s/iter; left time: 388.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.2639609 Vali Loss: 0.1822851 Test Loss: 0.1915715\n",
      "Validation loss decreased (inf --> 0.182285).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1499175\n",
      "\tspeed: 0.0392s/iter; left time: 865.6721s\n",
      "\titers: 200, epoch: 2 | loss: 0.1110561\n",
      "\tspeed: 0.0175s/iter; left time: 384.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.1521612 Vali Loss: 0.0901437 Test Loss: 0.0920071\n",
      "Validation loss decreased (0.182285 --> 0.090144).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0964962\n",
      "\tspeed: 0.0376s/iter; left time: 822.0139s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906514\n",
      "\tspeed: 0.0176s/iter; left time: 383.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0976476 Vali Loss: 0.0847392 Test Loss: 0.0874494\n",
      "Validation loss decreased (0.090144 --> 0.084739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0864783\n",
      "\tspeed: 0.0376s/iter; left time: 814.1386s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808783\n",
      "\tspeed: 0.0214s/iter; left time: 461.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0859300 Vali Loss: 0.0745625 Test Loss: 0.0767037\n",
      "Validation loss decreased (0.084739 --> 0.074563).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772275\n",
      "\tspeed: 0.0386s/iter; left time: 825.7412s\n",
      "\titers: 200, epoch: 5 | loss: 0.0778586\n",
      "\tspeed: 0.0175s/iter; left time: 372.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0791329 Vali Loss: 0.0722122 Test Loss: 0.0735523\n",
      "Validation loss decreased (0.074563 --> 0.072212).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728484\n",
      "\tspeed: 0.0382s/iter; left time: 810.0153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0703937\n",
      "\tspeed: 0.0174s/iter; left time: 367.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0749529 Vali Loss: 0.0680712 Test Loss: 0.0702668\n",
      "Validation loss decreased (0.072212 --> 0.068071).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0738745\n",
      "\tspeed: 0.0382s/iter; left time: 800.5918s\n",
      "\titers: 200, epoch: 7 | loss: 0.0698383\n",
      "\tspeed: 0.0211s/iter; left time: 440.1896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0722505 Vali Loss: 0.0665125 Test Loss: 0.0687683\n",
      "Validation loss decreased (0.068071 --> 0.066513).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0688370\n",
      "\tspeed: 0.0385s/iter; left time: 797.6860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0689583\n",
      "\tspeed: 0.0188s/iter; left time: 387.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0702076 Vali Loss: 0.0653898 Test Loss: 0.0675688\n",
      "Validation loss decreased (0.066513 --> 0.065390).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0647229\n",
      "\tspeed: 0.0357s/iter; left time: 732.6824s\n",
      "\titers: 200, epoch: 9 | loss: 0.0688971\n",
      "\tspeed: 0.0173s/iter; left time: 352.7447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0684367 Vali Loss: 0.0633853 Test Loss: 0.0661179\n",
      "Validation loss decreased (0.065390 --> 0.063385).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0661676\n",
      "\tspeed: 0.0369s/iter; left time: 747.5107s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664062\n",
      "\tspeed: 0.0181s/iter; left time: 366.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0671174 Vali Loss: 0.0630891 Test Loss: 0.0654256\n",
      "Validation loss decreased (0.063385 --> 0.063089).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0693754\n",
      "\tspeed: 0.0375s/iter; left time: 752.4592s\n",
      "\titers: 200, epoch: 11 | loss: 0.0624651\n",
      "\tspeed: 0.0172s/iter; left time: 343.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0662988 Vali Loss: 0.0635253 Test Loss: 0.0655094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611211\n",
      "\tspeed: 0.0387s/iter; left time: 766.8558s\n",
      "\titers: 200, epoch: 12 | loss: 0.0669602\n",
      "\tspeed: 0.0178s/iter; left time: 351.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0656425 Vali Loss: 0.0622943 Test Loss: 0.0649446\n",
      "Validation loss decreased (0.063089 --> 0.062294).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0642260\n",
      "\tspeed: 0.0356s/iter; left time: 698.5475s\n",
      "\titers: 200, epoch: 13 | loss: 0.0644801\n",
      "\tspeed: 0.0172s/iter; left time: 335.9136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0647798 Vali Loss: 0.0621777 Test Loss: 0.0645988\n",
      "Validation loss decreased (0.062294 --> 0.062178).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0674695\n",
      "\tspeed: 0.0360s/iter; left time: 697.7282s\n",
      "\titers: 200, epoch: 14 | loss: 0.0632765\n",
      "\tspeed: 0.0189s/iter; left time: 365.5181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0646523 Vali Loss: 0.0618180 Test Loss: 0.0642300\n",
      "Validation loss decreased (0.062178 --> 0.061818).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0655746\n",
      "\tspeed: 0.0392s/iter; left time: 752.1274s\n",
      "\titers: 200, epoch: 15 | loss: 0.0638550\n",
      "\tspeed: 0.0174s/iter; left time: 331.8465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0637141 Vali Loss: 0.0608835 Test Loss: 0.0631070\n",
      "Validation loss decreased (0.061818 --> 0.060883).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0640039\n",
      "\tspeed: 0.0383s/iter; left time: 726.0784s\n",
      "\titers: 200, epoch: 16 | loss: 0.0642456\n",
      "\tspeed: 0.0199s/iter; left time: 374.5112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0636292 Vali Loss: 0.0608949 Test Loss: 0.0631435\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685354\n",
      "\tspeed: 0.0361s/iter; left time: 676.4537s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637547\n",
      "\tspeed: 0.0173s/iter; left time: 321.1864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0630940 Vali Loss: 0.0606412 Test Loss: 0.0629768\n",
      "Validation loss decreased (0.060883 --> 0.060641).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0598314\n",
      "\tspeed: 0.0415s/iter; left time: 766.9315s\n",
      "\titers: 200, epoch: 18 | loss: 0.0647024\n",
      "\tspeed: 0.0233s/iter; left time: 427.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0630775 Vali Loss: 0.0606949 Test Loss: 0.0630801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0620685\n",
      "\tspeed: 0.0358s/iter; left time: 653.1507s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674284\n",
      "\tspeed: 0.0176s/iter; left time: 320.4150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0624383 Vali Loss: 0.0603855 Test Loss: 0.0626716\n",
      "Validation loss decreased (0.060641 --> 0.060385).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621745\n",
      "\tspeed: 0.0359s/iter; left time: 648.3252s\n",
      "\titers: 200, epoch: 20 | loss: 0.0610410\n",
      "\tspeed: 0.0188s/iter; left time: 337.8408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0623783 Vali Loss: 0.0597838 Test Loss: 0.0622265\n",
      "Validation loss decreased (0.060385 --> 0.059784).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0643027\n",
      "\tspeed: 0.0386s/iter; left time: 688.3263s\n",
      "\titers: 200, epoch: 21 | loss: 0.0635789\n",
      "\tspeed: 0.0193s/iter; left time: 342.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0620359 Vali Loss: 0.0599911 Test Loss: 0.0622726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0596088\n",
      "\tspeed: 0.0380s/iter; left time: 668.4387s\n",
      "\titers: 200, epoch: 22 | loss: 0.0565989\n",
      "\tspeed: 0.0176s/iter; left time: 307.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0619664 Vali Loss: 0.0603789 Test Loss: 0.0627585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0617142\n",
      "\tspeed: 0.0367s/iter; left time: 637.1185s\n",
      "\titers: 200, epoch: 23 | loss: 0.0577852\n",
      "\tspeed: 0.0175s/iter; left time: 302.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0620533 Vali Loss: 0.0601866 Test Loss: 0.0625348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0658285\n",
      "\tspeed: 0.0392s/iter; left time: 671.5639s\n",
      "\titers: 200, epoch: 24 | loss: 0.0624162\n",
      "\tspeed: 0.0214s/iter; left time: 364.0427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0617895 Vali Loss: 0.0595263 Test Loss: 0.0618030\n",
      "Validation loss decreased (0.059784 --> 0.059526).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0604893\n",
      "\tspeed: 0.0438s/iter; left time: 741.8350s\n",
      "\titers: 200, epoch: 25 | loss: 0.0644202\n",
      "\tspeed: 0.0229s/iter; left time: 385.8357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0616262 Vali Loss: 0.0594431 Test Loss: 0.0618435\n",
      "Validation loss decreased (0.059526 --> 0.059443).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0633843\n",
      "\tspeed: 0.0404s/iter; left time: 675.5006s\n",
      "\titers: 200, epoch: 26 | loss: 0.0642667\n",
      "\tspeed: 0.0203s/iter; left time: 336.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0613934 Vali Loss: 0.0597313 Test Loss: 0.0621125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0635059\n",
      "\tspeed: 0.0372s/iter; left time: 612.8952s\n",
      "\titers: 200, epoch: 27 | loss: 0.0648736\n",
      "\tspeed: 0.0173s/iter; left time: 282.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0616678 Vali Loss: 0.0593503 Test Loss: 0.0616880\n",
      "Validation loss decreased (0.059443 --> 0.059350).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0627745\n",
      "\tspeed: 0.0388s/iter; left time: 630.8490s\n",
      "\titers: 200, epoch: 28 | loss: 0.0599788\n",
      "\tspeed: 0.0176s/iter; left time: 283.5790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0613947 Vali Loss: 0.0594047 Test Loss: 0.0617809\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0639490\n",
      "\tspeed: 0.0396s/iter; left time: 634.7008s\n",
      "\titers: 200, epoch: 29 | loss: 0.0592804\n",
      "\tspeed: 0.0202s/iter; left time: 321.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0612338 Vali Loss: 0.0593479 Test Loss: 0.0617195\n",
      "Validation loss decreased (0.059350 --> 0.059348).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0607678\n",
      "\tspeed: 0.0377s/iter; left time: 596.4333s\n",
      "\titers: 200, epoch: 30 | loss: 0.0641361\n",
      "\tspeed: 0.0175s/iter; left time: 274.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0611303 Vali Loss: 0.0593081 Test Loss: 0.0616164\n",
      "Validation loss decreased (0.059348 --> 0.059308).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0588564\n",
      "\tspeed: 0.0376s/iter; left time: 585.0672s\n",
      "\titers: 200, epoch: 31 | loss: 0.0648428\n",
      "\tspeed: 0.0173s/iter; left time: 268.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0613387 Vali Loss: 0.0591463 Test Loss: 0.0613821\n",
      "Validation loss decreased (0.059308 --> 0.059146).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0604499\n",
      "\tspeed: 0.0367s/iter; left time: 564.1100s\n",
      "\titers: 200, epoch: 32 | loss: 0.0640636\n",
      "\tspeed: 0.0172s/iter; left time: 262.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0612083 Vali Loss: 0.0594587 Test Loss: 0.0617125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0624675\n",
      "\tspeed: 0.0349s/iter; left time: 528.0813s\n",
      "\titers: 200, epoch: 33 | loss: 0.0600911\n",
      "\tspeed: 0.0172s/iter; left time: 258.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0609271 Vali Loss: 0.0592494 Test Loss: 0.0614855\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0635118\n",
      "\tspeed: 0.0358s/iter; left time: 533.0532s\n",
      "\titers: 200, epoch: 34 | loss: 0.0946214\n",
      "\tspeed: 0.0204s/iter; left time: 302.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0611602 Vali Loss: 0.0593447 Test Loss: 0.0616473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0602311\n",
      "\tspeed: 0.0366s/iter; left time: 538.1458s\n",
      "\titers: 200, epoch: 35 | loss: 0.0621813\n",
      "\tspeed: 0.0176s/iter; left time: 257.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0609819 Vali Loss: 0.0590882 Test Loss: 0.0613859\n",
      "Validation loss decreased (0.059146 --> 0.059088).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0620438\n",
      "\tspeed: 0.0380s/iter; left time: 548.8782s\n",
      "\titers: 200, epoch: 36 | loss: 0.0598730\n",
      "\tspeed: 0.0176s/iter; left time: 253.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0609751 Vali Loss: 0.0590834 Test Loss: 0.0613925\n",
      "Validation loss decreased (0.059088 --> 0.059083).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0600442\n",
      "\tspeed: 0.0404s/iter; left time: 575.3891s\n",
      "\titers: 200, epoch: 37 | loss: 0.0591222\n",
      "\tspeed: 0.0233s/iter; left time: 329.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0609594 Vali Loss: 0.0589771 Test Loss: 0.0613019\n",
      "Validation loss decreased (0.059083 --> 0.058977).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0589398\n",
      "\tspeed: 0.0386s/iter; left time: 540.5845s\n",
      "\titers: 200, epoch: 38 | loss: 0.0614082\n",
      "\tspeed: 0.0206s/iter; left time: 286.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0607794 Vali Loss: 0.0589334 Test Loss: 0.0612865\n",
      "Validation loss decreased (0.058977 --> 0.058933).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0574795\n",
      "\tspeed: 0.0394s/iter; left time: 542.6203s\n",
      "\titers: 200, epoch: 39 | loss: 0.0624223\n",
      "\tspeed: 0.0182s/iter; left time: 249.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0611033 Vali Loss: 0.0591056 Test Loss: 0.0613814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0639464\n",
      "\tspeed: 0.0355s/iter; left time: 481.2856s\n",
      "\titers: 200, epoch: 40 | loss: 0.0595626\n",
      "\tspeed: 0.0175s/iter; left time: 234.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0608663 Vali Loss: 0.0589405 Test Loss: 0.0612287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0621145\n",
      "\tspeed: 0.0387s/iter; left time: 516.7067s\n",
      "\titers: 200, epoch: 41 | loss: 0.0573874\n",
      "\tspeed: 0.0175s/iter; left time: 232.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0607561 Vali Loss: 0.0590657 Test Loss: 0.0614425\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0572144\n",
      "\tspeed: 0.0380s/iter; left time: 497.8001s\n",
      "\titers: 200, epoch: 42 | loss: 0.0644505\n",
      "\tspeed: 0.0188s/iter; left time: 244.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0607047 Vali Loss: 0.0591092 Test Loss: 0.0613679\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0579505\n",
      "\tspeed: 0.0389s/iter; left time: 502.0051s\n",
      "\titers: 200, epoch: 43 | loss: 0.0580008\n",
      "\tspeed: 0.0197s/iter; left time: 252.1301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0607837 Vali Loss: 0.0590627 Test Loss: 0.0613699\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0629449\n",
      "\tspeed: 0.0376s/iter; left time: 476.1771s\n",
      "\titers: 200, epoch: 44 | loss: 0.0596044\n",
      "\tspeed: 0.0173s/iter; left time: 217.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0606620 Vali Loss: 0.0589061 Test Loss: 0.0612458\n",
      "Validation loss decreased (0.058933 --> 0.058906).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0618322\n",
      "\tspeed: 0.0364s/iter; left time: 452.6790s\n",
      "\titers: 200, epoch: 45 | loss: 0.0619233\n",
      "\tspeed: 0.0174s/iter; left time: 214.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0607194 Vali Loss: 0.0589944 Test Loss: 0.0612786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0583248\n",
      "\tspeed: 0.0376s/iter; left time: 458.9229s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663955\n",
      "\tspeed: 0.0180s/iter; left time: 217.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0607617 Vali Loss: 0.0589031 Test Loss: 0.0611764\n",
      "Validation loss decreased (0.058906 --> 0.058903).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0660463\n",
      "\tspeed: 0.0403s/iter; left time: 483.5874s\n",
      "\titers: 200, epoch: 47 | loss: 0.0552468\n",
      "\tspeed: 0.0223s/iter; left time: 265.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0606627 Vali Loss: 0.0588262 Test Loss: 0.0611966\n",
      "Validation loss decreased (0.058903 --> 0.058826).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0637724\n",
      "\tspeed: 0.0386s/iter; left time: 454.2796s\n",
      "\titers: 200, epoch: 48 | loss: 0.0581999\n",
      "\tspeed: 0.0174s/iter; left time: 202.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0606510 Vali Loss: 0.0588008 Test Loss: 0.0611676\n",
      "Validation loss decreased (0.058826 --> 0.058801).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0612788\n",
      "\tspeed: 0.0370s/iter; left time: 427.6264s\n",
      "\titers: 200, epoch: 49 | loss: 0.0595845\n",
      "\tspeed: 0.0172s/iter; left time: 196.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0607609 Vali Loss: 0.0589493 Test Loss: 0.0612049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0606880\n",
      "\tspeed: 0.0359s/iter; left time: 406.4402s\n",
      "\titers: 200, epoch: 50 | loss: 0.0575103\n",
      "\tspeed: 0.0176s/iter; left time: 197.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0605927 Vali Loss: 0.0588233 Test Loss: 0.0611529\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0583223\n",
      "\tspeed: 0.0360s/iter; left time: 399.6193s\n",
      "\titers: 200, epoch: 51 | loss: 0.0564286\n",
      "\tspeed: 0.0175s/iter; left time: 193.0200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0606428 Vali Loss: 0.0589695 Test Loss: 0.0612331\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0586103\n",
      "\tspeed: 0.0362s/iter; left time: 393.3556s\n",
      "\titers: 200, epoch: 52 | loss: 0.0599242\n",
      "\tspeed: 0.0174s/iter; left time: 187.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0609928 Vali Loss: 0.0589494 Test Loss: 0.0612600\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0607768\n",
      "\tspeed: 0.0352s/iter; left time: 375.3503s\n",
      "\titers: 200, epoch: 53 | loss: 0.0578123\n",
      "\tspeed: 0.0172s/iter; left time: 181.9672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0605673 Vali Loss: 0.0589965 Test Loss: 0.0612734\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0582478\n",
      "\tspeed: 0.0351s/iter; left time: 365.7491s\n",
      "\titers: 200, epoch: 54 | loss: 0.0650805\n",
      "\tspeed: 0.0172s/iter; left time: 177.4844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0608260 Vali Loss: 0.0589558 Test Loss: 0.0612622\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0621394\n",
      "\tspeed: 0.0364s/iter; left time: 371.8522s\n",
      "\titers: 200, epoch: 55 | loss: 0.0649265\n",
      "\tspeed: 0.0209s/iter; left time: 211.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0605743 Vali Loss: 0.0588586 Test Loss: 0.0611447\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0603352\n",
      "\tspeed: 0.0409s/iter; left time: 408.6260s\n",
      "\titers: 200, epoch: 56 | loss: 0.0634415\n",
      "\tspeed: 0.0176s/iter; left time: 173.6850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0607421 Vali Loss: 0.0590274 Test Loss: 0.0612483\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0622949\n",
      "\tspeed: 0.0353s/iter; left time: 344.6568s\n",
      "\titers: 200, epoch: 57 | loss: 0.0601036\n",
      "\tspeed: 0.0175s/iter; left time: 168.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0606561 Vali Loss: 0.0588887 Test Loss: 0.0612124\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0599005\n",
      "\tspeed: 0.0364s/iter; left time: 347.3906s\n",
      "\titers: 200, epoch: 58 | loss: 0.0614105\n",
      "\tspeed: 0.0174s/iter; left time: 163.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0604505 Vali Loss: 0.0589556 Test Loss: 0.0612334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010705658234655857, rmse:0.1034681499004364, mae:0.061167631298303604, rse:0.3909551799297333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2627974\n",
      "\tspeed: 0.0193s/iter; left time: 430.5646s\n",
      "\titers: 200, epoch: 1 | loss: 0.2482974\n",
      "\tspeed: 0.0175s/iter; left time: 388.4034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.2667958 Vali Loss: 0.1863317 Test Loss: 0.1942592\n",
      "Validation loss decreased (inf --> 0.186332).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1461807\n",
      "\tspeed: 0.0373s/iter; left time: 824.3923s\n",
      "\titers: 200, epoch: 2 | loss: 0.1113860\n",
      "\tspeed: 0.0175s/iter; left time: 385.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1526986 Vali Loss: 0.0869366 Test Loss: 0.0887382\n",
      "Validation loss decreased (0.186332 --> 0.086937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0986181\n",
      "\tspeed: 0.0362s/iter; left time: 790.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901592\n",
      "\tspeed: 0.0183s/iter; left time: 398.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0963260 Vali Loss: 0.0807218 Test Loss: 0.0841014\n",
      "Validation loss decreased (0.086937 --> 0.080722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0871330\n",
      "\tspeed: 0.0402s/iter; left time: 870.2912s\n",
      "\titers: 200, epoch: 4 | loss: 0.0840114\n",
      "\tspeed: 0.0191s/iter; left time: 411.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0852837 Vali Loss: 0.0751896 Test Loss: 0.0769653\n",
      "Validation loss decreased (0.080722 --> 0.075190).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0768439\n",
      "\tspeed: 0.0388s/iter; left time: 830.3850s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793418\n",
      "\tspeed: 0.0175s/iter; left time: 373.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0780172 Vali Loss: 0.0714483 Test Loss: 0.0738530\n",
      "Validation loss decreased (0.075190 --> 0.071448).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0694878\n",
      "\tspeed: 0.0416s/iter; left time: 882.0605s\n",
      "\titers: 200, epoch: 6 | loss: 0.0743181\n",
      "\tspeed: 0.0201s/iter; left time: 422.7854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0743077 Vali Loss: 0.0710880 Test Loss: 0.0734069\n",
      "Validation loss decreased (0.071448 --> 0.071088).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744916\n",
      "\tspeed: 0.0365s/iter; left time: 765.6697s\n",
      "\titers: 200, epoch: 7 | loss: 0.0658048\n",
      "\tspeed: 0.0174s/iter; left time: 363.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0720179 Vali Loss: 0.0662823 Test Loss: 0.0683096\n",
      "Validation loss decreased (0.071088 --> 0.066282).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715183\n",
      "\tspeed: 0.0368s/iter; left time: 762.7043s\n",
      "\titers: 200, epoch: 8 | loss: 0.0724966\n",
      "\tspeed: 0.0177s/iter; left time: 365.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0697359 Vali Loss: 0.0648159 Test Loss: 0.0669165\n",
      "Validation loss decreased (0.066282 --> 0.064816).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0668630\n",
      "\tspeed: 0.0404s/iter; left time: 829.0244s\n",
      "\titers: 200, epoch: 9 | loss: 0.0695754\n",
      "\tspeed: 0.0205s/iter; left time: 418.1882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0680483 Vali Loss: 0.0635846 Test Loss: 0.0658263\n",
      "Validation loss decreased (0.064816 --> 0.063585).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0655731\n",
      "\tspeed: 0.0363s/iter; left time: 737.0032s\n",
      "\titers: 200, epoch: 10 | loss: 0.0673971\n",
      "\tspeed: 0.0181s/iter; left time: 365.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0670103 Vali Loss: 0.0635516 Test Loss: 0.0655961\n",
      "Validation loss decreased (0.063585 --> 0.063552).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0665270\n",
      "\tspeed: 0.0368s/iter; left time: 737.6568s\n",
      "\titers: 200, epoch: 11 | loss: 0.0609907\n",
      "\tspeed: 0.0179s/iter; left time: 356.4799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0659983 Vali Loss: 0.0625107 Test Loss: 0.0645274\n",
      "Validation loss decreased (0.063552 --> 0.062511).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692555\n",
      "\tspeed: 0.0361s/iter; left time: 716.5178s\n",
      "\titers: 200, epoch: 12 | loss: 0.0660140\n",
      "\tspeed: 0.0174s/iter; left time: 343.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0652268 Vali Loss: 0.0622787 Test Loss: 0.0640785\n",
      "Validation loss decreased (0.062511 --> 0.062279).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0641926\n",
      "\tspeed: 0.0361s/iter; left time: 708.6438s\n",
      "\titers: 200, epoch: 13 | loss: 0.0653889\n",
      "\tspeed: 0.0173s/iter; left time: 337.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0647603 Vali Loss: 0.0619080 Test Loss: 0.0636974\n",
      "Validation loss decreased (0.062279 --> 0.061908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0642686\n",
      "\tspeed: 0.0377s/iter; left time: 731.4140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605915\n",
      "\tspeed: 0.0173s/iter; left time: 332.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0643771 Vali Loss: 0.0613482 Test Loss: 0.0635745\n",
      "Validation loss decreased (0.061908 --> 0.061348).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0620587\n",
      "\tspeed: 0.0375s/iter; left time: 718.6670s\n",
      "\titers: 200, epoch: 15 | loss: 0.0655933\n",
      "\tspeed: 0.0175s/iter; left time: 333.3668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0638910 Vali Loss: 0.0607766 Test Loss: 0.0626828\n",
      "Validation loss decreased (0.061348 --> 0.060777).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618527\n",
      "\tspeed: 0.0381s/iter; left time: 720.9613s\n",
      "\titers: 200, epoch: 16 | loss: 0.0637665\n",
      "\tspeed: 0.0192s/iter; left time: 361.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0635206 Vali Loss: 0.0609402 Test Loss: 0.0630070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0652005\n",
      "\tspeed: 0.0368s/iter; left time: 688.1737s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630468\n",
      "\tspeed: 0.0173s/iter; left time: 321.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0629550 Vali Loss: 0.0602277 Test Loss: 0.0622284\n",
      "Validation loss decreased (0.060777 --> 0.060228).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679912\n",
      "\tspeed: 0.0367s/iter; left time: 679.1837s\n",
      "\titers: 200, epoch: 18 | loss: 0.0651876\n",
      "\tspeed: 0.0177s/iter; left time: 326.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0628191 Vali Loss: 0.0599023 Test Loss: 0.0619776\n",
      "Validation loss decreased (0.060228 --> 0.059902).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0635181\n",
      "\tspeed: 0.0361s/iter; left time: 658.7932s\n",
      "\titers: 200, epoch: 19 | loss: 0.0645638\n",
      "\tspeed: 0.0172s/iter; left time: 312.5175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0626648 Vali Loss: 0.0603637 Test Loss: 0.0622229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0580611\n",
      "\tspeed: 0.0381s/iter; left time: 686.6253s\n",
      "\titers: 200, epoch: 20 | loss: 0.0628925\n",
      "\tspeed: 0.0200s/iter; left time: 359.6547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0624406 Vali Loss: 0.0599697 Test Loss: 0.0619383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711100\n",
      "\tspeed: 0.0426s/iter; left time: 759.6886s\n",
      "\titers: 200, epoch: 21 | loss: 0.0645816\n",
      "\tspeed: 0.0222s/iter; left time: 393.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0621689 Vali Loss: 0.0596436 Test Loss: 0.0616355\n",
      "Validation loss decreased (0.059902 --> 0.059644).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0582503\n",
      "\tspeed: 0.0400s/iter; left time: 704.0043s\n",
      "\titers: 200, epoch: 22 | loss: 0.0627619\n",
      "\tspeed: 0.0187s/iter; left time: 326.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0621025 Vali Loss: 0.0594025 Test Loss: 0.0614220\n",
      "Validation loss decreased (0.059644 --> 0.059403).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0611445\n",
      "\tspeed: 0.0418s/iter; left time: 726.9927s\n",
      "\titers: 200, epoch: 23 | loss: 0.0618353\n",
      "\tspeed: 0.0187s/iter; left time: 323.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0618943 Vali Loss: 0.0593977 Test Loss: 0.0614119\n",
      "Validation loss decreased (0.059403 --> 0.059398).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0679248\n",
      "\tspeed: 0.0388s/iter; left time: 665.4331s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606133\n",
      "\tspeed: 0.0191s/iter; left time: 325.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0617276 Vali Loss: 0.0598767 Test Loss: 0.0617889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0623691\n",
      "\tspeed: 0.0383s/iter; left time: 647.9886s\n",
      "\titers: 200, epoch: 25 | loss: 0.0598570\n",
      "\tspeed: 0.0175s/iter; left time: 293.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0617205 Vali Loss: 0.0593523 Test Loss: 0.0613467\n",
      "Validation loss decreased (0.059398 --> 0.059352).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0600722\n",
      "\tspeed: 0.0369s/iter; left time: 615.9920s\n",
      "\titers: 200, epoch: 26 | loss: 0.0593836\n",
      "\tspeed: 0.0200s/iter; left time: 332.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0614930 Vali Loss: 0.0593502 Test Loss: 0.0612584\n",
      "Validation loss decreased (0.059352 --> 0.059350).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0632631\n",
      "\tspeed: 0.0401s/iter; left time: 660.4494s\n",
      "\titers: 200, epoch: 27 | loss: 0.0630781\n",
      "\tspeed: 0.0191s/iter; left time: 312.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0616397 Vali Loss: 0.0592269 Test Loss: 0.0612088\n",
      "Validation loss decreased (0.059350 --> 0.059227).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0618017\n",
      "\tspeed: 0.0413s/iter; left time: 670.4767s\n",
      "\titers: 200, epoch: 28 | loss: 0.0607987\n",
      "\tspeed: 0.0241s/iter; left time: 388.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0613251 Vali Loss: 0.0593490 Test Loss: 0.0612670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0644551\n",
      "\tspeed: 0.0413s/iter; left time: 662.2073s\n",
      "\titers: 200, epoch: 29 | loss: 0.0655226\n",
      "\tspeed: 0.0182s/iter; left time: 289.5898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0615183 Vali Loss: 0.0591007 Test Loss: 0.0611095\n",
      "Validation loss decreased (0.059227 --> 0.059101).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0664257\n",
      "\tspeed: 0.0381s/iter; left time: 601.9028s\n",
      "\titers: 200, epoch: 30 | loss: 0.0627920\n",
      "\tspeed: 0.0180s/iter; left time: 282.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0612978 Vali Loss: 0.0591229 Test Loss: 0.0610999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0620899\n",
      "\tspeed: 0.0423s/iter; left time: 659.8320s\n",
      "\titers: 200, epoch: 31 | loss: 0.0607894\n",
      "\tspeed: 0.0197s/iter; left time: 304.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0612123 Vali Loss: 0.0591392 Test Loss: 0.0611416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0620529\n",
      "\tspeed: 0.0431s/iter; left time: 661.4097s\n",
      "\titers: 200, epoch: 32 | loss: 0.0619041\n",
      "\tspeed: 0.0230s/iter; left time: 350.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0613713 Vali Loss: 0.0593856 Test Loss: 0.0613479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0619630\n",
      "\tspeed: 0.0427s/iter; left time: 646.0509s\n",
      "\titers: 200, epoch: 33 | loss: 0.0566477\n",
      "\tspeed: 0.0179s/iter; left time: 269.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0611536 Vali Loss: 0.0589994 Test Loss: 0.0610205\n",
      "Validation loss decreased (0.059101 --> 0.058999).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0623833\n",
      "\tspeed: 0.0391s/iter; left time: 582.7121s\n",
      "\titers: 200, epoch: 34 | loss: 0.0577790\n",
      "\tspeed: 0.0190s/iter; left time: 281.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0611065 Vali Loss: 0.0590976 Test Loss: 0.0610434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0605745\n",
      "\tspeed: 0.0366s/iter; left time: 537.4654s\n",
      "\titers: 200, epoch: 35 | loss: 0.0655310\n",
      "\tspeed: 0.0171s/iter; left time: 250.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0610947 Vali Loss: 0.0590545 Test Loss: 0.0609568\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0582355\n",
      "\tspeed: 0.0379s/iter; left time: 548.3079s\n",
      "\titers: 200, epoch: 36 | loss: 0.0577565\n",
      "\tspeed: 0.0197s/iter; left time: 282.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0610722 Vali Loss: 0.0593121 Test Loss: 0.0611070\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0573750\n",
      "\tspeed: 0.0389s/iter; left time: 554.3860s\n",
      "\titers: 200, epoch: 37 | loss: 0.0579213\n",
      "\tspeed: 0.0196s/iter; left time: 276.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0610631 Vali Loss: 0.0590559 Test Loss: 0.0610414\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0544301\n",
      "\tspeed: 0.0387s/iter; left time: 542.6548s\n",
      "\titers: 200, epoch: 38 | loss: 0.0596081\n",
      "\tspeed: 0.0200s/iter; left time: 278.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0608733 Vali Loss: 0.0589671 Test Loss: 0.0609717\n",
      "Validation loss decreased (0.058999 --> 0.058967).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0568072\n",
      "\tspeed: 0.0400s/iter; left time: 551.1060s\n",
      "\titers: 200, epoch: 39 | loss: 0.0630284\n",
      "\tspeed: 0.0197s/iter; left time: 269.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0608011 Vali Loss: 0.0588598 Test Loss: 0.0608266\n",
      "Validation loss decreased (0.058967 --> 0.058860).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0575882\n",
      "\tspeed: 0.0423s/iter; left time: 573.1905s\n",
      "\titers: 200, epoch: 40 | loss: 0.0650143\n",
      "\tspeed: 0.0207s/iter; left time: 278.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0608132 Vali Loss: 0.0588868 Test Loss: 0.0608633\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0590181\n",
      "\tspeed: 0.0393s/iter; left time: 524.9369s\n",
      "\titers: 200, epoch: 41 | loss: 0.0607992\n",
      "\tspeed: 0.0177s/iter; left time: 234.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0608190 Vali Loss: 0.0590502 Test Loss: 0.0609728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0619558\n",
      "\tspeed: 0.0364s/iter; left time: 477.3899s\n",
      "\titers: 200, epoch: 42 | loss: 0.0621211\n",
      "\tspeed: 0.0178s/iter; left time: 232.1458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0609334 Vali Loss: 0.0588145 Test Loss: 0.0608321\n",
      "Validation loss decreased (0.058860 --> 0.058814).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0615486\n",
      "\tspeed: 0.0403s/iter; left time: 519.6059s\n",
      "\titers: 200, epoch: 43 | loss: 0.0570586\n",
      "\tspeed: 0.0243s/iter; left time: 310.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0608828 Vali Loss: 0.0589712 Test Loss: 0.0609513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0568614\n",
      "\tspeed: 0.0402s/iter; left time: 508.7358s\n",
      "\titers: 200, epoch: 44 | loss: 0.0636867\n",
      "\tspeed: 0.0207s/iter; left time: 259.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0609143 Vali Loss: 0.0590896 Test Loss: 0.0609673\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0624496\n",
      "\tspeed: 0.0380s/iter; left time: 472.6744s\n",
      "\titers: 200, epoch: 45 | loss: 0.0557643\n",
      "\tspeed: 0.0186s/iter; left time: 229.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0607798 Vali Loss: 0.0588787 Test Loss: 0.0608122\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0582896\n",
      "\tspeed: 0.0423s/iter; left time: 517.2451s\n",
      "\titers: 200, epoch: 46 | loss: 0.0600299\n",
      "\tspeed: 0.0214s/iter; left time: 259.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606731 Vali Loss: 0.0587618 Test Loss: 0.0607486\n",
      "Validation loss decreased (0.058814 --> 0.058762).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0574329\n",
      "\tspeed: 0.0383s/iter; left time: 459.1380s\n",
      "\titers: 200, epoch: 47 | loss: 0.0574801\n",
      "\tspeed: 0.0172s/iter; left time: 204.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0608053 Vali Loss: 0.0589745 Test Loss: 0.0609324\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0612617\n",
      "\tspeed: 0.0409s/iter; left time: 481.2634s\n",
      "\titers: 200, epoch: 48 | loss: 0.0586047\n",
      "\tspeed: 0.0180s/iter; left time: 210.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0607525 Vali Loss: 0.0588990 Test Loss: 0.0608540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0599462\n",
      "\tspeed: 0.0435s/iter; left time: 502.7869s\n",
      "\titers: 200, epoch: 49 | loss: 0.0602446\n",
      "\tspeed: 0.0235s/iter; left time: 268.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0606914 Vali Loss: 0.0588749 Test Loss: 0.0607733\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0643789\n",
      "\tspeed: 0.0427s/iter; left time: 483.4032s\n",
      "\titers: 200, epoch: 50 | loss: 0.0623915\n",
      "\tspeed: 0.0201s/iter; left time: 225.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0606604 Vali Loss: 0.0589239 Test Loss: 0.0607977\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0569400\n",
      "\tspeed: 0.0386s/iter; left time: 428.7284s\n",
      "\titers: 200, epoch: 51 | loss: 0.0602231\n",
      "\tspeed: 0.0206s/iter; left time: 226.7860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0606344 Vali Loss: 0.0587940 Test Loss: 0.0607396\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0622999\n",
      "\tspeed: 0.0410s/iter; left time: 445.6390s\n",
      "\titers: 200, epoch: 52 | loss: 0.0640980\n",
      "\tspeed: 0.0183s/iter; left time: 197.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0606872 Vali Loss: 0.0587773 Test Loss: 0.0607380\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0584325\n",
      "\tspeed: 0.0368s/iter; left time: 391.5507s\n",
      "\titers: 200, epoch: 53 | loss: 0.0610537\n",
      "\tspeed: 0.0172s/iter; left time: 181.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0605868 Vali Loss: 0.0588708 Test Loss: 0.0607831\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0620976\n",
      "\tspeed: 0.0368s/iter; left time: 383.7663s\n",
      "\titers: 200, epoch: 54 | loss: 0.0603975\n",
      "\tspeed: 0.0174s/iter; left time: 179.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0606225 Vali Loss: 0.0587787 Test Loss: 0.0607135\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0620877\n",
      "\tspeed: 0.0369s/iter; left time: 376.9220s\n",
      "\titers: 200, epoch: 55 | loss: 0.0590931\n",
      "\tspeed: 0.0171s/iter; left time: 173.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0606608 Vali Loss: 0.0588166 Test Loss: 0.0607272\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0580562\n",
      "\tspeed: 0.0364s/iter; left time: 362.9874s\n",
      "\titers: 200, epoch: 56 | loss: 0.0539987\n",
      "\tspeed: 0.0195s/iter; left time: 192.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0605068 Vali Loss: 0.0587827 Test Loss: 0.0607081\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010598608292639256, rmse:0.10294954478740692, mae:0.0607486292719841, rse:0.3889956474304199\n",
      "Intermediate time for IT and pred_len 24: 00h:10m:58.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2604629\n",
      "\tspeed: 0.0422s/iter; left time: 940.2215s\n",
      "\titers: 200, epoch: 1 | loss: 0.2423152\n",
      "\tspeed: 0.0175s/iter; left time: 389.2494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.2648623 Vali Loss: 0.1834424 Test Loss: 0.1930739\n",
      "Validation loss decreased (inf --> 0.183442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1424379\n",
      "\tspeed: 0.0377s/iter; left time: 832.0443s\n",
      "\titers: 200, epoch: 2 | loss: 0.1129646\n",
      "\tspeed: 0.0175s/iter; left time: 384.7421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1525857 Vali Loss: 0.1033205 Test Loss: 0.1089858\n",
      "Validation loss decreased (0.183442 --> 0.103320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1093492\n",
      "\tspeed: 0.0408s/iter; left time: 890.7279s\n",
      "\titers: 200, epoch: 3 | loss: 0.1031741\n",
      "\tspeed: 0.0193s/iter; left time: 419.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1081475 Vali Loss: 0.0955844 Test Loss: 0.1005626\n",
      "Validation loss decreased (0.103320 --> 0.095584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0958332\n",
      "\tspeed: 0.0398s/iter; left time: 861.1281s\n",
      "\titers: 200, epoch: 4 | loss: 0.0928613\n",
      "\tspeed: 0.0176s/iter; left time: 379.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0971412 Vali Loss: 0.0887435 Test Loss: 0.0933526\n",
      "Validation loss decreased (0.095584 --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0926998\n",
      "\tspeed: 0.0376s/iter; left time: 805.6997s\n",
      "\titers: 200, epoch: 5 | loss: 0.0891793\n",
      "\tspeed: 0.0177s/iter; left time: 376.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0914521 Vali Loss: 0.0856440 Test Loss: 0.0892723\n",
      "Validation loss decreased (0.088743 --> 0.085644).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913657\n",
      "\tspeed: 0.0380s/iter; left time: 805.5923s\n",
      "\titers: 200, epoch: 6 | loss: 0.0861900\n",
      "\tspeed: 0.0179s/iter; left time: 376.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0882072 Vali Loss: 0.0826065 Test Loss: 0.0869915\n",
      "Validation loss decreased (0.085644 --> 0.082606).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0878516\n",
      "\tspeed: 0.0396s/iter; left time: 829.0945s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830736\n",
      "\tspeed: 0.0201s/iter; left time: 418.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0863684 Vali Loss: 0.0824323 Test Loss: 0.0853957\n",
      "Validation loss decreased (0.082606 --> 0.082432).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0853143\n",
      "\tspeed: 0.0396s/iter; left time: 821.8514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793520\n",
      "\tspeed: 0.0196s/iter; left time: 404.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0849917 Vali Loss: 0.0812135 Test Loss: 0.0853825\n",
      "Validation loss decreased (0.082432 --> 0.081214).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0831149\n",
      "\tspeed: 0.0377s/iter; left time: 772.7803s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795631\n",
      "\tspeed: 0.0176s/iter; left time: 360.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0847246 Vali Loss: 0.0808714 Test Loss: 0.0850799\n",
      "Validation loss decreased (0.081214 --> 0.080871).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0807580\n",
      "\tspeed: 0.0385s/iter; left time: 781.6510s\n",
      "\titers: 200, epoch: 10 | loss: 0.0867554\n",
      "\tspeed: 0.0177s/iter; left time: 356.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0833497 Vali Loss: 0.0810849 Test Loss: 0.0853150\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0853099\n",
      "\tspeed: 0.0401s/iter; left time: 804.0430s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809132\n",
      "\tspeed: 0.0214s/iter; left time: 427.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0829447 Vali Loss: 0.0799023 Test Loss: 0.0841955\n",
      "Validation loss decreased (0.080871 --> 0.079902).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0814938\n",
      "\tspeed: 0.0392s/iter; left time: 777.1048s\n",
      "\titers: 200, epoch: 12 | loss: 0.0847448\n",
      "\tspeed: 0.0182s/iter; left time: 358.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0822131 Vali Loss: 0.0804344 Test Loss: 0.0841287\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0809954\n",
      "\tspeed: 0.0373s/iter; left time: 731.8970s\n",
      "\titers: 200, epoch: 13 | loss: 0.0858219\n",
      "\tspeed: 0.0186s/iter; left time: 362.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0820751 Vali Loss: 0.0805065 Test Loss: 0.0840351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0806159\n",
      "\tspeed: 0.0364s/iter; left time: 706.4534s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795833\n",
      "\tspeed: 0.0175s/iter; left time: 337.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0816624 Vali Loss: 0.0804602 Test Loss: 0.0844575\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0779172\n",
      "\tspeed: 0.0378s/iter; left time: 725.1374s\n",
      "\titers: 200, epoch: 15 | loss: 0.0824445\n",
      "\tspeed: 0.0181s/iter; left time: 345.2149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0812928 Vali Loss: 0.0793254 Test Loss: 0.0834020\n",
      "Validation loss decreased (0.079902 --> 0.079325).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0927447\n",
      "\tspeed: 0.0375s/iter; left time: 709.8501s\n",
      "\titers: 200, epoch: 16 | loss: 0.0828852\n",
      "\tspeed: 0.0175s/iter; left time: 330.2680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0811191 Vali Loss: 0.0797241 Test Loss: 0.0843871\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0811357\n",
      "\tspeed: 0.0372s/iter; left time: 696.5983s\n",
      "\titers: 200, epoch: 17 | loss: 0.0798844\n",
      "\tspeed: 0.0175s/iter; left time: 324.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0809317 Vali Loss: 0.0797516 Test Loss: 0.0837846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797971\n",
      "\tspeed: 0.0382s/iter; left time: 707.2021s\n",
      "\titers: 200, epoch: 18 | loss: 0.0834154\n",
      "\tspeed: 0.0180s/iter; left time: 330.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0805756 Vali Loss: 0.0792588 Test Loss: 0.0833703\n",
      "Validation loss decreased (0.079325 --> 0.079259).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0777356\n",
      "\tspeed: 0.0405s/iter; left time: 740.5875s\n",
      "\titers: 200, epoch: 19 | loss: 0.0803758\n",
      "\tspeed: 0.0182s/iter; left time: 329.7680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0807877 Vali Loss: 0.0796320 Test Loss: 0.0839161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0809253\n",
      "\tspeed: 0.0384s/iter; left time: 692.1384s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807327\n",
      "\tspeed: 0.0199s/iter; left time: 356.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0803043 Vali Loss: 0.0803296 Test Loss: 0.0847105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814064\n",
      "\tspeed: 0.0368s/iter; left time: 656.5285s\n",
      "\titers: 200, epoch: 21 | loss: 0.0740589\n",
      "\tspeed: 0.0190s/iter; left time: 336.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0803020 Vali Loss: 0.0793213 Test Loss: 0.0837104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0788433\n",
      "\tspeed: 0.0380s/iter; left time: 669.0341s\n",
      "\titers: 200, epoch: 22 | loss: 0.0801094\n",
      "\tspeed: 0.0179s/iter; left time: 313.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0799116 Vali Loss: 0.0794162 Test Loss: 0.0836434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780965\n",
      "\tspeed: 0.0385s/iter; left time: 669.4752s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793583\n",
      "\tspeed: 0.0182s/iter; left time: 313.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0797848 Vali Loss: 0.0791958 Test Loss: 0.0836920\n",
      "Validation loss decreased (0.079259 --> 0.079196).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0816518\n",
      "\tspeed: 0.0412s/iter; left time: 706.5450s\n",
      "\titers: 200, epoch: 24 | loss: 0.0771318\n",
      "\tspeed: 0.0197s/iter; left time: 336.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0798217 Vali Loss: 0.0807391 Test Loss: 0.0849686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0804060\n",
      "\tspeed: 0.0379s/iter; left time: 642.0584s\n",
      "\titers: 200, epoch: 25 | loss: 0.0775783\n",
      "\tspeed: 0.0196s/iter; left time: 329.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0797370 Vali Loss: 0.0794826 Test Loss: 0.0838034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0790573\n",
      "\tspeed: 0.0396s/iter; left time: 661.3285s\n",
      "\titers: 200, epoch: 26 | loss: 0.0821203\n",
      "\tspeed: 0.0216s/iter; left time: 358.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0795945 Vali Loss: 0.0791850 Test Loss: 0.0836309\n",
      "Validation loss decreased (0.079196 --> 0.079185).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0807247\n",
      "\tspeed: 0.0399s/iter; left time: 657.2338s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761688\n",
      "\tspeed: 0.0189s/iter; left time: 310.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0795645 Vali Loss: 0.0788539 Test Loss: 0.0835670\n",
      "Validation loss decreased (0.079185 --> 0.078854).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0810647\n",
      "\tspeed: 0.0382s/iter; left time: 621.0593s\n",
      "\titers: 200, epoch: 28 | loss: 0.0775783\n",
      "\tspeed: 0.0175s/iter; left time: 281.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0794294 Vali Loss: 0.0790341 Test Loss: 0.0836024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0791476\n",
      "\tspeed: 0.0372s/iter; left time: 596.9193s\n",
      "\titers: 200, epoch: 29 | loss: 0.0792168\n",
      "\tspeed: 0.0176s/iter; left time: 280.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0793715 Vali Loss: 0.0791466 Test Loss: 0.0836969\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792660\n",
      "\tspeed: 0.0375s/iter; left time: 592.9876s\n",
      "\titers: 200, epoch: 30 | loss: 0.0794438\n",
      "\tspeed: 0.0186s/iter; left time: 292.1582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0793188 Vali Loss: 0.0790983 Test Loss: 0.0838351\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807952\n",
      "\tspeed: 0.0370s/iter; left time: 576.2128s\n",
      "\titers: 200, epoch: 31 | loss: 0.0756893\n",
      "\tspeed: 0.0177s/iter; left time: 273.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0792780 Vali Loss: 0.0789480 Test Loss: 0.0837407\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0803414\n",
      "\tspeed: 0.0374s/iter; left time: 575.0831s\n",
      "\titers: 200, epoch: 32 | loss: 0.0832933\n",
      "\tspeed: 0.0214s/iter; left time: 326.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0791073 Vali Loss: 0.0790042 Test Loss: 0.0836918\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774591\n",
      "\tspeed: 0.0389s/iter; left time: 587.9616s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834226\n",
      "\tspeed: 0.0176s/iter; left time: 265.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0791703 Vali Loss: 0.0786317 Test Loss: 0.0832839\n",
      "Validation loss decreased (0.078854 --> 0.078632).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0779626\n",
      "\tspeed: 0.0373s/iter; left time: 555.4768s\n",
      "\titers: 200, epoch: 34 | loss: 0.0791747\n",
      "\tspeed: 0.0176s/iter; left time: 260.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0791629 Vali Loss: 0.0787512 Test Loss: 0.0835474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0755134\n",
      "\tspeed: 0.0414s/iter; left time: 608.0829s\n",
      "\titers: 200, epoch: 35 | loss: 0.0837611\n",
      "\tspeed: 0.0187s/iter; left time: 273.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0792482 Vali Loss: 0.0783733 Test Loss: 0.0830684\n",
      "Validation loss decreased (0.078632 --> 0.078373).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0782254\n",
      "\tspeed: 0.0379s/iter; left time: 548.5207s\n",
      "\titers: 200, epoch: 36 | loss: 0.0776678\n",
      "\tspeed: 0.0181s/iter; left time: 260.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0794613 Vali Loss: 0.0785407 Test Loss: 0.0834308\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0818818\n",
      "\tspeed: 0.0391s/iter; left time: 556.0398s\n",
      "\titers: 200, epoch: 37 | loss: 0.0786573\n",
      "\tspeed: 0.0179s/iter; left time: 252.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0791341 Vali Loss: 0.0786149 Test Loss: 0.0834020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0758005\n",
      "\tspeed: 0.0379s/iter; left time: 530.6879s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819356\n",
      "\tspeed: 0.0192s/iter; left time: 267.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0790339 Vali Loss: 0.0784416 Test Loss: 0.0832714\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806531\n",
      "\tspeed: 0.0394s/iter; left time: 543.5236s\n",
      "\titers: 200, epoch: 39 | loss: 0.0777452\n",
      "\tspeed: 0.0188s/iter; left time: 257.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0790220 Vali Loss: 0.0785469 Test Loss: 0.0835634\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0808816\n",
      "\tspeed: 0.0411s/iter; left time: 557.1258s\n",
      "\titers: 200, epoch: 40 | loss: 0.0779331\n",
      "\tspeed: 0.0184s/iter; left time: 248.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0790106 Vali Loss: 0.0784936 Test Loss: 0.0833236\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0770621\n",
      "\tspeed: 0.0396s/iter; left time: 528.8388s\n",
      "\titers: 200, epoch: 41 | loss: 0.0769058\n",
      "\tspeed: 0.0177s/iter; left time: 234.2338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0790752 Vali Loss: 0.0785050 Test Loss: 0.0834829\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0816045\n",
      "\tspeed: 0.0395s/iter; left time: 517.5127s\n",
      "\titers: 200, epoch: 42 | loss: 0.0768652\n",
      "\tspeed: 0.0184s/iter; left time: 239.7384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0789593 Vali Loss: 0.0786374 Test Loss: 0.0834311\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0823383\n",
      "\tspeed: 0.0389s/iter; left time: 501.2683s\n",
      "\titers: 200, epoch: 43 | loss: 0.0827467\n",
      "\tspeed: 0.0182s/iter; left time: 232.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0789068 Vali Loss: 0.0785045 Test Loss: 0.0833443\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0810998\n",
      "\tspeed: 0.0374s/iter; left time: 474.2018s\n",
      "\titers: 200, epoch: 44 | loss: 0.0810645\n",
      "\tspeed: 0.0177s/iter; left time: 222.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0789337 Vali Loss: 0.0786096 Test Loss: 0.0833639\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0796581\n",
      "\tspeed: 0.0383s/iter; left time: 476.1345s\n",
      "\titers: 200, epoch: 45 | loss: 0.0772102\n",
      "\tspeed: 0.0188s/iter; left time: 232.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0789322 Vali Loss: 0.0784388 Test Loss: 0.0832606\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018459854647517204, rmse:0.13586704432964325, mae:0.0830683708190918, rse:0.5137279629707336\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2633902\n",
      "\tspeed: 0.0199s/iter; left time: 444.8449s\n",
      "\titers: 200, epoch: 1 | loss: 0.2498939\n",
      "\tspeed: 0.0174s/iter; left time: 387.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.2701202 Vali Loss: 0.1831898 Test Loss: 0.1920654\n",
      "Validation loss decreased (inf --> 0.183190).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1412768\n",
      "\tspeed: 0.0411s/iter; left time: 906.2863s\n",
      "\titers: 200, epoch: 2 | loss: 0.1198113\n",
      "\tspeed: 0.0201s/iter; left time: 442.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1530998 Vali Loss: 0.1046383 Test Loss: 0.1103508\n",
      "Validation loss decreased (0.183190 --> 0.104638).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1075058\n",
      "\tspeed: 0.0381s/iter; left time: 832.6648s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024728\n",
      "\tspeed: 0.0175s/iter; left time: 381.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1081631 Vali Loss: 0.0960207 Test Loss: 0.1003207\n",
      "Validation loss decreased (0.104638 --> 0.096021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0989143\n",
      "\tspeed: 0.0377s/iter; left time: 815.7902s\n",
      "\titers: 200, epoch: 4 | loss: 0.0959302\n",
      "\tspeed: 0.0177s/iter; left time: 380.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0969617 Vali Loss: 0.0876513 Test Loss: 0.0912269\n",
      "Validation loss decreased (0.096021 --> 0.087651).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0922850\n",
      "\tspeed: 0.0392s/iter; left time: 839.2089s\n",
      "\titers: 200, epoch: 5 | loss: 0.0925212\n",
      "\tspeed: 0.0182s/iter; left time: 387.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0911765 Vali Loss: 0.0846339 Test Loss: 0.0885949\n",
      "Validation loss decreased (0.087651 --> 0.084634).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807054\n",
      "\tspeed: 0.0380s/iter; left time: 804.4260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0900945\n",
      "\tspeed: 0.0210s/iter; left time: 443.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0888132 Vali Loss: 0.0833841 Test Loss: 0.0867837\n",
      "Validation loss decreased (0.084634 --> 0.083384).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0852673\n",
      "\tspeed: 0.0394s/iter; left time: 825.1896s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861322\n",
      "\tspeed: 0.0177s/iter; left time: 368.4266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0865695 Vali Loss: 0.0825928 Test Loss: 0.0858456\n",
      "Validation loss decreased (0.083384 --> 0.082593).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0809142\n",
      "\tspeed: 0.0395s/iter; left time: 819.5413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0852987\n",
      "\tspeed: 0.0175s/iter; left time: 360.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0856313 Vali Loss: 0.0831936 Test Loss: 0.0871715\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0835497\n",
      "\tspeed: 0.0390s/iter; left time: 800.5870s\n",
      "\titers: 200, epoch: 9 | loss: 0.0909500\n",
      "\tspeed: 0.0177s/iter; left time: 360.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0848892 Vali Loss: 0.0809508 Test Loss: 0.0849843\n",
      "Validation loss decreased (0.082593 --> 0.080951).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832622\n",
      "\tspeed: 0.0386s/iter; left time: 782.9861s\n",
      "\titers: 200, epoch: 10 | loss: 0.0816330\n",
      "\tspeed: 0.0181s/iter; left time: 364.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0838950 Vali Loss: 0.0810119 Test Loss: 0.0843500\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823479\n",
      "\tspeed: 0.0369s/iter; left time: 741.0397s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797392\n",
      "\tspeed: 0.0205s/iter; left time: 409.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0834092 Vali Loss: 0.0804584 Test Loss: 0.0841500\n",
      "Validation loss decreased (0.080951 --> 0.080458).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0788790\n",
      "\tspeed: 0.0395s/iter; left time: 783.1219s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763031\n",
      "\tspeed: 0.0178s/iter; left time: 351.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0825815 Vali Loss: 0.0798619 Test Loss: 0.0837918\n",
      "Validation loss decreased (0.080458 --> 0.079862).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0810508\n",
      "\tspeed: 0.0385s/iter; left time: 755.5665s\n",
      "\titers: 200, epoch: 13 | loss: 0.0791811\n",
      "\tspeed: 0.0176s/iter; left time: 344.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0822505 Vali Loss: 0.0801797 Test Loss: 0.0839376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800357\n",
      "\tspeed: 0.0377s/iter; left time: 730.6998s\n",
      "\titers: 200, epoch: 14 | loss: 0.0825908\n",
      "\tspeed: 0.0179s/iter; left time: 345.9528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0821585 Vali Loss: 0.0798246 Test Loss: 0.0841053\n",
      "Validation loss decreased (0.079862 --> 0.079825).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803743\n",
      "\tspeed: 0.0379s/iter; left time: 726.9469s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822192\n",
      "\tspeed: 0.0178s/iter; left time: 339.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0819028 Vali Loss: 0.0798835 Test Loss: 0.0839211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815150\n",
      "\tspeed: 0.0371s/iter; left time: 702.3098s\n",
      "\titers: 200, epoch: 16 | loss: 0.0846371\n",
      "\tspeed: 0.0176s/iter; left time: 331.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0812258 Vali Loss: 0.0792488 Test Loss: 0.0837073\n",
      "Validation loss decreased (0.079825 --> 0.079249).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0787798\n",
      "\tspeed: 0.0383s/iter; left time: 716.0123s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758536\n",
      "\tspeed: 0.0176s/iter; left time: 328.1706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0809318 Vali Loss: 0.0792728 Test Loss: 0.0835242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0856505\n",
      "\tspeed: 0.0375s/iter; left time: 693.5057s\n",
      "\titers: 200, epoch: 18 | loss: 0.0821285\n",
      "\tspeed: 0.0177s/iter; left time: 325.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0807226 Vali Loss: 0.0791358 Test Loss: 0.0838297\n",
      "Validation loss decreased (0.079249 --> 0.079136).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0854405\n",
      "\tspeed: 0.0382s/iter; left time: 698.2759s\n",
      "\titers: 200, epoch: 19 | loss: 0.0808203\n",
      "\tspeed: 0.0177s/iter; left time: 322.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0805419 Vali Loss: 0.0786519 Test Loss: 0.0832431\n",
      "Validation loss decreased (0.079136 --> 0.078652).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0768757\n",
      "\tspeed: 0.0384s/iter; left time: 692.5387s\n",
      "\titers: 200, epoch: 20 | loss: 0.0836926\n",
      "\tspeed: 0.0177s/iter; left time: 316.9618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0808815 Vali Loss: 0.0788314 Test Loss: 0.0833596\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0788373\n",
      "\tspeed: 0.0376s/iter; left time: 669.9588s\n",
      "\titers: 200, epoch: 21 | loss: 0.0830935\n",
      "\tspeed: 0.0177s/iter; left time: 313.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0802833 Vali Loss: 0.0785787 Test Loss: 0.0832150\n",
      "Validation loss decreased (0.078652 --> 0.078579).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0764465\n",
      "\tspeed: 0.0406s/iter; left time: 713.6416s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798683\n",
      "\tspeed: 0.0208s/iter; left time: 363.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0804388 Vali Loss: 0.0785920 Test Loss: 0.0833893\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0800391\n",
      "\tspeed: 0.0376s/iter; left time: 652.8931s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768104\n",
      "\tspeed: 0.0177s/iter; left time: 305.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0799818 Vali Loss: 0.0783198 Test Loss: 0.0832006\n",
      "Validation loss decreased (0.078579 --> 0.078320).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0780598\n",
      "\tspeed: 0.0396s/iter; left time: 679.6285s\n",
      "\titers: 200, epoch: 24 | loss: 0.0812857\n",
      "\tspeed: 0.0181s/iter; left time: 308.0206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0798504 Vali Loss: 0.0789208 Test Loss: 0.0834581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0797256\n",
      "\tspeed: 0.0375s/iter; left time: 635.3555s\n",
      "\titers: 200, epoch: 25 | loss: 0.0803634\n",
      "\tspeed: 0.0175s/iter; left time: 293.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0799274 Vali Loss: 0.0784315 Test Loss: 0.0832071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0801724\n",
      "\tspeed: 0.0407s/iter; left time: 678.9461s\n",
      "\titers: 200, epoch: 26 | loss: 0.0792413\n",
      "\tspeed: 0.0189s/iter; left time: 313.6101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0797059 Vali Loss: 0.0782750 Test Loss: 0.0831834\n",
      "Validation loss decreased (0.078320 --> 0.078275).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0806413\n",
      "\tspeed: 0.0427s/iter; left time: 703.6826s\n",
      "\titers: 200, epoch: 27 | loss: 0.0788254\n",
      "\tspeed: 0.0175s/iter; left time: 286.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0795695 Vali Loss: 0.0782672 Test Loss: 0.0829756\n",
      "Validation loss decreased (0.078275 --> 0.078267).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762409\n",
      "\tspeed: 0.0420s/iter; left time: 683.3500s\n",
      "\titers: 200, epoch: 28 | loss: 0.0832204\n",
      "\tspeed: 0.0179s/iter; left time: 288.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0795220 Vali Loss: 0.0783756 Test Loss: 0.0831942\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0755171\n",
      "\tspeed: 0.0391s/iter; left time: 627.4245s\n",
      "\titers: 200, epoch: 29 | loss: 0.0799543\n",
      "\tspeed: 0.0179s/iter; left time: 285.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0795414 Vali Loss: 0.0783198 Test Loss: 0.0832834\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0809168\n",
      "\tspeed: 0.0392s/iter; left time: 618.9313s\n",
      "\titers: 200, epoch: 30 | loss: 0.0776021\n",
      "\tspeed: 0.0174s/iter; left time: 272.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0793517 Vali Loss: 0.0782524 Test Loss: 0.0834267\n",
      "Validation loss decreased (0.078267 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0798810\n",
      "\tspeed: 0.0393s/iter; left time: 611.5846s\n",
      "\titers: 200, epoch: 31 | loss: 0.0847576\n",
      "\tspeed: 0.0197s/iter; left time: 305.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0793432 Vali Loss: 0.0785735 Test Loss: 0.0833395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0820202\n",
      "\tspeed: 0.0386s/iter; left time: 592.8653s\n",
      "\titers: 200, epoch: 32 | loss: 0.0780760\n",
      "\tspeed: 0.0175s/iter; left time: 266.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0793279 Vali Loss: 0.0781227 Test Loss: 0.0831220\n",
      "Validation loss decreased (0.078252 --> 0.078123).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0784964\n",
      "\tspeed: 0.0399s/iter; left time: 603.2432s\n",
      "\titers: 200, epoch: 33 | loss: 0.0800942\n",
      "\tspeed: 0.0181s/iter; left time: 271.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0792461 Vali Loss: 0.0781400 Test Loss: 0.0830985\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0783564\n",
      "\tspeed: 0.0450s/iter; left time: 670.6480s\n",
      "\titers: 200, epoch: 34 | loss: 0.0756153\n",
      "\tspeed: 0.0240s/iter; left time: 355.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0793294 Vali Loss: 0.0780001 Test Loss: 0.0831595\n",
      "Validation loss decreased (0.078123 --> 0.078000).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0827296\n",
      "\tspeed: 0.0426s/iter; left time: 625.7874s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781024\n",
      "\tspeed: 0.0211s/iter; left time: 307.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0793010 Vali Loss: 0.0781735 Test Loss: 0.0831860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0829730\n",
      "\tspeed: 0.0399s/iter; left time: 577.7028s\n",
      "\titers: 200, epoch: 36 | loss: 0.0764428\n",
      "\tspeed: 0.0175s/iter; left time: 251.5983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0791474 Vali Loss: 0.0781738 Test Loss: 0.0831930\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0818572\n",
      "\tspeed: 0.0374s/iter; left time: 531.7544s\n",
      "\titers: 200, epoch: 37 | loss: 0.0786788\n",
      "\tspeed: 0.0177s/iter; left time: 249.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0791359 Vali Loss: 0.0780627 Test Loss: 0.0831984\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0735988\n",
      "\tspeed: 0.0371s/iter; left time: 520.1814s\n",
      "\titers: 200, epoch: 38 | loss: 0.0772743\n",
      "\tspeed: 0.0175s/iter; left time: 243.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0790314 Vali Loss: 0.0782232 Test Loss: 0.0831310\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803424\n",
      "\tspeed: 0.0385s/iter; left time: 531.3018s\n",
      "\titers: 200, epoch: 39 | loss: 0.0774279\n",
      "\tspeed: 0.0173s/iter; left time: 237.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0794683 Vali Loss: 0.0782137 Test Loss: 0.0831036\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824025\n",
      "\tspeed: 0.0385s/iter; left time: 522.3132s\n",
      "\titers: 200, epoch: 40 | loss: 0.0808806\n",
      "\tspeed: 0.0188s/iter; left time: 252.6167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0789695 Vali Loss: 0.0782394 Test Loss: 0.0832140\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0765408\n",
      "\tspeed: 0.0388s/iter; left time: 517.0474s\n",
      "\titers: 200, epoch: 41 | loss: 0.0806076\n",
      "\tspeed: 0.0183s/iter; left time: 242.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0791506 Vali Loss: 0.0783099 Test Loss: 0.0832641\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0782502\n",
      "\tspeed: 0.0374s/iter; left time: 490.2872s\n",
      "\titers: 200, epoch: 42 | loss: 0.0761774\n",
      "\tspeed: 0.0180s/iter; left time: 234.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0790142 Vali Loss: 0.0779812 Test Loss: 0.0830856\n",
      "Validation loss decreased (0.078000 --> 0.077981).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0794970\n",
      "\tspeed: 0.0393s/iter; left time: 507.3315s\n",
      "\titers: 200, epoch: 43 | loss: 0.0779923\n",
      "\tspeed: 0.0175s/iter; left time: 223.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0794099 Vali Loss: 0.0781618 Test Loss: 0.0831427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0826394\n",
      "\tspeed: 0.0369s/iter; left time: 468.0010s\n",
      "\titers: 200, epoch: 44 | loss: 0.0761337\n",
      "\tspeed: 0.0176s/iter; left time: 221.6712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0789953 Vali Loss: 0.0781651 Test Loss: 0.0831567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0786274\n",
      "\tspeed: 0.0394s/iter; left time: 490.3835s\n",
      "\titers: 200, epoch: 45 | loss: 0.0807655\n",
      "\tspeed: 0.0184s/iter; left time: 227.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0789668 Vali Loss: 0.0780502 Test Loss: 0.0831159\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0769732\n",
      "\tspeed: 0.0408s/iter; left time: 498.4777s\n",
      "\titers: 200, epoch: 46 | loss: 0.0772156\n",
      "\tspeed: 0.0182s/iter; left time: 220.9963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0789443 Vali Loss: 0.0779427 Test Loss: 0.0830539\n",
      "Validation loss decreased (0.077981 --> 0.077943).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0804595\n",
      "\tspeed: 0.0395s/iter; left time: 473.5711s\n",
      "\titers: 200, epoch: 47 | loss: 0.0782881\n",
      "\tspeed: 0.0179s/iter; left time: 212.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0789955 Vali Loss: 0.0780217 Test Loss: 0.0830913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784007\n",
      "\tspeed: 0.0382s/iter; left time: 449.3469s\n",
      "\titers: 200, epoch: 48 | loss: 0.0771884\n",
      "\tspeed: 0.0204s/iter; left time: 238.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0790766 Vali Loss: 0.0781744 Test Loss: 0.0831143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0783620\n",
      "\tspeed: 0.0393s/iter; left time: 453.3140s\n",
      "\titers: 200, epoch: 49 | loss: 0.0763013\n",
      "\tspeed: 0.0177s/iter; left time: 202.6763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0788638 Vali Loss: 0.0781407 Test Loss: 0.0832584\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0797226\n",
      "\tspeed: 0.0411s/iter; left time: 465.5889s\n",
      "\titers: 200, epoch: 50 | loss: 0.0782608\n",
      "\tspeed: 0.0190s/iter; left time: 213.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0789711 Vali Loss: 0.0780533 Test Loss: 0.0831397\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0804075\n",
      "\tspeed: 0.0388s/iter; left time: 430.4697s\n",
      "\titers: 200, epoch: 51 | loss: 0.0838626\n",
      "\tspeed: 0.0177s/iter; left time: 194.3465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0789737 Vali Loss: 0.0783615 Test Loss: 0.0833214\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0822536\n",
      "\tspeed: 0.0375s/iter; left time: 408.3638s\n",
      "\titers: 200, epoch: 52 | loss: 0.0792260\n",
      "\tspeed: 0.0175s/iter; left time: 189.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0789445 Vali Loss: 0.0779912 Test Loss: 0.0830515\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0799038\n",
      "\tspeed: 0.0383s/iter; left time: 408.0374s\n",
      "\titers: 200, epoch: 53 | loss: 0.0754777\n",
      "\tspeed: 0.0180s/iter; left time: 189.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0789257 Vali Loss: 0.0780353 Test Loss: 0.0831481\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802066\n",
      "\tspeed: 0.0381s/iter; left time: 396.8304s\n",
      "\titers: 200, epoch: 54 | loss: 0.0771957\n",
      "\tspeed: 0.0175s/iter; left time: 180.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0792655 Vali Loss: 0.0781010 Test Loss: 0.0831064\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0827046\n",
      "\tspeed: 0.0387s/iter; left time: 394.9468s\n",
      "\titers: 200, epoch: 55 | loss: 0.0743920\n",
      "\tspeed: 0.0178s/iter; left time: 179.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0790204 Vali Loss: 0.0782403 Test Loss: 0.0831909\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0775810\n",
      "\tspeed: 0.0381s/iter; left time: 379.9134s\n",
      "\titers: 200, epoch: 56 | loss: 0.0783878\n",
      "\tspeed: 0.0176s/iter; left time: 173.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0792037 Vali Loss: 0.0780373 Test Loss: 0.0830897\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01852767914533615, rmse:0.1361164152622223, mae:0.08305386453866959, rse:0.5146708488464355\n",
      "Intermediate time for IT and pred_len 96: 00h:09m:49.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2618526\n",
      "\tspeed: 0.0305s/iter; left time: 677.9446s\n",
      "\titers: 200, epoch: 1 | loss: 0.2437329\n",
      "\tspeed: 0.0178s/iter; left time: 393.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.2659036 Vali Loss: 0.1835878 Test Loss: 0.1923225\n",
      "Validation loss decreased (inf --> 0.183588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1408188\n",
      "\tspeed: 0.0404s/iter; left time: 888.4358s\n",
      "\titers: 200, epoch: 2 | loss: 0.1191315\n",
      "\tspeed: 0.0200s/iter; left time: 437.6589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.1517580 Vali Loss: 0.1063494 Test Loss: 0.1110453\n",
      "Validation loss decreased (0.183588 --> 0.106349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138826\n",
      "\tspeed: 0.0400s/iter; left time: 869.9507s\n",
      "\titers: 200, epoch: 3 | loss: 0.1030243\n",
      "\tspeed: 0.0179s/iter; left time: 386.8005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1102856 Vali Loss: 0.1004769 Test Loss: 0.1051075\n",
      "Validation loss decreased (0.106349 --> 0.100477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014542\n",
      "\tspeed: 0.0386s/iter; left time: 831.5773s\n",
      "\titers: 200, epoch: 4 | loss: 0.1005135\n",
      "\tspeed: 0.0187s/iter; left time: 401.6495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0996700 Vali Loss: 0.0918122 Test Loss: 0.0940000\n",
      "Validation loss decreased (0.100477 --> 0.091812).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0907509\n",
      "\tspeed: 0.0436s/iter; left time: 929.4594s\n",
      "\titers: 200, epoch: 5 | loss: 0.0912171\n",
      "\tspeed: 0.0185s/iter; left time: 391.6411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0947535 Vali Loss: 0.0885435 Test Loss: 0.0914100\n",
      "Validation loss decreased (0.091812 --> 0.088544).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0906665\n",
      "\tspeed: 0.0388s/iter; left time: 818.5845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0929077\n",
      "\tspeed: 0.0176s/iter; left time: 369.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0915389 Vali Loss: 0.0868798 Test Loss: 0.0899508\n",
      "Validation loss decreased (0.088544 --> 0.086880).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0905956\n",
      "\tspeed: 0.0416s/iter; left time: 867.3586s\n",
      "\titers: 200, epoch: 7 | loss: 0.0907880\n",
      "\tspeed: 0.0175s/iter; left time: 363.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0898464 Vali Loss: 0.0865407 Test Loss: 0.0891372\n",
      "Validation loss decreased (0.086880 --> 0.086541).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0865913\n",
      "\tspeed: 0.0406s/iter; left time: 837.8577s\n",
      "\titers: 200, epoch: 8 | loss: 0.0852502\n",
      "\tspeed: 0.0196s/iter; left time: 402.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0885017 Vali Loss: 0.0852268 Test Loss: 0.0887005\n",
      "Validation loss decreased (0.086541 --> 0.085227).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0862438\n",
      "\tspeed: 0.0411s/iter; left time: 838.7830s\n",
      "\titers: 200, epoch: 9 | loss: 0.0848469\n",
      "\tspeed: 0.0177s/iter; left time: 359.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0876411 Vali Loss: 0.0876688 Test Loss: 0.0913752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852093\n",
      "\tspeed: 0.0399s/iter; left time: 805.2072s\n",
      "\titers: 200, epoch: 10 | loss: 0.0877460\n",
      "\tspeed: 0.0244s/iter; left time: 489.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0870991 Vali Loss: 0.0846349 Test Loss: 0.0878684\n",
      "Validation loss decreased (0.085227 --> 0.084635).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1038115\n",
      "\tspeed: 0.0420s/iter; left time: 838.0884s\n",
      "\titers: 200, epoch: 11 | loss: 0.0825079\n",
      "\tspeed: 0.0187s/iter; left time: 370.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0866282 Vali Loss: 0.0844627 Test Loss: 0.0876917\n",
      "Validation loss decreased (0.084635 --> 0.084463).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0848862\n",
      "\tspeed: 0.0413s/iter; left time: 815.2028s\n",
      "\titers: 200, epoch: 12 | loss: 0.0860416\n",
      "\tspeed: 0.0198s/iter; left time: 388.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0861590 Vali Loss: 0.0843448 Test Loss: 0.0876028\n",
      "Validation loss decreased (0.084463 --> 0.084345).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0836668\n",
      "\tspeed: 0.0402s/iter; left time: 785.2082s\n",
      "\titers: 200, epoch: 13 | loss: 0.0862086\n",
      "\tspeed: 0.0191s/iter; left time: 371.2688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0857145 Vali Loss: 0.0839328 Test Loss: 0.0872818\n",
      "Validation loss decreased (0.084345 --> 0.083933).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848311\n",
      "\tspeed: 0.0417s/iter; left time: 804.7374s\n",
      "\titers: 200, epoch: 14 | loss: 0.0857376\n",
      "\tspeed: 0.0194s/iter; left time: 371.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0852117 Vali Loss: 0.0847552 Test Loss: 0.0878138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0834751\n",
      "\tspeed: 0.0404s/iter; left time: 770.2587s\n",
      "\titers: 200, epoch: 15 | loss: 0.0915823\n",
      "\tspeed: 0.0190s/iter; left time: 361.2826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0849433 Vali Loss: 0.0841904 Test Loss: 0.0875766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0860700\n",
      "\tspeed: 0.0438s/iter; left time: 826.7907s\n",
      "\titers: 200, epoch: 16 | loss: 0.0841868\n",
      "\tspeed: 0.0197s/iter; left time: 368.9963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0848660 Vali Loss: 0.0835877 Test Loss: 0.0872214\n",
      "Validation loss decreased (0.083933 --> 0.083588).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0860361\n",
      "\tspeed: 0.0414s/iter; left time: 771.7841s\n",
      "\titers: 200, epoch: 17 | loss: 0.0865286\n",
      "\tspeed: 0.0178s/iter; left time: 329.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0849234 Vali Loss: 0.0841695 Test Loss: 0.0881402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0808376\n",
      "\tspeed: 0.0386s/iter; left time: 710.9850s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866519\n",
      "\tspeed: 0.0177s/iter; left time: 323.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0844290 Vali Loss: 0.0839188 Test Loss: 0.0877824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0827186\n",
      "\tspeed: 0.0381s/iter; left time: 693.2600s\n",
      "\titers: 200, epoch: 19 | loss: 0.0852388\n",
      "\tspeed: 0.0184s/iter; left time: 333.6682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0842245 Vali Loss: 0.0831437 Test Loss: 0.0875251\n",
      "Validation loss decreased (0.083588 --> 0.083144).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0842740\n",
      "\tspeed: 0.0412s/iter; left time: 740.3701s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798561\n",
      "\tspeed: 0.0185s/iter; left time: 329.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0839738 Vali Loss: 0.0835456 Test Loss: 0.0876565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0844715\n",
      "\tspeed: 0.0403s/iter; left time: 714.3296s\n",
      "\titers: 200, epoch: 21 | loss: 0.0844097\n",
      "\tspeed: 0.0192s/iter; left time: 339.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0839412 Vali Loss: 0.0833058 Test Loss: 0.0873658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0835519\n",
      "\tspeed: 0.0408s/iter; left time: 715.4605s\n",
      "\titers: 200, epoch: 22 | loss: 0.0868410\n",
      "\tspeed: 0.0177s/iter; left time: 307.6031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0836301 Vali Loss: 0.0827821 Test Loss: 0.0871706\n",
      "Validation loss decreased (0.083144 --> 0.082782).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0787933\n",
      "\tspeed: 0.0387s/iter; left time: 669.7411s\n",
      "\titers: 200, epoch: 23 | loss: 0.0835324\n",
      "\tspeed: 0.0176s/iter; left time: 303.2379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0839153 Vali Loss: 0.0830652 Test Loss: 0.0870562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0858449\n",
      "\tspeed: 0.0397s/iter; left time: 678.0082s\n",
      "\titers: 200, epoch: 24 | loss: 0.0827970\n",
      "\tspeed: 0.0204s/iter; left time: 345.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0833876 Vali Loss: 0.0825687 Test Loss: 0.0870922\n",
      "Validation loss decreased (0.082782 --> 0.082569).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0830724\n",
      "\tspeed: 0.0394s/iter; left time: 664.2001s\n",
      "\titers: 200, epoch: 25 | loss: 0.0819455\n",
      "\tspeed: 0.0178s/iter; left time: 298.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0834162 Vali Loss: 0.0829770 Test Loss: 0.0871466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0862517\n",
      "\tspeed: 0.0376s/iter; left time: 625.9024s\n",
      "\titers: 200, epoch: 26 | loss: 0.0832444\n",
      "\tspeed: 0.0179s/iter; left time: 295.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0836620 Vali Loss: 0.0828633 Test Loss: 0.0868982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810724\n",
      "\tspeed: 0.0387s/iter; left time: 634.5376s\n",
      "\titers: 200, epoch: 27 | loss: 0.0871291\n",
      "\tspeed: 0.0186s/iter; left time: 303.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0833860 Vali Loss: 0.0832820 Test Loss: 0.0875993\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0828814\n",
      "\tspeed: 0.0384s/iter; left time: 621.6235s\n",
      "\titers: 200, epoch: 28 | loss: 0.0834261\n",
      "\tspeed: 0.0202s/iter; left time: 325.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0832057 Vali Loss: 0.0830274 Test Loss: 0.0874306\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0795119\n",
      "\tspeed: 0.0379s/iter; left time: 604.5026s\n",
      "\titers: 200, epoch: 29 | loss: 0.0835493\n",
      "\tspeed: 0.0179s/iter; left time: 283.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0831295 Vali Loss: 0.0828504 Test Loss: 0.0873075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0820471\n",
      "\tspeed: 0.0396s/iter; left time: 622.9232s\n",
      "\titers: 200, epoch: 30 | loss: 0.0849657\n",
      "\tspeed: 0.0198s/iter; left time: 309.3678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0831793 Vali Loss: 0.0829110 Test Loss: 0.0872107\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0845075\n",
      "\tspeed: 0.0410s/iter; left time: 635.6578s\n",
      "\titers: 200, epoch: 31 | loss: 0.0835567\n",
      "\tspeed: 0.0235s/iter; left time: 362.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0830533 Vali Loss: 0.0830682 Test Loss: 0.0872975\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0820101\n",
      "\tspeed: 0.0405s/iter; left time: 619.6774s\n",
      "\titers: 200, epoch: 32 | loss: 0.0822481\n",
      "\tspeed: 0.0182s/iter; left time: 276.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0831543 Vali Loss: 0.0829948 Test Loss: 0.0874315\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0814776\n",
      "\tspeed: 0.0406s/iter; left time: 611.7506s\n",
      "\titers: 200, epoch: 33 | loss: 0.0830027\n",
      "\tspeed: 0.0200s/iter; left time: 299.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0829303 Vali Loss: 0.0826190 Test Loss: 0.0872689\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0803830\n",
      "\tspeed: 0.0407s/iter; left time: 603.8938s\n",
      "\titers: 200, epoch: 34 | loss: 0.0853011\n",
      "\tspeed: 0.0214s/iter; left time: 316.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0830261 Vali Loss: 0.0829794 Test Loss: 0.0871384\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019714010879397392, rmse:0.14040659368038177, mae:0.08709219098091125, rse:0.5313858389854431\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2722960\n",
      "\tspeed: 0.0235s/iter; left time: 522.0063s\n",
      "\titers: 200, epoch: 1 | loss: 0.2520403\n",
      "\tspeed: 0.0225s/iter; left time: 497.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.2729355 Vali Loss: 0.1871675 Test Loss: 0.1942406\n",
      "Validation loss decreased (inf --> 0.187168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451315\n",
      "\tspeed: 0.0433s/iter; left time: 951.7937s\n",
      "\titers: 200, epoch: 2 | loss: 0.1175948\n",
      "\tspeed: 0.0176s/iter; left time: 386.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.1519489 Vali Loss: 0.1065287 Test Loss: 0.1124682\n",
      "Validation loss decreased (0.187168 --> 0.106529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1093920\n",
      "\tspeed: 0.0388s/iter; left time: 843.5858s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011367\n",
      "\tspeed: 0.0176s/iter; left time: 381.9942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1095336 Vali Loss: 0.0991193 Test Loss: 0.1020565\n",
      "Validation loss decreased (0.106529 --> 0.099119).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1005649\n",
      "\tspeed: 0.0412s/iter; left time: 887.5448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982407\n",
      "\tspeed: 0.0195s/iter; left time: 417.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0996083 Vali Loss: 0.0927828 Test Loss: 0.0957338\n",
      "Validation loss decreased (0.099119 --> 0.092783).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0915633\n",
      "\tspeed: 0.0407s/iter; left time: 866.7162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0933431\n",
      "\tspeed: 0.0194s/iter; left time: 412.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0943571 Vali Loss: 0.0890659 Test Loss: 0.0916014\n",
      "Validation loss decreased (0.092783 --> 0.089066).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0901610\n",
      "\tspeed: 0.0436s/iter; left time: 920.3169s\n",
      "\titers: 200, epoch: 6 | loss: 0.0907858\n",
      "\tspeed: 0.0197s/iter; left time: 413.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0922208 Vali Loss: 0.0875594 Test Loss: 0.0909533\n",
      "Validation loss decreased (0.089066 --> 0.087559).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0865553\n",
      "\tspeed: 0.0396s/iter; left time: 826.2321s\n",
      "\titers: 200, epoch: 7 | loss: 0.0909120\n",
      "\tspeed: 0.0177s/iter; left time: 368.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0900594 Vali Loss: 0.0859338 Test Loss: 0.0903283\n",
      "Validation loss decreased (0.087559 --> 0.085934).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0875558\n",
      "\tspeed: 0.0412s/iter; left time: 849.5548s\n",
      "\titers: 200, epoch: 8 | loss: 0.0910288\n",
      "\tspeed: 0.0178s/iter; left time: 365.5032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0887726 Vali Loss: 0.0861879 Test Loss: 0.0898933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0925807\n",
      "\tspeed: 0.0413s/iter; left time: 843.0904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0852723\n",
      "\tspeed: 0.0205s/iter; left time: 417.1838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0880142 Vali Loss: 0.0854083 Test Loss: 0.0899860\n",
      "Validation loss decreased (0.085934 --> 0.085408).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0877279\n",
      "\tspeed: 0.0441s/iter; left time: 891.2089s\n",
      "\titers: 200, epoch: 10 | loss: 0.0881637\n",
      "\tspeed: 0.0230s/iter; left time: 461.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0870026 Vali Loss: 0.0842553 Test Loss: 0.0891894\n",
      "Validation loss decreased (0.085408 --> 0.084255).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0845610\n",
      "\tspeed: 0.0413s/iter; left time: 825.6375s\n",
      "\titers: 200, epoch: 11 | loss: 0.0836188\n",
      "\tspeed: 0.0197s/iter; left time: 390.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0865821 Vali Loss: 0.0840564 Test Loss: 0.0891234\n",
      "Validation loss decreased (0.084255 --> 0.084056).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0851073\n",
      "\tspeed: 0.0409s/iter; left time: 807.1010s\n",
      "\titers: 200, epoch: 12 | loss: 0.0875089\n",
      "\tspeed: 0.0218s/iter; left time: 428.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0859562 Vali Loss: 0.0838318 Test Loss: 0.0894333\n",
      "Validation loss decreased (0.084056 --> 0.083832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0848750\n",
      "\tspeed: 0.0420s/iter; left time: 819.2236s\n",
      "\titers: 200, epoch: 13 | loss: 0.0861893\n",
      "\tspeed: 0.0183s/iter; left time: 355.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0858611 Vali Loss: 0.0833734 Test Loss: 0.0887535\n",
      "Validation loss decreased (0.083832 --> 0.083373).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0860830\n",
      "\tspeed: 0.0420s/iter; left time: 810.3363s\n",
      "\titers: 200, epoch: 14 | loss: 0.0848291\n",
      "\tspeed: 0.0226s/iter; left time: 434.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0854367 Vali Loss: 0.0841547 Test Loss: 0.0900619\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0818479\n",
      "\tspeed: 0.0419s/iter; left time: 798.8150s\n",
      "\titers: 200, epoch: 15 | loss: 0.0812685\n",
      "\tspeed: 0.0206s/iter; left time: 391.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0850249 Vali Loss: 0.0830967 Test Loss: 0.0891032\n",
      "Validation loss decreased (0.083373 --> 0.083097).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0832635\n",
      "\tspeed: 0.0427s/iter; left time: 804.8350s\n",
      "\titers: 200, epoch: 16 | loss: 0.0835396\n",
      "\tspeed: 0.0184s/iter; left time: 345.9199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0846237 Vali Loss: 0.0839857 Test Loss: 0.0897158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0865859\n",
      "\tspeed: 0.0420s/iter; left time: 781.8145s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830418\n",
      "\tspeed: 0.0233s/iter; left time: 431.1910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0846093 Vali Loss: 0.0829229 Test Loss: 0.0888173\n",
      "Validation loss decreased (0.083097 --> 0.082923).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878394\n",
      "\tspeed: 0.0420s/iter; left time: 772.8597s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843701\n",
      "\tspeed: 0.0207s/iter; left time: 378.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0842403 Vali Loss: 0.0827744 Test Loss: 0.0888727\n",
      "Validation loss decreased (0.082923 --> 0.082774).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800858\n",
      "\tspeed: 0.0430s/iter; left time: 782.7241s\n",
      "\titers: 200, epoch: 19 | loss: 0.0841985\n",
      "\tspeed: 0.0208s/iter; left time: 377.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0839250 Vali Loss: 0.0828307 Test Loss: 0.0890774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0823361\n",
      "\tspeed: 0.0394s/iter; left time: 707.7687s\n",
      "\titers: 200, epoch: 20 | loss: 0.0813437\n",
      "\tspeed: 0.0176s/iter; left time: 313.9295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0838102 Vali Loss: 0.0836323 Test Loss: 0.0896494\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0843800\n",
      "\tspeed: 0.0403s/iter; left time: 714.2671s\n",
      "\titers: 200, epoch: 21 | loss: 0.0815336\n",
      "\tspeed: 0.0218s/iter; left time: 385.4117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0835798 Vali Loss: 0.0830011 Test Loss: 0.0888385\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0837442\n",
      "\tspeed: 0.0399s/iter; left time: 699.3352s\n",
      "\titers: 200, epoch: 22 | loss: 0.0840666\n",
      "\tspeed: 0.0185s/iter; left time: 322.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0833981 Vali Loss: 0.0827323 Test Loss: 0.0891256\n",
      "Validation loss decreased (0.082774 --> 0.082732).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0806301\n",
      "\tspeed: 0.0441s/iter; left time: 763.0869s\n",
      "\titers: 200, epoch: 23 | loss: 0.0837485\n",
      "\tspeed: 0.0213s/iter; left time: 366.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0831782 Vali Loss: 0.0830684 Test Loss: 0.0891765\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0847063\n",
      "\tspeed: 0.0417s/iter; left time: 711.2161s\n",
      "\titers: 200, epoch: 24 | loss: 0.0892751\n",
      "\tspeed: 0.0179s/iter; left time: 302.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0832580 Vali Loss: 0.0834589 Test Loss: 0.0896644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0811307\n",
      "\tspeed: 0.0404s/iter; left time: 679.9608s\n",
      "\titers: 200, epoch: 25 | loss: 0.0808395\n",
      "\tspeed: 0.0178s/iter; left time: 297.3802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0834092 Vali Loss: 0.0836975 Test Loss: 0.0896986\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0824584\n",
      "\tspeed: 0.0393s/iter; left time: 653.1168s\n",
      "\titers: 200, epoch: 26 | loss: 0.0837605\n",
      "\tspeed: 0.0181s/iter; left time: 299.5267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0829938 Vali Loss: 0.0828161 Test Loss: 0.0889473\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0861984\n",
      "\tspeed: 0.0393s/iter; left time: 645.4068s\n",
      "\titers: 200, epoch: 27 | loss: 0.0795609\n",
      "\tspeed: 0.0183s/iter; left time: 298.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0832123 Vali Loss: 0.0828130 Test Loss: 0.0890543\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0834852\n",
      "\tspeed: 0.0424s/iter; left time: 685.4439s\n",
      "\titers: 200, epoch: 28 | loss: 0.0844575\n",
      "\tspeed: 0.0178s/iter; left time: 286.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0829307 Vali Loss: 0.0832087 Test Loss: 0.0893112\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0846860\n",
      "\tspeed: 0.0382s/iter; left time: 608.9777s\n",
      "\titers: 200, epoch: 29 | loss: 0.0851766\n",
      "\tspeed: 0.0175s/iter; left time: 276.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0829010 Vali Loss: 0.0828926 Test Loss: 0.0890503\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0829685\n",
      "\tspeed: 0.0389s/iter; left time: 612.0914s\n",
      "\titers: 200, epoch: 30 | loss: 0.0811437\n",
      "\tspeed: 0.0216s/iter; left time: 337.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0829337 Vali Loss: 0.0829649 Test Loss: 0.0891979\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0834660\n",
      "\tspeed: 0.0415s/iter; left time: 644.0878s\n",
      "\titers: 200, epoch: 31 | loss: 0.0847687\n",
      "\tspeed: 0.0212s/iter; left time: 326.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0828318 Vali Loss: 0.0832319 Test Loss: 0.0892689\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0830979\n",
      "\tspeed: 0.0414s/iter; left time: 633.4162s\n",
      "\titers: 200, epoch: 32 | loss: 0.0814148\n",
      "\tspeed: 0.0194s/iter; left time: 294.4085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0827432 Vali Loss: 0.0831890 Test Loss: 0.0893123\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020823365077376366, rmse:0.14430303871631622, mae:0.08912559598684311, rse:0.5461323857307434\n",
      "Intermediate time for IT and pred_len 168: 00h:06m:44.81s\n",
      "Intermediate time for IT: 00h:27m:32.32s\n",
      "Total time: 02h:24m:30.60s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1473  0.0914\n",
       "        96        0.0405  0.2013  0.1320\n",
       "        168       0.0450  0.2121  0.1408\n",
       "ES      24        0.0128  0.1130  0.0728\n",
       "        96        0.0330  0.1801  0.1138\n",
       "        168       0.0306  0.1748  0.1165\n",
       "FR      24        0.0107  0.1033  0.0598\n",
       "        96        0.0197  0.1402  0.0822\n",
       "        168       0.0228  0.1511  0.0891\n",
       "GB      24        0.0261  0.1616  0.1045\n",
       "        96        0.0457  0.2137  0.1464\n",
       "        168       0.0485  0.2201  0.1532\n",
       "IT      24        0.0107  0.1032  0.0610\n",
       "        96        0.0185  0.1360  0.0831\n",
       "        168       0.0203  0.1424  0.0881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1112533\n",
      "\tspeed: 0.1231s/iter; left time: 2746.3413s\n",
      "\titers: 200, epoch: 1 | loss: 0.0947237\n",
      "\tspeed: 0.0979s/iter; left time: 2173.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.1155480 Vali Loss: 0.1083674 Test Loss: 0.1112919\n",
      "Validation loss decreased (inf --> 0.108367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0854550\n",
      "\tspeed: 0.1683s/iter; left time: 3716.6007s\n",
      "\titers: 200, epoch: 2 | loss: 0.0782319\n",
      "\tspeed: 0.0980s/iter; left time: 2154.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0869274 Vali Loss: 0.0998944 Test Loss: 0.1056200\n",
      "Validation loss decreased (0.108367 --> 0.099894).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0739933\n",
      "\tspeed: 0.1672s/iter; left time: 3654.3358s\n",
      "\titers: 200, epoch: 3 | loss: 0.0765578\n",
      "\tspeed: 0.0978s/iter; left time: 2128.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0778407 Vali Loss: 0.0991285 Test Loss: 0.1069202\n",
      "Validation loss decreased (0.099894 --> 0.099128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0697385\n",
      "\tspeed: 0.1682s/iter; left time: 3639.0088s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638608\n",
      "\tspeed: 0.0980s/iter; left time: 2109.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0693531 Vali Loss: 0.1024066 Test Loss: 0.1129898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582502\n",
      "\tspeed: 0.1631s/iter; left time: 3491.8476s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585040\n",
      "\tspeed: 0.0979s/iter; left time: 2084.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0609865 Vali Loss: 0.1040621 Test Loss: 0.1140443\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572859\n",
      "\tspeed: 0.1637s/iter; left time: 3467.9959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0524833\n",
      "\tspeed: 0.0980s/iter; left time: 2065.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.16s\n",
      "Steps: 224 | Train Loss: 0.0544637 Vali Loss: 0.1054772 Test Loss: 0.1150894\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504480\n",
      "\tspeed: 0.1630s/iter; left time: 3416.3312s\n",
      "\titers: 200, epoch: 7 | loss: 0.0498273\n",
      "\tspeed: 0.0979s/iter; left time: 2042.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0495332 Vali Loss: 0.1044851 Test Loss: 0.1146997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0444115\n",
      "\tspeed: 0.1638s/iter; left time: 3396.4821s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440660\n",
      "\tspeed: 0.0981s/iter; left time: 2025.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0461323 Vali Loss: 0.1038223 Test Loss: 0.1127458\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0430763\n",
      "\tspeed: 0.1640s/iter; left time: 3363.6509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0425591\n",
      "\tspeed: 0.0983s/iter; left time: 2006.6833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.23s\n",
      "Steps: 224 | Train Loss: 0.0430833 Vali Loss: 0.1051498 Test Loss: 0.1131369\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0384030\n",
      "\tspeed: 0.1642s/iter; left time: 3330.5913s\n",
      "\titers: 200, epoch: 10 | loss: 0.0380151\n",
      "\tspeed: 0.0982s/iter; left time: 1982.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0405867 Vali Loss: 0.1042476 Test Loss: 0.1118535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0366854\n",
      "\tspeed: 0.1636s/iter; left time: 3281.5571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0389781\n",
      "\tspeed: 0.0985s/iter; left time: 1966.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0386601 Vali Loss: 0.1039293 Test Loss: 0.1120706\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0360011\n",
      "\tspeed: 0.1641s/iter; left time: 3256.1169s\n",
      "\titers: 200, epoch: 12 | loss: 0.0358986\n",
      "\tspeed: 0.0978s/iter; left time: 1930.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.14s\n",
      "Steps: 224 | Train Loss: 0.0366836 Vali Loss: 0.1034238 Test Loss: 0.1116644\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0363298\n",
      "\tspeed: 0.1635s/iter; left time: 3207.4983s\n",
      "\titers: 200, epoch: 13 | loss: 0.0352150\n",
      "\tspeed: 0.0983s/iter; left time: 1918.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0354312 Vali Loss: 0.1032293 Test Loss: 0.1111846\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027056831866502762, rmse:0.16448961198329926, mae:0.10692021995782852, rse:0.5805065631866455\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1104277\n",
      "\tspeed: 0.1006s/iter; left time: 2242.6529s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958888\n",
      "\tspeed: 0.0982s/iter; left time: 2179.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.30s\n",
      "Steps: 224 | Train Loss: 0.1144290 Vali Loss: 0.1079746 Test Loss: 0.1105221\n",
      "Validation loss decreased (inf --> 0.107975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0823085\n",
      "\tspeed: 0.1691s/iter; left time: 3732.9607s\n",
      "\titers: 200, epoch: 2 | loss: 0.0799549\n",
      "\tspeed: 0.0987s/iter; left time: 2168.7480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.26s\n",
      "Steps: 224 | Train Loss: 0.0861994 Vali Loss: 0.1006127 Test Loss: 0.1039980\n",
      "Validation loss decreased (0.107975 --> 0.100613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0805682\n",
      "\tspeed: 0.1707s/iter; left time: 3731.1330s\n",
      "\titers: 200, epoch: 3 | loss: 0.0741031\n",
      "\tspeed: 0.0986s/iter; left time: 2145.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.38s\n",
      "Steps: 224 | Train Loss: 0.0781434 Vali Loss: 0.1008413 Test Loss: 0.1066661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0722199\n",
      "\tspeed: 0.1649s/iter; left time: 3566.4820s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663662\n",
      "\tspeed: 0.0986s/iter; left time: 2123.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.35s\n",
      "Steps: 224 | Train Loss: 0.0701794 Vali Loss: 0.1043894 Test Loss: 0.1115258\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600862\n",
      "\tspeed: 0.1654s/iter; left time: 3541.1986s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605440\n",
      "\tspeed: 0.0992s/iter; left time: 2112.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0612372 Vali Loss: 0.1049034 Test Loss: 0.1115060\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0573480\n",
      "\tspeed: 0.1641s/iter; left time: 3475.4696s\n",
      "\titers: 200, epoch: 6 | loss: 0.0534590\n",
      "\tspeed: 0.0984s/iter; left time: 2073.4958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 224 | Train Loss: 0.0543473 Vali Loss: 0.1030101 Test Loss: 0.1130545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0521577\n",
      "\tspeed: 0.1650s/iter; left time: 3458.9430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0499089\n",
      "\tspeed: 0.0994s/iter; left time: 2074.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.0494745 Vali Loss: 0.1061422 Test Loss: 0.1134916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0478449\n",
      "\tspeed: 0.1653s/iter; left time: 3426.7520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0461110\n",
      "\tspeed: 0.0986s/iter; left time: 2034.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.33s\n",
      "Steps: 224 | Train Loss: 0.0460226 Vali Loss: 0.1054480 Test Loss: 0.1134600\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442130\n",
      "\tspeed: 0.1655s/iter; left time: 3394.3082s\n",
      "\titers: 200, epoch: 9 | loss: 0.0409993\n",
      "\tspeed: 0.0995s/iter; left time: 2030.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0430741 Vali Loss: 0.1049370 Test Loss: 0.1139135\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0401310\n",
      "\tspeed: 0.1664s/iter; left time: 3374.7413s\n",
      "\titers: 200, epoch: 10 | loss: 0.0397451\n",
      "\tspeed: 0.0986s/iter; left time: 1990.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.0407757 Vali Loss: 0.1058690 Test Loss: 0.1138797\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0401663\n",
      "\tspeed: 0.1662s/iter; left time: 3334.1508s\n",
      "\titers: 200, epoch: 11 | loss: 0.0379177\n",
      "\tspeed: 0.0999s/iter; left time: 1993.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0388926 Vali Loss: 0.1049644 Test Loss: 0.1126991\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0368711\n",
      "\tspeed: 0.1670s/iter; left time: 3312.3730s\n",
      "\titers: 200, epoch: 12 | loss: 0.0373080\n",
      "\tspeed: 0.0985s/iter; left time: 1943.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.34s\n",
      "Steps: 224 | Train Loss: 0.0372816 Vali Loss: 0.1046643 Test Loss: 0.1133890\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025797396898269653, rmse:0.1606156826019287, mae:0.10399806499481201, rse:0.5668349862098694\n",
      "Intermediate time for DE and pred_len 24: 00h:11m:15.14s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1223163\n",
      "\tspeed: 0.1264s/iter; left time: 2817.8532s\n",
      "\titers: 200, epoch: 1 | loss: 0.1179984\n",
      "\tspeed: 0.1009s/iter; left time: 2240.6734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 224 | Train Loss: 0.1299141 Vali Loss: 0.1308546 Test Loss: 0.1396497\n",
      "Validation loss decreased (inf --> 0.130855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1022252\n",
      "\tspeed: 0.1756s/iter; left time: 3876.1657s\n",
      "\titers: 200, epoch: 2 | loss: 0.0907339\n",
      "\tspeed: 0.1000s/iter; left time: 2198.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.1030955 Vali Loss: 0.1370220 Test Loss: 0.1497822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0787314\n",
      "\tspeed: 0.1667s/iter; left time: 3642.4992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0721129\n",
      "\tspeed: 0.1003s/iter; left time: 2182.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.0795147 Vali Loss: 0.1362003 Test Loss: 0.1498653\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672994\n",
      "\tspeed: 0.1667s/iter; left time: 3606.0938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617716\n",
      "\tspeed: 0.0997s/iter; left time: 2146.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0662196 Vali Loss: 0.1312884 Test Loss: 0.1464415\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0554917\n",
      "\tspeed: 0.1673s/iter; left time: 3580.1698s\n",
      "\titers: 200, epoch: 5 | loss: 0.0537446\n",
      "\tspeed: 0.1049s/iter; left time: 2235.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 224 | Train Loss: 0.0566004 Vali Loss: 0.1303605 Test Loss: 0.1468938\n",
      "Validation loss decreased (0.130855 --> 0.130360).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494789\n",
      "\tspeed: 0.1903s/iter; left time: 4030.1447s\n",
      "\titers: 200, epoch: 6 | loss: 0.0491216\n",
      "\tspeed: 0.0998s/iter; left time: 2104.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0503385 Vali Loss: 0.1282276 Test Loss: 0.1452809\n",
      "Validation loss decreased (0.130360 --> 0.128228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0476965\n",
      "\tspeed: 0.1740s/iter; left time: 3646.4895s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456673\n",
      "\tspeed: 0.1014s/iter; left time: 2114.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 224 | Train Loss: 0.0460990 Vali Loss: 0.1284869 Test Loss: 0.1437094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409390\n",
      "\tspeed: 0.1675s/iter; left time: 3472.7147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0420192\n",
      "\tspeed: 0.1000s/iter; left time: 2063.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 224 | Train Loss: 0.0428764 Vali Loss: 0.1284564 Test Loss: 0.1440781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444956\n",
      "\tspeed: 0.1685s/iter; left time: 3455.6580s\n",
      "\titers: 200, epoch: 9 | loss: 0.0387594\n",
      "\tspeed: 0.1016s/iter; left time: 2074.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 224 | Train Loss: 0.0407125 Vali Loss: 0.1305699 Test Loss: 0.1438922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0374829\n",
      "\tspeed: 0.1671s/iter; left time: 3390.4842s\n",
      "\titers: 200, epoch: 10 | loss: 0.0365280\n",
      "\tspeed: 0.0998s/iter; left time: 2015.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0390599 Vali Loss: 0.1287085 Test Loss: 0.1438078\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0362832\n",
      "\tspeed: 0.1683s/iter; left time: 3375.8092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0386881\n",
      "\tspeed: 0.1010s/iter; left time: 2016.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 224 | Train Loss: 0.0373755 Vali Loss: 0.1280792 Test Loss: 0.1441514\n",
      "Validation loss decreased (0.128228 --> 0.128079).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0369315\n",
      "\tspeed: 0.1853s/iter; left time: 3675.4814s\n",
      "\titers: 200, epoch: 12 | loss: 0.0343455\n",
      "\tspeed: 0.0998s/iter; left time: 1970.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0356504 Vali Loss: 0.1269628 Test Loss: 0.1420918\n",
      "Validation loss decreased (0.128079 --> 0.126963).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0335403\n",
      "\tspeed: 0.1778s/iter; left time: 3487.3644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0352450\n",
      "\tspeed: 0.1012s/iter; left time: 1974.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 224 | Train Loss: 0.0349691 Vali Loss: 0.1272836 Test Loss: 0.1418213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0318428\n",
      "\tspeed: 0.1702s/iter; left time: 3300.6497s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324326\n",
      "\tspeed: 0.0997s/iter; left time: 1923.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.60s\n",
      "Steps: 224 | Train Loss: 0.0338992 Vali Loss: 0.1269519 Test Loss: 0.1416352\n",
      "Validation loss decreased (0.126963 --> 0.126952).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0320864\n",
      "\tspeed: 0.1923s/iter; left time: 3684.7328s\n",
      "\titers: 200, epoch: 15 | loss: 0.0322615\n",
      "\tspeed: 0.0999s/iter; left time: 1904.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.63s\n",
      "Steps: 224 | Train Loss: 0.0333974 Vali Loss: 0.1274366 Test Loss: 0.1414319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0321085\n",
      "\tspeed: 0.1708s/iter; left time: 3234.3843s\n",
      "\titers: 200, epoch: 16 | loss: 0.0311919\n",
      "\tspeed: 0.1000s/iter; left time: 1884.7500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0323608 Vali Loss: 0.1268734 Test Loss: 0.1406729\n",
      "Validation loss decreased (0.126952 --> 0.126873).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0328568\n",
      "\tspeed: 0.1755s/iter; left time: 3285.6408s\n",
      "\titers: 200, epoch: 17 | loss: 0.0315784\n",
      "\tspeed: 0.1003s/iter; left time: 1867.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0319499 Vali Loss: 0.1269051 Test Loss: 0.1413284\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0313548\n",
      "\tspeed: 0.1698s/iter; left time: 3140.1900s\n",
      "\titers: 200, epoch: 18 | loss: 0.0328749\n",
      "\tspeed: 0.0998s/iter; left time: 1835.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.0316611 Vali Loss: 0.1266844 Test Loss: 0.1419162\n",
      "Validation loss decreased (0.126873 --> 0.126684).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0298367\n",
      "\tspeed: 0.2082s/iter; left time: 3804.1620s\n",
      "\titers: 200, epoch: 19 | loss: 0.0298126\n",
      "\tspeed: 0.0998s/iter; left time: 1812.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 224 | Train Loss: 0.0311329 Vali Loss: 0.1270447 Test Loss: 0.1420292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0311288\n",
      "\tspeed: 0.1699s/iter; left time: 3065.0701s\n",
      "\titers: 200, epoch: 20 | loss: 0.0301998\n",
      "\tspeed: 0.1005s/iter; left time: 1803.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 224 | Train Loss: 0.0312470 Vali Loss: 0.1267967 Test Loss: 0.1413040\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0298048\n",
      "\tspeed: 0.1671s/iter; left time: 2978.3748s\n",
      "\titers: 200, epoch: 21 | loss: 0.0307570\n",
      "\tspeed: 0.0997s/iter; left time: 1767.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0303649 Vali Loss: 0.1261611 Test Loss: 0.1411284\n",
      "Validation loss decreased (0.126684 --> 0.126161).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0304579\n",
      "\tspeed: 0.1768s/iter; left time: 3110.2793s\n",
      "\titers: 200, epoch: 22 | loss: 0.0297905\n",
      "\tspeed: 0.1002s/iter; left time: 1753.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 224 | Train Loss: 0.0304837 Vali Loss: 0.1264128 Test Loss: 0.1408116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0307272\n",
      "\tspeed: 0.1681s/iter; left time: 2919.5898s\n",
      "\titers: 200, epoch: 23 | loss: 0.0295572\n",
      "\tspeed: 0.1003s/iter; left time: 1733.1509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.62s\n",
      "Steps: 224 | Train Loss: 0.0297434 Vali Loss: 0.1263970 Test Loss: 0.1411095\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0314769\n",
      "\tspeed: 0.1684s/iter; left time: 2888.2314s\n",
      "\titers: 200, epoch: 24 | loss: 0.0295095\n",
      "\tspeed: 0.1005s/iter; left time: 1713.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 224 | Train Loss: 0.0295767 Vali Loss: 0.1259887 Test Loss: 0.1408765\n",
      "Validation loss decreased (0.126161 --> 0.125989).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0312430\n",
      "\tspeed: 0.1914s/iter; left time: 3239.6202s\n",
      "\titers: 200, epoch: 25 | loss: 0.0308773\n",
      "\tspeed: 0.0998s/iter; left time: 1679.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0291316 Vali Loss: 0.1260642 Test Loss: 0.1408389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0319661\n",
      "\tspeed: 0.1692s/iter; left time: 2826.4961s\n",
      "\titers: 200, epoch: 26 | loss: 0.0286000\n",
      "\tspeed: 0.1011s/iter; left time: 1678.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 224 | Train Loss: 0.0289346 Vali Loss: 0.1262054 Test Loss: 0.1407005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0285632\n",
      "\tspeed: 0.1670s/iter; left time: 2750.8384s\n",
      "\titers: 200, epoch: 27 | loss: 0.0289748\n",
      "\tspeed: 0.0996s/iter; left time: 1630.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0287466 Vali Loss: 0.1262713 Test Loss: 0.1408920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0290055\n",
      "\tspeed: 0.1689s/iter; left time: 2744.3283s\n",
      "\titers: 200, epoch: 28 | loss: 0.0277826\n",
      "\tspeed: 0.1010s/iter; left time: 1632.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 224 | Train Loss: 0.0286593 Vali Loss: 0.1261419 Test Loss: 0.1399771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0292756\n",
      "\tspeed: 0.1674s/iter; left time: 2683.1799s\n",
      "\titers: 200, epoch: 29 | loss: 0.0283121\n",
      "\tspeed: 0.1000s/iter; left time: 1593.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0285146 Vali Loss: 0.1261241 Test Loss: 0.1406155\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0271864\n",
      "\tspeed: 0.1694s/iter; left time: 2677.2505s\n",
      "\titers: 200, epoch: 30 | loss: 0.0279842\n",
      "\tspeed: 0.1019s/iter; left time: 1600.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 224 | Train Loss: 0.0283375 Vali Loss: 0.1260011 Test Loss: 0.1401229\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0279219\n",
      "\tspeed: 0.1690s/iter; left time: 2632.6991s\n",
      "\titers: 200, epoch: 31 | loss: 0.0284825\n",
      "\tspeed: 0.0994s/iter; left time: 1539.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0281008 Vali Loss: 0.1260184 Test Loss: 0.1401648\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0274448\n",
      "\tspeed: 0.1668s/iter; left time: 2561.8487s\n",
      "\titers: 200, epoch: 32 | loss: 0.0278788\n",
      "\tspeed: 0.0994s/iter; left time: 1517.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0280171 Vali Loss: 0.1261915 Test Loss: 0.1406342\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0274708\n",
      "\tspeed: 0.1667s/iter; left time: 2522.5358s\n",
      "\titers: 200, epoch: 33 | loss: 0.0282368\n",
      "\tspeed: 0.0995s/iter; left time: 1495.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0280225 Vali Loss: 0.1261243 Test Loss: 0.1408214\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0286569\n",
      "\tspeed: 0.1671s/iter; left time: 2490.5578s\n",
      "\titers: 200, epoch: 34 | loss: 0.0280261\n",
      "\tspeed: 0.0994s/iter; left time: 1471.3830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0278311 Vali Loss: 0.1261183 Test Loss: 0.1404821\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04204396903514862, rmse:0.20504626631736755, mae:0.14087654650211334, rse:0.7261102199554443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1242477\n",
      "\tspeed: 0.1012s/iter; left time: 2257.2450s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171697\n",
      "\tspeed: 0.0997s/iter; left time: 2213.0749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.1299392 Vali Loss: 0.1311586 Test Loss: 0.1394444\n",
      "Validation loss decreased (inf --> 0.131159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1039839\n",
      "\tspeed: 0.1771s/iter; left time: 3910.7070s\n",
      "\titers: 200, epoch: 2 | loss: 0.0935863\n",
      "\tspeed: 0.0994s/iter; left time: 2183.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.1030212 Vali Loss: 0.1342872 Test Loss: 0.1477258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0777247\n",
      "\tspeed: 0.1686s/iter; left time: 3684.1362s\n",
      "\titers: 200, epoch: 3 | loss: 0.0737206\n",
      "\tspeed: 0.0994s/iter; left time: 2161.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0787656 Vali Loss: 0.1355689 Test Loss: 0.1499120\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638760\n",
      "\tspeed: 0.1678s/iter; left time: 3628.4389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635152\n",
      "\tspeed: 0.0993s/iter; left time: 2138.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0655781 Vali Loss: 0.1333372 Test Loss: 0.1491168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0555358\n",
      "\tspeed: 0.1679s/iter; left time: 3593.6052s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573160\n",
      "\tspeed: 0.0993s/iter; left time: 2115.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0570693 Vali Loss: 0.1329813 Test Loss: 0.1468537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0531334\n",
      "\tspeed: 0.1681s/iter; left time: 3561.4293s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529571\n",
      "\tspeed: 0.0997s/iter; left time: 2101.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0510583 Vali Loss: 0.1324312 Test Loss: 0.1463843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0469876\n",
      "\tspeed: 0.1686s/iter; left time: 3532.4185s\n",
      "\titers: 200, epoch: 7 | loss: 0.0458747\n",
      "\tspeed: 0.0994s/iter; left time: 2072.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0464710 Vali Loss: 0.1307112 Test Loss: 0.1434968\n",
      "Validation loss decreased (0.131159 --> 0.130711).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0451981\n",
      "\tspeed: 0.1938s/iter; left time: 4018.4328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0411316\n",
      "\tspeed: 0.0996s/iter; left time: 2055.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0429134 Vali Loss: 0.1289652 Test Loss: 0.1438801\n",
      "Validation loss decreased (0.130711 --> 0.128965).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396862\n",
      "\tspeed: 0.1764s/iter; left time: 3617.1161s\n",
      "\titers: 200, epoch: 9 | loss: 0.0396968\n",
      "\tspeed: 0.0991s/iter; left time: 2023.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0406364 Vali Loss: 0.1287583 Test Loss: 0.1428453\n",
      "Validation loss decreased (0.128965 --> 0.128758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0372063\n",
      "\tspeed: 0.1759s/iter; left time: 3567.7333s\n",
      "\titers: 200, epoch: 10 | loss: 0.0396097\n",
      "\tspeed: 0.0993s/iter; left time: 2004.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0382141 Vali Loss: 0.1289230 Test Loss: 0.1427508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0397195\n",
      "\tspeed: 0.1671s/iter; left time: 3352.7139s\n",
      "\titers: 200, epoch: 11 | loss: 0.0351189\n",
      "\tspeed: 0.0993s/iter; left time: 1982.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0368077 Vali Loss: 0.1288192 Test Loss: 0.1422276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0337716\n",
      "\tspeed: 0.1684s/iter; left time: 3340.3024s\n",
      "\titers: 200, epoch: 12 | loss: 0.0348658\n",
      "\tspeed: 0.0992s/iter; left time: 1958.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0356215 Vali Loss: 0.1283011 Test Loss: 0.1428052\n",
      "Validation loss decreased (0.128758 --> 0.128301).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0344515\n",
      "\tspeed: 0.1825s/iter; left time: 3578.4759s\n",
      "\titers: 200, epoch: 13 | loss: 0.0332311\n",
      "\tspeed: 0.0994s/iter; left time: 1939.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0347675 Vali Loss: 0.1277235 Test Loss: 0.1420104\n",
      "Validation loss decreased (0.128301 --> 0.127723).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0325857\n",
      "\tspeed: 0.1761s/iter; left time: 3414.2019s\n",
      "\titers: 200, epoch: 14 | loss: 0.0326958\n",
      "\tspeed: 0.0993s/iter; left time: 1916.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0337991 Vali Loss: 0.1276056 Test Loss: 0.1410959\n",
      "Validation loss decreased (0.127723 --> 0.127606).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0332377\n",
      "\tspeed: 0.1800s/iter; left time: 3448.8690s\n",
      "\titers: 200, epoch: 15 | loss: 0.0326112\n",
      "\tspeed: 0.0993s/iter; left time: 1893.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0331643 Vali Loss: 0.1276101 Test Loss: 0.1415685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0317841\n",
      "\tspeed: 0.1677s/iter; left time: 3177.3019s\n",
      "\titers: 200, epoch: 16 | loss: 0.0336634\n",
      "\tspeed: 0.1000s/iter; left time: 1883.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 224 | Train Loss: 0.0319262 Vali Loss: 0.1273212 Test Loss: 0.1411992\n",
      "Validation loss decreased (0.127606 --> 0.127321).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0315294\n",
      "\tspeed: 0.1766s/iter; left time: 3306.3062s\n",
      "\titers: 200, epoch: 17 | loss: 0.0402153\n",
      "\tspeed: 0.0992s/iter; left time: 1847.0172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0316037 Vali Loss: 0.1274369 Test Loss: 0.1422841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0310733\n",
      "\tspeed: 0.1675s/iter; left time: 3096.9075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0316665\n",
      "\tspeed: 0.0992s/iter; left time: 1825.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0310502 Vali Loss: 0.1270434 Test Loss: 0.1407711\n",
      "Validation loss decreased (0.127321 --> 0.127043).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0287771\n",
      "\tspeed: 0.1760s/iter; left time: 3216.1727s\n",
      "\titers: 200, epoch: 19 | loss: 0.0305514\n",
      "\tspeed: 0.0992s/iter; left time: 1802.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0303930 Vali Loss: 0.1270769 Test Loss: 0.1405970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0289193\n",
      "\tspeed: 0.1678s/iter; left time: 3027.4632s\n",
      "\titers: 200, epoch: 20 | loss: 0.0286493\n",
      "\tspeed: 0.0992s/iter; left time: 1779.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0299198 Vali Loss: 0.1268112 Test Loss: 0.1410203\n",
      "Validation loss decreased (0.127043 --> 0.126811).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0310301\n",
      "\tspeed: 0.1729s/iter; left time: 3080.7583s\n",
      "\titers: 200, epoch: 21 | loss: 0.0276777\n",
      "\tspeed: 0.0992s/iter; left time: 1758.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.42s\n",
      "Steps: 224 | Train Loss: 0.0296345 Vali Loss: 0.1268980 Test Loss: 0.1419411\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0292942\n",
      "\tspeed: 0.1676s/iter; left time: 2949.2473s\n",
      "\titers: 200, epoch: 22 | loss: 0.0303327\n",
      "\tspeed: 0.0996s/iter; left time: 1742.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0295196 Vali Loss: 0.1270390 Test Loss: 0.1411565\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0279907\n",
      "\tspeed: 0.1675s/iter; left time: 2909.5327s\n",
      "\titers: 200, epoch: 23 | loss: 0.0285120\n",
      "\tspeed: 0.0996s/iter; left time: 1719.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0291036 Vali Loss: 0.1268217 Test Loss: 0.1409847\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0285618\n",
      "\tspeed: 0.1670s/iter; left time: 2864.0232s\n",
      "\titers: 200, epoch: 24 | loss: 0.0295330\n",
      "\tspeed: 0.0991s/iter; left time: 1690.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.41s\n",
      "Steps: 224 | Train Loss: 0.0287539 Vali Loss: 0.1268914 Test Loss: 0.1410079\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0284254\n",
      "\tspeed: 0.1687s/iter; left time: 2854.9025s\n",
      "\titers: 200, epoch: 25 | loss: 0.0317466\n",
      "\tspeed: 0.0992s/iter; left time: 1669.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0286661 Vali Loss: 0.1269969 Test Loss: 0.1407455\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0279723\n",
      "\tspeed: 0.1670s/iter; left time: 2789.8496s\n",
      "\titers: 200, epoch: 26 | loss: 0.0280906\n",
      "\tspeed: 0.0995s/iter; left time: 1651.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0282482 Vali Loss: 0.1268042 Test Loss: 0.1406889\n",
      "Validation loss decreased (0.126811 --> 0.126804).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0271803\n",
      "\tspeed: 0.1742s/iter; left time: 2871.0541s\n",
      "\titers: 200, epoch: 27 | loss: 0.0277322\n",
      "\tspeed: 0.0992s/iter; left time: 1624.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0281096 Vali Loss: 0.1267876 Test Loss: 0.1410657\n",
      "Validation loss decreased (0.126804 --> 0.126788).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0290098\n",
      "\tspeed: 0.1758s/iter; left time: 2856.5209s\n",
      "\titers: 200, epoch: 28 | loss: 0.0280983\n",
      "\tspeed: 0.1004s/iter; left time: 1621.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.63s\n",
      "Steps: 224 | Train Loss: 0.0280412 Vali Loss: 0.1270118 Test Loss: 0.1409286\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0277480\n",
      "\tspeed: 0.1673s/iter; left time: 2681.9287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0283032\n",
      "\tspeed: 0.0996s/iter; left time: 1586.6668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0277198 Vali Loss: 0.1267704 Test Loss: 0.1407932\n",
      "Validation loss decreased (0.126788 --> 0.126770).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0269211\n",
      "\tspeed: 0.1756s/iter; left time: 2775.2859s\n",
      "\titers: 200, epoch: 30 | loss: 0.0287858\n",
      "\tspeed: 0.0996s/iter; left time: 1563.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0275932 Vali Loss: 0.1266454 Test Loss: 0.1408675\n",
      "Validation loss decreased (0.126770 --> 0.126645).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0289489\n",
      "\tspeed: 0.1765s/iter; left time: 2750.1467s\n",
      "\titers: 200, epoch: 31 | loss: 0.0269842\n",
      "\tspeed: 0.0995s/iter; left time: 1540.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0275068 Vali Loss: 0.1267893 Test Loss: 0.1410453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0268948\n",
      "\tspeed: 0.1672s/iter; left time: 2568.2920s\n",
      "\titers: 200, epoch: 32 | loss: 0.0275908\n",
      "\tspeed: 0.0994s/iter; left time: 1517.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0272988 Vali Loss: 0.1267322 Test Loss: 0.1409021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0268456\n",
      "\tspeed: 0.1672s/iter; left time: 2529.4851s\n",
      "\titers: 200, epoch: 33 | loss: 0.0273315\n",
      "\tspeed: 0.0992s/iter; left time: 1491.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.42s\n",
      "Steps: 224 | Train Loss: 0.0273786 Vali Loss: 0.1266959 Test Loss: 0.1406758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0265508\n",
      "\tspeed: 0.1676s/iter; left time: 2498.8035s\n",
      "\titers: 200, epoch: 34 | loss: 0.0265951\n",
      "\tspeed: 0.0992s/iter; left time: 1469.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0271909 Vali Loss: 0.1265954 Test Loss: 0.1406779\n",
      "Validation loss decreased (0.126645 --> 0.126595).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0265231\n",
      "\tspeed: 0.1753s/iter; left time: 2574.9398s\n",
      "\titers: 200, epoch: 35 | loss: 0.0273827\n",
      "\tspeed: 0.0992s/iter; left time: 1446.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0273014 Vali Loss: 0.1266384 Test Loss: 0.1406149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0272715\n",
      "\tspeed: 0.1679s/iter; left time: 2427.9285s\n",
      "\titers: 200, epoch: 36 | loss: 0.0263559\n",
      "\tspeed: 0.0992s/iter; left time: 1425.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0269461 Vali Loss: 0.1266462 Test Loss: 0.1410074\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0273352\n",
      "\tspeed: 0.1672s/iter; left time: 2380.9293s\n",
      "\titers: 200, epoch: 37 | loss: 0.0265992\n",
      "\tspeed: 0.0993s/iter; left time: 1403.3173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0268802 Vali Loss: 0.1267088 Test Loss: 0.1409060\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0262193\n",
      "\tspeed: 0.1681s/iter; left time: 2356.0506s\n",
      "\titers: 200, epoch: 38 | loss: 0.0269825\n",
      "\tspeed: 0.0990s/iter; left time: 1376.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0269931 Vali Loss: 0.1266754 Test Loss: 0.1408476\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0283489\n",
      "\tspeed: 0.1672s/iter; left time: 2305.8184s\n",
      "\titers: 200, epoch: 39 | loss: 0.0262878\n",
      "\tspeed: 0.0992s/iter; left time: 1358.1670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.43s\n",
      "Steps: 224 | Train Loss: 0.0268186 Vali Loss: 0.1266399 Test Loss: 0.1409293\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0266380\n",
      "\tspeed: 0.1672s/iter; left time: 2268.1683s\n",
      "\titers: 200, epoch: 40 | loss: 0.0259960\n",
      "\tspeed: 0.0993s/iter; left time: 1336.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:22.43s\n",
      "Steps: 224 | Train Loss: 0.0267726 Vali Loss: 0.1267287 Test Loss: 0.1406187\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0269313\n",
      "\tspeed: 0.1679s/iter; left time: 2240.0805s\n",
      "\titers: 200, epoch: 41 | loss: 0.0265634\n",
      "\tspeed: 0.0995s/iter; left time: 1317.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0268338 Vali Loss: 0.1266552 Test Loss: 0.1407018\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0262663\n",
      "\tspeed: 0.1695s/iter; left time: 2222.7706s\n",
      "\titers: 200, epoch: 42 | loss: 0.0278459\n",
      "\tspeed: 0.0993s/iter; left time: 1291.9458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0267926 Vali Loss: 0.1266343 Test Loss: 0.1407602\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0261751\n",
      "\tspeed: 0.1680s/iter; left time: 2166.1836s\n",
      "\titers: 200, epoch: 43 | loss: 0.0273091\n",
      "\tspeed: 0.0995s/iter; left time: 1273.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0268088 Vali Loss: 0.1266787 Test Loss: 0.1408890\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0276403\n",
      "\tspeed: 0.1675s/iter; left time: 2121.9633s\n",
      "\titers: 200, epoch: 44 | loss: 0.0258890\n",
      "\tspeed: 0.0988s/iter; left time: 1242.3966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:22.37s\n",
      "Steps: 224 | Train Loss: 0.0266744 Vali Loss: 0.1265327 Test Loss: 0.1406834\n",
      "Validation loss decreased (0.126595 --> 0.126533).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0271499\n",
      "\tspeed: 0.1774s/iter; left time: 2207.2382s\n",
      "\titers: 200, epoch: 45 | loss: 0.0256475\n",
      "\tspeed: 0.0997s/iter; left time: 1230.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0265942 Vali Loss: 0.1266127 Test Loss: 0.1406820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0264941\n",
      "\tspeed: 0.1676s/iter; left time: 2047.6383s\n",
      "\titers: 200, epoch: 46 | loss: 0.0259737\n",
      "\tspeed: 0.0993s/iter; left time: 1203.2065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0265642 Vali Loss: 0.1265820 Test Loss: 0.1407245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0254731\n",
      "\tspeed: 0.1670s/iter; left time: 2003.3742s\n",
      "\titers: 200, epoch: 47 | loss: 0.0265677\n",
      "\tspeed: 0.0996s/iter; left time: 1184.6251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0265836 Vali Loss: 0.1266140 Test Loss: 0.1408633\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0276974\n",
      "\tspeed: 0.1670s/iter; left time: 1966.5134s\n",
      "\titers: 200, epoch: 48 | loss: 0.0270967\n",
      "\tspeed: 0.0991s/iter; left time: 1157.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0265990 Vali Loss: 0.1265998 Test Loss: 0.1405815\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0262738\n",
      "\tspeed: 0.1675s/iter; left time: 1934.4115s\n",
      "\titers: 200, epoch: 49 | loss: 0.0273522\n",
      "\tspeed: 0.0996s/iter; left time: 1139.8608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0265748 Vali Loss: 0.1264659 Test Loss: 0.1406672\n",
      "Validation loss decreased (0.126533 --> 0.126466).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0260855\n",
      "\tspeed: 0.1769s/iter; left time: 2003.1773s\n",
      "\titers: 200, epoch: 50 | loss: 0.0267769\n",
      "\tspeed: 0.0992s/iter; left time: 1113.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0264955 Vali Loss: 0.1264177 Test Loss: 0.1403963\n",
      "Validation loss decreased (0.126466 --> 0.126418).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0259825\n",
      "\tspeed: 0.1780s/iter; left time: 1975.9628s\n",
      "\titers: 200, epoch: 51 | loss: 0.0265678\n",
      "\tspeed: 0.0995s/iter; left time: 1094.8766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0265601 Vali Loss: 0.1264171 Test Loss: 0.1407261\n",
      "Validation loss decreased (0.126418 --> 0.126417).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0255395\n",
      "\tspeed: 0.1752s/iter; left time: 1905.7906s\n",
      "\titers: 200, epoch: 52 | loss: 0.0261697\n",
      "\tspeed: 0.0994s/iter; left time: 1071.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0265688 Vali Loss: 0.1265205 Test Loss: 0.1405940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0261250\n",
      "\tspeed: 0.1681s/iter; left time: 1791.1259s\n",
      "\titers: 200, epoch: 53 | loss: 0.0263986\n",
      "\tspeed: 0.0994s/iter; left time: 1049.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0264487 Vali Loss: 0.1265929 Test Loss: 0.1407698\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0263977\n",
      "\tspeed: 0.1674s/iter; left time: 1746.1420s\n",
      "\titers: 200, epoch: 54 | loss: 0.0268512\n",
      "\tspeed: 0.0993s/iter; left time: 1026.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0264494 Vali Loss: 0.1265761 Test Loss: 0.1408572\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0282792\n",
      "\tspeed: 0.1675s/iter; left time: 1709.2491s\n",
      "\titers: 200, epoch: 55 | loss: 0.0252980\n",
      "\tspeed: 0.0992s/iter; left time: 1002.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0264651 Vali Loss: 0.1266173 Test Loss: 0.1409407\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0268920\n",
      "\tspeed: 0.1676s/iter; left time: 1672.7793s\n",
      "\titers: 200, epoch: 56 | loss: 0.0262528\n",
      "\tspeed: 0.0995s/iter; left time: 982.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0263788 Vali Loss: 0.1266261 Test Loss: 0.1407852\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0261843\n",
      "\tspeed: 0.1681s/iter; left time: 1639.8427s\n",
      "\titers: 200, epoch: 57 | loss: 0.0265339\n",
      "\tspeed: 0.0994s/iter; left time: 959.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0264286 Vali Loss: 0.1265251 Test Loss: 0.1406273\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0257913\n",
      "\tspeed: 0.1670s/iter; left time: 1591.8488s\n",
      "\titers: 200, epoch: 58 | loss: 0.0256953\n",
      "\tspeed: 0.0995s/iter; left time: 938.6728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0265050 Vali Loss: 0.1264443 Test Loss: 0.1406734\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0269404\n",
      "\tspeed: 0.1679s/iter; left time: 1563.2571s\n",
      "\titers: 200, epoch: 59 | loss: 0.0263439\n",
      "\tspeed: 0.0993s/iter; left time: 914.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0264420 Vali Loss: 0.1266005 Test Loss: 0.1408871\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0265904\n",
      "\tspeed: 0.1681s/iter; left time: 1527.2104s\n",
      "\titers: 200, epoch: 60 | loss: 0.0249333\n",
      "\tspeed: 0.0996s/iter; left time: 894.6528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0263893 Vali Loss: 0.1265873 Test Loss: 0.1406013\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0261007\n",
      "\tspeed: 0.1683s/iter; left time: 1491.6577s\n",
      "\titers: 200, epoch: 61 | loss: 0.0266510\n",
      "\tspeed: 0.0993s/iter; left time: 869.7511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0264167 Vali Loss: 0.1265362 Test Loss: 0.1407479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04155511409044266, rmse:0.20385071635246277, mae:0.14072604477405548, rse:0.7218766212463379\n",
      "Intermediate time for DE and pred_len 96: 00h:43m:13.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1261648\n",
      "\tspeed: 0.1298s/iter; left time: 2880.7539s\n",
      "\titers: 200, epoch: 1 | loss: 0.1190995\n",
      "\tspeed: 0.1011s/iter; left time: 2235.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.1339292 Vali Loss: 0.1335317 Test Loss: 0.1439572\n",
      "Validation loss decreased (inf --> 0.133532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1051248\n",
      "\tspeed: 0.1748s/iter; left time: 3840.6729s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949041\n",
      "\tspeed: 0.1009s/iter; left time: 2207.4692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.1056621 Vali Loss: 0.1374970 Test Loss: 0.1528661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0788745\n",
      "\tspeed: 0.1684s/iter; left time: 3663.2307s\n",
      "\titers: 200, epoch: 3 | loss: 0.0743790\n",
      "\tspeed: 0.1009s/iter; left time: 2185.6150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0800766 Vali Loss: 0.1391651 Test Loss: 0.1580985\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0654544\n",
      "\tspeed: 0.1691s/iter; left time: 3641.0910s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631503\n",
      "\tspeed: 0.1010s/iter; left time: 2165.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0666773 Vali Loss: 0.1346968 Test Loss: 0.1523327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569980\n",
      "\tspeed: 0.1691s/iter; left time: 3603.2151s\n",
      "\titers: 200, epoch: 5 | loss: 0.0533941\n",
      "\tspeed: 0.1011s/iter; left time: 2143.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0580855 Vali Loss: 0.1348484 Test Loss: 0.1486578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0516111\n",
      "\tspeed: 0.1696s/iter; left time: 3576.4654s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490716\n",
      "\tspeed: 0.1009s/iter; left time: 2118.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0514214 Vali Loss: 0.1381943 Test Loss: 0.1528778\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464494\n",
      "\tspeed: 0.1686s/iter; left time: 3516.9433s\n",
      "\titers: 200, epoch: 7 | loss: 0.0477641\n",
      "\tspeed: 0.1010s/iter; left time: 2096.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0472122 Vali Loss: 0.1324671 Test Loss: 0.1473247\n",
      "Validation loss decreased (0.133532 --> 0.132467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0425316\n",
      "\tspeed: 0.1749s/iter; left time: 3609.7500s\n",
      "\titers: 200, epoch: 8 | loss: 0.0432509\n",
      "\tspeed: 0.1009s/iter; left time: 2073.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 223 | Train Loss: 0.0445452 Vali Loss: 0.1312808 Test Loss: 0.1476530\n",
      "Validation loss decreased (0.132467 --> 0.131281).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0425568\n",
      "\tspeed: 0.1777s/iter; left time: 3627.8907s\n",
      "\titers: 200, epoch: 9 | loss: 0.0417050\n",
      "\tspeed: 0.1020s/iter; left time: 2072.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 223 | Train Loss: 0.0420848 Vali Loss: 0.1306852 Test Loss: 0.1460166\n",
      "Validation loss decreased (0.131281 --> 0.130685).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378647\n",
      "\tspeed: 0.1766s/iter; left time: 3567.0309s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402136\n",
      "\tspeed: 0.1026s/iter; left time: 2062.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:23.01s\n",
      "Steps: 223 | Train Loss: 0.0400473 Vali Loss: 0.1308217 Test Loss: 0.1454586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0374846\n",
      "\tspeed: 0.1708s/iter; left time: 3410.6057s\n",
      "\titers: 200, epoch: 11 | loss: 0.0383585\n",
      "\tspeed: 0.1024s/iter; left time: 2035.1479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.0382027 Vali Loss: 0.1303351 Test Loss: 0.1458236\n",
      "Validation loss decreased (0.130685 --> 0.130335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0374159\n",
      "\tspeed: 0.1788s/iter; left time: 3531.5616s\n",
      "\titers: 200, epoch: 12 | loss: 0.0373506\n",
      "\tspeed: 0.1012s/iter; left time: 1988.8510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0376595 Vali Loss: 0.1295768 Test Loss: 0.1450953\n",
      "Validation loss decreased (0.130335 --> 0.129577).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0358182\n",
      "\tspeed: 0.1874s/iter; left time: 3659.5721s\n",
      "\titers: 200, epoch: 13 | loss: 0.0358183\n",
      "\tspeed: 0.1017s/iter; left time: 1975.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.0360024 Vali Loss: 0.1304294 Test Loss: 0.1469097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0353733\n",
      "\tspeed: 0.1710s/iter; left time: 3301.2346s\n",
      "\titers: 200, epoch: 14 | loss: 0.0349147\n",
      "\tspeed: 0.1022s/iter; left time: 1961.7360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.05s\n",
      "Steps: 223 | Train Loss: 0.0355296 Vali Loss: 0.1294342 Test Loss: 0.1449126\n",
      "Validation loss decreased (0.129577 --> 0.129434).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0354217\n",
      "\tspeed: 0.1826s/iter; left time: 3483.0609s\n",
      "\titers: 200, epoch: 15 | loss: 0.0349589\n",
      "\tspeed: 0.1029s/iter; left time: 1953.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.23s\n",
      "Steps: 223 | Train Loss: 0.0346953 Vali Loss: 0.1293914 Test Loss: 0.1447888\n",
      "Validation loss decreased (0.129434 --> 0.129391).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0353416\n",
      "\tspeed: 0.1784s/iter; left time: 3364.5301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0330689\n",
      "\tspeed: 0.1011s/iter; left time: 1896.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0347494 Vali Loss: 0.1293732 Test Loss: 0.1447825\n",
      "Validation loss decreased (0.129391 --> 0.129373).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0339002\n",
      "\tspeed: 0.1782s/iter; left time: 3320.3985s\n",
      "\titers: 200, epoch: 17 | loss: 0.0314987\n",
      "\tspeed: 0.1019s/iter; left time: 1888.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 223 | Train Loss: 0.0332876 Vali Loss: 0.1293050 Test Loss: 0.1444554\n",
      "Validation loss decreased (0.129373 --> 0.129305).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0325020\n",
      "\tspeed: 0.1765s/iter; left time: 3249.8851s\n",
      "\titers: 200, epoch: 18 | loss: 0.0317712\n",
      "\tspeed: 0.1010s/iter; left time: 1850.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0327897 Vali Loss: 0.1290222 Test Loss: 0.1443444\n",
      "Validation loss decreased (0.129305 --> 0.129022).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0323275\n",
      "\tspeed: 0.1878s/iter; left time: 3415.4863s\n",
      "\titers: 200, epoch: 19 | loss: 0.0306696\n",
      "\tspeed: 0.1024s/iter; left time: 1851.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:23.07s\n",
      "Steps: 223 | Train Loss: 0.0321643 Vali Loss: 0.1289278 Test Loss: 0.1446663\n",
      "Validation loss decreased (0.129022 --> 0.128928).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0317876\n",
      "\tspeed: 0.1973s/iter; left time: 3544.8125s\n",
      "\titers: 200, epoch: 20 | loss: 0.0313587\n",
      "\tspeed: 0.1014s/iter; left time: 1811.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0316554 Vali Loss: 0.1286264 Test Loss: 0.1439690\n",
      "Validation loss decreased (0.128928 --> 0.128626).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0304738\n",
      "\tspeed: 0.1830s/iter; left time: 3246.3841s\n",
      "\titers: 200, epoch: 21 | loss: 0.0327107\n",
      "\tspeed: 0.1028s/iter; left time: 1813.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 223 | Train Loss: 0.0315763 Vali Loss: 0.1285892 Test Loss: 0.1445394\n",
      "Validation loss decreased (0.128626 --> 0.128589).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0316087\n",
      "\tspeed: 0.1925s/iter; left time: 3371.8919s\n",
      "\titers: 200, epoch: 22 | loss: 0.0318276\n",
      "\tspeed: 0.1010s/iter; left time: 1759.2516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 223 | Train Loss: 0.0310572 Vali Loss: 0.1286587 Test Loss: 0.1445479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0302220\n",
      "\tspeed: 0.1707s/iter; left time: 2951.9827s\n",
      "\titers: 200, epoch: 23 | loss: 0.0304300\n",
      "\tspeed: 0.1021s/iter; left time: 1755.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:23.07s\n",
      "Steps: 223 | Train Loss: 0.0307635 Vali Loss: 0.1284783 Test Loss: 0.1442952\n",
      "Validation loss decreased (0.128589 --> 0.128478).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0304984\n",
      "\tspeed: 0.1763s/iter; left time: 3009.3992s\n",
      "\titers: 200, epoch: 24 | loss: 0.0302245\n",
      "\tspeed: 0.1016s/iter; left time: 1724.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0307209 Vali Loss: 0.1284794 Test Loss: 0.1443956\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0304130\n",
      "\tspeed: 0.1709s/iter; left time: 2880.2588s\n",
      "\titers: 200, epoch: 25 | loss: 0.0304252\n",
      "\tspeed: 0.1025s/iter; left time: 1716.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:23.06s\n",
      "Steps: 223 | Train Loss: 0.0305077 Vali Loss: 0.1283769 Test Loss: 0.1444592\n",
      "Validation loss decreased (0.128478 --> 0.128377).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0312527\n",
      "\tspeed: 0.1832s/iter; left time: 3046.0227s\n",
      "\titers: 200, epoch: 26 | loss: 0.0312282\n",
      "\tspeed: 0.1019s/iter; left time: 1684.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.88s\n",
      "Steps: 223 | Train Loss: 0.0302471 Vali Loss: 0.1284113 Test Loss: 0.1442370\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0307134\n",
      "\tspeed: 0.1700s/iter; left time: 2788.0699s\n",
      "\titers: 200, epoch: 27 | loss: 0.0288876\n",
      "\tspeed: 0.1026s/iter; left time: 1673.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.92s\n",
      "Steps: 223 | Train Loss: 0.0298442 Vali Loss: 0.1283943 Test Loss: 0.1446010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0302495\n",
      "\tspeed: 0.1689s/iter; left time: 2733.5069s\n",
      "\titers: 200, epoch: 28 | loss: 0.0294432\n",
      "\tspeed: 0.1016s/iter; left time: 1633.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0296582 Vali Loss: 0.1284400 Test Loss: 0.1444808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0289791\n",
      "\tspeed: 0.1686s/iter; left time: 2689.7123s\n",
      "\titers: 200, epoch: 29 | loss: 0.0302416\n",
      "\tspeed: 0.1021s/iter; left time: 1618.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0295461 Vali Loss: 0.1284262 Test Loss: 0.1441522\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0299884\n",
      "\tspeed: 0.1717s/iter; left time: 2702.0460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0282255\n",
      "\tspeed: 0.1018s/iter; left time: 1591.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 223 | Train Loss: 0.0294263 Vali Loss: 0.1284449 Test Loss: 0.1445789\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0307204\n",
      "\tspeed: 0.1689s/iter; left time: 2619.1072s\n",
      "\titers: 200, epoch: 31 | loss: 0.0296950\n",
      "\tspeed: 0.1019s/iter; left time: 1570.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0292683 Vali Loss: 0.1281265 Test Loss: 0.1442216\n",
      "Validation loss decreased (0.128377 --> 0.128127).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0292686\n",
      "\tspeed: 0.1794s/iter; left time: 2741.9895s\n",
      "\titers: 200, epoch: 32 | loss: 0.0289746\n",
      "\tspeed: 0.1011s/iter; left time: 1536.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0290840 Vali Loss: 0.1284545 Test Loss: 0.1444478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0279634\n",
      "\tspeed: 0.1701s/iter; left time: 2563.0027s\n",
      "\titers: 200, epoch: 33 | loss: 0.0291580\n",
      "\tspeed: 0.1025s/iter; left time: 1533.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.99s\n",
      "Steps: 223 | Train Loss: 0.0290805 Vali Loss: 0.1283684 Test Loss: 0.1443674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0277546\n",
      "\tspeed: 0.1707s/iter; left time: 2533.4751s\n",
      "\titers: 200, epoch: 34 | loss: 0.0292509\n",
      "\tspeed: 0.1015s/iter; left time: 1496.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0289610 Vali Loss: 0.1284619 Test Loss: 0.1445035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0279095\n",
      "\tspeed: 0.1706s/iter; left time: 2493.7406s\n",
      "\titers: 200, epoch: 35 | loss: 0.0283519\n",
      "\tspeed: 0.1015s/iter; left time: 1473.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0288164 Vali Loss: 0.1283115 Test Loss: 0.1441863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0276260\n",
      "\tspeed: 0.1719s/iter; left time: 2473.9977s\n",
      "\titers: 200, epoch: 36 | loss: 0.0282516\n",
      "\tspeed: 0.1017s/iter; left time: 1454.0066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0287018 Vali Loss: 0.1282796 Test Loss: 0.1444267\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0282841\n",
      "\tspeed: 0.1702s/iter; left time: 2412.9425s\n",
      "\titers: 200, epoch: 37 | loss: 0.0275572\n",
      "\tspeed: 0.1017s/iter; left time: 1431.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 223 | Train Loss: 0.0287441 Vali Loss: 0.1285490 Test Loss: 0.1445745\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0285645\n",
      "\tspeed: 0.1708s/iter; left time: 2382.3946s\n",
      "\titers: 200, epoch: 38 | loss: 0.0292528\n",
      "\tspeed: 0.1020s/iter; left time: 1413.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 223 | Train Loss: 0.0286795 Vali Loss: 0.1284727 Test Loss: 0.1444877\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0287385\n",
      "\tspeed: 0.1696s/iter; left time: 2327.4948s\n",
      "\titers: 200, epoch: 39 | loss: 0.0279627\n",
      "\tspeed: 0.1016s/iter; left time: 1384.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.0284555 Vali Loss: 0.1285705 Test Loss: 0.1444850\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0289875\n",
      "\tspeed: 0.1722s/iter; left time: 2325.6854s\n",
      "\titers: 200, epoch: 40 | loss: 0.0288850\n",
      "\tspeed: 0.1024s/iter; left time: 1372.6636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:23.09s\n",
      "Steps: 223 | Train Loss: 0.0284726 Vali Loss: 0.1283926 Test Loss: 0.1443235\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0283259\n",
      "\tspeed: 0.1705s/iter; left time: 2263.9987s\n",
      "\titers: 200, epoch: 41 | loss: 0.0278825\n",
      "\tspeed: 0.1027s/iter; left time: 1353.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 223 | Train Loss: 0.0285104 Vali Loss: 0.1286705 Test Loss: 0.1444085\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043613020330667496, rmse:0.20883730053901672, mae:0.14422158896923065, rse:0.7397185564041138\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1338459\n",
      "\tspeed: 0.1034s/iter; left time: 2294.7097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1213693\n",
      "\tspeed: 0.1014s/iter; left time: 2241.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 223 | Train Loss: 0.1337232 Vali Loss: 0.1337726 Test Loss: 0.1441684\n",
      "Validation loss decreased (inf --> 0.133773).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1043951\n",
      "\tspeed: 0.1813s/iter; left time: 3984.8829s\n",
      "\titers: 200, epoch: 2 | loss: 0.0920857\n",
      "\tspeed: 0.1024s/iter; left time: 2240.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 223 | Train Loss: 0.1057510 Vali Loss: 0.1365143 Test Loss: 0.1516177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821584\n",
      "\tspeed: 0.1726s/iter; left time: 3755.3538s\n",
      "\titers: 200, epoch: 3 | loss: 0.0746673\n",
      "\tspeed: 0.1011s/iter; left time: 2188.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.89s\n",
      "Steps: 223 | Train Loss: 0.0797383 Vali Loss: 0.1378467 Test Loss: 0.1510403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0667732\n",
      "\tspeed: 0.1697s/iter; left time: 3653.9238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0627262\n",
      "\tspeed: 0.1010s/iter; left time: 2164.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0662417 Vali Loss: 0.1371741 Test Loss: 0.1498331\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562829\n",
      "\tspeed: 0.1699s/iter; left time: 3620.2836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0550903\n",
      "\tspeed: 0.1010s/iter; left time: 2143.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0572172 Vali Loss: 0.1346277 Test Loss: 0.1484157\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0504830\n",
      "\tspeed: 0.1704s/iter; left time: 3592.5173s\n",
      "\titers: 200, epoch: 6 | loss: 0.0477005\n",
      "\tspeed: 0.1012s/iter; left time: 2123.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0506504 Vali Loss: 0.1318472 Test Loss: 0.1444080\n",
      "Validation loss decreased (0.133773 --> 0.131847).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0474096\n",
      "\tspeed: 0.1955s/iter; left time: 4078.2914s\n",
      "\titers: 200, epoch: 7 | loss: 0.0459429\n",
      "\tspeed: 0.1011s/iter; left time: 2099.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0467058 Vali Loss: 0.1315055 Test Loss: 0.1430237\n",
      "Validation loss decreased (0.131847 --> 0.131506).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0485883\n",
      "\tspeed: 0.1798s/iter; left time: 3711.2370s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448056\n",
      "\tspeed: 0.1011s/iter; left time: 2077.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.0443797 Vali Loss: 0.1315295 Test Loss: 0.1430706\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0408929\n",
      "\tspeed: 0.1705s/iter; left time: 3480.7831s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445887\n",
      "\tspeed: 0.1010s/iter; left time: 2052.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0419238 Vali Loss: 0.1313425 Test Loss: 0.1432481\n",
      "Validation loss decreased (0.131506 --> 0.131342).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0368652\n",
      "\tspeed: 0.1805s/iter; left time: 3644.0987s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413611\n",
      "\tspeed: 0.1011s/iter; left time: 2032.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 223 | Train Loss: 0.0396389 Vali Loss: 0.1304631 Test Loss: 0.1420865\n",
      "Validation loss decreased (0.131342 --> 0.130463).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378972\n",
      "\tspeed: 0.1792s/iter; left time: 3578.5187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0404556\n",
      "\tspeed: 0.1011s/iter; left time: 2008.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0381702 Vali Loss: 0.1310368 Test Loss: 0.1427826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0374863\n",
      "\tspeed: 0.1685s/iter; left time: 3328.1501s\n",
      "\titers: 200, epoch: 12 | loss: 0.0395534\n",
      "\tspeed: 0.1010s/iter; left time: 1983.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0372254 Vali Loss: 0.1305252 Test Loss: 0.1424272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0391716\n",
      "\tspeed: 0.1692s/iter; left time: 3303.8621s\n",
      "\titers: 200, epoch: 13 | loss: 0.0361170\n",
      "\tspeed: 0.1010s/iter; left time: 1961.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0358281 Vali Loss: 0.1303129 Test Loss: 0.1430231\n",
      "Validation loss decreased (0.130463 --> 0.130313).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0342916\n",
      "\tspeed: 0.1812s/iter; left time: 3498.0966s\n",
      "\titers: 200, epoch: 14 | loss: 0.0359754\n",
      "\tspeed: 0.1012s/iter; left time: 1943.6959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0349007 Vali Loss: 0.1301288 Test Loss: 0.1417290\n",
      "Validation loss decreased (0.130313 --> 0.130129).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0340790\n",
      "\tspeed: 0.1858s/iter; left time: 3544.9399s\n",
      "\titers: 200, epoch: 15 | loss: 0.0339541\n",
      "\tspeed: 0.1009s/iter; left time: 1915.6930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0348570 Vali Loss: 0.1305743 Test Loss: 0.1419227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0337586\n",
      "\tspeed: 0.1697s/iter; left time: 3200.0545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0331303\n",
      "\tspeed: 0.1010s/iter; left time: 1894.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0335450 Vali Loss: 0.1298782 Test Loss: 0.1412999\n",
      "Validation loss decreased (0.130129 --> 0.129878).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0318183\n",
      "\tspeed: 0.1851s/iter; left time: 3449.1933s\n",
      "\titers: 200, epoch: 17 | loss: 0.0328143\n",
      "\tspeed: 0.1009s/iter; left time: 1869.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 223 | Train Loss: 0.0329707 Vali Loss: 0.1298787 Test Loss: 0.1423763\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0320255\n",
      "\tspeed: 0.1696s/iter; left time: 3122.4738s\n",
      "\titers: 200, epoch: 18 | loss: 0.0310955\n",
      "\tspeed: 0.1009s/iter; left time: 1847.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0324296 Vali Loss: 0.1296944 Test Loss: 0.1420973\n",
      "Validation loss decreased (0.129878 --> 0.129694).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0331034\n",
      "\tspeed: 0.1784s/iter; left time: 3244.0197s\n",
      "\titers: 200, epoch: 19 | loss: 0.0322973\n",
      "\tspeed: 0.1009s/iter; left time: 1825.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0317739 Vali Loss: 0.1300072 Test Loss: 0.1421231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0312252\n",
      "\tspeed: 0.1686s/iter; left time: 3029.1912s\n",
      "\titers: 200, epoch: 20 | loss: 0.0306236\n",
      "\tspeed: 0.1011s/iter; left time: 1805.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0313309 Vali Loss: 0.1296711 Test Loss: 0.1417137\n",
      "Validation loss decreased (0.129694 --> 0.129671).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0304254\n",
      "\tspeed: 0.1912s/iter; left time: 3392.9331s\n",
      "\titers: 200, epoch: 21 | loss: 0.0311199\n",
      "\tspeed: 0.1009s/iter; left time: 1780.1910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0310391 Vali Loss: 0.1295275 Test Loss: 0.1416109\n",
      "Validation loss decreased (0.129671 --> 0.129527).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0298874\n",
      "\tspeed: 0.1842s/iter; left time: 3227.2307s\n",
      "\titers: 200, epoch: 22 | loss: 0.0302612\n",
      "\tspeed: 0.1010s/iter; left time: 1759.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0310310 Vali Loss: 0.1297438 Test Loss: 0.1420938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0294712\n",
      "\tspeed: 0.1701s/iter; left time: 2941.6373s\n",
      "\titers: 200, epoch: 23 | loss: 0.0311504\n",
      "\tspeed: 0.1010s/iter; left time: 1736.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.74s\n",
      "Steps: 223 | Train Loss: 0.0306204 Vali Loss: 0.1293175 Test Loss: 0.1416340\n",
      "Validation loss decreased (0.129527 --> 0.129318).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0306717\n",
      "\tspeed: 0.1754s/iter; left time: 2993.8695s\n",
      "\titers: 200, epoch: 24 | loss: 0.0326125\n",
      "\tspeed: 0.1013s/iter; left time: 1718.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0301517 Vali Loss: 0.1295908 Test Loss: 0.1415685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0294771\n",
      "\tspeed: 0.1693s/iter; left time: 2852.5034s\n",
      "\titers: 200, epoch: 25 | loss: 0.0290208\n",
      "\tspeed: 0.1009s/iter; left time: 1689.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0300518 Vali Loss: 0.1294771 Test Loss: 0.1413270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0310628\n",
      "\tspeed: 0.1686s/iter; left time: 2803.7500s\n",
      "\titers: 200, epoch: 26 | loss: 0.0298298\n",
      "\tspeed: 0.1009s/iter; left time: 1667.7063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0298269 Vali Loss: 0.1297811 Test Loss: 0.1419676\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0308892\n",
      "\tspeed: 0.1693s/iter; left time: 2777.2208s\n",
      "\titers: 200, epoch: 27 | loss: 0.0297598\n",
      "\tspeed: 0.1009s/iter; left time: 1645.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0296573 Vali Loss: 0.1293213 Test Loss: 0.1413701\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0298229\n",
      "\tspeed: 0.1707s/iter; left time: 2762.2213s\n",
      "\titers: 200, epoch: 28 | loss: 0.0291561\n",
      "\tspeed: 0.1009s/iter; left time: 1622.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0293908 Vali Loss: 0.1292067 Test Loss: 0.1414965\n",
      "Validation loss decreased (0.129318 --> 0.129207).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0295447\n",
      "\tspeed: 0.1762s/iter; left time: 2812.1745s\n",
      "\titers: 200, epoch: 29 | loss: 0.0289325\n",
      "\tspeed: 0.1018s/iter; left time: 1613.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0292231 Vali Loss: 0.1293714 Test Loss: 0.1416098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0297523\n",
      "\tspeed: 0.1696s/iter; left time: 2668.8141s\n",
      "\titers: 200, epoch: 30 | loss: 0.0293122\n",
      "\tspeed: 0.1010s/iter; left time: 1578.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0291896 Vali Loss: 0.1295614 Test Loss: 0.1418938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0294015\n",
      "\tspeed: 0.1690s/iter; left time: 2620.6202s\n",
      "\titers: 200, epoch: 31 | loss: 0.0278125\n",
      "\tspeed: 0.1011s/iter; left time: 1557.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0289900 Vali Loss: 0.1293283 Test Loss: 0.1413058\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0296534\n",
      "\tspeed: 0.1684s/iter; left time: 2574.1649s\n",
      "\titers: 200, epoch: 32 | loss: 0.0288739\n",
      "\tspeed: 0.1010s/iter; left time: 1534.5276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0287816 Vali Loss: 0.1293303 Test Loss: 0.1414459\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0288480\n",
      "\tspeed: 0.1698s/iter; left time: 2557.5053s\n",
      "\titers: 200, epoch: 33 | loss: 0.0295896\n",
      "\tspeed: 0.1011s/iter; left time: 1512.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0287548 Vali Loss: 0.1292268 Test Loss: 0.1410291\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0292089\n",
      "\tspeed: 0.1695s/iter; left time: 2515.1648s\n",
      "\titers: 200, epoch: 34 | loss: 0.0275612\n",
      "\tspeed: 0.1013s/iter; left time: 1493.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 223 | Train Loss: 0.0285835 Vali Loss: 0.1293273 Test Loss: 0.1415049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0284292\n",
      "\tspeed: 0.1692s/iter; left time: 2473.1380s\n",
      "\titers: 200, epoch: 35 | loss: 0.0274603\n",
      "\tspeed: 0.1011s/iter; left time: 1468.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0285293 Vali Loss: 0.1294487 Test Loss: 0.1417609\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0283691\n",
      "\tspeed: 0.1711s/iter; left time: 2462.4770s\n",
      "\titers: 200, epoch: 36 | loss: 0.0281101\n",
      "\tspeed: 0.1013s/iter; left time: 1448.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0283747 Vali Loss: 0.1292968 Test Loss: 0.1414106\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0297436\n",
      "\tspeed: 0.1698s/iter; left time: 2405.9788s\n",
      "\titers: 200, epoch: 37 | loss: 0.0285179\n",
      "\tspeed: 0.1012s/iter; left time: 1424.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0285509 Vali Loss: 0.1293069 Test Loss: 0.1414223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0277756\n",
      "\tspeed: 0.1697s/iter; left time: 2367.4064s\n",
      "\titers: 200, epoch: 38 | loss: 0.0290327\n",
      "\tspeed: 0.1012s/iter; left time: 1401.3622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0283419 Vali Loss: 0.1292873 Test Loss: 0.1415935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04234959930181503, rmse:0.205790176987648, mae:0.14149640500545502, rse:0.7289254069328308\n",
      "Intermediate time for DE and pred_len 168: 00h:36m:38.08s\n",
      "Intermediate time for DE: 01h:31m:06.35s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1000400\n",
      "\tspeed: 0.1256s/iter; left time: 2800.9754s\n",
      "\titers: 200, epoch: 1 | loss: 0.0889657\n",
      "\tspeed: 0.0978s/iter; left time: 2172.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.1082130 Vali Loss: 0.1031816 Test Loss: 0.1152446\n",
      "Validation loss decreased (inf --> 0.103182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0845666\n",
      "\tspeed: 0.1743s/iter; left time: 3847.0460s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818039\n",
      "\tspeed: 0.0982s/iter; left time: 2157.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.16s\n",
      "Steps: 224 | Train Loss: 0.0857477 Vali Loss: 0.0982765 Test Loss: 0.1124934\n",
      "Validation loss decreased (0.103182 --> 0.098277).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0732861\n",
      "\tspeed: 0.1698s/iter; left time: 3709.8877s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766309\n",
      "\tspeed: 0.0978s/iter; left time: 2127.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.11s\n",
      "Steps: 224 | Train Loss: 0.0785921 Vali Loss: 0.1015784 Test Loss: 0.1143293\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728939\n",
      "\tspeed: 0.1620s/iter; left time: 3503.8179s\n",
      "\titers: 200, epoch: 4 | loss: 0.0681023\n",
      "\tspeed: 0.0990s/iter; left time: 2131.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.18s\n",
      "Steps: 224 | Train Loss: 0.0711089 Vali Loss: 0.1054293 Test Loss: 0.1163301\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639224\n",
      "\tspeed: 0.1627s/iter; left time: 3482.3726s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605066\n",
      "\tspeed: 0.0981s/iter; left time: 2089.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.12s\n",
      "Steps: 224 | Train Loss: 0.0622334 Vali Loss: 0.1083525 Test Loss: 0.1197059\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0546447\n",
      "\tspeed: 0.1631s/iter; left time: 3453.5807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536140\n",
      "\tspeed: 0.0979s/iter; left time: 2064.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.12s\n",
      "Steps: 224 | Train Loss: 0.0555567 Vali Loss: 0.1104376 Test Loss: 0.1198921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0516678\n",
      "\tspeed: 0.1625s/iter; left time: 3405.3044s\n",
      "\titers: 200, epoch: 7 | loss: 0.0488077\n",
      "\tspeed: 0.0980s/iter; left time: 2043.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.0507787 Vali Loss: 0.1112424 Test Loss: 0.1215639\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0464973\n",
      "\tspeed: 0.1635s/iter; left time: 3390.0308s\n",
      "\titers: 200, epoch: 8 | loss: 0.0490609\n",
      "\tspeed: 0.0980s/iter; left time: 2021.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0473406 Vali Loss: 0.1101312 Test Loss: 0.1211495\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0439890\n",
      "\tspeed: 0.1631s/iter; left time: 3346.0291s\n",
      "\titers: 200, epoch: 9 | loss: 0.0441779\n",
      "\tspeed: 0.0982s/iter; left time: 2004.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0442485 Vali Loss: 0.1090659 Test Loss: 0.1218175\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0418965\n",
      "\tspeed: 0.1634s/iter; left time: 3315.0499s\n",
      "\titers: 200, epoch: 10 | loss: 0.0423168\n",
      "\tspeed: 0.0981s/iter; left time: 1979.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0417639 Vali Loss: 0.1084580 Test Loss: 0.1203145\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0392470\n",
      "\tspeed: 0.1630s/iter; left time: 3270.8621s\n",
      "\titers: 200, epoch: 11 | loss: 0.0400443\n",
      "\tspeed: 0.0989s/iter; left time: 1974.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0399939 Vali Loss: 0.1085082 Test Loss: 0.1204979\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0389502\n",
      "\tspeed: 0.1628s/iter; left time: 3230.0995s\n",
      "\titers: 200, epoch: 12 | loss: 0.0355284\n",
      "\tspeed: 0.0979s/iter; left time: 1931.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.09s\n",
      "Steps: 224 | Train Loss: 0.0382218 Vali Loss: 0.1076079 Test Loss: 0.1214052\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029199549928307533, rmse:0.17087875306606293, mae:0.11249343305826187, rse:0.5894832611083984\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1040811\n",
      "\tspeed: 0.0996s/iter; left time: 2221.4734s\n",
      "\titers: 200, epoch: 1 | loss: 0.0935913\n",
      "\tspeed: 0.0979s/iter; left time: 2172.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.1089075 Vali Loss: 0.1033798 Test Loss: 0.1159112\n",
      "Validation loss decreased (inf --> 0.103380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0797644\n",
      "\tspeed: 0.1745s/iter; left time: 3851.9621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0804092\n",
      "\tspeed: 0.0981s/iter; left time: 2155.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 224 | Train Loss: 0.0856039 Vali Loss: 0.0979992 Test Loss: 0.1111437\n",
      "Validation loss decreased (0.103380 --> 0.097999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0766721\n",
      "\tspeed: 0.1760s/iter; left time: 3845.5997s\n",
      "\titers: 200, epoch: 3 | loss: 0.0783876\n",
      "\tspeed: 0.0981s/iter; left time: 2133.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0784792 Vali Loss: 0.0983647 Test Loss: 0.1096302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729389\n",
      "\tspeed: 0.1636s/iter; left time: 3538.1950s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714793\n",
      "\tspeed: 0.0980s/iter; left time: 2109.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0713042 Vali Loss: 0.1074160 Test Loss: 0.1172837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637151\n",
      "\tspeed: 0.1629s/iter; left time: 3487.4557s\n",
      "\titers: 200, epoch: 5 | loss: 0.0599574\n",
      "\tspeed: 0.0979s/iter; left time: 2086.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.09s\n",
      "Steps: 224 | Train Loss: 0.0628277 Vali Loss: 0.1088988 Test Loss: 0.1203743\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0548561\n",
      "\tspeed: 0.1635s/iter; left time: 3463.8681s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529555\n",
      "\tspeed: 0.0980s/iter; left time: 2065.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0561751 Vali Loss: 0.1093509 Test Loss: 0.1232503\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568765\n",
      "\tspeed: 0.1625s/iter; left time: 3405.3661s\n",
      "\titers: 200, epoch: 7 | loss: 0.0484834\n",
      "\tspeed: 0.0975s/iter; left time: 2032.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.04s\n",
      "Steps: 224 | Train Loss: 0.0508114 Vali Loss: 0.1082517 Test Loss: 0.1216338\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0478964\n",
      "\tspeed: 0.1640s/iter; left time: 3401.0924s\n",
      "\titers: 200, epoch: 8 | loss: 0.0458303\n",
      "\tspeed: 0.0979s/iter; left time: 2020.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0471401 Vali Loss: 0.1078706 Test Loss: 0.1242654\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0449760\n",
      "\tspeed: 0.1644s/iter; left time: 3370.9944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443707\n",
      "\tspeed: 0.0982s/iter; left time: 2003.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.23s\n",
      "Steps: 224 | Train Loss: 0.0438777 Vali Loss: 0.1064936 Test Loss: 0.1229029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0417951\n",
      "\tspeed: 0.1627s/iter; left time: 3301.1427s\n",
      "\titers: 200, epoch: 10 | loss: 0.0405808\n",
      "\tspeed: 0.0979s/iter; left time: 1976.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.0417294 Vali Loss: 0.1068690 Test Loss: 0.1220882\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0396463\n",
      "\tspeed: 0.1632s/iter; left time: 3273.3391s\n",
      "\titers: 200, epoch: 11 | loss: 0.0384465\n",
      "\tspeed: 0.0979s/iter; left time: 1954.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0397610 Vali Loss: 0.1065472 Test Loss: 0.1219878\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0375036\n",
      "\tspeed: 0.1628s/iter; left time: 3229.6234s\n",
      "\titers: 200, epoch: 12 | loss: 0.0383344\n",
      "\tspeed: 0.0979s/iter; left time: 1932.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.11s\n",
      "Steps: 224 | Train Loss: 0.0381573 Vali Loss: 0.1053996 Test Loss: 0.1228065\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028552530333399773, rmse:0.16897493600845337, mae:0.11114371567964554, rse:0.5829156041145325\n",
      "Intermediate time for GB and pred_len 24: 00h:10m:46.68s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1210458\n",
      "\tspeed: 0.1269s/iter; left time: 2830.2620s\n",
      "\titers: 200, epoch: 1 | loss: 0.1112605\n",
      "\tspeed: 0.0995s/iter; left time: 2209.8410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 224 | Train Loss: 0.1222008 Vali Loss: 0.1245735 Test Loss: 0.1466682\n",
      "Validation loss decreased (inf --> 0.124573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038702\n",
      "\tspeed: 0.1772s/iter; left time: 3911.0823s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924622\n",
      "\tspeed: 0.0996s/iter; left time: 2189.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.1059021 Vali Loss: 0.1332862 Test Loss: 0.1500637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0808003\n",
      "\tspeed: 0.1660s/iter; left time: 3626.9603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0736129\n",
      "\tspeed: 0.0995s/iter; left time: 2164.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0828622 Vali Loss: 0.1415045 Test Loss: 0.1570451\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0686038\n",
      "\tspeed: 0.1689s/iter; left time: 3653.0037s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656218\n",
      "\tspeed: 0.1005s/iter; left time: 2162.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 224 | Train Loss: 0.0670727 Vali Loss: 0.1425244 Test Loss: 0.1607312\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0593092\n",
      "\tspeed: 0.1673s/iter; left time: 3581.4297s\n",
      "\titers: 200, epoch: 5 | loss: 0.0538448\n",
      "\tspeed: 0.0994s/iter; left time: 2117.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0584418 Vali Loss: 0.1416681 Test Loss: 0.1574435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0527765\n",
      "\tspeed: 0.1669s/iter; left time: 3535.6931s\n",
      "\titers: 200, epoch: 6 | loss: 0.0497815\n",
      "\tspeed: 0.0998s/iter; left time: 2104.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0519867 Vali Loss: 0.1407373 Test Loss: 0.1585691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0489115\n",
      "\tspeed: 0.1663s/iter; left time: 3485.4344s\n",
      "\titers: 200, epoch: 7 | loss: 0.0484653\n",
      "\tspeed: 0.0994s/iter; left time: 2073.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0475200 Vali Loss: 0.1369800 Test Loss: 0.1548225\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409547\n",
      "\tspeed: 0.1668s/iter; left time: 3457.4731s\n",
      "\titers: 200, epoch: 8 | loss: 0.0426313\n",
      "\tspeed: 0.0996s/iter; left time: 2055.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0440538 Vali Loss: 0.1374608 Test Loss: 0.1542663\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0407711\n",
      "\tspeed: 0.1667s/iter; left time: 3419.2583s\n",
      "\titers: 200, epoch: 9 | loss: 0.0403957\n",
      "\tspeed: 0.0995s/iter; left time: 2031.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0417281 Vali Loss: 0.1348568 Test Loss: 0.1534370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0386112\n",
      "\tspeed: 0.1665s/iter; left time: 3377.1250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402503\n",
      "\tspeed: 0.0995s/iter; left time: 2008.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0405633 Vali Loss: 0.1359578 Test Loss: 0.1525046\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0384958\n",
      "\tspeed: 0.1657s/iter; left time: 3324.6472s\n",
      "\titers: 200, epoch: 11 | loss: 0.0376746\n",
      "\tspeed: 0.0994s/iter; left time: 1984.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0389795 Vali Loss: 0.1339630 Test Loss: 0.1529814\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04464218392968178, rmse:0.2112869769334793, mae:0.1466681808233261, rse:0.7306598424911499\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1185862\n",
      "\tspeed: 0.1007s/iter; left time: 2246.7355s\n",
      "\titers: 200, epoch: 1 | loss: 0.1120367\n",
      "\tspeed: 0.0995s/iter; left time: 2208.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.1219711 Vali Loss: 0.1247018 Test Loss: 0.1465372\n",
      "Validation loss decreased (inf --> 0.124702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1071755\n",
      "\tspeed: 0.1783s/iter; left time: 3935.7838s\n",
      "\titers: 200, epoch: 2 | loss: 0.0921484\n",
      "\tspeed: 0.0996s/iter; left time: 2189.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.1046357 Vali Loss: 0.1321889 Test Loss: 0.1508403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0789659\n",
      "\tspeed: 0.1683s/iter; left time: 3678.3543s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739356\n",
      "\tspeed: 0.0994s/iter; left time: 2161.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0799068 Vali Loss: 0.1397098 Test Loss: 0.1557169\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647016\n",
      "\tspeed: 0.1667s/iter; left time: 3605.9977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0596794\n",
      "\tspeed: 0.0995s/iter; left time: 2141.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0650651 Vali Loss: 0.1369236 Test Loss: 0.1548756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552947\n",
      "\tspeed: 0.1667s/iter; left time: 3568.3970s\n",
      "\titers: 200, epoch: 5 | loss: 0.0535644\n",
      "\tspeed: 0.0994s/iter; left time: 2117.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0560993 Vali Loss: 0.1345373 Test Loss: 0.1530709\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0523013\n",
      "\tspeed: 0.1669s/iter; left time: 3534.0539s\n",
      "\titers: 200, epoch: 6 | loss: 0.0488983\n",
      "\tspeed: 0.0994s/iter; left time: 2095.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0505612 Vali Loss: 0.1308149 Test Loss: 0.1535134\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531405\n",
      "\tspeed: 0.1667s/iter; left time: 3493.7993s\n",
      "\titers: 200, epoch: 7 | loss: 0.0464522\n",
      "\tspeed: 0.0994s/iter; left time: 2072.3212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0472376 Vali Loss: 0.1320213 Test Loss: 0.1530477\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0429615\n",
      "\tspeed: 0.1662s/iter; left time: 3445.9405s\n",
      "\titers: 200, epoch: 8 | loss: 0.0425697\n",
      "\tspeed: 0.0994s/iter; left time: 2051.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0434822 Vali Loss: 0.1306199 Test Loss: 0.1524510\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0411477\n",
      "\tspeed: 0.1665s/iter; left time: 3415.7583s\n",
      "\titers: 200, epoch: 9 | loss: 0.0385973\n",
      "\tspeed: 0.0994s/iter; left time: 2028.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0412297 Vali Loss: 0.1286369 Test Loss: 0.1519012\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0394646\n",
      "\tspeed: 0.1683s/iter; left time: 3414.0083s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407799\n",
      "\tspeed: 0.0995s/iter; left time: 2008.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0394865 Vali Loss: 0.1282582 Test Loss: 0.1509731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0409676\n",
      "\tspeed: 0.1672s/iter; left time: 3354.0731s\n",
      "\titers: 200, epoch: 11 | loss: 0.0372345\n",
      "\tspeed: 0.0995s/iter; left time: 1986.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0393302 Vali Loss: 0.1287157 Test Loss: 0.1511781\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044634852558374405, rmse:0.21126961708068848, mae:0.14653731882572174, rse:0.7305997610092163\n",
      "Intermediate time for GB and pred_len 96: 00h:10m:06.07s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1212218\n",
      "\tspeed: 0.1264s/iter; left time: 2807.3061s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139713\n",
      "\tspeed: 0.1011s/iter; left time: 2234.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 223 | Train Loss: 0.1252046 Vali Loss: 0.1282504 Test Loss: 0.1520317\n",
      "Validation loss decreased (inf --> 0.128250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1078130\n",
      "\tspeed: 0.1820s/iter; left time: 3999.9323s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011755\n",
      "\tspeed: 0.1011s/iter; left time: 2211.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.1077820 Vali Loss: 0.1364171 Test Loss: 0.1541169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831033\n",
      "\tspeed: 0.1681s/iter; left time: 3657.9561s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750316\n",
      "\tspeed: 0.1008s/iter; left time: 2182.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0813860 Vali Loss: 0.1430847 Test Loss: 0.1601447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659564\n",
      "\tspeed: 0.1663s/iter; left time: 3581.3312s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617063\n",
      "\tspeed: 0.1010s/iter; left time: 2163.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0664012 Vali Loss: 0.1409647 Test Loss: 0.1582429\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0551478\n",
      "\tspeed: 0.1661s/iter; left time: 3538.7871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0538402\n",
      "\tspeed: 0.1009s/iter; left time: 2139.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 223 | Train Loss: 0.0568825 Vali Loss: 0.1416528 Test Loss: 0.1601245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0496445\n",
      "\tspeed: 0.1661s/iter; left time: 3502.8575s\n",
      "\titers: 200, epoch: 6 | loss: 0.0504231\n",
      "\tspeed: 0.1011s/iter; left time: 2121.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.0519403 Vali Loss: 0.1357887 Test Loss: 0.1577356\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0514954\n",
      "\tspeed: 0.1673s/iter; left time: 3490.1665s\n",
      "\titers: 200, epoch: 7 | loss: 0.0473062\n",
      "\tspeed: 0.1011s/iter; left time: 2098.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0473768 Vali Loss: 0.1372073 Test Loss: 0.1573528\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422178\n",
      "\tspeed: 0.1665s/iter; left time: 3437.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0432705\n",
      "\tspeed: 0.1010s/iter; left time: 2075.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 223 | Train Loss: 0.0447079 Vali Loss: 0.1335165 Test Loss: 0.1570952\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0454519\n",
      "\tspeed: 0.1654s/iter; left time: 3376.6563s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439654\n",
      "\tspeed: 0.1012s/iter; left time: 2055.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0434310 Vali Loss: 0.1341390 Test Loss: 0.1555370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399883\n",
      "\tspeed: 0.1669s/iter; left time: 3370.8261s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389427\n",
      "\tspeed: 0.1010s/iter; left time: 2029.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.66s\n",
      "Steps: 223 | Train Loss: 0.0405045 Vali Loss: 0.1328685 Test Loss: 0.1561904\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0404393\n",
      "\tspeed: 0.1657s/iter; left time: 3309.0078s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401293\n",
      "\tspeed: 0.1009s/iter; left time: 2004.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0393156 Vali Loss: 0.1367602 Test Loss: 0.1561167\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047135237604379654, rmse:0.21710650622844696, mae:0.15203170478343964, rse:0.752739429473877\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1246958\n",
      "\tspeed: 0.1027s/iter; left time: 2280.7693s\n",
      "\titers: 200, epoch: 1 | loss: 0.1193848\n",
      "\tspeed: 0.1010s/iter; left time: 2232.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.1251033 Vali Loss: 0.1285281 Test Loss: 0.1520350\n",
      "Validation loss decreased (inf --> 0.128528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1079517\n",
      "\tspeed: 0.1846s/iter; left time: 4056.5247s\n",
      "\titers: 200, epoch: 2 | loss: 0.0979819\n",
      "\tspeed: 0.1013s/iter; left time: 2215.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.1067287 Vali Loss: 0.1381765 Test Loss: 0.1558307\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806419\n",
      "\tspeed: 0.1688s/iter; left time: 3672.0790s\n",
      "\titers: 200, epoch: 3 | loss: 0.0722020\n",
      "\tspeed: 0.1009s/iter; left time: 2185.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0795303 Vali Loss: 0.1408413 Test Loss: 0.1584047\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0665133\n",
      "\tspeed: 0.1695s/iter; left time: 3649.7260s\n",
      "\titers: 200, epoch: 4 | loss: 0.0628806\n",
      "\tspeed: 0.1010s/iter; left time: 2164.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0655871 Vali Loss: 0.1403571 Test Loss: 0.1598811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0583973\n",
      "\tspeed: 0.1679s/iter; left time: 3577.5676s\n",
      "\titers: 200, epoch: 5 | loss: 0.0529059\n",
      "\tspeed: 0.1009s/iter; left time: 2139.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0570187 Vali Loss: 0.1381003 Test Loss: 0.1594655\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0521242\n",
      "\tspeed: 0.1683s/iter; left time: 3547.9760s\n",
      "\titers: 200, epoch: 6 | loss: 0.0498817\n",
      "\tspeed: 0.1013s/iter; left time: 2126.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0517209 Vali Loss: 0.1397730 Test Loss: 0.1600732\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0468313\n",
      "\tspeed: 0.1696s/iter; left time: 3539.3593s\n",
      "\titers: 200, epoch: 7 | loss: 0.0480323\n",
      "\tspeed: 0.1010s/iter; left time: 2096.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0474814 Vali Loss: 0.1360781 Test Loss: 0.1613502\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0461521\n",
      "\tspeed: 0.1694s/iter; left time: 3495.6213s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448193\n",
      "\tspeed: 0.1010s/iter; left time: 2074.4310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.74s\n",
      "Steps: 223 | Train Loss: 0.0448962 Vali Loss: 0.1352690 Test Loss: 0.1596699\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418778\n",
      "\tspeed: 0.1680s/iter; left time: 3430.8513s\n",
      "\titers: 200, epoch: 9 | loss: 0.0405838\n",
      "\tspeed: 0.1009s/iter; left time: 2050.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 223 | Train Loss: 0.0422619 Vali Loss: 0.1348368 Test Loss: 0.1576244\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0396611\n",
      "\tspeed: 0.1692s/iter; left time: 3415.9756s\n",
      "\titers: 200, epoch: 10 | loss: 0.0392483\n",
      "\tspeed: 0.1009s/iter; left time: 2027.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.0415109 Vali Loss: 0.1355973 Test Loss: 0.1582328\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0386109\n",
      "\tspeed: 0.1681s/iter; left time: 3357.6595s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408022\n",
      "\tspeed: 0.1010s/iter; left time: 2006.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0391746 Vali Loss: 0.1352939 Test Loss: 0.1572801\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04724753275513649, rmse:0.21736498177051544, mae:0.1520349681377411, rse:0.7536356449127197\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:13.64s\n",
      "Intermediate time for GB: 00h:31m:06.39s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1083394\n",
      "\tspeed: 0.0564s/iter; left time: 1257.0853s\n",
      "\titers: 200, epoch: 1 | loss: 0.0949330\n",
      "\tspeed: 0.0322s/iter; left time: 715.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.1146521 Vali Loss: 0.0854233 Test Loss: 0.0978887\n",
      "Validation loss decreased (inf --> 0.085423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694569\n",
      "\tspeed: 0.0609s/iter; left time: 1344.2013s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682702\n",
      "\tspeed: 0.0323s/iter; left time: 710.5164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0716935 Vali Loss: 0.0656114 Test Loss: 0.0731752\n",
      "Validation loss decreased (0.085423 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638887\n",
      "\tspeed: 0.0623s/iter; left time: 1361.0037s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625745\n",
      "\tspeed: 0.0321s/iter; left time: 698.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0642866 Vali Loss: 0.0630241 Test Loss: 0.0710565\n",
      "Validation loss decreased (0.065611 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611238\n",
      "\tspeed: 0.0613s/iter; left time: 1325.6060s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643910\n",
      "\tspeed: 0.0324s/iter; left time: 696.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0619596 Vali Loss: 0.0643963 Test Loss: 0.0716253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614629\n",
      "\tspeed: 0.0601s/iter; left time: 1286.6637s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591143\n",
      "\tspeed: 0.0323s/iter; left time: 687.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0598301 Vali Loss: 0.0612322 Test Loss: 0.0694189\n",
      "Validation loss decreased (0.063024 --> 0.061232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568408\n",
      "\tspeed: 0.0638s/iter; left time: 1350.7376s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567278\n",
      "\tspeed: 0.0321s/iter; left time: 676.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0577446 Vali Loss: 0.0609693 Test Loss: 0.0682407\n",
      "Validation loss decreased (0.061232 --> 0.060969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562621\n",
      "\tspeed: 0.0607s/iter; left time: 1271.2555s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554868\n",
      "\tspeed: 0.0322s/iter; left time: 672.5456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0561681 Vali Loss: 0.0597783 Test Loss: 0.0675127\n",
      "Validation loss decreased (0.060969 --> 0.059778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569908\n",
      "\tspeed: 0.0609s/iter; left time: 1262.2103s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577169\n",
      "\tspeed: 0.0321s/iter; left time: 662.8541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0544420 Vali Loss: 0.0602443 Test Loss: 0.0683316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521781\n",
      "\tspeed: 0.0592s/iter; left time: 1214.7410s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503141\n",
      "\tspeed: 0.0326s/iter; left time: 666.2345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0526811 Vali Loss: 0.0609316 Test Loss: 0.0681847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519583\n",
      "\tspeed: 0.0586s/iter; left time: 1188.8725s\n",
      "\titers: 200, epoch: 10 | loss: 0.0487051\n",
      "\tspeed: 0.0322s/iter; left time: 649.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0512578 Vali Loss: 0.0613501 Test Loss: 0.0695660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517822\n",
      "\tspeed: 0.0595s/iter; left time: 1193.3900s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482223\n",
      "\tspeed: 0.0322s/iter; left time: 643.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0498223 Vali Loss: 0.0620379 Test Loss: 0.0702392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494305\n",
      "\tspeed: 0.0583s/iter; left time: 1156.3769s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481998\n",
      "\tspeed: 0.0327s/iter; left time: 645.6910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0483653 Vali Loss: 0.0612045 Test Loss: 0.0701841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0462038\n",
      "\tspeed: 0.0580s/iter; left time: 1136.6627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461890\n",
      "\tspeed: 0.0321s/iter; left time: 626.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0470476 Vali Loss: 0.0618377 Test Loss: 0.0701277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0474969\n",
      "\tspeed: 0.0581s/iter; left time: 1125.8177s\n",
      "\titers: 200, epoch: 14 | loss: 0.0462358\n",
      "\tspeed: 0.0323s/iter; left time: 622.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0460021 Vali Loss: 0.0619138 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441642\n",
      "\tspeed: 0.0589s/iter; left time: 1128.4667s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437523\n",
      "\tspeed: 0.0321s/iter; left time: 611.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0449358 Vali Loss: 0.0615214 Test Loss: 0.0704811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440189\n",
      "\tspeed: 0.0582s/iter; left time: 1101.4306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432764\n",
      "\tspeed: 0.0322s/iter; left time: 607.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0439870 Vali Loss: 0.0616211 Test Loss: 0.0707664\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423084\n",
      "\tspeed: 0.0582s/iter; left time: 1090.1792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0415025\n",
      "\tspeed: 0.0323s/iter; left time: 601.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0431494 Vali Loss: 0.0620262 Test Loss: 0.0715410\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01133799646049738, rmse:0.10648002475500107, mae:0.06751272827386856, rse:0.3133578300476074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1059176\n",
      "\tspeed: 0.0344s/iter; left time: 766.7583s\n",
      "\titers: 200, epoch: 1 | loss: 0.0954594\n",
      "\tspeed: 0.0326s/iter; left time: 722.8007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.1132807 Vali Loss: 0.0858611 Test Loss: 0.0978220\n",
      "Validation loss decreased (inf --> 0.085861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672946\n",
      "\tspeed: 0.0650s/iter; left time: 1435.0460s\n",
      "\titers: 200, epoch: 2 | loss: 0.0662497\n",
      "\tspeed: 0.0323s/iter; left time: 709.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0716624 Vali Loss: 0.0645302 Test Loss: 0.0728868\n",
      "Validation loss decreased (0.085861 --> 0.064530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636461\n",
      "\tspeed: 0.0631s/iter; left time: 1379.3753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644167\n",
      "\tspeed: 0.0320s/iter; left time: 697.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0639991 Vali Loss: 0.0630432 Test Loss: 0.0709006\n",
      "Validation loss decreased (0.064530 --> 0.063043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621769\n",
      "\tspeed: 0.0615s/iter; left time: 1330.3933s\n",
      "\titers: 200, epoch: 4 | loss: 0.0600844\n",
      "\tspeed: 0.0322s/iter; left time: 693.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0615069 Vali Loss: 0.0610647 Test Loss: 0.0695123\n",
      "Validation loss decreased (0.063043 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0606961\n",
      "\tspeed: 0.0618s/iter; left time: 1322.3372s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597096\n",
      "\tspeed: 0.0320s/iter; left time: 682.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0594661 Vali Loss: 0.0604619 Test Loss: 0.0694347\n",
      "Validation loss decreased (0.061065 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590119\n",
      "\tspeed: 0.0600s/iter; left time: 1271.2708s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569254\n",
      "\tspeed: 0.0320s/iter; left time: 674.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0579130 Vali Loss: 0.0610369 Test Loss: 0.0684163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0548901\n",
      "\tspeed: 0.0585s/iter; left time: 1226.6705s\n",
      "\titers: 200, epoch: 7 | loss: 0.0539524\n",
      "\tspeed: 0.0321s/iter; left time: 668.6249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0559329 Vali Loss: 0.0594218 Test Loss: 0.0678336\n",
      "Validation loss decreased (0.060462 --> 0.059422).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0538018\n",
      "\tspeed: 0.0622s/iter; left time: 1288.9799s\n",
      "\titers: 200, epoch: 8 | loss: 0.0530818\n",
      "\tspeed: 0.0327s/iter; left time: 675.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0542583 Vali Loss: 0.0599612 Test Loss: 0.0689581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552536\n",
      "\tspeed: 0.0589s/iter; left time: 1207.6644s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516640\n",
      "\tspeed: 0.0324s/iter; left time: 662.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0527426 Vali Loss: 0.0591997 Test Loss: 0.0679362\n",
      "Validation loss decreased (0.059422 --> 0.059200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536080\n",
      "\tspeed: 0.0609s/iter; left time: 1235.1285s\n",
      "\titers: 200, epoch: 10 | loss: 0.0499571\n",
      "\tspeed: 0.0322s/iter; left time: 649.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0512842 Vali Loss: 0.0599653 Test Loss: 0.0687808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517187\n",
      "\tspeed: 0.0595s/iter; left time: 1194.0080s\n",
      "\titers: 200, epoch: 11 | loss: 0.0499973\n",
      "\tspeed: 0.0321s/iter; left time: 640.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0497935 Vali Loss: 0.0604572 Test Loss: 0.0696274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468627\n",
      "\tspeed: 0.0593s/iter; left time: 1176.0288s\n",
      "\titers: 200, epoch: 12 | loss: 0.0489540\n",
      "\tspeed: 0.0325s/iter; left time: 641.9414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0483913 Vali Loss: 0.0602030 Test Loss: 0.0697745\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496078\n",
      "\tspeed: 0.0592s/iter; left time: 1161.9942s\n",
      "\titers: 200, epoch: 13 | loss: 0.0476634\n",
      "\tspeed: 0.0324s/iter; left time: 632.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0473625 Vali Loss: 0.0604081 Test Loss: 0.0700828\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464205\n",
      "\tspeed: 0.0592s/iter; left time: 1147.5243s\n",
      "\titers: 200, epoch: 14 | loss: 0.0435993\n",
      "\tspeed: 0.0323s/iter; left time: 623.3370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0461338 Vali Loss: 0.0605141 Test Loss: 0.0701649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0460268\n",
      "\tspeed: 0.0616s/iter; left time: 1180.3255s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453027\n",
      "\tspeed: 0.0329s/iter; left time: 627.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0451875 Vali Loss: 0.0609419 Test Loss: 0.0697475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0459039\n",
      "\tspeed: 0.0612s/iter; left time: 1159.3341s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434766\n",
      "\tspeed: 0.0322s/iter; left time: 605.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0443061 Vali Loss: 0.0615374 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0443573\n",
      "\tspeed: 0.0596s/iter; left time: 1114.8255s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425250\n",
      "\tspeed: 0.0321s/iter; left time: 598.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0435606 Vali Loss: 0.0604851 Test Loss: 0.0707585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413324\n",
      "\tspeed: 0.0595s/iter; left time: 1100.8525s\n",
      "\titers: 200, epoch: 18 | loss: 0.0445203\n",
      "\tspeed: 0.0322s/iter; left time: 591.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0428060 Vali Loss: 0.0611732 Test Loss: 0.0707645\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0436631\n",
      "\tspeed: 0.0591s/iter; left time: 1080.1691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429139\n",
      "\tspeed: 0.0322s/iter; left time: 584.5549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0421968 Vali Loss: 0.0612346 Test Loss: 0.0706914\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011598608456552029, rmse:0.10769683867692947, mae:0.06793618202209473, rse:0.31693875789642334\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:44.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1167209\n",
      "\tspeed: 0.0575s/iter; left time: 1282.5565s\n",
      "\titers: 200, epoch: 1 | loss: 0.1056875\n",
      "\tspeed: 0.0337s/iter; left time: 747.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1227398 Vali Loss: 0.0988195 Test Loss: 0.1124716\n",
      "Validation loss decreased (inf --> 0.098819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888136\n",
      "\tspeed: 0.0705s/iter; left time: 1555.6215s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841860\n",
      "\tspeed: 0.0332s/iter; left time: 729.7375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0888445 Vali Loss: 0.0866662 Test Loss: 0.0969930\n",
      "Validation loss decreased (0.098819 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807913\n",
      "\tspeed: 0.0705s/iter; left time: 1541.6938s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785247\n",
      "\tspeed: 0.0334s/iter; left time: 726.6489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0809936 Vali Loss: 0.0850435 Test Loss: 0.0962780\n",
      "Validation loss decreased (0.086666 --> 0.085044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0752124\n",
      "\tspeed: 0.0654s/iter; left time: 1415.3897s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712232\n",
      "\tspeed: 0.0331s/iter; left time: 711.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0751077 Vali Loss: 0.0873182 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689497\n",
      "\tspeed: 0.0620s/iter; left time: 1326.5338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683093\n",
      "\tspeed: 0.0338s/iter; left time: 719.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0684474 Vali Loss: 0.0864051 Test Loss: 0.1003118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626845\n",
      "\tspeed: 0.0618s/iter; left time: 1309.1709s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603980\n",
      "\tspeed: 0.0334s/iter; left time: 705.0497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0631113 Vali Loss: 0.0877236 Test Loss: 0.1011920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590933\n",
      "\tspeed: 0.0625s/iter; left time: 1308.7874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597084\n",
      "\tspeed: 0.0343s/iter; left time: 715.6098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0589081 Vali Loss: 0.0872310 Test Loss: 0.1004953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552450\n",
      "\tspeed: 0.0615s/iter; left time: 1275.5372s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551953\n",
      "\tspeed: 0.0330s/iter; left time: 681.7645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0555059 Vali Loss: 0.0881087 Test Loss: 0.1008888\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524991\n",
      "\tspeed: 0.0613s/iter; left time: 1258.2121s\n",
      "\titers: 200, epoch: 9 | loss: 0.0530768\n",
      "\tspeed: 0.0335s/iter; left time: 684.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0527471 Vali Loss: 0.0886423 Test Loss: 0.1020612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515361\n",
      "\tspeed: 0.0615s/iter; left time: 1248.5369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495522\n",
      "\tspeed: 0.0333s/iter; left time: 672.2791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0506641 Vali Loss: 0.0878667 Test Loss: 0.1018857\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0495449\n",
      "\tspeed: 0.0623s/iter; left time: 1250.3964s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484085\n",
      "\tspeed: 0.0335s/iter; left time: 669.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0487303 Vali Loss: 0.0874963 Test Loss: 0.1018826\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460823\n",
      "\tspeed: 0.0617s/iter; left time: 1223.9532s\n",
      "\titers: 200, epoch: 12 | loss: 0.0487627\n",
      "\tspeed: 0.0336s/iter; left time: 663.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0472277 Vali Loss: 0.0875905 Test Loss: 0.1023017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0471489\n",
      "\tspeed: 0.0633s/iter; left time: 1242.2478s\n",
      "\titers: 200, epoch: 13 | loss: 0.0454935\n",
      "\tspeed: 0.0338s/iter; left time: 658.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0459133 Vali Loss: 0.0874007 Test Loss: 0.1019594\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021271303296089172, rmse:0.14584684371948242, mae:0.09627804905176163, rse:0.4284541606903076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204117\n",
      "\tspeed: 0.0358s/iter; left time: 798.9261s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046546\n",
      "\tspeed: 0.0334s/iter; left time: 741.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.1222082 Vali Loss: 0.0986339 Test Loss: 0.1127096\n",
      "Validation loss decreased (inf --> 0.098634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892475\n",
      "\tspeed: 0.0657s/iter; left time: 1450.8334s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875973\n",
      "\tspeed: 0.0336s/iter; left time: 737.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0889160 Vali Loss: 0.0860521 Test Loss: 0.0965959\n",
      "Validation loss decreased (0.098634 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820314\n",
      "\tspeed: 0.0665s/iter; left time: 1452.5428s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766245\n",
      "\tspeed: 0.0333s/iter; left time: 724.2658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0810734 Vali Loss: 0.0846253 Test Loss: 0.0976963\n",
      "Validation loss decreased (0.086052 --> 0.084625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731675\n",
      "\tspeed: 0.0650s/iter; left time: 1405.0739s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741658\n",
      "\tspeed: 0.0334s/iter; left time: 718.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0754243 Vali Loss: 0.0878123 Test Loss: 0.1005267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0716164\n",
      "\tspeed: 0.0627s/iter; left time: 1342.0038s\n",
      "\titers: 200, epoch: 5 | loss: 0.0671426\n",
      "\tspeed: 0.0338s/iter; left time: 719.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0690027 Vali Loss: 0.0878285 Test Loss: 0.1006422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641997\n",
      "\tspeed: 0.0646s/iter; left time: 1367.6287s\n",
      "\titers: 200, epoch: 6 | loss: 0.0674796\n",
      "\tspeed: 0.0337s/iter; left time: 710.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0635019 Vali Loss: 0.0878592 Test Loss: 0.1024417\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591606\n",
      "\tspeed: 0.0641s/iter; left time: 1344.1498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583029\n",
      "\tspeed: 0.0334s/iter; left time: 697.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0588996 Vali Loss: 0.0877868 Test Loss: 0.1020480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553827\n",
      "\tspeed: 0.0635s/iter; left time: 1316.4154s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554482\n",
      "\tspeed: 0.0342s/iter; left time: 705.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0554791 Vali Loss: 0.0881074 Test Loss: 0.1035934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0541625\n",
      "\tspeed: 0.0631s/iter; left time: 1294.9886s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502246\n",
      "\tspeed: 0.0337s/iter; left time: 687.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0527017 Vali Loss: 0.0881722 Test Loss: 0.1024241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0498284\n",
      "\tspeed: 0.0627s/iter; left time: 1270.8746s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489367\n",
      "\tspeed: 0.0336s/iter; left time: 678.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0506088 Vali Loss: 0.0888529 Test Loss: 0.1031139\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476753\n",
      "\tspeed: 0.0635s/iter; left time: 1273.9747s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481353\n",
      "\tspeed: 0.0333s/iter; left time: 665.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0486823 Vali Loss: 0.0881064 Test Loss: 0.1029631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0461587\n",
      "\tspeed: 0.0642s/iter; left time: 1272.9597s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474565\n",
      "\tspeed: 0.0335s/iter; left time: 661.5125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0471709 Vali Loss: 0.0887941 Test Loss: 0.1031620\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465209\n",
      "\tspeed: 0.0635s/iter; left time: 1245.9409s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457823\n",
      "\tspeed: 0.0337s/iter; left time: 657.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0457775 Vali Loss: 0.0880506 Test Loss: 0.1036356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021871840581297874, rmse:0.1478913128376007, mae:0.09769626706838608, rse:0.4344601631164551\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:25.68s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163252\n",
      "\tspeed: 0.0581s/iter; left time: 1290.1549s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111509\n",
      "\tspeed: 0.0341s/iter; left time: 754.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1248032 Vali Loss: 0.1023557 Test Loss: 0.1157608\n",
      "Validation loss decreased (inf --> 0.102356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920324\n",
      "\tspeed: 0.0796s/iter; left time: 1748.3776s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905396\n",
      "\tspeed: 0.0341s/iter; left time: 745.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 223 | Train Loss: 0.0927347 Vali Loss: 0.0911596 Test Loss: 0.1026373\n",
      "Validation loss decreased (0.102356 --> 0.091160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813993\n",
      "\tspeed: 0.0668s/iter; left time: 1454.1653s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804934\n",
      "\tspeed: 0.0344s/iter; left time: 745.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0837477 Vali Loss: 0.0901361 Test Loss: 0.1034494\n",
      "Validation loss decreased (0.091160 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745005\n",
      "\tspeed: 0.0733s/iter; left time: 1577.2343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743757\n",
      "\tspeed: 0.0343s/iter; left time: 735.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0773343 Vali Loss: 0.0920163 Test Loss: 0.1045371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717543\n",
      "\tspeed: 0.0647s/iter; left time: 1377.6613s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683926\n",
      "\tspeed: 0.0343s/iter; left time: 728.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0706961 Vali Loss: 0.0927095 Test Loss: 0.1056051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635267\n",
      "\tspeed: 0.0641s/iter; left time: 1352.1299s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626201\n",
      "\tspeed: 0.0338s/iter; left time: 710.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 223 | Train Loss: 0.0648583 Vali Loss: 0.0928507 Test Loss: 0.1066073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594731\n",
      "\tspeed: 0.0642s/iter; left time: 1339.7372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574201\n",
      "\tspeed: 0.0343s/iter; left time: 712.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0604445 Vali Loss: 0.0937179 Test Loss: 0.1071184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578186\n",
      "\tspeed: 0.0639s/iter; left time: 1319.0169s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562383\n",
      "\tspeed: 0.0342s/iter; left time: 702.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0571987 Vali Loss: 0.0920181 Test Loss: 0.1071269\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552342\n",
      "\tspeed: 0.0663s/iter; left time: 1352.9714s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548123\n",
      "\tspeed: 0.0342s/iter; left time: 694.4682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0545950 Vali Loss: 0.0930666 Test Loss: 0.1075234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529762\n",
      "\tspeed: 0.0646s/iter; left time: 1303.6571s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518859\n",
      "\tspeed: 0.0340s/iter; left time: 684.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 223 | Train Loss: 0.0524777 Vali Loss: 0.0920488 Test Loss: 0.1072294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0511605\n",
      "\tspeed: 0.0643s/iter; left time: 1283.3830s\n",
      "\titers: 200, epoch: 11 | loss: 0.0511627\n",
      "\tspeed: 0.0342s/iter; left time: 678.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0506818 Vali Loss: 0.0927317 Test Loss: 0.1083499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0496722\n",
      "\tspeed: 0.0636s/iter; left time: 1256.5535s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484021\n",
      "\tspeed: 0.0342s/iter; left time: 672.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.0491604 Vali Loss: 0.0922555 Test Loss: 0.1075642\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480842\n",
      "\tspeed: 0.0637s/iter; left time: 1243.6095s\n",
      "\titers: 200, epoch: 13 | loss: 0.0480131\n",
      "\tspeed: 0.0340s/iter; left time: 659.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0478748 Vali Loss: 0.0920726 Test Loss: 0.1082650\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0238569937646389, rmse:0.15445709228515625, mae:0.10344940423965454, rse:0.45378103852272034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175357\n",
      "\tspeed: 0.0366s/iter; left time: 812.7469s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085309\n",
      "\tspeed: 0.0348s/iter; left time: 768.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.1244877 Vali Loss: 0.1024658 Test Loss: 0.1162681\n",
      "Validation loss decreased (inf --> 0.102466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892978\n",
      "\tspeed: 0.0710s/iter; left time: 1559.3727s\n",
      "\titers: 200, epoch: 2 | loss: 0.0858404\n",
      "\tspeed: 0.0338s/iter; left time: 739.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0925368 Vali Loss: 0.0931649 Test Loss: 0.1041178\n",
      "Validation loss decreased (0.102466 --> 0.093165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0832203\n",
      "\tspeed: 0.0715s/iter; left time: 1555.9789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824200\n",
      "\tspeed: 0.0342s/iter; left time: 740.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0840002 Vali Loss: 0.0918773 Test Loss: 0.1027539\n",
      "Validation loss decreased (0.093165 --> 0.091877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755718\n",
      "\tspeed: 0.0702s/iter; left time: 1511.5730s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789680\n",
      "\tspeed: 0.0343s/iter; left time: 734.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0778846 Vali Loss: 0.0915824 Test Loss: 0.1033742\n",
      "Validation loss decreased (0.091877 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740893\n",
      "\tspeed: 0.0685s/iter; left time: 1460.2654s\n",
      "\titers: 200, epoch: 5 | loss: 0.0704942\n",
      "\tspeed: 0.0340s/iter; left time: 721.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0719597 Vali Loss: 0.0934459 Test Loss: 0.1050283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0674252\n",
      "\tspeed: 0.0654s/iter; left time: 1378.6719s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634718\n",
      "\tspeed: 0.0340s/iter; left time: 712.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0659032 Vali Loss: 0.0927102 Test Loss: 0.1051720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629653\n",
      "\tspeed: 0.0657s/iter; left time: 1371.1388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605651\n",
      "\tspeed: 0.0342s/iter; left time: 709.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0613759 Vali Loss: 0.0924244 Test Loss: 0.1051302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563948\n",
      "\tspeed: 0.0668s/iter; left time: 1379.2055s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562144\n",
      "\tspeed: 0.0339s/iter; left time: 696.2432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0577199 Vali Loss: 0.0931844 Test Loss: 0.1064090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559244\n",
      "\tspeed: 0.0656s/iter; left time: 1339.6380s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532067\n",
      "\tspeed: 0.0341s/iter; left time: 691.9724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0549016 Vali Loss: 0.0936035 Test Loss: 0.1066466\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514232\n",
      "\tspeed: 0.0648s/iter; left time: 1309.3887s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512180\n",
      "\tspeed: 0.0341s/iter; left time: 686.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0526190 Vali Loss: 0.0929514 Test Loss: 0.1060959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514014\n",
      "\tspeed: 0.0655s/iter; left time: 1307.3120s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494085\n",
      "\tspeed: 0.0343s/iter; left time: 682.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0508202 Vali Loss: 0.0938980 Test Loss: 0.1071277\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0495044\n",
      "\tspeed: 0.0658s/iter; left time: 1299.7733s\n",
      "\titers: 200, epoch: 12 | loss: 0.0483764\n",
      "\tspeed: 0.0352s/iter; left time: 690.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0491536 Vali Loss: 0.0933724 Test Loss: 0.1070942\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0487324\n",
      "\tspeed: 0.0668s/iter; left time: 1304.0319s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466656\n",
      "\tspeed: 0.0350s/iter; left time: 680.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0478594 Vali Loss: 0.0935658 Test Loss: 0.1077204\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470098\n",
      "\tspeed: 0.0657s/iter; left time: 1267.9379s\n",
      "\titers: 200, epoch: 14 | loss: 0.0454411\n",
      "\tspeed: 0.0341s/iter; left time: 654.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0467149 Vali Loss: 0.0932253 Test Loss: 0.1074122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023433756083250046, rmse:0.15308088064193726, mae:0.10337422043085098, rse:0.44973787665367126\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:45.14s\n",
      "Intermediate time for ES: 00h:14m:55.41s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0776064\n",
      "\tspeed: 0.0587s/iter; left time: 1309.0773s\n",
      "\titers: 200, epoch: 1 | loss: 0.0689711\n",
      "\tspeed: 0.0323s/iter; left time: 716.3089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0842278 Vali Loss: 0.0746167 Test Loss: 0.0815443\n",
      "Validation loss decreased (inf --> 0.074617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0531533\n",
      "\tspeed: 0.0614s/iter; left time: 1354.6684s\n",
      "\titers: 200, epoch: 2 | loss: 0.0528795\n",
      "\tspeed: 0.0324s/iter; left time: 711.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0527035 Vali Loss: 0.0587939 Test Loss: 0.0632445\n",
      "Validation loss decreased (0.074617 --> 0.058794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0471682\n",
      "\tspeed: 0.0660s/iter; left time: 1441.7854s\n",
      "\titers: 200, epoch: 3 | loss: 0.0457505\n",
      "\tspeed: 0.0327s/iter; left time: 712.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0473227 Vali Loss: 0.0575117 Test Loss: 0.0627745\n",
      "Validation loss decreased (0.058794 --> 0.057512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0463470\n",
      "\tspeed: 0.0664s/iter; left time: 1435.6515s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481664\n",
      "\tspeed: 0.0332s/iter; left time: 714.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0455139 Vali Loss: 0.0574781 Test Loss: 0.0624749\n",
      "Validation loss decreased (0.057512 --> 0.057478).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467309\n",
      "\tspeed: 0.0657s/iter; left time: 1406.4669s\n",
      "\titers: 200, epoch: 5 | loss: 0.0446282\n",
      "\tspeed: 0.0326s/iter; left time: 694.6811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0437584 Vali Loss: 0.0551695 Test Loss: 0.0619991\n",
      "Validation loss decreased (0.057478 --> 0.055170).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0407794\n",
      "\tspeed: 0.0623s/iter; left time: 1318.7658s\n",
      "\titers: 200, epoch: 6 | loss: 0.0384185\n",
      "\tspeed: 0.0331s/iter; left time: 697.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0419962 Vali Loss: 0.0557887 Test Loss: 0.0628854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0402396\n",
      "\tspeed: 0.0595s/iter; left time: 1247.8860s\n",
      "\titers: 200, epoch: 7 | loss: 0.0402509\n",
      "\tspeed: 0.0325s/iter; left time: 676.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0402307 Vali Loss: 0.0556562 Test Loss: 0.0631281\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0379331\n",
      "\tspeed: 0.0613s/iter; left time: 1270.0383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0385543\n",
      "\tspeed: 0.0325s/iter; left time: 671.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0386213 Vali Loss: 0.0560320 Test Loss: 0.0646798\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0364931\n",
      "\tspeed: 0.0598s/iter; left time: 1226.0757s\n",
      "\titers: 200, epoch: 9 | loss: 0.0386902\n",
      "\tspeed: 0.0324s/iter; left time: 661.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0371513 Vali Loss: 0.0557153 Test Loss: 0.0647850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0368047\n",
      "\tspeed: 0.0609s/iter; left time: 1234.9129s\n",
      "\titers: 200, epoch: 10 | loss: 0.0341395\n",
      "\tspeed: 0.0327s/iter; left time: 661.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0357683 Vali Loss: 0.0568122 Test Loss: 0.0655629\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0343697\n",
      "\tspeed: 0.0615s/iter; left time: 1233.2480s\n",
      "\titers: 200, epoch: 11 | loss: 0.0357826\n",
      "\tspeed: 0.0324s/iter; left time: 646.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0344320 Vali Loss: 0.0567076 Test Loss: 0.0657521\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0327125\n",
      "\tspeed: 0.0596s/iter; left time: 1182.0525s\n",
      "\titers: 200, epoch: 12 | loss: 0.0331983\n",
      "\tspeed: 0.0325s/iter; left time: 640.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0332904 Vali Loss: 0.0569363 Test Loss: 0.0662714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0341434\n",
      "\tspeed: 0.0609s/iter; left time: 1193.9434s\n",
      "\titers: 200, epoch: 13 | loss: 0.0316493\n",
      "\tspeed: 0.0325s/iter; left time: 635.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0322657 Vali Loss: 0.0569743 Test Loss: 0.0673161\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0335650\n",
      "\tspeed: 0.0616s/iter; left time: 1194.7385s\n",
      "\titers: 200, epoch: 14 | loss: 0.0316226\n",
      "\tspeed: 0.0325s/iter; left time: 626.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0313672 Vali Loss: 0.0569273 Test Loss: 0.0670634\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0285776\n",
      "\tspeed: 0.0607s/iter; left time: 1162.9691s\n",
      "\titers: 200, epoch: 15 | loss: 0.0301777\n",
      "\tspeed: 0.0325s/iter; left time: 618.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0306123 Vali Loss: 0.0578428 Test Loss: 0.0671806\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011569960042834282, rmse:0.10756374895572662, mae:0.06199907511472702, rse:0.4149779677391052\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0765755\n",
      "\tspeed: 0.0347s/iter; left time: 773.8502s\n",
      "\titers: 200, epoch: 1 | loss: 0.0715873\n",
      "\tspeed: 0.0323s/iter; left time: 716.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0848132 Vali Loss: 0.0750400 Test Loss: 0.0822929\n",
      "Validation loss decreased (inf --> 0.075040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0532299\n",
      "\tspeed: 0.0637s/iter; left time: 1405.6653s\n",
      "\titers: 200, epoch: 2 | loss: 0.0497959\n",
      "\tspeed: 0.0327s/iter; left time: 719.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0526962 Vali Loss: 0.0586718 Test Loss: 0.0637208\n",
      "Validation loss decreased (0.075040 --> 0.058672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0449452\n",
      "\tspeed: 0.0619s/iter; left time: 1352.4978s\n",
      "\titers: 200, epoch: 3 | loss: 0.0478727\n",
      "\tspeed: 0.0326s/iter; left time: 708.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0474259 Vali Loss: 0.0574775 Test Loss: 0.0623785\n",
      "Validation loss decreased (0.058672 --> 0.057478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0479655\n",
      "\tspeed: 0.0632s/iter; left time: 1366.7544s\n",
      "\titers: 200, epoch: 4 | loss: 0.0423369\n",
      "\tspeed: 0.0328s/iter; left time: 706.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0456964 Vali Loss: 0.0566878 Test Loss: 0.0617239\n",
      "Validation loss decreased (0.057478 --> 0.056688).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0443972\n",
      "\tspeed: 0.0628s/iter; left time: 1344.7824s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437183\n",
      "\tspeed: 0.0326s/iter; left time: 694.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0440220 Vali Loss: 0.0561451 Test Loss: 0.0622689\n",
      "Validation loss decreased (0.056688 --> 0.056145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0417378\n",
      "\tspeed: 0.0650s/iter; left time: 1376.4881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0425886\n",
      "\tspeed: 0.0330s/iter; left time: 695.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0423362 Vali Loss: 0.0566242 Test Loss: 0.0636812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0408028\n",
      "\tspeed: 0.0630s/iter; left time: 1319.6563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407621\n",
      "\tspeed: 0.0327s/iter; left time: 682.4362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0406709 Vali Loss: 0.0558169 Test Loss: 0.0628909\n",
      "Validation loss decreased (0.056145 --> 0.055817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0415118\n",
      "\tspeed: 0.0623s/iter; left time: 1291.6641s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397285\n",
      "\tspeed: 0.0323s/iter; left time: 667.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0390934 Vali Loss: 0.0559703 Test Loss: 0.0631211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0359722\n",
      "\tspeed: 0.0603s/iter; left time: 1237.2548s\n",
      "\titers: 200, epoch: 9 | loss: 0.0355636\n",
      "\tspeed: 0.0324s/iter; left time: 661.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0375667 Vali Loss: 0.0563328 Test Loss: 0.0643593\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0364585\n",
      "\tspeed: 0.0623s/iter; left time: 1262.7730s\n",
      "\titers: 200, epoch: 10 | loss: 0.0347073\n",
      "\tspeed: 0.0330s/iter; left time: 665.5518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0361043 Vali Loss: 0.0561320 Test Loss: 0.0643679\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0359929\n",
      "\tspeed: 0.0612s/iter; left time: 1228.5221s\n",
      "\titers: 200, epoch: 11 | loss: 0.0343686\n",
      "\tspeed: 0.0323s/iter; left time: 644.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0348943 Vali Loss: 0.0568348 Test Loss: 0.0645087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0346736\n",
      "\tspeed: 0.0605s/iter; left time: 1200.1561s\n",
      "\titers: 200, epoch: 12 | loss: 0.0335486\n",
      "\tspeed: 0.0327s/iter; left time: 646.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0338053 Vali Loss: 0.0570722 Test Loss: 0.0656173\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0334411\n",
      "\tspeed: 0.0618s/iter; left time: 1212.0180s\n",
      "\titers: 200, epoch: 13 | loss: 0.0322468\n",
      "\tspeed: 0.0328s/iter; left time: 639.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0328119 Vali Loss: 0.0568148 Test Loss: 0.0648483\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0326624\n",
      "\tspeed: 0.0606s/iter; left time: 1175.6832s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324357\n",
      "\tspeed: 0.0329s/iter; left time: 635.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0318300 Vali Loss: 0.0576550 Test Loss: 0.0659730\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0302384\n",
      "\tspeed: 0.0606s/iter; left time: 1160.5533s\n",
      "\titers: 200, epoch: 15 | loss: 0.0335285\n",
      "\tspeed: 0.0324s/iter; left time: 618.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0310831 Vali Loss: 0.0576739 Test Loss: 0.0659032\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0316819\n",
      "\tspeed: 0.0602s/iter; left time: 1140.3543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0300952\n",
      "\tspeed: 0.0323s/iter; left time: 608.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0304891 Vali Loss: 0.0578517 Test Loss: 0.0663014\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0300540\n",
      "\tspeed: 0.0626s/iter; left time: 1172.3508s\n",
      "\titers: 200, epoch: 17 | loss: 0.0303118\n",
      "\tspeed: 0.0323s/iter; left time: 601.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0299137 Vali Loss: 0.0575964 Test Loss: 0.0659298\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012248861603438854, rmse:0.11067457497119904, mae:0.0628909021615982, rse:0.4269794225692749\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:14.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0862475\n",
      "\tspeed: 0.0585s/iter; left time: 1305.5679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0789353\n",
      "\tspeed: 0.0334s/iter; left time: 741.2368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0918407 Vali Loss: 0.0848530 Test Loss: 0.0949307\n",
      "Validation loss decreased (inf --> 0.084853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0645173\n",
      "\tspeed: 0.0730s/iter; left time: 1611.9318s\n",
      "\titers: 200, epoch: 2 | loss: 0.0630785\n",
      "\tspeed: 0.0332s/iter; left time: 729.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0665209 Vali Loss: 0.0769489 Test Loss: 0.0858871\n",
      "Validation loss decreased (0.084853 --> 0.076949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0585615\n",
      "\tspeed: 0.0677s/iter; left time: 1480.2264s\n",
      "\titers: 200, epoch: 3 | loss: 0.0544285\n",
      "\tspeed: 0.0334s/iter; left time: 725.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0585479 Vali Loss: 0.0776967 Test Loss: 0.0911700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0547643\n",
      "\tspeed: 0.0635s/iter; left time: 1374.2713s\n",
      "\titers: 200, epoch: 4 | loss: 0.0521349\n",
      "\tspeed: 0.0333s/iter; left time: 717.6269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0523000 Vali Loss: 0.0776609 Test Loss: 0.0917702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467123\n",
      "\tspeed: 0.0641s/iter; left time: 1372.1629s\n",
      "\titers: 200, epoch: 5 | loss: 0.0436993\n",
      "\tspeed: 0.0333s/iter; left time: 710.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0471033 Vali Loss: 0.0789060 Test Loss: 0.0933320\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454650\n",
      "\tspeed: 0.0631s/iter; left time: 1336.3567s\n",
      "\titers: 200, epoch: 6 | loss: 0.0418738\n",
      "\tspeed: 0.0342s/iter; left time: 721.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0433095 Vali Loss: 0.0802796 Test Loss: 0.0966435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0411551\n",
      "\tspeed: 0.0650s/iter; left time: 1361.8377s\n",
      "\titers: 200, epoch: 7 | loss: 0.0411320\n",
      "\tspeed: 0.0340s/iter; left time: 709.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0405892 Vali Loss: 0.0795505 Test Loss: 0.0968952\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0395948\n",
      "\tspeed: 0.0634s/iter; left time: 1314.8204s\n",
      "\titers: 200, epoch: 8 | loss: 0.0366879\n",
      "\tspeed: 0.0334s/iter; left time: 688.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0383602 Vali Loss: 0.0795767 Test Loss: 0.0967200\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0365589\n",
      "\tspeed: 0.0642s/iter; left time: 1316.7185s\n",
      "\titers: 200, epoch: 9 | loss: 0.0354121\n",
      "\tspeed: 0.0334s/iter; left time: 681.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0365612 Vali Loss: 0.0798155 Test Loss: 0.0960024\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0347551\n",
      "\tspeed: 0.0645s/iter; left time: 1308.1237s\n",
      "\titers: 200, epoch: 10 | loss: 0.0357937\n",
      "\tspeed: 0.0334s/iter; left time: 675.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0351166 Vali Loss: 0.0796748 Test Loss: 0.0970269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0328615\n",
      "\tspeed: 0.0638s/iter; left time: 1280.0189s\n",
      "\titers: 200, epoch: 11 | loss: 0.0321747\n",
      "\tspeed: 0.0334s/iter; left time: 666.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0338496 Vali Loss: 0.0797598 Test Loss: 0.0963629\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0320179\n",
      "\tspeed: 0.0644s/iter; left time: 1277.9659s\n",
      "\titers: 200, epoch: 12 | loss: 0.0319372\n",
      "\tspeed: 0.0336s/iter; left time: 664.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0327725 Vali Loss: 0.0793384 Test Loss: 0.0966827\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020557139068841934, rmse:0.1433776170015335, mae:0.0858871340751648, rse:0.5546227097511292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0868272\n",
      "\tspeed: 0.0359s/iter; left time: 800.3377s\n",
      "\titers: 200, epoch: 1 | loss: 0.0793261\n",
      "\tspeed: 0.0333s/iter; left time: 740.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0914667 Vali Loss: 0.0848870 Test Loss: 0.0946935\n",
      "Validation loss decreased (inf --> 0.084887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672989\n",
      "\tspeed: 0.0671s/iter; left time: 1480.3526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0643385\n",
      "\tspeed: 0.0337s/iter; left time: 740.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0665327 Vali Loss: 0.0759749 Test Loss: 0.0862460\n",
      "Validation loss decreased (0.084887 --> 0.075975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0572134\n",
      "\tspeed: 0.0704s/iter; left time: 1537.4687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0561207\n",
      "\tspeed: 0.0333s/iter; left time: 725.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0591155 Vali Loss: 0.0771875 Test Loss: 0.0894880\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0540748\n",
      "\tspeed: 0.0646s/iter; left time: 1398.0343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0516426\n",
      "\tspeed: 0.0333s/iter; left time: 716.7366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0531906 Vali Loss: 0.0777607 Test Loss: 0.0927518\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0487083\n",
      "\tspeed: 0.0646s/iter; left time: 1383.6796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0476975\n",
      "\tspeed: 0.0334s/iter; left time: 711.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0481023 Vali Loss: 0.0778513 Test Loss: 0.0919247\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0438590\n",
      "\tspeed: 0.0664s/iter; left time: 1407.3779s\n",
      "\titers: 200, epoch: 6 | loss: 0.0438163\n",
      "\tspeed: 0.0340s/iter; left time: 716.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0444282 Vali Loss: 0.0778370 Test Loss: 0.0944785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0434413\n",
      "\tspeed: 0.0637s/iter; left time: 1335.7837s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407474\n",
      "\tspeed: 0.0333s/iter; left time: 693.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0413640 Vali Loss: 0.0781349 Test Loss: 0.0949088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0380688\n",
      "\tspeed: 0.0650s/iter; left time: 1347.8890s\n",
      "\titers: 200, epoch: 8 | loss: 0.0378286\n",
      "\tspeed: 0.0335s/iter; left time: 690.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0390794 Vali Loss: 0.0777945 Test Loss: 0.0954822\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0375700\n",
      "\tspeed: 0.0648s/iter; left time: 1329.4683s\n",
      "\titers: 200, epoch: 9 | loss: 0.0364217\n",
      "\tspeed: 0.0334s/iter; left time: 680.7501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0372009 Vali Loss: 0.0778999 Test Loss: 0.0945588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352148\n",
      "\tspeed: 0.0638s/iter; left time: 1295.1439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0341083\n",
      "\tspeed: 0.0335s/iter; left time: 677.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0356917 Vali Loss: 0.0790417 Test Loss: 0.0960830\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0338370\n",
      "\tspeed: 0.0646s/iter; left time: 1295.8137s\n",
      "\titers: 200, epoch: 11 | loss: 0.0333588\n",
      "\tspeed: 0.0339s/iter; left time: 675.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0343948 Vali Loss: 0.0780501 Test Loss: 0.0963719\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0330616\n",
      "\tspeed: 0.0653s/iter; left time: 1295.9105s\n",
      "\titers: 200, epoch: 12 | loss: 0.0332803\n",
      "\tspeed: 0.0339s/iter; left time: 669.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0333036 Vali Loss: 0.0783700 Test Loss: 0.0960959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021034399047493935, rmse:0.14503240585327148, mae:0.08624604344367981, rse:0.5610238909721375\n",
      "Intermediate time for FR and pred_len 96: 00h:04m:10.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0884569\n",
      "\tspeed: 0.0585s/iter; left time: 1299.3233s\n",
      "\titers: 200, epoch: 1 | loss: 0.0808866\n",
      "\tspeed: 0.0337s/iter; left time: 744.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0938542 Vali Loss: 0.0877504 Test Loss: 0.0973185\n",
      "Validation loss decreased (inf --> 0.087750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0651276\n",
      "\tspeed: 0.0940s/iter; left time: 2065.7458s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672713\n",
      "\tspeed: 0.0339s/iter; left time: 742.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 223 | Train Loss: 0.0701975 Vali Loss: 0.0814480 Test Loss: 0.0920999\n",
      "Validation loss decreased (0.087750 --> 0.081448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0625057\n",
      "\tspeed: 0.1012s/iter; left time: 2201.0929s\n",
      "\titers: 200, epoch: 3 | loss: 0.0557836\n",
      "\tspeed: 0.0350s/iter; left time: 758.6544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0607981 Vali Loss: 0.0819982 Test Loss: 0.0934285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0535417\n",
      "\tspeed: 0.0656s/iter; left time: 1412.4035s\n",
      "\titers: 200, epoch: 4 | loss: 0.0509764\n",
      "\tspeed: 0.0344s/iter; left time: 737.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0534699 Vali Loss: 0.0824004 Test Loss: 0.0964533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0492397\n",
      "\tspeed: 0.0652s/iter; left time: 1389.0673s\n",
      "\titers: 200, epoch: 5 | loss: 0.0452260\n",
      "\tspeed: 0.0341s/iter; left time: 723.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0479584 Vali Loss: 0.0834585 Test Loss: 0.0963291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0442968\n",
      "\tspeed: 0.0631s/iter; left time: 1330.9333s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427738\n",
      "\tspeed: 0.0335s/iter; left time: 703.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0441876 Vali Loss: 0.0830720 Test Loss: 0.0960464\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0400089\n",
      "\tspeed: 0.0633s/iter; left time: 1320.4161s\n",
      "\titers: 200, epoch: 7 | loss: 0.0401345\n",
      "\tspeed: 0.0334s/iter; left time: 694.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 223 | Train Loss: 0.0413019 Vali Loss: 0.0828756 Test Loss: 0.0959889\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0403139\n",
      "\tspeed: 0.0635s/iter; left time: 1309.8995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0387559\n",
      "\tspeed: 0.0335s/iter; left time: 688.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0391119 Vali Loss: 0.0828041 Test Loss: 0.0960062\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0369264\n",
      "\tspeed: 0.0639s/iter; left time: 1304.7621s\n",
      "\titers: 200, epoch: 9 | loss: 0.0361813\n",
      "\tspeed: 0.0338s/iter; left time: 686.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0373108 Vali Loss: 0.0828253 Test Loss: 0.0964746\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0361604\n",
      "\tspeed: 0.0644s/iter; left time: 1301.1673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0344419\n",
      "\tspeed: 0.0337s/iter; left time: 677.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0358161 Vali Loss: 0.0833129 Test Loss: 0.0963833\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0343810\n",
      "\tspeed: 0.0637s/iter; left time: 1272.4359s\n",
      "\titers: 200, epoch: 11 | loss: 0.0339394\n",
      "\tspeed: 0.0335s/iter; left time: 666.3024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0345840 Vali Loss: 0.0826738 Test Loss: 0.0961679\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0336313\n",
      "\tspeed: 0.0637s/iter; left time: 1258.9254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0324802\n",
      "\tspeed: 0.0333s/iter; left time: 655.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0335197 Vali Loss: 0.0831679 Test Loss: 0.0963215\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02259443700313568, rmse:0.15031446516513824, mae:0.09209997206926346, rse:0.5821821093559265\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0894092\n",
      "\tspeed: 0.0361s/iter; left time: 800.5101s\n",
      "\titers: 200, epoch: 1 | loss: 0.0825871\n",
      "\tspeed: 0.0336s/iter; left time: 742.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0932287 Vali Loss: 0.0877802 Test Loss: 0.0973582\n",
      "Validation loss decreased (inf --> 0.087780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0690800\n",
      "\tspeed: 0.0697s/iter; left time: 1531.7156s\n",
      "\titers: 200, epoch: 2 | loss: 0.0640077\n",
      "\tspeed: 0.0335s/iter; left time: 733.1942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0702661 Vali Loss: 0.0803683 Test Loss: 0.0915588\n",
      "Validation loss decreased (0.087780 --> 0.080368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638850\n",
      "\tspeed: 0.0665s/iter; left time: 1446.7912s\n",
      "\titers: 200, epoch: 3 | loss: 0.0567797\n",
      "\tspeed: 0.0335s/iter; left time: 724.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0612572 Vali Loss: 0.0804416 Test Loss: 0.0938794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0542146\n",
      "\tspeed: 0.0632s/iter; left time: 1360.5697s\n",
      "\titers: 200, epoch: 4 | loss: 0.0533359\n",
      "\tspeed: 0.0336s/iter; left time: 720.3123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 223 | Train Loss: 0.0544359 Vali Loss: 0.0820984 Test Loss: 0.0975414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0482048\n",
      "\tspeed: 0.0633s/iter; left time: 1349.6828s\n",
      "\titers: 200, epoch: 5 | loss: 0.0485607\n",
      "\tspeed: 0.0343s/iter; left time: 726.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0490092 Vali Loss: 0.0828655 Test Loss: 0.0976705\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460692\n",
      "\tspeed: 0.0646s/iter; left time: 1361.7513s\n",
      "\titers: 200, epoch: 6 | loss: 0.0440988\n",
      "\tspeed: 0.0335s/iter; left time: 703.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0451625 Vali Loss: 0.0829948 Test Loss: 0.0985005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0410739\n",
      "\tspeed: 0.0637s/iter; left time: 1329.6645s\n",
      "\titers: 200, epoch: 7 | loss: 0.0414795\n",
      "\tspeed: 0.0335s/iter; left time: 695.1018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0421384 Vali Loss: 0.0837119 Test Loss: 0.0984630\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0402316\n",
      "\tspeed: 0.0634s/iter; left time: 1307.8705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0391680\n",
      "\tspeed: 0.0336s/iter; left time: 689.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0398440 Vali Loss: 0.0833129 Test Loss: 0.0983980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0374279\n",
      "\tspeed: 0.0633s/iter; left time: 1292.6745s\n",
      "\titers: 200, epoch: 9 | loss: 0.0369868\n",
      "\tspeed: 0.0335s/iter; left time: 680.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0379773 Vali Loss: 0.0829931 Test Loss: 0.0977898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0371010\n",
      "\tspeed: 0.0647s/iter; left time: 1306.6680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0362111\n",
      "\tspeed: 0.0339s/iter; left time: 681.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0364681 Vali Loss: 0.0829628 Test Loss: 0.0973047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0354411\n",
      "\tspeed: 0.0638s/iter; left time: 1274.4820s\n",
      "\titers: 200, epoch: 11 | loss: 0.0354721\n",
      "\tspeed: 0.0336s/iter; left time: 667.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0351750 Vali Loss: 0.0829564 Test Loss: 0.0978901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0346587\n",
      "\tspeed: 0.0632s/iter; left time: 1248.7402s\n",
      "\titers: 200, epoch: 12 | loss: 0.0330839\n",
      "\tspeed: 0.0335s/iter; left time: 658.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0340922 Vali Loss: 0.0831059 Test Loss: 0.0969260\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023193681612610817, rmse:0.15229472517967224, mae:0.09155873954296112, rse:0.5898519158363342\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:15.03s\n",
      "Intermediate time for FR: 00h:13m:40.44s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1052240\n",
      "\tspeed: 0.0593s/iter; left time: 1322.3394s\n",
      "\titers: 200, epoch: 1 | loss: 0.0995200\n",
      "\tspeed: 0.0324s/iter; left time: 718.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.1188541 Vali Loss: 0.0861337 Test Loss: 0.0891670\n",
      "Validation loss decreased (inf --> 0.086134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0668029\n",
      "\tspeed: 0.0639s/iter; left time: 1409.7165s\n",
      "\titers: 200, epoch: 2 | loss: 0.0655162\n",
      "\tspeed: 0.0322s/iter; left time: 708.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0720778 Vali Loss: 0.0639649 Test Loss: 0.0668498\n",
      "Validation loss decreased (0.086134 --> 0.063965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670426\n",
      "\tspeed: 0.0627s/iter; left time: 1369.7477s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649540\n",
      "\tspeed: 0.0323s/iter; left time: 703.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0645235 Vali Loss: 0.0623632 Test Loss: 0.0646318\n",
      "Validation loss decreased (0.063965 --> 0.062363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615188\n",
      "\tspeed: 0.0631s/iter; left time: 1364.2213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651470\n",
      "\tspeed: 0.0322s/iter; left time: 693.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0623022 Vali Loss: 0.0613726 Test Loss: 0.0651140\n",
      "Validation loss decreased (0.062363 --> 0.061373).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610557\n",
      "\tspeed: 0.0632s/iter; left time: 1352.2947s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604981\n",
      "\tspeed: 0.0324s/iter; left time: 689.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0607665 Vali Loss: 0.0618560 Test Loss: 0.0650788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569930\n",
      "\tspeed: 0.0619s/iter; left time: 1310.1207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620100\n",
      "\tspeed: 0.0326s/iter; left time: 686.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0583740 Vali Loss: 0.0603924 Test Loss: 0.0641359\n",
      "Validation loss decreased (0.061373 --> 0.060392).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534668\n",
      "\tspeed: 0.0649s/iter; left time: 1359.5353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0552543\n",
      "\tspeed: 0.0325s/iter; left time: 677.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0567980 Vali Loss: 0.0595051 Test Loss: 0.0627162\n",
      "Validation loss decreased (0.060392 --> 0.059505).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0539588\n",
      "\tspeed: 0.0638s/iter; left time: 1323.3991s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549810\n",
      "\tspeed: 0.0322s/iter; left time: 663.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0549697 Vali Loss: 0.0608740 Test Loss: 0.0637390\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538474\n",
      "\tspeed: 0.0603s/iter; left time: 1236.8981s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502654\n",
      "\tspeed: 0.0323s/iter; left time: 660.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0530986 Vali Loss: 0.0604585 Test Loss: 0.0635977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519460\n",
      "\tspeed: 0.0612s/iter; left time: 1241.8916s\n",
      "\titers: 200, epoch: 10 | loss: 0.0463895\n",
      "\tspeed: 0.0330s/iter; left time: 665.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0514600 Vali Loss: 0.0600744 Test Loss: 0.0641934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518249\n",
      "\tspeed: 0.0612s/iter; left time: 1227.1669s\n",
      "\titers: 200, epoch: 11 | loss: 0.0491804\n",
      "\tspeed: 0.0323s/iter; left time: 644.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0500287 Vali Loss: 0.0611684 Test Loss: 0.0645865\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0503090\n",
      "\tspeed: 0.0597s/iter; left time: 1184.4776s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513023\n",
      "\tspeed: 0.0321s/iter; left time: 633.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0486316 Vali Loss: 0.0609906 Test Loss: 0.0643800\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0467671\n",
      "\tspeed: 0.0608s/iter; left time: 1193.2976s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463996\n",
      "\tspeed: 0.0325s/iter; left time: 633.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0472041 Vali Loss: 0.0615323 Test Loss: 0.0650614\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0485981\n",
      "\tspeed: 0.0612s/iter; left time: 1186.2148s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465529\n",
      "\tspeed: 0.0323s/iter; left time: 622.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0459658 Vali Loss: 0.0623372 Test Loss: 0.0648194\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0431688\n",
      "\tspeed: 0.0611s/iter; left time: 1171.0140s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447366\n",
      "\tspeed: 0.0328s/iter; left time: 626.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0449380 Vali Loss: 0.0626743 Test Loss: 0.0651143\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0431246\n",
      "\tspeed: 0.0615s/iter; left time: 1165.6164s\n",
      "\titers: 200, epoch: 16 | loss: 0.0459317\n",
      "\tspeed: 0.0321s/iter; left time: 604.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0439346 Vali Loss: 0.0624681 Test Loss: 0.0658006\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0437078\n",
      "\tspeed: 0.0598s/iter; left time: 1118.7880s\n",
      "\titers: 200, epoch: 17 | loss: 0.0450082\n",
      "\tspeed: 0.0325s/iter; left time: 604.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0430947 Vali Loss: 0.0630289 Test Loss: 0.0656900\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011220804415643215, rmse:0.10592830181121826, mae:0.06271616369485855, rse:0.4002508819103241\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1160403\n",
      "\tspeed: 0.0343s/iter; left time: 765.5966s\n",
      "\titers: 200, epoch: 1 | loss: 0.0940983\n",
      "\tspeed: 0.0322s/iter; left time: 714.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.1176875 Vali Loss: 0.0858559 Test Loss: 0.0892095\n",
      "Validation loss decreased (inf --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0703001\n",
      "\tspeed: 0.0618s/iter; left time: 1364.3592s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682917\n",
      "\tspeed: 0.0327s/iter; left time: 718.0935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0718768 Vali Loss: 0.0640197 Test Loss: 0.0671154\n",
      "Validation loss decreased (0.085856 --> 0.064020).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675953\n",
      "\tspeed: 0.0645s/iter; left time: 1410.0610s\n",
      "\titers: 200, epoch: 3 | loss: 0.0618320\n",
      "\tspeed: 0.0321s/iter; left time: 699.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0647467 Vali Loss: 0.0626417 Test Loss: 0.0650419\n",
      "Validation loss decreased (0.064020 --> 0.062642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0653759\n",
      "\tspeed: 0.0627s/iter; left time: 1356.2144s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638989\n",
      "\tspeed: 0.0322s/iter; left time: 692.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0623659 Vali Loss: 0.0610645 Test Loss: 0.0640131\n",
      "Validation loss decreased (0.062642 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575085\n",
      "\tspeed: 0.0623s/iter; left time: 1334.1177s\n",
      "\titers: 200, epoch: 5 | loss: 0.0587094\n",
      "\tspeed: 0.0321s/iter; left time: 684.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0601151 Vali Loss: 0.0610883 Test Loss: 0.0636876\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577437\n",
      "\tspeed: 0.0599s/iter; left time: 1268.1228s\n",
      "\titers: 200, epoch: 6 | loss: 0.0556418\n",
      "\tspeed: 0.0322s/iter; left time: 678.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0580983 Vali Loss: 0.0604166 Test Loss: 0.0639995\n",
      "Validation loss decreased (0.061065 --> 0.060417).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0561289\n",
      "\tspeed: 0.0621s/iter; left time: 1302.1858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0562709\n",
      "\tspeed: 0.0325s/iter; left time: 677.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0565202 Vali Loss: 0.0604680 Test Loss: 0.0635442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0581985\n",
      "\tspeed: 0.0603s/iter; left time: 1250.4228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0544954\n",
      "\tspeed: 0.0321s/iter; left time: 662.6251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0545067 Vali Loss: 0.0608139 Test Loss: 0.0642482\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0527575\n",
      "\tspeed: 0.0617s/iter; left time: 1265.7564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503566\n",
      "\tspeed: 0.0324s/iter; left time: 660.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0529972 Vali Loss: 0.0604772 Test Loss: 0.0637462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0521386\n",
      "\tspeed: 0.0621s/iter; left time: 1260.5590s\n",
      "\titers: 200, epoch: 10 | loss: 0.0501020\n",
      "\tspeed: 0.0323s/iter; left time: 652.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0513403 Vali Loss: 0.0607974 Test Loss: 0.0645847\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0499747\n",
      "\tspeed: 0.0611s/iter; left time: 1225.9885s\n",
      "\titers: 200, epoch: 11 | loss: 0.0474736\n",
      "\tspeed: 0.0321s/iter; left time: 640.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0495997 Vali Loss: 0.0612057 Test Loss: 0.0651089\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0470874\n",
      "\tspeed: 0.0611s/iter; left time: 1212.8747s\n",
      "\titers: 200, epoch: 12 | loss: 0.0499756\n",
      "\tspeed: 0.0321s/iter; left time: 633.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0482302 Vali Loss: 0.0611211 Test Loss: 0.0649221\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0500659\n",
      "\tspeed: 0.0601s/iter; left time: 1178.1560s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463377\n",
      "\tspeed: 0.0322s/iter; left time: 627.9842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0468275 Vali Loss: 0.0616577 Test Loss: 0.0657040\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0437683\n",
      "\tspeed: 0.0599s/iter; left time: 1161.6980s\n",
      "\titers: 200, epoch: 14 | loss: 0.0452077\n",
      "\tspeed: 0.0321s/iter; left time: 619.3575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0456268 Vali Loss: 0.0622756 Test Loss: 0.0657823\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0445578\n",
      "\tspeed: 0.0620s/iter; left time: 1188.7984s\n",
      "\titers: 200, epoch: 15 | loss: 0.0429793\n",
      "\tspeed: 0.0324s/iter; left time: 617.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0444806 Vali Loss: 0.0620232 Test Loss: 0.0653317\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0447943\n",
      "\tspeed: 0.0622s/iter; left time: 1179.0772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0439081\n",
      "\tspeed: 0.0331s/iter; left time: 624.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0435288 Vali Loss: 0.0623529 Test Loss: 0.0663972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01142948679625988, rmse:0.10690877586603165, mae:0.06399953365325928, rse:0.4039556086063385\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:23.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1181966\n",
      "\tspeed: 0.0595s/iter; left time: 1326.4071s\n",
      "\titers: 200, epoch: 1 | loss: 0.1096394\n",
      "\tspeed: 0.0328s/iter; left time: 728.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.1280400 Vali Loss: 0.0973109 Test Loss: 0.1012016\n",
      "Validation loss decreased (inf --> 0.097311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877090\n",
      "\tspeed: 0.0656s/iter; left time: 1449.2473s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852547\n",
      "\tspeed: 0.0327s/iter; left time: 719.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0902369 Vali Loss: 0.0833138 Test Loss: 0.0876840\n",
      "Validation loss decreased (0.097311 --> 0.083314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0796998\n",
      "\tspeed: 0.0637s/iter; left time: 1392.6980s\n",
      "\titers: 200, epoch: 3 | loss: 0.0754760\n",
      "\tspeed: 0.0330s/iter; left time: 718.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0821896 Vali Loss: 0.0847121 Test Loss: 0.0885704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0757821\n",
      "\tspeed: 0.0636s/iter; left time: 1375.0338s\n",
      "\titers: 200, epoch: 4 | loss: 0.0727580\n",
      "\tspeed: 0.0330s/iter; left time: 710.4566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0758136 Vali Loss: 0.0868573 Test Loss: 0.0913092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0687613\n",
      "\tspeed: 0.0616s/iter; left time: 1319.5185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685968\n",
      "\tspeed: 0.0328s/iter; left time: 697.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0689663 Vali Loss: 0.0893411 Test Loss: 0.0935924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651921\n",
      "\tspeed: 0.0615s/iter; left time: 1301.9021s\n",
      "\titers: 200, epoch: 6 | loss: 0.0632846\n",
      "\tspeed: 0.0329s/iter; left time: 692.8142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0631031 Vali Loss: 0.0897252 Test Loss: 0.0937936\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562681\n",
      "\tspeed: 0.0623s/iter; left time: 1306.4249s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584004\n",
      "\tspeed: 0.0328s/iter; left time: 683.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0586738 Vali Loss: 0.0891313 Test Loss: 0.0927569\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0594843\n",
      "\tspeed: 0.0632s/iter; left time: 1310.5403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0533358\n",
      "\tspeed: 0.0333s/iter; left time: 686.7450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0551203 Vali Loss: 0.0891207 Test Loss: 0.0943138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0506663\n",
      "\tspeed: 0.0621s/iter; left time: 1274.4806s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516839\n",
      "\tspeed: 0.0329s/iter; left time: 671.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0524840 Vali Loss: 0.0899251 Test Loss: 0.0945375\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0502532\n",
      "\tspeed: 0.0617s/iter; left time: 1252.1771s\n",
      "\titers: 200, epoch: 10 | loss: 0.0516907\n",
      "\tspeed: 0.0329s/iter; left time: 663.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0503486 Vali Loss: 0.0897381 Test Loss: 0.0947718\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476377\n",
      "\tspeed: 0.0618s/iter; left time: 1240.4583s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482675\n",
      "\tspeed: 0.0328s/iter; left time: 655.2572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0485826 Vali Loss: 0.0897575 Test Loss: 0.0946977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0458898\n",
      "\tspeed: 0.0616s/iter; left time: 1222.0938s\n",
      "\titers: 200, epoch: 12 | loss: 0.0471257\n",
      "\tspeed: 0.0333s/iter; left time: 657.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0471242 Vali Loss: 0.0901863 Test Loss: 0.0944600\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02016986720263958, rmse:0.14202065765857697, mae:0.08768393099308014, rse:0.5369954109191895\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1255154\n",
      "\tspeed: 0.0352s/iter; left time: 784.3829s\n",
      "\titers: 200, epoch: 1 | loss: 0.1049256\n",
      "\tspeed: 0.0328s/iter; left time: 727.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.1278330 Vali Loss: 0.0975431 Test Loss: 0.1014083\n",
      "Validation loss decreased (inf --> 0.097543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0899003\n",
      "\tspeed: 0.0656s/iter; left time: 1448.8317s\n",
      "\titers: 200, epoch: 2 | loss: 0.0846541\n",
      "\tspeed: 0.0330s/iter; left time: 726.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0901421 Vali Loss: 0.0825803 Test Loss: 0.0863189\n",
      "Validation loss decreased (0.097543 --> 0.082580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845014\n",
      "\tspeed: 0.0644s/iter; left time: 1408.1594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811608\n",
      "\tspeed: 0.0330s/iter; left time: 717.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0826669 Vali Loss: 0.0844429 Test Loss: 0.0884733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0779427\n",
      "\tspeed: 0.0631s/iter; left time: 1364.3807s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703318\n",
      "\tspeed: 0.0333s/iter; left time: 716.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0767097 Vali Loss: 0.0885497 Test Loss: 0.0904577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0702917\n",
      "\tspeed: 0.0637s/iter; left time: 1364.4786s\n",
      "\titers: 200, epoch: 5 | loss: 0.0693786\n",
      "\tspeed: 0.0327s/iter; left time: 696.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0701658 Vali Loss: 0.0881929 Test Loss: 0.0910864\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0627403\n",
      "\tspeed: 0.0625s/iter; left time: 1323.8462s\n",
      "\titers: 200, epoch: 6 | loss: 0.0628337\n",
      "\tspeed: 0.0328s/iter; left time: 692.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0642376 Vali Loss: 0.0915709 Test Loss: 0.0943422\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0589409\n",
      "\tspeed: 0.0625s/iter; left time: 1310.2335s\n",
      "\titers: 200, epoch: 7 | loss: 0.0613292\n",
      "\tspeed: 0.0327s/iter; left time: 681.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0597377 Vali Loss: 0.0914882 Test Loss: 0.0947146\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0582752\n",
      "\tspeed: 0.0619s/iter; left time: 1282.9689s\n",
      "\titers: 200, epoch: 8 | loss: 0.0556407\n",
      "\tspeed: 0.0327s/iter; left time: 673.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0564200 Vali Loss: 0.0915248 Test Loss: 0.0945174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0531261\n",
      "\tspeed: 0.0613s/iter; left time: 1257.0216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0556055\n",
      "\tspeed: 0.0328s/iter; left time: 669.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0534906 Vali Loss: 0.0919397 Test Loss: 0.0957770\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536001\n",
      "\tspeed: 0.0626s/iter; left time: 1268.8658s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489793\n",
      "\tspeed: 0.0330s/iter; left time: 665.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0513367 Vali Loss: 0.0924511 Test Loss: 0.0954170\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0486944\n",
      "\tspeed: 0.0618s/iter; left time: 1240.4935s\n",
      "\titers: 200, epoch: 11 | loss: 0.0491078\n",
      "\tspeed: 0.0328s/iter; left time: 654.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0493445 Vali Loss: 0.0925241 Test Loss: 0.0958952\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0473603\n",
      "\tspeed: 0.0622s/iter; left time: 1233.9804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0451833\n",
      "\tspeed: 0.0331s/iter; left time: 653.1351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0478553 Vali Loss: 0.0918346 Test Loss: 0.0957100\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01941889151930809, rmse:0.13935168087482452, mae:0.08631888031959534, rse:0.5269036889076233\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:02.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1198918\n",
      "\tspeed: 0.0602s/iter; left time: 1335.4515s\n",
      "\titers: 200, epoch: 1 | loss: 0.1119531\n",
      "\tspeed: 0.0335s/iter; left time: 739.9478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1296531 Vali Loss: 0.0998805 Test Loss: 0.1030402\n",
      "Validation loss decreased (inf --> 0.099880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907918\n",
      "\tspeed: 0.0724s/iter; left time: 1591.1121s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905884\n",
      "\tspeed: 0.0334s/iter; left time: 731.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0942718 Vali Loss: 0.0888983 Test Loss: 0.0913404\n",
      "Validation loss decreased (0.099880 --> 0.088898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0858455\n",
      "\tspeed: 0.0693s/iter; left time: 1506.8082s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790434\n",
      "\tspeed: 0.0334s/iter; left time: 724.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0845714 Vali Loss: 0.0910256 Test Loss: 0.0931149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0759794\n",
      "\tspeed: 0.0621s/iter; left time: 1336.2590s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741858\n",
      "\tspeed: 0.0336s/iter; left time: 720.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 223 | Train Loss: 0.0770820 Vali Loss: 0.0927773 Test Loss: 0.0950808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691015\n",
      "\tspeed: 0.0650s/iter; left time: 1386.1147s\n",
      "\titers: 200, epoch: 5 | loss: 0.0647586\n",
      "\tspeed: 0.0348s/iter; left time: 737.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0700328 Vali Loss: 0.0943000 Test Loss: 0.0950744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640472\n",
      "\tspeed: 0.0640s/iter; left time: 1350.1069s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612911\n",
      "\tspeed: 0.0336s/iter; left time: 704.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0645894 Vali Loss: 0.0963655 Test Loss: 0.0991898\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0610605\n",
      "\tspeed: 0.0640s/iter; left time: 1335.5354s\n",
      "\titers: 200, epoch: 7 | loss: 0.0579671\n",
      "\tspeed: 0.0335s/iter; left time: 696.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0603602 Vali Loss: 0.0950874 Test Loss: 0.0973007\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567950\n",
      "\tspeed: 0.0644s/iter; left time: 1330.2366s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570818\n",
      "\tspeed: 0.0336s/iter; left time: 689.7922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0570988 Vali Loss: 0.0949548 Test Loss: 0.0956630\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546112\n",
      "\tspeed: 0.0634s/iter; left time: 1294.7920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0524339\n",
      "\tspeed: 0.0335s/iter; left time: 680.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0544873 Vali Loss: 0.0957294 Test Loss: 0.0976520\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0508264\n",
      "\tspeed: 0.0644s/iter; left time: 1300.9257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543244\n",
      "\tspeed: 0.0338s/iter; left time: 678.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0524037 Vali Loss: 0.0946522 Test Loss: 0.0974682\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0509232\n",
      "\tspeed: 0.0635s/iter; left time: 1268.2480s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519942\n",
      "\tspeed: 0.0335s/iter; left time: 666.4533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0505157 Vali Loss: 0.0947079 Test Loss: 0.0967350\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0484439\n",
      "\tspeed: 0.0637s/iter; left time: 1258.3883s\n",
      "\titers: 200, epoch: 12 | loss: 0.0475559\n",
      "\tspeed: 0.0336s/iter; left time: 659.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0490816 Vali Loss: 0.0940101 Test Loss: 0.0961627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021067097783088684, rmse:0.14514508843421936, mae:0.09134043753147125, rse:0.5493192076683044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1244710\n",
      "\tspeed: 0.0360s/iter; left time: 799.8840s\n",
      "\titers: 200, epoch: 1 | loss: 0.1170316\n",
      "\tspeed: 0.0336s/iter; left time: 743.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.1287358 Vali Loss: 0.0999947 Test Loss: 0.1031152\n",
      "Validation loss decreased (inf --> 0.099995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0887262\n",
      "\tspeed: 0.0713s/iter; left time: 1566.0629s\n",
      "\titers: 200, epoch: 2 | loss: 0.0913494\n",
      "\tspeed: 0.0341s/iter; left time: 746.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0940741 Vali Loss: 0.0886703 Test Loss: 0.0908009\n",
      "Validation loss decreased (0.099995 --> 0.088670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0876927\n",
      "\tspeed: 0.0767s/iter; left time: 1668.1872s\n",
      "\titers: 200, epoch: 3 | loss: 0.0828235\n",
      "\tspeed: 0.0335s/iter; left time: 726.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0851875 Vali Loss: 0.0917103 Test Loss: 0.0935745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786623\n",
      "\tspeed: 0.0643s/iter; left time: 1384.5670s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741892\n",
      "\tspeed: 0.0336s/iter; left time: 719.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0777442 Vali Loss: 0.0918386 Test Loss: 0.0967076\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0694645\n",
      "\tspeed: 0.0639s/iter; left time: 1361.7622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682284\n",
      "\tspeed: 0.0335s/iter; left time: 710.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0704027 Vali Loss: 0.0935241 Test Loss: 0.0960906\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646602\n",
      "\tspeed: 0.0650s/iter; left time: 1371.0488s\n",
      "\titers: 200, epoch: 6 | loss: 0.0633540\n",
      "\tspeed: 0.0336s/iter; left time: 704.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0650664 Vali Loss: 0.0929157 Test Loss: 0.0990988\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606141\n",
      "\tspeed: 0.0643s/iter; left time: 1341.6915s\n",
      "\titers: 200, epoch: 7 | loss: 0.0587380\n",
      "\tspeed: 0.0336s/iter; left time: 697.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0609457 Vali Loss: 0.0932918 Test Loss: 0.0978042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0581316\n",
      "\tspeed: 0.0635s/iter; left time: 1311.4885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562303\n",
      "\tspeed: 0.0335s/iter; left time: 688.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0575464 Vali Loss: 0.0935499 Test Loss: 0.0977738\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535778\n",
      "\tspeed: 0.0644s/iter; left time: 1314.3718s\n",
      "\titers: 200, epoch: 9 | loss: 0.0549186\n",
      "\tspeed: 0.0337s/iter; left time: 685.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0548766 Vali Loss: 0.0944758 Test Loss: 0.0985249\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0527458\n",
      "\tspeed: 0.0639s/iter; left time: 1289.7448s\n",
      "\titers: 200, epoch: 10 | loss: 0.0528382\n",
      "\tspeed: 0.0343s/iter; left time: 689.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 223 | Train Loss: 0.0526781 Vali Loss: 0.0944073 Test Loss: 0.0979464\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0520308\n",
      "\tspeed: 0.0647s/iter; left time: 1292.4631s\n",
      "\titers: 200, epoch: 11 | loss: 0.0492344\n",
      "\tspeed: 0.0336s/iter; left time: 667.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0509229 Vali Loss: 0.0946541 Test Loss: 0.0983658\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0504324\n",
      "\tspeed: 0.0635s/iter; left time: 1254.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474441\n",
      "\tspeed: 0.0335s/iter; left time: 657.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0494031 Vali Loss: 0.0943606 Test Loss: 0.0970964\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020650984719395638, rmse:0.14370450377464294, mae:0.0908009260892868, rse:0.5438671112060547\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:11.04s\n",
      "Intermediate time for IT: 00h:13m:36.74s\n",
      "Total time: 02h:44m:25.33s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0264  0.1626  0.1055\n",
       "        96        0.0418  0.2044  0.1408\n",
       "        168       0.0430  0.2073  0.1429\n",
       "ES      24        0.0115  0.1071  0.0677\n",
       "        96        0.0216  0.1469  0.0970\n",
       "        168       0.0236  0.1538  0.1034\n",
       "FR      24        0.0119  0.1091  0.0624\n",
       "        96        0.0208  0.1442  0.0861\n",
       "        168       0.0229  0.1513  0.0918\n",
       "GB      24        0.0289  0.1699  0.1118\n",
       "        96        0.0446  0.2113  0.1466\n",
       "        168       0.0472  0.2172  0.1520\n",
       "IT      24        0.0113  0.1064  0.0634\n",
       "        96        0.0198  0.1407  0.0870\n",
       "        168       0.0209  0.1444  0.0911"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD, PROBABLY NOT REALLY CHANNEL MIXING (APPROACH 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1288347\n",
      "\tspeed: 0.0621s/iter; left time: 271.8497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153558\n",
      "\tspeed: 0.0434s/iter; left time: 185.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 224 | Train Loss: 0.1386400 Vali Loss: 0.1264737 Test Loss: 0.1306201\n",
      "Validation loss decreased (inf --> 0.126474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0790193\n",
      "\tspeed: 0.0814s/iter; left time: 338.4901s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790826\n",
      "\tspeed: 0.0434s/iter; left time: 176.1489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0848311 Vali Loss: 0.0908782 Test Loss: 0.0928910\n",
      "Validation loss decreased (0.126474 --> 0.090878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733861\n",
      "\tspeed: 0.0806s/iter; left time: 317.1256s\n",
      "\titers: 200, epoch: 3 | loss: 0.0763236\n",
      "\tspeed: 0.0433s/iter; left time: 166.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0745720 Vali Loss: 0.0889853 Test Loss: 0.0914121\n",
      "Validation loss decreased (0.090878 --> 0.088985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0697485\n",
      "\tspeed: 0.0788s/iter; left time: 292.3043s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646489\n",
      "\tspeed: 0.0434s/iter; left time: 156.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0712106 Vali Loss: 0.0887275 Test Loss: 0.0919944\n",
      "Validation loss decreased (0.088985 --> 0.088728).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0703026\n",
      "\tspeed: 0.0788s/iter; left time: 274.5695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0676346\n",
      "\tspeed: 0.0435s/iter; left time: 147.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0672696 Vali Loss: 0.0913164 Test Loss: 0.0948952\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0655603\n",
      "\tspeed: 0.0766s/iter; left time: 249.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588298\n",
      "\tspeed: 0.0435s/iter; left time: 137.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0624329 Vali Loss: 0.0931622 Test Loss: 0.0983253\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566716\n",
      "\tspeed: 0.0771s/iter; left time: 234.2919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535484\n",
      "\tspeed: 0.0436s/iter; left time: 127.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0572146 Vali Loss: 0.0963221 Test Loss: 0.1005249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0505644\n",
      "\tspeed: 0.0771s/iter; left time: 216.7448s\n",
      "\titers: 200, epoch: 8 | loss: 0.0515958\n",
      "\tspeed: 0.0436s/iter; left time: 118.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0530652 Vali Loss: 0.0984603 Test Loss: 0.1033134\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0509193\n",
      "\tspeed: 0.0771s/iter; left time: 199.6553s\n",
      "\titers: 200, epoch: 9 | loss: 0.0492906\n",
      "\tspeed: 0.0436s/iter; left time: 108.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0496132 Vali Loss: 0.0986490 Test Loss: 0.1038890\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021372228860855103, rmse:0.14619243144989014, mae:0.09199438244104385, rse:0.5159333348274231\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1415286\n",
      "\tspeed: 0.0455s/iter; left time: 199.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177186\n",
      "\tspeed: 0.0435s/iter; left time: 186.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1398765 Vali Loss: 0.1292176 Test Loss: 0.1340619\n",
      "Validation loss decreased (inf --> 0.129218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0836441\n",
      "\tspeed: 0.0835s/iter; left time: 347.2026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0809262\n",
      "\tspeed: 0.0435s/iter; left time: 176.6243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.46s\n",
      "Steps: 224 | Train Loss: 0.0844209 Vali Loss: 0.0905276 Test Loss: 0.0925714\n",
      "Validation loss decreased (0.129218 --> 0.090528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768631\n",
      "\tspeed: 0.0790s/iter; left time: 310.6964s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733880\n",
      "\tspeed: 0.0436s/iter; left time: 167.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0744031 Vali Loss: 0.0889989 Test Loss: 0.0919095\n",
      "Validation loss decreased (0.090528 --> 0.088999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692604\n",
      "\tspeed: 0.0788s/iter; left time: 292.2920s\n",
      "\titers: 200, epoch: 4 | loss: 0.0709451\n",
      "\tspeed: 0.0436s/iter; left time: 157.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0706481 Vali Loss: 0.0892855 Test Loss: 0.0918443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620473\n",
      "\tspeed: 0.0770s/iter; left time: 268.2856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0703997\n",
      "\tspeed: 0.0436s/iter; left time: 147.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0662776 Vali Loss: 0.0921095 Test Loss: 0.0963930\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0618102\n",
      "\tspeed: 0.0768s/iter; left time: 250.5855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612112\n",
      "\tspeed: 0.0435s/iter; left time: 137.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0609258 Vali Loss: 0.0947462 Test Loss: 0.0991559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528752\n",
      "\tspeed: 0.0777s/iter; left time: 236.0680s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571331\n",
      "\tspeed: 0.0435s/iter; left time: 127.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0557489 Vali Loss: 0.0972916 Test Loss: 0.1027085\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0492335\n",
      "\tspeed: 0.0782s/iter; left time: 219.8889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0513884\n",
      "\tspeed: 0.0436s/iter; left time: 118.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0512173 Vali Loss: 0.0977964 Test Loss: 0.1046530\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02161523513495922, rmse:0.14702120423316956, mae:0.0919095128774643, rse:0.5188581943511963\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:37.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431927\n",
      "\tspeed: 0.0619s/iter; left time: 271.3939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1289140\n",
      "\tspeed: 0.0437s/iter; left time: 186.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 224 | Train Loss: 0.1487396 Vali Loss: 0.1405490 Test Loss: 0.1488965\n",
      "Validation loss decreased (inf --> 0.140549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1077801\n",
      "\tspeed: 0.0797s/iter; left time: 331.2474s\n",
      "\titers: 200, epoch: 2 | loss: 0.0963636\n",
      "\tspeed: 0.0437s/iter; left time: 177.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1068755 Vali Loss: 0.1224208 Test Loss: 0.1325869\n",
      "Validation loss decreased (0.140549 --> 0.122421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926780\n",
      "\tspeed: 0.0803s/iter; left time: 315.7715s\n",
      "\titers: 200, epoch: 3 | loss: 0.0843681\n",
      "\tspeed: 0.0437s/iter; left time: 167.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0893946 Vali Loss: 0.1247966 Test Loss: 0.1377297\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736906\n",
      "\tspeed: 0.0782s/iter; left time: 289.9745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699906\n",
      "\tspeed: 0.0438s/iter; left time: 157.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0746758 Vali Loss: 0.1276431 Test Loss: 0.1399731\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639692\n",
      "\tspeed: 0.0775s/iter; left time: 270.0486s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590412\n",
      "\tspeed: 0.0438s/iter; left time: 148.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0646408 Vali Loss: 0.1299467 Test Loss: 0.1427322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569997\n",
      "\tspeed: 0.0782s/iter; left time: 255.0126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539131\n",
      "\tspeed: 0.0439s/iter; left time: 138.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0580533 Vali Loss: 0.1302402 Test Loss: 0.1435865\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0529144\n",
      "\tspeed: 0.0785s/iter; left time: 238.5008s\n",
      "\titers: 200, epoch: 7 | loss: 0.0503044\n",
      "\tspeed: 0.0440s/iter; left time: 129.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0534348 Vali Loss: 0.1301299 Test Loss: 0.1424773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04040202498435974, rmse:0.2010025531053543, mae:0.13258694112300873, rse:0.7117906808853149\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446730\n",
      "\tspeed: 0.0495s/iter; left time: 216.8344s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379150\n",
      "\tspeed: 0.0437s/iter; left time: 187.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 224 | Train Loss: 0.1482707 Vali Loss: 0.1405652 Test Loss: 0.1491016\n",
      "Validation loss decreased (inf --> 0.140565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1060695\n",
      "\tspeed: 0.0804s/iter; left time: 334.4022s\n",
      "\titers: 200, epoch: 2 | loss: 0.0933992\n",
      "\tspeed: 0.0439s/iter; left time: 178.1298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.1067035 Vali Loss: 0.1217589 Test Loss: 0.1363821\n",
      "Validation loss decreased (0.140565 --> 0.121759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0944410\n",
      "\tspeed: 0.0800s/iter; left time: 314.5728s\n",
      "\titers: 200, epoch: 3 | loss: 0.0786479\n",
      "\tspeed: 0.0437s/iter; left time: 167.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0873720 Vali Loss: 0.1261233 Test Loss: 0.1370733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0743208\n",
      "\tspeed: 0.0786s/iter; left time: 291.3874s\n",
      "\titers: 200, epoch: 4 | loss: 0.0682476\n",
      "\tspeed: 0.0438s/iter; left time: 157.9232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0722580 Vali Loss: 0.1309307 Test Loss: 0.1429823\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630023\n",
      "\tspeed: 0.0780s/iter; left time: 271.8135s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619667\n",
      "\tspeed: 0.0437s/iter; left time: 147.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0632695 Vali Loss: 0.1294827 Test Loss: 0.1430689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583094\n",
      "\tspeed: 0.0784s/iter; left time: 255.6968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569461\n",
      "\tspeed: 0.0437s/iter; left time: 138.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0574156 Vali Loss: 0.1289199 Test Loss: 0.1438109\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0540976\n",
      "\tspeed: 0.0786s/iter; left time: 238.7198s\n",
      "\titers: 200, epoch: 7 | loss: 0.0510037\n",
      "\tspeed: 0.0437s/iter; left time: 128.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0531317 Vali Loss: 0.1288909 Test Loss: 0.1443605\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043257858604192734, rmse:0.20798523724079132, mae:0.1363820880651474, rse:0.7365177869796753\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:02.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1518797\n",
      "\tspeed: 0.0609s/iter; left time: 265.7029s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341218\n",
      "\tspeed: 0.0438s/iter; left time: 186.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1515815 Vali Loss: 0.1431780 Test Loss: 0.1525715\n",
      "Validation loss decreased (inf --> 0.143178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1105171\n",
      "\tspeed: 0.0810s/iter; left time: 335.2319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020385\n",
      "\tspeed: 0.0439s/iter; left time: 177.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.1109439 Vali Loss: 0.1256638 Test Loss: 0.1443070\n",
      "Validation loss decreased (0.143178 --> 0.125664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909588\n",
      "\tspeed: 0.0809s/iter; left time: 316.8799s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823636\n",
      "\tspeed: 0.0439s/iter; left time: 167.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0895617 Vali Loss: 0.1273583 Test Loss: 0.1470855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744034\n",
      "\tspeed: 0.0785s/iter; left time: 289.7581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0707802\n",
      "\tspeed: 0.0440s/iter; left time: 157.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0744996 Vali Loss: 0.1302383 Test Loss: 0.1442910\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646706\n",
      "\tspeed: 0.0779s/iter; left time: 270.2656s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608316\n",
      "\tspeed: 0.0441s/iter; left time: 148.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0651669 Vali Loss: 0.1310407 Test Loss: 0.1438465\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574107\n",
      "\tspeed: 0.0790s/iter; left time: 256.3127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584476\n",
      "\tspeed: 0.0440s/iter; left time: 138.2686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0592617 Vali Loss: 0.1324312 Test Loss: 0.1442218\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0558157\n",
      "\tspeed: 0.0785s/iter; left time: 237.2210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557166\n",
      "\tspeed: 0.0440s/iter; left time: 128.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.0549841 Vali Loss: 0.1323213 Test Loss: 0.1434522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04741961508989334, rmse:0.21776045858860016, mae:0.14430703222751617, rse:0.7713250517845154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1513522\n",
      "\tspeed: 0.0464s/iter; left time: 202.2887s\n",
      "\titers: 200, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0439s/iter; left time: 187.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.1521855 Vali Loss: 0.1438601 Test Loss: 0.1531233\n",
      "Validation loss decreased (inf --> 0.143860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1064229\n",
      "\tspeed: 0.0815s/iter; left time: 337.4412s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020931\n",
      "\tspeed: 0.0440s/iter; left time: 177.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1112131 Vali Loss: 0.1247842 Test Loss: 0.1412956\n",
      "Validation loss decreased (0.143860 --> 0.124784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0937691\n",
      "\tspeed: 0.0820s/iter; left time: 321.1670s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833023\n",
      "\tspeed: 0.0439s/iter; left time: 167.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0891496 Vali Loss: 0.1302273 Test Loss: 0.1467150\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755298\n",
      "\tspeed: 0.0787s/iter; left time: 290.5388s\n",
      "\titers: 200, epoch: 4 | loss: 0.0678074\n",
      "\tspeed: 0.0440s/iter; left time: 158.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0731834 Vali Loss: 0.1329896 Test Loss: 0.1487310\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0666101\n",
      "\tspeed: 0.0788s/iter; left time: 273.4192s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610430\n",
      "\tspeed: 0.0440s/iter; left time: 148.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0643469 Vali Loss: 0.1333733 Test Loss: 0.1499041\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0585870\n",
      "\tspeed: 0.0789s/iter; left time: 256.0959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568665\n",
      "\tspeed: 0.0440s/iter; left time: 138.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0583537 Vali Loss: 0.1314956 Test Loss: 0.1464267\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0525444\n",
      "\tspeed: 0.0790s/iter; left time: 238.9590s\n",
      "\titers: 200, epoch: 7 | loss: 0.0518316\n",
      "\tspeed: 0.0439s/iter; left time: 128.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0540509 Vali Loss: 0.1317015 Test Loss: 0.1481518\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486357793211937, rmse:0.21181024610996246, mae:0.14129573106765747, rse:0.7502489686012268\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:04.36s\n",
      "Intermediate time for DE: 00h:09m:44.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1249031\n",
      "\tspeed: 0.0601s/iter; left time: 263.2734s\n",
      "\titers: 200, epoch: 1 | loss: 0.1127680\n",
      "\tspeed: 0.0432s/iter; left time: 184.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.1274041 Vali Loss: 0.1188559 Test Loss: 0.1365499\n",
      "Validation loss decreased (inf --> 0.118856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0752068\n",
      "\tspeed: 0.0804s/iter; left time: 334.0770s\n",
      "\titers: 200, epoch: 2 | loss: 0.0756959\n",
      "\tspeed: 0.0433s/iter; left time: 175.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0829447 Vali Loss: 0.0909307 Test Loss: 0.1030746\n",
      "Validation loss decreased (0.118856 --> 0.090931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754961\n",
      "\tspeed: 0.0784s/iter; left time: 308.3153s\n",
      "\titers: 200, epoch: 3 | loss: 0.0801942\n",
      "\tspeed: 0.0433s/iter; left time: 166.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0758008 Vali Loss: 0.0894891 Test Loss: 0.1017765\n",
      "Validation loss decreased (0.090931 --> 0.089489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0749308\n",
      "\tspeed: 0.0787s/iter; left time: 291.7423s\n",
      "\titers: 200, epoch: 4 | loss: 0.0664703\n",
      "\tspeed: 0.0433s/iter; left time: 156.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0732703 Vali Loss: 0.0913262 Test Loss: 0.1023002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723235\n",
      "\tspeed: 0.0758s/iter; left time: 264.2858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0701183\n",
      "\tspeed: 0.0433s/iter; left time: 146.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0703901 Vali Loss: 0.0899382 Test Loss: 0.1038470\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0694546\n",
      "\tspeed: 0.0756s/iter; left time: 246.6922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659585\n",
      "\tspeed: 0.0433s/iter; left time: 136.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0664127 Vali Loss: 0.0935771 Test Loss: 0.1056621\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577669\n",
      "\tspeed: 0.0760s/iter; left time: 230.8019s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580327\n",
      "\tspeed: 0.0434s/iter; left time: 127.3561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0617652 Vali Loss: 0.0964528 Test Loss: 0.1120393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580244\n",
      "\tspeed: 0.0781s/iter; left time: 219.7505s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549745\n",
      "\tspeed: 0.0434s/iter; left time: 117.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0575566 Vali Loss: 0.0996388 Test Loss: 0.1158492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025332890450954437, rmse:0.15916308760643005, mae:0.10177655518054962, rse:0.5490675568580627\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1193750\n",
      "\tspeed: 0.0450s/iter; left time: 197.2874s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060155\n",
      "\tspeed: 0.0434s/iter; left time: 185.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.1250374 Vali Loss: 0.1174057 Test Loss: 0.1348697\n",
      "Validation loss decreased (inf --> 0.117406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0799368\n",
      "\tspeed: 0.0782s/iter; left time: 325.0579s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795878\n",
      "\tspeed: 0.0434s/iter; left time: 176.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0825805 Vali Loss: 0.0911475 Test Loss: 0.1029994\n",
      "Validation loss decreased (0.117406 --> 0.091147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0756929\n",
      "\tspeed: 0.0784s/iter; left time: 308.3488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774784\n",
      "\tspeed: 0.0434s/iter; left time: 166.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0757685 Vali Loss: 0.0891861 Test Loss: 0.1012558\n",
      "Validation loss decreased (0.091147 --> 0.089186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0707852\n",
      "\tspeed: 0.0825s/iter; left time: 306.1245s\n",
      "\titers: 200, epoch: 4 | loss: 0.0715328\n",
      "\tspeed: 0.0434s/iter; left time: 156.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0732520 Vali Loss: 0.0898914 Test Loss: 0.1021442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689220\n",
      "\tspeed: 0.0771s/iter; left time: 268.8159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0702394\n",
      "\tspeed: 0.0435s/iter; left time: 147.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0703283 Vali Loss: 0.0914296 Test Loss: 0.1033106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0662516\n",
      "\tspeed: 0.0764s/iter; left time: 249.0542s\n",
      "\titers: 200, epoch: 6 | loss: 0.0679668\n",
      "\tspeed: 0.0434s/iter; left time: 137.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0663290 Vali Loss: 0.0943815 Test Loss: 0.1062462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0596283\n",
      "\tspeed: 0.0761s/iter; left time: 231.1431s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606526\n",
      "\tspeed: 0.0434s/iter; left time: 127.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0616254 Vali Loss: 0.0968927 Test Loss: 0.1100579\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565274\n",
      "\tspeed: 0.0763s/iter; left time: 214.5441s\n",
      "\titers: 200, epoch: 8 | loss: 0.0578602\n",
      "\tspeed: 0.0434s/iter; left time: 117.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0571208 Vali Loss: 0.1001299 Test Loss: 0.1126765\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02496434934437275, rmse:0.158001109957695, mae:0.10125575959682465, rse:0.5450590252876282\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:23.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1300309\n",
      "\tspeed: 0.0619s/iter; left time: 271.1114s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175259\n",
      "\tspeed: 0.0437s/iter; left time: 187.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.1356121 Vali Loss: 0.1320696 Test Loss: 0.1547136\n",
      "Validation loss decreased (inf --> 0.132070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1107192\n",
      "\tspeed: 0.0793s/iter; left time: 329.5753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0974107\n",
      "\tspeed: 0.0437s/iter; left time: 177.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1059472 Vali Loss: 0.1207289 Test Loss: 0.1423227\n",
      "Validation loss decreased (0.132070 --> 0.120729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921785\n",
      "\tspeed: 0.0789s/iter; left time: 310.4888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906572\n",
      "\tspeed: 0.0436s/iter; left time: 167.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0932772 Vali Loss: 0.1250454 Test Loss: 0.1396944\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0780643\n",
      "\tspeed: 0.0772s/iter; left time: 286.1969s\n",
      "\titers: 200, epoch: 4 | loss: 0.0736055\n",
      "\tspeed: 0.0436s/iter; left time: 157.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0790285 Vali Loss: 0.1302246 Test Loss: 0.1424275\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0678155\n",
      "\tspeed: 0.0771s/iter; left time: 268.8162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652552\n",
      "\tspeed: 0.0435s/iter; left time: 147.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0684898 Vali Loss: 0.1330113 Test Loss: 0.1475625\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595127\n",
      "\tspeed: 0.0765s/iter; left time: 249.4589s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599183\n",
      "\tspeed: 0.0436s/iter; left time: 137.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0620094 Vali Loss: 0.1328093 Test Loss: 0.1456130\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0760s/iter; left time: 230.7722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578840\n",
      "\tspeed: 0.0436s/iter; left time: 128.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0574334 Vali Loss: 0.1333681 Test Loss: 0.1477004\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04291878640651703, rmse:0.20716850459575653, mae:0.14232265949249268, rse:0.7164175510406494\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1369909\n",
      "\tspeed: 0.0452s/iter; left time: 198.1251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1235660\n",
      "\tspeed: 0.0436s/iter; left time: 186.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.1355126 Vali Loss: 0.1321635 Test Loss: 0.1548172\n",
      "Validation loss decreased (inf --> 0.132164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024315\n",
      "\tspeed: 0.0822s/iter; left time: 341.8837s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971463\n",
      "\tspeed: 0.0436s/iter; left time: 176.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.1058134 Vali Loss: 0.1206499 Test Loss: 0.1399352\n",
      "Validation loss decreased (0.132164 --> 0.120650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939326\n",
      "\tspeed: 0.0953s/iter; left time: 374.8068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0851375\n",
      "\tspeed: 0.0436s/iter; left time: 166.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0934879 Vali Loss: 0.1276292 Test Loss: 0.1426655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788433\n",
      "\tspeed: 0.0770s/iter; left time: 285.4099s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714974\n",
      "\tspeed: 0.0435s/iter; left time: 157.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0783464 Vali Loss: 0.1301064 Test Loss: 0.1484889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0670597\n",
      "\tspeed: 0.0768s/iter; left time: 267.4897s\n",
      "\titers: 200, epoch: 5 | loss: 0.0632937\n",
      "\tspeed: 0.1556s/iter; left time: 526.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.12s\n",
      "Steps: 224 | Train Loss: 0.0674435 Vali Loss: 0.1301742 Test Loss: 0.1560793\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597854\n",
      "\tspeed: 0.0763s/iter; left time: 248.9769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592995\n",
      "\tspeed: 0.0435s/iter; left time: 137.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0609915 Vali Loss: 0.1312574 Test Loss: 0.1548149\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571895\n",
      "\tspeed: 0.0767s/iter; left time: 233.0420s\n",
      "\titers: 200, epoch: 7 | loss: 0.0534755\n",
      "\tspeed: 0.0437s/iter; left time: 128.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0563500 Vali Loss: 0.1323618 Test Loss: 0.1562927\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042682863771915436, rmse:0.20659831166267395, mae:0.1399351954460144, rse:0.7144457697868347\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:13.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1341277\n",
      "\tspeed: 0.0614s/iter; left time: 267.8026s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240424\n",
      "\tspeed: 0.0436s/iter; left time: 185.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 223 | Train Loss: 0.1377349 Vali Loss: 0.1347460 Test Loss: 0.1585737\n",
      "Validation loss decreased (inf --> 0.134746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1115550\n",
      "\tspeed: 0.0794s/iter; left time: 328.6687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019396\n",
      "\tspeed: 0.0439s/iter; left time: 177.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.1095999 Vali Loss: 0.1251576 Test Loss: 0.1528900\n",
      "Validation loss decreased (0.134746 --> 0.125158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0949040\n",
      "\tspeed: 0.0798s/iter; left time: 312.4155s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896047\n",
      "\tspeed: 0.0439s/iter; left time: 167.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0943391 Vali Loss: 0.1325155 Test Loss: 0.1532334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0794888\n",
      "\tspeed: 0.0785s/iter; left time: 289.9586s\n",
      "\titers: 200, epoch: 4 | loss: 0.0751732\n",
      "\tspeed: 0.0439s/iter; left time: 157.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 223 | Train Loss: 0.0793516 Vali Loss: 0.1352002 Test Loss: 0.1513123\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0718923\n",
      "\tspeed: 0.0780s/iter; left time: 270.5778s\n",
      "\titers: 200, epoch: 5 | loss: 0.0654820\n",
      "\tspeed: 0.0440s/iter; left time: 148.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 223 | Train Loss: 0.0696418 Vali Loss: 0.1345929 Test Loss: 0.1558284\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637268\n",
      "\tspeed: 0.0777s/iter; left time: 252.2374s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619536\n",
      "\tspeed: 0.0440s/iter; left time: 138.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0636521 Vali Loss: 0.1361301 Test Loss: 0.1573202\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584776\n",
      "\tspeed: 0.0777s/iter; left time: 234.7740s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590519\n",
      "\tspeed: 0.0440s/iter; left time: 128.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0592529 Vali Loss: 0.1356159 Test Loss: 0.1559382\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.052469152957201004, rmse:0.22906145453453064, mae:0.15288984775543213, rse:0.7941889762878418\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1340767\n",
      "\tspeed: 0.0507s/iter; left time: 221.1755s\n",
      "\titers: 200, epoch: 1 | loss: 0.1268893\n",
      "\tspeed: 0.0439s/iter; left time: 187.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 223 | Train Loss: 0.1382299 Vali Loss: 0.1351098 Test Loss: 0.1589990\n",
      "Validation loss decreased (inf --> 0.135110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089100\n",
      "\tspeed: 0.0820s/iter; left time: 339.4382s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047608\n",
      "\tspeed: 0.0439s/iter; left time: 177.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1098012 Vali Loss: 0.1272498 Test Loss: 0.1492751\n",
      "Validation loss decreased (0.135110 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0957372\n",
      "\tspeed: 0.0820s/iter; left time: 321.1154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877633\n",
      "\tspeed: 0.0440s/iter; left time: 167.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0951678 Vali Loss: 0.1317861 Test Loss: 0.1500311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815844\n",
      "\tspeed: 0.0793s/iter; left time: 292.7075s\n",
      "\titers: 200, epoch: 4 | loss: 0.0720776\n",
      "\tspeed: 0.0440s/iter; left time: 157.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0793402 Vali Loss: 0.1376163 Test Loss: 0.1564661\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0674153\n",
      "\tspeed: 0.0795s/iter; left time: 275.6132s\n",
      "\titers: 200, epoch: 5 | loss: 0.0677345\n",
      "\tspeed: 0.0440s/iter; left time: 148.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0688048 Vali Loss: 0.1402889 Test Loss: 0.1571947\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602527\n",
      "\tspeed: 0.0797s/iter; left time: 258.7197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598245\n",
      "\tspeed: 0.0441s/iter; left time: 138.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0624292 Vali Loss: 0.1399303 Test Loss: 0.1577230\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568240\n",
      "\tspeed: 0.0793s/iter; left time: 239.7509s\n",
      "\titers: 200, epoch: 7 | loss: 0.0553108\n",
      "\tspeed: 0.0441s/iter; left time: 128.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0579504 Vali Loss: 0.1376240 Test Loss: 0.1562205\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047632455825805664, rmse:0.21824860572814941, mae:0.1492750644683838, rse:0.75669926404953\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:05.15s\n",
      "Intermediate time for GB: 00h:09m:41.67s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1197053\n",
      "\tspeed: 0.0389s/iter; left time: 170.4659s\n",
      "\titers: 200, epoch: 1 | loss: 0.1074361\n",
      "\tspeed: 0.0220s/iter; left time: 94.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.1288011 Vali Loss: 0.0958644 Test Loss: 0.1084929\n",
      "Validation loss decreased (inf --> 0.095864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743673\n",
      "\tspeed: 0.0438s/iter; left time: 181.9416s\n",
      "\titers: 200, epoch: 2 | loss: 0.0671951\n",
      "\tspeed: 0.0220s/iter; left time: 89.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732195 Vali Loss: 0.0619111 Test Loss: 0.0689737\n",
      "Validation loss decreased (0.095864 --> 0.061911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636132\n",
      "\tspeed: 0.0443s/iter; left time: 174.4196s\n",
      "\titers: 200, epoch: 3 | loss: 0.0605463\n",
      "\tspeed: 0.0220s/iter; left time: 84.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0620891 Vali Loss: 0.0585566 Test Loss: 0.0651297\n",
      "Validation loss decreased (0.061911 --> 0.058557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0559345\n",
      "\tspeed: 0.0444s/iter; left time: 164.5139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0574044\n",
      "\tspeed: 0.0220s/iter; left time: 79.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0591701 Vali Loss: 0.0568301 Test Loss: 0.0641761\n",
      "Validation loss decreased (0.058557 --> 0.056830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585900\n",
      "\tspeed: 0.0441s/iter; left time: 153.7485s\n",
      "\titers: 200, epoch: 5 | loss: 0.0586798\n",
      "\tspeed: 0.0220s/iter; left time: 74.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0574670 Vali Loss: 0.0560226 Test Loss: 0.0631666\n",
      "Validation loss decreased (0.056830 --> 0.056023).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0571813\n",
      "\tspeed: 0.0442s/iter; left time: 143.9950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582810\n",
      "\tspeed: 0.0220s/iter; left time: 69.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0561205 Vali Loss: 0.0555882 Test Loss: 0.0626708\n",
      "Validation loss decreased (0.056023 --> 0.055588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0552973\n",
      "\tspeed: 0.0447s/iter; left time: 135.8377s\n",
      "\titers: 200, epoch: 7 | loss: 0.0541853\n",
      "\tspeed: 0.0221s/iter; left time: 64.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0551273 Vali Loss: 0.0547986 Test Loss: 0.0620969\n",
      "Validation loss decreased (0.055588 --> 0.054799).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540874\n",
      "\tspeed: 0.0443s/iter; left time: 124.6580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545249\n",
      "\tspeed: 0.0221s/iter; left time: 59.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0540969 Vali Loss: 0.0546852 Test Loss: 0.0622704\n",
      "Validation loss decreased (0.054799 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535808\n",
      "\tspeed: 0.0438s/iter; left time: 113.4066s\n",
      "\titers: 200, epoch: 9 | loss: 0.0510668\n",
      "\tspeed: 0.0220s/iter; left time: 54.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0533764 Vali Loss: 0.0539643 Test Loss: 0.0610771\n",
      "Validation loss decreased (0.054685 --> 0.053964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544953\n",
      "\tspeed: 0.0444s/iter; left time: 105.0310s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548255\n",
      "\tspeed: 0.0220s/iter; left time: 49.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0525270 Vali Loss: 0.0542821 Test Loss: 0.0614841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0498544\n",
      "\tspeed: 0.0431s/iter; left time: 92.3523s\n",
      "\titers: 200, epoch: 11 | loss: 0.0507155\n",
      "\tspeed: 0.0220s/iter; left time: 44.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0518580 Vali Loss: 0.0541489 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0490863\n",
      "\tspeed: 0.0439s/iter; left time: 84.2093s\n",
      "\titers: 200, epoch: 12 | loss: 0.0500919\n",
      "\tspeed: 0.0221s/iter; left time: 40.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0512090 Vali Loss: 0.0545745 Test Loss: 0.0619080\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0565618\n",
      "\tspeed: 0.0441s/iter; left time: 74.6360s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477618\n",
      "\tspeed: 0.0221s/iter; left time: 35.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0505550 Vali Loss: 0.0545160 Test Loss: 0.0619966\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0485411\n",
      "\tspeed: 0.0446s/iter; left time: 65.5215s\n",
      "\titers: 200, epoch: 14 | loss: 0.0494428\n",
      "\tspeed: 0.0221s/iter; left time: 30.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0499811 Vali Loss: 0.0538818 Test Loss: 0.0613545\n",
      "Validation loss decreased (0.053964 --> 0.053882).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486182\n",
      "\tspeed: 0.0441s/iter; left time: 54.9210s\n",
      "\titers: 200, epoch: 15 | loss: 0.0522056\n",
      "\tspeed: 0.0220s/iter; left time: 25.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0493475 Vali Loss: 0.0540712 Test Loss: 0.0617006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517759\n",
      "\tspeed: 0.0428s/iter; left time: 43.6968s\n",
      "\titers: 200, epoch: 16 | loss: 0.0503656\n",
      "\tspeed: 0.0220s/iter; left time: 20.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0488575 Vali Loss: 0.0544644 Test Loss: 0.0622188\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0497399\n",
      "\tspeed: 0.0442s/iter; left time: 35.2565s\n",
      "\titers: 200, epoch: 17 | loss: 0.0500861\n",
      "\tspeed: 0.0221s/iter; left time: 15.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0484129 Vali Loss: 0.0545549 Test Loss: 0.0625807\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0462332\n",
      "\tspeed: 0.0443s/iter; left time: 25.4011s\n",
      "\titers: 200, epoch: 18 | loss: 0.0489886\n",
      "\tspeed: 0.0221s/iter; left time: 10.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0480003 Vali Loss: 0.0545118 Test Loss: 0.0624015\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0488784\n",
      "\tspeed: 0.0429s/iter; left time: 14.9608s\n",
      "\titers: 200, epoch: 19 | loss: 0.0505258\n",
      "\tspeed: 0.0220s/iter; left time: 5.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0475646 Vali Loss: 0.0548550 Test Loss: 0.0625891\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00992313027381897, rmse:0.09961491078138351, mae:0.06135452166199684, rse:0.29315462708473206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1214782\n",
      "\tspeed: 0.0264s/iter; left time: 115.7879s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079467\n",
      "\tspeed: 0.0220s/iter; left time: 94.2519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.1318527 Vali Loss: 0.0977142 Test Loss: 0.1096083\n",
      "Validation loss decreased (inf --> 0.097714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0695145\n",
      "\tspeed: 0.0431s/iter; left time: 179.1939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0641104\n",
      "\tspeed: 0.0221s/iter; left time: 89.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732974 Vali Loss: 0.0619658 Test Loss: 0.0686749\n",
      "Validation loss decreased (0.097714 --> 0.061966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0587519\n",
      "\tspeed: 0.0433s/iter; left time: 170.3049s\n",
      "\titers: 200, epoch: 3 | loss: 0.0618919\n",
      "\tspeed: 0.0220s/iter; left time: 84.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0621301 Vali Loss: 0.0587658 Test Loss: 0.0654708\n",
      "Validation loss decreased (0.061966 --> 0.058766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0594057\n",
      "\tspeed: 0.0432s/iter; left time: 160.3581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0569952\n",
      "\tspeed: 0.0220s/iter; left time: 79.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0592448 Vali Loss: 0.0570653 Test Loss: 0.0638682\n",
      "Validation loss decreased (0.058766 --> 0.057065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0583459\n",
      "\tspeed: 0.0432s/iter; left time: 150.4146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606583\n",
      "\tspeed: 0.0220s/iter; left time: 74.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0573962 Vali Loss: 0.0562197 Test Loss: 0.0633890\n",
      "Validation loss decreased (0.057065 --> 0.056220).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551197\n",
      "\tspeed: 0.0432s/iter; left time: 140.8077s\n",
      "\titers: 200, epoch: 6 | loss: 0.0542481\n",
      "\tspeed: 0.0221s/iter; left time: 69.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0560827 Vali Loss: 0.0551677 Test Loss: 0.0620240\n",
      "Validation loss decreased (0.056220 --> 0.055168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0546338\n",
      "\tspeed: 0.0433s/iter; left time: 131.3840s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557244\n",
      "\tspeed: 0.0220s/iter; left time: 64.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0550370 Vali Loss: 0.0549158 Test Loss: 0.0618460\n",
      "Validation loss decreased (0.055168 --> 0.054916).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0533591\n",
      "\tspeed: 0.0432s/iter; left time: 121.5712s\n",
      "\titers: 200, epoch: 8 | loss: 0.0514893\n",
      "\tspeed: 0.0221s/iter; left time: 59.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0541582 Vali Loss: 0.0542985 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.054916 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0519505\n",
      "\tspeed: 0.0448s/iter; left time: 116.0249s\n",
      "\titers: 200, epoch: 9 | loss: 0.0505060\n",
      "\tspeed: 0.0221s/iter; left time: 54.9988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0532708 Vali Loss: 0.0543194 Test Loss: 0.0613890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0501624\n",
      "\tspeed: 0.0442s/iter; left time: 104.6277s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489627\n",
      "\tspeed: 0.0220s/iter; left time: 49.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0524889 Vali Loss: 0.0542982 Test Loss: 0.0611642\n",
      "Validation loss decreased (0.054299 --> 0.054298).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491599\n",
      "\tspeed: 0.0436s/iter; left time: 93.2524s\n",
      "\titers: 200, epoch: 11 | loss: 0.0504890\n",
      "\tspeed: 0.0220s/iter; left time: 44.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0518310 Vali Loss: 0.0544719 Test Loss: 0.0615248\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0504733\n",
      "\tspeed: 0.0420s/iter; left time: 80.4454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0517810\n",
      "\tspeed: 0.0220s/iter; left time: 39.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0511032 Vali Loss: 0.0544304 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491990\n",
      "\tspeed: 0.0424s/iter; left time: 71.7644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494348\n",
      "\tspeed: 0.0221s/iter; left time: 35.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0505439 Vali Loss: 0.0546408 Test Loss: 0.0613864\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0487825\n",
      "\tspeed: 0.0423s/iter; left time: 62.0977s\n",
      "\titers: 200, epoch: 14 | loss: 0.0486977\n",
      "\tspeed: 0.0220s/iter; left time: 30.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0499626 Vali Loss: 0.0548986 Test Loss: 0.0617785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0492183\n",
      "\tspeed: 0.0421s/iter; left time: 52.4408s\n",
      "\titers: 200, epoch: 15 | loss: 0.0466172\n",
      "\tspeed: 0.0221s/iter; left time: 25.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0494497 Vali Loss: 0.0548974 Test Loss: 0.0618186\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009944847784936428, rmse:0.09972386062145233, mae:0.061164192855358124, rse:0.29347527027130127\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:51.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1327750\n",
      "\tspeed: 0.0392s/iter; left time: 171.5321s\n",
      "\titers: 200, epoch: 1 | loss: 0.1151738\n",
      "\tspeed: 0.0222s/iter; left time: 94.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.1380184 Vali Loss: 0.1075002 Test Loss: 0.1211424\n",
      "Validation loss decreased (inf --> 0.107500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898748\n",
      "\tspeed: 0.0455s/iter; left time: 189.0479s\n",
      "\titers: 200, epoch: 2 | loss: 0.0794849\n",
      "\tspeed: 0.0221s/iter; left time: 89.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0905244 Vali Loss: 0.0823172 Test Loss: 0.0928391\n",
      "Validation loss decreased (0.107500 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804560\n",
      "\tspeed: 0.0464s/iter; left time: 182.6691s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776050\n",
      "\tspeed: 0.0222s/iter; left time: 85.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0808929 Vali Loss: 0.0794616 Test Loss: 0.0906161\n",
      "Validation loss decreased (0.082317 --> 0.079462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755306\n",
      "\tspeed: 0.0460s/iter; left time: 170.4463s\n",
      "\titers: 200, epoch: 4 | loss: 0.0755394\n",
      "\tspeed: 0.0222s/iter; left time: 80.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0769380 Vali Loss: 0.0798931 Test Loss: 0.0919429\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722298\n",
      "\tspeed: 0.0439s/iter; left time: 153.0381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743159\n",
      "\tspeed: 0.0222s/iter; left time: 75.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0732500 Vali Loss: 0.0803050 Test Loss: 0.0922237\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0681314\n",
      "\tspeed: 0.0445s/iter; left time: 145.0482s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714724\n",
      "\tspeed: 0.0222s/iter; left time: 70.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0696609 Vali Loss: 0.0804545 Test Loss: 0.0929369\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662445\n",
      "\tspeed: 0.0446s/iter; left time: 135.3941s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645176\n",
      "\tspeed: 0.0222s/iter; left time: 65.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0819036 Test Loss: 0.0936721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0646453\n",
      "\tspeed: 0.0446s/iter; left time: 125.4376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620963\n",
      "\tspeed: 0.0222s/iter; left time: 60.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0630618 Vali Loss: 0.0830514 Test Loss: 0.0945923\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019271597266197205, rmse:0.13882218301296234, mae:0.09061609208583832, rse:0.4078177809715271\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1359011\n",
      "\tspeed: 0.0239s/iter; left time: 104.8345s\n",
      "\titers: 200, epoch: 1 | loss: 0.1179544\n",
      "\tspeed: 0.0222s/iter; left time: 95.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1384543 Vali Loss: 0.1076759 Test Loss: 0.1211382\n",
      "Validation loss decreased (inf --> 0.107676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0889097\n",
      "\tspeed: 0.0449s/iter; left time: 186.7324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868934\n",
      "\tspeed: 0.0222s/iter; left time: 90.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0903999 Vali Loss: 0.0819206 Test Loss: 0.0922778\n",
      "Validation loss decreased (0.107676 --> 0.081921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819837\n",
      "\tspeed: 0.0461s/iter; left time: 181.4797s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790465\n",
      "\tspeed: 0.0222s/iter; left time: 85.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0806006 Vali Loss: 0.0789759 Test Loss: 0.0910454\n",
      "Validation loss decreased (0.081921 --> 0.078976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0802818\n",
      "\tspeed: 0.0450s/iter; left time: 167.0762s\n",
      "\titers: 200, epoch: 4 | loss: 0.0744955\n",
      "\tspeed: 0.0223s/iter; left time: 80.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0764292 Vali Loss: 0.0790067 Test Loss: 0.0904807\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730120\n",
      "\tspeed: 0.0473s/iter; left time: 164.8390s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737626\n",
      "\tspeed: 0.0223s/iter; left time: 75.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0720678 Vali Loss: 0.0799713 Test Loss: 0.0924472\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0680700\n",
      "\tspeed: 0.0442s/iter; left time: 144.1804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0682947\n",
      "\tspeed: 0.0223s/iter; left time: 70.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0677571 Vali Loss: 0.0811187 Test Loss: 0.0937446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656267\n",
      "\tspeed: 0.0441s/iter; left time: 134.0765s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630400\n",
      "\tspeed: 0.0223s/iter; left time: 65.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0640458 Vali Loss: 0.0827304 Test Loss: 0.0952476\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0612878\n",
      "\tspeed: 0.0439s/iter; left time: 123.4383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0583994\n",
      "\tspeed: 0.0223s/iter; left time: 60.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0610601 Vali Loss: 0.0839228 Test Loss: 0.0960289\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019083218649029732, rmse:0.13814201951026917, mae:0.09104538708925247, rse:0.40581971406936646\n",
      "Intermediate time for ES and pred_len 96: 00h:01m:56.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1385189\n",
      "\tspeed: 0.0407s/iter; left time: 177.6641s\n",
      "\titers: 200, epoch: 1 | loss: 0.1222085\n",
      "\tspeed: 0.0226s/iter; left time: 96.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.1415203 Vali Loss: 0.1107488 Test Loss: 0.1235423\n",
      "Validation loss decreased (inf --> 0.110749).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0943981\n",
      "\tspeed: 0.0462s/iter; left time: 191.3232s\n",
      "\titers: 200, epoch: 2 | loss: 0.0923413\n",
      "\tspeed: 0.0226s/iter; left time: 91.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0948072 Vali Loss: 0.0882457 Test Loss: 0.0986240\n",
      "Validation loss decreased (0.110749 --> 0.088246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0849652\n",
      "\tspeed: 0.0468s/iter; left time: 183.2532s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840910\n",
      "\tspeed: 0.0226s/iter; left time: 86.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0844714 Vali Loss: 0.0858070 Test Loss: 0.0971049\n",
      "Validation loss decreased (0.088246 --> 0.085807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787158\n",
      "\tspeed: 0.0466s/iter; left time: 171.8860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0773474\n",
      "\tspeed: 0.0226s/iter; left time: 81.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0792804 Vali Loss: 0.0866306 Test Loss: 0.0979837\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746874\n",
      "\tspeed: 0.0449s/iter; left time: 155.7042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0745576\n",
      "\tspeed: 0.0224s/iter; left time: 75.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0749708 Vali Loss: 0.0876147 Test Loss: 0.0982907\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734099\n",
      "\tspeed: 0.0442s/iter; left time: 143.3839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726197\n",
      "\tspeed: 0.0224s/iter; left time: 70.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0713834 Vali Loss: 0.0886993 Test Loss: 0.0983842\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0680743\n",
      "\tspeed: 0.0443s/iter; left time: 133.8580s\n",
      "\titers: 200, epoch: 7 | loss: 0.0658535\n",
      "\tspeed: 0.0223s/iter; left time: 65.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0679162 Vali Loss: 0.0891556 Test Loss: 0.0995721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637082\n",
      "\tspeed: 0.0452s/iter; left time: 126.6094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638428\n",
      "\tspeed: 0.0223s/iter; left time: 60.1778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0645114 Vali Loss: 0.0891259 Test Loss: 0.1003027\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02172878384590149, rmse:0.14740686118602753, mae:0.09710493683815002, rse:0.4330681264400482\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1338054\n",
      "\tspeed: 0.0246s/iter; left time: 107.0937s\n",
      "\titers: 200, epoch: 1 | loss: 0.1172974\n",
      "\tspeed: 0.0226s/iter; left time: 96.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.1397129 Vali Loss: 0.1100905 Test Loss: 0.1230639\n",
      "Validation loss decreased (inf --> 0.110091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909255\n",
      "\tspeed: 0.0458s/iter; left time: 189.6162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0843903\n",
      "\tspeed: 0.0224s/iter; left time: 90.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0946380 Vali Loss: 0.0877320 Test Loss: 0.0977113\n",
      "Validation loss decreased (0.110091 --> 0.087732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0839579\n",
      "\tspeed: 0.0458s/iter; left time: 179.1708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794685\n",
      "\tspeed: 0.0223s/iter; left time: 85.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0840396 Vali Loss: 0.0863901 Test Loss: 0.0984656\n",
      "Validation loss decreased (0.087732 --> 0.086390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788893\n",
      "\tspeed: 0.0458s/iter; left time: 169.1486s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761613\n",
      "\tspeed: 0.0224s/iter; left time: 80.5832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0789190 Vali Loss: 0.0869178 Test Loss: 0.0986370\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0742886\n",
      "\tspeed: 0.0478s/iter; left time: 165.6836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743236\n",
      "\tspeed: 0.0223s/iter; left time: 75.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0746482 Vali Loss: 0.0868706 Test Loss: 0.0991525\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0722558\n",
      "\tspeed: 0.0442s/iter; left time: 143.5750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707610\n",
      "\tspeed: 0.0223s/iter; left time: 70.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0706094 Vali Loss: 0.0871155 Test Loss: 0.1002640\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0670408\n",
      "\tspeed: 0.0439s/iter; left time: 132.6848s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647997\n",
      "\tspeed: 0.0224s/iter; left time: 65.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0668925 Vali Loss: 0.0879370 Test Loss: 0.1000142\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0650123\n",
      "\tspeed: 0.0447s/iter; left time: 125.0898s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613846\n",
      "\tspeed: 0.0224s/iter; left time: 60.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0635497 Vali Loss: 0.0889210 Test Loss: 0.1020326\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021894296631217003, rmse:0.14796721935272217, mae:0.09846556931734085, rse:0.43471434712409973\n",
      "Intermediate time for ES and pred_len 168: 00h:01m:58.41s\n",
      "Intermediate time for ES: 00h:07m:47.25s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0911608\n",
      "\tspeed: 0.0395s/iter; left time: 173.2211s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807561\n",
      "\tspeed: 0.0220s/iter; left time: 93.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0953799 Vali Loss: 0.0820948 Test Loss: 0.0894879\n",
      "Validation loss decreased (inf --> 0.082095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561930\n",
      "\tspeed: 0.0444s/iter; left time: 184.7348s\n",
      "\titers: 200, epoch: 2 | loss: 0.0492035\n",
      "\tspeed: 0.0220s/iter; left time: 89.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0542452 Vali Loss: 0.0557568 Test Loss: 0.0594116\n",
      "Validation loss decreased (0.082095 --> 0.055757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486324\n",
      "\tspeed: 0.0473s/iter; left time: 185.8351s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475799\n",
      "\tspeed: 0.0220s/iter; left time: 84.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0461456 Vali Loss: 0.0538717 Test Loss: 0.0575684\n",
      "Validation loss decreased (0.055757 --> 0.053872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0437132\n",
      "\tspeed: 0.0439s/iter; left time: 162.6741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0451161\n",
      "\tspeed: 0.0220s/iter; left time: 79.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0440538 Vali Loss: 0.0533928 Test Loss: 0.0573033\n",
      "Validation loss decreased (0.053872 --> 0.053393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0390914\n",
      "\tspeed: 0.0439s/iter; left time: 152.9549s\n",
      "\titers: 200, epoch: 5 | loss: 0.0422770\n",
      "\tspeed: 0.0220s/iter; left time: 74.5831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0426606 Vali Loss: 0.0522712 Test Loss: 0.0566506\n",
      "Validation loss decreased (0.053393 --> 0.052271).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0419594\n",
      "\tspeed: 0.0464s/iter; left time: 151.1885s\n",
      "\titers: 200, epoch: 6 | loss: 0.0421335\n",
      "\tspeed: 0.0220s/iter; left time: 69.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0415427 Vali Loss: 0.0521313 Test Loss: 0.0565895\n",
      "Validation loss decreased (0.052271 --> 0.052131).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0394318\n",
      "\tspeed: 0.0437s/iter; left time: 132.7002s\n",
      "\titers: 200, epoch: 7 | loss: 0.0366648\n",
      "\tspeed: 0.0220s/iter; left time: 64.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0405039 Vali Loss: 0.0522789 Test Loss: 0.0569994\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0414733\n",
      "\tspeed: 0.0435s/iter; left time: 122.3514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397425\n",
      "\tspeed: 0.0220s/iter; left time: 59.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0396449 Vali Loss: 0.0521628 Test Loss: 0.0571179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0387222\n",
      "\tspeed: 0.0429s/iter; left time: 111.0310s\n",
      "\titers: 200, epoch: 9 | loss: 0.0377659\n",
      "\tspeed: 0.0220s/iter; left time: 54.7764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0387779 Vali Loss: 0.0524518 Test Loss: 0.0580054\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399559\n",
      "\tspeed: 0.0440s/iter; left time: 103.9845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0383337\n",
      "\tspeed: 0.0221s/iter; left time: 50.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0379001 Vali Loss: 0.0528825 Test Loss: 0.0582209\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0369181\n",
      "\tspeed: 0.0455s/iter; left time: 97.4036s\n",
      "\titers: 200, epoch: 11 | loss: 0.0370933\n",
      "\tspeed: 0.0222s/iter; left time: 45.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0371930 Vali Loss: 0.0523042 Test Loss: 0.0584522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01019241288304329, rmse:0.1009574830532074, mae:0.056589506566524506, rse:0.38949114084243774\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0983568\n",
      "\tspeed: 0.0247s/iter; left time: 108.3098s\n",
      "\titers: 200, epoch: 1 | loss: 0.0811648\n",
      "\tspeed: 0.0220s/iter; left time: 94.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0986384 Vali Loss: 0.0830617 Test Loss: 0.0900622\n",
      "Validation loss decreased (inf --> 0.083062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534172\n",
      "\tspeed: 0.0459s/iter; left time: 190.8347s\n",
      "\titers: 200, epoch: 2 | loss: 0.0459291\n",
      "\tspeed: 0.0220s/iter; left time: 89.4148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0541714 Vali Loss: 0.0558285 Test Loss: 0.0595404\n",
      "Validation loss decreased (0.083062 --> 0.055828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0488589\n",
      "\tspeed: 0.0455s/iter; left time: 179.1443s\n",
      "\titers: 200, epoch: 3 | loss: 0.0440432\n",
      "\tspeed: 0.0220s/iter; left time: 84.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0462337 Vali Loss: 0.0534941 Test Loss: 0.0573518\n",
      "Validation loss decreased (0.055828 --> 0.053494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0463716\n",
      "\tspeed: 0.0472s/iter; left time: 175.1546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0456805\n",
      "\tspeed: 0.0220s/iter; left time: 79.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0441008 Vali Loss: 0.0527866 Test Loss: 0.0569766\n",
      "Validation loss decreased (0.053494 --> 0.052787).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0462096\n",
      "\tspeed: 0.0456s/iter; left time: 158.7527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0410608\n",
      "\tspeed: 0.0220s/iter; left time: 74.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0427795 Vali Loss: 0.0525542 Test Loss: 0.0569405\n",
      "Validation loss decreased (0.052787 --> 0.052554).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0407355\n",
      "\tspeed: 0.0498s/iter; left time: 162.4428s\n",
      "\titers: 200, epoch: 6 | loss: 0.0419847\n",
      "\tspeed: 0.0221s/iter; left time: 70.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0416694 Vali Loss: 0.0518883 Test Loss: 0.0565364\n",
      "Validation loss decreased (0.052554 --> 0.051888).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0414056\n",
      "\tspeed: 0.0486s/iter; left time: 147.6256s\n",
      "\titers: 200, epoch: 7 | loss: 0.0415133\n",
      "\tspeed: 0.0221s/iter; left time: 64.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0407206 Vali Loss: 0.0519327 Test Loss: 0.0568358\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0397163\n",
      "\tspeed: 0.0451s/iter; left time: 126.8378s\n",
      "\titers: 200, epoch: 8 | loss: 0.0388439\n",
      "\tspeed: 0.0221s/iter; left time: 60.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0398980 Vali Loss: 0.0518868 Test Loss: 0.0571416\n",
      "Validation loss decreased (0.051888 --> 0.051887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0371764\n",
      "\tspeed: 0.0451s/iter; left time: 116.6879s\n",
      "\titers: 200, epoch: 9 | loss: 0.0366343\n",
      "\tspeed: 0.0220s/iter; left time: 54.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0390674 Vali Loss: 0.0520276 Test Loss: 0.0576413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378093\n",
      "\tspeed: 0.0440s/iter; left time: 103.9488s\n",
      "\titers: 200, epoch: 10 | loss: 0.0378744\n",
      "\tspeed: 0.0220s/iter; left time: 49.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0382958 Vali Loss: 0.0521671 Test Loss: 0.0580638\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378447\n",
      "\tspeed: 0.0425s/iter; left time: 90.9655s\n",
      "\titers: 200, epoch: 11 | loss: 0.0375221\n",
      "\tspeed: 0.0220s/iter; left time: 44.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0375433 Vali Loss: 0.0524383 Test Loss: 0.0580152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0369047\n",
      "\tspeed: 0.0426s/iter; left time: 81.6378s\n",
      "\titers: 200, epoch: 12 | loss: 0.0374718\n",
      "\tspeed: 0.0220s/iter; left time: 40.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0368759 Vali Loss: 0.0522108 Test Loss: 0.0584778\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0371997\n",
      "\tspeed: 0.0426s/iter; left time: 72.0876s\n",
      "\titers: 200, epoch: 13 | loss: 0.0384833\n",
      "\tspeed: 0.0220s/iter; left time: 35.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0362783 Vali Loss: 0.0522735 Test Loss: 0.0587735\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010431569069623947, rmse:0.1021350547671318, mae:0.057141587138175964, rse:0.394034206867218\n",
      "Intermediate time for FR and pred_len 24: 00h:02m:50.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1006848\n",
      "\tspeed: 0.0397s/iter; left time: 174.0005s\n",
      "\titers: 200, epoch: 1 | loss: 0.0841898\n",
      "\tspeed: 0.0221s/iter; left time: 94.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1028407 Vali Loss: 0.0909074 Test Loss: 0.1000355\n",
      "Validation loss decreased (inf --> 0.090907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0667737\n",
      "\tspeed: 0.0449s/iter; left time: 186.6393s\n",
      "\titers: 200, epoch: 2 | loss: 0.0597491\n",
      "\tspeed: 0.0222s/iter; left time: 90.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0683883 Vali Loss: 0.0734551 Test Loss: 0.0820000\n",
      "Validation loss decreased (0.090907 --> 0.073455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0597644\n",
      "\tspeed: 0.0536s/iter; left time: 210.6612s\n",
      "\titers: 200, epoch: 3 | loss: 0.0573469\n",
      "\tspeed: 0.0222s/iter; left time: 85.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0604713 Vali Loss: 0.0728116 Test Loss: 0.0829389\n",
      "Validation loss decreased (0.073455 --> 0.072812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0543406\n",
      "\tspeed: 0.0467s/iter; left time: 173.1935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0559489\n",
      "\tspeed: 0.0222s/iter; left time: 80.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0555894 Vali Loss: 0.0726943 Test Loss: 0.0856126\n",
      "Validation loss decreased (0.072812 --> 0.072694).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0521473\n",
      "\tspeed: 0.0458s/iter; left time: 159.5019s\n",
      "\titers: 200, epoch: 5 | loss: 0.0497508\n",
      "\tspeed: 0.0222s/iter; left time: 75.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0508938 Vali Loss: 0.0734280 Test Loss: 0.0868193\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0467287\n",
      "\tspeed: 0.0453s/iter; left time: 147.8227s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474530\n",
      "\tspeed: 0.0222s/iter; left time: 70.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0473731 Vali Loss: 0.0740491 Test Loss: 0.0903171\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445259\n",
      "\tspeed: 0.0460s/iter; left time: 139.7311s\n",
      "\titers: 200, epoch: 7 | loss: 0.0429022\n",
      "\tspeed: 0.0222s/iter; left time: 65.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0449064 Vali Loss: 0.0749877 Test Loss: 0.0900412\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447864\n",
      "\tspeed: 0.0459s/iter; left time: 129.0161s\n",
      "\titers: 200, epoch: 8 | loss: 0.0412697\n",
      "\tspeed: 0.0223s/iter; left time: 60.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0427259 Vali Loss: 0.0744871 Test Loss: 0.0900806\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0412090\n",
      "\tspeed: 0.0458s/iter; left time: 118.6480s\n",
      "\titers: 200, epoch: 9 | loss: 0.0411860\n",
      "\tspeed: 0.0225s/iter; left time: 55.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0410810 Vali Loss: 0.0739628 Test Loss: 0.0906877\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022053049877285957, rmse:0.14850269258022308, mae:0.08561256527900696, rse:0.5744478702545166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1005642\n",
      "\tspeed: 0.0244s/iter; left time: 106.7894s\n",
      "\titers: 200, epoch: 1 | loss: 0.0917427\n",
      "\tspeed: 0.0221s/iter; left time: 94.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.1031050 Vali Loss: 0.0911626 Test Loss: 0.1002582\n",
      "Validation loss decreased (inf --> 0.091163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0699997\n",
      "\tspeed: 0.0464s/iter; left time: 192.8545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0637312\n",
      "\tspeed: 0.0222s/iter; left time: 90.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0683236 Vali Loss: 0.0735162 Test Loss: 0.0822804\n",
      "Validation loss decreased (0.091163 --> 0.073516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0605401\n",
      "\tspeed: 0.0471s/iter; left time: 185.0752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0607821\n",
      "\tspeed: 0.0223s/iter; left time: 85.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0604257 Vali Loss: 0.0721129 Test Loss: 0.0824257\n",
      "Validation loss decreased (0.073516 --> 0.072113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0555506\n",
      "\tspeed: 0.0492s/iter; left time: 182.4720s\n",
      "\titers: 200, epoch: 4 | loss: 0.0568947\n",
      "\tspeed: 0.0222s/iter; left time: 80.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0552945 Vali Loss: 0.0730396 Test Loss: 0.0871446\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0492285\n",
      "\tspeed: 0.0458s/iter; left time: 159.7724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0476777\n",
      "\tspeed: 0.0223s/iter; left time: 75.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0505104 Vali Loss: 0.0731663 Test Loss: 0.0874221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488765\n",
      "\tspeed: 0.0447s/iter; left time: 145.7902s\n",
      "\titers: 200, epoch: 6 | loss: 0.0477134\n",
      "\tspeed: 0.0222s/iter; left time: 70.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0469335 Vali Loss: 0.0743040 Test Loss: 0.0891248\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0456722\n",
      "\tspeed: 0.0447s/iter; left time: 135.6284s\n",
      "\titers: 200, epoch: 7 | loss: 0.0439361\n",
      "\tspeed: 0.0224s/iter; left time: 65.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0442663 Vali Loss: 0.0741631 Test Loss: 0.0898651\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0420532\n",
      "\tspeed: 0.0447s/iter; left time: 125.8808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0395115\n",
      "\tspeed: 0.0224s/iter; left time: 60.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0422339 Vali Loss: 0.0745660 Test Loss: 0.0915339\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019726678729057312, rmse:0.14045169949531555, mae:0.08242567628622055, rse:0.543304443359375\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:06.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1056457\n",
      "\tspeed: 0.0398s/iter; left time: 173.6812s\n",
      "\titers: 200, epoch: 1 | loss: 0.0920094\n",
      "\tspeed: 0.0224s/iter; left time: 95.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.1057240 Vali Loss: 0.0936650 Test Loss: 0.1019153\n",
      "Validation loss decreased (inf --> 0.093665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0718475\n",
      "\tspeed: 0.0447s/iter; left time: 185.1133s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731005\n",
      "\tspeed: 0.0224s/iter; left time: 90.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0723086 Vali Loss: 0.0779335 Test Loss: 0.0873305\n",
      "Validation loss decreased (0.093665 --> 0.077934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632716\n",
      "\tspeed: 0.0459s/iter; left time: 179.8549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641079\n",
      "\tspeed: 0.0224s/iter; left time: 85.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0631816 Vali Loss: 0.0758860 Test Loss: 0.0896951\n",
      "Validation loss decreased (0.077934 --> 0.075886).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0551088\n",
      "\tspeed: 0.0459s/iter; left time: 169.5448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547754\n",
      "\tspeed: 0.0225s/iter; left time: 80.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0568533 Vali Loss: 0.0776557 Test Loss: 0.0928236\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0526990\n",
      "\tspeed: 0.0449s/iter; left time: 155.9181s\n",
      "\titers: 200, epoch: 5 | loss: 0.0493257\n",
      "\tspeed: 0.0224s/iter; left time: 75.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0520216 Vali Loss: 0.0776104 Test Loss: 0.0933026\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494825\n",
      "\tspeed: 0.0439s/iter; left time: 142.5911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0487090\n",
      "\tspeed: 0.0225s/iter; left time: 70.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0485547 Vali Loss: 0.0779353 Test Loss: 0.0935854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0466170\n",
      "\tspeed: 0.0443s/iter; left time: 133.9005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0462868\n",
      "\tspeed: 0.0224s/iter; left time: 65.4560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0459587 Vali Loss: 0.0782540 Test Loss: 0.0941730\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0445945\n",
      "\tspeed: 0.0442s/iter; left time: 123.8177s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431015\n",
      "\tspeed: 0.0225s/iter; left time: 60.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0438796 Vali Loss: 0.0789876 Test Loss: 0.0948573\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021620899438858032, rmse:0.1470404714345932, mae:0.08969511091709137, rse:0.5695016980171204\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0991714\n",
      "\tspeed: 0.0242s/iter; left time: 105.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885712\n",
      "\tspeed: 0.0224s/iter; left time: 95.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.1043165 Vali Loss: 0.0933984 Test Loss: 0.1014372\n",
      "Validation loss decreased (inf --> 0.093398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710609\n",
      "\tspeed: 0.0452s/iter; left time: 187.1805s\n",
      "\titers: 200, epoch: 2 | loss: 0.0618889\n",
      "\tspeed: 0.0225s/iter; left time: 90.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0721745 Vali Loss: 0.0774508 Test Loss: 0.0867138\n",
      "Validation loss decreased (0.093398 --> 0.077451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0610502\n",
      "\tspeed: 0.0455s/iter; left time: 178.2605s\n",
      "\titers: 200, epoch: 3 | loss: 0.0590557\n",
      "\tspeed: 0.0225s/iter; left time: 85.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0635017 Vali Loss: 0.0759463 Test Loss: 0.0875126\n",
      "Validation loss decreased (0.077451 --> 0.075946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0575557\n",
      "\tspeed: 0.0448s/iter; left time: 165.3782s\n",
      "\titers: 200, epoch: 4 | loss: 0.0550404\n",
      "\tspeed: 0.0224s/iter; left time: 80.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0579271 Vali Loss: 0.0790097 Test Loss: 0.0919720\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552282\n",
      "\tspeed: 0.0460s/iter; left time: 159.5844s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517130\n",
      "\tspeed: 0.0225s/iter; left time: 75.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0529827 Vali Loss: 0.0791752 Test Loss: 0.0956786\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0491072\n",
      "\tspeed: 0.0445s/iter; left time: 144.5271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490277\n",
      "\tspeed: 0.0225s/iter; left time: 70.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0493609 Vali Loss: 0.0793608 Test Loss: 0.0970479\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464880\n",
      "\tspeed: 0.0440s/iter; left time: 132.9713s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456919\n",
      "\tspeed: 0.0224s/iter; left time: 65.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0465144 Vali Loss: 0.0802678 Test Loss: 0.0969906\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447792\n",
      "\tspeed: 0.0438s/iter; left time: 122.5531s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422901\n",
      "\tspeed: 0.0225s/iter; left time: 60.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0443371 Vali Loss: 0.0795111 Test Loss: 0.0977988\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02099021151661873, rmse:0.1448799967765808, mae:0.08751260489225388, rse:0.5611339211463928\n",
      "Intermediate time for FR and pred_len 168: 00h:01m:56.97s\n",
      "Intermediate time for FR: 00h:06m:53.36s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1278432\n",
      "\tspeed: 0.0403s/iter; left time: 176.4808s\n",
      "\titers: 200, epoch: 1 | loss: 0.1199756\n",
      "\tspeed: 0.0221s/iter; left time: 94.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1362877 Vali Loss: 0.0958211 Test Loss: 0.0981545\n",
      "Validation loss decreased (inf --> 0.095821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0730210\n",
      "\tspeed: 0.0448s/iter; left time: 186.1073s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685680\n",
      "\tspeed: 0.0221s/iter; left time: 89.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0737874 Vali Loss: 0.0606424 Test Loss: 0.0634204\n",
      "Validation loss decreased (0.095821 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679964\n",
      "\tspeed: 0.0455s/iter; left time: 179.1425s\n",
      "\titers: 200, epoch: 3 | loss: 0.0627244\n",
      "\tspeed: 0.0221s/iter; left time: 84.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0626436 Vali Loss: 0.0585590 Test Loss: 0.0609500\n",
      "Validation loss decreased (0.060642 --> 0.058559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0576157\n",
      "\tspeed: 0.0441s/iter; left time: 163.6331s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638441\n",
      "\tspeed: 0.0221s/iter; left time: 79.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0600721 Vali Loss: 0.0572869 Test Loss: 0.0595370\n",
      "Validation loss decreased (0.058559 --> 0.057287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601263\n",
      "\tspeed: 0.0447s/iter; left time: 155.6338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590720\n",
      "\tspeed: 0.0222s/iter; left time: 75.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0583885 Vali Loss: 0.0561951 Test Loss: 0.0586180\n",
      "Validation loss decreased (0.057287 --> 0.056195).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568630\n",
      "\tspeed: 0.0444s/iter; left time: 144.7807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588873\n",
      "\tspeed: 0.0221s/iter; left time: 69.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0571105 Vali Loss: 0.0560492 Test Loss: 0.0585387\n",
      "Validation loss decreased (0.056195 --> 0.056049).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534128\n",
      "\tspeed: 0.0449s/iter; left time: 136.3684s\n",
      "\titers: 200, epoch: 7 | loss: 0.0566401\n",
      "\tspeed: 0.0221s/iter; left time: 65.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0559917 Vali Loss: 0.0559686 Test Loss: 0.0586595\n",
      "Validation loss decreased (0.056049 --> 0.055969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540253\n",
      "\tspeed: 0.0445s/iter; left time: 125.2643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0523734\n",
      "\tspeed: 0.0221s/iter; left time: 59.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0550626 Vali Loss: 0.0557020 Test Loss: 0.0581373\n",
      "Validation loss decreased (0.055969 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549227\n",
      "\tspeed: 0.0441s/iter; left time: 114.2035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555563\n",
      "\tspeed: 0.0220s/iter; left time: 54.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0541545 Vali Loss: 0.0554387 Test Loss: 0.0579014\n",
      "Validation loss decreased (0.055702 --> 0.055439).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573516\n",
      "\tspeed: 0.0443s/iter; left time: 104.8230s\n",
      "\titers: 200, epoch: 10 | loss: 0.0533080\n",
      "\tspeed: 0.0223s/iter; left time: 50.6226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0534064 Vali Loss: 0.0554795 Test Loss: 0.0580060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0537935\n",
      "\tspeed: 0.0433s/iter; left time: 92.7225s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519395\n",
      "\tspeed: 0.0221s/iter; left time: 45.1442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0526716 Vali Loss: 0.0553332 Test Loss: 0.0582383\n",
      "Validation loss decreased (0.055439 --> 0.055333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494004\n",
      "\tspeed: 0.0442s/iter; left time: 84.6628s\n",
      "\titers: 200, epoch: 12 | loss: 0.0503696\n",
      "\tspeed: 0.0222s/iter; left time: 40.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0519590 Vali Loss: 0.0552357 Test Loss: 0.0584522\n",
      "Validation loss decreased (0.055333 --> 0.055236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0522351\n",
      "\tspeed: 0.0446s/iter; left time: 75.5378s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554844\n",
      "\tspeed: 0.0221s/iter; left time: 35.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0512310 Vali Loss: 0.0556980 Test Loss: 0.0582841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0527922\n",
      "\tspeed: 0.0441s/iter; left time: 64.7681s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496648\n",
      "\tspeed: 0.0221s/iter; left time: 30.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0505910 Vali Loss: 0.0554339 Test Loss: 0.0585908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0505742\n",
      "\tspeed: 0.0428s/iter; left time: 53.3226s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552145\n",
      "\tspeed: 0.0221s/iter; left time: 25.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499754 Vali Loss: 0.0557357 Test Loss: 0.0589469\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0501169\n",
      "\tspeed: 0.0435s/iter; left time: 44.3919s\n",
      "\titers: 200, epoch: 16 | loss: 0.0476602\n",
      "\tspeed: 0.0223s/iter; left time: 20.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0494236 Vali Loss: 0.0556930 Test Loss: 0.0588406\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0540575\n",
      "\tspeed: 0.0434s/iter; left time: 34.5807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0460231\n",
      "\tspeed: 0.0221s/iter; left time: 15.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0488599 Vali Loss: 0.0560844 Test Loss: 0.0593362\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010351636447012424, rmse:0.10174299031496048, mae:0.05845222249627113, rse:0.3844366669654846\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1312290\n",
      "\tspeed: 0.0239s/iter; left time: 104.5800s\n",
      "\titers: 200, epoch: 1 | loss: 0.1132838\n",
      "\tspeed: 0.0221s/iter; left time: 94.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1434084 Vali Loss: 0.0982049 Test Loss: 0.1005447\n",
      "Validation loss decreased (inf --> 0.098205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0674736\n",
      "\tspeed: 0.0449s/iter; left time: 186.7286s\n",
      "\titers: 200, epoch: 2 | loss: 0.0681145\n",
      "\tspeed: 0.0221s/iter; left time: 89.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0744928 Vali Loss: 0.0611276 Test Loss: 0.0633811\n",
      "Validation loss decreased (0.098205 --> 0.061128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0622577\n",
      "\tspeed: 0.0485s/iter; left time: 190.7232s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642815\n",
      "\tspeed: 0.0221s/iter; left time: 84.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0627514 Vali Loss: 0.0584585 Test Loss: 0.0605055\n",
      "Validation loss decreased (0.061128 --> 0.058458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0570491\n",
      "\tspeed: 0.0435s/iter; left time: 161.3850s\n",
      "\titers: 200, epoch: 4 | loss: 0.0608197\n",
      "\tspeed: 0.0221s/iter; left time: 79.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0602316 Vali Loss: 0.0581894 Test Loss: 0.0604754\n",
      "Validation loss decreased (0.058458 --> 0.058189).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571427\n",
      "\tspeed: 0.0434s/iter; left time: 151.1813s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591655\n",
      "\tspeed: 0.0221s/iter; left time: 74.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0585666 Vali Loss: 0.0570316 Test Loss: 0.0593375\n",
      "Validation loss decreased (0.058189 --> 0.057032).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569229\n",
      "\tspeed: 0.0446s/iter; left time: 145.4980s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601685\n",
      "\tspeed: 0.0221s/iter; left time: 69.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0572205 Vali Loss: 0.0561985 Test Loss: 0.0586197\n",
      "Validation loss decreased (0.057032 --> 0.056198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528390\n",
      "\tspeed: 0.0443s/iter; left time: 134.6254s\n",
      "\titers: 200, epoch: 7 | loss: 0.0560399\n",
      "\tspeed: 0.0220s/iter; left time: 64.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0561812 Vali Loss: 0.0559815 Test Loss: 0.0584007\n",
      "Validation loss decreased (0.056198 --> 0.055982).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0566561\n",
      "\tspeed: 0.0432s/iter; left time: 121.5715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0531043\n",
      "\tspeed: 0.0220s/iter; left time: 59.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0552645 Vali Loss: 0.0561232 Test Loss: 0.0582675\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0574572\n",
      "\tspeed: 0.0422s/iter; left time: 109.1267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525047\n",
      "\tspeed: 0.0221s/iter; left time: 55.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0542702 Vali Loss: 0.0558798 Test Loss: 0.0580742\n",
      "Validation loss decreased (0.055982 --> 0.055880).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514821\n",
      "\tspeed: 0.0442s/iter; left time: 104.4473s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550405\n",
      "\tspeed: 0.0222s/iter; left time: 50.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0534769 Vali Loss: 0.0561165 Test Loss: 0.0583153\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0494045\n",
      "\tspeed: 0.0429s/iter; left time: 91.7487s\n",
      "\titers: 200, epoch: 11 | loss: 0.0544998\n",
      "\tspeed: 0.0222s/iter; left time: 45.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0527047 Vali Loss: 0.0559758 Test Loss: 0.0582508\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558888\n",
      "\tspeed: 0.0430s/iter; left time: 82.4352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0501107\n",
      "\tspeed: 0.0223s/iter; left time: 40.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0519439 Vali Loss: 0.0558040 Test Loss: 0.0584697\n",
      "Validation loss decreased (0.055880 --> 0.055804).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0464681\n",
      "\tspeed: 0.0440s/iter; left time: 74.4818s\n",
      "\titers: 200, epoch: 13 | loss: 0.0487312\n",
      "\tspeed: 0.0221s/iter; left time: 35.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0512102 Vali Loss: 0.0558723 Test Loss: 0.0584111\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0515612\n",
      "\tspeed: 0.0426s/iter; left time: 62.5964s\n",
      "\titers: 200, epoch: 14 | loss: 0.0508993\n",
      "\tspeed: 0.0221s/iter; left time: 30.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0505620 Vali Loss: 0.0561245 Test Loss: 0.0586363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0493988\n",
      "\tspeed: 0.0426s/iter; left time: 53.0185s\n",
      "\titers: 200, epoch: 15 | loss: 0.0481921\n",
      "\tspeed: 0.0222s/iter; left time: 25.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499058 Vali Loss: 0.0561699 Test Loss: 0.0588772\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517682\n",
      "\tspeed: 0.0428s/iter; left time: 43.7099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0486397\n",
      "\tspeed: 0.0223s/iter; left time: 20.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0493334 Vali Loss: 0.0565590 Test Loss: 0.0592585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0502274\n",
      "\tspeed: 0.0428s/iter; left time: 34.1402s\n",
      "\titers: 200, epoch: 17 | loss: 0.0491273\n",
      "\tspeed: 0.0221s/iter; left time: 15.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0487718 Vali Loss: 0.0566396 Test Loss: 0.0595277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335784405469894, rmse:0.10166505724191666, mae:0.05846967175602913, rse:0.3841421902179718\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:53.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1406602\n",
      "\tspeed: 0.0396s/iter; left time: 173.4839s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232709\n",
      "\tspeed: 0.0222s/iter; left time: 95.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.1463149 Vali Loss: 0.1063972 Test Loss: 0.1096973\n",
      "Validation loss decreased (inf --> 0.106397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0882624\n",
      "\tspeed: 0.0446s/iter; left time: 185.3561s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824391\n",
      "\tspeed: 0.0223s/iter; left time: 90.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0918562 Vali Loss: 0.0795108 Test Loss: 0.0841194\n",
      "Validation loss decreased (0.106397 --> 0.079511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0812526\n",
      "\tspeed: 0.0456s/iter; left time: 179.2393s\n",
      "\titers: 200, epoch: 3 | loss: 0.0784772\n",
      "\tspeed: 0.0222s/iter; left time: 85.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0820270 Vali Loss: 0.0783789 Test Loss: 0.0819392\n",
      "Validation loss decreased (0.079511 --> 0.078379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744383\n",
      "\tspeed: 0.0454s/iter; left time: 168.5465s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777021\n",
      "\tspeed: 0.0223s/iter; left time: 80.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0783910 Vali Loss: 0.0788257 Test Loss: 0.0830169\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0753594\n",
      "\tspeed: 0.0442s/iter; left time: 153.9169s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750151\n",
      "\tspeed: 0.0223s/iter; left time: 75.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0734081 Vali Loss: 0.0819957 Test Loss: 0.0856044\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0659106\n",
      "\tspeed: 0.0441s/iter; left time: 143.8063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659576\n",
      "\tspeed: 0.0222s/iter; left time: 70.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0686825 Vali Loss: 0.0842883 Test Loss: 0.0852429\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648111\n",
      "\tspeed: 0.0444s/iter; left time: 134.8696s\n",
      "\titers: 200, epoch: 7 | loss: 0.0614157\n",
      "\tspeed: 0.0222s/iter; left time: 65.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650621 Vali Loss: 0.0839392 Test Loss: 0.0866236\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651447\n",
      "\tspeed: 0.0440s/iter; left time: 123.8320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613163\n",
      "\tspeed: 0.0222s/iter; left time: 60.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0623451 Vali Loss: 0.0845894 Test Loss: 0.0871178\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018120603635907173, rmse:0.1346127986907959, mae:0.08193915337324142, rse:0.5089855194091797\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431607\n",
      "\tspeed: 0.0244s/iter; left time: 106.7205s\n",
      "\titers: 200, epoch: 1 | loss: 0.1226398\n",
      "\tspeed: 0.0223s/iter; left time: 95.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1465745 Vali Loss: 0.1063707 Test Loss: 0.1097031\n",
      "Validation loss decreased (inf --> 0.106371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898145\n",
      "\tspeed: 0.0452s/iter; left time: 188.1016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898023\n",
      "\tspeed: 0.0223s/iter; left time: 90.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0918464 Vali Loss: 0.0796784 Test Loss: 0.0837768\n",
      "Validation loss decreased (0.106371 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820685\n",
      "\tspeed: 0.0451s/iter; left time: 177.2884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804370\n",
      "\tspeed: 0.0223s/iter; left time: 85.3903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0818808 Vali Loss: 0.0782289 Test Loss: 0.0822492\n",
      "Validation loss decreased (0.079678 --> 0.078229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801883\n",
      "\tspeed: 0.0466s/iter; left time: 172.7831s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770322\n",
      "\tspeed: 0.0222s/iter; left time: 80.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0781260 Vali Loss: 0.0790618 Test Loss: 0.0833921\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0714568\n",
      "\tspeed: 0.0439s/iter; left time: 152.9201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724024\n",
      "\tspeed: 0.0222s/iter; left time: 75.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0734421 Vali Loss: 0.0818351 Test Loss: 0.0865005\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0687422\n",
      "\tspeed: 0.0441s/iter; left time: 143.6745s\n",
      "\titers: 200, epoch: 6 | loss: 0.0683053\n",
      "\tspeed: 0.0223s/iter; left time: 70.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0687262 Vali Loss: 0.0829564 Test Loss: 0.0874128\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0646902\n",
      "\tspeed: 0.0443s/iter; left time: 134.5349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0637687\n",
      "\tspeed: 0.0223s/iter; left time: 65.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650412 Vali Loss: 0.0835494 Test Loss: 0.0889566\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0622228\n",
      "\tspeed: 0.0437s/iter; left time: 123.0097s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603192\n",
      "\tspeed: 0.0223s/iter; left time: 60.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0619382 Vali Loss: 0.0838071 Test Loss: 0.0882461\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01840209774672985, rmse:0.13565433025360107, mae:0.08224920183420181, rse:0.5129236578941345\n",
      "Intermediate time for IT and pred_len 96: 00h:01m:55.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423591\n",
      "\tspeed: 0.0387s/iter; left time: 168.9553s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247035\n",
      "\tspeed: 0.0224s/iter; left time: 95.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.1496753 Vali Loss: 0.1086939 Test Loss: 0.1115384\n",
      "Validation loss decreased (inf --> 0.108694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0945189\n",
      "\tspeed: 0.0450s/iter; left time: 186.0453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915999\n",
      "\tspeed: 0.0224s/iter; left time: 90.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0958328 Vali Loss: 0.0841946 Test Loss: 0.0881004\n",
      "Validation loss decreased (0.108694 --> 0.084195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0892303\n",
      "\tspeed: 0.0455s/iter; left time: 178.0036s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885527\n",
      "\tspeed: 0.0224s/iter; left time: 85.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0856628 Vali Loss: 0.0844716 Test Loss: 0.0865444\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801477\n",
      "\tspeed: 0.0441s/iter; left time: 162.6857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779318\n",
      "\tspeed: 0.0224s/iter; left time: 80.4699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0803572 Vali Loss: 0.0860760 Test Loss: 0.0882949\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737198\n",
      "\tspeed: 0.0444s/iter; left time: 153.9110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765113\n",
      "\tspeed: 0.0225s/iter; left time: 75.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0744970 Vali Loss: 0.0889429 Test Loss: 0.0900481\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0701593\n",
      "\tspeed: 0.0447s/iter; left time: 145.1644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692381\n",
      "\tspeed: 0.0224s/iter; left time: 70.6155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0699709 Vali Loss: 0.0898496 Test Loss: 0.0908735\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0679185\n",
      "\tspeed: 0.0456s/iter; left time: 137.7382s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630262\n",
      "\tspeed: 0.0225s/iter; left time: 65.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0663681 Vali Loss: 0.0885903 Test Loss: 0.0913930\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019992955029010773, rmse:0.1413964480161667, mae:0.08810041099786758, rse:0.5351320505142212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1404880\n",
      "\tspeed: 0.0284s/iter; left time: 123.7550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218658\n",
      "\tspeed: 0.0225s/iter; left time: 95.6780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.1495159 Vali Loss: 0.1086430 Test Loss: 0.1113816\n",
      "Validation loss decreased (inf --> 0.108643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0947164\n",
      "\tspeed: 0.0464s/iter; left time: 191.8074s\n",
      "\titers: 200, epoch: 2 | loss: 0.0872592\n",
      "\tspeed: 0.0224s/iter; left time: 90.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0958824 Vali Loss: 0.0842354 Test Loss: 0.0879539\n",
      "Validation loss decreased (0.108643 --> 0.084235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0828680\n",
      "\tspeed: 0.0454s/iter; left time: 177.6948s\n",
      "\titers: 200, epoch: 3 | loss: 0.0856310\n",
      "\tspeed: 0.0225s/iter; left time: 85.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0855720 Vali Loss: 0.0846827 Test Loss: 0.0879662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820475\n",
      "\tspeed: 0.0441s/iter; left time: 162.7253s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760696\n",
      "\tspeed: 0.0224s/iter; left time: 80.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0801973 Vali Loss: 0.0866909 Test Loss: 0.0899356\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758944\n",
      "\tspeed: 0.0441s/iter; left time: 152.8667s\n",
      "\titers: 200, epoch: 5 | loss: 0.0725707\n",
      "\tspeed: 0.0225s/iter; left time: 75.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0741449 Vali Loss: 0.0878185 Test Loss: 0.0923809\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0708352\n",
      "\tspeed: 0.0441s/iter; left time: 143.0451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0676354\n",
      "\tspeed: 0.0225s/iter; left time: 70.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0694595 Vali Loss: 0.0874840 Test Loss: 0.0934459\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662269\n",
      "\tspeed: 0.0439s/iter; left time: 132.7135s\n",
      "\titers: 200, epoch: 7 | loss: 0.0632087\n",
      "\tspeed: 0.0225s/iter; left time: 65.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0656503 Vali Loss: 0.0889737 Test Loss: 0.0943873\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019958944991230965, rmse:0.14127613604068756, mae:0.08795391023159027, rse:0.5346766710281372\n",
      "Intermediate time for IT and pred_len 168: 00h:01m:43.60s\n",
      "Intermediate time for IT: 00h:07m:33.05s\n",
      "Total time: 00h:41m:40.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1466  0.0920\n",
       "        96        0.0418  0.2045  0.1345\n",
       "        168       0.0461  0.2148  0.1428\n",
       "ES      24        0.0099  0.0997  0.0613\n",
       "        96        0.0192  0.1385  0.0908\n",
       "        168       0.0218  0.1477  0.0978\n",
       "FR      24        0.0103  0.1015  0.0569\n",
       "        96        0.0209  0.1445  0.0840\n",
       "        168       0.0213  0.1460  0.0886\n",
       "GB      24        0.0251  0.1586  0.1015\n",
       "        96        0.0428  0.2069  0.1411\n",
       "        168       0.0501  0.2237  0.1511\n",
       "IT      24        0.0103  0.1017  0.0585\n",
       "        96        0.0183  0.1351  0.0821\n",
       "        168       0.0200  0.1413  0.0880"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1461562\n",
      "\tspeed: 0.0870s/iter; left time: 1939.9968s\n",
      "\titers: 200, epoch: 1 | loss: 0.1378466\n",
      "\tspeed: 0.0681s/iter; left time: 1512.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.1492350 Vali Loss: 0.1491234 Test Loss: 0.1573499\n",
      "Validation loss decreased (inf --> 0.149123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934312\n",
      "\tspeed: 0.1174s/iter; left time: 2592.4927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790701\n",
      "\tspeed: 0.0682s/iter; left time: 1498.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0957774 Vali Loss: 0.0962578 Test Loss: 0.0969347\n",
      "Validation loss decreased (0.149123 --> 0.096258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799299\n",
      "\tspeed: 0.1177s/iter; left time: 2571.7666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831469\n",
      "\tspeed: 0.0682s/iter; left time: 1483.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0800204 Vali Loss: 0.0912525 Test Loss: 0.0925209\n",
      "Validation loss decreased (0.096258 --> 0.091253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0719650\n",
      "\tspeed: 0.1174s/iter; left time: 2538.3949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779148\n",
      "\tspeed: 0.0682s/iter; left time: 1467.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0767896 Vali Loss: 0.0894866 Test Loss: 0.0911194\n",
      "Validation loss decreased (0.091253 --> 0.089487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0700634\n",
      "\tspeed: 0.1163s/iter; left time: 2489.1998s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721898\n",
      "\tspeed: 0.0682s/iter; left time: 1452.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0751648 Vali Loss: 0.0887144 Test Loss: 0.0904107\n",
      "Validation loss decreased (0.089487 --> 0.088714).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749286\n",
      "\tspeed: 0.1160s/iter; left time: 2458.0185s\n",
      "\titers: 200, epoch: 6 | loss: 0.0738826\n",
      "\tspeed: 0.0681s/iter; left time: 1436.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0741185 Vali Loss: 0.0878579 Test Loss: 0.0896857\n",
      "Validation loss decreased (0.088714 --> 0.087858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773617\n",
      "\tspeed: 0.1159s/iter; left time: 2428.6779s\n",
      "\titers: 200, epoch: 7 | loss: 0.0697817\n",
      "\tspeed: 0.0682s/iter; left time: 1422.8361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0732767 Vali Loss: 0.0878588 Test Loss: 0.0896681\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0730642\n",
      "\tspeed: 0.1162s/iter; left time: 2409.5194s\n",
      "\titers: 200, epoch: 8 | loss: 0.0692202\n",
      "\tspeed: 0.0682s/iter; left time: 1407.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726633 Vali Loss: 0.0872458 Test Loss: 0.0892158\n",
      "Validation loss decreased (0.087858 --> 0.087246).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729467\n",
      "\tspeed: 0.1163s/iter; left time: 2385.3545s\n",
      "\titers: 200, epoch: 9 | loss: 0.0744857\n",
      "\tspeed: 0.0681s/iter; left time: 1390.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0721623 Vali Loss: 0.0872867 Test Loss: 0.0896076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0656316\n",
      "\tspeed: 0.1169s/iter; left time: 2370.6480s\n",
      "\titers: 200, epoch: 10 | loss: 0.0678511\n",
      "\tspeed: 0.0681s/iter; left time: 1374.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0717752 Vali Loss: 0.0871055 Test Loss: 0.0893893\n",
      "Validation loss decreased (0.087246 --> 0.087106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0707091\n",
      "\tspeed: 0.1165s/iter; left time: 2336.5772s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774499\n",
      "\tspeed: 0.0682s/iter; left time: 1360.7911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0715148 Vali Loss: 0.0870615 Test Loss: 0.0894800\n",
      "Validation loss decreased (0.087106 --> 0.087061).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0717980\n",
      "\tspeed: 0.1170s/iter; left time: 2321.4775s\n",
      "\titers: 200, epoch: 12 | loss: 0.0725807\n",
      "\tspeed: 0.0682s/iter; left time: 1345.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0711614 Vali Loss: 0.0869605 Test Loss: 0.0890957\n",
      "Validation loss decreased (0.087061 --> 0.086960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0668585\n",
      "\tspeed: 0.1175s/iter; left time: 2305.2279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692727\n",
      "\tspeed: 0.0681s/iter; left time: 1329.0050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0709143 Vali Loss: 0.0864946 Test Loss: 0.0891141\n",
      "Validation loss decreased (0.086960 --> 0.086495).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735727\n",
      "\tspeed: 0.1174s/iter; left time: 2277.1140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0707164\n",
      "\tspeed: 0.0682s/iter; left time: 1314.7134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0707176 Vali Loss: 0.0864244 Test Loss: 0.0890591\n",
      "Validation loss decreased (0.086495 --> 0.086424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733102\n",
      "\tspeed: 0.1170s/iter; left time: 2243.1031s\n",
      "\titers: 200, epoch: 15 | loss: 0.0694377\n",
      "\tspeed: 0.0682s/iter; left time: 1299.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0704899 Vali Loss: 0.0864086 Test Loss: 0.0890507\n",
      "Validation loss decreased (0.086424 --> 0.086409).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683793\n",
      "\tspeed: 0.1172s/iter; left time: 2219.2491s\n",
      "\titers: 200, epoch: 16 | loss: 0.0738790\n",
      "\tspeed: 0.0682s/iter; left time: 1284.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0703185 Vali Loss: 0.0864727 Test Loss: 0.0892115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669841\n",
      "\tspeed: 0.1164s/iter; left time: 2178.4624s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688473\n",
      "\tspeed: 0.0682s/iter; left time: 1270.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0701495 Vali Loss: 0.0867436 Test Loss: 0.0892003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0703127\n",
      "\tspeed: 0.1166s/iter; left time: 2157.1552s\n",
      "\titers: 200, epoch: 18 | loss: 0.0680623\n",
      "\tspeed: 0.0682s/iter; left time: 1253.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0700702 Vali Loss: 0.0863745 Test Loss: 0.0892077\n",
      "Validation loss decreased (0.086409 --> 0.086374).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0690351\n",
      "\tspeed: 0.1182s/iter; left time: 2158.8575s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699728\n",
      "\tspeed: 0.0685s/iter; left time: 1244.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0698759 Vali Loss: 0.0863962 Test Loss: 0.0891723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747989\n",
      "\tspeed: 0.1163s/iter; left time: 2099.3134s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701621\n",
      "\tspeed: 0.0681s/iter; left time: 1222.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0698077 Vali Loss: 0.0862366 Test Loss: 0.0890738\n",
      "Validation loss decreased (0.086374 --> 0.086237).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651559\n",
      "\tspeed: 0.1188s/iter; left time: 2117.8094s\n",
      "\titers: 200, epoch: 21 | loss: 0.0728592\n",
      "\tspeed: 0.0682s/iter; left time: 1208.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0696717 Vali Loss: 0.0862255 Test Loss: 0.0889388\n",
      "Validation loss decreased (0.086237 --> 0.086225).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0660903\n",
      "\tspeed: 0.1169s/iter; left time: 2057.1570s\n",
      "\titers: 200, epoch: 22 | loss: 0.0671541\n",
      "\tspeed: 0.0682s/iter; left time: 1193.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0695768 Vali Loss: 0.0863444 Test Loss: 0.0891108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0654175\n",
      "\tspeed: 0.1160s/iter; left time: 2015.2371s\n",
      "\titers: 200, epoch: 23 | loss: 0.0723482\n",
      "\tspeed: 0.0681s/iter; left time: 1176.3975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0695305 Vali Loss: 0.0861597 Test Loss: 0.0890979\n",
      "Validation loss decreased (0.086225 --> 0.086160).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697307\n",
      "\tspeed: 0.1174s/iter; left time: 2013.1403s\n",
      "\titers: 200, epoch: 24 | loss: 0.0650538\n",
      "\tspeed: 0.0682s/iter; left time: 1162.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0694439 Vali Loss: 0.0862999 Test Loss: 0.0889981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0687164\n",
      "\tspeed: 0.1167s/iter; left time: 1974.7961s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703700\n",
      "\tspeed: 0.0682s/iter; left time: 1147.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0694621 Vali Loss: 0.0863222 Test Loss: 0.0891119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0651680\n",
      "\tspeed: 0.1168s/iter; left time: 1950.1423s\n",
      "\titers: 200, epoch: 26 | loss: 0.0651452\n",
      "\tspeed: 0.0683s/iter; left time: 1134.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0693130 Vali Loss: 0.0863219 Test Loss: 0.0892911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680985\n",
      "\tspeed: 0.1161s/iter; left time: 1913.5918s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710439\n",
      "\tspeed: 0.0682s/iter; left time: 1117.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692731 Vali Loss: 0.0861376 Test Loss: 0.0890480\n",
      "Validation loss decreased (0.086160 --> 0.086138).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662021\n",
      "\tspeed: 0.1180s/iter; left time: 1917.0443s\n",
      "\titers: 200, epoch: 28 | loss: 0.0719197\n",
      "\tspeed: 0.0681s/iter; left time: 1100.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0692632 Vali Loss: 0.0861789 Test Loss: 0.0889845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0666632\n",
      "\tspeed: 0.1166s/iter; left time: 1868.4072s\n",
      "\titers: 200, epoch: 29 | loss: 0.0693237\n",
      "\tspeed: 0.0682s/iter; left time: 1086.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0691389 Vali Loss: 0.0861610 Test Loss: 0.0891781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0710969\n",
      "\tspeed: 0.1165s/iter; left time: 1841.6270s\n",
      "\titers: 200, epoch: 30 | loss: 0.0695848\n",
      "\tspeed: 0.0682s/iter; left time: 1071.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0692292 Vali Loss: 0.0863213 Test Loss: 0.0891762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0700110\n",
      "\tspeed: 0.1158s/iter; left time: 1804.9240s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660521\n",
      "\tspeed: 0.0683s/iter; left time: 1057.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0691260 Vali Loss: 0.0860816 Test Loss: 0.0891049\n",
      "Validation loss decreased (0.086138 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0688812\n",
      "\tspeed: 0.1164s/iter; left time: 1787.8197s\n",
      "\titers: 200, epoch: 32 | loss: 0.0697777\n",
      "\tspeed: 0.0682s/iter; left time: 1041.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691065 Vali Loss: 0.0862049 Test Loss: 0.0891521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0682049\n",
      "\tspeed: 0.1170s/iter; left time: 1770.2912s\n",
      "\titers: 200, epoch: 33 | loss: 0.0652785\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0863302 Test Loss: 0.0892339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697649\n",
      "\tspeed: 0.1185s/iter; left time: 1767.0506s\n",
      "\titers: 200, epoch: 34 | loss: 0.0742545\n",
      "\tspeed: 0.0683s/iter; left time: 1011.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0690200 Vali Loss: 0.0862837 Test Loss: 0.0892433\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694564\n",
      "\tspeed: 0.1176s/iter; left time: 1727.2184s\n",
      "\titers: 200, epoch: 35 | loss: 0.0653591\n",
      "\tspeed: 0.0682s/iter; left time: 994.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0861455 Test Loss: 0.0891630\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0664618\n",
      "\tspeed: 0.1166s/iter; left time: 1685.7674s\n",
      "\titers: 200, epoch: 36 | loss: 0.0715217\n",
      "\tspeed: 0.0682s/iter; left time: 979.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689417 Vali Loss: 0.0861939 Test Loss: 0.0891584\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0691396\n",
      "\tspeed: 0.1169s/iter; left time: 1663.9450s\n",
      "\titers: 200, epoch: 37 | loss: 0.0702624\n",
      "\tspeed: 0.0682s/iter; left time: 963.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689000 Vali Loss: 0.0863010 Test Loss: 0.0891434\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0753347\n",
      "\tspeed: 0.1163s/iter; left time: 1630.1800s\n",
      "\titers: 200, epoch: 38 | loss: 0.0695233\n",
      "\tspeed: 0.0682s/iter; left time: 948.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0689737 Vali Loss: 0.0862217 Test Loss: 0.0891257\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0725676\n",
      "\tspeed: 0.1169s/iter; left time: 1612.2869s\n",
      "\titers: 200, epoch: 39 | loss: 0.0694272\n",
      "\tspeed: 0.0681s/iter; left time: 932.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0688931 Vali Loss: 0.0861030 Test Loss: 0.0891194\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669012\n",
      "\tspeed: 0.1167s/iter; left time: 1583.0745s\n",
      "\titers: 200, epoch: 40 | loss: 0.0678386\n",
      "\tspeed: 0.0682s/iter; left time: 918.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689278 Vali Loss: 0.0861022 Test Loss: 0.0891052\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0652631\n",
      "\tspeed: 0.1166s/iter; left time: 1555.1809s\n",
      "\titers: 200, epoch: 41 | loss: 0.0645099\n",
      "\tspeed: 0.0681s/iter; left time: 902.1476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689060 Vali Loss: 0.0861354 Test Loss: 0.0891289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021332554519176483, rmse:0.14605668187141418, mae:0.08910492062568665, rse:0.5154542922973633\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1481339\n",
      "\tspeed: 0.0695s/iter; left time: 1549.3538s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375552\n",
      "\tspeed: 0.0681s/iter; left time: 1512.1521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.1479610 Vali Loss: 0.1469265 Test Loss: 0.1552719\n",
      "Validation loss decreased (inf --> 0.146926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0865266\n",
      "\tspeed: 0.1168s/iter; left time: 2579.1506s\n",
      "\titers: 200, epoch: 2 | loss: 0.0838551\n",
      "\tspeed: 0.0682s/iter; left time: 1498.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0964700 Vali Loss: 0.0967222 Test Loss: 0.0970902\n",
      "Validation loss decreased (0.146926 --> 0.096722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0791053\n",
      "\tspeed: 0.1175s/iter; left time: 2567.7102s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794358\n",
      "\tspeed: 0.0682s/iter; left time: 1483.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0806912 Vali Loss: 0.0917135 Test Loss: 0.0933135\n",
      "Validation loss decreased (0.096722 --> 0.091714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691623\n",
      "\tspeed: 0.1166s/iter; left time: 2521.8402s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749935\n",
      "\tspeed: 0.0681s/iter; left time: 1465.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0772206 Vali Loss: 0.0896696 Test Loss: 0.0914560\n",
      "Validation loss decreased (0.091714 --> 0.089670).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780290\n",
      "\tspeed: 0.1169s/iter; left time: 2502.3026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737418\n",
      "\tspeed: 0.0681s/iter; left time: 1451.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0753263 Vali Loss: 0.0887567 Test Loss: 0.0905667\n",
      "Validation loss decreased (0.089670 --> 0.088757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728102\n",
      "\tspeed: 0.1166s/iter; left time: 2470.7172s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751472\n",
      "\tspeed: 0.0681s/iter; left time: 1435.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0740903 Vali Loss: 0.0880040 Test Loss: 0.0901668\n",
      "Validation loss decreased (0.088757 --> 0.088004).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700100\n",
      "\tspeed: 0.1165s/iter; left time: 2441.6990s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719608\n",
      "\tspeed: 0.0682s/iter; left time: 1422.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0733094 Vali Loss: 0.0876565 Test Loss: 0.0895658\n",
      "Validation loss decreased (0.088004 --> 0.087656).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736883\n",
      "\tspeed: 0.1163s/iter; left time: 2411.0395s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753195\n",
      "\tspeed: 0.0681s/iter; left time: 1404.8808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726421 Vali Loss: 0.0870508 Test Loss: 0.0893122\n",
      "Validation loss decreased (0.087656 --> 0.087051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736136\n",
      "\tspeed: 0.1163s/iter; left time: 2385.7227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0743958\n",
      "\tspeed: 0.0681s/iter; left time: 1390.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0721928 Vali Loss: 0.0869639 Test Loss: 0.0890566\n",
      "Validation loss decreased (0.087051 --> 0.086964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751010\n",
      "\tspeed: 0.1164s/iter; left time: 2360.5034s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675038\n",
      "\tspeed: 0.0681s/iter; left time: 1374.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0717584 Vali Loss: 0.0868287 Test Loss: 0.0892483\n",
      "Validation loss decreased (0.086964 --> 0.086829).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0670119\n",
      "\tspeed: 0.1167s/iter; left time: 2341.7488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717888\n",
      "\tspeed: 0.0681s/iter; left time: 1359.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0714888 Vali Loss: 0.0868792 Test Loss: 0.0891389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712271\n",
      "\tspeed: 0.1159s/iter; left time: 2299.0788s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672809\n",
      "\tspeed: 0.0681s/iter; left time: 1343.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0712019 Vali Loss: 0.0867305 Test Loss: 0.0890825\n",
      "Validation loss decreased (0.086829 --> 0.086731).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719725\n",
      "\tspeed: 0.1167s/iter; left time: 2289.5881s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728667\n",
      "\tspeed: 0.0681s/iter; left time: 1328.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0709423 Vali Loss: 0.0863669 Test Loss: 0.0889514\n",
      "Validation loss decreased (0.086731 --> 0.086367).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0692876\n",
      "\tspeed: 0.1167s/iter; left time: 2262.4731s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697647\n",
      "\tspeed: 0.0681s/iter; left time: 1313.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0707196 Vali Loss: 0.0867283 Test Loss: 0.0890393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662864\n",
      "\tspeed: 0.1161s/iter; left time: 2224.9158s\n",
      "\titers: 200, epoch: 15 | loss: 0.0771343\n",
      "\tspeed: 0.0682s/iter; left time: 1299.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0705296 Vali Loss: 0.0863529 Test Loss: 0.0889915\n",
      "Validation loss decreased (0.086367 --> 0.086353).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746282\n",
      "\tspeed: 0.1165s/iter; left time: 2206.4443s\n",
      "\titers: 200, epoch: 16 | loss: 0.0754090\n",
      "\tspeed: 0.0680s/iter; left time: 1282.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0703587 Vali Loss: 0.0864495 Test Loss: 0.0889058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0699291\n",
      "\tspeed: 0.1157s/iter; left time: 2166.3741s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712281\n",
      "\tspeed: 0.0681s/iter; left time: 1268.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0701812 Vali Loss: 0.0863386 Test Loss: 0.0889277\n",
      "Validation loss decreased (0.086353 --> 0.086339).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725383\n",
      "\tspeed: 0.1164s/iter; left time: 2153.0135s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666652\n",
      "\tspeed: 0.0681s/iter; left time: 1252.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0700965 Vali Loss: 0.0862578 Test Loss: 0.0888635\n",
      "Validation loss decreased (0.086339 --> 0.086258).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668497\n",
      "\tspeed: 0.1165s/iter; left time: 2129.1404s\n",
      "\titers: 200, epoch: 19 | loss: 0.0658489\n",
      "\tspeed: 0.0681s/iter; left time: 1237.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0699537 Vali Loss: 0.0863137 Test Loss: 0.0890127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0738967\n",
      "\tspeed: 0.1177s/iter; left time: 2123.9244s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694792\n",
      "\tspeed: 0.0685s/iter; left time: 1229.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0698415 Vali Loss: 0.0861164 Test Loss: 0.0890737\n",
      "Validation loss decreased (0.086258 --> 0.086116).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683504\n",
      "\tspeed: 0.1182s/iter; left time: 2106.3686s\n",
      "\titers: 200, epoch: 21 | loss: 0.0662834\n",
      "\tspeed: 0.0681s/iter; left time: 1206.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0697480 Vali Loss: 0.0862716 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0703220\n",
      "\tspeed: 0.1164s/iter; left time: 2047.8510s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745794\n",
      "\tspeed: 0.0681s/iter; left time: 1191.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0696553 Vali Loss: 0.0863418 Test Loss: 0.0890533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0711524\n",
      "\tspeed: 0.1162s/iter; left time: 2019.3311s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714321\n",
      "\tspeed: 0.0681s/iter; left time: 1176.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0695627 Vali Loss: 0.0861240 Test Loss: 0.0890432\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0750200\n",
      "\tspeed: 0.1159s/iter; left time: 1987.3924s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680464\n",
      "\tspeed: 0.0681s/iter; left time: 1160.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0695156 Vali Loss: 0.0861897 Test Loss: 0.0889316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0634025\n",
      "\tspeed: 0.1160s/iter; left time: 1963.0234s\n",
      "\titers: 200, epoch: 25 | loss: 0.0649181\n",
      "\tspeed: 0.0681s/iter; left time: 1145.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0694371 Vali Loss: 0.0860986 Test Loss: 0.0890105\n",
      "Validation loss decreased (0.086116 --> 0.086099).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696129\n",
      "\tspeed: 0.1165s/iter; left time: 1945.9701s\n",
      "\titers: 200, epoch: 26 | loss: 0.0687395\n",
      "\tspeed: 0.0681s/iter; left time: 1130.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0693808 Vali Loss: 0.0860134 Test Loss: 0.0890921\n",
      "Validation loss decreased (0.086099 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0684652\n",
      "\tspeed: 0.1167s/iter; left time: 1923.3255s\n",
      "\titers: 200, epoch: 27 | loss: 0.0704379\n",
      "\tspeed: 0.0681s/iter; left time: 1115.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692557 Vali Loss: 0.0860665 Test Loss: 0.0890185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0660548\n",
      "\tspeed: 0.1157s/iter; left time: 1880.1403s\n",
      "\titers: 200, epoch: 28 | loss: 0.0695759\n",
      "\tspeed: 0.0681s/iter; left time: 1099.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692245 Vali Loss: 0.0860535 Test Loss: 0.0891044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729185\n",
      "\tspeed: 0.1158s/iter; left time: 1855.9955s\n",
      "\titers: 200, epoch: 29 | loss: 0.0718815\n",
      "\tspeed: 0.0681s/iter; left time: 1084.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692287 Vali Loss: 0.0860219 Test Loss: 0.0890628\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0671238\n",
      "\tspeed: 0.1159s/iter; left time: 1831.8557s\n",
      "\titers: 200, epoch: 30 | loss: 0.0673873\n",
      "\tspeed: 0.0681s/iter; left time: 1069.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692022 Vali Loss: 0.0860136 Test Loss: 0.0890284\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0704793\n",
      "\tspeed: 0.1178s/iter; left time: 1835.7009s\n",
      "\titers: 200, epoch: 31 | loss: 0.0718422\n",
      "\tspeed: 0.0684s/iter; left time: 1058.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0691225 Vali Loss: 0.0860802 Test Loss: 0.0890919\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725498\n",
      "\tspeed: 0.1185s/iter; left time: 1819.2180s\n",
      "\titers: 200, epoch: 32 | loss: 0.0676495\n",
      "\tspeed: 0.0681s/iter; left time: 1039.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0691134 Vali Loss: 0.0860155 Test Loss: 0.0890442\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0670726\n",
      "\tspeed: 0.1166s/iter; left time: 1764.2981s\n",
      "\titers: 200, epoch: 33 | loss: 0.0635491\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691029 Vali Loss: 0.0859950 Test Loss: 0.0890772\n",
      "Validation loss decreased (0.086013 --> 0.085995).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0719834\n",
      "\tspeed: 0.1168s/iter; left time: 1741.3619s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686517\n",
      "\tspeed: 0.0682s/iter; left time: 1009.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0690270 Vali Loss: 0.0861514 Test Loss: 0.0890609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0703810\n",
      "\tspeed: 0.1165s/iter; left time: 1711.0968s\n",
      "\titers: 200, epoch: 35 | loss: 0.0672738\n",
      "\tspeed: 0.0682s/iter; left time: 994.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0690094 Vali Loss: 0.0860701 Test Loss: 0.0889734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0648728\n",
      "\tspeed: 0.1180s/iter; left time: 1705.8382s\n",
      "\titers: 200, epoch: 36 | loss: 0.0674613\n",
      "\tspeed: 0.0688s/iter; left time: 988.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.0689744 Vali Loss: 0.0859692 Test Loss: 0.0889376\n",
      "Validation loss decreased (0.085995 --> 0.085969).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744139\n",
      "\tspeed: 0.1181s/iter; left time: 1682.0318s\n",
      "\titers: 200, epoch: 37 | loss: 0.0644355\n",
      "\tspeed: 0.0682s/iter; left time: 963.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689775 Vali Loss: 0.0860912 Test Loss: 0.0890521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0704839\n",
      "\tspeed: 0.1166s/iter; left time: 1633.4715s\n",
      "\titers: 200, epoch: 38 | loss: 0.0659875\n",
      "\tspeed: 0.0682s/iter; left time: 948.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0689991 Vali Loss: 0.0860307 Test Loss: 0.0890244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0652285\n",
      "\tspeed: 0.1163s/iter; left time: 1603.7897s\n",
      "\titers: 200, epoch: 39 | loss: 0.0635228\n",
      "\tspeed: 0.0682s/iter; left time: 932.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689129 Vali Loss: 0.0860817 Test Loss: 0.0890117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0707843\n",
      "\tspeed: 0.1163s/iter; left time: 1576.9634s\n",
      "\titers: 200, epoch: 40 | loss: 0.0744735\n",
      "\tspeed: 0.0682s/iter; left time: 917.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0688853 Vali Loss: 0.0859151 Test Loss: 0.0890057\n",
      "Validation loss decreased (0.085969 --> 0.085915).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0651298\n",
      "\tspeed: 0.1174s/iter; left time: 1566.6230s\n",
      "\titers: 200, epoch: 41 | loss: 0.0705316\n",
      "\tspeed: 0.0685s/iter; left time: 906.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0688910 Vali Loss: 0.0860872 Test Loss: 0.0890310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0715486\n",
      "\tspeed: 0.1173s/iter; left time: 1537.9944s\n",
      "\titers: 200, epoch: 42 | loss: 0.0710283\n",
      "\tspeed: 0.0681s/iter; left time: 886.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0688885 Vali Loss: 0.0859699 Test Loss: 0.0890445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0740932\n",
      "\tspeed: 0.1165s/iter; left time: 1501.5440s\n",
      "\titers: 200, epoch: 43 | loss: 0.0689263\n",
      "\tspeed: 0.0682s/iter; left time: 871.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688816 Vali Loss: 0.0860015 Test Loss: 0.0890182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0642701\n",
      "\tspeed: 0.1166s/iter; left time: 1476.6701s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692235\n",
      "\tspeed: 0.0684s/iter; left time: 859.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688794 Vali Loss: 0.0860575 Test Loss: 0.0890519\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0663138\n",
      "\tspeed: 0.1179s/iter; left time: 1466.8916s\n",
      "\titers: 200, epoch: 45 | loss: 0.0658265\n",
      "\tspeed: 0.0682s/iter; left time: 842.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0688699 Vali Loss: 0.0860186 Test Loss: 0.0890270\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0702913\n",
      "\tspeed: 0.1172s/iter; left time: 1431.8558s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666724\n",
      "\tspeed: 0.0684s/iter; left time: 828.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0688977 Vali Loss: 0.0860817 Test Loss: 0.0890611\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0673764\n",
      "\tspeed: 0.1164s/iter; left time: 1396.2169s\n",
      "\titers: 200, epoch: 47 | loss: 0.0681927\n",
      "\tspeed: 0.0682s/iter; left time: 810.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688601 Vali Loss: 0.0859702 Test Loss: 0.0890412\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0663044\n",
      "\tspeed: 0.1161s/iter; left time: 1367.3692s\n",
      "\titers: 200, epoch: 48 | loss: 0.0695243\n",
      "\tspeed: 0.0681s/iter; left time: 794.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0687945 Vali Loss: 0.0859358 Test Loss: 0.0890456\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0653680\n",
      "\tspeed: 0.1171s/iter; left time: 1352.6229s\n",
      "\titers: 200, epoch: 49 | loss: 0.0728765\n",
      "\tspeed: 0.0684s/iter; left time: 782.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0688531 Vali Loss: 0.0860522 Test Loss: 0.0890502\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0683106\n",
      "\tspeed: 0.1173s/iter; left time: 1328.5994s\n",
      "\titers: 200, epoch: 50 | loss: 0.0671068\n",
      "\tspeed: 0.0683s/iter; left time: 767.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688381 Vali Loss: 0.0860414 Test Loss: 0.0890929\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021220816299319267, rmse:0.14567366242408752, mae:0.08900570124387741, rse:0.5141025185585022\n",
      "Intermediate time for DE and pred_len 24: 00h:28m:14.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1553198\n",
      "\tspeed: 0.0894s/iter; left time: 1993.5704s\n",
      "\titers: 200, epoch: 1 | loss: 0.1476482\n",
      "\tspeed: 0.0686s/iter; left time: 1523.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 224 | Train Loss: 0.1587726 Vali Loss: 0.1620284 Test Loss: 0.1741853\n",
      "Validation loss decreased (inf --> 0.162028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1152195\n",
      "\tspeed: 0.1189s/iter; left time: 2625.1259s\n",
      "\titers: 200, epoch: 2 | loss: 0.1058429\n",
      "\tspeed: 0.0687s/iter; left time: 1509.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1189176 Vali Loss: 0.1228653 Test Loss: 0.1296490\n",
      "Validation loss decreased (0.162028 --> 0.122865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058418\n",
      "\tspeed: 0.1196s/iter; left time: 2614.5310s\n",
      "\titers: 200, epoch: 3 | loss: 0.1070150\n",
      "\tspeed: 0.0686s/iter; left time: 1492.3288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1064492 Vali Loss: 0.1198202 Test Loss: 0.1269938\n",
      "Validation loss decreased (0.122865 --> 0.119820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1012271\n",
      "\tspeed: 0.1207s/iter; left time: 2611.6478s\n",
      "\titers: 200, epoch: 4 | loss: 0.0987478\n",
      "\tspeed: 0.0686s/iter; left time: 1476.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1033720 Vali Loss: 0.1182980 Test Loss: 0.1268990\n",
      "Validation loss decreased (0.119820 --> 0.118298).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1041800\n",
      "\tspeed: 0.1203s/iter; left time: 2573.9606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997182\n",
      "\tspeed: 0.0686s/iter; left time: 1461.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1016296 Vali Loss: 0.1186564 Test Loss: 0.1272689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994423\n",
      "\tspeed: 0.1177s/iter; left time: 2492.6164s\n",
      "\titers: 200, epoch: 6 | loss: 0.1013170\n",
      "\tspeed: 0.0686s/iter; left time: 1445.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1003724 Vali Loss: 0.1183913 Test Loss: 0.1269911\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0949351\n",
      "\tspeed: 0.1187s/iter; left time: 2488.1407s\n",
      "\titers: 200, epoch: 7 | loss: 0.1020790\n",
      "\tspeed: 0.0686s/iter; left time: 1430.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.0993798 Vali Loss: 0.1190878 Test Loss: 0.1270349\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977151\n",
      "\tspeed: 0.1187s/iter; left time: 2460.3847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0957019\n",
      "\tspeed: 0.0685s/iter; left time: 1414.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0985318 Vali Loss: 0.1188884 Test Loss: 0.1277997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0936474\n",
      "\tspeed: 0.1172s/iter; left time: 2403.2456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0981991\n",
      "\tspeed: 0.0686s/iter; left time: 1400.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0976707 Vali Loss: 0.1194609 Test Loss: 0.1275967\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0972934\n",
      "\tspeed: 0.1186s/iter; left time: 2406.3673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0945473\n",
      "\tspeed: 0.0685s/iter; left time: 1383.2447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0969444 Vali Loss: 0.1195559 Test Loss: 0.1284629\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0940746\n",
      "\tspeed: 0.1174s/iter; left time: 2355.8651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0956078\n",
      "\tspeed: 0.0685s/iter; left time: 1367.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0961737 Vali Loss: 0.1201853 Test Loss: 0.1291677\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987268\n",
      "\tspeed: 0.1186s/iter; left time: 2353.6459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0970581\n",
      "\tspeed: 0.0686s/iter; left time: 1354.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0955070 Vali Loss: 0.1205458 Test Loss: 0.1305023\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0955645\n",
      "\tspeed: 0.1199s/iter; left time: 2351.4552s\n",
      "\titers: 200, epoch: 13 | loss: 0.0935065\n",
      "\tspeed: 0.0688s/iter; left time: 1343.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0948097 Vali Loss: 0.1206527 Test Loss: 0.1302494\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0937597\n",
      "\tspeed: 0.1196s/iter; left time: 2318.3649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0950699\n",
      "\tspeed: 0.0687s/iter; left time: 1325.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0941970 Vali Loss: 0.1206340 Test Loss: 0.1308207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03608657419681549, rmse:0.1899646669626236, mae:0.12689906358718872, rse:0.6727032661437988\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1584245\n",
      "\tspeed: 0.0702s/iter; left time: 1566.2615s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467351\n",
      "\tspeed: 0.0685s/iter; left time: 1520.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1586937 Vali Loss: 0.1618374 Test Loss: 0.1740249\n",
      "Validation loss decreased (inf --> 0.161837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1216307\n",
      "\tspeed: 0.1204s/iter; left time: 2658.2494s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122305\n",
      "\tspeed: 0.0686s/iter; left time: 1507.3866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1201242 Vali Loss: 0.1231106 Test Loss: 0.1303863\n",
      "Validation loss decreased (0.161837 --> 0.123111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1122966\n",
      "\tspeed: 0.1206s/iter; left time: 2635.8908s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102855\n",
      "\tspeed: 0.0690s/iter; left time: 1500.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.1063538 Vali Loss: 0.1198373 Test Loss: 0.1280635\n",
      "Validation loss decreased (0.123111 --> 0.119837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058941\n",
      "\tspeed: 0.1215s/iter; left time: 2628.3113s\n",
      "\titers: 200, epoch: 4 | loss: 0.1058972\n",
      "\tspeed: 0.0693s/iter; left time: 1491.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.1034576 Vali Loss: 0.1186996 Test Loss: 0.1267959\n",
      "Validation loss decreased (0.119837 --> 0.118700).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032637\n",
      "\tspeed: 0.1213s/iter; left time: 2596.4239s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977947\n",
      "\tspeed: 0.0689s/iter; left time: 1467.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1017239 Vali Loss: 0.1180575 Test Loss: 0.1264388\n",
      "Validation loss decreased (0.118700 --> 0.118057).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026086\n",
      "\tspeed: 0.1203s/iter; left time: 2547.2596s\n",
      "\titers: 200, epoch: 6 | loss: 0.1012904\n",
      "\tspeed: 0.0688s/iter; left time: 1451.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1004415 Vali Loss: 0.1183241 Test Loss: 0.1264702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958061\n",
      "\tspeed: 0.1198s/iter; left time: 2509.7809s\n",
      "\titers: 200, epoch: 7 | loss: 0.0977835\n",
      "\tspeed: 0.0686s/iter; left time: 1431.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0993413 Vali Loss: 0.1187937 Test Loss: 0.1269252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0999358\n",
      "\tspeed: 0.1198s/iter; left time: 2484.6183s\n",
      "\titers: 200, epoch: 8 | loss: 0.0953013\n",
      "\tspeed: 0.0685s/iter; left time: 1412.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0984381 Vali Loss: 0.1188546 Test Loss: 0.1268269\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1026255\n",
      "\tspeed: 0.1182s/iter; left time: 2424.0537s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962968\n",
      "\tspeed: 0.0685s/iter; left time: 1398.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0976047 Vali Loss: 0.1191079 Test Loss: 0.1277792\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0980087\n",
      "\tspeed: 0.1189s/iter; left time: 2411.6126s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934485\n",
      "\tspeed: 0.0686s/iter; left time: 1384.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0967829 Vali Loss: 0.1193806 Test Loss: 0.1285394\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0947366\n",
      "\tspeed: 0.1187s/iter; left time: 2380.3778s\n",
      "\titers: 200, epoch: 11 | loss: 0.0951942\n",
      "\tspeed: 0.0684s/iter; left time: 1366.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0961140 Vali Loss: 0.1194274 Test Loss: 0.1278090\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0942025\n",
      "\tspeed: 0.1182s/iter; left time: 2344.6639s\n",
      "\titers: 200, epoch: 12 | loss: 0.0922594\n",
      "\tspeed: 0.0685s/iter; left time: 1351.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0954150 Vali Loss: 0.1197382 Test Loss: 0.1294381\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0935657\n",
      "\tspeed: 0.1185s/iter; left time: 2323.2796s\n",
      "\titers: 200, epoch: 13 | loss: 0.0939974\n",
      "\tspeed: 0.0685s/iter; left time: 1337.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0947779 Vali Loss: 0.1200896 Test Loss: 0.1289643\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0945294\n",
      "\tspeed: 0.1196s/iter; left time: 2319.0838s\n",
      "\titers: 200, epoch: 14 | loss: 0.0924002\n",
      "\tspeed: 0.0691s/iter; left time: 1331.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0942263 Vali Loss: 0.1200542 Test Loss: 0.1291798\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901726\n",
      "\tspeed: 0.1184s/iter; left time: 2269.0467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943275\n",
      "\tspeed: 0.0685s/iter; left time: 1305.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0936829 Vali Loss: 0.1200363 Test Loss: 0.1297049\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036072153598070145, rmse:0.18992669880390167, mae:0.12643878161907196, rse:0.6725688576698303\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:17.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1549753\n",
      "\tspeed: 0.0902s/iter; left time: 2002.2874s\n",
      "\titers: 200, epoch: 1 | loss: 0.1490488\n",
      "\tspeed: 0.0690s/iter; left time: 1525.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.1608003 Vali Loss: 0.1642570 Test Loss: 0.1773680\n",
      "Validation loss decreased (inf --> 0.164257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1214390\n",
      "\tspeed: 0.1193s/iter; left time: 2622.3446s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186189\n",
      "\tspeed: 0.0694s/iter; left time: 1517.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 223 | Train Loss: 0.1239646 Vali Loss: 0.1269783 Test Loss: 0.1358851\n",
      "Validation loss decreased (0.164257 --> 0.126978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1172384\n",
      "\tspeed: 0.1224s/iter; left time: 2663.5086s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076551\n",
      "\tspeed: 0.0691s/iter; left time: 1497.2145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1123203 Vali Loss: 0.1241126 Test Loss: 0.1345313\n",
      "Validation loss decreased (0.126978 --> 0.124113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1120366\n",
      "\tspeed: 0.1222s/iter; left time: 2630.9343s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102021\n",
      "\tspeed: 0.0710s/iter; left time: 1521.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 223 | Train Loss: 0.1094738 Vali Loss: 0.1237527 Test Loss: 0.1338149\n",
      "Validation loss decreased (0.124113 --> 0.123753).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105729\n",
      "\tspeed: 0.1208s/iter; left time: 2574.8094s\n",
      "\titers: 200, epoch: 5 | loss: 0.1061440\n",
      "\tspeed: 0.0692s/iter; left time: 1468.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1077770 Vali Loss: 0.1238218 Test Loss: 0.1339873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1095262\n",
      "\tspeed: 0.1194s/iter; left time: 2517.6188s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042345\n",
      "\tspeed: 0.0691s/iter; left time: 1451.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1063676 Vali Loss: 0.1235585 Test Loss: 0.1348094\n",
      "Validation loss decreased (0.123753 --> 0.123558).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005648\n",
      "\tspeed: 0.1203s/iter; left time: 2509.2368s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043318\n",
      "\tspeed: 0.0692s/iter; left time: 1436.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1052716 Vali Loss: 0.1240842 Test Loss: 0.1343348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054658\n",
      "\tspeed: 0.1199s/iter; left time: 2474.3814s\n",
      "\titers: 200, epoch: 8 | loss: 0.1059599\n",
      "\tspeed: 0.0693s/iter; left time: 1423.1761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1042885 Vali Loss: 0.1244867 Test Loss: 0.1349613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1038408\n",
      "\tspeed: 0.1191s/iter; left time: 2431.4259s\n",
      "\titers: 200, epoch: 9 | loss: 0.1002405\n",
      "\tspeed: 0.0691s/iter; left time: 1403.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1032768 Vali Loss: 0.1248526 Test Loss: 0.1349830\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0949917\n",
      "\tspeed: 0.1200s/iter; left time: 2424.1421s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013010\n",
      "\tspeed: 0.0691s/iter; left time: 1388.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1024455 Vali Loss: 0.1252553 Test Loss: 0.1358568\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1012795\n",
      "\tspeed: 0.1207s/iter; left time: 2410.1695s\n",
      "\titers: 200, epoch: 11 | loss: 0.1041970\n",
      "\tspeed: 0.0691s/iter; left time: 1372.8264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1017006 Vali Loss: 0.1258108 Test Loss: 0.1355357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0993979\n",
      "\tspeed: 0.1187s/iter; left time: 2344.6987s\n",
      "\titers: 200, epoch: 12 | loss: 0.1057732\n",
      "\tspeed: 0.0691s/iter; left time: 1358.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1009501 Vali Loss: 0.1261189 Test Loss: 0.1361108\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020337\n",
      "\tspeed: 0.1192s/iter; left time: 2328.0625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0951053\n",
      "\tspeed: 0.0692s/iter; left time: 1343.7230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1002808 Vali Loss: 0.1269347 Test Loss: 0.1376551\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966744\n",
      "\tspeed: 0.1189s/iter; left time: 2294.7735s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020604\n",
      "\tspeed: 0.0692s/iter; left time: 1328.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.0994902 Vali Loss: 0.1274046 Test Loss: 0.1371823\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0936168\n",
      "\tspeed: 0.1190s/iter; left time: 2270.1035s\n",
      "\titers: 200, epoch: 15 | loss: 0.0942707\n",
      "\tspeed: 0.0692s/iter; left time: 1312.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0989118 Vali Loss: 0.1278043 Test Loss: 0.1380977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0972000\n",
      "\tspeed: 0.1190s/iter; left time: 2244.6240s\n",
      "\titers: 200, epoch: 16 | loss: 0.1007343\n",
      "\tspeed: 0.0691s/iter; left time: 1296.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0983926 Vali Loss: 0.1279984 Test Loss: 0.1382564\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03949786722660065, rmse:0.19874070584774017, mae:0.1348094493150711, rse:0.7039555311203003\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588997\n",
      "\tspeed: 0.0746s/iter; left time: 1656.7000s\n",
      "\titers: 200, epoch: 1 | loss: 0.1519462\n",
      "\tspeed: 0.0692s/iter; left time: 1530.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 223 | Train Loss: 0.1616140 Vali Loss: 0.1641594 Test Loss: 0.1773060\n",
      "Validation loss decreased (inf --> 0.164159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1188093\n",
      "\tspeed: 0.1200s/iter; left time: 2638.3913s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157238\n",
      "\tspeed: 0.0692s/iter; left time: 1513.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1240953 Vali Loss: 0.1277020 Test Loss: 0.1362368\n",
      "Validation loss decreased (0.164159 --> 0.127702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1087447\n",
      "\tspeed: 0.1214s/iter; left time: 2640.9385s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102369\n",
      "\tspeed: 0.0692s/iter; left time: 1498.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1123339 Vali Loss: 0.1243157 Test Loss: 0.1344908\n",
      "Validation loss decreased (0.127702 --> 0.124316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040820\n",
      "\tspeed: 0.1211s/iter; left time: 2607.6138s\n",
      "\titers: 200, epoch: 4 | loss: 0.1147634\n",
      "\tspeed: 0.0691s/iter; left time: 1481.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1095129 Vali Loss: 0.1235023 Test Loss: 0.1340304\n",
      "Validation loss decreased (0.124316 --> 0.123502).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1062547\n",
      "\tspeed: 0.1199s/iter; left time: 2554.4991s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056936\n",
      "\tspeed: 0.0691s/iter; left time: 1464.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1076909 Vali Loss: 0.1228546 Test Loss: 0.1347191\n",
      "Validation loss decreased (0.123502 --> 0.122855).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1069995\n",
      "\tspeed: 0.1212s/iter; left time: 2556.1518s\n",
      "\titers: 200, epoch: 6 | loss: 0.1051202\n",
      "\tspeed: 0.0692s/iter; left time: 1451.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1062499 Vali Loss: 0.1232824 Test Loss: 0.1350140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1089477\n",
      "\tspeed: 0.1197s/iter; left time: 2497.3162s\n",
      "\titers: 200, epoch: 7 | loss: 0.1064909\n",
      "\tspeed: 0.0691s/iter; left time: 1434.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1049699 Vali Loss: 0.1233181 Test Loss: 0.1350354\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1094153\n",
      "\tspeed: 0.1181s/iter; left time: 2437.8416s\n",
      "\titers: 200, epoch: 8 | loss: 0.1034480\n",
      "\tspeed: 0.0691s/iter; left time: 1419.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1039009 Vali Loss: 0.1239157 Test Loss: 0.1360014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1056654\n",
      "\tspeed: 0.1205s/iter; left time: 2459.8758s\n",
      "\titers: 200, epoch: 9 | loss: 0.1067714\n",
      "\tspeed: 0.0691s/iter; left time: 1403.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1028753 Vali Loss: 0.1241723 Test Loss: 0.1362410\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1025408\n",
      "\tspeed: 0.1186s/iter; left time: 2394.6312s\n",
      "\titers: 200, epoch: 10 | loss: 0.1066732\n",
      "\tspeed: 0.0691s/iter; left time: 1388.5267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1018622 Vali Loss: 0.1249785 Test Loss: 0.1366130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0992114\n",
      "\tspeed: 0.1194s/iter; left time: 2384.6691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0965374\n",
      "\tspeed: 0.0694s/iter; left time: 1378.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1008964 Vali Loss: 0.1254471 Test Loss: 0.1377246\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1030749\n",
      "\tspeed: 0.1204s/iter; left time: 2378.5863s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003793\n",
      "\tspeed: 0.0694s/iter; left time: 1364.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1000783 Vali Loss: 0.1260959 Test Loss: 0.1375503\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1018916\n",
      "\tspeed: 0.1194s/iter; left time: 2330.8392s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990939\n",
      "\tspeed: 0.0691s/iter; left time: 1342.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0993299 Vali Loss: 0.1267395 Test Loss: 0.1381821\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967322\n",
      "\tspeed: 0.1191s/iter; left time: 2298.5401s\n",
      "\titers: 200, epoch: 14 | loss: 0.0990912\n",
      "\tspeed: 0.0691s/iter; left time: 1327.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0985874 Vali Loss: 0.1270754 Test Loss: 0.1382004\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0972180\n",
      "\tspeed: 0.1186s/iter; left time: 2263.4286s\n",
      "\titers: 200, epoch: 15 | loss: 0.0954075\n",
      "\tspeed: 0.0692s/iter; left time: 1312.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0980638 Vali Loss: 0.1273433 Test Loss: 0.1388922\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03948056325316429, rmse:0.19869716465473175, mae:0.13471922278404236, rse:0.7038013339042664\n",
      "Intermediate time for DE and pred_len 168: 00h:10m:01.92s\n",
      "Intermediate time for DE: 00h:47m:34.52s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1333680\n",
      "\tspeed: 0.0888s/iter; left time: 1980.9873s\n",
      "\titers: 200, epoch: 1 | loss: 0.1306122\n",
      "\tspeed: 0.0683s/iter; left time: 1515.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 224 | Train Loss: 0.1369647 Vali Loss: 0.1359312 Test Loss: 0.1559038\n",
      "Validation loss decreased (inf --> 0.135931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0914119\n",
      "\tspeed: 0.1171s/iter; left time: 2584.8234s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847467\n",
      "\tspeed: 0.0681s/iter; left time: 1496.7916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0923135 Vali Loss: 0.0929183 Test Loss: 0.1049555\n",
      "Validation loss decreased (0.135931 --> 0.092918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0800922\n",
      "\tspeed: 0.1174s/iter; left time: 2565.4313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858246\n",
      "\tspeed: 0.0681s/iter; left time: 1480.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0791665 Vali Loss: 0.0912677 Test Loss: 0.1042033\n",
      "Validation loss decreased (0.092918 --> 0.091268).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731348\n",
      "\tspeed: 0.1169s/iter; left time: 2528.4876s\n",
      "\titers: 200, epoch: 4 | loss: 0.0773949\n",
      "\tspeed: 0.0681s/iter; left time: 1466.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0772773 Vali Loss: 0.0907929 Test Loss: 0.1035567\n",
      "Validation loss decreased (0.091268 --> 0.090793).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722893\n",
      "\tspeed: 0.1167s/iter; left time: 2498.1122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0714369\n",
      "\tspeed: 0.0681s/iter; left time: 1450.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0761371 Vali Loss: 0.0896728 Test Loss: 0.1029171\n",
      "Validation loss decreased (0.090793 --> 0.089673).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774925\n",
      "\tspeed: 0.1166s/iter; left time: 2468.8454s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720026\n",
      "\tspeed: 0.0681s/iter; left time: 1435.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0753417 Vali Loss: 0.0894101 Test Loss: 0.1027032\n",
      "Validation loss decreased (0.089673 --> 0.089410).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0786619\n",
      "\tspeed: 0.1173s/iter; left time: 2457.3267s\n",
      "\titers: 200, epoch: 7 | loss: 0.0714008\n",
      "\tspeed: 0.0681s/iter; left time: 1420.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0747525 Vali Loss: 0.0894637 Test Loss: 0.1024739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758944\n",
      "\tspeed: 0.1173s/iter; left time: 2431.3588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728859\n",
      "\tspeed: 0.0681s/iter; left time: 1405.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0743224 Vali Loss: 0.0890427 Test Loss: 0.1023517\n",
      "Validation loss decreased (0.089410 --> 0.089043).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774943\n",
      "\tspeed: 0.1169s/iter; left time: 2396.5468s\n",
      "\titers: 200, epoch: 9 | loss: 0.0751756\n",
      "\tspeed: 0.0681s/iter; left time: 1389.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0738270 Vali Loss: 0.0888496 Test Loss: 0.1026962\n",
      "Validation loss decreased (0.089043 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0729855\n",
      "\tspeed: 0.1173s/iter; left time: 2378.8617s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749506\n",
      "\tspeed: 0.0681s/iter; left time: 1374.4904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0735145 Vali Loss: 0.0884768 Test Loss: 0.1022387\n",
      "Validation loss decreased (0.088850 --> 0.088477).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0703702\n",
      "\tspeed: 0.1176s/iter; left time: 2359.1218s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753163\n",
      "\tspeed: 0.0683s/iter; left time: 1362.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0731616 Vali Loss: 0.0884949 Test Loss: 0.1025441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0697689\n",
      "\tspeed: 0.1169s/iter; left time: 2319.5251s\n",
      "\titers: 200, epoch: 12 | loss: 0.0717288\n",
      "\tspeed: 0.0681s/iter; left time: 1343.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0729910 Vali Loss: 0.0885811 Test Loss: 0.1023816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769481\n",
      "\tspeed: 0.1164s/iter; left time: 2283.3286s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731467\n",
      "\tspeed: 0.0683s/iter; left time: 1332.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0726464 Vali Loss: 0.0884182 Test Loss: 0.1019948\n",
      "Validation loss decreased (0.088477 --> 0.088418).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0727538\n",
      "\tspeed: 0.1170s/iter; left time: 2269.4322s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745294\n",
      "\tspeed: 0.0680s/iter; left time: 1311.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0724863 Vali Loss: 0.0884307 Test Loss: 0.1020039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0743532\n",
      "\tspeed: 0.1165s/iter; left time: 2231.7804s\n",
      "\titers: 200, epoch: 15 | loss: 0.0696489\n",
      "\tspeed: 0.0683s/iter; left time: 1301.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0722417 Vali Loss: 0.0881380 Test Loss: 0.1021411\n",
      "Validation loss decreased (0.088418 --> 0.088138).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0769881\n",
      "\tspeed: 0.1170s/iter; left time: 2216.1289s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698817\n",
      "\tspeed: 0.0680s/iter; left time: 1282.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0721133 Vali Loss: 0.0881289 Test Loss: 0.1024259\n",
      "Validation loss decreased (0.088138 --> 0.088129).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659922\n",
      "\tspeed: 0.1169s/iter; left time: 2188.1816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688582\n",
      "\tspeed: 0.0683s/iter; left time: 1270.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0719713 Vali Loss: 0.0882590 Test Loss: 0.1025742\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732577\n",
      "\tspeed: 0.1169s/iter; left time: 2161.5882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0694320\n",
      "\tspeed: 0.0681s/iter; left time: 1252.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0717804 Vali Loss: 0.0882470 Test Loss: 0.1023746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679316\n",
      "\tspeed: 0.1165s/iter; left time: 2127.4974s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690580\n",
      "\tspeed: 0.0681s/iter; left time: 1237.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0716955 Vali Loss: 0.0879507 Test Loss: 0.1025331\n",
      "Validation loss decreased (0.088129 --> 0.087951).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747656\n",
      "\tspeed: 0.1189s/iter; left time: 2144.7055s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723538\n",
      "\tspeed: 0.0683s/iter; left time: 1225.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0715595 Vali Loss: 0.0880102 Test Loss: 0.1024311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0675295\n",
      "\tspeed: 0.1172s/iter; left time: 2088.5393s\n",
      "\titers: 200, epoch: 21 | loss: 0.0754626\n",
      "\tspeed: 0.0683s/iter; left time: 1210.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0714036 Vali Loss: 0.0880359 Test Loss: 0.1027101\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747559\n",
      "\tspeed: 0.1183s/iter; left time: 2081.4978s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735652\n",
      "\tspeed: 0.0686s/iter; left time: 1199.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0714004 Vali Loss: 0.0880514 Test Loss: 0.1024467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0726551\n",
      "\tspeed: 0.1188s/iter; left time: 2064.5593s\n",
      "\titers: 200, epoch: 23 | loss: 0.0736888\n",
      "\tspeed: 0.0685s/iter; left time: 1183.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0712337 Vali Loss: 0.0878681 Test Loss: 0.1021830\n",
      "Validation loss decreased (0.087951 --> 0.087868).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0731569\n",
      "\tspeed: 0.1173s/iter; left time: 2011.1946s\n",
      "\titers: 200, epoch: 24 | loss: 0.0654764\n",
      "\tspeed: 0.0682s/iter; left time: 1163.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0711718 Vali Loss: 0.0880312 Test Loss: 0.1023722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0753586\n",
      "\tspeed: 0.1162s/iter; left time: 1966.9141s\n",
      "\titers: 200, epoch: 25 | loss: 0.0715960\n",
      "\tspeed: 0.0683s/iter; left time: 1149.0157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0711529 Vali Loss: 0.0877999 Test Loss: 0.1024489\n",
      "Validation loss decreased (0.087868 --> 0.087800).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0729085\n",
      "\tspeed: 0.1171s/iter; left time: 1955.7698s\n",
      "\titers: 200, epoch: 26 | loss: 0.0663390\n",
      "\tspeed: 0.0681s/iter; left time: 1130.9998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0709616 Vali Loss: 0.0879779 Test Loss: 0.1026313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0700807\n",
      "\tspeed: 0.1165s/iter; left time: 1919.8403s\n",
      "\titers: 200, epoch: 27 | loss: 0.0744579\n",
      "\tspeed: 0.0681s/iter; left time: 1115.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0710200 Vali Loss: 0.0879474 Test Loss: 0.1024743\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0730878\n",
      "\tspeed: 0.1156s/iter; left time: 1878.7285s\n",
      "\titers: 200, epoch: 28 | loss: 0.0696250\n",
      "\tspeed: 0.0681s/iter; left time: 1099.6188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0708943 Vali Loss: 0.0878046 Test Loss: 0.1025338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729829\n",
      "\tspeed: 0.1160s/iter; left time: 1859.3250s\n",
      "\titers: 200, epoch: 29 | loss: 0.0762085\n",
      "\tspeed: 0.0681s/iter; left time: 1084.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0708806 Vali Loss: 0.0878422 Test Loss: 0.1025320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0690114\n",
      "\tspeed: 0.1164s/iter; left time: 1840.2345s\n",
      "\titers: 200, epoch: 30 | loss: 0.0681642\n",
      "\tspeed: 0.0681s/iter; left time: 1069.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0708473 Vali Loss: 0.0879095 Test Loss: 0.1024646\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0675929\n",
      "\tspeed: 0.1159s/iter; left time: 1805.7393s\n",
      "\titers: 200, epoch: 31 | loss: 0.0703068\n",
      "\tspeed: 0.0683s/iter; left time: 1057.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0707743 Vali Loss: 0.0877124 Test Loss: 0.1025452\n",
      "Validation loss decreased (0.087800 --> 0.087712).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0713335\n",
      "\tspeed: 0.1181s/iter; left time: 1813.2451s\n",
      "\titers: 200, epoch: 32 | loss: 0.0659095\n",
      "\tspeed: 0.0681s/iter; left time: 1038.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0708065 Vali Loss: 0.0878161 Test Loss: 0.1026590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0685042\n",
      "\tspeed: 0.1154s/iter; left time: 1746.8283s\n",
      "\titers: 200, epoch: 33 | loss: 0.0746160\n",
      "\tspeed: 0.0682s/iter; left time: 1025.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0707395 Vali Loss: 0.0878438 Test Loss: 0.1025891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687872\n",
      "\tspeed: 0.1167s/iter; left time: 1739.5423s\n",
      "\titers: 200, epoch: 34 | loss: 0.0705506\n",
      "\tspeed: 0.0681s/iter; left time: 1008.0078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0707021 Vali Loss: 0.0877845 Test Loss: 0.1025829\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705029\n",
      "\tspeed: 0.1164s/iter; left time: 1710.0465s\n",
      "\titers: 200, epoch: 35 | loss: 0.0674875\n",
      "\tspeed: 0.0681s/iter; left time: 993.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0707380 Vali Loss: 0.0878009 Test Loss: 0.1025980\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0722462\n",
      "\tspeed: 0.1161s/iter; left time: 1678.9166s\n",
      "\titers: 200, epoch: 36 | loss: 0.0744660\n",
      "\tspeed: 0.0681s/iter; left time: 977.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0707073 Vali Loss: 0.0878338 Test Loss: 0.1025811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0681205\n",
      "\tspeed: 0.1160s/iter; left time: 1652.0876s\n",
      "\titers: 200, epoch: 37 | loss: 0.0667671\n",
      "\tspeed: 0.0681s/iter; left time: 962.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0706651 Vali Loss: 0.0877007 Test Loss: 0.1025965\n",
      "Validation loss decreased (0.087712 --> 0.087701).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0699443\n",
      "\tspeed: 0.1170s/iter; left time: 1639.0840s\n",
      "\titers: 200, epoch: 38 | loss: 0.0756920\n",
      "\tspeed: 0.0681s/iter; left time: 947.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0705406 Vali Loss: 0.0878251 Test Loss: 0.1026505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0680239\n",
      "\tspeed: 0.1161s/iter; left time: 1600.7003s\n",
      "\titers: 200, epoch: 39 | loss: 0.0739465\n",
      "\tspeed: 0.0683s/iter; left time: 935.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0705888 Vali Loss: 0.0879452 Test Loss: 0.1026051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0695183\n",
      "\tspeed: 0.1158s/iter; left time: 1571.4075s\n",
      "\titers: 200, epoch: 40 | loss: 0.0666538\n",
      "\tspeed: 0.0681s/iter; left time: 917.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0706275 Vali Loss: 0.0877649 Test Loss: 0.1026028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0692699\n",
      "\tspeed: 0.1162s/iter; left time: 1549.9471s\n",
      "\titers: 200, epoch: 41 | loss: 0.0674599\n",
      "\tspeed: 0.0685s/iter; left time: 906.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0706151 Vali Loss: 0.0878319 Test Loss: 0.1026039\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0714812\n",
      "\tspeed: 0.1163s/iter; left time: 1525.8277s\n",
      "\titers: 200, epoch: 42 | loss: 0.0698971\n",
      "\tspeed: 0.0681s/iter; left time: 886.1202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0706012 Vali Loss: 0.0877543 Test Loss: 0.1026634\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0722987\n",
      "\tspeed: 0.1180s/iter; left time: 1521.8007s\n",
      "\titers: 200, epoch: 43 | loss: 0.0705802\n",
      "\tspeed: 0.0681s/iter; left time: 871.2431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705847 Vali Loss: 0.0877952 Test Loss: 0.1026460\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0699486\n",
      "\tspeed: 0.1177s/iter; left time: 1490.5583s\n",
      "\titers: 200, epoch: 44 | loss: 0.0705507\n",
      "\tspeed: 0.0682s/iter; left time: 857.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705450 Vali Loss: 0.0878588 Test Loss: 0.1026352\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0747878\n",
      "\tspeed: 0.1161s/iter; left time: 1444.6048s\n",
      "\titers: 200, epoch: 45 | loss: 0.0717317\n",
      "\tspeed: 0.0682s/iter; left time: 841.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0705373 Vali Loss: 0.0876339 Test Loss: 0.1025996\n",
      "Validation loss decreased (0.087701 --> 0.087634).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0752051\n",
      "\tspeed: 0.1168s/iter; left time: 1427.5335s\n",
      "\titers: 200, epoch: 46 | loss: 0.0732657\n",
      "\tspeed: 0.0683s/iter; left time: 827.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705972 Vali Loss: 0.0877636 Test Loss: 0.1026519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0670457\n",
      "\tspeed: 0.1167s/iter; left time: 1400.1929s\n",
      "\titers: 200, epoch: 47 | loss: 0.0690192\n",
      "\tspeed: 0.0682s/iter; left time: 810.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0705293 Vali Loss: 0.0877585 Test Loss: 0.1026266\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0698591\n",
      "\tspeed: 0.1162s/iter; left time: 1368.0350s\n",
      "\titers: 200, epoch: 48 | loss: 0.0677563\n",
      "\tspeed: 0.0681s/iter; left time: 794.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0705553 Vali Loss: 0.0878443 Test Loss: 0.1026310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700425\n",
      "\tspeed: 0.1159s/iter; left time: 1338.1389s\n",
      "\titers: 200, epoch: 49 | loss: 0.0663642\n",
      "\tspeed: 0.0683s/iter; left time: 781.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0705249 Vali Loss: 0.0877746 Test Loss: 0.1026161\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0729307\n",
      "\tspeed: 0.1162s/iter; left time: 1316.4437s\n",
      "\titers: 200, epoch: 50 | loss: 0.0685636\n",
      "\tspeed: 0.0683s/iter; left time: 767.1826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0705094 Vali Loss: 0.0878694 Test Loss: 0.1026199\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0732157\n",
      "\tspeed: 0.1163s/iter; left time: 1291.0775s\n",
      "\titers: 200, epoch: 51 | loss: 0.0650010\n",
      "\tspeed: 0.0682s/iter; left time: 749.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0705308 Vali Loss: 0.0877515 Test Loss: 0.1026408\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707113\n",
      "\tspeed: 0.1155s/iter; left time: 1256.6665s\n",
      "\titers: 200, epoch: 52 | loss: 0.0763716\n",
      "\tspeed: 0.0681s/iter; left time: 733.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0705010 Vali Loss: 0.0877244 Test Loss: 0.1026250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0712100\n",
      "\tspeed: 0.1159s/iter; left time: 1235.0412s\n",
      "\titers: 200, epoch: 53 | loss: 0.0675191\n",
      "\tspeed: 0.0681s/iter; left time: 718.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0705063 Vali Loss: 0.0877397 Test Loss: 0.1026659\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0707961\n",
      "\tspeed: 0.1174s/iter; left time: 1224.0732s\n",
      "\titers: 200, epoch: 54 | loss: 0.0701372\n",
      "\tspeed: 0.0685s/iter; left time: 707.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0704876 Vali Loss: 0.0878127 Test Loss: 0.1026263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0696509\n",
      "\tspeed: 0.1187s/iter; left time: 1211.0421s\n",
      "\titers: 200, epoch: 55 | loss: 0.0660280\n",
      "\tspeed: 0.0685s/iter; left time: 692.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.0704608 Vali Loss: 0.0878102 Test Loss: 0.1026641\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02609824575483799, rmse:0.16154950857162476, mae:0.10259955376386642, rse:0.5573000311851501\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1350485\n",
      "\tspeed: 0.0704s/iter; left time: 1569.2453s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283367\n",
      "\tspeed: 0.0686s/iter; left time: 1523.3137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1371332 Vali Loss: 0.1359186 Test Loss: 0.1564243\n",
      "Validation loss decreased (inf --> 0.135919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0985610\n",
      "\tspeed: 0.1199s/iter; left time: 2648.1026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824623\n",
      "\tspeed: 0.0685s/iter; left time: 1504.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0930008 Vali Loss: 0.0932679 Test Loss: 0.1046689\n",
      "Validation loss decreased (0.135919 --> 0.093268).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804342\n",
      "\tspeed: 0.1198s/iter; left time: 2618.8854s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779750\n",
      "\tspeed: 0.0685s/iter; left time: 1490.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0793289 Vali Loss: 0.0914860 Test Loss: 0.1031895\n",
      "Validation loss decreased (0.093268 --> 0.091486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806159\n",
      "\tspeed: 0.1188s/iter; left time: 2570.4593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749596\n",
      "\tspeed: 0.0685s/iter; left time: 1474.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0774207 Vali Loss: 0.0906169 Test Loss: 0.1029897\n",
      "Validation loss decreased (0.091486 --> 0.090617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734674\n",
      "\tspeed: 0.1187s/iter; left time: 2540.1744s\n",
      "\titers: 200, epoch: 5 | loss: 0.0709467\n",
      "\tspeed: 0.0682s/iter; left time: 1453.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0763811 Vali Loss: 0.0900442 Test Loss: 0.1027449\n",
      "Validation loss decreased (0.090617 --> 0.090044).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0769009\n",
      "\tspeed: 0.1191s/iter; left time: 2522.2977s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798781\n",
      "\tspeed: 0.0687s/iter; left time: 1447.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0755034 Vali Loss: 0.0893161 Test Loss: 0.1025999\n",
      "Validation loss decreased (0.090044 --> 0.089316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748013\n",
      "\tspeed: 0.1195s/iter; left time: 2503.5218s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699343\n",
      "\tspeed: 0.0685s/iter; left time: 1428.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0749898 Vali Loss: 0.0891517 Test Loss: 0.1022313\n",
      "Validation loss decreased (0.089316 --> 0.089152).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0731926\n",
      "\tspeed: 0.1191s/iter; left time: 2469.1667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763248\n",
      "\tspeed: 0.0681s/iter; left time: 1406.0134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0744346 Vali Loss: 0.0888427 Test Loss: 0.1025807\n",
      "Validation loss decreased (0.089152 --> 0.088843).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749135\n",
      "\tspeed: 0.1190s/iter; left time: 2439.6769s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725394\n",
      "\tspeed: 0.0686s/iter; left time: 1399.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0740005 Vali Loss: 0.0889117 Test Loss: 0.1022311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735895\n",
      "\tspeed: 0.1182s/iter; left time: 2398.2413s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685794\n",
      "\tspeed: 0.0685s/iter; left time: 1381.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0736818 Vali Loss: 0.0882763 Test Loss: 0.1021831\n",
      "Validation loss decreased (0.088843 --> 0.088276).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0686587\n",
      "\tspeed: 0.1188s/iter; left time: 2383.4469s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753800\n",
      "\tspeed: 0.0685s/iter; left time: 1366.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0733869 Vali Loss: 0.0885128 Test Loss: 0.1024305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0699067\n",
      "\tspeed: 0.1183s/iter; left time: 2347.2859s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729937\n",
      "\tspeed: 0.0685s/iter; left time: 1352.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0730673 Vali Loss: 0.0883502 Test Loss: 0.1023613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0723066\n",
      "\tspeed: 0.1181s/iter; left time: 2317.2114s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696954\n",
      "\tspeed: 0.0685s/iter; left time: 1337.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0728639 Vali Loss: 0.0880580 Test Loss: 0.1021787\n",
      "Validation loss decreased (0.088276 --> 0.088058).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0684518\n",
      "\tspeed: 0.1194s/iter; left time: 2315.5890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723450\n",
      "\tspeed: 0.0685s/iter; left time: 1321.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0726623 Vali Loss: 0.0878234 Test Loss: 0.1023084\n",
      "Validation loss decreased (0.088058 --> 0.087823).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0754770\n",
      "\tspeed: 0.1187s/iter; left time: 2273.9481s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705056\n",
      "\tspeed: 0.0685s/iter; left time: 1305.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0723844 Vali Loss: 0.0882556 Test Loss: 0.1023628\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741688\n",
      "\tspeed: 0.1181s/iter; left time: 2237.4073s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731742\n",
      "\tspeed: 0.0687s/iter; left time: 1293.9790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.0722727 Vali Loss: 0.0880262 Test Loss: 0.1020618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704471\n",
      "\tspeed: 0.1202s/iter; left time: 2249.0798s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648888\n",
      "\tspeed: 0.0688s/iter; left time: 1281.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.98s\n",
      "Steps: 224 | Train Loss: 0.0721046 Vali Loss: 0.0878210 Test Loss: 0.1022013\n",
      "Validation loss decreased (0.087823 --> 0.087821).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0698321\n",
      "\tspeed: 0.3378s/iter; left time: 6246.4706s\n",
      "\titers: 200, epoch: 18 | loss: 0.0738711\n",
      "\tspeed: 0.0691s/iter; left time: 1271.8617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.22s\n",
      "Steps: 224 | Train Loss: 0.0719306 Vali Loss: 0.0880854 Test Loss: 0.1021067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720899\n",
      "\tspeed: 0.1193s/iter; left time: 2178.8884s\n",
      "\titers: 200, epoch: 19 | loss: 0.0801290\n",
      "\tspeed: 0.0685s/iter; left time: 1244.6685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.0718406 Vali Loss: 0.0880833 Test Loss: 0.1023844\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720547\n",
      "\tspeed: 0.1183s/iter; left time: 2135.5429s\n",
      "\titers: 200, epoch: 20 | loss: 0.0702580\n",
      "\tspeed: 0.0683s/iter; left time: 1225.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0717006 Vali Loss: 0.0878402 Test Loss: 0.1021511\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0730690\n",
      "\tspeed: 0.1192s/iter; left time: 2124.3285s\n",
      "\titers: 200, epoch: 21 | loss: 0.0687931\n",
      "\tspeed: 0.0683s/iter; left time: 1210.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0716337 Vali Loss: 0.0878857 Test Loss: 0.1023159\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0694852\n",
      "\tspeed: 0.1197s/iter; left time: 2106.9395s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696693\n",
      "\tspeed: 0.0685s/iter; left time: 1198.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.0714591 Vali Loss: 0.0878322 Test Loss: 0.1021257\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0696523\n",
      "\tspeed: 0.1184s/iter; left time: 2057.1705s\n",
      "\titers: 200, epoch: 23 | loss: 0.0666929\n",
      "\tspeed: 0.0687s/iter; left time: 1186.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0714148 Vali Loss: 0.0878777 Test Loss: 0.1024495\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0707410\n",
      "\tspeed: 0.1182s/iter; left time: 2027.5832s\n",
      "\titers: 200, epoch: 24 | loss: 0.0696989\n",
      "\tspeed: 0.0686s/iter; left time: 1168.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0713207 Vali Loss: 0.0879480 Test Loss: 0.1023523\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0666071\n",
      "\tspeed: 0.1201s/iter; left time: 2033.0903s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697921\n",
      "\tspeed: 0.0686s/iter; left time: 1154.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0712574 Vali Loss: 0.0878814 Test Loss: 0.1024345\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0692760\n",
      "\tspeed: 0.1190s/iter; left time: 1986.8559s\n",
      "\titers: 200, epoch: 26 | loss: 0.0700209\n",
      "\tspeed: 0.0682s/iter; left time: 1132.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0711826 Vali Loss: 0.0878382 Test Loss: 0.1024064\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0691675\n",
      "\tspeed: 0.1180s/iter; left time: 1944.3105s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724144\n",
      "\tspeed: 0.0686s/iter; left time: 1123.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0711065 Vali Loss: 0.0878209 Test Loss: 0.1023688\n",
      "Validation loss decreased (0.087821 --> 0.087821).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0745372\n",
      "\tspeed: 0.1227s/iter; left time: 1994.7667s\n",
      "\titers: 200, epoch: 28 | loss: 0.0677864\n",
      "\tspeed: 0.0685s/iter; left time: 1107.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.0710921 Vali Loss: 0.0877655 Test Loss: 0.1024723\n",
      "Validation loss decreased (0.087821 --> 0.087765).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0683585\n",
      "\tspeed: 0.1193s/iter; left time: 1912.0059s\n",
      "\titers: 200, epoch: 29 | loss: 0.0687528\n",
      "\tspeed: 0.0683s/iter; left time: 1088.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0710071 Vali Loss: 0.0878820 Test Loss: 0.1025295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0688418\n",
      "\tspeed: 0.1184s/iter; left time: 1872.0666s\n",
      "\titers: 200, epoch: 30 | loss: 0.0696204\n",
      "\tspeed: 0.0684s/iter; left time: 1074.3598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0709781 Vali Loss: 0.0878687 Test Loss: 0.1024631\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0681575\n",
      "\tspeed: 0.1190s/iter; left time: 1853.9655s\n",
      "\titers: 200, epoch: 31 | loss: 0.0685834\n",
      "\tspeed: 0.0681s/iter; left time: 1054.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0709512 Vali Loss: 0.0877548 Test Loss: 0.1024851\n",
      "Validation loss decreased (0.087765 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0706097\n",
      "\tspeed: 0.1185s/iter; left time: 1819.6040s\n",
      "\titers: 200, epoch: 32 | loss: 0.0708976\n",
      "\tspeed: 0.0684s/iter; left time: 1043.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0709215 Vali Loss: 0.0878163 Test Loss: 0.1024806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0749903\n",
      "\tspeed: 0.1187s/iter; left time: 1796.5819s\n",
      "\titers: 200, epoch: 33 | loss: 0.0708938\n",
      "\tspeed: 0.0694s/iter; left time: 1043.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 224 | Train Loss: 0.0708929 Vali Loss: 0.0878683 Test Loss: 0.1023930\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0706175\n",
      "\tspeed: 0.1176s/iter; left time: 1753.4913s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725679\n",
      "\tspeed: 0.0681s/iter; left time: 1008.2804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0708099 Vali Loss: 0.0878590 Test Loss: 0.1025046\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732726\n",
      "\tspeed: 0.1176s/iter; left time: 1726.7687s\n",
      "\titers: 200, epoch: 35 | loss: 0.0754984\n",
      "\tspeed: 0.0681s/iter; left time: 993.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:16.92s\n",
      "Steps: 224 | Train Loss: 0.0708670 Vali Loss: 0.0877823 Test Loss: 0.1024617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0774366\n",
      "\tspeed: 0.2177s/iter; left time: 3147.5712s\n",
      "\titers: 200, epoch: 36 | loss: 0.0740482\n",
      "\tspeed: 0.0682s/iter; left time: 978.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:16.04s\n",
      "Steps: 224 | Train Loss: 0.0708381 Vali Loss: 0.0878741 Test Loss: 0.1024432\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0760511\n",
      "\tspeed: 0.1696s/iter; left time: 2415.1887s\n",
      "\titers: 200, epoch: 37 | loss: 0.0682933\n",
      "\tspeed: 0.1863s/iter; left time: 2633.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:35.32s\n",
      "Steps: 224 | Train Loss: 0.0707611 Vali Loss: 0.0878462 Test Loss: 0.1025407\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0697511\n",
      "\tspeed: 0.1913s/iter; left time: 2680.5915s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706254\n",
      "\tspeed: 0.0718s/iter; left time: 998.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 224 | Train Loss: 0.0708227 Vali Loss: 0.0878476 Test Loss: 0.1025691\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0684740\n",
      "\tspeed: 0.1177s/iter; left time: 1622.8936s\n",
      "\titers: 200, epoch: 39 | loss: 0.0708653\n",
      "\tspeed: 0.0680s/iter; left time: 931.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0707966 Vali Loss: 0.0878813 Test Loss: 0.1024478\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0717423\n",
      "\tspeed: 0.1179s/iter; left time: 1599.3272s\n",
      "\titers: 200, epoch: 40 | loss: 0.0685868\n",
      "\tspeed: 0.0680s/iter; left time: 915.0396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0707911 Vali Loss: 0.0877578 Test Loss: 0.1024289\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0677724\n",
      "\tspeed: 0.1179s/iter; left time: 1573.0796s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708079\n",
      "\tspeed: 0.0687s/iter; left time: 910.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0707299 Vali Loss: 0.0878519 Test Loss: 0.1024545\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025986187160015106, rmse:0.1612023115158081, mae:0.10248507559299469, rse:0.5561022758483887\n",
      "Intermediate time for GB and pred_len 24: 00h:30m:54.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1405991\n",
      "\tspeed: 0.0894s/iter; left time: 1994.2111s\n",
      "\titers: 200, epoch: 1 | loss: 0.1340275\n",
      "\tspeed: 0.0687s/iter; left time: 1524.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 224 | Train Loss: 0.1448432 Vali Loss: 0.1478213 Test Loss: 0.1730928\n",
      "Validation loss decreased (inf --> 0.147821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138117\n",
      "\tspeed: 0.1213s/iter; left time: 2678.6025s\n",
      "\titers: 200, epoch: 2 | loss: 0.1045887\n",
      "\tspeed: 0.0686s/iter; left time: 1507.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.1130604 Vali Loss: 0.1190637 Test Loss: 0.1405119\n",
      "Validation loss decreased (0.147821 --> 0.119064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055495\n",
      "\tspeed: 0.1203s/iter; left time: 2627.9081s\n",
      "\titers: 200, epoch: 3 | loss: 0.0997061\n",
      "\tspeed: 0.0686s/iter; left time: 1492.3047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1032594 Vali Loss: 0.1175504 Test Loss: 0.1404777\n",
      "Validation loss decreased (0.119064 --> 0.117550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0996446\n",
      "\tspeed: 0.1195s/iter; left time: 2583.9106s\n",
      "\titers: 200, epoch: 4 | loss: 0.1002228\n",
      "\tspeed: 0.0687s/iter; left time: 1479.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1012278 Vali Loss: 0.1170777 Test Loss: 0.1409550\n",
      "Validation loss decreased (0.117550 --> 0.117078).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005896\n",
      "\tspeed: 0.1204s/iter; left time: 2577.1258s\n",
      "\titers: 200, epoch: 5 | loss: 0.1019444\n",
      "\tspeed: 0.0705s/iter; left time: 1501.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 224 | Train Loss: 0.0999217 Vali Loss: 0.1165160 Test Loss: 0.1420076\n",
      "Validation loss decreased (0.117078 --> 0.116516).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982100\n",
      "\tspeed: 0.1232s/iter; left time: 2609.0948s\n",
      "\titers: 200, epoch: 6 | loss: 0.1017919\n",
      "\tspeed: 0.0685s/iter; left time: 1444.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 224 | Train Loss: 0.0987352 Vali Loss: 0.1165895 Test Loss: 0.1424067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0939507\n",
      "\tspeed: 0.1228s/iter; left time: 2573.0127s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043875\n",
      "\tspeed: 0.0686s/iter; left time: 1430.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0976624 Vali Loss: 0.1166685 Test Loss: 0.1426034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960657\n",
      "\tspeed: 0.1201s/iter; left time: 2490.8351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0936981\n",
      "\tspeed: 0.0686s/iter; left time: 1415.1463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0965947 Vali Loss: 0.1169973 Test Loss: 0.1427235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0966231\n",
      "\tspeed: 0.1194s/iter; left time: 2448.7314s\n",
      "\titers: 200, epoch: 9 | loss: 0.0959772\n",
      "\tspeed: 0.0687s/iter; left time: 1401.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0956147 Vali Loss: 0.1171770 Test Loss: 0.1436713\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0897570\n",
      "\tspeed: 0.1188s/iter; left time: 2410.0226s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925299\n",
      "\tspeed: 0.0685s/iter; left time: 1382.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0947032 Vali Loss: 0.1173011 Test Loss: 0.1430885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937624\n",
      "\tspeed: 0.1179s/iter; left time: 2365.5809s\n",
      "\titers: 200, epoch: 11 | loss: 0.0942345\n",
      "\tspeed: 0.0687s/iter; left time: 1371.6999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0939199 Vali Loss: 0.1177284 Test Loss: 0.1446626\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0962773\n",
      "\tspeed: 0.1184s/iter; left time: 2348.8117s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923434\n",
      "\tspeed: 0.0687s/iter; left time: 1355.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0932281 Vali Loss: 0.1179432 Test Loss: 0.1441796\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0915588\n",
      "\tspeed: 0.1190s/iter; left time: 2334.1176s\n",
      "\titers: 200, epoch: 13 | loss: 0.0947063\n",
      "\tspeed: 0.0685s/iter; left time: 1336.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0925696 Vali Loss: 0.1184001 Test Loss: 0.1446941\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0948453\n",
      "\tspeed: 0.1207s/iter; left time: 2340.5900s\n",
      "\titers: 200, epoch: 14 | loss: 0.0923975\n",
      "\tspeed: 0.0688s/iter; left time: 1327.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0918646 Vali Loss: 0.1180691 Test Loss: 0.1447409\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889596\n",
      "\tspeed: 0.1223s/iter; left time: 2343.2314s\n",
      "\titers: 200, epoch: 15 | loss: 0.0921152\n",
      "\tspeed: 0.0687s/iter; left time: 1309.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0913107 Vali Loss: 0.1185684 Test Loss: 0.1451798\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04291575402021408, rmse:0.20716117322444916, mae:0.14200760424137115, rse:0.7163922190666199\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487318\n",
      "\tspeed: 0.0704s/iter; left time: 1570.4113s\n",
      "\titers: 200, epoch: 1 | loss: 0.1370086\n",
      "\tspeed: 0.0686s/iter; left time: 1522.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1440499 Vali Loss: 0.1468293 Test Loss: 0.1719950\n",
      "Validation loss decreased (inf --> 0.146829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138063\n",
      "\tspeed: 0.1286s/iter; left time: 2838.4423s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064841\n",
      "\tspeed: 0.1335s/iter; left time: 2934.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.05s\n",
      "Steps: 224 | Train Loss: 0.1139268 Vali Loss: 0.1199203 Test Loss: 0.1413460\n",
      "Validation loss decreased (0.146829 --> 0.119920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1038082\n",
      "\tspeed: 0.1272s/iter; left time: 2780.0861s\n",
      "\titers: 200, epoch: 3 | loss: 0.1057726\n",
      "\tspeed: 0.0703s/iter; left time: 1529.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 224 | Train Loss: 0.1035078 Vali Loss: 0.1172815 Test Loss: 0.1411853\n",
      "Validation loss decreased (0.119920 --> 0.117282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1052683\n",
      "\tspeed: 0.2809s/iter; left time: 6075.1382s\n",
      "\titers: 200, epoch: 4 | loss: 0.0991758\n",
      "\tspeed: 0.2453s/iter; left time: 5281.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 224 | Train Loss: 0.1012741 Vali Loss: 0.1170539 Test Loss: 0.1416775\n",
      "Validation loss decreased (0.117282 --> 0.117054).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1004815\n",
      "\tspeed: 0.8175s/iter; left time: 17498.1451s\n",
      "\titers: 200, epoch: 5 | loss: 0.0980172\n",
      "\tspeed: 0.2404s/iter; left time: 5122.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.31s\n",
      "Steps: 224 | Train Loss: 0.0997677 Vali Loss: 0.1162018 Test Loss: 0.1421025\n",
      "Validation loss decreased (0.117054 --> 0.116202).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961827\n",
      "\tspeed: 0.8096s/iter; left time: 17147.9534s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999542\n",
      "\tspeed: 0.2562s/iter; left time: 5400.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.70s\n",
      "Steps: 224 | Train Loss: 0.0984421 Vali Loss: 0.1164734 Test Loss: 0.1426005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0981211\n",
      "\tspeed: 0.6218s/iter; left time: 13030.5121s\n",
      "\titers: 200, epoch: 7 | loss: 0.0941548\n",
      "\tspeed: 0.0852s/iter; left time: 1776.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.08s\n",
      "Steps: 224 | Train Loss: 0.0972705 Vali Loss: 0.1162785 Test Loss: 0.1422600\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0962675\n",
      "\tspeed: 0.1340s/iter; left time: 2778.7869s\n",
      "\titers: 200, epoch: 8 | loss: 0.0931595\n",
      "\tspeed: 0.0697s/iter; left time: 1438.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 224 | Train Loss: 0.0962770 Vali Loss: 0.1164722 Test Loss: 0.1422352\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0926272\n",
      "\tspeed: 0.1242s/iter; left time: 2546.9365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0948652\n",
      "\tspeed: 0.0695s/iter; left time: 1418.0947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 224 | Train Loss: 0.0952981 Vali Loss: 0.1172631 Test Loss: 0.1434910\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920814\n",
      "\tspeed: 0.1228s/iter; left time: 2491.7438s\n",
      "\titers: 200, epoch: 10 | loss: 0.0969522\n",
      "\tspeed: 0.0693s/iter; left time: 1398.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 224 | Train Loss: 0.0944917 Vali Loss: 0.1168175 Test Loss: 0.1432077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0946180\n",
      "\tspeed: 0.1229s/iter; left time: 2465.5769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0920481\n",
      "\tspeed: 0.0695s/iter; left time: 1387.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 224 | Train Loss: 0.0936815 Vali Loss: 0.1166289 Test Loss: 0.1433958\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0943805\n",
      "\tspeed: 0.1222s/iter; left time: 2423.8897s\n",
      "\titers: 200, epoch: 12 | loss: 0.0935987\n",
      "\tspeed: 0.0692s/iter; left time: 1364.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.0930455 Vali Loss: 0.1179340 Test Loss: 0.1440605\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0935798\n",
      "\tspeed: 0.1215s/iter; left time: 2383.7646s\n",
      "\titers: 200, epoch: 13 | loss: 0.0908417\n",
      "\tspeed: 0.0690s/iter; left time: 1347.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 224 | Train Loss: 0.0923338 Vali Loss: 0.1177619 Test Loss: 0.1443216\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884786\n",
      "\tspeed: 0.1203s/iter; left time: 2333.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0921750\n",
      "\tspeed: 0.0691s/iter; left time: 1333.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.0917843 Vali Loss: 0.1178600 Test Loss: 0.1436017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0891715\n",
      "\tspeed: 0.1201s/iter; left time: 2301.0858s\n",
      "\titers: 200, epoch: 15 | loss: 0.0895614\n",
      "\tspeed: 0.0689s/iter; left time: 1313.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.0912016 Vali Loss: 0.1195128 Test Loss: 0.1452190\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04321127384901047, rmse:0.20787321031093597, mae:0.14210249483585358, rse:0.718854546546936\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:10.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1382906\n",
      "\tspeed: 0.0873s/iter; left time: 1939.0829s\n",
      "\titers: 200, epoch: 1 | loss: 0.1395264\n",
      "\tspeed: 0.0694s/iter; left time: 1534.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.1463332 Vali Loss: 0.1503430 Test Loss: 0.1766358\n",
      "Validation loss decreased (inf --> 0.150343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1166224\n",
      "\tspeed: 0.1210s/iter; left time: 2659.6390s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143445\n",
      "\tspeed: 0.0693s/iter; left time: 1515.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 223 | Train Loss: 0.1172942 Vali Loss: 0.1232760 Test Loss: 0.1470696\n",
      "Validation loss decreased (0.150343 --> 0.123276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1106884\n",
      "\tspeed: 0.1217s/iter; left time: 2647.4163s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059793\n",
      "\tspeed: 0.0693s/iter; left time: 1500.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1077958 Vali Loss: 0.1214558 Test Loss: 0.1481016\n",
      "Validation loss decreased (0.123276 --> 0.121456).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1101232\n",
      "\tspeed: 0.1220s/iter; left time: 2625.9509s\n",
      "\titers: 200, epoch: 4 | loss: 0.1033802\n",
      "\tspeed: 0.0693s/iter; left time: 1485.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1054731 Vali Loss: 0.1212433 Test Loss: 0.1480350\n",
      "Validation loss decreased (0.121456 --> 0.121243).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1055346\n",
      "\tspeed: 0.1208s/iter; left time: 2573.2861s\n",
      "\titers: 200, epoch: 5 | loss: 0.1031732\n",
      "\tspeed: 0.0692s/iter; left time: 1467.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1035302 Vali Loss: 0.1213536 Test Loss: 0.1497387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046123\n",
      "\tspeed: 0.1209s/iter; left time: 2549.2983s\n",
      "\titers: 200, epoch: 6 | loss: 0.1001897\n",
      "\tspeed: 0.0691s/iter; left time: 1450.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1017962 Vali Loss: 0.1209992 Test Loss: 0.1488341\n",
      "Validation loss decreased (0.121243 --> 0.120999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0978718\n",
      "\tspeed: 0.1242s/iter; left time: 2591.1679s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973325\n",
      "\tspeed: 0.0692s/iter; left time: 1437.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.1003711 Vali Loss: 0.1218036 Test Loss: 0.1504623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0989455\n",
      "\tspeed: 0.1191s/iter; left time: 2458.1201s\n",
      "\titers: 200, epoch: 8 | loss: 0.1002991\n",
      "\tspeed: 0.0693s/iter; left time: 1422.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.0990875 Vali Loss: 0.1218348 Test Loss: 0.1500351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0976945\n",
      "\tspeed: 0.1187s/iter; left time: 2422.8535s\n",
      "\titers: 200, epoch: 9 | loss: 0.0966081\n",
      "\tspeed: 0.0691s/iter; left time: 1404.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0978859 Vali Loss: 0.1225475 Test Loss: 0.1525755\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0926314\n",
      "\tspeed: 0.1191s/iter; left time: 2405.5362s\n",
      "\titers: 200, epoch: 10 | loss: 0.0951924\n",
      "\tspeed: 0.0691s/iter; left time: 1389.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0968670 Vali Loss: 0.1221416 Test Loss: 0.1514783\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0938441\n",
      "\tspeed: 0.1191s/iter; left time: 2378.9691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0952162\n",
      "\tspeed: 0.0695s/iter; left time: 1380.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0958730 Vali Loss: 0.1224927 Test Loss: 0.1522670\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0958836\n",
      "\tspeed: 0.1193s/iter; left time: 2355.6395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0952033\n",
      "\tspeed: 0.0692s/iter; left time: 1360.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0949836 Vali Loss: 0.1231256 Test Loss: 0.1527645\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0955233\n",
      "\tspeed: 0.1200s/iter; left time: 2343.5379s\n",
      "\titers: 200, epoch: 13 | loss: 0.0914457\n",
      "\tspeed: 0.0693s/iter; left time: 1346.2415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0941686 Vali Loss: 0.1234475 Test Loss: 0.1532591\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0911015\n",
      "\tspeed: 0.1193s/iter; left time: 2301.7760s\n",
      "\titers: 200, epoch: 14 | loss: 0.0922876\n",
      "\tspeed: 0.0691s/iter; left time: 1327.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0934280 Vali Loss: 0.1233402 Test Loss: 0.1538700\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0898075\n",
      "\tspeed: 0.1189s/iter; left time: 2267.6586s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903602\n",
      "\tspeed: 0.0692s/iter; left time: 1313.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.0927919 Vali Loss: 0.1235200 Test Loss: 0.1532498\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0931074\n",
      "\tspeed: 0.1192s/iter; left time: 2247.1640s\n",
      "\titers: 200, epoch: 16 | loss: 0.0941772\n",
      "\tspeed: 0.0691s/iter; left time: 1296.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.0921870 Vali Loss: 0.1240861 Test Loss: 0.1538316\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04635089635848999, rmse:0.21529258787631989, mae:0.14883416891098022, rse:0.7464503049850464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1435386\n",
      "\tspeed: 0.0709s/iter; left time: 1574.5806s\n",
      "\titers: 200, epoch: 1 | loss: 0.1412452\n",
      "\tspeed: 0.0693s/iter; left time: 1531.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1469587 Vali Loss: 0.1503619 Test Loss: 0.1767886\n",
      "Validation loss decreased (inf --> 0.150362).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1120439\n",
      "\tspeed: 0.1237s/iter; left time: 2717.7933s\n",
      "\titers: 200, epoch: 2 | loss: 0.1109545\n",
      "\tspeed: 0.0697s/iter; left time: 1525.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1172456 Vali Loss: 0.1231335 Test Loss: 0.1470964\n",
      "Validation loss decreased (0.150362 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074619\n",
      "\tspeed: 0.1203s/iter; left time: 2618.0072s\n",
      "\titers: 200, epoch: 3 | loss: 0.1085829\n",
      "\tspeed: 0.0693s/iter; left time: 1499.8180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1079589 Vali Loss: 0.1217438 Test Loss: 0.1472394\n",
      "Validation loss decreased (0.123134 --> 0.121744).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029040\n",
      "\tspeed: 0.1198s/iter; left time: 2579.2513s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092405\n",
      "\tspeed: 0.0693s/iter; left time: 1484.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1056315 Vali Loss: 0.1210526 Test Loss: 0.1478875\n",
      "Validation loss decreased (0.121744 --> 0.121053).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1050835\n",
      "\tspeed: 0.1224s/iter; left time: 2608.6936s\n",
      "\titers: 200, epoch: 5 | loss: 0.1013691\n",
      "\tspeed: 0.0692s/iter; left time: 1467.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1037747 Vali Loss: 0.1207483 Test Loss: 0.1486701\n",
      "Validation loss decreased (0.121053 --> 0.120748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023986\n",
      "\tspeed: 0.1197s/iter; left time: 2524.9708s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022196\n",
      "\tspeed: 0.0693s/iter; left time: 1454.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1021649 Vali Loss: 0.1210408 Test Loss: 0.1488155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028455\n",
      "\tspeed: 0.1203s/iter; left time: 2509.4943s\n",
      "\titers: 200, epoch: 7 | loss: 0.1001752\n",
      "\tspeed: 0.0692s/iter; left time: 1437.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1008448 Vali Loss: 0.1212449 Test Loss: 0.1488863\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1033451\n",
      "\tspeed: 0.1190s/iter; left time: 2456.3905s\n",
      "\titers: 200, epoch: 8 | loss: 0.0971676\n",
      "\tspeed: 0.0694s/iter; left time: 1424.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0996199 Vali Loss: 0.1219015 Test Loss: 0.1491982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0990058\n",
      "\tspeed: 0.1190s/iter; left time: 2428.9481s\n",
      "\titers: 200, epoch: 9 | loss: 0.1007090\n",
      "\tspeed: 0.0694s/iter; left time: 1409.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0985102 Vali Loss: 0.1213971 Test Loss: 0.1493594\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975233\n",
      "\tspeed: 0.1187s/iter; left time: 2397.7097s\n",
      "\titers: 200, epoch: 10 | loss: 0.0986166\n",
      "\tspeed: 0.0694s/iter; left time: 1394.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0975176 Vali Loss: 0.1219288 Test Loss: 0.1506020\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0978751\n",
      "\tspeed: 0.1197s/iter; left time: 2391.2975s\n",
      "\titers: 200, epoch: 11 | loss: 0.0927297\n",
      "\tspeed: 0.0694s/iter; left time: 1378.0695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0966755 Vali Loss: 0.1223882 Test Loss: 0.1509488\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987984\n",
      "\tspeed: 0.1190s/iter; left time: 2349.5385s\n",
      "\titers: 200, epoch: 12 | loss: 0.0944003\n",
      "\tspeed: 0.0693s/iter; left time: 1361.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0959382 Vali Loss: 0.1223772 Test Loss: 0.1499679\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0941867\n",
      "\tspeed: 0.1187s/iter; left time: 2317.9481s\n",
      "\titers: 200, epoch: 13 | loss: 0.0910453\n",
      "\tspeed: 0.0693s/iter; left time: 1346.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0952061 Vali Loss: 0.1230551 Test Loss: 0.1518901\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0943975\n",
      "\tspeed: 0.1193s/iter; left time: 2302.1516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0946359\n",
      "\tspeed: 0.0693s/iter; left time: 1331.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0946333 Vali Loss: 0.1231219 Test Loss: 0.1512958\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0915139\n",
      "\tspeed: 0.1197s/iter; left time: 2283.2056s\n",
      "\titers: 200, epoch: 15 | loss: 0.0912506\n",
      "\tspeed: 0.0693s/iter; left time: 1315.7765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0940620 Vali Loss: 0.1231321 Test Loss: 0.1521490\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046182967722415924, rmse:0.21490222215652466, mae:0.14867003262043, rse:0.7450969219207764\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:00.72s\n",
      "Intermediate time for GB: 00h:55m:05.11s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1529711\n",
      "\tspeed: 0.0596s/iter; left time: 1329.7049s\n",
      "\titers: 200, epoch: 1 | loss: 0.1360108\n",
      "\tspeed: 0.0421s/iter; left time: 935.5135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.1550293 Vali Loss: 0.1393889 Test Loss: 0.1681391\n",
      "Validation loss decreased (inf --> 0.139389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0734895\n",
      "\tspeed: 0.0764s/iter; left time: 1687.5220s\n",
      "\titers: 200, epoch: 2 | loss: 0.0732423\n",
      "\tspeed: 0.0421s/iter; left time: 925.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0805362 Vali Loss: 0.0644472 Test Loss: 0.0716057\n",
      "Validation loss decreased (0.139389 --> 0.064447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670037\n",
      "\tspeed: 0.0765s/iter; left time: 1670.8438s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633987\n",
      "\tspeed: 0.0421s/iter; left time: 915.5253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0639687 Vali Loss: 0.0604835 Test Loss: 0.0676901\n",
      "Validation loss decreased (0.064447 --> 0.060484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0613006\n",
      "\tspeed: 0.0761s/iter; left time: 1646.4538s\n",
      "\titers: 200, epoch: 4 | loss: 0.0589914\n",
      "\tspeed: 0.0422s/iter; left time: 907.8062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0607848 Vali Loss: 0.0584154 Test Loss: 0.0650347\n",
      "Validation loss decreased (0.060484 --> 0.058415).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0590660\n",
      "\tspeed: 0.0762s/iter; left time: 1631.6562s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541014\n",
      "\tspeed: 0.0421s/iter; left time: 897.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0585594 Vali Loss: 0.0570394 Test Loss: 0.0637940\n",
      "Validation loss decreased (0.058415 --> 0.057039).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569912\n",
      "\tspeed: 0.0761s/iter; left time: 1611.4262s\n",
      "\titers: 200, epoch: 6 | loss: 0.0541913\n",
      "\tspeed: 0.0421s/iter; left time: 887.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0571212 Vali Loss: 0.0560755 Test Loss: 0.0628937\n",
      "Validation loss decreased (0.057039 --> 0.056075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585085\n",
      "\tspeed: 0.0759s/iter; left time: 1591.1244s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523225\n",
      "\tspeed: 0.0421s/iter; left time: 879.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0562777 Vali Loss: 0.0558876 Test Loss: 0.0626064\n",
      "Validation loss decreased (0.056075 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0545201\n",
      "\tspeed: 0.0761s/iter; left time: 1577.9117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590803\n",
      "\tspeed: 0.0420s/iter; left time: 867.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0555750 Vali Loss: 0.0552337 Test Loss: 0.0619180\n",
      "Validation loss decreased (0.055888 --> 0.055234).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0534203\n",
      "\tspeed: 0.0769s/iter; left time: 1577.3118s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581229\n",
      "\tspeed: 0.0421s/iter; left time: 858.7538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0550523 Vali Loss: 0.0547637 Test Loss: 0.0615436\n",
      "Validation loss decreased (0.055234 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546895\n",
      "\tspeed: 0.0768s/iter; left time: 1557.8429s\n",
      "\titers: 200, epoch: 10 | loss: 0.0517974\n",
      "\tspeed: 0.0421s/iter; left time: 850.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0545337 Vali Loss: 0.0549140 Test Loss: 0.0615433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0547254\n",
      "\tspeed: 0.0753s/iter; left time: 1510.6060s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556244\n",
      "\tspeed: 0.0420s/iter; left time: 839.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0541035 Vali Loss: 0.0542901 Test Loss: 0.0609592\n",
      "Validation loss decreased (0.054764 --> 0.054290).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0526986\n",
      "\tspeed: 0.0749s/iter; left time: 1484.9537s\n",
      "\titers: 200, epoch: 12 | loss: 0.0537033\n",
      "\tspeed: 0.0421s/iter; left time: 830.4634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0538599 Vali Loss: 0.0542014 Test Loss: 0.0608091\n",
      "Validation loss decreased (0.054290 --> 0.054201).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556784\n",
      "\tspeed: 0.0758s/iter; left time: 1487.0728s\n",
      "\titers: 200, epoch: 13 | loss: 0.0531932\n",
      "\tspeed: 0.0421s/iter; left time: 821.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0536762 Vali Loss: 0.0541160 Test Loss: 0.0608011\n",
      "Validation loss decreased (0.054201 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0536481\n",
      "\tspeed: 0.0760s/iter; left time: 1474.4599s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535595\n",
      "\tspeed: 0.0422s/iter; left time: 814.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0534330 Vali Loss: 0.0540443 Test Loss: 0.0607316\n",
      "Validation loss decreased (0.054116 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0523399\n",
      "\tspeed: 0.0756s/iter; left time: 1449.4713s\n",
      "\titers: 200, epoch: 15 | loss: 0.0528310\n",
      "\tspeed: 0.0420s/iter; left time: 801.5816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0531772 Vali Loss: 0.0539118 Test Loss: 0.0605432\n",
      "Validation loss decreased (0.054044 --> 0.053912).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517506\n",
      "\tspeed: 0.0768s/iter; left time: 1455.2459s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502353\n",
      "\tspeed: 0.0419s/iter; left time: 789.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0530458 Vali Loss: 0.0537179 Test Loss: 0.0605205\n",
      "Validation loss decreased (0.053912 --> 0.053718).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0516205\n",
      "\tspeed: 0.0748s/iter; left time: 1400.1206s\n",
      "\titers: 200, epoch: 17 | loss: 0.0487740\n",
      "\tspeed: 0.0419s/iter; left time: 780.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528856 Vali Loss: 0.0536976 Test Loss: 0.0603235\n",
      "Validation loss decreased (0.053718 --> 0.053698).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0495635\n",
      "\tspeed: 0.0745s/iter; left time: 1376.9593s\n",
      "\titers: 200, epoch: 18 | loss: 0.0475049\n",
      "\tspeed: 0.0419s/iter; left time: 771.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0527332 Vali Loss: 0.0535530 Test Loss: 0.0601319\n",
      "Validation loss decreased (0.053698 --> 0.053553).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542793\n",
      "\tspeed: 0.0751s/iter; left time: 1372.8692s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542914\n",
      "\tspeed: 0.0419s/iter; left time: 761.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0526262 Vali Loss: 0.0534551 Test Loss: 0.0600646\n",
      "Validation loss decreased (0.053553 --> 0.053455).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0502990\n",
      "\tspeed: 0.0747s/iter; left time: 1348.6633s\n",
      "\titers: 200, epoch: 20 | loss: 0.0520770\n",
      "\tspeed: 0.0419s/iter; left time: 751.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0525189 Vali Loss: 0.0534990 Test Loss: 0.0601889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0514833\n",
      "\tspeed: 0.0742s/iter; left time: 1322.9144s\n",
      "\titers: 200, epoch: 21 | loss: 0.0518561\n",
      "\tspeed: 0.0419s/iter; left time: 743.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0523950 Vali Loss: 0.0533594 Test Loss: 0.0600421\n",
      "Validation loss decreased (0.053455 --> 0.053359).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0482492\n",
      "\tspeed: 0.0751s/iter; left time: 1321.4273s\n",
      "\titers: 200, epoch: 22 | loss: 0.0523444\n",
      "\tspeed: 0.0418s/iter; left time: 731.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0523219 Vali Loss: 0.0532337 Test Loss: 0.0598630\n",
      "Validation loss decreased (0.053359 --> 0.053234).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0495374\n",
      "\tspeed: 0.0742s/iter; left time: 1289.0237s\n",
      "\titers: 200, epoch: 23 | loss: 0.0533514\n",
      "\tspeed: 0.0419s/iter; left time: 723.5867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0522467 Vali Loss: 0.0533042 Test Loss: 0.0599243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0537487\n",
      "\tspeed: 0.0740s/iter; left time: 1269.3511s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510432\n",
      "\tspeed: 0.0419s/iter; left time: 713.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0522055 Vali Loss: 0.0532749 Test Loss: 0.0598150\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508326\n",
      "\tspeed: 0.0740s/iter; left time: 1252.8814s\n",
      "\titers: 200, epoch: 25 | loss: 0.0547152\n",
      "\tspeed: 0.0419s/iter; left time: 704.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0521477 Vali Loss: 0.0531669 Test Loss: 0.0598374\n",
      "Validation loss decreased (0.053234 --> 0.053167).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0478256\n",
      "\tspeed: 0.0753s/iter; left time: 1257.8698s\n",
      "\titers: 200, epoch: 26 | loss: 0.0542118\n",
      "\tspeed: 0.0419s/iter; left time: 695.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0520078 Vali Loss: 0.0532341 Test Loss: 0.0598802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524855\n",
      "\tspeed: 0.0745s/iter; left time: 1227.8457s\n",
      "\titers: 200, epoch: 27 | loss: 0.0518160\n",
      "\tspeed: 0.0419s/iter; left time: 685.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0520100 Vali Loss: 0.0530923 Test Loss: 0.0596831\n",
      "Validation loss decreased (0.053167 --> 0.053092).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0535040\n",
      "\tspeed: 0.0744s/iter; left time: 1209.1036s\n",
      "\titers: 200, epoch: 28 | loss: 0.0530858\n",
      "\tspeed: 0.0419s/iter; left time: 676.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519409 Vali Loss: 0.0530335 Test Loss: 0.0596972\n",
      "Validation loss decreased (0.053092 --> 0.053034).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0497071\n",
      "\tspeed: 0.0748s/iter; left time: 1199.3714s\n",
      "\titers: 200, epoch: 29 | loss: 0.0555924\n",
      "\tspeed: 0.0419s/iter; left time: 666.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0519867 Vali Loss: 0.0531298 Test Loss: 0.0597869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0511343\n",
      "\tspeed: 0.0743s/iter; left time: 1174.7319s\n",
      "\titers: 200, epoch: 30 | loss: 0.0550379\n",
      "\tspeed: 0.0418s/iter; left time: 657.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519589 Vali Loss: 0.0530690 Test Loss: 0.0597366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0516089\n",
      "\tspeed: 0.0742s/iter; left time: 1156.6521s\n",
      "\titers: 200, epoch: 31 | loss: 0.0502292\n",
      "\tspeed: 0.0418s/iter; left time: 647.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0518643 Vali Loss: 0.0530980 Test Loss: 0.0596929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0494124\n",
      "\tspeed: 0.0739s/iter; left time: 1135.3118s\n",
      "\titers: 200, epoch: 32 | loss: 0.0510262\n",
      "\tspeed: 0.0419s/iter; left time: 638.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517700 Vali Loss: 0.0531316 Test Loss: 0.0597132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0485354\n",
      "\tspeed: 0.0741s/iter; left time: 1121.3862s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532829\n",
      "\tspeed: 0.0419s/iter; left time: 630.3779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0518294 Vali Loss: 0.0531285 Test Loss: 0.0597745\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0523017\n",
      "\tspeed: 0.0740s/iter; left time: 1103.3919s\n",
      "\titers: 200, epoch: 34 | loss: 0.0521809\n",
      "\tspeed: 0.0419s/iter; left time: 620.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517885 Vali Loss: 0.0531236 Test Loss: 0.0595324\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0526446\n",
      "\tspeed: 0.0743s/iter; left time: 1091.8115s\n",
      "\titers: 200, epoch: 35 | loss: 0.0531692\n",
      "\tspeed: 0.0419s/iter; left time: 610.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0517643 Vali Loss: 0.0528842 Test Loss: 0.0594883\n",
      "Validation loss decreased (0.053034 --> 0.052884).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0511099\n",
      "\tspeed: 0.0750s/iter; left time: 1084.8478s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518669\n",
      "\tspeed: 0.0419s/iter; left time: 601.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0517620 Vali Loss: 0.0530359 Test Loss: 0.0596728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0513136\n",
      "\tspeed: 0.0747s/iter; left time: 1063.3120s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500350\n",
      "\tspeed: 0.0419s/iter; left time: 592.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0517964 Vali Loss: 0.0530424 Test Loss: 0.0596265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0505333\n",
      "\tspeed: 0.0748s/iter; left time: 1048.5269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0558573\n",
      "\tspeed: 0.0419s/iter; left time: 582.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0517588 Vali Loss: 0.0529814 Test Loss: 0.0595264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0490988\n",
      "\tspeed: 0.0739s/iter; left time: 1018.3320s\n",
      "\titers: 200, epoch: 39 | loss: 0.0539161\n",
      "\tspeed: 0.0418s/iter; left time: 572.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517282 Vali Loss: 0.0530113 Test Loss: 0.0595206\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0515784\n",
      "\tspeed: 0.0745s/iter; left time: 1010.0002s\n",
      "\titers: 200, epoch: 40 | loss: 0.0517620\n",
      "\tspeed: 0.0418s/iter; left time: 563.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516523 Vali Loss: 0.0530574 Test Loss: 0.0596935\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0514502\n",
      "\tspeed: 0.0742s/iter; left time: 989.3825s\n",
      "\titers: 200, epoch: 41 | loss: 0.0488613\n",
      "\tspeed: 0.0419s/iter; left time: 554.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0516880 Vali Loss: 0.0528703 Test Loss: 0.0594812\n",
      "Validation loss decreased (0.052884 --> 0.052870).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0496368\n",
      "\tspeed: 0.0750s/iter; left time: 983.8314s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539314\n",
      "\tspeed: 0.0418s/iter; left time: 544.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516577 Vali Loss: 0.0529605 Test Loss: 0.0594789\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0520530\n",
      "\tspeed: 0.0736s/iter; left time: 949.4889s\n",
      "\titers: 200, epoch: 43 | loss: 0.0479843\n",
      "\tspeed: 0.0419s/iter; left time: 535.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516277 Vali Loss: 0.0529979 Test Loss: 0.0595466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0522960\n",
      "\tspeed: 0.0744s/iter; left time: 942.7700s\n",
      "\titers: 200, epoch: 44 | loss: 0.0505055\n",
      "\tspeed: 0.0418s/iter; left time: 525.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516367 Vali Loss: 0.0529722 Test Loss: 0.0595264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0533356\n",
      "\tspeed: 0.0746s/iter; left time: 929.0001s\n",
      "\titers: 200, epoch: 45 | loss: 0.0502352\n",
      "\tspeed: 0.0419s/iter; left time: 516.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0515927 Vali Loss: 0.0530458 Test Loss: 0.0596104\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0517692\n",
      "\tspeed: 0.0746s/iter; left time: 911.5233s\n",
      "\titers: 200, epoch: 46 | loss: 0.0498136\n",
      "\tspeed: 0.0418s/iter; left time: 507.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516503 Vali Loss: 0.0529150 Test Loss: 0.0594626\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0508997\n",
      "\tspeed: 0.0740s/iter; left time: 887.9165s\n",
      "\titers: 200, epoch: 47 | loss: 0.0512915\n",
      "\tspeed: 0.0418s/iter; left time: 497.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516404 Vali Loss: 0.0531144 Test Loss: 0.0597561\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0517852\n",
      "\tspeed: 0.0739s/iter; left time: 870.2552s\n",
      "\titers: 200, epoch: 48 | loss: 0.0506876\n",
      "\tspeed: 0.0419s/iter; left time: 488.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516248 Vali Loss: 0.0530044 Test Loss: 0.0595320\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0547697\n",
      "\tspeed: 0.0741s/iter; left time: 855.5929s\n",
      "\titers: 200, epoch: 49 | loss: 0.0555677\n",
      "\tspeed: 0.0420s/iter; left time: 480.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516264 Vali Loss: 0.0528984 Test Loss: 0.0594791\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0482547\n",
      "\tspeed: 0.0742s/iter; left time: 840.1247s\n",
      "\titers: 200, epoch: 50 | loss: 0.0517692\n",
      "\tspeed: 0.0418s/iter; left time: 469.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0516105 Vali Loss: 0.0528318 Test Loss: 0.0594671\n",
      "Validation loss decreased (0.052870 --> 0.052832).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0545435\n",
      "\tspeed: 0.0746s/iter; left time: 828.3088s\n",
      "\titers: 200, epoch: 51 | loss: 0.0500720\n",
      "\tspeed: 0.0418s/iter; left time: 459.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516374 Vali Loss: 0.0529633 Test Loss: 0.0595131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0499847\n",
      "\tspeed: 0.0750s/iter; left time: 816.1339s\n",
      "\titers: 200, epoch: 52 | loss: 0.0503403\n",
      "\tspeed: 0.0419s/iter; left time: 451.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0516169 Vali Loss: 0.0529436 Test Loss: 0.0595761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0509274\n",
      "\tspeed: 0.0744s/iter; left time: 792.6976s\n",
      "\titers: 200, epoch: 53 | loss: 0.0516314\n",
      "\tspeed: 0.0419s/iter; left time: 441.6514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516119 Vali Loss: 0.0528572 Test Loss: 0.0594418\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0558771\n",
      "\tspeed: 0.0739s/iter; left time: 770.8764s\n",
      "\titers: 200, epoch: 54 | loss: 0.0494262\n",
      "\tspeed: 0.0419s/iter; left time: 432.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0516379 Vali Loss: 0.0529400 Test Loss: 0.0595203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0516943\n",
      "\tspeed: 0.0738s/iter; left time: 753.2285s\n",
      "\titers: 200, epoch: 55 | loss: 0.0511932\n",
      "\tspeed: 0.0418s/iter; left time: 422.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0515673 Vali Loss: 0.0529744 Test Loss: 0.0596210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0525783\n",
      "\tspeed: 0.0742s/iter; left time: 740.6482s\n",
      "\titers: 200, epoch: 56 | loss: 0.0492389\n",
      "\tspeed: 0.0421s/iter; left time: 415.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516370 Vali Loss: 0.0529574 Test Loss: 0.0595281\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0545935\n",
      "\tspeed: 0.0746s/iter; left time: 727.7998s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523759\n",
      "\tspeed: 0.0420s/iter; left time: 405.2712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0516061 Vali Loss: 0.0529795 Test Loss: 0.0595364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0511875\n",
      "\tspeed: 0.0751s/iter; left time: 715.6339s\n",
      "\titers: 200, epoch: 58 | loss: 0.0533470\n",
      "\tspeed: 0.0419s/iter; left time: 394.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0515821 Vali Loss: 0.0529342 Test Loss: 0.0595035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0510884\n",
      "\tspeed: 0.0738s/iter; left time: 687.2696s\n",
      "\titers: 200, epoch: 59 | loss: 0.0499370\n",
      "\tspeed: 0.0419s/iter; left time: 385.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0515440 Vali Loss: 0.0529809 Test Loss: 0.0596370\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0486272\n",
      "\tspeed: 0.0737s/iter; left time: 669.5302s\n",
      "\titers: 200, epoch: 60 | loss: 0.0515719\n",
      "\tspeed: 0.0418s/iter; left time: 375.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0516205 Vali Loss: 0.0529591 Test Loss: 0.0596179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009799639694392681, rmse:0.09899313002824783, mae:0.05946708470582962, rse:0.29132479429244995\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1476018\n",
      "\tspeed: 0.0434s/iter; left time: 967.3401s\n",
      "\titers: 200, epoch: 1 | loss: 0.1437213\n",
      "\tspeed: 0.0418s/iter; left time: 928.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.1531461 Vali Loss: 0.1377213 Test Loss: 0.1661581\n",
      "Validation loss decreased (inf --> 0.137721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746912\n",
      "\tspeed: 0.0756s/iter; left time: 1669.1042s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647650\n",
      "\tspeed: 0.0418s/iter; left time: 919.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0809738 Vali Loss: 0.0644596 Test Loss: 0.0714945\n",
      "Validation loss decreased (0.137721 --> 0.064460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640776\n",
      "\tspeed: 0.0745s/iter; left time: 1627.5040s\n",
      "\titers: 200, epoch: 3 | loss: 0.0653341\n",
      "\tspeed: 0.0419s/iter; left time: 910.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0643923 Vali Loss: 0.0610661 Test Loss: 0.0680844\n",
      "Validation loss decreased (0.064460 --> 0.061066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614698\n",
      "\tspeed: 0.0750s/iter; left time: 1622.1674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615958\n",
      "\tspeed: 0.0420s/iter; left time: 904.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0611753 Vali Loss: 0.0585783 Test Loss: 0.0655559\n",
      "Validation loss decreased (0.061066 --> 0.058578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0570497\n",
      "\tspeed: 0.0744s/iter; left time: 1592.0999s\n",
      "\titers: 200, epoch: 5 | loss: 0.0569669\n",
      "\tspeed: 0.0418s/iter; left time: 891.5242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0590486 Vali Loss: 0.0571490 Test Loss: 0.0639000\n",
      "Validation loss decreased (0.058578 --> 0.057149).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0563935\n",
      "\tspeed: 0.0741s/iter; left time: 1569.2281s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545689\n",
      "\tspeed: 0.0418s/iter; left time: 881.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0574238 Vali Loss: 0.0563478 Test Loss: 0.0633337\n",
      "Validation loss decreased (0.057149 --> 0.056348).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543616\n",
      "\tspeed: 0.0742s/iter; left time: 1554.6276s\n",
      "\titers: 200, epoch: 7 | loss: 0.0533362\n",
      "\tspeed: 0.0419s/iter; left time: 873.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0563506 Vali Loss: 0.0555214 Test Loss: 0.0626752\n",
      "Validation loss decreased (0.056348 --> 0.055521).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0559180\n",
      "\tspeed: 0.0741s/iter; left time: 1536.6109s\n",
      "\titers: 200, epoch: 8 | loss: 0.0533546\n",
      "\tspeed: 0.0418s/iter; left time: 863.1065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0556354 Vali Loss: 0.0550512 Test Loss: 0.0623097\n",
      "Validation loss decreased (0.055521 --> 0.055051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521461\n",
      "\tspeed: 0.0744s/iter; left time: 1525.2461s\n",
      "\titers: 200, epoch: 9 | loss: 0.0539520\n",
      "\tspeed: 0.0419s/iter; left time: 854.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0550924 Vali Loss: 0.0547789 Test Loss: 0.0615542\n",
      "Validation loss decreased (0.055051 --> 0.054779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549681\n",
      "\tspeed: 0.0745s/iter; left time: 1510.4364s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536708\n",
      "\tspeed: 0.0418s/iter; left time: 844.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0546157 Vali Loss: 0.0545722 Test Loss: 0.0614398\n",
      "Validation loss decreased (0.054779 --> 0.054572).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0526006\n",
      "\tspeed: 0.0746s/iter; left time: 1497.1449s\n",
      "\titers: 200, epoch: 11 | loss: 0.0524122\n",
      "\tspeed: 0.0419s/iter; left time: 836.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0542620 Vali Loss: 0.0542749 Test Loss: 0.0611336\n",
      "Validation loss decreased (0.054572 --> 0.054275).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0543727\n",
      "\tspeed: 0.0744s/iter; left time: 1476.5967s\n",
      "\titers: 200, epoch: 12 | loss: 0.0528240\n",
      "\tspeed: 0.0418s/iter; left time: 825.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0538929 Vali Loss: 0.0541811 Test Loss: 0.0609238\n",
      "Validation loss decreased (0.054275 --> 0.054181).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580260\n",
      "\tspeed: 0.0746s/iter; left time: 1462.7228s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543900\n",
      "\tspeed: 0.0418s/iter; left time: 816.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0536706 Vali Loss: 0.0540516 Test Loss: 0.0607060\n",
      "Validation loss decreased (0.054181 --> 0.054052).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0565432\n",
      "\tspeed: 0.0740s/iter; left time: 1433.8208s\n",
      "\titers: 200, epoch: 14 | loss: 0.0505316\n",
      "\tspeed: 0.0418s/iter; left time: 805.6353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0535040 Vali Loss: 0.0538637 Test Loss: 0.0606829\n",
      "Validation loss decreased (0.054052 --> 0.053864).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0581060\n",
      "\tspeed: 0.0741s/iter; left time: 1420.0279s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532165\n",
      "\tspeed: 0.0418s/iter; left time: 796.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0531955 Vali Loss: 0.0537251 Test Loss: 0.0603922\n",
      "Validation loss decreased (0.053864 --> 0.053725).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0522039\n",
      "\tspeed: 0.0742s/iter; left time: 1404.7267s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557981\n",
      "\tspeed: 0.0418s/iter; left time: 788.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530805 Vali Loss: 0.0535555 Test Loss: 0.0602422\n",
      "Validation loss decreased (0.053725 --> 0.053556).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513855\n",
      "\tspeed: 0.0741s/iter; left time: 1387.5643s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546825\n",
      "\tspeed: 0.0418s/iter; left time: 778.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529455 Vali Loss: 0.0536849 Test Loss: 0.0604115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0556174\n",
      "\tspeed: 0.0737s/iter; left time: 1362.4725s\n",
      "\titers: 200, epoch: 18 | loss: 0.0520927\n",
      "\tspeed: 0.0418s/iter; left time: 769.4816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0527236 Vali Loss: 0.0535271 Test Loss: 0.0601175\n",
      "Validation loss decreased (0.053556 --> 0.053527).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525549\n",
      "\tspeed: 0.0744s/iter; left time: 1359.2558s\n",
      "\titers: 200, epoch: 19 | loss: 0.0489624\n",
      "\tspeed: 0.0418s/iter; left time: 759.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0527059 Vali Loss: 0.0535655 Test Loss: 0.0602358\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0496512\n",
      "\tspeed: 0.0737s/iter; left time: 1330.0334s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536459\n",
      "\tspeed: 0.0419s/iter; left time: 751.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0525997 Vali Loss: 0.0534788 Test Loss: 0.0601111\n",
      "Validation loss decreased (0.053527 --> 0.053479).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0562994\n",
      "\tspeed: 0.0744s/iter; left time: 1326.1666s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519681\n",
      "\tspeed: 0.0418s/iter; left time: 741.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0524832 Vali Loss: 0.0533591 Test Loss: 0.0600647\n",
      "Validation loss decreased (0.053479 --> 0.053359).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0498014\n",
      "\tspeed: 0.0740s/iter; left time: 1302.2149s\n",
      "\titers: 200, epoch: 22 | loss: 0.0511340\n",
      "\tspeed: 0.0418s/iter; left time: 731.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0524015 Vali Loss: 0.0533194 Test Loss: 0.0599013\n",
      "Validation loss decreased (0.053359 --> 0.053319).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511480\n",
      "\tspeed: 0.0752s/iter; left time: 1307.2778s\n",
      "\titers: 200, epoch: 23 | loss: 0.0547260\n",
      "\tspeed: 0.0426s/iter; left time: 736.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0523454 Vali Loss: 0.0532531 Test Loss: 0.0598640\n",
      "Validation loss decreased (0.053319 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0494056\n",
      "\tspeed: 0.0741s/iter; left time: 1270.1937s\n",
      "\titers: 200, epoch: 24 | loss: 0.0505622\n",
      "\tspeed: 0.0418s/iter; left time: 712.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0522534 Vali Loss: 0.0532340 Test Loss: 0.0598475\n",
      "Validation loss decreased (0.053253 --> 0.053234).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0507696\n",
      "\tspeed: 0.0740s/iter; left time: 1252.1243s\n",
      "\titers: 200, epoch: 25 | loss: 0.0518188\n",
      "\tspeed: 0.0417s/iter; left time: 702.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0521564 Vali Loss: 0.0531983 Test Loss: 0.0597164\n",
      "Validation loss decreased (0.053234 --> 0.053198).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0543133\n",
      "\tspeed: 0.0739s/iter; left time: 1234.9556s\n",
      "\titers: 200, epoch: 26 | loss: 0.0491244\n",
      "\tspeed: 0.0418s/iter; left time: 694.0445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0521741 Vali Loss: 0.0532081 Test Loss: 0.0597476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0529002\n",
      "\tspeed: 0.0736s/iter; left time: 1212.4261s\n",
      "\titers: 200, epoch: 27 | loss: 0.0531516\n",
      "\tspeed: 0.0418s/iter; left time: 684.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0520485 Vali Loss: 0.0532592 Test Loss: 0.0598365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0536259\n",
      "\tspeed: 0.0738s/iter; left time: 1199.2121s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525920\n",
      "\tspeed: 0.0418s/iter; left time: 675.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0520732 Vali Loss: 0.0530898 Test Loss: 0.0597077\n",
      "Validation loss decreased (0.053198 --> 0.053090).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543261\n",
      "\tspeed: 0.0741s/iter; left time: 1187.1689s\n",
      "\titers: 200, epoch: 29 | loss: 0.0550454\n",
      "\tspeed: 0.0418s/iter; left time: 665.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519956 Vali Loss: 0.0531452 Test Loss: 0.0597517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523805\n",
      "\tspeed: 0.0735s/iter; left time: 1162.1472s\n",
      "\titers: 200, epoch: 30 | loss: 0.0516562\n",
      "\tspeed: 0.0418s/iter; left time: 656.2511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0519390 Vali Loss: 0.0532631 Test Loss: 0.0597923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0534631\n",
      "\tspeed: 0.0739s/iter; left time: 1152.0264s\n",
      "\titers: 200, epoch: 31 | loss: 0.0478987\n",
      "\tspeed: 0.0418s/iter; left time: 646.6618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0519516 Vali Loss: 0.0530886 Test Loss: 0.0596565\n",
      "Validation loss decreased (0.053090 --> 0.053089).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0525212\n",
      "\tspeed: 0.0745s/iter; left time: 1143.6131s\n",
      "\titers: 200, epoch: 32 | loss: 0.0448811\n",
      "\tspeed: 0.0419s/iter; left time: 638.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0519044 Vali Loss: 0.0531356 Test Loss: 0.0596514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543640\n",
      "\tspeed: 0.0737s/iter; left time: 1115.7017s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521232\n",
      "\tspeed: 0.0418s/iter; left time: 629.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0518768 Vali Loss: 0.0530850 Test Loss: 0.0596694\n",
      "Validation loss decreased (0.053089 --> 0.053085).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0533725\n",
      "\tspeed: 0.0742s/iter; left time: 1106.4521s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530695\n",
      "\tspeed: 0.0418s/iter; left time: 619.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0518850 Vali Loss: 0.0531215 Test Loss: 0.0596977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0490373\n",
      "\tspeed: 0.0737s/iter; left time: 1082.1185s\n",
      "\titers: 200, epoch: 35 | loss: 0.0513428\n",
      "\tspeed: 0.0418s/iter; left time: 609.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0518383 Vali Loss: 0.0530350 Test Loss: 0.0596393\n",
      "Validation loss decreased (0.053085 --> 0.053035).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0535707\n",
      "\tspeed: 0.0742s/iter; left time: 1072.6000s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524036\n",
      "\tspeed: 0.0418s/iter; left time: 600.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0517890 Vali Loss: 0.0530882 Test Loss: 0.0596071\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0524593\n",
      "\tspeed: 0.0737s/iter; left time: 1049.1655s\n",
      "\titers: 200, epoch: 37 | loss: 0.0530749\n",
      "\tspeed: 0.0418s/iter; left time: 590.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517949 Vali Loss: 0.0530463 Test Loss: 0.0596028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0532010\n",
      "\tspeed: 0.0738s/iter; left time: 1033.7296s\n",
      "\titers: 200, epoch: 38 | loss: 0.0495975\n",
      "\tspeed: 0.0418s/iter; left time: 582.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0517682 Vali Loss: 0.0529934 Test Loss: 0.0595207\n",
      "Validation loss decreased (0.053035 --> 0.052993).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0499899\n",
      "\tspeed: 0.0740s/iter; left time: 1020.9604s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538907\n",
      "\tspeed: 0.0418s/iter; left time: 572.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0517210 Vali Loss: 0.0530056 Test Loss: 0.0595864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0525996\n",
      "\tspeed: 0.0738s/iter; left time: 1000.8883s\n",
      "\titers: 200, epoch: 40 | loss: 0.0529549\n",
      "\tspeed: 0.0419s/iter; left time: 564.1836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0517723 Vali Loss: 0.0530561 Test Loss: 0.0595950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0519737\n",
      "\tspeed: 0.0736s/iter; left time: 981.2992s\n",
      "\titers: 200, epoch: 41 | loss: 0.0519630\n",
      "\tspeed: 0.0417s/iter; left time: 552.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0517834 Vali Loss: 0.0530609 Test Loss: 0.0596149\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509723\n",
      "\tspeed: 0.0745s/iter; left time: 977.7813s\n",
      "\titers: 200, epoch: 42 | loss: 0.0524476\n",
      "\tspeed: 0.0544s/iter; left time: 708.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0518105 Vali Loss: 0.0530046 Test Loss: 0.0595797\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0503187\n",
      "\tspeed: 0.1446s/iter; left time: 1863.8645s\n",
      "\titers: 200, epoch: 43 | loss: 0.0504047\n",
      "\tspeed: 0.0854s/iter; left time: 1092.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:19.29s\n",
      "Steps: 224 | Train Loss: 0.0516899 Vali Loss: 0.0529767 Test Loss: 0.0595138\n",
      "Validation loss decreased (0.052993 --> 0.052977).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0527615\n",
      "\tspeed: 0.1431s/iter; left time: 1812.5550s\n",
      "\titers: 200, epoch: 44 | loss: 0.0524022\n",
      "\tspeed: 0.0886s/iter; left time: 1113.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:19.16s\n",
      "Steps: 224 | Train Loss: 0.0517289 Vali Loss: 0.0530944 Test Loss: 0.0597356\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0513969\n",
      "\tspeed: 0.1463s/iter; left time: 1820.3994s\n",
      "\titers: 200, epoch: 45 | loss: 0.0538382\n",
      "\tspeed: 0.0826s/iter; left time: 1020.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:19.45s\n",
      "Steps: 224 | Train Loss: 0.0517787 Vali Loss: 0.0529584 Test Loss: 0.0594981\n",
      "Validation loss decreased (0.052977 --> 0.052958).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0507074\n",
      "\tspeed: 0.1467s/iter; left time: 1792.9198s\n",
      "\titers: 200, epoch: 46 | loss: 0.0531654\n",
      "\tspeed: 0.0863s/iter; left time: 1046.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:19.48s\n",
      "Steps: 224 | Train Loss: 0.0517703 Vali Loss: 0.0530363 Test Loss: 0.0595716\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0526433\n",
      "\tspeed: 0.1428s/iter; left time: 1712.7029s\n",
      "\titers: 200, epoch: 47 | loss: 0.0482868\n",
      "\tspeed: 0.0886s/iter; left time: 1054.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:19.20s\n",
      "Steps: 224 | Train Loss: 0.0516642 Vali Loss: 0.0530231 Test Loss: 0.0595973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0503860\n",
      "\tspeed: 0.1457s/iter; left time: 1715.0696s\n",
      "\titers: 200, epoch: 48 | loss: 0.0495362\n",
      "\tspeed: 0.0832s/iter; left time: 970.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:19.51s\n",
      "Steps: 224 | Train Loss: 0.0516952 Vali Loss: 0.0530382 Test Loss: 0.0595692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0528319\n",
      "\tspeed: 0.1448s/iter; left time: 1672.3772s\n",
      "\titers: 200, epoch: 49 | loss: 0.0522983\n",
      "\tspeed: 0.0861s/iter; left time: 986.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:19.33s\n",
      "Steps: 224 | Train Loss: 0.0517189 Vali Loss: 0.0530699 Test Loss: 0.0596293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0519786\n",
      "\tspeed: 0.1439s/iter; left time: 1629.4182s\n",
      "\titers: 200, epoch: 50 | loss: 0.0511020\n",
      "\tspeed: 0.0886s/iter; left time: 994.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:19.22s\n",
      "Steps: 224 | Train Loss: 0.0516822 Vali Loss: 0.0529885 Test Loss: 0.0594989\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0557232\n",
      "\tspeed: 0.1467s/iter; left time: 1628.4150s\n",
      "\titers: 200, epoch: 51 | loss: 0.0520977\n",
      "\tspeed: 0.0824s/iter; left time: 906.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 224 | Train Loss: 0.0516774 Vali Loss: 0.0530646 Test Loss: 0.0595811\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0513555\n",
      "\tspeed: 0.1452s/iter; left time: 1578.9646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0545720\n",
      "\tspeed: 0.0716s/iter; left time: 771.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:17.84s\n",
      "Steps: 224 | Train Loss: 0.0517186 Vali Loss: 0.0529541 Test Loss: 0.0595378\n",
      "Validation loss decreased (0.052958 --> 0.052954).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548120\n",
      "\tspeed: 0.1379s/iter; left time: 1468.8587s\n",
      "\titers: 200, epoch: 53 | loss: 0.0506285\n",
      "\tspeed: 0.0885s/iter; left time: 934.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:18.77s\n",
      "Steps: 224 | Train Loss: 0.0516620 Vali Loss: 0.0529870 Test Loss: 0.0596300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0522626\n",
      "\tspeed: 0.1423s/iter; left time: 1484.1139s\n",
      "\titers: 200, epoch: 54 | loss: 0.0501850\n",
      "\tspeed: 0.0875s/iter; left time: 903.4580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:19.05s\n",
      "Steps: 224 | Train Loss: 0.0517069 Vali Loss: 0.0530255 Test Loss: 0.0595458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548283\n",
      "\tspeed: 0.1429s/iter; left time: 1458.1575s\n",
      "\titers: 200, epoch: 55 | loss: 0.0515203\n",
      "\tspeed: 0.0821s/iter; left time: 829.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:19.58s\n",
      "Steps: 224 | Train Loss: 0.0517627 Vali Loss: 0.0529545 Test Loss: 0.0594461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0473725\n",
      "\tspeed: 0.1991s/iter; left time: 1987.2282s\n",
      "\titers: 200, epoch: 56 | loss: 0.0474448\n",
      "\tspeed: 0.1268s/iter; left time: 1252.9267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:27.83s\n",
      "Steps: 224 | Train Loss: 0.0516708 Vali Loss: 0.0529323 Test Loss: 0.0594687\n",
      "Validation loss decreased (0.052954 --> 0.052932).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0475008\n",
      "\tspeed: 0.2073s/iter; left time: 2022.5499s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523390\n",
      "\tspeed: 0.1267s/iter; left time: 1223.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:27.66s\n",
      "Steps: 224 | Train Loss: 0.0516606 Vali Loss: 0.0529457 Test Loss: 0.0595112\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0514652\n",
      "\tspeed: 0.0937s/iter; left time: 893.5721s\n",
      "\titers: 200, epoch: 58 | loss: 0.0510385\n",
      "\tspeed: 0.0419s/iter; left time: 394.7933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0516258 Vali Loss: 0.0530078 Test Loss: 0.0594691\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0523517\n",
      "\tspeed: 0.0745s/iter; left time: 693.8714s\n",
      "\titers: 200, epoch: 59 | loss: 0.0503257\n",
      "\tspeed: 0.0419s/iter; left time: 385.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0516860 Vali Loss: 0.0529880 Test Loss: 0.0595234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0493156\n",
      "\tspeed: 0.0738s/iter; left time: 670.6898s\n",
      "\titers: 200, epoch: 60 | loss: 0.0500680\n",
      "\tspeed: 0.0418s/iter; left time: 375.9259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516414 Vali Loss: 0.0530047 Test Loss: 0.0595303\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0520709\n",
      "\tspeed: 0.0737s/iter; left time: 652.8748s\n",
      "\titers: 200, epoch: 61 | loss: 0.0485221\n",
      "\tspeed: 0.0430s/iter; left time: 376.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0516731 Vali Loss: 0.0530099 Test Loss: 0.0595771\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0494203\n",
      "\tspeed: 0.0783s/iter; left time: 676.1625s\n",
      "\titers: 200, epoch: 62 | loss: 0.0503813\n",
      "\tspeed: 0.0434s/iter; left time: 370.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0516423 Vali Loss: 0.0530357 Test Loss: 0.0595844\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0526378\n",
      "\tspeed: 0.0798s/iter; left time: 671.5980s\n",
      "\titers: 200, epoch: 63 | loss: 0.0479659\n",
      "\tspeed: 0.0433s/iter; left time: 359.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0516823 Vali Loss: 0.0529699 Test Loss: 0.0594978\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0508766\n",
      "\tspeed: 0.0800s/iter; left time: 655.4513s\n",
      "\titers: 200, epoch: 64 | loss: 0.0505792\n",
      "\tspeed: 0.0438s/iter; left time: 353.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0530094 Test Loss: 0.0595359\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0496024\n",
      "\tspeed: 0.0792s/iter; left time: 630.9550s\n",
      "\titers: 200, epoch: 65 | loss: 0.0513106\n",
      "\tspeed: 0.0437s/iter; left time: 343.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0516431 Vali Loss: 0.0529733 Test Loss: 0.0594781\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0553750\n",
      "\tspeed: 0.0802s/iter; left time: 620.7282s\n",
      "\titers: 200, epoch: 66 | loss: 0.0515449\n",
      "\tspeed: 0.0441s/iter; left time: 336.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0517339 Vali Loss: 0.0529650 Test Loss: 0.0594281\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00978555716574192, rmse:0.09892197698354721, mae:0.05946873873472214, rse:0.291115403175354\n",
      "Intermediate time for ES and pred_len 24: 00h:27m:52.50s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1586270\n",
      "\tspeed: 0.0609s/iter; left time: 1358.5171s\n",
      "\titers: 200, epoch: 1 | loss: 0.1450784\n",
      "\tspeed: 0.0443s/iter; left time: 983.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 224 | Train Loss: 0.1628915 Vali Loss: 0.1497857 Test Loss: 0.1802254\n",
      "Validation loss decreased (inf --> 0.149786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918277\n",
      "\tspeed: 0.0842s/iter; left time: 1859.3174s\n",
      "\titers: 200, epoch: 2 | loss: 0.0816794\n",
      "\tspeed: 0.0447s/iter; left time: 983.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 224 | Train Loss: 0.0973313 Vali Loss: 0.0838464 Test Loss: 0.0949164\n",
      "Validation loss decreased (0.149786 --> 0.083846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829089\n",
      "\tspeed: 0.0812s/iter; left time: 1775.2768s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840276\n",
      "\tspeed: 0.0423s/iter; left time: 919.7388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0835588 Vali Loss: 0.0806199 Test Loss: 0.0917724\n",
      "Validation loss decreased (0.083846 --> 0.080620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808573\n",
      "\tspeed: 0.0795s/iter; left time: 1718.6657s\n",
      "\titers: 200, epoch: 4 | loss: 0.0771366\n",
      "\tspeed: 0.0432s/iter; left time: 929.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0804146 Vali Loss: 0.0785956 Test Loss: 0.0899684\n",
      "Validation loss decreased (0.080620 --> 0.078596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0811141\n",
      "\tspeed: 0.0808s/iter; left time: 1729.7450s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803113\n",
      "\tspeed: 0.0432s/iter; left time: 919.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0785678 Vali Loss: 0.0775166 Test Loss: 0.0890404\n",
      "Validation loss decreased (0.078596 --> 0.077517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755782\n",
      "\tspeed: 0.0802s/iter; left time: 1697.9951s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813857\n",
      "\tspeed: 0.0430s/iter; left time: 906.3293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0773221 Vali Loss: 0.0770633 Test Loss: 0.0883174\n",
      "Validation loss decreased (0.077517 --> 0.077063).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746969\n",
      "\tspeed: 0.0807s/iter; left time: 1690.2621s\n",
      "\titers: 200, epoch: 7 | loss: 0.0766782\n",
      "\tspeed: 0.0432s/iter; left time: 901.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0764304 Vali Loss: 0.0768258 Test Loss: 0.0879041\n",
      "Validation loss decreased (0.077063 --> 0.076826).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754822\n",
      "\tspeed: 0.0839s/iter; left time: 1739.1228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759594\n",
      "\tspeed: 0.0433s/iter; left time: 892.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0758011 Vali Loss: 0.0766668 Test Loss: 0.0877922\n",
      "Validation loss decreased (0.076826 --> 0.076667).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726592\n",
      "\tspeed: 0.0867s/iter; left time: 1777.7424s\n",
      "\titers: 200, epoch: 9 | loss: 0.0735152\n",
      "\tspeed: 0.0432s/iter; left time: 882.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0752415 Vali Loss: 0.0766290 Test Loss: 0.0876217\n",
      "Validation loss decreased (0.076667 --> 0.076629).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743559\n",
      "\tspeed: 0.0794s/iter; left time: 1610.5306s\n",
      "\titers: 200, epoch: 10 | loss: 0.0777107\n",
      "\tspeed: 0.0439s/iter; left time: 885.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0747904 Vali Loss: 0.0761793 Test Loss: 0.0872853\n",
      "Validation loss decreased (0.076629 --> 0.076179).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0745435\n",
      "\tspeed: 0.0863s/iter; left time: 1730.5839s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774285\n",
      "\tspeed: 0.0434s/iter; left time: 866.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0744887 Vali Loss: 0.0758530 Test Loss: 0.0868568\n",
      "Validation loss decreased (0.076179 --> 0.075853).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0747768\n",
      "\tspeed: 0.0824s/iter; left time: 1635.5455s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704287\n",
      "\tspeed: 0.0432s/iter; left time: 852.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0741229 Vali Loss: 0.0759289 Test Loss: 0.0864838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0732824\n",
      "\tspeed: 0.0816s/iter; left time: 1601.0958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723793\n",
      "\tspeed: 0.0432s/iter; left time: 843.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0738578 Vali Loss: 0.0760315 Test Loss: 0.0870588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0701876\n",
      "\tspeed: 0.0790s/iter; left time: 1532.5645s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745867\n",
      "\tspeed: 0.0440s/iter; left time: 849.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0736512 Vali Loss: 0.0758688 Test Loss: 0.0869034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0756198\n",
      "\tspeed: 0.0778s/iter; left time: 1490.6806s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735717\n",
      "\tspeed: 0.0440s/iter; left time: 838.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0732935 Vali Loss: 0.0758132 Test Loss: 0.0868040\n",
      "Validation loss decreased (0.075853 --> 0.075813).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0714306\n",
      "\tspeed: 0.0801s/iter; left time: 1517.3447s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736407\n",
      "\tspeed: 0.0432s/iter; left time: 812.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0731359 Vali Loss: 0.0755762 Test Loss: 0.0866504\n",
      "Validation loss decreased (0.075813 --> 0.075576).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0714845\n",
      "\tspeed: 0.1059s/iter; left time: 1982.6248s\n",
      "\titers: 200, epoch: 17 | loss: 0.0719373\n",
      "\tspeed: 0.0435s/iter; left time: 809.4978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0729409 Vali Loss: 0.0758209 Test Loss: 0.0867814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735483\n",
      "\tspeed: 0.0798s/iter; left time: 1475.8235s\n",
      "\titers: 200, epoch: 18 | loss: 0.0718875\n",
      "\tspeed: 0.0433s/iter; left time: 797.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0727708 Vali Loss: 0.0758975 Test Loss: 0.0866312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726891\n",
      "\tspeed: 0.0794s/iter; left time: 1450.2026s\n",
      "\titers: 200, epoch: 19 | loss: 0.0692141\n",
      "\tspeed: 0.0434s/iter; left time: 789.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0727016 Vali Loss: 0.0755487 Test Loss: 0.0864635\n",
      "Validation loss decreased (0.075576 --> 0.075549).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0737528\n",
      "\tspeed: 0.0862s/iter; left time: 1556.2331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0728427\n",
      "\tspeed: 0.0439s/iter; left time: 788.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0724692 Vali Loss: 0.0755976 Test Loss: 0.0864065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0726215\n",
      "\tspeed: 0.0788s/iter; left time: 1404.9209s\n",
      "\titers: 200, epoch: 21 | loss: 0.0720892\n",
      "\tspeed: 0.0431s/iter; left time: 763.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0724086 Vali Loss: 0.0755949 Test Loss: 0.0864117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723771\n",
      "\tspeed: 0.0784s/iter; left time: 1380.1135s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696119\n",
      "\tspeed: 0.0434s/iter; left time: 759.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0722944 Vali Loss: 0.0755619 Test Loss: 0.0864713\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0689607\n",
      "\tspeed: 0.0802s/iter; left time: 1392.7066s\n",
      "\titers: 200, epoch: 23 | loss: 0.0684920\n",
      "\tspeed: 0.0435s/iter; left time: 752.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0722183 Vali Loss: 0.0756311 Test Loss: 0.0865839\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0713682\n",
      "\tspeed: 0.0802s/iter; left time: 1375.7347s\n",
      "\titers: 200, epoch: 24 | loss: 0.0739676\n",
      "\tspeed: 0.0434s/iter; left time: 739.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0721205 Vali Loss: 0.0753485 Test Loss: 0.0863606\n",
      "Validation loss decreased (0.075549 --> 0.075348).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0724736\n",
      "\tspeed: 0.0805s/iter; left time: 1363.2252s\n",
      "\titers: 200, epoch: 25 | loss: 0.0702187\n",
      "\tspeed: 0.0436s/iter; left time: 733.6587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0720138 Vali Loss: 0.0755377 Test Loss: 0.0865106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0746010\n",
      "\tspeed: 0.0790s/iter; left time: 1318.5786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0682516\n",
      "\tspeed: 0.0439s/iter; left time: 729.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0719424 Vali Loss: 0.0755066 Test Loss: 0.0864553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0756939\n",
      "\tspeed: 0.0788s/iter; left time: 1297.7518s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694480\n",
      "\tspeed: 0.0431s/iter; left time: 706.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0719031 Vali Loss: 0.0754957 Test Loss: 0.0865196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0707726\n",
      "\tspeed: 0.0786s/iter; left time: 1278.0298s\n",
      "\titers: 200, epoch: 28 | loss: 0.0729235\n",
      "\tspeed: 0.0432s/iter; left time: 697.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0718348 Vali Loss: 0.0756311 Test Loss: 0.0866816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716222\n",
      "\tspeed: 0.0825s/iter; left time: 1321.7298s\n",
      "\titers: 200, epoch: 29 | loss: 0.0678281\n",
      "\tspeed: 0.0435s/iter; left time: 692.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0718101 Vali Loss: 0.0753566 Test Loss: 0.0863243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0712663\n",
      "\tspeed: 0.0787s/iter; left time: 1243.0862s\n",
      "\titers: 200, epoch: 30 | loss: 0.0745299\n",
      "\tspeed: 0.0442s/iter; left time: 693.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0718021 Vali Loss: 0.0753349 Test Loss: 0.0863798\n",
      "Validation loss decreased (0.075348 --> 0.075335).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0724587\n",
      "\tspeed: 0.0914s/iter; left time: 1423.6349s\n",
      "\titers: 200, epoch: 31 | loss: 0.0724711\n",
      "\tspeed: 0.0432s/iter; left time: 668.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0716330 Vali Loss: 0.0754693 Test Loss: 0.0865439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0730980\n",
      "\tspeed: 0.0812s/iter; left time: 1247.6069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705433\n",
      "\tspeed: 0.0439s/iter; left time: 669.1235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0716719 Vali Loss: 0.0754019 Test Loss: 0.0864273\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0715316\n",
      "\tspeed: 0.0783s/iter; left time: 1184.4293s\n",
      "\titers: 200, epoch: 33 | loss: 0.0711717\n",
      "\tspeed: 0.0436s/iter; left time: 654.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0715782 Vali Loss: 0.0754586 Test Loss: 0.0865546\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697430\n",
      "\tspeed: 0.0785s/iter; left time: 1169.7244s\n",
      "\titers: 200, epoch: 34 | loss: 0.0722043\n",
      "\tspeed: 0.0435s/iter; left time: 644.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0716041 Vali Loss: 0.0755848 Test Loss: 0.0867919\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753731\n",
      "\tspeed: 0.0797s/iter; left time: 1170.0707s\n",
      "\titers: 200, epoch: 35 | loss: 0.0724049\n",
      "\tspeed: 0.0431s/iter; left time: 629.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0716068 Vali Loss: 0.0754728 Test Loss: 0.0866043\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0714311\n",
      "\tspeed: 0.0792s/iter; left time: 1144.7564s\n",
      "\titers: 200, epoch: 36 | loss: 0.0718317\n",
      "\tspeed: 0.0433s/iter; left time: 621.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0714898 Vali Loss: 0.0754767 Test Loss: 0.0865963\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0701757\n",
      "\tspeed: 0.0813s/iter; left time: 1156.8416s\n",
      "\titers: 200, epoch: 37 | loss: 0.0718206\n",
      "\tspeed: 0.0439s/iter; left time: 620.6708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0715510 Vali Loss: 0.0754377 Test Loss: 0.0864953\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0731241\n",
      "\tspeed: 0.0784s/iter; left time: 1098.6226s\n",
      "\titers: 200, epoch: 38 | loss: 0.0693968\n",
      "\tspeed: 0.0438s/iter; left time: 608.7576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0715072 Vali Loss: 0.0754432 Test Loss: 0.0865382\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0723001\n",
      "\tspeed: 0.0799s/iter; left time: 1101.7771s\n",
      "\titers: 200, epoch: 39 | loss: 0.0704393\n",
      "\tspeed: 0.0432s/iter; left time: 591.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0714562 Vali Loss: 0.0755303 Test Loss: 0.0867850\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0707888\n",
      "\tspeed: 0.0814s/iter; left time: 1104.0422s\n",
      "\titers: 200, epoch: 40 | loss: 0.0684797\n",
      "\tspeed: 0.0439s/iter; left time: 591.1543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0714900 Vali Loss: 0.0754403 Test Loss: 0.0864604\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01853589527308941, rmse:0.13614659011363983, mae:0.086379773914814, rse:0.39995771646499634\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1595100\n",
      "\tspeed: 0.0460s/iter; left time: 1026.6767s\n",
      "\titers: 200, epoch: 1 | loss: 0.1464803\n",
      "\tspeed: 0.0435s/iter; left time: 966.7590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 224 | Train Loss: 0.1623900 Vali Loss: 0.1494924 Test Loss: 0.1800590\n",
      "Validation loss decreased (inf --> 0.149492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974927\n",
      "\tspeed: 0.0972s/iter; left time: 2146.4310s\n",
      "\titers: 200, epoch: 2 | loss: 0.0831096\n",
      "\tspeed: 0.0442s/iter; left time: 972.0529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.13s\n",
      "Steps: 224 | Train Loss: 0.0989482 Vali Loss: 0.0836564 Test Loss: 0.0951239\n",
      "Validation loss decreased (0.149492 --> 0.083656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0859427\n",
      "\tspeed: 0.0882s/iter; left time: 1926.3782s\n",
      "\titers: 200, epoch: 3 | loss: 0.0827934\n",
      "\tspeed: 0.0432s/iter; left time: 940.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 224 | Train Loss: 0.0840580 Vali Loss: 0.0804858 Test Loss: 0.0919310\n",
      "Validation loss decreased (0.083656 --> 0.080486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809943\n",
      "\tspeed: 0.0853s/iter; left time: 1844.2546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0824453\n",
      "\tspeed: 0.0485s/iter; left time: 1044.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.68s\n",
      "Steps: 224 | Train Loss: 0.0809367 Vali Loss: 0.0787052 Test Loss: 0.0902697\n",
      "Validation loss decreased (0.080486 --> 0.078705).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784219\n",
      "\tspeed: 0.0865s/iter; left time: 1852.5851s\n",
      "\titers: 200, epoch: 5 | loss: 0.0777955\n",
      "\tspeed: 0.0441s/iter; left time: 938.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.38s\n",
      "Steps: 224 | Train Loss: 0.0786152 Vali Loss: 0.0776663 Test Loss: 0.0886390\n",
      "Validation loss decreased (0.078705 --> 0.077666).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0771296\n",
      "\tspeed: 0.0928s/iter; left time: 1965.7520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751691\n",
      "\tspeed: 0.0476s/iter; left time: 1003.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 224 | Train Loss: 0.0773966 Vali Loss: 0.0769601 Test Loss: 0.0882143\n",
      "Validation loss decreased (0.077666 --> 0.076960).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770102\n",
      "\tspeed: 0.0869s/iter; left time: 1820.4239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743075\n",
      "\tspeed: 0.0467s/iter; left time: 974.1946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 224 | Train Loss: 0.0765820 Vali Loss: 0.0765978 Test Loss: 0.0877772\n",
      "Validation loss decreased (0.076960 --> 0.076598).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752847\n",
      "\tspeed: 0.0853s/iter; left time: 1767.8104s\n",
      "\titers: 200, epoch: 8 | loss: 0.0798416\n",
      "\tspeed: 0.0458s/iter; left time: 944.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0758869 Vali Loss: 0.0762154 Test Loss: 0.0875819\n",
      "Validation loss decreased (0.076598 --> 0.076215).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779041\n",
      "\tspeed: 0.0852s/iter; left time: 1747.8906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0767852\n",
      "\tspeed: 0.0475s/iter; left time: 969.5431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0753483 Vali Loss: 0.0761540 Test Loss: 0.0874702\n",
      "Validation loss decreased (0.076215 --> 0.076154).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750211\n",
      "\tspeed: 0.0876s/iter; left time: 1777.6915s\n",
      "\titers: 200, epoch: 10 | loss: 0.0759499\n",
      "\tspeed: 0.0439s/iter; left time: 886.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.25s\n",
      "Steps: 224 | Train Loss: 0.0748687 Vali Loss: 0.0757517 Test Loss: 0.0869395\n",
      "Validation loss decreased (0.076154 --> 0.075752).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746947\n",
      "\tspeed: 0.0864s/iter; left time: 1733.4514s\n",
      "\titers: 200, epoch: 11 | loss: 0.0727347\n",
      "\tspeed: 0.0441s/iter; left time: 879.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 224 | Train Loss: 0.0744353 Vali Loss: 0.0759637 Test Loss: 0.0869859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0743605\n",
      "\tspeed: 0.0840s/iter; left time: 1665.7074s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748632\n",
      "\tspeed: 0.0430s/iter; left time: 847.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.0740608 Vali Loss: 0.0756004 Test Loss: 0.0868234\n",
      "Validation loss decreased (0.075752 --> 0.075600).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698201\n",
      "\tspeed: 0.1110s/iter; left time: 2177.4018s\n",
      "\titers: 200, epoch: 13 | loss: 0.0715147\n",
      "\tspeed: 0.0495s/iter; left time: 965.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0737650 Vali Loss: 0.0755211 Test Loss: 0.0866745\n",
      "Validation loss decreased (0.075600 --> 0.075521).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0690998\n",
      "\tspeed: 0.0907s/iter; left time: 1757.6743s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740039\n",
      "\tspeed: 0.0427s/iter; left time: 822.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 224 | Train Loss: 0.0734863 Vali Loss: 0.0755634 Test Loss: 0.0866108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747141\n",
      "\tspeed: 0.0898s/iter; left time: 1721.8217s\n",
      "\titers: 200, epoch: 15 | loss: 0.0715218\n",
      "\tspeed: 0.0449s/iter; left time: 856.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 224 | Train Loss: 0.0732544 Vali Loss: 0.0754703 Test Loss: 0.0863815\n",
      "Validation loss decreased (0.075521 --> 0.075470).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0757171\n",
      "\tspeed: 0.1318s/iter; left time: 2496.1738s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741671\n",
      "\tspeed: 0.0439s/iter; left time: 826.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 224 | Train Loss: 0.0730401 Vali Loss: 0.0754147 Test Loss: 0.0865284\n",
      "Validation loss decreased (0.075470 --> 0.075415).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0738392\n",
      "\tspeed: 0.0886s/iter; left time: 1658.1517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0738164\n",
      "\tspeed: 0.0532s/iter; left time: 990.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 224 | Train Loss: 0.0727451 Vali Loss: 0.0753884 Test Loss: 0.0866636\n",
      "Validation loss decreased (0.075415 --> 0.075388).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0709763\n",
      "\tspeed: 0.0946s/iter; left time: 1749.5390s\n",
      "\titers: 200, epoch: 18 | loss: 0.0730822\n",
      "\tspeed: 0.0481s/iter; left time: 884.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 224 | Train Loss: 0.0725751 Vali Loss: 0.0753965 Test Loss: 0.0865688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0742952\n",
      "\tspeed: 0.0884s/iter; left time: 1614.6894s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760767\n",
      "\tspeed: 0.0481s/iter; left time: 874.2227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.80s\n",
      "Steps: 224 | Train Loss: 0.0724123 Vali Loss: 0.0755017 Test Loss: 0.0866896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718111\n",
      "\tspeed: 0.0877s/iter; left time: 1582.9746s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710565\n",
      "\tspeed: 0.0445s/iter; left time: 797.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.69s\n",
      "Steps: 224 | Train Loss: 0.0723087 Vali Loss: 0.0754631 Test Loss: 0.0866524\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0719257\n",
      "\tspeed: 0.0792s/iter; left time: 1412.1959s\n",
      "\titers: 200, epoch: 21 | loss: 0.0696810\n",
      "\tspeed: 0.0440s/iter; left time: 780.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0721695 Vali Loss: 0.0753144 Test Loss: 0.0863799\n",
      "Validation loss decreased (0.075388 --> 0.075314).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0725704\n",
      "\tspeed: 0.0797s/iter; left time: 1402.1948s\n",
      "\titers: 200, epoch: 22 | loss: 0.0757288\n",
      "\tspeed: 0.0451s/iter; left time: 789.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0720685 Vali Loss: 0.0754024 Test Loss: 0.0867224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0705284\n",
      "\tspeed: 0.0779s/iter; left time: 1353.3379s\n",
      "\titers: 200, epoch: 23 | loss: 0.0728130\n",
      "\tspeed: 0.0435s/iter; left time: 750.8516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0718940 Vali Loss: 0.0753721 Test Loss: 0.0865993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695775\n",
      "\tspeed: 0.0795s/iter; left time: 1364.1229s\n",
      "\titers: 200, epoch: 24 | loss: 0.0694624\n",
      "\tspeed: 0.0442s/iter; left time: 754.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0718041 Vali Loss: 0.0755413 Test Loss: 0.0868192\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0702295\n",
      "\tspeed: 0.0801s/iter; left time: 1355.2470s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673121\n",
      "\tspeed: 0.0441s/iter; left time: 741.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0717452 Vali Loss: 0.0753333 Test Loss: 0.0865029\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0699733\n",
      "\tspeed: 0.0797s/iter; left time: 1330.2455s\n",
      "\titers: 200, epoch: 26 | loss: 0.0694492\n",
      "\tspeed: 0.0441s/iter; left time: 732.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0716570 Vali Loss: 0.0753502 Test Loss: 0.0866323\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0750768\n",
      "\tspeed: 0.0805s/iter; left time: 1326.4382s\n",
      "\titers: 200, epoch: 27 | loss: 0.0676697\n",
      "\tspeed: 0.0434s/iter; left time: 711.0155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0715888 Vali Loss: 0.0753193 Test Loss: 0.0866331\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0697221\n",
      "\tspeed: 0.0787s/iter; left time: 1279.2560s\n",
      "\titers: 200, epoch: 28 | loss: 0.0742003\n",
      "\tspeed: 0.0445s/iter; left time: 718.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0714908 Vali Loss: 0.0753599 Test Loss: 0.0865416\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0737176\n",
      "\tspeed: 0.0802s/iter; left time: 1286.2247s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728098\n",
      "\tspeed: 0.0435s/iter; left time: 692.9588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0714532 Vali Loss: 0.0753859 Test Loss: 0.0867439\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0677266\n",
      "\tspeed: 0.0799s/iter; left time: 1263.2798s\n",
      "\titers: 200, epoch: 30 | loss: 0.0682861\n",
      "\tspeed: 0.0440s/iter; left time: 691.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0713848 Vali Loss: 0.0754361 Test Loss: 0.0865617\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0686235\n",
      "\tspeed: 0.0793s/iter; left time: 1235.7145s\n",
      "\titers: 200, epoch: 31 | loss: 0.0683744\n",
      "\tspeed: 0.0431s/iter; left time: 667.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0713562 Vali Loss: 0.0753999 Test Loss: 0.0868126\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018505122512578964, rmse:0.1360335350036621, mae:0.08637991547584534, rse:0.39962559938430786\n",
      "Intermediate time for ES and pred_len 96: 00h:15m:23.53s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1582002\n",
      "\tspeed: 0.0627s/iter; left time: 1392.8210s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504422\n",
      "\tspeed: 0.0426s/iter; left time: 941.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.1638853 Vali Loss: 0.1523434 Test Loss: 0.1819368\n",
      "Validation loss decreased (inf --> 0.152343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989957\n",
      "\tspeed: 0.0782s/iter; left time: 1719.1541s\n",
      "\titers: 200, epoch: 2 | loss: 0.0933139\n",
      "\tspeed: 0.0427s/iter; left time: 933.3875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.1013221 Vali Loss: 0.0892732 Test Loss: 0.1013731\n",
      "Validation loss decreased (0.152343 --> 0.089273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939221\n",
      "\tspeed: 0.0775s/iter; left time: 1685.8470s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870873\n",
      "\tspeed: 0.0426s/iter; left time: 922.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0888086 Vali Loss: 0.0861637 Test Loss: 0.0980787\n",
      "Validation loss decreased (0.089273 --> 0.086164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854114\n",
      "\tspeed: 0.0776s/iter; left time: 1670.6925s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838073\n",
      "\tspeed: 0.0426s/iter; left time: 912.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0857859 Vali Loss: 0.0842218 Test Loss: 0.0960832\n",
      "Validation loss decreased (0.086164 --> 0.084222).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821497\n",
      "\tspeed: 0.0772s/iter; left time: 1645.1318s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822526\n",
      "\tspeed: 0.0426s/iter; left time: 902.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0838813 Vali Loss: 0.0834715 Test Loss: 0.0949565\n",
      "Validation loss decreased (0.084222 --> 0.083471).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830588\n",
      "\tspeed: 0.0779s/iter; left time: 1642.6264s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822484\n",
      "\tspeed: 0.0425s/iter; left time: 892.9373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0827285 Vali Loss: 0.0832899 Test Loss: 0.0945786\n",
      "Validation loss decreased (0.083471 --> 0.083290).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0846333\n",
      "\tspeed: 0.0770s/iter; left time: 1606.7264s\n",
      "\titers: 200, epoch: 7 | loss: 0.0803458\n",
      "\tspeed: 0.0426s/iter; left time: 884.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0819744 Vali Loss: 0.0828027 Test Loss: 0.0940958\n",
      "Validation loss decreased (0.083290 --> 0.082803).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823168\n",
      "\tspeed: 0.0771s/iter; left time: 1591.3274s\n",
      "\titers: 200, epoch: 8 | loss: 0.0828552\n",
      "\tspeed: 0.0426s/iter; left time: 875.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0813660 Vali Loss: 0.0828556 Test Loss: 0.0939133\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780621\n",
      "\tspeed: 0.0768s/iter; left time: 1567.9788s\n",
      "\titers: 200, epoch: 9 | loss: 0.0816576\n",
      "\tspeed: 0.0427s/iter; left time: 867.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0808007 Vali Loss: 0.0826950 Test Loss: 0.0937721\n",
      "Validation loss decreased (0.082803 --> 0.082695).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775661\n",
      "\tspeed: 0.0964s/iter; left time: 1947.1080s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774189\n",
      "\tspeed: 0.0426s/iter; left time: 856.2542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 223 | Train Loss: 0.0802986 Vali Loss: 0.0825369 Test Loss: 0.0934516\n",
      "Validation loss decreased (0.082695 --> 0.082537).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796763\n",
      "\tspeed: 0.0781s/iter; left time: 1560.4622s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782240\n",
      "\tspeed: 0.0429s/iter; left time: 852.5089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 223 | Train Loss: 0.0798780 Vali Loss: 0.0824189 Test Loss: 0.0934367\n",
      "Validation loss decreased (0.082537 --> 0.082419).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813513\n",
      "\tspeed: 0.0784s/iter; left time: 1548.8565s\n",
      "\titers: 200, epoch: 12 | loss: 0.0797516\n",
      "\tspeed: 0.0426s/iter; left time: 837.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0794918 Vali Loss: 0.0824583 Test Loss: 0.0934083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0798676\n",
      "\tspeed: 0.0767s/iter; left time: 1498.4231s\n",
      "\titers: 200, epoch: 13 | loss: 0.0763271\n",
      "\tspeed: 0.0427s/iter; left time: 828.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0791038 Vali Loss: 0.0821107 Test Loss: 0.0937554\n",
      "Validation loss decreased (0.082419 --> 0.082111).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0794068\n",
      "\tspeed: 0.0782s/iter; left time: 1509.0850s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772176\n",
      "\tspeed: 0.0429s/iter; left time: 824.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 223 | Train Loss: 0.0787783 Vali Loss: 0.0821921 Test Loss: 0.0937325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0795014\n",
      "\tspeed: 0.0776s/iter; left time: 1479.8416s\n",
      "\titers: 200, epoch: 15 | loss: 0.0759366\n",
      "\tspeed: 0.0426s/iter; left time: 808.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0784788 Vali Loss: 0.0824661 Test Loss: 0.0939714\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786937\n",
      "\tspeed: 0.0771s/iter; left time: 1452.9907s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787571\n",
      "\tspeed: 0.0426s/iter; left time: 798.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0782784 Vali Loss: 0.0822087 Test Loss: 0.0945132\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0774266\n",
      "\tspeed: 0.0768s/iter; left time: 1430.4289s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766618\n",
      "\tspeed: 0.0426s/iter; left time: 788.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0780505 Vali Loss: 0.0822913 Test Loss: 0.0946241\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0793561\n",
      "\tspeed: 0.0764s/iter; left time: 1405.9621s\n",
      "\titers: 200, epoch: 18 | loss: 0.0766027\n",
      "\tspeed: 0.0427s/iter; left time: 781.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0778071 Vali Loss: 0.0824921 Test Loss: 0.0951358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0807288\n",
      "\tspeed: 0.0761s/iter; left time: 1383.5080s\n",
      "\titers: 200, epoch: 19 | loss: 0.0765183\n",
      "\tspeed: 0.0426s/iter; left time: 771.2372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0776330 Vali Loss: 0.0822682 Test Loss: 0.0952981\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0763897\n",
      "\tspeed: 0.0766s/iter; left time: 1375.7542s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792303\n",
      "\tspeed: 0.0426s/iter; left time: 760.7483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0775091 Vali Loss: 0.0822907 Test Loss: 0.0952427\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0762942\n",
      "\tspeed: 0.0763s/iter; left time: 1354.1459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771212\n",
      "\tspeed: 0.0426s/iter; left time: 750.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0773324 Vali Loss: 0.0822556 Test Loss: 0.0953331\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0753811\n",
      "\tspeed: 0.0762s/iter; left time: 1335.6703s\n",
      "\titers: 200, epoch: 22 | loss: 0.0768200\n",
      "\tspeed: 0.0426s/iter; left time: 741.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0772267 Vali Loss: 0.0820854 Test Loss: 0.0957104\n",
      "Validation loss decreased (0.082111 --> 0.082085).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765416\n",
      "\tspeed: 0.0770s/iter; left time: 1332.0961s\n",
      "\titers: 200, epoch: 23 | loss: 0.0776889\n",
      "\tspeed: 0.0426s/iter; left time: 732.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0770907 Vali Loss: 0.0822180 Test Loss: 0.0957075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0802181\n",
      "\tspeed: 0.0778s/iter; left time: 1327.7908s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708010\n",
      "\tspeed: 0.0428s/iter; left time: 725.5914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.0769400 Vali Loss: 0.0820887 Test Loss: 0.0957013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785841\n",
      "\tspeed: 0.0768s/iter; left time: 1293.5946s\n",
      "\titers: 200, epoch: 25 | loss: 0.0719926\n",
      "\tspeed: 0.0426s/iter; left time: 713.7501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0768448 Vali Loss: 0.0822283 Test Loss: 0.0959574\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0766644\n",
      "\tspeed: 0.0760s/iter; left time: 1263.3435s\n",
      "\titers: 200, epoch: 26 | loss: 0.0741731\n",
      "\tspeed: 0.0425s/iter; left time: 702.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0767627 Vali Loss: 0.0821415 Test Loss: 0.0960435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0779996\n",
      "\tspeed: 0.0758s/iter; left time: 1244.1082s\n",
      "\titers: 200, epoch: 27 | loss: 0.0773505\n",
      "\tspeed: 0.0426s/iter; left time: 694.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0766876 Vali Loss: 0.0821087 Test Loss: 0.0960073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762004\n",
      "\tspeed: 0.0762s/iter; left time: 1233.6128s\n",
      "\titers: 200, epoch: 28 | loss: 0.0732721\n",
      "\tspeed: 0.0426s/iter; left time: 684.3079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0766399 Vali Loss: 0.0821509 Test Loss: 0.0961446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777855\n",
      "\tspeed: 0.0757s/iter; left time: 1207.1792s\n",
      "\titers: 200, epoch: 29 | loss: 0.0782245\n",
      "\tspeed: 0.0425s/iter; left time: 674.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765682 Vali Loss: 0.0822768 Test Loss: 0.0963000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0783652\n",
      "\tspeed: 0.0757s/iter; left time: 1191.0149s\n",
      "\titers: 200, epoch: 30 | loss: 0.0760999\n",
      "\tspeed: 0.0426s/iter; left time: 665.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765361 Vali Loss: 0.0823724 Test Loss: 0.0966561\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0737685\n",
      "\tspeed: 0.0761s/iter; left time: 1179.6887s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757145\n",
      "\tspeed: 0.0426s/iter; left time: 656.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0764457 Vali Loss: 0.0821356 Test Loss: 0.0963666\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0770690\n",
      "\tspeed: 0.0760s/iter; left time: 1162.2512s\n",
      "\titers: 200, epoch: 32 | loss: 0.0798712\n",
      "\tspeed: 0.0426s/iter; left time: 646.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0763819 Vali Loss: 0.0822384 Test Loss: 0.0966226\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021373990923166275, rmse:0.14619846642017365, mae:0.09571041911840439, rse:0.4295179545879364\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1623213\n",
      "\tspeed: 0.0443s/iter; left time: 983.0044s\n",
      "\titers: 200, epoch: 1 | loss: 0.1507847\n",
      "\tspeed: 0.0424s/iter; left time: 937.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.1635632 Vali Loss: 0.1513731 Test Loss: 0.1804650\n",
      "Validation loss decreased (inf --> 0.151373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0967694\n",
      "\tspeed: 0.0798s/iter; left time: 1753.0825s\n",
      "\titers: 200, epoch: 2 | loss: 0.0900421\n",
      "\tspeed: 0.0425s/iter; left time: 929.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.1009800 Vali Loss: 0.0887405 Test Loss: 0.1008240\n",
      "Validation loss decreased (0.151373 --> 0.088740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0906517\n",
      "\tspeed: 0.1047s/iter; left time: 2278.7332s\n",
      "\titers: 200, epoch: 3 | loss: 0.0844556\n",
      "\tspeed: 0.0425s/iter; left time: 921.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0886283 Vali Loss: 0.0860639 Test Loss: 0.0981020\n",
      "Validation loss decreased (0.088740 --> 0.086064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862825\n",
      "\tspeed: 0.0946s/iter; left time: 2036.0942s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867988\n",
      "\tspeed: 0.0424s/iter; left time: 909.2479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0857093 Vali Loss: 0.0843615 Test Loss: 0.0962627\n",
      "Validation loss decreased (0.086064 --> 0.084361).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0855029\n",
      "\tspeed: 0.0833s/iter; left time: 1775.0499s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834127\n",
      "\tspeed: 0.0425s/iter; left time: 901.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0839361 Vali Loss: 0.0838893 Test Loss: 0.0956411\n",
      "Validation loss decreased (0.084361 --> 0.083889).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834710\n",
      "\tspeed: 0.0783s/iter; left time: 1651.8429s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811198\n",
      "\tspeed: 0.0425s/iter; left time: 891.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0828296 Vali Loss: 0.0837776 Test Loss: 0.0951267\n",
      "Validation loss decreased (0.083889 --> 0.083778).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861155\n",
      "\tspeed: 0.0770s/iter; left time: 1605.6841s\n",
      "\titers: 200, epoch: 7 | loss: 0.0855570\n",
      "\tspeed: 0.0425s/iter; left time: 882.7584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0820855 Vali Loss: 0.0831758 Test Loss: 0.0944226\n",
      "Validation loss decreased (0.083778 --> 0.083176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832355\n",
      "\tspeed: 0.0770s/iter; left time: 1589.2364s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795388\n",
      "\tspeed: 0.0425s/iter; left time: 873.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0814745 Vali Loss: 0.0831434 Test Loss: 0.0941327\n",
      "Validation loss decreased (0.083176 --> 0.083143).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795199\n",
      "\tspeed: 0.0766s/iter; left time: 1563.0382s\n",
      "\titers: 200, epoch: 9 | loss: 0.0825877\n",
      "\tspeed: 0.0425s/iter; left time: 862.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0809013 Vali Loss: 0.0832683 Test Loss: 0.0939217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0840776\n",
      "\tspeed: 0.0758s/iter; left time: 1530.1837s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821245\n",
      "\tspeed: 0.0425s/iter; left time: 854.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0804636 Vali Loss: 0.0829914 Test Loss: 0.0936194\n",
      "Validation loss decreased (0.083143 --> 0.082991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0797929\n",
      "\tspeed: 0.0770s/iter; left time: 1538.2168s\n",
      "\titers: 200, epoch: 11 | loss: 0.0799730\n",
      "\tspeed: 0.0425s/iter; left time: 844.1887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0800309 Vali Loss: 0.0829647 Test Loss: 0.0932871\n",
      "Validation loss decreased (0.082991 --> 0.082965).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810702\n",
      "\tspeed: 0.0768s/iter; left time: 1515.7670s\n",
      "\titers: 200, epoch: 12 | loss: 0.0835351\n",
      "\tspeed: 0.0425s/iter; left time: 835.8600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0796978 Vali Loss: 0.0829677 Test Loss: 0.0933932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0758945\n",
      "\tspeed: 0.0757s/iter; left time: 1479.0157s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817818\n",
      "\tspeed: 0.0425s/iter; left time: 825.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0793328 Vali Loss: 0.0829195 Test Loss: 0.0931888\n",
      "Validation loss decreased (0.082965 --> 0.082920).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800635\n",
      "\tspeed: 0.0772s/iter; left time: 1490.3276s\n",
      "\titers: 200, epoch: 14 | loss: 0.0825971\n",
      "\tspeed: 0.0426s/iter; left time: 817.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0789841 Vali Loss: 0.0826235 Test Loss: 0.0933784\n",
      "Validation loss decreased (0.082920 --> 0.082624).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0811006\n",
      "\tspeed: 0.0766s/iter; left time: 1461.9138s\n",
      "\titers: 200, epoch: 15 | loss: 0.0775294\n",
      "\tspeed: 0.0425s/iter; left time: 806.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0787673 Vali Loss: 0.0826715 Test Loss: 0.0933170\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789641\n",
      "\tspeed: 0.0757s/iter; left time: 1428.3418s\n",
      "\titers: 200, epoch: 16 | loss: 0.0824256\n",
      "\tspeed: 0.0425s/iter; left time: 797.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0785044 Vali Loss: 0.0825806 Test Loss: 0.0933613\n",
      "Validation loss decreased (0.082624 --> 0.082581).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0765666\n",
      "\tspeed: 0.0785s/iter; left time: 1461.7693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0772372\n",
      "\tspeed: 0.0425s/iter; left time: 788.3513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0781951 Vali Loss: 0.0824544 Test Loss: 0.0936698\n",
      "Validation loss decreased (0.082581 --> 0.082454).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735902\n",
      "\tspeed: 0.0769s/iter; left time: 1415.0900s\n",
      "\titers: 200, epoch: 18 | loss: 0.0794902\n",
      "\tspeed: 0.0425s/iter; left time: 777.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0779698 Vali Loss: 0.0825212 Test Loss: 0.0938011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772863\n",
      "\tspeed: 0.0757s/iter; left time: 1377.1688s\n",
      "\titers: 200, epoch: 19 | loss: 0.0747855\n",
      "\tspeed: 0.0425s/iter; left time: 769.3198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0777663 Vali Loss: 0.0825519 Test Loss: 0.0940492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0817482\n",
      "\tspeed: 0.0752s/iter; left time: 1350.6536s\n",
      "\titers: 200, epoch: 20 | loss: 0.0781768\n",
      "\tspeed: 0.0425s/iter; left time: 758.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0776105 Vali Loss: 0.0823942 Test Loss: 0.0938594\n",
      "Validation loss decreased (0.082454 --> 0.082394).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749328\n",
      "\tspeed: 0.0770s/iter; left time: 1366.7279s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789955\n",
      "\tspeed: 0.0425s/iter; left time: 749.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0774189 Vali Loss: 0.0823355 Test Loss: 0.0942890\n",
      "Validation loss decreased (0.082394 --> 0.082336).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0805455\n",
      "\tspeed: 0.0782s/iter; left time: 1369.4373s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754221\n",
      "\tspeed: 0.0425s/iter; left time: 741.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0773240 Vali Loss: 0.0822265 Test Loss: 0.0943614\n",
      "Validation loss decreased (0.082336 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0787228\n",
      "\tspeed: 0.0766s/iter; left time: 1324.1679s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742987\n",
      "\tspeed: 0.0425s/iter; left time: 731.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0772184 Vali Loss: 0.0823955 Test Loss: 0.0947567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775053\n",
      "\tspeed: 0.0755s/iter; left time: 1289.7837s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773024\n",
      "\tspeed: 0.0425s/iter; left time: 720.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0770285 Vali Loss: 0.0822210 Test Loss: 0.0943585\n",
      "Validation loss decreased (0.082226 --> 0.082221).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0765192\n",
      "\tspeed: 0.0774s/iter; left time: 1304.1396s\n",
      "\titers: 200, epoch: 25 | loss: 0.0779399\n",
      "\tspeed: 0.0425s/iter; left time: 711.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0769189 Vali Loss: 0.0821099 Test Loss: 0.0946129\n",
      "Validation loss decreased (0.082221 --> 0.082110).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0753684\n",
      "\tspeed: 0.0765s/iter; left time: 1271.9256s\n",
      "\titers: 200, epoch: 26 | loss: 0.0782473\n",
      "\tspeed: 0.0425s/iter; left time: 702.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0768195 Vali Loss: 0.0822617 Test Loss: 0.0949533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0764916\n",
      "\tspeed: 0.0759s/iter; left time: 1244.3974s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755978\n",
      "\tspeed: 0.0425s/iter; left time: 692.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0767680 Vali Loss: 0.0822143 Test Loss: 0.0950215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734486\n",
      "\tspeed: 0.0756s/iter; left time: 1222.4507s\n",
      "\titers: 200, epoch: 28 | loss: 0.0753237\n",
      "\tspeed: 0.0425s/iter; left time: 683.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0767142 Vali Loss: 0.0821859 Test Loss: 0.0945747\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0775932\n",
      "\tspeed: 0.0753s/iter; left time: 1201.2036s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780666\n",
      "\tspeed: 0.0425s/iter; left time: 673.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0765791 Vali Loss: 0.0820457 Test Loss: 0.0951564\n",
      "Validation loss decreased (0.082110 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0747046\n",
      "\tspeed: 0.0762s/iter; left time: 1199.6400s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805135\n",
      "\tspeed: 0.0425s/iter; left time: 665.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765586 Vali Loss: 0.0822913 Test Loss: 0.0951025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0762359\n",
      "\tspeed: 0.0764s/iter; left time: 1185.5860s\n",
      "\titers: 200, epoch: 31 | loss: 0.0755212\n",
      "\tspeed: 0.0426s/iter; left time: 655.8050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0764912 Vali Loss: 0.0820334 Test Loss: 0.0949782\n",
      "Validation loss decreased (0.082046 --> 0.082033).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0777004\n",
      "\tspeed: 0.0774s/iter; left time: 1183.8726s\n",
      "\titers: 200, epoch: 32 | loss: 0.0789844\n",
      "\tspeed: 0.0425s/iter; left time: 645.8433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0763796 Vali Loss: 0.0821568 Test Loss: 0.0956396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0738203\n",
      "\tspeed: 0.0753s/iter; left time: 1133.8288s\n",
      "\titers: 200, epoch: 33 | loss: 0.0756400\n",
      "\tspeed: 0.0425s/iter; left time: 636.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0763773 Vali Loss: 0.0821474 Test Loss: 0.0955317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754073\n",
      "\tspeed: 0.0756s/iter; left time: 1121.8630s\n",
      "\titers: 200, epoch: 34 | loss: 0.0707455\n",
      "\tspeed: 0.0424s/iter; left time: 625.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0763250 Vali Loss: 0.0821367 Test Loss: 0.0955293\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779735\n",
      "\tspeed: 0.0761s/iter; left time: 1113.0678s\n",
      "\titers: 200, epoch: 35 | loss: 0.0737309\n",
      "\tspeed: 0.0425s/iter; left time: 617.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762472 Vali Loss: 0.0820737 Test Loss: 0.0954533\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0777511\n",
      "\tspeed: 0.0757s/iter; left time: 1089.2019s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743867\n",
      "\tspeed: 0.0425s/iter; left time: 607.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762374 Vali Loss: 0.0821034 Test Loss: 0.0954588\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752488\n",
      "\tspeed: 0.0754s/iter; left time: 1069.0803s\n",
      "\titers: 200, epoch: 37 | loss: 0.0746293\n",
      "\tspeed: 0.0425s/iter; left time: 597.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0762136 Vali Loss: 0.0821561 Test Loss: 0.0956381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0745010\n",
      "\tspeed: 0.0755s/iter; left time: 1053.0512s\n",
      "\titers: 200, epoch: 38 | loss: 0.0772252\n",
      "\tspeed: 0.0425s/iter; left time: 589.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762028 Vali Loss: 0.0821295 Test Loss: 0.0955146\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0767802\n",
      "\tspeed: 0.0757s/iter; left time: 1038.6736s\n",
      "\titers: 200, epoch: 39 | loss: 0.0752683\n",
      "\tspeed: 0.0426s/iter; left time: 579.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0761856 Vali Loss: 0.0820946 Test Loss: 0.0955351\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0760245\n",
      "\tspeed: 0.0756s/iter; left time: 1021.2602s\n",
      "\titers: 200, epoch: 40 | loss: 0.0747323\n",
      "\tspeed: 0.0425s/iter; left time: 569.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761252 Vali Loss: 0.0821186 Test Loss: 0.0957213\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0742132\n",
      "\tspeed: 0.0755s/iter; left time: 1002.3750s\n",
      "\titers: 200, epoch: 41 | loss: 0.0766348\n",
      "\tspeed: 0.0425s/iter; left time: 559.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0760819 Vali Loss: 0.0822180 Test Loss: 0.0961468\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021038100123405457, rmse:0.14504516124725342, mae:0.09497818350791931, rse:0.42612963914871216\n",
      "Intermediate time for ES and pred_len 168: 00h:14m:49.56s\n",
      "Intermediate time for ES: 00h:58m:05.59s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1121947\n",
      "\tspeed: 0.0616s/iter; left time: 1374.4072s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003998\n",
      "\tspeed: 0.0419s/iter; left time: 930.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 224 | Train Loss: 0.1124252 Vali Loss: 0.1140230 Test Loss: 0.1257952\n",
      "Validation loss decreased (inf --> 0.114023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0552393\n",
      "\tspeed: 0.0758s/iter; left time: 1672.7063s\n",
      "\titers: 200, epoch: 2 | loss: 0.0489163\n",
      "\tspeed: 0.0419s/iter; left time: 920.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0612217 Vali Loss: 0.0596655 Test Loss: 0.0627740\n",
      "Validation loss decreased (0.114023 --> 0.059665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0480090\n",
      "\tspeed: 0.0751s/iter; left time: 1642.0388s\n",
      "\titers: 200, epoch: 3 | loss: 0.0485542\n",
      "\tspeed: 0.0419s/iter; left time: 911.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0487076 Vali Loss: 0.0571585 Test Loss: 0.0603112\n",
      "Validation loss decreased (0.059665 --> 0.057158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0447154\n",
      "\tspeed: 0.0762s/iter; left time: 1648.6851s\n",
      "\titers: 200, epoch: 4 | loss: 0.0429314\n",
      "\tspeed: 0.0419s/iter; left time: 902.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0464313 Vali Loss: 0.0554574 Test Loss: 0.0589497\n",
      "Validation loss decreased (0.057158 --> 0.055457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0423501\n",
      "\tspeed: 0.0769s/iter; left time: 1645.4209s\n",
      "\titers: 200, epoch: 5 | loss: 0.0467467\n",
      "\tspeed: 0.0419s/iter; left time: 892.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0449963 Vali Loss: 0.0544936 Test Loss: 0.0579954\n",
      "Validation loss decreased (0.055457 --> 0.054494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0428498\n",
      "\tspeed: 0.0767s/iter; left time: 1624.9825s\n",
      "\titers: 200, epoch: 6 | loss: 0.0431722\n",
      "\tspeed: 0.0419s/iter; left time: 882.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0438708 Vali Loss: 0.0535841 Test Loss: 0.0572606\n",
      "Validation loss decreased (0.054494 --> 0.053584).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0450463\n",
      "\tspeed: 0.0750s/iter; left time: 1571.3184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0422882\n",
      "\tspeed: 0.0419s/iter; left time: 873.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0432172 Vali Loss: 0.0532738 Test Loss: 0.0568294\n",
      "Validation loss decreased (0.053584 --> 0.053274).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0423689\n",
      "\tspeed: 0.0750s/iter; left time: 1555.0621s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431759\n",
      "\tspeed: 0.0418s/iter; left time: 863.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0426508 Vali Loss: 0.0527346 Test Loss: 0.0564877\n",
      "Validation loss decreased (0.053274 --> 0.052735).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423538\n",
      "\tspeed: 0.0751s/iter; left time: 1539.7498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0434452\n",
      "\tspeed: 0.0418s/iter; left time: 853.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0422342 Vali Loss: 0.0526336 Test Loss: 0.0563798\n",
      "Validation loss decreased (0.052735 --> 0.052634).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0398495\n",
      "\tspeed: 0.0748s/iter; left time: 1517.5962s\n",
      "\titers: 200, epoch: 10 | loss: 0.0404127\n",
      "\tspeed: 0.0419s/iter; left time: 845.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0419349 Vali Loss: 0.0524291 Test Loss: 0.0560434\n",
      "Validation loss decreased (0.052634 --> 0.052429).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0450116\n",
      "\tspeed: 0.0759s/iter; left time: 1522.7725s\n",
      "\titers: 200, epoch: 11 | loss: 0.0409348\n",
      "\tspeed: 0.0419s/iter; left time: 835.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0416426 Vali Loss: 0.0523388 Test Loss: 0.0560597\n",
      "Validation loss decreased (0.052429 --> 0.052339).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0402090\n",
      "\tspeed: 0.0752s/iter; left time: 1491.2999s\n",
      "\titers: 200, epoch: 12 | loss: 0.0399124\n",
      "\tspeed: 0.0419s/iter; left time: 826.9813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0414412 Vali Loss: 0.0522899 Test Loss: 0.0560075\n",
      "Validation loss decreased (0.052339 --> 0.052290).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0402795\n",
      "\tspeed: 0.0752s/iter; left time: 1474.5507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0442635\n",
      "\tspeed: 0.0419s/iter; left time: 816.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0412266 Vali Loss: 0.0521753 Test Loss: 0.0559162\n",
      "Validation loss decreased (0.052290 --> 0.052175).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0446919\n",
      "\tspeed: 0.0757s/iter; left time: 1467.3655s\n",
      "\titers: 200, epoch: 14 | loss: 0.0414494\n",
      "\tspeed: 0.0418s/iter; left time: 806.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0410329 Vali Loss: 0.0520798 Test Loss: 0.0556257\n",
      "Validation loss decreased (0.052175 --> 0.052080).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0421744\n",
      "\tspeed: 0.0752s/iter; left time: 1440.4107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421534\n",
      "\tspeed: 0.0418s/iter; left time: 797.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0408562 Vali Loss: 0.0522112 Test Loss: 0.0558546\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0408129\n",
      "\tspeed: 0.0745s/iter; left time: 1410.9069s\n",
      "\titers: 200, epoch: 16 | loss: 0.0392103\n",
      "\tspeed: 0.0419s/iter; left time: 788.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0407342 Vali Loss: 0.0521150 Test Loss: 0.0556049\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0377135\n",
      "\tspeed: 0.0743s/iter; left time: 1390.6428s\n",
      "\titers: 200, epoch: 17 | loss: 0.0385958\n",
      "\tspeed: 0.0419s/iter; left time: 779.2561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0406220 Vali Loss: 0.0520192 Test Loss: 0.0556480\n",
      "Validation loss decreased (0.052080 --> 0.052019).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0409500\n",
      "\tspeed: 0.0752s/iter; left time: 1390.7876s\n",
      "\titers: 200, epoch: 18 | loss: 0.0358631\n",
      "\tspeed: 0.0419s/iter; left time: 770.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0404933 Vali Loss: 0.0520228 Test Loss: 0.0554515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0379888\n",
      "\tspeed: 0.0744s/iter; left time: 1359.0458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0403270\n",
      "\tspeed: 0.0418s/iter; left time: 759.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0404586 Vali Loss: 0.0519224 Test Loss: 0.0554611\n",
      "Validation loss decreased (0.052019 --> 0.051922).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0409930\n",
      "\tspeed: 0.0752s/iter; left time: 1356.5940s\n",
      "\titers: 200, epoch: 20 | loss: 0.0405406\n",
      "\tspeed: 0.0418s/iter; left time: 749.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0403426 Vali Loss: 0.0520369 Test Loss: 0.0555618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0371660\n",
      "\tspeed: 0.0744s/iter; left time: 1326.5618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0402139\n",
      "\tspeed: 0.0419s/iter; left time: 742.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0402404 Vali Loss: 0.0519488 Test Loss: 0.0553637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0398164\n",
      "\tspeed: 0.0742s/iter; left time: 1304.9531s\n",
      "\titers: 200, epoch: 22 | loss: 0.0436726\n",
      "\tspeed: 0.0418s/iter; left time: 731.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0401827 Vali Loss: 0.0519050 Test Loss: 0.0553965\n",
      "Validation loss decreased (0.051922 --> 0.051905).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0383529\n",
      "\tspeed: 0.0755s/iter; left time: 1312.1832s\n",
      "\titers: 200, epoch: 23 | loss: 0.0441570\n",
      "\tspeed: 0.0418s/iter; left time: 721.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0400947 Vali Loss: 0.0519855 Test Loss: 0.0553256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0421799\n",
      "\tspeed: 0.0747s/iter; left time: 1280.7122s\n",
      "\titers: 200, epoch: 24 | loss: 0.0399955\n",
      "\tspeed: 0.0419s/iter; left time: 714.2296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0400648 Vali Loss: 0.0518750 Test Loss: 0.0554042\n",
      "Validation loss decreased (0.051905 --> 0.051875).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0394646\n",
      "\tspeed: 0.0755s/iter; left time: 1278.0270s\n",
      "\titers: 200, epoch: 25 | loss: 0.0383344\n",
      "\tspeed: 0.0418s/iter; left time: 703.8966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0400411 Vali Loss: 0.0519205 Test Loss: 0.0554544\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0413884\n",
      "\tspeed: 0.0747s/iter; left time: 1247.6525s\n",
      "\titers: 200, epoch: 26 | loss: 0.0399774\n",
      "\tspeed: 0.0418s/iter; left time: 694.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0399985 Vali Loss: 0.0519550 Test Loss: 0.0554619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0379206\n",
      "\tspeed: 0.0743s/iter; left time: 1223.5739s\n",
      "\titers: 200, epoch: 27 | loss: 0.0381168\n",
      "\tspeed: 0.0418s/iter; left time: 685.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399392 Vali Loss: 0.0518430 Test Loss: 0.0552859\n",
      "Validation loss decreased (0.051875 --> 0.051843).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0418810\n",
      "\tspeed: 0.0751s/iter; left time: 1220.8654s\n",
      "\titers: 200, epoch: 28 | loss: 0.0435387\n",
      "\tspeed: 0.0418s/iter; left time: 675.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399106 Vali Loss: 0.0518326 Test Loss: 0.0552616\n",
      "Validation loss decreased (0.051843 --> 0.051833).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0398603\n",
      "\tspeed: 0.0751s/iter; left time: 1203.2948s\n",
      "\titers: 200, epoch: 29 | loss: 0.0391199\n",
      "\tspeed: 0.0418s/iter; left time: 666.2721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0398559 Vali Loss: 0.0517640 Test Loss: 0.0552997\n",
      "Validation loss decreased (0.051833 --> 0.051764).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0415632\n",
      "\tspeed: 0.0750s/iter; left time: 1184.8973s\n",
      "\titers: 200, epoch: 30 | loss: 0.0422339\n",
      "\tspeed: 0.0419s/iter; left time: 657.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398787 Vali Loss: 0.0519103 Test Loss: 0.0553084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0399636\n",
      "\tspeed: 0.0751s/iter; left time: 1169.8527s\n",
      "\titers: 200, epoch: 31 | loss: 0.0369008\n",
      "\tspeed: 0.0419s/iter; left time: 648.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0398472 Vali Loss: 0.0518308 Test Loss: 0.0553513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0412430\n",
      "\tspeed: 0.0745s/iter; left time: 1144.2156s\n",
      "\titers: 200, epoch: 32 | loss: 0.0370305\n",
      "\tspeed: 0.0419s/iter; left time: 639.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0398461 Vali Loss: 0.0517918 Test Loss: 0.0553053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0375985\n",
      "\tspeed: 0.0746s/iter; left time: 1128.6510s\n",
      "\titers: 200, epoch: 33 | loss: 0.0408965\n",
      "\tspeed: 0.0419s/iter; left time: 629.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0397410 Vali Loss: 0.0518667 Test Loss: 0.0553178\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425997\n",
      "\tspeed: 0.0745s/iter; left time: 1111.3305s\n",
      "\titers: 200, epoch: 34 | loss: 0.0426921\n",
      "\tspeed: 0.0418s/iter; left time: 619.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397880 Vali Loss: 0.0518058 Test Loss: 0.0552537\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0403167\n",
      "\tspeed: 0.0752s/iter; left time: 1104.1239s\n",
      "\titers: 200, epoch: 35 | loss: 0.0391564\n",
      "\tspeed: 0.0419s/iter; left time: 611.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0397668 Vali Loss: 0.0518420 Test Loss: 0.0553296\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0378390\n",
      "\tspeed: 0.0743s/iter; left time: 1074.8417s\n",
      "\titers: 200, epoch: 36 | loss: 0.0453756\n",
      "\tspeed: 0.0419s/iter; left time: 602.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0397611 Vali Loss: 0.0517751 Test Loss: 0.0553614\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0439057\n",
      "\tspeed: 0.0750s/iter; left time: 1067.3460s\n",
      "\titers: 200, epoch: 37 | loss: 0.0392089\n",
      "\tspeed: 0.0419s/iter; left time: 591.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0397189 Vali Loss: 0.0518174 Test Loss: 0.0553212\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0399152\n",
      "\tspeed: 0.0763s/iter; left time: 1068.7099s\n",
      "\titers: 200, epoch: 38 | loss: 0.0420879\n",
      "\tspeed: 0.0419s/iter; left time: 582.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0397264 Vali Loss: 0.0517921 Test Loss: 0.0552313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0389435\n",
      "\tspeed: 0.0745s/iter; left time: 1027.9415s\n",
      "\titers: 200, epoch: 39 | loss: 0.0397875\n",
      "\tspeed: 0.0419s/iter; left time: 573.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0396921 Vali Loss: 0.0518452 Test Loss: 0.0552375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01012234017252922, rmse:0.10060983896255493, mae:0.05529971793293953, rse:0.3881499767303467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1097454\n",
      "\tspeed: 0.0434s/iter; left time: 968.2699s\n",
      "\titers: 200, epoch: 1 | loss: 0.1002832\n",
      "\tspeed: 0.0419s/iter; left time: 929.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.1106880 Vali Loss: 0.1126629 Test Loss: 0.1250687\n",
      "Validation loss decreased (inf --> 0.112663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0544365\n",
      "\tspeed: 0.0749s/iter; left time: 1654.1496s\n",
      "\titers: 200, epoch: 2 | loss: 0.0556558\n",
      "\tspeed: 0.0418s/iter; left time: 918.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0617991 Vali Loss: 0.0603117 Test Loss: 0.0635018\n",
      "Validation loss decreased (0.112663 --> 0.060312).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0518334\n",
      "\tspeed: 0.0751s/iter; left time: 1640.6910s\n",
      "\titers: 200, epoch: 3 | loss: 0.0479707\n",
      "\tspeed: 0.0419s/iter; left time: 910.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0490852 Vali Loss: 0.0573255 Test Loss: 0.0607568\n",
      "Validation loss decreased (0.060312 --> 0.057326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0464834\n",
      "\tspeed: 0.0750s/iter; left time: 1621.4002s\n",
      "\titers: 200, epoch: 4 | loss: 0.0456835\n",
      "\tspeed: 0.0418s/iter; left time: 900.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0467785 Vali Loss: 0.0556423 Test Loss: 0.0590097\n",
      "Validation loss decreased (0.057326 --> 0.055642).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0453287\n",
      "\tspeed: 0.0748s/iter; left time: 1601.1447s\n",
      "\titers: 200, epoch: 5 | loss: 0.0429152\n",
      "\tspeed: 0.0419s/iter; left time: 892.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0452205 Vali Loss: 0.0545473 Test Loss: 0.0580783\n",
      "Validation loss decreased (0.055642 --> 0.054547).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0394759\n",
      "\tspeed: 0.0765s/iter; left time: 1620.3665s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427372\n",
      "\tspeed: 0.0419s/iter; left time: 882.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0442165 Vali Loss: 0.0534045 Test Loss: 0.0573112\n",
      "Validation loss decreased (0.054547 --> 0.053404).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0455463\n",
      "\tspeed: 0.0749s/iter; left time: 1569.5681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0445603\n",
      "\tspeed: 0.0419s/iter; left time: 874.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0433700 Vali Loss: 0.0530924 Test Loss: 0.0570183\n",
      "Validation loss decreased (0.053404 --> 0.053092).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449817\n",
      "\tspeed: 0.0751s/iter; left time: 1556.6396s\n",
      "\titers: 200, epoch: 8 | loss: 0.0429298\n",
      "\tspeed: 0.0420s/iter; left time: 865.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0428334 Vali Loss: 0.0531420 Test Loss: 0.0565075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423502\n",
      "\tspeed: 0.0743s/iter; left time: 1524.5959s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445846\n",
      "\tspeed: 0.0418s/iter; left time: 853.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0424026 Vali Loss: 0.0525870 Test Loss: 0.0563246\n",
      "Validation loss decreased (0.053092 --> 0.052587).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0425135\n",
      "\tspeed: 0.0749s/iter; left time: 1518.9674s\n",
      "\titers: 200, epoch: 10 | loss: 0.0457547\n",
      "\tspeed: 0.0419s/iter; left time: 845.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0419955 Vali Loss: 0.0525711 Test Loss: 0.0565309\n",
      "Validation loss decreased (0.052587 --> 0.052571).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0431648\n",
      "\tspeed: 0.0745s/iter; left time: 1494.6285s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424161\n",
      "\tspeed: 0.0419s/iter; left time: 835.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0417232 Vali Loss: 0.0522938 Test Loss: 0.0558724\n",
      "Validation loss decreased (0.052571 --> 0.052294).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0447426\n",
      "\tspeed: 0.0749s/iter; left time: 1486.5755s\n",
      "\titers: 200, epoch: 12 | loss: 0.0382844\n",
      "\tspeed: 0.0419s/iter; left time: 827.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0414626 Vali Loss: 0.0523507 Test Loss: 0.0559838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0380325\n",
      "\tspeed: 0.0741s/iter; left time: 1454.0632s\n",
      "\titers: 200, epoch: 13 | loss: 0.0404050\n",
      "\tspeed: 0.0419s/iter; left time: 817.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0412239 Vali Loss: 0.0520597 Test Loss: 0.0557181\n",
      "Validation loss decreased (0.052294 --> 0.052060).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0420314\n",
      "\tspeed: 0.0746s/iter; left time: 1446.5701s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441814\n",
      "\tspeed: 0.0418s/iter; left time: 807.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0410656 Vali Loss: 0.0517921 Test Loss: 0.0556048\n",
      "Validation loss decreased (0.052060 --> 0.051792).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0390570\n",
      "\tspeed: 0.0755s/iter; left time: 1447.3233s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447538\n",
      "\tspeed: 0.0419s/iter; left time: 798.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0408988 Vali Loss: 0.0519798 Test Loss: 0.0555771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0387387\n",
      "\tspeed: 0.0742s/iter; left time: 1406.3297s\n",
      "\titers: 200, epoch: 16 | loss: 0.0386383\n",
      "\tspeed: 0.0419s/iter; left time: 789.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0407904 Vali Loss: 0.0519261 Test Loss: 0.0554437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0408869\n",
      "\tspeed: 0.0740s/iter; left time: 1385.1167s\n",
      "\titers: 200, epoch: 17 | loss: 0.0388287\n",
      "\tspeed: 0.0418s/iter; left time: 778.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0407096 Vali Loss: 0.0518903 Test Loss: 0.0554077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0411886\n",
      "\tspeed: 0.0740s/iter; left time: 1368.3384s\n",
      "\titers: 200, epoch: 18 | loss: 0.0390267\n",
      "\tspeed: 0.0419s/iter; left time: 770.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0405676 Vali Loss: 0.0518208 Test Loss: 0.0553516\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0415021\n",
      "\tspeed: 0.0747s/iter; left time: 1364.7439s\n",
      "\titers: 200, epoch: 19 | loss: 0.0406355\n",
      "\tspeed: 0.0419s/iter; left time: 761.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0404403 Vali Loss: 0.0518093 Test Loss: 0.0553732\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0448347\n",
      "\tspeed: 0.0742s/iter; left time: 1339.4886s\n",
      "\titers: 200, epoch: 20 | loss: 0.0391173\n",
      "\tspeed: 0.0419s/iter; left time: 752.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0403546 Vali Loss: 0.0517789 Test Loss: 0.0553628\n",
      "Validation loss decreased (0.051792 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0398589\n",
      "\tspeed: 0.0749s/iter; left time: 1333.9295s\n",
      "\titers: 200, epoch: 21 | loss: 0.0381496\n",
      "\tspeed: 0.0418s/iter; left time: 741.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0402457 Vali Loss: 0.0518312 Test Loss: 0.0552614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0385531\n",
      "\tspeed: 0.0744s/iter; left time: 1308.5965s\n",
      "\titers: 200, epoch: 22 | loss: 0.0400891\n",
      "\tspeed: 0.0419s/iter; left time: 732.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0401808 Vali Loss: 0.0517388 Test Loss: 0.0554081\n",
      "Validation loss decreased (0.051779 --> 0.051739).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0384819\n",
      "\tspeed: 0.0749s/iter; left time: 1300.4983s\n",
      "\titers: 200, epoch: 23 | loss: 0.0368943\n",
      "\tspeed: 0.0418s/iter; left time: 722.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0401281 Vali Loss: 0.0517458 Test Loss: 0.0554174\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0401000\n",
      "\tspeed: 0.0740s/iter; left time: 1268.9119s\n",
      "\titers: 200, epoch: 24 | loss: 0.0394788\n",
      "\tspeed: 0.0418s/iter; left time: 713.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0401284 Vali Loss: 0.0517721 Test Loss: 0.0554288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0411244\n",
      "\tspeed: 0.0742s/iter; left time: 1255.8286s\n",
      "\titers: 200, epoch: 25 | loss: 0.0381236\n",
      "\tspeed: 0.0419s/iter; left time: 704.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0400445 Vali Loss: 0.0515828 Test Loss: 0.0552302\n",
      "Validation loss decreased (0.051739 --> 0.051583).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0426891\n",
      "\tspeed: 0.0745s/iter; left time: 1244.0759s\n",
      "\titers: 200, epoch: 26 | loss: 0.0411633\n",
      "\tspeed: 0.0420s/iter; left time: 696.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0399843 Vali Loss: 0.0516705 Test Loss: 0.0553208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0387271\n",
      "\tspeed: 0.0741s/iter; left time: 1220.1777s\n",
      "\titers: 200, epoch: 27 | loss: 0.0394193\n",
      "\tspeed: 0.0418s/iter; left time: 685.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399810 Vali Loss: 0.0517005 Test Loss: 0.0552868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0415462\n",
      "\tspeed: 0.0742s/iter; left time: 1206.3162s\n",
      "\titers: 200, epoch: 28 | loss: 0.0391410\n",
      "\tspeed: 0.0418s/iter; left time: 675.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0399579 Vali Loss: 0.0515849 Test Loss: 0.0552142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0436352\n",
      "\tspeed: 0.0745s/iter; left time: 1194.7335s\n",
      "\titers: 200, epoch: 29 | loss: 0.0375349\n",
      "\tspeed: 0.0419s/iter; left time: 667.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398951 Vali Loss: 0.0516627 Test Loss: 0.0551619\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0356513\n",
      "\tspeed: 0.0740s/iter; left time: 1169.8539s\n",
      "\titers: 200, epoch: 30 | loss: 0.0385870\n",
      "\tspeed: 0.0419s/iter; left time: 657.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398974 Vali Loss: 0.0516312 Test Loss: 0.0551637\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0412497\n",
      "\tspeed: 0.0741s/iter; left time: 1153.7925s\n",
      "\titers: 200, epoch: 31 | loss: 0.0410214\n",
      "\tspeed: 0.0419s/iter; left time: 647.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0398423 Vali Loss: 0.0515021 Test Loss: 0.0551850\n",
      "Validation loss decreased (0.051583 --> 0.051502).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0411650\n",
      "\tspeed: 0.0746s/iter; left time: 1145.7192s\n",
      "\titers: 200, epoch: 32 | loss: 0.0411897\n",
      "\tspeed: 0.0419s/iter; left time: 638.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0398447 Vali Loss: 0.0516524 Test Loss: 0.0552015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0414264\n",
      "\tspeed: 0.0740s/iter; left time: 1120.0349s\n",
      "\titers: 200, epoch: 33 | loss: 0.0373195\n",
      "\tspeed: 0.0418s/iter; left time: 628.1793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0398136 Vali Loss: 0.0515943 Test Loss: 0.0551456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0420447\n",
      "\tspeed: 0.0739s/iter; left time: 1102.4725s\n",
      "\titers: 200, epoch: 34 | loss: 0.0418415\n",
      "\tspeed: 0.0419s/iter; left time: 620.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0397582 Vali Loss: 0.0515836 Test Loss: 0.0551158\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0439957\n",
      "\tspeed: 0.0738s/iter; left time: 1083.5330s\n",
      "\titers: 200, epoch: 35 | loss: 0.0377602\n",
      "\tspeed: 0.0418s/iter; left time: 609.9313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0398037 Vali Loss: 0.0516123 Test Loss: 0.0551900\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0440431\n",
      "\tspeed: 0.0744s/iter; left time: 1075.2332s\n",
      "\titers: 200, epoch: 36 | loss: 0.0373870\n",
      "\tspeed: 0.0419s/iter; left time: 601.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0397717 Vali Loss: 0.0515656 Test Loss: 0.0551841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0430282\n",
      "\tspeed: 0.0740s/iter; left time: 1053.7770s\n",
      "\titers: 200, epoch: 37 | loss: 0.0413177\n",
      "\tspeed: 0.0418s/iter; left time: 590.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0397954 Vali Loss: 0.0515806 Test Loss: 0.0551719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0357447\n",
      "\tspeed: 0.0741s/iter; left time: 1038.3779s\n",
      "\titers: 200, epoch: 38 | loss: 0.0371809\n",
      "\tspeed: 0.0419s/iter; left time: 582.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397360 Vali Loss: 0.0515720 Test Loss: 0.0551558\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0388872\n",
      "\tspeed: 0.0741s/iter; left time: 1021.1464s\n",
      "\titers: 200, epoch: 39 | loss: 0.0369145\n",
      "\tspeed: 0.0419s/iter; left time: 573.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0397296 Vali Loss: 0.0516767 Test Loss: 0.0551596\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0407941\n",
      "\tspeed: 0.0740s/iter; left time: 1003.7769s\n",
      "\titers: 200, epoch: 40 | loss: 0.0428946\n",
      "\tspeed: 0.0419s/iter; left time: 564.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397577 Vali Loss: 0.0515838 Test Loss: 0.0551644\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0428438\n",
      "\tspeed: 0.0740s/iter; left time: 986.6249s\n",
      "\titers: 200, epoch: 41 | loss: 0.0403244\n",
      "\tspeed: 0.0419s/iter; left time: 554.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397225 Vali Loss: 0.0517354 Test Loss: 0.0551707\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010068370029330254, rmse:0.10034126788377762, mae:0.05518501251935959, rse:0.3871138393878937\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:43.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1153915\n",
      "\tspeed: 0.0624s/iter; left time: 1391.7446s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060928\n",
      "\tspeed: 0.0421s/iter; left time: 935.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.1190758 Vali Loss: 0.1222350 Test Loss: 0.1367866\n",
      "Validation loss decreased (inf --> 0.122235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0703590\n",
      "\tspeed: 0.0772s/iter; left time: 1704.1421s\n",
      "\titers: 200, epoch: 2 | loss: 0.0631227\n",
      "\tspeed: 0.0422s/iter; left time: 927.1204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0741752 Vali Loss: 0.0765218 Test Loss: 0.0841672\n",
      "Validation loss decreased (0.122235 --> 0.076522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638842\n",
      "\tspeed: 0.0775s/iter; left time: 1693.0687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638510\n",
      "\tspeed: 0.0422s/iter; left time: 918.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0637024 Vali Loss: 0.0740111 Test Loss: 0.0829004\n",
      "Validation loss decreased (0.076522 --> 0.074011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0599669\n",
      "\tspeed: 0.0774s/iter; left time: 1673.1504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602428\n",
      "\tspeed: 0.0422s/iter; left time: 907.7448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0613726 Vali Loss: 0.0729702 Test Loss: 0.0828571\n",
      "Validation loss decreased (0.074011 --> 0.072970).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608108\n",
      "\tspeed: 0.0765s/iter; left time: 1637.6600s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596332\n",
      "\tspeed: 0.0421s/iter; left time: 897.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0599371 Vali Loss: 0.0722665 Test Loss: 0.0831574\n",
      "Validation loss decreased (0.072970 --> 0.072266).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591320\n",
      "\tspeed: 0.0770s/iter; left time: 1630.0226s\n",
      "\titers: 200, epoch: 6 | loss: 0.0609036\n",
      "\tspeed: 0.0422s/iter; left time: 889.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0590100 Vali Loss: 0.0717653 Test Loss: 0.0822677\n",
      "Validation loss decreased (0.072266 --> 0.071765).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570013\n",
      "\tspeed: 0.0778s/iter; left time: 1630.2538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558092\n",
      "\tspeed: 0.0423s/iter; left time: 881.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0583290 Vali Loss: 0.0718643 Test Loss: 0.0817473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0584184\n",
      "\tspeed: 0.0772s/iter; left time: 1601.3778s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561043\n",
      "\tspeed: 0.0422s/iter; left time: 870.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 224 | Train Loss: 0.0577498 Vali Loss: 0.0716929 Test Loss: 0.0819808\n",
      "Validation loss decreased (0.071765 --> 0.071693).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547079\n",
      "\tspeed: 0.0776s/iter; left time: 1590.5815s\n",
      "\titers: 200, epoch: 9 | loss: 0.0589732\n",
      "\tspeed: 0.0422s/iter; left time: 861.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0572604 Vali Loss: 0.0716615 Test Loss: 0.0817608\n",
      "Validation loss decreased (0.071693 --> 0.071662).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549507\n",
      "\tspeed: 0.0771s/iter; left time: 1563.3897s\n",
      "\titers: 200, epoch: 10 | loss: 0.0595628\n",
      "\tspeed: 0.0421s/iter; left time: 850.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0569233 Vali Loss: 0.0713719 Test Loss: 0.0818009\n",
      "Validation loss decreased (0.071662 --> 0.071372).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583551\n",
      "\tspeed: 0.0763s/iter; left time: 1531.2724s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565592\n",
      "\tspeed: 0.0422s/iter; left time: 842.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0565333 Vali Loss: 0.0717262 Test Loss: 0.0822539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0552871\n",
      "\tspeed: 0.0763s/iter; left time: 1513.4371s\n",
      "\titers: 200, epoch: 12 | loss: 0.0534210\n",
      "\tspeed: 0.0422s/iter; left time: 833.0360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0562415 Vali Loss: 0.0716062 Test Loss: 0.0821118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0572377\n",
      "\tspeed: 0.0761s/iter; left time: 1491.5899s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547919\n",
      "\tspeed: 0.0422s/iter; left time: 822.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0560026 Vali Loss: 0.0715299 Test Loss: 0.0820022\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0594103\n",
      "\tspeed: 0.0772s/iter; left time: 1496.0266s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563948\n",
      "\tspeed: 0.0424s/iter; left time: 818.5080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 224 | Train Loss: 0.0557053 Vali Loss: 0.0715743 Test Loss: 0.0825353\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0562952\n",
      "\tspeed: 0.0766s/iter; left time: 1468.4562s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543950\n",
      "\tspeed: 0.0422s/iter; left time: 805.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0554924 Vali Loss: 0.0715357 Test Loss: 0.0822632\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0568288\n",
      "\tspeed: 0.0767s/iter; left time: 1453.3149s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553723\n",
      "\tspeed: 0.0422s/iter; left time: 795.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0552482 Vali Loss: 0.0717300 Test Loss: 0.0825441\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0568050\n",
      "\tspeed: 0.0768s/iter; left time: 1437.3798s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549970\n",
      "\tspeed: 0.0422s/iter; left time: 786.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0550776 Vali Loss: 0.0714888 Test Loss: 0.0823092\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0559789\n",
      "\tspeed: 0.0767s/iter; left time: 1419.1503s\n",
      "\titers: 200, epoch: 18 | loss: 0.0549825\n",
      "\tspeed: 0.0421s/iter; left time: 774.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0549379 Vali Loss: 0.0716566 Test Loss: 0.0824809\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0559283\n",
      "\tspeed: 0.0768s/iter; left time: 1403.8936s\n",
      "\titers: 200, epoch: 19 | loss: 0.0576035\n",
      "\tspeed: 0.0421s/iter; left time: 765.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0547359 Vali Loss: 0.0717991 Test Loss: 0.0826052\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0550359\n",
      "\tspeed: 0.0766s/iter; left time: 1381.6697s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536892\n",
      "\tspeed: 0.0422s/iter; left time: 756.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0545703 Vali Loss: 0.0716234 Test Loss: 0.0824642\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019618265330791473, rmse:0.14006522297859192, mae:0.08180088549852371, rse:0.5418094992637634\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1183382\n",
      "\tspeed: 0.0437s/iter; left time: 974.3214s\n",
      "\titers: 200, epoch: 1 | loss: 0.1067132\n",
      "\tspeed: 0.0421s/iter; left time: 935.1136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.1185646 Vali Loss: 0.1221652 Test Loss: 0.1369242\n",
      "Validation loss decreased (inf --> 0.122165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710205\n",
      "\tspeed: 0.0773s/iter; left time: 1707.0127s\n",
      "\titers: 200, epoch: 2 | loss: 0.0608164\n",
      "\tspeed: 0.0421s/iter; left time: 926.3223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0749036 Vali Loss: 0.0765365 Test Loss: 0.0847675\n",
      "Validation loss decreased (0.122165 --> 0.076536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0649917\n",
      "\tspeed: 0.0764s/iter; left time: 1668.8608s\n",
      "\titers: 200, epoch: 3 | loss: 0.0605547\n",
      "\tspeed: 0.0421s/iter; left time: 916.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0638909 Vali Loss: 0.0741018 Test Loss: 0.0832592\n",
      "Validation loss decreased (0.076536 --> 0.074102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0593064\n",
      "\tspeed: 0.0761s/iter; left time: 1647.0304s\n",
      "\titers: 200, epoch: 4 | loss: 0.0614190\n",
      "\tspeed: 0.0421s/iter; left time: 905.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0614330 Vali Loss: 0.0730869 Test Loss: 0.0835192\n",
      "Validation loss decreased (0.074102 --> 0.073087).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0564989\n",
      "\tspeed: 0.0767s/iter; left time: 1642.1587s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585219\n",
      "\tspeed: 0.0421s/iter; left time: 897.7183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0599615 Vali Loss: 0.0721415 Test Loss: 0.0823667\n",
      "Validation loss decreased (0.073087 --> 0.072142).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572291\n",
      "\tspeed: 0.0759s/iter; left time: 1608.0054s\n",
      "\titers: 200, epoch: 6 | loss: 0.0590202\n",
      "\tspeed: 0.0422s/iter; left time: 888.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0590873 Vali Loss: 0.0719854 Test Loss: 0.0822540\n",
      "Validation loss decreased (0.072142 --> 0.071985).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584348\n",
      "\tspeed: 0.0762s/iter; left time: 1597.6538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0593594\n",
      "\tspeed: 0.0422s/iter; left time: 879.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0583521 Vali Loss: 0.0719110 Test Loss: 0.0827368\n",
      "Validation loss decreased (0.071985 --> 0.071911).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565943\n",
      "\tspeed: 0.0763s/iter; left time: 1581.1418s\n",
      "\titers: 200, epoch: 8 | loss: 0.0581434\n",
      "\tspeed: 0.0422s/iter; left time: 869.9349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0577961 Vali Loss: 0.0715724 Test Loss: 0.0823652\n",
      "Validation loss decreased (0.071911 --> 0.071572).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559165\n",
      "\tspeed: 0.0762s/iter; left time: 1562.1366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555138\n",
      "\tspeed: 0.0421s/iter; left time: 860.1257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0573474 Vali Loss: 0.0714440 Test Loss: 0.0819069\n",
      "Validation loss decreased (0.071572 --> 0.071444).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0537653\n",
      "\tspeed: 0.0892s/iter; left time: 1808.9242s\n",
      "\titers: 200, epoch: 10 | loss: 0.0534346\n",
      "\tspeed: 0.0422s/iter; left time: 851.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0569286 Vali Loss: 0.0715755 Test Loss: 0.0818373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572650\n",
      "\tspeed: 0.0752s/iter; left time: 1509.2995s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564079\n",
      "\tspeed: 0.0422s/iter; left time: 842.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0565144 Vali Loss: 0.0715929 Test Loss: 0.0819250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553930\n",
      "\tspeed: 0.0754s/iter; left time: 1495.0413s\n",
      "\titers: 200, epoch: 12 | loss: 0.0512815\n",
      "\tspeed: 0.0421s/iter; left time: 831.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0562026 Vali Loss: 0.0716908 Test Loss: 0.0820340\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0598023\n",
      "\tspeed: 0.0754s/iter; left time: 1477.9890s\n",
      "\titers: 200, epoch: 13 | loss: 0.0541688\n",
      "\tspeed: 0.0421s/iter; left time: 821.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0559420 Vali Loss: 0.0715412 Test Loss: 0.0819712\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563550\n",
      "\tspeed: 0.0755s/iter; left time: 1464.3693s\n",
      "\titers: 200, epoch: 14 | loss: 0.0574557\n",
      "\tspeed: 0.0422s/iter; left time: 813.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0556303 Vali Loss: 0.0716937 Test Loss: 0.0818968\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598165\n",
      "\tspeed: 0.0754s/iter; left time: 1445.4423s\n",
      "\titers: 200, epoch: 15 | loss: 0.0571043\n",
      "\tspeed: 0.0421s/iter; left time: 803.5626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0553934 Vali Loss: 0.0717617 Test Loss: 0.0820680\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545634\n",
      "\tspeed: 0.0752s/iter; left time: 1424.8424s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518719\n",
      "\tspeed: 0.0421s/iter; left time: 793.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0552036 Vali Loss: 0.0718749 Test Loss: 0.0818940\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0536293\n",
      "\tspeed: 0.0756s/iter; left time: 1414.3057s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532682\n",
      "\tspeed: 0.0421s/iter; left time: 783.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0549504 Vali Loss: 0.0719338 Test Loss: 0.0821902\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0550838\n",
      "\tspeed: 0.0757s/iter; left time: 1400.5497s\n",
      "\titers: 200, epoch: 18 | loss: 0.0541445\n",
      "\tspeed: 0.0422s/iter; left time: 775.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0547627 Vali Loss: 0.0717970 Test Loss: 0.0820770\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564983\n",
      "\tspeed: 0.0757s/iter; left time: 1382.5145s\n",
      "\titers: 200, epoch: 19 | loss: 0.0564426\n",
      "\tspeed: 0.0421s/iter; left time: 765.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0546047 Vali Loss: 0.0719225 Test Loss: 0.0821915\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019422350451350212, rmse:0.139364093542099, mae:0.08190689235925674, rse:0.5390973091125488\n",
      "Intermediate time for FR and pred_len 96: 00h:07m:54.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1155179\n",
      "\tspeed: 0.0637s/iter; left time: 1413.8900s\n",
      "\titers: 200, epoch: 1 | loss: 0.1100524\n",
      "\tspeed: 0.0425s/iter; left time: 940.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.1203775 Vali Loss: 0.1246447 Test Loss: 0.1390694\n",
      "Validation loss decreased (inf --> 0.124645).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0748355\n",
      "\tspeed: 0.0768s/iter; left time: 1688.8321s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722877\n",
      "\tspeed: 0.0426s/iter; left time: 931.1336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0777110 Vali Loss: 0.0800677 Test Loss: 0.0888488\n",
      "Validation loss decreased (0.124645 --> 0.080068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0673887\n",
      "\tspeed: 0.0769s/iter; left time: 1673.5104s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638294\n",
      "\tspeed: 0.0426s/iter; left time: 921.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0680442 Vali Loss: 0.0776311 Test Loss: 0.0878397\n",
      "Validation loss decreased (0.080068 --> 0.077631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0655597\n",
      "\tspeed: 0.0765s/iter; left time: 1648.0794s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643643\n",
      "\tspeed: 0.0426s/iter; left time: 912.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0657154 Vali Loss: 0.0768263 Test Loss: 0.0878044\n",
      "Validation loss decreased (0.077631 --> 0.076826).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0671170\n",
      "\tspeed: 0.0771s/iter; left time: 1642.3895s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653071\n",
      "\tspeed: 0.0426s/iter; left time: 903.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0642069 Vali Loss: 0.0759690 Test Loss: 0.0875316\n",
      "Validation loss decreased (0.076826 --> 0.075969).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0666012\n",
      "\tspeed: 0.0772s/iter; left time: 1627.9053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617591\n",
      "\tspeed: 0.0426s/iter; left time: 893.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0632363 Vali Loss: 0.0758135 Test Loss: 0.0876818\n",
      "Validation loss decreased (0.075969 --> 0.075813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585363\n",
      "\tspeed: 0.0764s/iter; left time: 1593.3725s\n",
      "\titers: 200, epoch: 7 | loss: 0.0633577\n",
      "\tspeed: 0.0426s/iter; left time: 883.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0625940 Vali Loss: 0.0755322 Test Loss: 0.0875475\n",
      "Validation loss decreased (0.075813 --> 0.075532).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0626959\n",
      "\tspeed: 0.0771s/iter; left time: 1592.1634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0624156\n",
      "\tspeed: 0.0425s/iter; left time: 873.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0619335 Vali Loss: 0.0756845 Test Loss: 0.0881885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0658133\n",
      "\tspeed: 0.0755s/iter; left time: 1540.5036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0612553\n",
      "\tspeed: 0.0426s/iter; left time: 865.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0614354 Vali Loss: 0.0754083 Test Loss: 0.0879239\n",
      "Validation loss decreased (0.075532 --> 0.075408).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571346\n",
      "\tspeed: 0.0772s/iter; left time: 1558.3133s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608960\n",
      "\tspeed: 0.0426s/iter; left time: 855.4101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0609741 Vali Loss: 0.0752998 Test Loss: 0.0884806\n",
      "Validation loss decreased (0.075408 --> 0.075300).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601922\n",
      "\tspeed: 0.0769s/iter; left time: 1535.2761s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642126\n",
      "\tspeed: 0.0426s/iter; left time: 846.1209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0605561 Vali Loss: 0.0755705 Test Loss: 0.0886884\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595557\n",
      "\tspeed: 0.0753s/iter; left time: 1486.7759s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635985\n",
      "\tspeed: 0.0426s/iter; left time: 836.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0601814 Vali Loss: 0.0755608 Test Loss: 0.0883276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0604448\n",
      "\tspeed: 0.0757s/iter; left time: 1477.2736s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586777\n",
      "\tspeed: 0.0426s/iter; left time: 826.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0598141 Vali Loss: 0.0753468 Test Loss: 0.0888019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0574171\n",
      "\tspeed: 0.0758s/iter; left time: 1462.6341s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605751\n",
      "\tspeed: 0.0426s/iter; left time: 817.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0595079 Vali Loss: 0.0756135 Test Loss: 0.0885193\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0583936\n",
      "\tspeed: 0.0757s/iter; left time: 1444.8969s\n",
      "\titers: 200, epoch: 15 | loss: 0.0582936\n",
      "\tspeed: 0.0426s/iter; left time: 807.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0591883 Vali Loss: 0.0754839 Test Loss: 0.0893167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0576946\n",
      "\tspeed: 0.0756s/iter; left time: 1424.6166s\n",
      "\titers: 200, epoch: 16 | loss: 0.0599246\n",
      "\tspeed: 0.0426s/iter; left time: 798.9218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0589706 Vali Loss: 0.0754589 Test Loss: 0.0887578\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570811\n",
      "\tspeed: 0.0755s/iter; left time: 1407.5508s\n",
      "\titers: 200, epoch: 17 | loss: 0.0559282\n",
      "\tspeed: 0.0426s/iter; left time: 788.9323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0587052 Vali Loss: 0.0757231 Test Loss: 0.0894269\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0592673\n",
      "\tspeed: 0.0761s/iter; left time: 1401.6157s\n",
      "\titers: 200, epoch: 18 | loss: 0.0587642\n",
      "\tspeed: 0.0426s/iter; left time: 779.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0584797 Vali Loss: 0.0757971 Test Loss: 0.0895223\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0581048\n",
      "\tspeed: 0.0771s/iter; left time: 1402.8565s\n",
      "\titers: 200, epoch: 19 | loss: 0.0556847\n",
      "\tspeed: 0.0430s/iter; left time: 776.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0583845 Vali Loss: 0.0757172 Test Loss: 0.0894682\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0584915\n",
      "\tspeed: 0.0764s/iter; left time: 1372.8196s\n",
      "\titers: 200, epoch: 20 | loss: 0.0591433\n",
      "\tspeed: 0.0425s/iter; left time: 759.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0581833 Vali Loss: 0.0757980 Test Loss: 0.0896036\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02110251970589161, rmse:0.1452670693397522, mae:0.08848056942224503, rse:0.5626330971717834\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1188243\n",
      "\tspeed: 0.0442s/iter; left time: 980.8067s\n",
      "\titers: 200, epoch: 1 | loss: 0.1097503\n",
      "\tspeed: 0.0425s/iter; left time: 939.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.1206074 Vali Loss: 0.1249007 Test Loss: 0.1393432\n",
      "Validation loss decreased (inf --> 0.124901).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710360\n",
      "\tspeed: 0.0765s/iter; left time: 1680.9727s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703140\n",
      "\tspeed: 0.0425s/iter; left time: 929.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0782399 Vali Loss: 0.0799150 Test Loss: 0.0890377\n",
      "Validation loss decreased (0.124901 --> 0.079915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686920\n",
      "\tspeed: 0.0771s/iter; left time: 1676.4317s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669794\n",
      "\tspeed: 0.0426s/iter; left time: 921.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0680045 Vali Loss: 0.0777030 Test Loss: 0.0883915\n",
      "Validation loss decreased (0.079915 --> 0.077703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0687920\n",
      "\tspeed: 0.0768s/iter; left time: 1654.5862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625754\n",
      "\tspeed: 0.0425s/iter; left time: 911.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0655856 Vali Loss: 0.0768370 Test Loss: 0.0883045\n",
      "Validation loss decreased (0.077703 --> 0.076837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0662790\n",
      "\tspeed: 0.0766s/iter; left time: 1632.5732s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664349\n",
      "\tspeed: 0.0425s/iter; left time: 901.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0642683 Vali Loss: 0.0762139 Test Loss: 0.0878965\n",
      "Validation loss decreased (0.076837 --> 0.076214).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0642509\n",
      "\tspeed: 0.0764s/iter; left time: 1611.4528s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635850\n",
      "\tspeed: 0.0426s/iter; left time: 893.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0633435 Vali Loss: 0.0759457 Test Loss: 0.0877568\n",
      "Validation loss decreased (0.076214 --> 0.075946).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607359\n",
      "\tspeed: 0.0762s/iter; left time: 1589.6072s\n",
      "\titers: 200, epoch: 7 | loss: 0.0600543\n",
      "\tspeed: 0.0425s/iter; left time: 883.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0624938 Vali Loss: 0.0757794 Test Loss: 0.0877522\n",
      "Validation loss decreased (0.075946 --> 0.075779).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640830\n",
      "\tspeed: 0.0764s/iter; left time: 1577.2283s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560839\n",
      "\tspeed: 0.0425s/iter; left time: 873.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0618970 Vali Loss: 0.0753602 Test Loss: 0.0876144\n",
      "Validation loss decreased (0.075779 --> 0.075360).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0622873\n",
      "\tspeed: 0.0765s/iter; left time: 1561.7475s\n",
      "\titers: 200, epoch: 9 | loss: 0.0610187\n",
      "\tspeed: 0.0425s/iter; left time: 863.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0613768 Vali Loss: 0.0755588 Test Loss: 0.0880555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0610971\n",
      "\tspeed: 0.0764s/iter; left time: 1543.7533s\n",
      "\titers: 200, epoch: 10 | loss: 0.0619647\n",
      "\tspeed: 0.0425s/iter; left time: 854.0016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0608380 Vali Loss: 0.0755213 Test Loss: 0.0878433\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0598250\n",
      "\tspeed: 0.0752s/iter; left time: 1502.5919s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568953\n",
      "\tspeed: 0.0424s/iter; left time: 843.3894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0604825 Vali Loss: 0.0753327 Test Loss: 0.0883517\n",
      "Validation loss decreased (0.075360 --> 0.075333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650479\n",
      "\tspeed: 0.0766s/iter; left time: 1511.9582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589150\n",
      "\tspeed: 0.0425s/iter; left time: 835.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0600851 Vali Loss: 0.0752878 Test Loss: 0.0881361\n",
      "Validation loss decreased (0.075333 --> 0.075288).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0590905\n",
      "\tspeed: 0.0767s/iter; left time: 1496.7399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0612453\n",
      "\tspeed: 0.0426s/iter; left time: 827.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0597502 Vali Loss: 0.0754289 Test Loss: 0.0883999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0635281\n",
      "\tspeed: 0.0756s/iter; left time: 1459.6066s\n",
      "\titers: 200, epoch: 14 | loss: 0.0579555\n",
      "\tspeed: 0.0425s/iter; left time: 816.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0594261 Vali Loss: 0.0753699 Test Loss: 0.0886773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597168\n",
      "\tspeed: 0.0755s/iter; left time: 1440.9881s\n",
      "\titers: 200, epoch: 15 | loss: 0.0604776\n",
      "\tspeed: 0.0426s/iter; left time: 807.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0591478 Vali Loss: 0.0751815 Test Loss: 0.0885951\n",
      "Validation loss decreased (0.075288 --> 0.075181).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0589496\n",
      "\tspeed: 0.0765s/iter; left time: 1442.7705s\n",
      "\titers: 200, epoch: 16 | loss: 0.0610695\n",
      "\tspeed: 0.0425s/iter; left time: 797.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0589543 Vali Loss: 0.0751560 Test Loss: 0.0883089\n",
      "Validation loss decreased (0.075181 --> 0.075156).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0550328\n",
      "\tspeed: 0.0768s/iter; left time: 1431.0088s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588443\n",
      "\tspeed: 0.0425s/iter; left time: 788.2971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0587267 Vali Loss: 0.0753057 Test Loss: 0.0887895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0589852\n",
      "\tspeed: 0.0756s/iter; left time: 1392.1435s\n",
      "\titers: 200, epoch: 18 | loss: 0.0540140\n",
      "\tspeed: 0.0424s/iter; left time: 777.2582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0585811 Vali Loss: 0.0752828 Test Loss: 0.0889161\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0613710\n",
      "\tspeed: 0.0759s/iter; left time: 1380.8301s\n",
      "\titers: 200, epoch: 19 | loss: 0.0610498\n",
      "\tspeed: 0.0425s/iter; left time: 768.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0583974 Vali Loss: 0.0751852 Test Loss: 0.0891550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0590157\n",
      "\tspeed: 0.0758s/iter; left time: 1362.3051s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577403\n",
      "\tspeed: 0.0426s/iter; left time: 760.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0581863 Vali Loss: 0.0754698 Test Loss: 0.0890949\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0588164\n",
      "\tspeed: 0.0754s/iter; left time: 1338.3577s\n",
      "\titers: 200, epoch: 21 | loss: 0.0568125\n",
      "\tspeed: 0.0426s/iter; left time: 750.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0580332 Vali Loss: 0.0751449 Test Loss: 0.0890774\n",
      "Validation loss decreased (0.075156 --> 0.075145).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0591515\n",
      "\tspeed: 0.0766s/iter; left time: 1341.7912s\n",
      "\titers: 200, epoch: 22 | loss: 0.0634039\n",
      "\tspeed: 0.0426s/iter; left time: 741.5917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0579535 Vali Loss: 0.0754300 Test Loss: 0.0893191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592452\n",
      "\tspeed: 0.0773s/iter; left time: 1336.1128s\n",
      "\titers: 200, epoch: 23 | loss: 0.0575206\n",
      "\tspeed: 0.0424s/iter; left time: 729.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0578123 Vali Loss: 0.0751504 Test Loss: 0.0893139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0615129\n",
      "\tspeed: 0.0764s/iter; left time: 1303.9488s\n",
      "\titers: 200, epoch: 24 | loss: 0.0616597\n",
      "\tspeed: 0.0425s/iter; left time: 721.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0577369 Vali Loss: 0.0753552 Test Loss: 0.0894956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0577549\n",
      "\tspeed: 0.0755s/iter; left time: 1271.8893s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567556\n",
      "\tspeed: 0.0425s/iter; left time: 712.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0577064 Vali Loss: 0.0753523 Test Loss: 0.0895203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556293\n",
      "\tspeed: 0.0756s/iter; left time: 1256.2181s\n",
      "\titers: 200, epoch: 26 | loss: 0.0592692\n",
      "\tspeed: 0.0425s/iter; left time: 702.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0575957 Vali Loss: 0.0752099 Test Loss: 0.0895419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0605084\n",
      "\tspeed: 0.0758s/iter; left time: 1243.0994s\n",
      "\titers: 200, epoch: 27 | loss: 0.0537401\n",
      "\tspeed: 0.0426s/iter; left time: 693.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0574944 Vali Loss: 0.0752354 Test Loss: 0.0897313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553524\n",
      "\tspeed: 0.0754s/iter; left time: 1219.6317s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644381\n",
      "\tspeed: 0.0425s/iter; left time: 683.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0574452 Vali Loss: 0.0751127 Test Loss: 0.0895886\n",
      "Validation loss decreased (0.075145 --> 0.075113).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0528446\n",
      "\tspeed: 0.0765s/iter; left time: 1220.0697s\n",
      "\titers: 200, epoch: 29 | loss: 0.0540518\n",
      "\tspeed: 0.0425s/iter; left time: 674.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0573492 Vali Loss: 0.0753453 Test Loss: 0.0897618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0544832\n",
      "\tspeed: 0.0762s/iter; left time: 1198.7870s\n",
      "\titers: 200, epoch: 30 | loss: 0.0593685\n",
      "\tspeed: 0.0425s/iter; left time: 664.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0573188 Vali Loss: 0.0752593 Test Loss: 0.0897383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0577189\n",
      "\tspeed: 0.0758s/iter; left time: 1176.2468s\n",
      "\titers: 200, epoch: 31 | loss: 0.0564524\n",
      "\tspeed: 0.0425s/iter; left time: 654.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0572871 Vali Loss: 0.0752722 Test Loss: 0.0897646\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0579591\n",
      "\tspeed: 0.0754s/iter; left time: 1152.6390s\n",
      "\titers: 200, epoch: 32 | loss: 0.0566821\n",
      "\tspeed: 0.0425s/iter; left time: 646.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0572057 Vali Loss: 0.0752317 Test Loss: 0.0898037\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0567452\n",
      "\tspeed: 0.0757s/iter; left time: 1140.8596s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603444\n",
      "\tspeed: 0.0425s/iter; left time: 636.3376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0571794 Vali Loss: 0.0752111 Test Loss: 0.0897663\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0596642\n",
      "\tspeed: 0.0764s/iter; left time: 1133.3197s\n",
      "\titers: 200, epoch: 34 | loss: 0.0565170\n",
      "\tspeed: 0.0425s/iter; left time: 626.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0571641 Vali Loss: 0.0751075 Test Loss: 0.0896395\n",
      "Validation loss decreased (0.075113 --> 0.075107).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0565159\n",
      "\tspeed: 0.0762s/iter; left time: 1114.6455s\n",
      "\titers: 200, epoch: 35 | loss: 0.0543115\n",
      "\tspeed: 0.0424s/iter; left time: 616.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0571129 Vali Loss: 0.0751775 Test Loss: 0.0898111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0575157\n",
      "\tspeed: 0.0756s/iter; left time: 1087.8771s\n",
      "\titers: 200, epoch: 36 | loss: 0.0590963\n",
      "\tspeed: 0.0424s/iter; left time: 606.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570837 Vali Loss: 0.0752165 Test Loss: 0.0898423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0554018\n",
      "\tspeed: 0.0762s/iter; left time: 1079.6209s\n",
      "\titers: 200, epoch: 37 | loss: 0.0596231\n",
      "\tspeed: 0.0426s/iter; left time: 599.0353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0571097 Vali Loss: 0.0752624 Test Loss: 0.0898242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0621724\n",
      "\tspeed: 0.0756s/iter; left time: 1055.0102s\n",
      "\titers: 200, epoch: 38 | loss: 0.0594966\n",
      "\tspeed: 0.0425s/iter; left time: 589.2088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570916 Vali Loss: 0.0752899 Test Loss: 0.0897771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0557170\n",
      "\tspeed: 0.0754s/iter; left time: 1035.0082s\n",
      "\titers: 200, epoch: 39 | loss: 0.0557038\n",
      "\tspeed: 0.0425s/iter; left time: 579.5831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0571168 Vali Loss: 0.0751440 Test Loss: 0.0898458\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0548218\n",
      "\tspeed: 0.0757s/iter; left time: 1022.1383s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535119\n",
      "\tspeed: 0.0425s/iter; left time: 569.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0570778 Vali Loss: 0.0753414 Test Loss: 0.0898209\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0595047\n",
      "\tspeed: 0.0753s/iter; left time: 1000.4601s\n",
      "\titers: 200, epoch: 41 | loss: 0.0574232\n",
      "\tspeed: 0.0425s/iter; left time: 560.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0569935 Vali Loss: 0.0752454 Test Loss: 0.0898885\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0572772\n",
      "\tspeed: 0.0754s/iter; left time: 984.8854s\n",
      "\titers: 200, epoch: 42 | loss: 0.0556398\n",
      "\tspeed: 0.0425s/iter; left time: 551.1102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570608 Vali Loss: 0.0753064 Test Loss: 0.0898839\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0548267\n",
      "\tspeed: 0.0755s/iter; left time: 968.4376s\n",
      "\titers: 200, epoch: 43 | loss: 0.0530517\n",
      "\tspeed: 0.0426s/iter; left time: 541.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0569894 Vali Loss: 0.0752069 Test Loss: 0.0898459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0569659\n",
      "\tspeed: 0.0756s/iter; left time: 953.2257s\n",
      "\titers: 200, epoch: 44 | loss: 0.0594817\n",
      "\tspeed: 0.0425s/iter; left time: 531.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0569357 Vali Loss: 0.0752656 Test Loss: 0.0899255\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022022612392902374, rmse:0.1484001725912094, mae:0.08963943272829056, rse:0.5747678875923157\n",
      "Intermediate time for FR and pred_len 168: 00h:12m:50.76s\n",
      "Intermediate time for FR: 00h:36m:29.00s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1668762\n",
      "\tspeed: 0.0632s/iter; left time: 1410.1924s\n",
      "\titers: 200, epoch: 1 | loss: 0.1487154\n",
      "\tspeed: 0.0419s/iter; left time: 929.4824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.1647057 Vali Loss: 0.1381319 Test Loss: 0.1453384\n",
      "Validation loss decreased (inf --> 0.138132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744973\n",
      "\tspeed: 0.0743s/iter; left time: 1640.0870s\n",
      "\titers: 200, epoch: 2 | loss: 0.0702725\n",
      "\tspeed: 0.0419s/iter; left time: 920.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0845355 Vali Loss: 0.0634649 Test Loss: 0.0669909\n",
      "Validation loss decreased (0.138132 --> 0.063465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0651665\n",
      "\tspeed: 0.0744s/iter; left time: 1626.7381s\n",
      "\titers: 200, epoch: 3 | loss: 0.0628549\n",
      "\tspeed: 0.0419s/iter; left time: 911.2587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0646237 Vali Loss: 0.0603763 Test Loss: 0.0639257\n",
      "Validation loss decreased (0.063465 --> 0.060376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586132\n",
      "\tspeed: 0.0749s/iter; left time: 1620.0159s\n",
      "\titers: 200, epoch: 4 | loss: 0.0582620\n",
      "\tspeed: 0.0420s/iter; left time: 903.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0615983 Vali Loss: 0.0585471 Test Loss: 0.0621628\n",
      "Validation loss decreased (0.060376 --> 0.058547).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0539563\n",
      "\tspeed: 0.0746s/iter; left time: 1597.0395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590897\n",
      "\tspeed: 0.0419s/iter; left time: 891.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0596819 Vali Loss: 0.0576238 Test Loss: 0.0609692\n",
      "Validation loss decreased (0.058547 --> 0.057624).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0563761\n",
      "\tspeed: 0.0749s/iter; left time: 1586.8317s\n",
      "\titers: 200, epoch: 6 | loss: 0.0547008\n",
      "\tspeed: 0.0418s/iter; left time: 881.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0583187 Vali Loss: 0.0567941 Test Loss: 0.0601914\n",
      "Validation loss decreased (0.057624 --> 0.056794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0598481\n",
      "\tspeed: 0.0750s/iter; left time: 1572.1981s\n",
      "\titers: 200, epoch: 7 | loss: 0.0572359\n",
      "\tspeed: 0.0419s/iter; left time: 873.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0573916 Vali Loss: 0.0562816 Test Loss: 0.0596388\n",
      "Validation loss decreased (0.056794 --> 0.056282).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574251\n",
      "\tspeed: 0.0748s/iter; left time: 1551.1427s\n",
      "\titers: 200, epoch: 8 | loss: 0.0573186\n",
      "\tspeed: 0.0419s/iter; left time: 863.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0567434 Vali Loss: 0.0557669 Test Loss: 0.0591180\n",
      "Validation loss decreased (0.056282 --> 0.055767).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559022\n",
      "\tspeed: 0.0743s/iter; left time: 1524.8342s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584287\n",
      "\tspeed: 0.0419s/iter; left time: 854.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0562328 Vali Loss: 0.0554319 Test Loss: 0.0587576\n",
      "Validation loss decreased (0.055767 --> 0.055432).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546298\n",
      "\tspeed: 0.0744s/iter; left time: 1509.0385s\n",
      "\titers: 200, epoch: 10 | loss: 0.0570061\n",
      "\tspeed: 0.0419s/iter; left time: 845.1574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0557634 Vali Loss: 0.0553139 Test Loss: 0.0584507\n",
      "Validation loss decreased (0.055432 --> 0.055314).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569785\n",
      "\tspeed: 0.0745s/iter; left time: 1495.5312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0548771\n",
      "\tspeed: 0.0418s/iter; left time: 834.8738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0553908 Vali Loss: 0.0551920 Test Loss: 0.0583368\n",
      "Validation loss decreased (0.055314 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560274\n",
      "\tspeed: 0.0755s/iter; left time: 1497.3163s\n",
      "\titers: 200, epoch: 12 | loss: 0.0540077\n",
      "\tspeed: 0.0419s/iter; left time: 826.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0550622 Vali Loss: 0.0551127 Test Loss: 0.0582354\n",
      "Validation loss decreased (0.055192 --> 0.055113).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0538228\n",
      "\tspeed: 0.0747s/iter; left time: 1464.8836s\n",
      "\titers: 200, epoch: 13 | loss: 0.0569437\n",
      "\tspeed: 0.0419s/iter; left time: 817.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0548389 Vali Loss: 0.0549542 Test Loss: 0.0579587\n",
      "Validation loss decreased (0.055113 --> 0.054954).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0516178\n",
      "\tspeed: 0.0745s/iter; left time: 1444.1845s\n",
      "\titers: 200, epoch: 14 | loss: 0.0514003\n",
      "\tspeed: 0.0419s/iter; left time: 807.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0545595 Vali Loss: 0.0548756 Test Loss: 0.0579918\n",
      "Validation loss decreased (0.054954 --> 0.054876).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533713\n",
      "\tspeed: 0.0750s/iter; left time: 1436.6809s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543369\n",
      "\tspeed: 0.0418s/iter; left time: 797.7377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0544265 Vali Loss: 0.0548448 Test Loss: 0.0579394\n",
      "Validation loss decreased (0.054876 --> 0.054845).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0529609\n",
      "\tspeed: 0.0745s/iter; left time: 1410.7601s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552985\n",
      "\tspeed: 0.0419s/iter; left time: 788.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0542592 Vali Loss: 0.0548368 Test Loss: 0.0579324\n",
      "Validation loss decreased (0.054845 --> 0.054837).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0501005\n",
      "\tspeed: 0.0750s/iter; left time: 1404.2534s\n",
      "\titers: 200, epoch: 17 | loss: 0.0501565\n",
      "\tspeed: 0.0419s/iter; left time: 779.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0540546 Vali Loss: 0.0547614 Test Loss: 0.0578513\n",
      "Validation loss decreased (0.054837 --> 0.054761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0539889\n",
      "\tspeed: 0.0746s/iter; left time: 1379.7234s\n",
      "\titers: 200, epoch: 18 | loss: 0.0508451\n",
      "\tspeed: 0.0419s/iter; left time: 770.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0539890 Vali Loss: 0.0546531 Test Loss: 0.0577155\n",
      "Validation loss decreased (0.054761 --> 0.054653).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0549342\n",
      "\tspeed: 0.0755s/iter; left time: 1378.6877s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539790\n",
      "\tspeed: 0.0419s/iter; left time: 760.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0539062 Vali Loss: 0.0547521 Test Loss: 0.0577877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0521993\n",
      "\tspeed: 0.0742s/iter; left time: 1338.0701s\n",
      "\titers: 200, epoch: 20 | loss: 0.0564071\n",
      "\tspeed: 0.0418s/iter; left time: 750.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0538328 Vali Loss: 0.0545932 Test Loss: 0.0576081\n",
      "Validation loss decreased (0.054653 --> 0.054593).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0518346\n",
      "\tspeed: 0.0741s/iter; left time: 1320.5455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0492195\n",
      "\tspeed: 0.0419s/iter; left time: 741.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0536230 Vali Loss: 0.0545515 Test Loss: 0.0576098\n",
      "Validation loss decreased (0.054593 --> 0.054552).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0529903\n",
      "\tspeed: 0.0752s/iter; left time: 1323.5637s\n",
      "\titers: 200, epoch: 22 | loss: 0.0542470\n",
      "\tspeed: 0.0419s/iter; left time: 732.3690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0536617 Vali Loss: 0.0544110 Test Loss: 0.0575890\n",
      "Validation loss decreased (0.054552 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0522088\n",
      "\tspeed: 0.0746s/iter; left time: 1295.2877s\n",
      "\titers: 200, epoch: 23 | loss: 0.0597315\n",
      "\tspeed: 0.0419s/iter; left time: 723.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0535213 Vali Loss: 0.0544596 Test Loss: 0.0575021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0541264\n",
      "\tspeed: 0.0743s/iter; left time: 1273.4573s\n",
      "\titers: 200, epoch: 24 | loss: 0.0508696\n",
      "\tspeed: 0.0419s/iter; left time: 713.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0534724 Vali Loss: 0.0544801 Test Loss: 0.0575809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0501939\n",
      "\tspeed: 0.0744s/iter; left time: 1258.4504s\n",
      "\titers: 200, epoch: 25 | loss: 0.0537891\n",
      "\tspeed: 0.0419s/iter; left time: 704.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0534406 Vali Loss: 0.0544176 Test Loss: 0.0574616\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0505069\n",
      "\tspeed: 0.0743s/iter; left time: 1240.5247s\n",
      "\titers: 200, epoch: 26 | loss: 0.0531720\n",
      "\tspeed: 0.0418s/iter; left time: 694.4466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0533208 Vali Loss: 0.0544965 Test Loss: 0.0575467\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0493177\n",
      "\tspeed: 0.0745s/iter; left time: 1228.0542s\n",
      "\titers: 200, epoch: 27 | loss: 0.0498824\n",
      "\tspeed: 0.0418s/iter; left time: 685.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0533288 Vali Loss: 0.0544455 Test Loss: 0.0574507\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0525627\n",
      "\tspeed: 0.0736s/iter; left time: 1196.7454s\n",
      "\titers: 200, epoch: 28 | loss: 0.0504644\n",
      "\tspeed: 0.0418s/iter; left time: 675.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0532673 Vali Loss: 0.0544091 Test Loss: 0.0574716\n",
      "Validation loss decreased (0.054411 --> 0.054409).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0531574\n",
      "\tspeed: 0.0747s/iter; left time: 1196.7584s\n",
      "\titers: 200, epoch: 29 | loss: 0.0548535\n",
      "\tspeed: 0.0418s/iter; left time: 665.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0532243 Vali Loss: 0.0543962 Test Loss: 0.0574245\n",
      "Validation loss decreased (0.054409 --> 0.054396).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0528839\n",
      "\tspeed: 0.0749s/iter; left time: 1183.9542s\n",
      "\titers: 200, epoch: 30 | loss: 0.0549718\n",
      "\tspeed: 0.0419s/iter; left time: 657.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0532229 Vali Loss: 0.0543955 Test Loss: 0.0574266\n",
      "Validation loss decreased (0.054396 --> 0.054395).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0496521\n",
      "\tspeed: 0.0744s/iter; left time: 1159.5301s\n",
      "\titers: 200, epoch: 31 | loss: 0.0537042\n",
      "\tspeed: 0.0418s/iter; left time: 647.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0531766 Vali Loss: 0.0543635 Test Loss: 0.0573991\n",
      "Validation loss decreased (0.054395 --> 0.054363).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555401\n",
      "\tspeed: 0.0743s/iter; left time: 1140.3479s\n",
      "\titers: 200, epoch: 32 | loss: 0.0543907\n",
      "\tspeed: 0.0418s/iter; left time: 638.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0531708 Vali Loss: 0.0543848 Test Loss: 0.0573410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553831\n",
      "\tspeed: 0.0738s/iter; left time: 1117.4445s\n",
      "\titers: 200, epoch: 33 | loss: 0.0529029\n",
      "\tspeed: 0.0419s/iter; left time: 629.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0531169 Vali Loss: 0.0544931 Test Loss: 0.0574164\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0566949\n",
      "\tspeed: 0.0743s/iter; left time: 1107.9614s\n",
      "\titers: 200, epoch: 34 | loss: 0.0510905\n",
      "\tspeed: 0.0418s/iter; left time: 619.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0530960 Vali Loss: 0.0544281 Test Loss: 0.0574047\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0519415\n",
      "\tspeed: 0.0739s/iter; left time: 1085.4541s\n",
      "\titers: 200, epoch: 35 | loss: 0.0507861\n",
      "\tspeed: 0.0418s/iter; left time: 609.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531171 Vali Loss: 0.0543847 Test Loss: 0.0573662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0498729\n",
      "\tspeed: 0.0737s/iter; left time: 1065.9495s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518879\n",
      "\tspeed: 0.0418s/iter; left time: 600.9679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0530941 Vali Loss: 0.0544304 Test Loss: 0.0573629\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0537743\n",
      "\tspeed: 0.0737s/iter; left time: 1049.4746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0551615\n",
      "\tspeed: 0.0418s/iter; left time: 591.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0530242 Vali Loss: 0.0544074 Test Loss: 0.0573354\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0526531\n",
      "\tspeed: 0.0735s/iter; left time: 1030.5877s\n",
      "\titers: 200, epoch: 38 | loss: 0.0578634\n",
      "\tspeed: 0.0418s/iter; left time: 582.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0530546 Vali Loss: 0.0543200 Test Loss: 0.0573338\n",
      "Validation loss decreased (0.054363 --> 0.054320).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526937\n",
      "\tspeed: 0.0746s/iter; left time: 1028.3645s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528568\n",
      "\tspeed: 0.0418s/iter; left time: 572.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530138 Vali Loss: 0.0542319 Test Loss: 0.0573226\n",
      "Validation loss decreased (0.054320 --> 0.054232).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0563120\n",
      "\tspeed: 0.0744s/iter; left time: 1009.9058s\n",
      "\titers: 200, epoch: 40 | loss: 0.0510091\n",
      "\tspeed: 0.0418s/iter; left time: 562.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529836 Vali Loss: 0.0543886 Test Loss: 0.0573441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0574817\n",
      "\tspeed: 0.0749s/iter; left time: 998.7108s\n",
      "\titers: 200, epoch: 41 | loss: 0.0560694\n",
      "\tspeed: 0.0418s/iter; left time: 553.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0530532 Vali Loss: 0.0543912 Test Loss: 0.0573497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0537718\n",
      "\tspeed: 0.0740s/iter; left time: 970.0687s\n",
      "\titers: 200, epoch: 42 | loss: 0.0548852\n",
      "\tspeed: 0.0418s/iter; left time: 544.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529759 Vali Loss: 0.0543679 Test Loss: 0.0573329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0538681\n",
      "\tspeed: 0.0739s/iter; left time: 952.8693s\n",
      "\titers: 200, epoch: 43 | loss: 0.0495705\n",
      "\tspeed: 0.0418s/iter; left time: 534.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529634 Vali Loss: 0.0542869 Test Loss: 0.0573246\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0502725\n",
      "\tspeed: 0.0748s/iter; left time: 947.7138s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535956\n",
      "\tspeed: 0.0419s/iter; left time: 526.2463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0529778 Vali Loss: 0.0542852 Test Loss: 0.0573048\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0540188\n",
      "\tspeed: 0.0736s/iter; left time: 916.5252s\n",
      "\titers: 200, epoch: 45 | loss: 0.0544035\n",
      "\tspeed: 0.0418s/iter; left time: 516.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529316 Vali Loss: 0.0543632 Test Loss: 0.0573138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547294\n",
      "\tspeed: 0.0752s/iter; left time: 919.0130s\n",
      "\titers: 200, epoch: 46 | loss: 0.0530386\n",
      "\tspeed: 0.0419s/iter; left time: 507.4683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0529451 Vali Loss: 0.0543928 Test Loss: 0.0573512\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528816\n",
      "\tspeed: 0.0743s/iter; left time: 891.8318s\n",
      "\titers: 200, epoch: 47 | loss: 0.0518007\n",
      "\tspeed: 0.0419s/iter; left time: 497.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0529247 Vali Loss: 0.0543985 Test Loss: 0.0573596\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547840\n",
      "\tspeed: 0.0751s/iter; left time: 884.6809s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521973\n",
      "\tspeed: 0.0419s/iter; left time: 488.5531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529457 Vali Loss: 0.0543617 Test Loss: 0.0573151\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0564644\n",
      "\tspeed: 0.0737s/iter; left time: 851.5835s\n",
      "\titers: 200, epoch: 49 | loss: 0.0526863\n",
      "\tspeed: 0.0418s/iter; left time: 478.6633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0529025 Vali Loss: 0.0543118 Test Loss: 0.0572813\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01028256956487894, rmse:0.10140300542116165, mae:0.05732264369726181, rse:0.383152037858963\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616639\n",
      "\tspeed: 0.0433s/iter; left time: 966.2199s\n",
      "\titers: 200, epoch: 1 | loss: 0.1476239\n",
      "\tspeed: 0.0418s/iter; left time: 927.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.1636449 Vali Loss: 0.1371539 Test Loss: 0.1445717\n",
      "Validation loss decreased (inf --> 0.137154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0788116\n",
      "\tspeed: 0.0744s/iter; left time: 1641.4583s\n",
      "\titers: 200, epoch: 2 | loss: 0.0667151\n",
      "\tspeed: 0.0419s/iter; left time: 919.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0861281 Vali Loss: 0.0642575 Test Loss: 0.0675583\n",
      "Validation loss decreased (0.137154 --> 0.064257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0629694\n",
      "\tspeed: 0.0742s/iter; left time: 1620.8953s\n",
      "\titers: 200, epoch: 3 | loss: 0.0626399\n",
      "\tspeed: 0.0419s/iter; left time: 910.8908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0657113 Vali Loss: 0.0612823 Test Loss: 0.0645098\n",
      "Validation loss decreased (0.064257 --> 0.061282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0575715\n",
      "\tspeed: 0.0747s/iter; left time: 1615.8757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0583651\n",
      "\tspeed: 0.0418s/iter; left time: 900.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0623427 Vali Loss: 0.0592041 Test Loss: 0.0625285\n",
      "Validation loss decreased (0.061282 --> 0.059204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582681\n",
      "\tspeed: 0.0746s/iter; left time: 1596.8355s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600793\n",
      "\tspeed: 0.0419s/iter; left time: 892.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0600875 Vali Loss: 0.0575578 Test Loss: 0.0608771\n",
      "Validation loss decreased (0.059204 --> 0.057558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0581085\n",
      "\tspeed: 0.0745s/iter; left time: 1579.0175s\n",
      "\titers: 200, epoch: 6 | loss: 0.0590649\n",
      "\tspeed: 0.0418s/iter; left time: 882.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0586191 Vali Loss: 0.0568939 Test Loss: 0.0597674\n",
      "Validation loss decreased (0.057558 --> 0.056894).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588938\n",
      "\tspeed: 0.0745s/iter; left time: 1561.6143s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554931\n",
      "\tspeed: 0.0418s/iter; left time: 872.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0575254 Vali Loss: 0.0565976 Test Loss: 0.0593791\n",
      "Validation loss decreased (0.056894 --> 0.056598).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574277\n",
      "\tspeed: 0.0746s/iter; left time: 1547.6722s\n",
      "\titers: 200, epoch: 8 | loss: 0.0596510\n",
      "\tspeed: 0.0419s/iter; left time: 864.0850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0567334 Vali Loss: 0.0560192 Test Loss: 0.0589414\n",
      "Validation loss decreased (0.056598 --> 0.056019).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0523476\n",
      "\tspeed: 0.0747s/iter; left time: 1533.0372s\n",
      "\titers: 200, epoch: 9 | loss: 0.0539958\n",
      "\tspeed: 0.0419s/iter; left time: 854.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0562151 Vali Loss: 0.0557441 Test Loss: 0.0587535\n",
      "Validation loss decreased (0.056019 --> 0.055744).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577841\n",
      "\tspeed: 0.0745s/iter; left time: 1510.8485s\n",
      "\titers: 200, epoch: 10 | loss: 0.0528773\n",
      "\tspeed: 0.0418s/iter; left time: 844.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0557223 Vali Loss: 0.0554646 Test Loss: 0.0585298\n",
      "Validation loss decreased (0.055744 --> 0.055465).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0538761\n",
      "\tspeed: 0.0747s/iter; left time: 1498.1527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553195\n",
      "\tspeed: 0.0419s/iter; left time: 835.7565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0553937 Vali Loss: 0.0552108 Test Loss: 0.0581949\n",
      "Validation loss decreased (0.055465 --> 0.055211).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0535571\n",
      "\tspeed: 0.0750s/iter; left time: 1488.3766s\n",
      "\titers: 200, epoch: 12 | loss: 0.0548535\n",
      "\tspeed: 0.0418s/iter; left time: 825.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0550495 Vali Loss: 0.0551921 Test Loss: 0.0583735\n",
      "Validation loss decreased (0.055211 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0553481\n",
      "\tspeed: 0.0747s/iter; left time: 1464.5915s\n",
      "\titers: 200, epoch: 13 | loss: 0.0544968\n",
      "\tspeed: 0.0418s/iter; left time: 815.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0547886 Vali Loss: 0.0551847 Test Loss: 0.0580902\n",
      "Validation loss decreased (0.055192 --> 0.055185).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0511046\n",
      "\tspeed: 0.0746s/iter; left time: 1445.9497s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555087\n",
      "\tspeed: 0.0419s/iter; left time: 807.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0545514 Vali Loss: 0.0548709 Test Loss: 0.0578461\n",
      "Validation loss decreased (0.055185 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580758\n",
      "\tspeed: 0.0745s/iter; left time: 1428.6298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566910\n",
      "\tspeed: 0.0418s/iter; left time: 797.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0544231 Vali Loss: 0.0549199 Test Loss: 0.0578442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0568407\n",
      "\tspeed: 0.0738s/iter; left time: 1397.4190s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580707\n",
      "\tspeed: 0.0418s/iter; left time: 787.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0542265 Vali Loss: 0.0546896 Test Loss: 0.0577216\n",
      "Validation loss decreased (0.054871 --> 0.054690).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518764\n",
      "\tspeed: 0.0747s/iter; left time: 1397.8150s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532458\n",
      "\tspeed: 0.0418s/iter; left time: 778.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0540888 Vali Loss: 0.0546941 Test Loss: 0.0577168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0508079\n",
      "\tspeed: 0.0741s/iter; left time: 1370.3762s\n",
      "\titers: 200, epoch: 18 | loss: 0.0514931\n",
      "\tspeed: 0.0418s/iter; left time: 769.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0539316 Vali Loss: 0.0545755 Test Loss: 0.0576704\n",
      "Validation loss decreased (0.054690 --> 0.054575).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0519903\n",
      "\tspeed: 0.0746s/iter; left time: 1362.6380s\n",
      "\titers: 200, epoch: 19 | loss: 0.0483813\n",
      "\tspeed: 0.0418s/iter; left time: 759.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0537805 Vali Loss: 0.0545462 Test Loss: 0.0575867\n",
      "Validation loss decreased (0.054575 --> 0.054546).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535914\n",
      "\tspeed: 0.0748s/iter; left time: 1349.5709s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546892\n",
      "\tspeed: 0.0418s/iter; left time: 750.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0536743 Vali Loss: 0.0544524 Test Loss: 0.0574283\n",
      "Validation loss decreased (0.054546 --> 0.054452).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0540178\n",
      "\tspeed: 0.0747s/iter; left time: 1331.5933s\n",
      "\titers: 200, epoch: 21 | loss: 0.0522899\n",
      "\tspeed: 0.0419s/iter; left time: 741.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0536213 Vali Loss: 0.0543808 Test Loss: 0.0575519\n",
      "Validation loss decreased (0.054452 --> 0.054381).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0546879\n",
      "\tspeed: 0.0746s/iter; left time: 1313.4636s\n",
      "\titers: 200, epoch: 22 | loss: 0.0504863\n",
      "\tspeed: 0.0418s/iter; left time: 731.8208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0535170 Vali Loss: 0.0543309 Test Loss: 0.0574142\n",
      "Validation loss decreased (0.054381 --> 0.054331).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0541547\n",
      "\tspeed: 0.0765s/iter; left time: 1329.3613s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524183\n",
      "\tspeed: 0.0418s/iter; left time: 722.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0534375 Vali Loss: 0.0543097 Test Loss: 0.0573499\n",
      "Validation loss decreased (0.054331 --> 0.054310).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0576624\n",
      "\tspeed: 0.0764s/iter; left time: 1309.7861s\n",
      "\titers: 200, epoch: 24 | loss: 0.0513303\n",
      "\tspeed: 0.0419s/iter; left time: 713.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0534079 Vali Loss: 0.0543459 Test Loss: 0.0574013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521893\n",
      "\tspeed: 0.0838s/iter; left time: 1418.1088s\n",
      "\titers: 200, epoch: 25 | loss: 0.0516139\n",
      "\tspeed: 0.0419s/iter; left time: 704.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0533243 Vali Loss: 0.0543876 Test Loss: 0.0573955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0501922\n",
      "\tspeed: 0.0741s/iter; left time: 1237.2528s\n",
      "\titers: 200, epoch: 26 | loss: 0.0541352\n",
      "\tspeed: 0.0418s/iter; left time: 693.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0532546 Vali Loss: 0.0541978 Test Loss: 0.0573019\n",
      "Validation loss decreased (0.054310 --> 0.054198).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0493153\n",
      "\tspeed: 0.0856s/iter; left time: 1410.4585s\n",
      "\titers: 200, epoch: 27 | loss: 0.0526472\n",
      "\tspeed: 0.0418s/iter; left time: 685.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0532697 Vali Loss: 0.0542148 Test Loss: 0.0573098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0514517\n",
      "\tspeed: 0.0740s/iter; left time: 1203.2562s\n",
      "\titers: 200, epoch: 28 | loss: 0.0499882\n",
      "\tspeed: 0.0419s/iter; left time: 676.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0531714 Vali Loss: 0.0542701 Test Loss: 0.0573346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0573119\n",
      "\tspeed: 0.0740s/iter; left time: 1186.0142s\n",
      "\titers: 200, epoch: 29 | loss: 0.0558033\n",
      "\tspeed: 0.0418s/iter; left time: 666.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0531370 Vali Loss: 0.0542226 Test Loss: 0.0572494\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516919\n",
      "\tspeed: 0.0740s/iter; left time: 1168.7904s\n",
      "\titers: 200, epoch: 30 | loss: 0.0497717\n",
      "\tspeed: 0.0419s/iter; left time: 657.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531310 Vali Loss: 0.0541556 Test Loss: 0.0572202\n",
      "Validation loss decreased (0.054198 --> 0.054156).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0527075\n",
      "\tspeed: 0.0747s/iter; left time: 1163.9633s\n",
      "\titers: 200, epoch: 31 | loss: 0.0537404\n",
      "\tspeed: 0.0418s/iter; left time: 646.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530956 Vali Loss: 0.0541769 Test Loss: 0.0571595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0533048\n",
      "\tspeed: 0.0738s/iter; left time: 1133.7672s\n",
      "\titers: 200, epoch: 32 | loss: 0.0556948\n",
      "\tspeed: 0.0418s/iter; left time: 638.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530611 Vali Loss: 0.0541787 Test Loss: 0.0571991\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0510798\n",
      "\tspeed: 0.0739s/iter; left time: 1118.2675s\n",
      "\titers: 200, epoch: 33 | loss: 0.0523759\n",
      "\tspeed: 0.0418s/iter; left time: 628.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531029 Vali Loss: 0.0541814 Test Loss: 0.0571673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0522886\n",
      "\tspeed: 0.0739s/iter; left time: 1101.8744s\n",
      "\titers: 200, epoch: 34 | loss: 0.0541572\n",
      "\tspeed: 0.0419s/iter; left time: 619.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530245 Vali Loss: 0.0540877 Test Loss: 0.0571120\n",
      "Validation loss decreased (0.054156 --> 0.054088).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515421\n",
      "\tspeed: 0.0744s/iter; left time: 1092.5634s\n",
      "\titers: 200, epoch: 35 | loss: 0.0513102\n",
      "\tspeed: 0.0418s/iter; left time: 610.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529863 Vali Loss: 0.0541510 Test Loss: 0.0571679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0522429\n",
      "\tspeed: 0.0739s/iter; left time: 1068.3731s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521231\n",
      "\tspeed: 0.0419s/iter; left time: 601.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530019 Vali Loss: 0.0541704 Test Loss: 0.0571422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0513952\n",
      "\tspeed: 0.0741s/iter; left time: 1054.2933s\n",
      "\titers: 200, epoch: 37 | loss: 0.0474398\n",
      "\tspeed: 0.0419s/iter; left time: 591.9197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529754 Vali Loss: 0.0540476 Test Loss: 0.0571175\n",
      "Validation loss decreased (0.054088 --> 0.054048).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0502229\n",
      "\tspeed: 0.0745s/iter; left time: 1044.6058s\n",
      "\titers: 200, epoch: 38 | loss: 0.0529533\n",
      "\tspeed: 0.0419s/iter; left time: 582.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529339 Vali Loss: 0.0542359 Test Loss: 0.0571858\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0542917\n",
      "\tspeed: 0.0740s/iter; left time: 1019.8536s\n",
      "\titers: 200, epoch: 39 | loss: 0.0531940\n",
      "\tspeed: 0.0419s/iter; left time: 573.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529129 Vali Loss: 0.0540209 Test Loss: 0.0571142\n",
      "Validation loss decreased (0.054048 --> 0.054021).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0547552\n",
      "\tspeed: 0.0745s/iter; left time: 1010.3311s\n",
      "\titers: 200, epoch: 40 | loss: 0.0557019\n",
      "\tspeed: 0.0418s/iter; left time: 562.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529163 Vali Loss: 0.0540310 Test Loss: 0.0571155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0534431\n",
      "\tspeed: 0.0740s/iter; left time: 986.6784s\n",
      "\titers: 200, epoch: 41 | loss: 0.0568288\n",
      "\tspeed: 0.0419s/iter; left time: 554.3730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0528946 Vali Loss: 0.0540863 Test Loss: 0.0571200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536664\n",
      "\tspeed: 0.0740s/iter; left time: 970.1198s\n",
      "\titers: 200, epoch: 42 | loss: 0.0512080\n",
      "\tspeed: 0.0419s/iter; left time: 545.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529005 Vali Loss: 0.0540332 Test Loss: 0.0570927\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552242\n",
      "\tspeed: 0.0744s/iter; left time: 958.8215s\n",
      "\titers: 200, epoch: 43 | loss: 0.0507111\n",
      "\tspeed: 0.0419s/iter; left time: 535.7786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528627 Vali Loss: 0.0541517 Test Loss: 0.0571203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526871\n",
      "\tspeed: 0.0738s/iter; left time: 934.8897s\n",
      "\titers: 200, epoch: 44 | loss: 0.0537241\n",
      "\tspeed: 0.0418s/iter; left time: 525.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529090 Vali Loss: 0.0540866 Test Loss: 0.0571252\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0587728\n",
      "\tspeed: 0.0741s/iter; left time: 921.8914s\n",
      "\titers: 200, epoch: 45 | loss: 0.0491216\n",
      "\tspeed: 0.0418s/iter; left time: 516.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0528336 Vali Loss: 0.0541069 Test Loss: 0.0571408\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0522368\n",
      "\tspeed: 0.0740s/iter; left time: 903.8769s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523553\n",
      "\tspeed: 0.0419s/iter; left time: 507.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0528736 Vali Loss: 0.0540359 Test Loss: 0.0571018\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0527549\n",
      "\tspeed: 0.0742s/iter; left time: 889.9456s\n",
      "\titers: 200, epoch: 47 | loss: 0.0514552\n",
      "\tspeed: 0.0418s/iter; left time: 497.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528191 Vali Loss: 0.0540452 Test Loss: 0.0571226\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0518987\n",
      "\tspeed: 0.0739s/iter; left time: 870.1079s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528718\n",
      "\tspeed: 0.0418s/iter; left time: 488.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528364 Vali Loss: 0.0541071 Test Loss: 0.0571336\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543009\n",
      "\tspeed: 0.0739s/iter; left time: 853.3450s\n",
      "\titers: 200, epoch: 49 | loss: 0.0517853\n",
      "\tspeed: 0.0418s/iter; left time: 478.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0528222 Vali Loss: 0.0540462 Test Loss: 0.0571074\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0101736169308424, rmse:0.10086435079574585, mae:0.05711417645215988, rse:0.38111668825149536\n",
      "Intermediate time for IT and pred_len 24: 00h:19m:12.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1709637\n",
      "\tspeed: 0.0628s/iter; left time: 1401.4907s\n",
      "\titers: 200, epoch: 1 | loss: 0.1590622\n",
      "\tspeed: 0.0423s/iter; left time: 940.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1731405 Vali Loss: 0.1467602 Test Loss: 0.1548989\n",
      "Validation loss decreased (inf --> 0.146760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0915521\n",
      "\tspeed: 0.0775s/iter; left time: 1709.9081s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813664\n",
      "\tspeed: 0.0423s/iter; left time: 928.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.1010438 Vali Loss: 0.0820178 Test Loss: 0.0875869\n",
      "Validation loss decreased (0.146760 --> 0.082018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0834640\n",
      "\tspeed: 0.0785s/iter; left time: 1714.7168s\n",
      "\titers: 200, epoch: 3 | loss: 0.0890686\n",
      "\tspeed: 0.0423s/iter; left time: 919.0786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0845064 Vali Loss: 0.0791088 Test Loss: 0.0851409\n",
      "Validation loss decreased (0.082018 --> 0.079109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0819988\n",
      "\tspeed: 0.0766s/iter; left time: 1657.1573s\n",
      "\titers: 200, epoch: 4 | loss: 0.0786908\n",
      "\tspeed: 0.0422s/iter; left time: 908.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0813391 Vali Loss: 0.0774892 Test Loss: 0.0833235\n",
      "Validation loss decreased (0.079109 --> 0.077489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812265\n",
      "\tspeed: 0.0802s/iter; left time: 1716.1672s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782264\n",
      "\tspeed: 0.0422s/iter; left time: 898.4396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0792095 Vali Loss: 0.0765936 Test Loss: 0.0825124\n",
      "Validation loss decreased (0.077489 --> 0.076594).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764224\n",
      "\tspeed: 0.0775s/iter; left time: 1642.2676s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783107\n",
      "\tspeed: 0.0422s/iter; left time: 889.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0779074 Vali Loss: 0.0763852 Test Loss: 0.0820518\n",
      "Validation loss decreased (0.076594 --> 0.076385).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758527\n",
      "\tspeed: 0.0768s/iter; left time: 1610.0296s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771271\n",
      "\tspeed: 0.0422s/iter; left time: 881.1937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769735 Vali Loss: 0.0758655 Test Loss: 0.0815309\n",
      "Validation loss decreased (0.076385 --> 0.075866).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826955\n",
      "\tspeed: 0.0767s/iter; left time: 1589.9065s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760676\n",
      "\tspeed: 0.0421s/iter; left time: 869.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0762410 Vali Loss: 0.0755869 Test Loss: 0.0812099\n",
      "Validation loss decreased (0.075866 --> 0.075587).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0707286\n",
      "\tspeed: 0.0770s/iter; left time: 1578.7741s\n",
      "\titers: 200, epoch: 9 | loss: 0.0743069\n",
      "\tspeed: 0.0421s/iter; left time: 859.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0756071 Vali Loss: 0.0752984 Test Loss: 0.0811832\n",
      "Validation loss decreased (0.075587 --> 0.075298).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0766918\n",
      "\tspeed: 0.0773s/iter; left time: 1567.9840s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728842\n",
      "\tspeed: 0.0421s/iter; left time: 850.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0751414 Vali Loss: 0.0754443 Test Loss: 0.0811766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736202\n",
      "\tspeed: 0.0761s/iter; left time: 1526.8073s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760152\n",
      "\tspeed: 0.0422s/iter; left time: 842.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0747158 Vali Loss: 0.0752145 Test Loss: 0.0808049\n",
      "Validation loss decreased (0.075298 --> 0.075215).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720106\n",
      "\tspeed: 0.0768s/iter; left time: 1524.2798s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731059\n",
      "\tspeed: 0.0421s/iter; left time: 831.7771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0743176 Vali Loss: 0.0752223 Test Loss: 0.0806497\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700952\n",
      "\tspeed: 0.0765s/iter; left time: 1500.3928s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709079\n",
      "\tspeed: 0.0421s/iter; left time: 821.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0739965 Vali Loss: 0.0750111 Test Loss: 0.0804848\n",
      "Validation loss decreased (0.075215 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0717369\n",
      "\tspeed: 0.0764s/iter; left time: 1481.0720s\n",
      "\titers: 200, epoch: 14 | loss: 0.0706455\n",
      "\tspeed: 0.0422s/iter; left time: 813.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0735995 Vali Loss: 0.0751630 Test Loss: 0.0805996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0726589\n",
      "\tspeed: 0.0753s/iter; left time: 1442.9068s\n",
      "\titers: 200, epoch: 15 | loss: 0.0723697\n",
      "\tspeed: 0.0422s/iter; left time: 803.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0733330 Vali Loss: 0.0750874 Test Loss: 0.0805799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707894\n",
      "\tspeed: 0.0762s/iter; left time: 1443.0990s\n",
      "\titers: 200, epoch: 16 | loss: 0.0748958\n",
      "\tspeed: 0.0422s/iter; left time: 795.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0730366 Vali Loss: 0.0752258 Test Loss: 0.0806013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0713298\n",
      "\tspeed: 0.0759s/iter; left time: 1420.6176s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706481\n",
      "\tspeed: 0.0422s/iter; left time: 785.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0728366 Vali Loss: 0.0750299 Test Loss: 0.0805444\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766651\n",
      "\tspeed: 0.0759s/iter; left time: 1403.4191s\n",
      "\titers: 200, epoch: 18 | loss: 0.0755578\n",
      "\tspeed: 0.0422s/iter; left time: 776.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0726392 Vali Loss: 0.0750070 Test Loss: 0.0803575\n",
      "Validation loss decreased (0.075011 --> 0.075007).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0721044\n",
      "\tspeed: 0.0761s/iter; left time: 1389.8956s\n",
      "\titers: 200, epoch: 19 | loss: 0.0752852\n",
      "\tspeed: 0.0422s/iter; left time: 767.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0724808 Vali Loss: 0.0749559 Test Loss: 0.0802967\n",
      "Validation loss decreased (0.075007 --> 0.074956).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0686410\n",
      "\tspeed: 0.0765s/iter; left time: 1380.9826s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692698\n",
      "\tspeed: 0.0422s/iter; left time: 757.2277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0722542 Vali Loss: 0.0750252 Test Loss: 0.0803124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0693305\n",
      "\tspeed: 0.0768s/iter; left time: 1369.0937s\n",
      "\titers: 200, epoch: 21 | loss: 0.0740962\n",
      "\tspeed: 0.0422s/iter; left time: 747.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0721057 Vali Loss: 0.0750124 Test Loss: 0.0803431\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0718964\n",
      "\tspeed: 0.0764s/iter; left time: 1344.5747s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750140\n",
      "\tspeed: 0.0422s/iter; left time: 739.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0719894 Vali Loss: 0.0749805 Test Loss: 0.0802566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0679527\n",
      "\tspeed: 0.0761s/iter; left time: 1321.8060s\n",
      "\titers: 200, epoch: 23 | loss: 0.0706710\n",
      "\tspeed: 0.0422s/iter; left time: 728.9515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0718464 Vali Loss: 0.0750409 Test Loss: 0.0802397\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0731610\n",
      "\tspeed: 0.0756s/iter; left time: 1297.0458s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708685\n",
      "\tspeed: 0.0422s/iter; left time: 719.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0716813 Vali Loss: 0.0750071 Test Loss: 0.0803240\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0706737\n",
      "\tspeed: 0.0760s/iter; left time: 1285.8573s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705063\n",
      "\tspeed: 0.0422s/iter; left time: 710.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0716176 Vali Loss: 0.0749813 Test Loss: 0.0803697\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0735623\n",
      "\tspeed: 0.0765s/iter; left time: 1278.3694s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690790\n",
      "\tspeed: 0.0421s/iter; left time: 699.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0715137 Vali Loss: 0.0749541 Test Loss: 0.0802607\n",
      "Validation loss decreased (0.074956 --> 0.074954).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0726354\n",
      "\tspeed: 0.0771s/iter; left time: 1270.4747s\n",
      "\titers: 200, epoch: 27 | loss: 0.0705061\n",
      "\tspeed: 0.0422s/iter; left time: 690.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0714466 Vali Loss: 0.0750012 Test Loss: 0.0802674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0757946\n",
      "\tspeed: 0.0758s/iter; left time: 1232.4026s\n",
      "\titers: 200, epoch: 28 | loss: 0.0710962\n",
      "\tspeed: 0.0422s/iter; left time: 682.0408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0714014 Vali Loss: 0.0750562 Test Loss: 0.0802803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0731476\n",
      "\tspeed: 0.0760s/iter; left time: 1217.4944s\n",
      "\titers: 200, epoch: 29 | loss: 0.0687728\n",
      "\tspeed: 0.0421s/iter; left time: 671.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0712709 Vali Loss: 0.0749656 Test Loss: 0.0802395\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0708239\n",
      "\tspeed: 0.0754s/iter; left time: 1192.3866s\n",
      "\titers: 200, epoch: 30 | loss: 0.0733953\n",
      "\tspeed: 0.0422s/iter; left time: 662.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0712485 Vali Loss: 0.0751104 Test Loss: 0.0802817\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0703984\n",
      "\tspeed: 0.0761s/iter; left time: 1185.9316s\n",
      "\titers: 200, epoch: 31 | loss: 0.0692999\n",
      "\tspeed: 0.0422s/iter; left time: 653.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0711721 Vali Loss: 0.0750923 Test Loss: 0.0802622\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0759123\n",
      "\tspeed: 0.0762s/iter; left time: 1170.1991s\n",
      "\titers: 200, epoch: 32 | loss: 0.0721979\n",
      "\tspeed: 0.0422s/iter; left time: 643.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0711303 Vali Loss: 0.0749914 Test Loss: 0.0802187\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0675400\n",
      "\tspeed: 0.0756s/iter; left time: 1143.3427s\n",
      "\titers: 200, epoch: 33 | loss: 0.0712444\n",
      "\tspeed: 0.0423s/iter; left time: 635.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0710815 Vali Loss: 0.0750909 Test Loss: 0.0803081\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0708706\n",
      "\tspeed: 0.0757s/iter; left time: 1128.5315s\n",
      "\titers: 200, epoch: 34 | loss: 0.0726558\n",
      "\tspeed: 0.0422s/iter; left time: 624.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0710599 Vali Loss: 0.0749457 Test Loss: 0.0802050\n",
      "Validation loss decreased (0.074954 --> 0.074946).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705489\n",
      "\tspeed: 0.0765s/iter; left time: 1123.9537s\n",
      "\titers: 200, epoch: 35 | loss: 0.0747192\n",
      "\tspeed: 0.0422s/iter; left time: 615.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0710360 Vali Loss: 0.0750625 Test Loss: 0.0802698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0733743\n",
      "\tspeed: 0.0758s/iter; left time: 1096.4568s\n",
      "\titers: 200, epoch: 36 | loss: 0.0699492\n",
      "\tspeed: 0.0422s/iter; left time: 605.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0709659 Vali Loss: 0.0749656 Test Loss: 0.0802171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0723512\n",
      "\tspeed: 0.0760s/iter; left time: 1081.4515s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751660\n",
      "\tspeed: 0.0422s/iter; left time: 596.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0709697 Vali Loss: 0.0749879 Test Loss: 0.0802169\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0702403\n",
      "\tspeed: 0.0759s/iter; left time: 1063.1375s\n",
      "\titers: 200, epoch: 38 | loss: 0.0739042\n",
      "\tspeed: 0.0422s/iter; left time: 586.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0709164 Vali Loss: 0.0750351 Test Loss: 0.0802318\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0726668\n",
      "\tspeed: 0.0754s/iter; left time: 1039.7809s\n",
      "\titers: 200, epoch: 39 | loss: 0.0694377\n",
      "\tspeed: 0.0421s/iter; left time: 576.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0709209 Vali Loss: 0.0750078 Test Loss: 0.0802350\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712593\n",
      "\tspeed: 0.0752s/iter; left time: 1019.8353s\n",
      "\titers: 200, epoch: 40 | loss: 0.0750139\n",
      "\tspeed: 0.0422s/iter; left time: 568.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0708410 Vali Loss: 0.0750490 Test Loss: 0.0802376\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0708972\n",
      "\tspeed: 0.0760s/iter; left time: 1013.7989s\n",
      "\titers: 200, epoch: 41 | loss: 0.0737602\n",
      "\tspeed: 0.0421s/iter; left time: 558.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0708548 Vali Loss: 0.0750213 Test Loss: 0.0802427\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0709119\n",
      "\tspeed: 0.0753s/iter; left time: 988.0675s\n",
      "\titers: 200, epoch: 42 | loss: 0.0701031\n",
      "\tspeed: 0.0422s/iter; left time: 548.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0708338 Vali Loss: 0.0750549 Test Loss: 0.0802160\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0709096\n",
      "\tspeed: 0.0755s/iter; left time: 973.0272s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690312\n",
      "\tspeed: 0.0421s/iter; left time: 538.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0708735 Vali Loss: 0.0750550 Test Loss: 0.0802526\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0671204\n",
      "\tspeed: 0.0757s/iter; left time: 958.5804s\n",
      "\titers: 200, epoch: 44 | loss: 0.0687659\n",
      "\tspeed: 0.0422s/iter; left time: 529.9900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0708380 Vali Loss: 0.0750403 Test Loss: 0.0802399\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018426574766635895, rmse:0.13574452698230743, mae:0.08020501583814621, rse:0.5132646560668945\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1690528\n",
      "\tspeed: 0.0439s/iter; left time: 978.1898s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593371\n",
      "\tspeed: 0.0422s/iter; left time: 936.4705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1715413 Vali Loss: 0.1460627 Test Loss: 0.1542718\n",
      "Validation loss decreased (inf --> 0.146063).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974870\n",
      "\tspeed: 0.0763s/iter; left time: 1685.3289s\n",
      "\titers: 200, epoch: 2 | loss: 0.0848063\n",
      "\tspeed: 0.0422s/iter; left time: 927.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1027044 Vali Loss: 0.0821888 Test Loss: 0.0880603\n",
      "Validation loss decreased (0.146063 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870626\n",
      "\tspeed: 0.0764s/iter; left time: 1668.8168s\n",
      "\titers: 200, epoch: 3 | loss: 0.0844888\n",
      "\tspeed: 0.0422s/iter; left time: 917.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0846875 Vali Loss: 0.0790373 Test Loss: 0.0849046\n",
      "Validation loss decreased (0.082189 --> 0.079037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827117\n",
      "\tspeed: 0.0764s/iter; left time: 1652.0138s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803005\n",
      "\tspeed: 0.0422s/iter; left time: 907.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0816715 Vali Loss: 0.0771680 Test Loss: 0.0833144\n",
      "Validation loss decreased (0.079037 --> 0.077168).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0789151\n",
      "\tspeed: 0.0766s/iter; left time: 1639.4496s\n",
      "\titers: 200, epoch: 5 | loss: 0.0748166\n",
      "\tspeed: 0.0422s/iter; left time: 898.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0794953 Vali Loss: 0.0765681 Test Loss: 0.0823561\n",
      "Validation loss decreased (0.077168 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0762038\n",
      "\tspeed: 0.0764s/iter; left time: 1617.1734s\n",
      "\titers: 200, epoch: 6 | loss: 0.0740378\n",
      "\tspeed: 0.0421s/iter; left time: 888.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0782446 Vali Loss: 0.0759999 Test Loss: 0.0817863\n",
      "Validation loss decreased (0.076568 --> 0.076000).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763244\n",
      "\tspeed: 0.0767s/iter; left time: 1606.8378s\n",
      "\titers: 200, epoch: 7 | loss: 0.0782034\n",
      "\tspeed: 0.0421s/iter; left time: 878.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0771933 Vali Loss: 0.0759410 Test Loss: 0.0814095\n",
      "Validation loss decreased (0.076000 --> 0.075941).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0747644\n",
      "\tspeed: 0.0763s/iter; left time: 1582.0210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761208\n",
      "\tspeed: 0.0422s/iter; left time: 871.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0764373 Vali Loss: 0.0757183 Test Loss: 0.0811260\n",
      "Validation loss decreased (0.075941 --> 0.075718).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0750381\n",
      "\tspeed: 0.0765s/iter; left time: 1569.2628s\n",
      "\titers: 200, epoch: 9 | loss: 0.0731351\n",
      "\tspeed: 0.0422s/iter; left time: 860.9791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0757711 Vali Loss: 0.0755833 Test Loss: 0.0808182\n",
      "Validation loss decreased (0.075718 --> 0.075583).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783068\n",
      "\tspeed: 0.0761s/iter; left time: 1543.9719s\n",
      "\titers: 200, epoch: 10 | loss: 0.0743017\n",
      "\tspeed: 0.0422s/iter; left time: 851.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0753262 Vali Loss: 0.0755877 Test Loss: 0.0805964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771382\n",
      "\tspeed: 0.0756s/iter; left time: 1516.5527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740948\n",
      "\tspeed: 0.0422s/iter; left time: 842.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0747834 Vali Loss: 0.0756617 Test Loss: 0.0803652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0786360\n",
      "\tspeed: 0.0756s/iter; left time: 1499.9003s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729992\n",
      "\tspeed: 0.0422s/iter; left time: 832.2774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0743543 Vali Loss: 0.0755620 Test Loss: 0.0802146\n",
      "Validation loss decreased (0.075583 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0725833\n",
      "\tspeed: 0.0765s/iter; left time: 1499.4473s\n",
      "\titers: 200, epoch: 13 | loss: 0.0697948\n",
      "\tspeed: 0.0422s/iter; left time: 823.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0740273 Vali Loss: 0.0755412 Test Loss: 0.0800680\n",
      "Validation loss decreased (0.075562 --> 0.075541).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0740454\n",
      "\tspeed: 0.0764s/iter; left time: 1480.4458s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752891\n",
      "\tspeed: 0.0422s/iter; left time: 813.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0736795 Vali Loss: 0.0755513 Test Loss: 0.0800328\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793785\n",
      "\tspeed: 0.0758s/iter; left time: 1452.8962s\n",
      "\titers: 200, epoch: 15 | loss: 0.0747355\n",
      "\tspeed: 0.0422s/iter; left time: 804.0020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0733939 Vali Loss: 0.0753872 Test Loss: 0.0796960\n",
      "Validation loss decreased (0.075541 --> 0.075387).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0686066\n",
      "\tspeed: 0.0764s/iter; left time: 1447.3942s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700632\n",
      "\tspeed: 0.0422s/iter; left time: 795.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0730653 Vali Loss: 0.0757043 Test Loss: 0.0799135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754684\n",
      "\tspeed: 0.0754s/iter; left time: 1410.9061s\n",
      "\titers: 200, epoch: 17 | loss: 0.0724376\n",
      "\tspeed: 0.0421s/iter; left time: 784.5095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0728220 Vali Loss: 0.0758647 Test Loss: 0.0800363\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0696758\n",
      "\tspeed: 0.0754s/iter; left time: 1394.1991s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764009\n",
      "\tspeed: 0.0422s/iter; left time: 776.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0725893 Vali Loss: 0.0754318 Test Loss: 0.0797931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728003\n",
      "\tspeed: 0.0752s/iter; left time: 1374.6866s\n",
      "\titers: 200, epoch: 19 | loss: 0.0710235\n",
      "\tspeed: 0.0421s/iter; left time: 765.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0723859 Vali Loss: 0.0757423 Test Loss: 0.0799313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743600\n",
      "\tspeed: 0.0755s/iter; left time: 1362.9587s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744077\n",
      "\tspeed: 0.0422s/iter; left time: 757.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0721254 Vali Loss: 0.0756425 Test Loss: 0.0798354\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732355\n",
      "\tspeed: 0.0757s/iter; left time: 1348.4602s\n",
      "\titers: 200, epoch: 21 | loss: 0.0718889\n",
      "\tspeed: 0.0422s/iter; left time: 747.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0720353 Vali Loss: 0.0757102 Test Loss: 0.0798239\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0769786\n",
      "\tspeed: 0.0757s/iter; left time: 1331.8141s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750980\n",
      "\tspeed: 0.0422s/iter; left time: 737.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0719278 Vali Loss: 0.0756645 Test Loss: 0.0797868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0732628\n",
      "\tspeed: 0.0757s/iter; left time: 1315.6078s\n",
      "\titers: 200, epoch: 23 | loss: 0.0671167\n",
      "\tspeed: 0.0422s/iter; left time: 728.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0717096 Vali Loss: 0.0756078 Test Loss: 0.0796641\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0737137\n",
      "\tspeed: 0.0758s/iter; left time: 1299.6338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0736793\n",
      "\tspeed: 0.0421s/iter; left time: 718.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0714802 Vali Loss: 0.0756013 Test Loss: 0.0797363\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0705145\n",
      "\tspeed: 0.0755s/iter; left time: 1277.6675s\n",
      "\titers: 200, epoch: 25 | loss: 0.0737963\n",
      "\tspeed: 0.0421s/iter; left time: 708.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0715292 Vali Loss: 0.0757246 Test Loss: 0.0798351\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018040161579847336, rmse:0.1343136727809906, mae:0.07969599217176437, rse:0.5078544616699219\n",
      "Intermediate time for IT and pred_len 96: 00h:13m:47.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1685084\n",
      "\tspeed: 0.0612s/iter; left time: 1358.8251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1568417\n",
      "\tspeed: 0.0426s/iter; left time: 941.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.1736281 Vali Loss: 0.1484829 Test Loss: 0.1557589\n",
      "Validation loss decreased (inf --> 0.148483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974766\n",
      "\tspeed: 0.1101s/iter; left time: 2418.9825s\n",
      "\titers: 200, epoch: 2 | loss: 0.0909598\n",
      "\tspeed: 0.0427s/iter; left time: 933.3097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.1043616 Vali Loss: 0.0868721 Test Loss: 0.0920455\n",
      "Validation loss decreased (0.148483 --> 0.086872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907705\n",
      "\tspeed: 0.0781s/iter; left time: 1698.4357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903725\n",
      "\tspeed: 0.0426s/iter; left time: 922.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0891924 Vali Loss: 0.0843571 Test Loss: 0.0895865\n",
      "Validation loss decreased (0.086872 --> 0.084357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856451\n",
      "\tspeed: 0.0786s/iter; left time: 1691.3843s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856527\n",
      "\tspeed: 0.0426s/iter; left time: 911.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0858986 Vali Loss: 0.0823978 Test Loss: 0.0877564\n",
      "Validation loss decreased (0.084357 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821580\n",
      "\tspeed: 0.0772s/iter; left time: 1646.0170s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865016\n",
      "\tspeed: 0.0426s/iter; left time: 902.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0836854 Vali Loss: 0.0821022 Test Loss: 0.0869493\n",
      "Validation loss decreased (0.082398 --> 0.082102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0820099\n",
      "\tspeed: 0.0771s/iter; left time: 1626.0144s\n",
      "\titers: 200, epoch: 6 | loss: 0.0806738\n",
      "\tspeed: 0.0426s/iter; left time: 893.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0824466 Vali Loss: 0.0818127 Test Loss: 0.0865573\n",
      "Validation loss decreased (0.082102 --> 0.081813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782823\n",
      "\tspeed: 0.0763s/iter; left time: 1591.4388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0790035\n",
      "\tspeed: 0.0426s/iter; left time: 883.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0815521 Vali Loss: 0.0815402 Test Loss: 0.0861961\n",
      "Validation loss decreased (0.081813 --> 0.081540).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0853935\n",
      "\tspeed: 0.0768s/iter; left time: 1584.1711s\n",
      "\titers: 200, epoch: 8 | loss: 0.0811640\n",
      "\tspeed: 0.0426s/iter; left time: 874.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0807243 Vali Loss: 0.0813643 Test Loss: 0.0859200\n",
      "Validation loss decreased (0.081540 --> 0.081364).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0786720\n",
      "\tspeed: 0.0764s/iter; left time: 1560.1609s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794805\n",
      "\tspeed: 0.0426s/iter; left time: 865.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0800110 Vali Loss: 0.0811726 Test Loss: 0.0858258\n",
      "Validation loss decreased (0.081364 --> 0.081173).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747472\n",
      "\tspeed: 0.0768s/iter; left time: 1550.7885s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790480\n",
      "\tspeed: 0.0426s/iter; left time: 855.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0794431 Vali Loss: 0.0812832 Test Loss: 0.0858309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785402\n",
      "\tspeed: 0.0763s/iter; left time: 1523.1569s\n",
      "\titers: 200, epoch: 11 | loss: 0.0822288\n",
      "\tspeed: 0.0426s/iter; left time: 845.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0789551 Vali Loss: 0.0812124 Test Loss: 0.0858182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0803159\n",
      "\tspeed: 0.0760s/iter; left time: 1501.7685s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763940\n",
      "\tspeed: 0.0426s/iter; left time: 836.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0784845 Vali Loss: 0.0816927 Test Loss: 0.0861263\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0770830\n",
      "\tspeed: 0.0756s/iter; left time: 1475.6543s\n",
      "\titers: 200, epoch: 13 | loss: 0.0745756\n",
      "\tspeed: 0.0426s/iter; left time: 826.9298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0780846 Vali Loss: 0.0811105 Test Loss: 0.0860111\n",
      "Validation loss decreased (0.081173 --> 0.081111).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754176\n",
      "\tspeed: 0.0782s/iter; left time: 1510.2850s\n",
      "\titers: 200, epoch: 14 | loss: 0.0782623\n",
      "\tspeed: 0.0426s/iter; left time: 817.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0777484 Vali Loss: 0.0813321 Test Loss: 0.0858601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782674\n",
      "\tspeed: 0.0761s/iter; left time: 1452.0951s\n",
      "\titers: 200, epoch: 15 | loss: 0.0810125\n",
      "\tspeed: 0.0425s/iter; left time: 807.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0774745 Vali Loss: 0.0815115 Test Loss: 0.0860015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0776845\n",
      "\tspeed: 0.0762s/iter; left time: 1435.8855s\n",
      "\titers: 200, epoch: 16 | loss: 0.0781795\n",
      "\tspeed: 0.0426s/iter; left time: 798.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0771345 Vali Loss: 0.0815269 Test Loss: 0.0859353\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0737727\n",
      "\tspeed: 0.0763s/iter; left time: 1421.3241s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730831\n",
      "\tspeed: 0.0426s/iter; left time: 788.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0769411 Vali Loss: 0.0812567 Test Loss: 0.0857312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0752616\n",
      "\tspeed: 0.0754s/iter; left time: 1388.9115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0719897\n",
      "\tspeed: 0.0425s/iter; left time: 778.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0767019 Vali Loss: 0.0813096 Test Loss: 0.0859496\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0768243\n",
      "\tspeed: 0.0760s/iter; left time: 1382.7631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0735799\n",
      "\tspeed: 0.0425s/iter; left time: 769.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0765290 Vali Loss: 0.0812752 Test Loss: 0.0859788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0761607\n",
      "\tspeed: 0.0761s/iter; left time: 1367.2224s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744282\n",
      "\tspeed: 0.0426s/iter; left time: 760.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0762922 Vali Loss: 0.0812472 Test Loss: 0.0858141\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799511\n",
      "\tspeed: 0.0759s/iter; left time: 1346.6839s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779543\n",
      "\tspeed: 0.0426s/iter; left time: 751.0341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761807 Vali Loss: 0.0814064 Test Loss: 0.0856810\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0768406\n",
      "\tspeed: 0.0777s/iter; left time: 1360.9688s\n",
      "\titers: 200, epoch: 22 | loss: 0.0725928\n",
      "\tspeed: 0.0431s/iter; left time: 750.6392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0759702 Vali Loss: 0.0813204 Test Loss: 0.0858513\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0737765\n",
      "\tspeed: 0.0780s/iter; left time: 1348.2847s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740322\n",
      "\tspeed: 0.0425s/iter; left time: 731.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0758253 Vali Loss: 0.0816101 Test Loss: 0.0858746\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019910652190446854, rmse:0.14110511541366577, mae:0.08601111173629761, rse:0.5340294241905212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1738360\n",
      "\tspeed: 0.0442s/iter; left time: 981.7278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1570505\n",
      "\tspeed: 0.0425s/iter; left time: 939.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.1732006 Vali Loss: 0.1485402 Test Loss: 0.1558604\n",
      "Validation loss decreased (inf --> 0.148540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986272\n",
      "\tspeed: 0.0770s/iter; left time: 1691.7702s\n",
      "\titers: 200, epoch: 2 | loss: 0.0931965\n",
      "\tspeed: 0.0425s/iter; left time: 929.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.1054054 Vali Loss: 0.0868926 Test Loss: 0.0923197\n",
      "Validation loss decreased (0.148540 --> 0.086893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888634\n",
      "\tspeed: 0.0772s/iter; left time: 1678.5131s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917304\n",
      "\tspeed: 0.0425s/iter; left time: 919.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0895569 Vali Loss: 0.0843855 Test Loss: 0.0898747\n",
      "Validation loss decreased (0.086893 --> 0.084385).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0846417\n",
      "\tspeed: 0.0771s/iter; left time: 1659.5696s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825565\n",
      "\tspeed: 0.0425s/iter; left time: 910.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0864843 Vali Loss: 0.0826916 Test Loss: 0.0881381\n",
      "Validation loss decreased (0.084385 --> 0.082692).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862233\n",
      "\tspeed: 0.0766s/iter; left time: 1632.0659s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826791\n",
      "\tspeed: 0.0425s/iter; left time: 902.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0839479 Vali Loss: 0.0819256 Test Loss: 0.0870442\n",
      "Validation loss decreased (0.082692 --> 0.081926).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0812812\n",
      "\tspeed: 0.0769s/iter; left time: 1620.5324s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846281\n",
      "\tspeed: 0.0426s/iter; left time: 893.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0825281 Vali Loss: 0.0813871 Test Loss: 0.0863121\n",
      "Validation loss decreased (0.081926 --> 0.081387).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798724\n",
      "\tspeed: 0.0772s/iter; left time: 1609.8902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788262\n",
      "\tspeed: 0.0425s/iter; left time: 883.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0815098 Vali Loss: 0.0816422 Test Loss: 0.0858767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0786085\n",
      "\tspeed: 0.0763s/iter; left time: 1574.0331s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805364\n",
      "\tspeed: 0.0425s/iter; left time: 872.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0807263 Vali Loss: 0.0811599 Test Loss: 0.0855367\n",
      "Validation loss decreased (0.081387 --> 0.081160).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0814225\n",
      "\tspeed: 0.0767s/iter; left time: 1565.8337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0816666\n",
      "\tspeed: 0.0425s/iter; left time: 863.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0800378 Vali Loss: 0.0809861 Test Loss: 0.0854724\n",
      "Validation loss decreased (0.081160 --> 0.080986).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825524\n",
      "\tspeed: 0.0765s/iter; left time: 1543.9701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0778407\n",
      "\tspeed: 0.0425s/iter; left time: 854.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0794228 Vali Loss: 0.0812544 Test Loss: 0.0852757\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800575\n",
      "\tspeed: 0.0757s/iter; left time: 1511.8930s\n",
      "\titers: 200, epoch: 11 | loss: 0.0771785\n",
      "\tspeed: 0.0425s/iter; left time: 844.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0787776 Vali Loss: 0.0813259 Test Loss: 0.0853913\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0784340\n",
      "\tspeed: 0.0757s/iter; left time: 1495.1569s\n",
      "\titers: 200, epoch: 12 | loss: 0.0783378\n",
      "\tspeed: 0.0425s/iter; left time: 835.1028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0783605 Vali Loss: 0.0813706 Test Loss: 0.0855518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815431\n",
      "\tspeed: 0.0757s/iter; left time: 1478.1764s\n",
      "\titers: 200, epoch: 13 | loss: 0.0804912\n",
      "\tspeed: 0.0425s/iter; left time: 825.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0779481 Vali Loss: 0.0812705 Test Loss: 0.0853575\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0739288\n",
      "\tspeed: 0.0757s/iter; left time: 1461.2092s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797356\n",
      "\tspeed: 0.0425s/iter; left time: 816.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0775050 Vali Loss: 0.0813125 Test Loss: 0.0853628\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0769799\n",
      "\tspeed: 0.0760s/iter; left time: 1449.5217s\n",
      "\titers: 200, epoch: 15 | loss: 0.0748191\n",
      "\tspeed: 0.0425s/iter; left time: 807.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0771534 Vali Loss: 0.0813744 Test Loss: 0.0854055\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790950\n",
      "\tspeed: 0.0761s/iter; left time: 1435.8119s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787604\n",
      "\tspeed: 0.0425s/iter; left time: 796.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0768260 Vali Loss: 0.0812937 Test Loss: 0.0853267\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749521\n",
      "\tspeed: 0.0760s/iter; left time: 1416.8419s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770926\n",
      "\tspeed: 0.0425s/iter; left time: 787.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0765596 Vali Loss: 0.0813438 Test Loss: 0.0854356\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787697\n",
      "\tspeed: 0.0762s/iter; left time: 1403.4467s\n",
      "\titers: 200, epoch: 18 | loss: 0.0734112\n",
      "\tspeed: 0.0425s/iter; left time: 777.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0762949 Vali Loss: 0.0812519 Test Loss: 0.0853387\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0755710\n",
      "\tspeed: 0.0758s/iter; left time: 1378.9938s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773897\n",
      "\tspeed: 0.0425s/iter; left time: 768.9724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761299 Vali Loss: 0.0814988 Test Loss: 0.0855493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019644267857074738, rmse:0.140158012509346, mae:0.08547242730855942, rse:0.5304449796676636\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:37.41s\n",
      "Intermediate time for IT: 00h:41m:37.27s\n",
      "Total time: 03h:58m:51.50s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1459  0.0891\n",
       "        96              0.0361  0.1899  0.1267\n",
       "        168             0.0395  0.1987  0.1348\n",
       "ES      24              0.0098  0.0990  0.0595\n",
       "        96              0.0185  0.1361  0.0864\n",
       "        168             0.0212  0.1456  0.0953\n",
       "FR      24              0.0101  0.1005  0.0552\n",
       "        96              0.0195  0.1397  0.0819\n",
       "        168             0.0216  0.1468  0.0891\n",
       "GB      24              0.0260  0.1614  0.1025\n",
       "        96              0.0431  0.2075  0.1421\n",
       "        168             0.0463  0.2151  0.1488\n",
       "IT      24              0.0102  0.1011  0.0572\n",
       "        96              0.0182  0.1350  0.0800\n",
       "        168             0.0198  0.1406  0.0857"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
