{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0425s/iter; left time: 186.3442s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0147s/iter; left time: 62.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0336s/iter; left time: 139.6125s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0162s/iter; left time: 65.6242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0352s/iter; left time: 138.5111s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0196s/iter; left time: 75.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0372s/iter; left time: 137.9160s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0185s/iter; left time: 66.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0409s/iter; left time: 142.6269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0177s/iter; left time: 59.8200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0365s/iter; left time: 119.0118s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0186s/iter; left time: 58.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0356s/iter; left time: 108.0049s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0174s/iter; left time: 51.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0360s/iter; left time: 101.2319s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0192s/iter; left time: 52.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0370s/iter; left time: 95.6674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0180s/iter; left time: 44.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0352s/iter; left time: 83.2606s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0181s/iter; left time: 40.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0363s/iter; left time: 77.6939s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0185s/iter; left time: 37.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0402s/iter; left time: 77.0498s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0166s/iter; left time: 30.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0385s/iter; left time: 65.2465s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0159s/iter; left time: 25.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0420s/iter; left time: 61.6369s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0202s/iter; left time: 27.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0377s/iter; left time: 46.9912s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0194s/iter; left time: 22.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0369s/iter; left time: 37.6850s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0177s/iter; left time: 16.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0325s/iter; left time: 25.9253s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0147s/iter; left time: 10.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0339s/iter; left time: 19.4218s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0175s/iter; left time: 8.2969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0420s/iter; left time: 14.6607s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0227s/iter; left time: 5.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0420s/iter; left time: 5.2486s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0198s/iter; left time: 0.4942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02197897806763649, rmse:0.14825308322906494, mae:0.09260880947113037, rse:0.5232056975364685\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2721842\n",
      "\tspeed: 0.0240s/iter; left time: 104.9852s\n",
      "\titers: 200, epoch: 1 | loss: 0.2545170\n",
      "\tspeed: 0.0218s/iter; left time: 93.4615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.2761312 Vali Loss: 0.2322660 Test Loss: 0.2356385\n",
      "Validation loss decreased (inf --> 0.232266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482331\n",
      "\tspeed: 0.0355s/iter; left time: 147.6405s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319499\n",
      "\tspeed: 0.0149s/iter; left time: 60.3281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1566612 Vali Loss: 0.1185808 Test Loss: 0.1211408\n",
      "Validation loss decreased (0.232266 --> 0.118581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1081690\n",
      "\tspeed: 0.0360s/iter; left time: 141.6233s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004020\n",
      "\tspeed: 0.0192s/iter; left time: 73.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1067749 Vali Loss: 0.1074769 Test Loss: 0.1081204\n",
      "Validation loss decreased (0.118581 --> 0.107477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891181\n",
      "\tspeed: 0.0348s/iter; left time: 128.8989s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888426\n",
      "\tspeed: 0.0166s/iter; left time: 59.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0955432 Vali Loss: 0.1000804 Test Loss: 0.1024884\n",
      "Validation loss decreased (0.107477 --> 0.100080).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895891\n",
      "\tspeed: 0.0377s/iter; left time: 131.2394s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858524\n",
      "\tspeed: 0.0191s/iter; left time: 64.6147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0902970 Vali Loss: 0.1001018 Test Loss: 0.1025615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886195\n",
      "\tspeed: 0.0368s/iter; left time: 120.0273s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897056\n",
      "\tspeed: 0.0187s/iter; left time: 59.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0877654 Vali Loss: 0.0981362 Test Loss: 0.1006853\n",
      "Validation loss decreased (0.100080 --> 0.098136).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0878300\n",
      "\tspeed: 0.0372s/iter; left time: 113.0827s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826553\n",
      "\tspeed: 0.0174s/iter; left time: 51.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0857944 Vali Loss: 0.0958969 Test Loss: 0.0983018\n",
      "Validation loss decreased (0.098136 --> 0.095897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869670\n",
      "\tspeed: 0.0372s/iter; left time: 104.5667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836679\n",
      "\tspeed: 0.0185s/iter; left time: 50.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0840915 Vali Loss: 0.0946294 Test Loss: 0.0966067\n",
      "Validation loss decreased (0.095897 --> 0.094629).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806168\n",
      "\tspeed: 0.0325s/iter; left time: 84.2252s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788730\n",
      "\tspeed: 0.0147s/iter; left time: 36.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0832127 Vali Loss: 0.0942125 Test Loss: 0.0963571\n",
      "Validation loss decreased (0.094629 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0863781\n",
      "\tspeed: 0.0347s/iter; left time: 81.9788s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827872\n",
      "\tspeed: 0.0147s/iter; left time: 33.2494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 224 | Train Loss: 0.0823142 Vali Loss: 0.0934206 Test Loss: 0.0951447\n",
      "Validation loss decreased (0.094213 --> 0.093421).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0842941\n",
      "\tspeed: 0.0376s/iter; left time: 80.4039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798917\n",
      "\tspeed: 0.0213s/iter; left time: 43.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0812334 Vali Loss: 0.0930360 Test Loss: 0.0947575\n",
      "Validation loss decreased (0.093421 --> 0.093036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834161\n",
      "\tspeed: 0.0396s/iter; left time: 75.9682s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799981\n",
      "\tspeed: 0.0207s/iter; left time: 37.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0807119 Vali Loss: 0.0929712 Test Loss: 0.0947066\n",
      "Validation loss decreased (0.093036 --> 0.092971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815257\n",
      "\tspeed: 0.0427s/iter; left time: 72.2253s\n",
      "\titers: 200, epoch: 13 | loss: 0.0776588\n",
      "\tspeed: 0.0180s/iter; left time: 28.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0801480 Vali Loss: 0.0923747 Test Loss: 0.0944369\n",
      "Validation loss decreased (0.092971 --> 0.092375).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754340\n",
      "\tspeed: 0.0394s/iter; left time: 57.8197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819355\n",
      "\tspeed: 0.0170s/iter; left time: 23.3345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0798022 Vali Loss: 0.0923370 Test Loss: 0.0939305\n",
      "Validation loss decreased (0.092375 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803141\n",
      "\tspeed: 0.0380s/iter; left time: 47.3277s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758411\n",
      "\tspeed: 0.0209s/iter; left time: 23.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0792215 Vali Loss: 0.0938695 Test Loss: 0.0954283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0765127\n",
      "\tspeed: 0.0372s/iter; left time: 38.0095s\n",
      "\titers: 200, epoch: 16 | loss: 0.0853249\n",
      "\tspeed: 0.0176s/iter; left time: 16.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0790664 Vali Loss: 0.0919052 Test Loss: 0.0936920\n",
      "Validation loss decreased (0.092337 --> 0.091905).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0840101\n",
      "\tspeed: 0.0358s/iter; left time: 28.5016s\n",
      "\titers: 200, epoch: 17 | loss: 0.0743264\n",
      "\tspeed: 0.0217s/iter; left time: 15.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0785786 Vali Loss: 0.0913657 Test Loss: 0.0932587\n",
      "Validation loss decreased (0.091905 --> 0.091366).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0817556\n",
      "\tspeed: 0.0387s/iter; left time: 22.1612s\n",
      "\titers: 200, epoch: 18 | loss: 0.0756749\n",
      "\tspeed: 0.0168s/iter; left time: 7.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0783503 Vali Loss: 0.0909367 Test Loss: 0.0929703\n",
      "Validation loss decreased (0.091366 --> 0.090937).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806383\n",
      "\tspeed: 0.0397s/iter; left time: 13.8603s\n",
      "\titers: 200, epoch: 19 | loss: 0.0788134\n",
      "\tspeed: 0.0243s/iter; left time: 6.0394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0782910 Vali Loss: 0.0909684 Test Loss: 0.0929274\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790623\n",
      "\tspeed: 0.0360s/iter; left time: 4.4990s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762136\n",
      "\tspeed: 0.0170s/iter; left time: 0.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0779857 Vali Loss: 0.0904959 Test Loss: 0.0925888\n",
      "Validation loss decreased (0.090937 --> 0.090496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02206687070429325, rmse:0.14854921400547028, mae:0.09258876740932465, rse:0.5242507457733154\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:52.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0434s/iter; left time: 190.3141s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0150s/iter; left time: 64.0342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0360s/iter; left time: 149.6428s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0167s/iter; left time: 67.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0361s/iter; left time: 141.7978s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0187s/iter; left time: 71.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0418s/iter; left time: 154.9258s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0178s/iter; left time: 64.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0363s/iter; left time: 126.4420s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0202s/iter; left time: 68.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0380s/iter; left time: 123.8193s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0162s/iter; left time: 51.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0360s/iter; left time: 109.1829s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0162s/iter; left time: 47.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0390s/iter; left time: 109.6243s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0170s/iter; left time: 46.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0367s/iter; left time: 94.9922s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0150s/iter; left time: 37.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0365s/iter; left time: 86.2110s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0178s/iter; left time: 40.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0407s/iter; left time: 87.1434s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0186s/iter; left time: 38.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0357s/iter; left time: 68.4599s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0168s/iter; left time: 30.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0353s/iter; left time: 59.8180s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0160s/iter; left time: 25.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0355s/iter; left time: 52.0884s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0179s/iter; left time: 24.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0378s/iter; left time: 47.0716s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0226s/iter; left time: 25.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0380s/iter; left time: 38.8147s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0158s/iter; left time: 14.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0383s/iter; left time: 30.5138s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0156s/iter; left time: 10.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0368s/iter; left time: 21.0625s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0169s/iter; left time: 7.9763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0397s/iter; left time: 13.8496s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0196s/iter; left time: 4.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0341s/iter; left time: 4.2672s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0191s/iter; left time: 0.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04150562733411789, rmse:0.2037293016910553, mae:0.13349591195583344, rse:0.721446692943573\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2745755\n",
      "\tspeed: 0.0235s/iter; left time: 103.1565s\n",
      "\titers: 200, epoch: 1 | loss: 0.2692268\n",
      "\tspeed: 0.0231s/iter; left time: 98.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.2751624 Vali Loss: 0.2348203 Test Loss: 0.2388337\n",
      "Validation loss decreased (inf --> 0.234820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551890\n",
      "\tspeed: 0.0400s/iter; left time: 166.3750s\n",
      "\titers: 200, epoch: 2 | loss: 0.1321813\n",
      "\tspeed: 0.0160s/iter; left time: 64.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1654698 Vali Loss: 0.1417630 Test Loss: 0.1481800\n",
      "Validation loss decreased (0.234820 --> 0.141763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1215974\n",
      "\tspeed: 0.0370s/iter; left time: 145.4642s\n",
      "\titers: 200, epoch: 3 | loss: 0.1256834\n",
      "\tspeed: 0.0167s/iter; left time: 64.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1263876 Vali Loss: 0.1325889 Test Loss: 0.1409987\n",
      "Validation loss decreased (0.141763 --> 0.132589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1135110\n",
      "\tspeed: 0.0414s/iter; left time: 153.4803s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192949\n",
      "\tspeed: 0.0224s/iter; left time: 80.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.1174851 Vali Loss: 0.1272122 Test Loss: 0.1361652\n",
      "Validation loss decreased (0.132589 --> 0.127212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163965\n",
      "\tspeed: 0.0444s/iter; left time: 154.6167s\n",
      "\titers: 200, epoch: 5 | loss: 0.1152640\n",
      "\tspeed: 0.0207s/iter; left time: 70.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.1131541 Vali Loss: 0.1246094 Test Loss: 0.1332051\n",
      "Validation loss decreased (0.127212 --> 0.124609).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112591\n",
      "\tspeed: 0.0413s/iter; left time: 134.6318s\n",
      "\titers: 200, epoch: 6 | loss: 0.1082482\n",
      "\tspeed: 0.0193s/iter; left time: 61.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1111110 Vali Loss: 0.1238740 Test Loss: 0.1333937\n",
      "Validation loss decreased (0.124609 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057189\n",
      "\tspeed: 0.0411s/iter; left time: 124.8942s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117747\n",
      "\tspeed: 0.0182s/iter; left time: 53.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1091282 Vali Loss: 0.1267143 Test Loss: 0.1375530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1141506\n",
      "\tspeed: 0.0384s/iter; left time: 108.1486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009115\n",
      "\tspeed: 0.0183s/iter; left time: 49.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1081073 Vali Loss: 0.1231339 Test Loss: 0.1339826\n",
      "Validation loss decreased (0.123874 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1019052\n",
      "\tspeed: 0.0375s/iter; left time: 97.1743s\n",
      "\titers: 200, epoch: 9 | loss: 0.1077909\n",
      "\tspeed: 0.0184s/iter; left time: 45.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1073068 Vali Loss: 0.1232993 Test Loss: 0.1331413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1092062\n",
      "\tspeed: 0.0391s/iter; left time: 92.4493s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068623\n",
      "\tspeed: 0.0197s/iter; left time: 44.7243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.1064968 Vali Loss: 0.1219509 Test Loss: 0.1326125\n",
      "Validation loss decreased (0.123134 --> 0.121951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040168\n",
      "\tspeed: 0.0360s/iter; left time: 77.1446s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067823\n",
      "\tspeed: 0.0150s/iter; left time: 30.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1059778 Vali Loss: 0.1218960 Test Loss: 0.1338872\n",
      "Validation loss decreased (0.121951 --> 0.121896).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011791\n",
      "\tspeed: 0.0370s/iter; left time: 70.8505s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045789\n",
      "\tspeed: 0.0178s/iter; left time: 32.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1055520 Vali Loss: 0.1224215 Test Loss: 0.1361842\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020355\n",
      "\tspeed: 0.0396s/iter; left time: 66.9582s\n",
      "\titers: 200, epoch: 13 | loss: 0.1006409\n",
      "\tspeed: 0.0177s/iter; left time: 28.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.1050931 Vali Loss: 0.1211242 Test Loss: 0.1328582\n",
      "Validation loss decreased (0.121896 --> 0.121124).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023372\n",
      "\tspeed: 0.0402s/iter; left time: 59.1163s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056428\n",
      "\tspeed: 0.0174s/iter; left time: 23.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1046984 Vali Loss: 0.1215836 Test Loss: 0.1348134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028019\n",
      "\tspeed: 0.0377s/iter; left time: 46.9137s\n",
      "\titers: 200, epoch: 15 | loss: 0.1016776\n",
      "\tspeed: 0.0183s/iter; left time: 20.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1043435 Vali Loss: 0.1219964 Test Loss: 0.1366068\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1028563\n",
      "\tspeed: 0.0355s/iter; left time: 36.2853s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091383\n",
      "\tspeed: 0.0152s/iter; left time: 13.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1043203 Vali Loss: 0.1209410 Test Loss: 0.1350278\n",
      "Validation loss decreased (0.121124 --> 0.120941).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068253\n",
      "\tspeed: 0.0388s/iter; left time: 30.9340s\n",
      "\titers: 200, epoch: 17 | loss: 0.1018474\n",
      "\tspeed: 0.0183s/iter; left time: 12.7437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1039987 Vali Loss: 0.1214914 Test Loss: 0.1367325\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1014489\n",
      "\tspeed: 0.0365s/iter; left time: 20.9099s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990626\n",
      "\tspeed: 0.0150s/iter; left time: 7.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1036466 Vali Loss: 0.1200883 Test Loss: 0.1337987\n",
      "Validation loss decreased (0.120941 --> 0.120088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1060394\n",
      "\tspeed: 0.0358s/iter; left time: 12.4978s\n",
      "\titers: 200, epoch: 19 | loss: 0.1063231\n",
      "\tspeed: 0.0172s/iter; left time: 4.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1036820 Vali Loss: 0.1203940 Test Loss: 0.1338672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1069428\n",
      "\tspeed: 0.0374s/iter; left time: 4.6735s\n",
      "\titers: 200, epoch: 20 | loss: 0.1037648\n",
      "\tspeed: 0.0178s/iter; left time: 0.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.1033537 Vali Loss: 0.1214264 Test Loss: 0.1366773\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04148979112505913, rmse:0.20369042456150055, mae:0.1337987184524536, rse:0.7213089466094971\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:56.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0434s/iter; left time: 189.2073s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0153s/iter; left time: 65.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0352s/iter; left time: 145.7541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0152s/iter; left time: 61.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0349s/iter; left time: 136.5407s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0153s/iter; left time: 58.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0385s/iter; left time: 142.0827s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0152s/iter; left time: 54.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0348s/iter; left time: 120.8552s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0201s/iter; left time: 67.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0371s/iter; left time: 120.2849s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0152s/iter; left time: 47.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0378s/iter; left time: 114.2307s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0164s/iter; left time: 47.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0393s/iter; left time: 110.1425s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0200s/iter; left time: 53.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0374s/iter; left time: 96.2940s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0165s/iter; left time: 40.9024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0375s/iter; left time: 88.1992s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0171s/iter; left time: 38.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0417s/iter; left time: 88.9434s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0190s/iter; left time: 38.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0350s/iter; left time: 66.8163s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0194s/iter; left time: 35.0513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0403s/iter; left time: 67.8308s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0152s/iter; left time: 24.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0365s/iter; left time: 53.3737s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0154s/iter; left time: 20.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0372s/iter; left time: 46.0534s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0169s/iter; left time: 19.2656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0393s/iter; left time: 39.9785s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0191s/iter; left time: 17.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0373s/iter; left time: 29.5417s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0182s/iter; left time: 12.6162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0376s/iter; left time: 21.4098s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0179s/iter; left time: 8.3986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0404s/iter; left time: 14.0241s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0151s/iter; left time: 3.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04356519505381584, rmse:0.2087227702140808, mae:0.1395985186100006, rse:0.7393128275871277\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812734\n",
      "\tspeed: 0.0215s/iter; left time: 93.9062s\n",
      "\titers: 200, epoch: 1 | loss: 0.2648552\n",
      "\tspeed: 0.0193s/iter; left time: 82.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.2822170 Vali Loss: 0.2397827 Test Loss: 0.2450302\n",
      "Validation loss decreased (inf --> 0.239783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632033\n",
      "\tspeed: 0.0429s/iter; left time: 177.3251s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432949\n",
      "\tspeed: 0.0170s/iter; left time: 68.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1688149 Vali Loss: 0.1457720 Test Loss: 0.1536164\n",
      "Validation loss decreased (0.239783 --> 0.145772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1266351\n",
      "\tspeed: 0.0383s/iter; left time: 149.9207s\n",
      "\titers: 200, epoch: 3 | loss: 0.1198552\n",
      "\tspeed: 0.0180s/iter; left time: 68.6526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1316933 Vali Loss: 0.1368362 Test Loss: 0.1507061\n",
      "Validation loss decreased (0.145772 --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1193674\n",
      "\tspeed: 0.0433s/iter; left time: 159.7624s\n",
      "\titers: 200, epoch: 4 | loss: 0.1206695\n",
      "\tspeed: 0.0193s/iter; left time: 69.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1227247 Vali Loss: 0.1357975 Test Loss: 0.1491872\n",
      "Validation loss decreased (0.136836 --> 0.135798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187348\n",
      "\tspeed: 0.0390s/iter; left time: 135.3528s\n",
      "\titers: 200, epoch: 5 | loss: 0.1190373\n",
      "\tspeed: 0.0177s/iter; left time: 59.4858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1191489 Vali Loss: 0.1308743 Test Loss: 0.1448017\n",
      "Validation loss decreased (0.135798 --> 0.130874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146746\n",
      "\tspeed: 0.0376s/iter; left time: 121.9025s\n",
      "\titers: 200, epoch: 6 | loss: 0.1148309\n",
      "\tspeed: 0.0152s/iter; left time: 47.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1166092 Vali Loss: 0.1314674 Test Loss: 0.1459267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1175115\n",
      "\tspeed: 0.0407s/iter; left time: 122.9642s\n",
      "\titers: 200, epoch: 7 | loss: 0.1088397\n",
      "\tspeed: 0.0194s/iter; left time: 56.7015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1151693 Vali Loss: 0.1312253 Test Loss: 0.1448718\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1191927\n",
      "\tspeed: 0.0422s/iter; left time: 118.1438s\n",
      "\titers: 200, epoch: 8 | loss: 0.1117679\n",
      "\tspeed: 0.0194s/iter; left time: 52.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1141006 Vali Loss: 0.1306444 Test Loss: 0.1441707\n",
      "Validation loss decreased (0.130874 --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1125659\n",
      "\tspeed: 0.0412s/iter; left time: 106.1390s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103978\n",
      "\tspeed: 0.0197s/iter; left time: 48.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.1131375 Vali Loss: 0.1308488 Test Loss: 0.1439586\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097929\n",
      "\tspeed: 0.0371s/iter; left time: 87.3929s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076796\n",
      "\tspeed: 0.0171s/iter; left time: 38.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1123829 Vali Loss: 0.1314475 Test Loss: 0.1447518\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068592\n",
      "\tspeed: 0.0436s/iter; left time: 92.8487s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085388\n",
      "\tspeed: 0.0229s/iter; left time: 46.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.1117776 Vali Loss: 0.1311427 Test Loss: 0.1450391\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080086\n",
      "\tspeed: 0.0375s/iter; left time: 71.4826s\n",
      "\titers: 200, epoch: 12 | loss: 0.1089400\n",
      "\tspeed: 0.0180s/iter; left time: 32.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1112884 Vali Loss: 0.1306694 Test Loss: 0.1443284\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1129659\n",
      "\tspeed: 0.0447s/iter; left time: 75.2401s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087663\n",
      "\tspeed: 0.0225s/iter; left time: 35.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1107222 Vali Loss: 0.1300552 Test Loss: 0.1437648\n",
      "Validation loss decreased (0.130644 --> 0.130055).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1106686\n",
      "\tspeed: 0.0391s/iter; left time: 57.1431s\n",
      "\titers: 200, epoch: 14 | loss: 0.1079151\n",
      "\tspeed: 0.0170s/iter; left time: 23.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.1102911 Vali Loss: 0.1309756 Test Loss: 0.1456672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1096638\n",
      "\tspeed: 0.0378s/iter; left time: 46.8410s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065728\n",
      "\tspeed: 0.0168s/iter; left time: 19.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1099320 Vali Loss: 0.1304136 Test Loss: 0.1437775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1128930\n",
      "\tspeed: 0.0380s/iter; left time: 38.5860s\n",
      "\titers: 200, epoch: 16 | loss: 0.1056558\n",
      "\tspeed: 0.0155s/iter; left time: 14.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1095359 Vali Loss: 0.1290297 Test Loss: 0.1434999\n",
      "Validation loss decreased (0.130055 --> 0.129030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1129074\n",
      "\tspeed: 0.0377s/iter; left time: 29.9343s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060182\n",
      "\tspeed: 0.0173s/iter; left time: 12.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1093078 Vali Loss: 0.1279821 Test Loss: 0.1426028\n",
      "Validation loss decreased (0.129030 --> 0.127982).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089246\n",
      "\tspeed: 0.0386s/iter; left time: 22.0086s\n",
      "\titers: 200, epoch: 18 | loss: 0.1129903\n",
      "\tspeed: 0.0166s/iter; left time: 7.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.1088755 Vali Loss: 0.1292565 Test Loss: 0.1439340\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1071319\n",
      "\tspeed: 0.0382s/iter; left time: 13.2416s\n",
      "\titers: 200, epoch: 19 | loss: 0.1072017\n",
      "\tspeed: 0.0169s/iter; left time: 4.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1088933 Vali Loss: 0.1299791 Test Loss: 0.1445618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1044815\n",
      "\tspeed: 0.0402s/iter; left time: 4.9789s\n",
      "\titers: 200, epoch: 20 | loss: 0.1130169\n",
      "\tspeed: 0.0153s/iter; left time: 0.3666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.1085727 Vali Loss: 0.1287442 Test Loss: 0.1427801\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046037085354328156, rmse:0.2145625501871109, mae:0.1426028162240982, rse:0.7599977850914001\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:52.32s\n",
      "Intermediate time for DE: 00h:11m:41.48s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0419s/iter; left time: 183.4743s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0148s/iter; left time: 63.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0352s/iter; left time: 146.4228s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0166s/iter; left time: 67.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0353s/iter; left time: 138.7091s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0162s/iter; left time: 62.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0346s/iter; left time: 128.2672s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0148s/iter; left time: 53.4397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0381s/iter; left time: 132.6051s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0174s/iter; left time: 59.0135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0378s/iter; left time: 123.2190s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0186s/iter; left time: 58.8762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0361s/iter; left time: 109.5462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0163s/iter; left time: 47.9565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0387s/iter; left time: 108.8325s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0185s/iter; left time: 50.2520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0392s/iter; left time: 101.5800s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0169s/iter; left time: 42.1018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0399s/iter; left time: 94.3928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0201s/iter; left time: 45.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0381s/iter; left time: 81.6356s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0199s/iter; left time: 40.5385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0363s/iter; left time: 69.6433s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0186s/iter; left time: 33.8804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0384s/iter; left time: 64.9685s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0194s/iter; left time: 30.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0343s/iter; left time: 50.3897s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0154s/iter; left time: 21.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0347s/iter; left time: 43.2111s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0147s/iter; left time: 16.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0371s/iter; left time: 37.8707s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0163s/iter; left time: 14.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0341s/iter; left time: 27.1531s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0148s/iter; left time: 10.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0370s/iter; left time: 21.1810s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0191s/iter; left time: 9.0471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0379s/iter; left time: 13.2122s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0153s/iter; left time: 3.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0368s/iter; left time: 4.5993s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0148s/iter; left time: 0.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026859937235713005, rmse:0.1638900190591812, mae:0.10591384768486023, rse:0.5653740763664246\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2846910\n",
      "\tspeed: 0.0209s/iter; left time: 91.7064s\n",
      "\titers: 200, epoch: 1 | loss: 0.2726133\n",
      "\tspeed: 0.0158s/iter; left time: 67.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.2926167 Vali Loss: 0.2415705 Test Loss: 0.2631590\n",
      "Validation loss decreased (inf --> 0.241570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474976\n",
      "\tspeed: 0.0376s/iter; left time: 156.3673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268219\n",
      "\tspeed: 0.0178s/iter; left time: 72.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.1575704 Vali Loss: 0.1085933 Test Loss: 0.1230968\n",
      "Validation loss decreased (0.241570 --> 0.108593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0972578\n",
      "\tspeed: 0.0377s/iter; left time: 148.1305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915387\n",
      "\tspeed: 0.0173s/iter; left time: 66.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1023461 Vali Loss: 0.1003349 Test Loss: 0.1123432\n",
      "Validation loss decreased (0.108593 --> 0.100335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907324\n",
      "\tspeed: 0.0397s/iter; left time: 147.2404s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907905\n",
      "\tspeed: 0.0198s/iter; left time: 71.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0922343 Vali Loss: 0.0962823 Test Loss: 0.1112334\n",
      "Validation loss decreased (0.100335 --> 0.096282).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833255\n",
      "\tspeed: 0.0375s/iter; left time: 130.5555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889493\n",
      "\tspeed: 0.0168s/iter; left time: 56.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0880692 Vali Loss: 0.0964027 Test Loss: 0.1125074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861537\n",
      "\tspeed: 0.0381s/iter; left time: 124.1791s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848577\n",
      "\tspeed: 0.0181s/iter; left time: 57.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0863465 Vali Loss: 0.0961963 Test Loss: 0.1143982\n",
      "Validation loss decreased (0.096282 --> 0.096196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867636\n",
      "\tspeed: 0.0359s/iter; left time: 109.0779s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810365\n",
      "\tspeed: 0.0148s/iter; left time: 43.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0849434 Vali Loss: 0.0958150 Test Loss: 0.1149141\n",
      "Validation loss decreased (0.096196 --> 0.095815).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857168\n",
      "\tspeed: 0.0385s/iter; left time: 108.4043s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765620\n",
      "\tspeed: 0.0205s/iter; left time: 55.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0839813 Vali Loss: 0.0954577 Test Loss: 0.1139534\n",
      "Validation loss decreased (0.095815 --> 0.095458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816585\n",
      "\tspeed: 0.0401s/iter; left time: 103.7107s\n",
      "\titers: 200, epoch: 9 | loss: 0.0860098\n",
      "\tspeed: 0.0172s/iter; left time: 42.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0829976 Vali Loss: 0.0949424 Test Loss: 0.1124260\n",
      "Validation loss decreased (0.095458 --> 0.094942).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758343\n",
      "\tspeed: 0.0376s/iter; left time: 88.9079s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839384\n",
      "\tspeed: 0.0171s/iter; left time: 38.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0826377 Vali Loss: 0.0951414 Test Loss: 0.1145257\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811790\n",
      "\tspeed: 0.0366s/iter; left time: 78.4086s\n",
      "\titers: 200, epoch: 11 | loss: 0.0772140\n",
      "\tspeed: 0.0169s/iter; left time: 34.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0818311 Vali Loss: 0.0955937 Test Loss: 0.1145437\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838942\n",
      "\tspeed: 0.0393s/iter; left time: 75.4245s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844036\n",
      "\tspeed: 0.0148s/iter; left time: 26.8373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0815183 Vali Loss: 0.0939972 Test Loss: 0.1111869\n",
      "Validation loss decreased (0.094942 --> 0.093997).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823378\n",
      "\tspeed: 0.0342s/iter; left time: 57.8470s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742934\n",
      "\tspeed: 0.0149s/iter; left time: 23.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0810441 Vali Loss: 0.0945207 Test Loss: 0.1117665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795040\n",
      "\tspeed: 0.0378s/iter; left time: 55.4870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800683\n",
      "\tspeed: 0.0192s/iter; left time: 26.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0807827 Vali Loss: 0.0942772 Test Loss: 0.1117615\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812870\n",
      "\tspeed: 0.0376s/iter; left time: 46.8602s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817963\n",
      "\tspeed: 0.0206s/iter; left time: 23.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0804734 Vali Loss: 0.0958008 Test Loss: 0.1114092\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0762049\n",
      "\tspeed: 0.0363s/iter; left time: 37.0384s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810765\n",
      "\tspeed: 0.0167s/iter; left time: 15.3521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0802297 Vali Loss: 0.0947608 Test Loss: 0.1110980\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810842\n",
      "\tspeed: 0.0392s/iter; left time: 31.2205s\n",
      "\titers: 200, epoch: 17 | loss: 0.0765186\n",
      "\tspeed: 0.0162s/iter; left time: 11.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0800327 Vali Loss: 0.0935502 Test Loss: 0.1104114\n",
      "Validation loss decreased (0.093997 --> 0.093550).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781353\n",
      "\tspeed: 0.0354s/iter; left time: 20.2928s\n",
      "\titers: 200, epoch: 18 | loss: 0.0784078\n",
      "\tspeed: 0.0172s/iter; left time: 8.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0798923 Vali Loss: 0.0934620 Test Loss: 0.1093775\n",
      "Validation loss decreased (0.093550 --> 0.093462).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748001\n",
      "\tspeed: 0.0402s/iter; left time: 14.0236s\n",
      "\titers: 200, epoch: 19 | loss: 0.0821338\n",
      "\tspeed: 0.0196s/iter; left time: 4.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0798001 Vali Loss: 0.0938784 Test Loss: 0.1097977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804354\n",
      "\tspeed: 0.0373s/iter; left time: 4.6662s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798344\n",
      "\tspeed: 0.0153s/iter; left time: 0.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0795825 Vali Loss: 0.0931064 Test Loss: 0.1094512\n",
      "Validation loss decreased (0.093462 --> 0.093106).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029882589355111122, rmse:0.17286580801010132, mae:0.10945114493370056, rse:0.5963380336761475\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:49.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0430s/iter; left time: 188.5474s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0150s/iter; left time: 64.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0355s/iter; left time: 147.5405s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0157s/iter; left time: 63.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0361s/iter; left time: 141.8351s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0168s/iter; left time: 64.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0356s/iter; left time: 131.9749s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0162s/iter; left time: 58.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0346s/iter; left time: 120.4759s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0150s/iter; left time: 50.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0396s/iter; left time: 129.0400s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0164s/iter; left time: 51.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0378s/iter; left time: 114.9110s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0188s/iter; left time: 55.3132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0366s/iter; left time: 102.8540s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0164s/iter; left time: 44.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0424s/iter; left time: 109.6519s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0175s/iter; left time: 43.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0371s/iter; left time: 87.7814s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0152s/iter; left time: 34.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0354s/iter; left time: 75.8158s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0167s/iter; left time: 34.0205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0380s/iter; left time: 72.9154s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0158s/iter; left time: 28.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0383s/iter; left time: 64.8504s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0217s/iter; left time: 34.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0408s/iter; left time: 59.9570s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0182s/iter; left time: 24.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0343s/iter; left time: 42.7084s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0177s/iter; left time: 20.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0369s/iter; left time: 37.7032s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0159s/iter; left time: 14.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2884372\n",
      "\tspeed: 0.0257s/iter; left time: 112.7879s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747863\n",
      "\tspeed: 0.0176s/iter; left time: 75.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.2938896 Vali Loss: 0.2499466 Test Loss: 0.2730130\n",
      "Validation loss decreased (inf --> 0.249947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520033\n",
      "\tspeed: 0.0413s/iter; left time: 171.8261s\n",
      "\titers: 200, epoch: 2 | loss: 0.1356943\n",
      "\tspeed: 0.0198s/iter; left time: 80.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1651964 Vali Loss: 0.1318234 Test Loss: 0.1534363\n",
      "Validation loss decreased (0.249947 --> 0.131823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1237962\n",
      "\tspeed: 0.0393s/iter; left time: 154.4481s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129839\n",
      "\tspeed: 0.0176s/iter; left time: 67.4369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1195505 Vali Loss: 0.1288494 Test Loss: 0.1563801\n",
      "Validation loss decreased (0.131823 --> 0.128849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1170108\n",
      "\tspeed: 0.0362s/iter; left time: 134.3832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1174021\n",
      "\tspeed: 0.0160s/iter; left time: 57.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1124832 Vali Loss: 0.1280748 Test Loss: 0.1573510\n",
      "Validation loss decreased (0.128849 --> 0.128075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121775\n",
      "\tspeed: 0.0409s/iter; left time: 142.4109s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137156\n",
      "\tspeed: 0.0202s/iter; left time: 68.3345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1097073 Vali Loss: 0.1282495 Test Loss: 0.1588879\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1099907\n",
      "\tspeed: 0.0351s/iter; left time: 114.5354s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046706\n",
      "\tspeed: 0.0149s/iter; left time: 47.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1083800 Vali Loss: 0.1289193 Test Loss: 0.1627320\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1065593\n",
      "\tspeed: 0.0388s/iter; left time: 117.9460s\n",
      "\titers: 200, epoch: 7 | loss: 0.1135744\n",
      "\tspeed: 0.0225s/iter; left time: 65.9947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.1073907 Vali Loss: 0.1286131 Test Loss: 0.1610762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1053690\n",
      "\tspeed: 0.0344s/iter; left time: 96.7885s\n",
      "\titers: 200, epoch: 8 | loss: 0.1122044\n",
      "\tspeed: 0.0149s/iter; left time: 40.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1064029 Vali Loss: 0.1285266 Test Loss: 0.1602909\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083794\n",
      "\tspeed: 0.0362s/iter; left time: 93.6266s\n",
      "\titers: 200, epoch: 9 | loss: 0.1089216\n",
      "\tspeed: 0.0176s/iter; left time: 43.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1057083 Vali Loss: 0.1278156 Test Loss: 0.1567183\n",
      "Validation loss decreased (0.128075 --> 0.127816).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061578\n",
      "\tspeed: 0.0362s/iter; left time: 85.5576s\n",
      "\titers: 200, epoch: 10 | loss: 0.1020783\n",
      "\tspeed: 0.0179s/iter; left time: 40.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1050890 Vali Loss: 0.1274880 Test Loss: 0.1587726\n",
      "Validation loss decreased (0.127816 --> 0.127488).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040444\n",
      "\tspeed: 0.0411s/iter; left time: 88.0374s\n",
      "\titers: 200, epoch: 11 | loss: 0.1054638\n",
      "\tspeed: 0.0196s/iter; left time: 40.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1047036 Vali Loss: 0.1277202 Test Loss: 0.1562177\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1064437\n",
      "\tspeed: 0.0374s/iter; left time: 71.6716s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029790\n",
      "\tspeed: 0.0150s/iter; left time: 27.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1041447 Vali Loss: 0.1276648 Test Loss: 0.1580956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009996\n",
      "\tspeed: 0.0430s/iter; left time: 72.7680s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043827\n",
      "\tspeed: 0.0228s/iter; left time: 36.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1039346 Vali Loss: 0.1263682 Test Loss: 0.1542069\n",
      "Validation loss decreased (0.127488 --> 0.126368).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028414\n",
      "\tspeed: 0.0491s/iter; left time: 72.1637s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043060\n",
      "\tspeed: 0.0241s/iter; left time: 33.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1265923 Test Loss: 0.1548574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1049191\n",
      "\tspeed: 0.0411s/iter; left time: 51.1296s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034089\n",
      "\tspeed: 0.0186s/iter; left time: 21.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1032026 Vali Loss: 0.1266271 Test Loss: 0.1559636\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0956138\n",
      "\tspeed: 0.0414s/iter; left time: 42.3062s\n",
      "\titers: 200, epoch: 16 | loss: 0.0995768\n",
      "\tspeed: 0.0222s/iter; left time: 20.4676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1030918 Vali Loss: 0.1263742 Test Loss: 0.1539116\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0985429\n",
      "\tspeed: 0.0391s/iter; left time: 31.1634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0990500\n",
      "\tspeed: 0.0182s/iter; left time: 12.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1027496 Vali Loss: 0.1258379 Test Loss: 0.1540648\n",
      "Validation loss decreased (0.126368 --> 0.125838).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1027168\n",
      "\tspeed: 0.0388s/iter; left time: 22.2377s\n",
      "\titers: 200, epoch: 18 | loss: 0.1045104\n",
      "\tspeed: 0.0192s/iter; left time: 9.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1025700 Vali Loss: 0.1264045 Test Loss: 0.1539411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973583\n",
      "\tspeed: 0.0405s/iter; left time: 14.1415s\n",
      "\titers: 200, epoch: 19 | loss: 0.1044858\n",
      "\tspeed: 0.0192s/iter; left time: 4.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1024406 Vali Loss: 0.1257624 Test Loss: 0.1536622\n",
      "Validation loss decreased (0.125838 --> 0.125762).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1020775\n",
      "\tspeed: 0.0402s/iter; left time: 5.0212s\n",
      "\titers: 200, epoch: 20 | loss: 0.1067188\n",
      "\tspeed: 0.0163s/iter; left time: 0.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1022315 Vali Loss: 0.1262378 Test Loss: 0.1535022\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05444870516657829, rmse:0.2333424687385559, mae:0.15366211533546448, rse:0.8069307208061218\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:35.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0442s/iter; left time: 192.5491s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0153s/iter; left time: 65.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0370s/iter; left time: 153.2001s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0154s/iter; left time: 62.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0378s/iter; left time: 148.0475s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0152s/iter; left time: 58.0914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0346s/iter; left time: 127.7711s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0152s/iter; left time: 54.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0385s/iter; left time: 133.3915s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0186s/iter; left time: 62.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0392s/iter; left time: 127.3192s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0156s/iter; left time: 49.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0394s/iter; left time: 118.9614s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0202s/iter; left time: 59.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0436s/iter; left time: 122.0930s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0173s/iter; left time: 46.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0392s/iter; left time: 100.8971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0169s/iter; left time: 41.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0367s/iter; left time: 86.3427s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0173s/iter; left time: 39.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0354s/iter; left time: 75.4878s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0155s/iter; left time: 31.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0347s/iter; left time: 66.1984s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0152s/iter; left time: 27.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0398s/iter; left time: 67.0667s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0169s/iter; left time: 26.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2910986\n",
      "\tspeed: 0.0207s/iter; left time: 90.2693s\n",
      "\titers: 200, epoch: 1 | loss: 0.2834949\n",
      "\tspeed: 0.0178s/iter; left time: 75.9692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.2923341 Vali Loss: 0.2478191 Test Loss: 0.2692312\n",
      "Validation loss decreased (inf --> 0.247819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1509961\n",
      "\tspeed: 0.0398s/iter; left time: 164.7404s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339484\n",
      "\tspeed: 0.0171s/iter; left time: 69.1170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1644157 Vali Loss: 0.1374244 Test Loss: 0.1619911\n",
      "Validation loss decreased (0.247819 --> 0.137424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1268936\n",
      "\tspeed: 0.0435s/iter; left time: 170.3688s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223414\n",
      "\tspeed: 0.0211s/iter; left time: 80.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.1241407 Vali Loss: 0.1313642 Test Loss: 0.1588054\n",
      "Validation loss decreased (0.137424 --> 0.131364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162787\n",
      "\tspeed: 0.0455s/iter; left time: 168.1084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1151809\n",
      "\tspeed: 0.0193s/iter; left time: 69.1527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.1166980 Vali Loss: 0.1309440 Test Loss: 0.1621463\n",
      "Validation loss decreased (0.131364 --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1171696\n",
      "\tspeed: 0.0433s/iter; left time: 150.1149s\n",
      "\titers: 200, epoch: 5 | loss: 0.1122425\n",
      "\tspeed: 0.0214s/iter; left time: 72.0375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.1139985 Vali Loss: 0.1325590 Test Loss: 0.1652431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128479\n",
      "\tspeed: 0.0441s/iter; left time: 143.0990s\n",
      "\titers: 200, epoch: 6 | loss: 0.1111952\n",
      "\tspeed: 0.0197s/iter; left time: 61.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1127247 Vali Loss: 0.1303820 Test Loss: 0.1614654\n",
      "Validation loss decreased (0.130944 --> 0.130382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101843\n",
      "\tspeed: 0.0436s/iter; left time: 131.7685s\n",
      "\titers: 200, epoch: 7 | loss: 0.1144683\n",
      "\tspeed: 0.0198s/iter; left time: 57.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.1113464 Vali Loss: 0.1307575 Test Loss: 0.1610118\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114429\n",
      "\tspeed: 0.0429s/iter; left time: 120.2410s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068022\n",
      "\tspeed: 0.0199s/iter; left time: 53.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.1105503 Vali Loss: 0.1301013 Test Loss: 0.1594315\n",
      "Validation loss decreased (0.130382 --> 0.130101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1073766\n",
      "\tspeed: 0.0434s/iter; left time: 111.9315s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039732\n",
      "\tspeed: 0.0196s/iter; left time: 48.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1099073 Vali Loss: 0.1295959 Test Loss: 0.1585122\n",
      "Validation loss decreased (0.130101 --> 0.129596).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061911\n",
      "\tspeed: 0.0436s/iter; left time: 102.5790s\n",
      "\titers: 200, epoch: 10 | loss: 0.1109751\n",
      "\tspeed: 0.0200s/iter; left time: 45.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1095424 Vali Loss: 0.1308877 Test Loss: 0.1626594\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129102\n",
      "\tspeed: 0.0426s/iter; left time: 90.8034s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085048\n",
      "\tspeed: 0.0193s/iter; left time: 39.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1089675 Vali Loss: 0.1291195 Test Loss: 0.1578232\n",
      "Validation loss decreased (0.129596 --> 0.129120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1070272\n",
      "\tspeed: 0.0424s/iter; left time: 80.9687s\n",
      "\titers: 200, epoch: 12 | loss: 0.1068779\n",
      "\tspeed: 0.0213s/iter; left time: 38.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.1084242 Vali Loss: 0.1284974 Test Loss: 0.1579687\n",
      "Validation loss decreased (0.129120 --> 0.128497).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1096114\n",
      "\tspeed: 0.0445s/iter; left time: 75.0221s\n",
      "\titers: 200, epoch: 13 | loss: 0.1048709\n",
      "\tspeed: 0.0198s/iter; left time: 31.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1081906 Vali Loss: 0.1276691 Test Loss: 0.1578244\n",
      "Validation loss decreased (0.128497 --> 0.127669).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1105448\n",
      "\tspeed: 0.0429s/iter; left time: 62.7782s\n",
      "\titers: 200, epoch: 14 | loss: 0.1075893\n",
      "\tspeed: 0.0197s/iter; left time: 26.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1080442 Vali Loss: 0.1281609 Test Loss: 0.1572570\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1092115\n",
      "\tspeed: 0.0423s/iter; left time: 52.3640s\n",
      "\titers: 200, epoch: 15 | loss: 0.1053336\n",
      "\tspeed: 0.0202s/iter; left time: 23.0467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1076674 Vali Loss: 0.1286696 Test Loss: 0.1582996\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044834\n",
      "\tspeed: 0.0449s/iter; left time: 45.5981s\n",
      "\titers: 200, epoch: 16 | loss: 0.1047895\n",
      "\tspeed: 0.0248s/iter; left time: 22.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.1073679 Vali Loss: 0.1284060 Test Loss: 0.1590570\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1063645\n",
      "\tspeed: 0.0392s/iter; left time: 31.0738s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060797\n",
      "\tspeed: 0.0174s/iter; left time: 12.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1071399 Vali Loss: 0.1274910 Test Loss: 0.1575341\n",
      "Validation loss decreased (0.127669 --> 0.127491).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051314\n",
      "\tspeed: 0.0406s/iter; left time: 23.1175s\n",
      "\titers: 200, epoch: 18 | loss: 0.1067741\n",
      "\tspeed: 0.0200s/iter; left time: 9.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.1070178 Vali Loss: 0.1272823 Test Loss: 0.1581545\n",
      "Validation loss decreased (0.127491 --> 0.127282).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1085588\n",
      "\tspeed: 0.0424s/iter; left time: 14.7107s\n",
      "\titers: 200, epoch: 19 | loss: 0.1043933\n",
      "\tspeed: 0.0199s/iter; left time: 4.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1068289 Vali Loss: 0.1283977 Test Loss: 0.1593443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073587\n",
      "\tspeed: 0.0417s/iter; left time: 5.1744s\n",
      "\titers: 200, epoch: 20 | loss: 0.1076517\n",
      "\tspeed: 0.0201s/iter; left time: 0.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1066923 Vali Loss: 0.1281582 Test Loss: 0.1594106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05579496920108795, rmse:0.23620958626270294, mae:0.1581544131040573, rse:0.8189725875854492\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:29.51s\n",
      "Intermediate time for GB: 00h:10m:53.81s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0422s/iter; left time: 184.8017s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0158s/iter; left time: 67.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0335s/iter; left time: 139.1603s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0185s/iter; left time: 75.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0361s/iter; left time: 141.8640s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0200s/iter; left time: 76.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0405s/iter; left time: 150.3698s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0192s/iter; left time: 69.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0351s/iter; left time: 122.2895s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0179s/iter; left time: 60.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0390s/iter; left time: 127.1359s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0173s/iter; left time: 54.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0377s/iter; left time: 114.5358s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0195s/iter; left time: 57.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0392s/iter; left time: 110.2013s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0203s/iter; left time: 55.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0390s/iter; left time: 100.8476s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0208s/iter; left time: 51.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0381s/iter; left time: 90.1899s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0195s/iter; left time: 44.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0382s/iter; left time: 81.7295s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0202s/iter; left time: 41.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0377s/iter; left time: 72.3255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0202s/iter; left time: 36.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0410s/iter; left time: 69.4850s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0208s/iter; left time: 33.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0330s/iter; left time: 48.5477s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0171s/iter; left time: 23.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0413s/iter; left time: 51.4679s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0200s/iter; left time: 22.8844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0417s/iter; left time: 42.5280s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0242s/iter; left time: 22.2751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0385s/iter; left time: 30.6890s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0173s/iter; left time: 12.0500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0404s/iter; left time: 23.1778s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0219s/iter; left time: 10.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0373s/iter; left time: 13.0044s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0222s/iter; left time: 5.5359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0378s/iter; left time: 4.7191s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0176s/iter; left time: 0.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02119249477982521, rmse:0.14557641744613647, mae:0.08472280204296112, rse:0.4284138083457947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2933527\n",
      "\tspeed: 0.0201s/iter; left time: 88.0106s\n",
      "\titers: 200, epoch: 1 | loss: 0.2704865\n",
      "\tspeed: 0.0176s/iter; left time: 75.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.2947414 Vali Loss: 0.2184829 Test Loss: 0.2361712\n",
      "Validation loss decreased (inf --> 0.218483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535339\n",
      "\tspeed: 0.0396s/iter; left time: 164.6121s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133334\n",
      "\tspeed: 0.0183s/iter; left time: 74.2201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1637773 Vali Loss: 0.0885669 Test Loss: 0.0970050\n",
      "Validation loss decreased (0.218483 --> 0.088567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1018822\n",
      "\tspeed: 0.0377s/iter; left time: 148.4018s\n",
      "\titers: 200, epoch: 3 | loss: 0.0948918\n",
      "\tspeed: 0.0189s/iter; left time: 72.6322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1007216 Vali Loss: 0.0790505 Test Loss: 0.0879022\n",
      "Validation loss decreased (0.088567 --> 0.079051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878256\n",
      "\tspeed: 0.0400s/iter; left time: 148.1847s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835657\n",
      "\tspeed: 0.0182s/iter; left time: 65.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0883169 Vali Loss: 0.0730279 Test Loss: 0.0804366\n",
      "Validation loss decreased (0.079051 --> 0.073028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824891\n",
      "\tspeed: 0.0409s/iter; left time: 142.6297s\n",
      "\titers: 200, epoch: 5 | loss: 0.0751157\n",
      "\tspeed: 0.0219s/iter; left time: 74.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0807013 Vali Loss: 0.0705443 Test Loss: 0.0847321\n",
      "Validation loss decreased (0.073028 --> 0.070544).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0724511\n",
      "\tspeed: 0.0346s/iter; left time: 112.9735s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762253\n",
      "\tspeed: 0.0181s/iter; left time: 57.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0764399 Vali Loss: 0.0675259 Test Loss: 0.0945590\n",
      "Validation loss decreased (0.070544 --> 0.067526).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760236\n",
      "\tspeed: 0.0389s/iter; left time: 118.1804s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679494\n",
      "\tspeed: 0.0166s/iter; left time: 48.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0736369 Vali Loss: 0.0678774 Test Loss: 0.0992442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708459\n",
      "\tspeed: 0.0360s/iter; left time: 101.3354s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680928\n",
      "\tspeed: 0.0169s/iter; left time: 45.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0709821 Vali Loss: 0.0655568 Test Loss: 0.0969620\n",
      "Validation loss decreased (0.067526 --> 0.065557).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0714074\n",
      "\tspeed: 0.0317s/iter; left time: 82.1935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749444\n",
      "\tspeed: 0.0191s/iter; left time: 47.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0694430 Vali Loss: 0.0641238 Test Loss: 0.0946040\n",
      "Validation loss decreased (0.065557 --> 0.064124).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666802\n",
      "\tspeed: 0.0361s/iter; left time: 85.4878s\n",
      "\titers: 200, epoch: 10 | loss: 0.0671037\n",
      "\tspeed: 0.0209s/iter; left time: 47.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0686812 Vali Loss: 0.0635217 Test Loss: 0.0920826\n",
      "Validation loss decreased (0.064124 --> 0.063522).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657643\n",
      "\tspeed: 0.0382s/iter; left time: 81.7464s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640680\n",
      "\tspeed: 0.0183s/iter; left time: 37.3703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0677449 Vali Loss: 0.0631191 Test Loss: 0.0914283\n",
      "Validation loss decreased (0.063522 --> 0.063119).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628503\n",
      "\tspeed: 0.0347s/iter; left time: 66.5373s\n",
      "\titers: 200, epoch: 12 | loss: 0.0651587\n",
      "\tspeed: 0.0195s/iter; left time: 35.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0672804 Vali Loss: 0.0626110 Test Loss: 0.0832856\n",
      "Validation loss decreased (0.063119 --> 0.062611).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0623292\n",
      "\tspeed: 0.0368s/iter; left time: 62.3830s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658564\n",
      "\tspeed: 0.0175s/iter; left time: 27.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0664633 Vali Loss: 0.0621283 Test Loss: 0.0837443\n",
      "Validation loss decreased (0.062611 --> 0.062128).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687133\n",
      "\tspeed: 0.0369s/iter; left time: 54.2308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648790\n",
      "\tspeed: 0.0194s/iter; left time: 26.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0656932 Vali Loss: 0.0620166 Test Loss: 0.0845872\n",
      "Validation loss decreased (0.062128 --> 0.062017).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649449\n",
      "\tspeed: 0.0321s/iter; left time: 40.0241s\n",
      "\titers: 200, epoch: 15 | loss: 0.0653902\n",
      "\tspeed: 0.0100s/iter; left time: 11.4417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0656366 Vali Loss: 0.0617880 Test Loss: 0.0808425\n",
      "Validation loss decreased (0.062017 --> 0.061788).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618114\n",
      "\tspeed: 0.0325s/iter; left time: 33.1834s\n",
      "\titers: 200, epoch: 16 | loss: 0.0655272\n",
      "\tspeed: 0.0110s/iter; left time: 10.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0655247 Vali Loss: 0.0616549 Test Loss: 0.0858418\n",
      "Validation loss decreased (0.061788 --> 0.061655).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0677098\n",
      "\tspeed: 0.0362s/iter; left time: 28.8845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637103\n",
      "\tspeed: 0.0185s/iter; left time: 12.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0648700 Vali Loss: 0.0612696 Test Loss: 0.0789498\n",
      "Validation loss decreased (0.061655 --> 0.061270).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0684756\n",
      "\tspeed: 0.0392s/iter; left time: 22.4876s\n",
      "\titers: 200, epoch: 18 | loss: 0.0658208\n",
      "\tspeed: 0.0200s/iter; left time: 9.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0648673 Vali Loss: 0.0613987 Test Loss: 0.0799385\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0637714\n",
      "\tspeed: 0.0380s/iter; left time: 13.2577s\n",
      "\titers: 200, epoch: 19 | loss: 0.0642970\n",
      "\tspeed: 0.0197s/iter; left time: 4.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0642515 Vali Loss: 0.0606022 Test Loss: 0.0827977\n",
      "Validation loss decreased (0.061270 --> 0.060602).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0594665\n",
      "\tspeed: 0.0383s/iter; left time: 4.7878s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622201\n",
      "\tspeed: 0.0175s/iter; left time: 0.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0640075 Vali Loss: 0.0609228 Test Loss: 0.0824307\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019271206110715866, rmse:0.13882076740264893, mae:0.08279767632484436, rse:0.4085327386856079\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:55.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0426s/iter; left time: 186.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0117s/iter; left time: 50.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0315s/iter; left time: 130.9415s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0158s/iter; left time: 64.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0331s/iter; left time: 130.1391s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0164s/iter; left time: 62.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0348s/iter; left time: 129.2279s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0208s/iter; left time: 74.8950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0345s/iter; left time: 120.2348s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0161s/iter; left time: 54.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0322s/iter; left time: 105.0155s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0175s/iter; left time: 55.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0369s/iter; left time: 111.9894s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0225s/iter; left time: 66.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0382s/iter; left time: 107.5352s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0186s/iter; left time: 50.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0350s/iter; left time: 90.5386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0181s/iter; left time: 45.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0348s/iter; left time: 82.3695s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0163s/iter; left time: 36.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0336s/iter; left time: 71.8577s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0162s/iter; left time: 33.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0340s/iter; left time: 65.2305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0198s/iter; left time: 35.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0386s/iter; left time: 65.3967s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0205s/iter; left time: 32.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0369s/iter; left time: 54.2181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0193s/iter; left time: 26.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0376s/iter; left time: 46.8436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0196s/iter; left time: 22.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0416s/iter; left time: 42.4258s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0266s/iter; left time: 24.5067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0390s/iter; left time: 31.0719s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0220s/iter; left time: 15.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0357s/iter; left time: 20.4440s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0187s/iter; left time: 8.8381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0387s/iter; left time: 13.4946s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0196s/iter; left time: 4.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0372s/iter; left time: 4.6512s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0196s/iter; left time: 0.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.025789545848965645, rmse:0.1605912446975708, mae:0.10785099118947983, rse:0.47176873683929443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2952403\n",
      "\tspeed: 0.0204s/iter; left time: 89.3438s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667057\n",
      "\tspeed: 0.0197s/iter; left time: 84.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.2909098 Vali Loss: 0.2230923 Test Loss: 0.2409381\n",
      "Validation loss decreased (inf --> 0.223092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1491593\n",
      "\tspeed: 0.0407s/iter; left time: 169.1740s\n",
      "\titers: 200, epoch: 2 | loss: 0.1210495\n",
      "\tspeed: 0.0182s/iter; left time: 73.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1614247 Vali Loss: 0.1116909 Test Loss: 0.1254427\n",
      "Validation loss decreased (0.223092 --> 0.111691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085087\n",
      "\tspeed: 0.0364s/iter; left time: 143.0639s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104036\n",
      "\tspeed: 0.0211s/iter; left time: 80.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1113403 Vali Loss: 0.0953680 Test Loss: 0.1103432\n",
      "Validation loss decreased (0.111691 --> 0.095368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050000\n",
      "\tspeed: 0.0433s/iter; left time: 160.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.0989005\n",
      "\tspeed: 0.0230s/iter; left time: 82.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0994751 Vali Loss: 0.0900774 Test Loss: 0.1305989\n",
      "Validation loss decreased (0.095368 --> 0.090077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0924402\n",
      "\tspeed: 0.0336s/iter; left time: 117.1968s\n",
      "\titers: 200, epoch: 5 | loss: 0.0925185\n",
      "\tspeed: 0.0116s/iter; left time: 39.2989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 224 | Train Loss: 0.0936407 Vali Loss: 0.0879273 Test Loss: 0.1221537\n",
      "Validation loss decreased (0.090077 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856230\n",
      "\tspeed: 0.0355s/iter; left time: 115.6163s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879899\n",
      "\tspeed: 0.0186s/iter; left time: 58.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0899839 Vali Loss: 0.0851904 Test Loss: 0.1239189\n",
      "Validation loss decreased (0.087927 --> 0.085190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0908499\n",
      "\tspeed: 0.0381s/iter; left time: 115.6458s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900486\n",
      "\tspeed: 0.0194s/iter; left time: 57.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0885243 Vali Loss: 0.0836331 Test Loss: 0.1237736\n",
      "Validation loss decreased (0.085190 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901688\n",
      "\tspeed: 0.0370s/iter; left time: 103.9528s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838144\n",
      "\tspeed: 0.0184s/iter; left time: 49.8065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0868885 Vali Loss: 0.0829176 Test Loss: 0.1260237\n",
      "Validation loss decreased (0.083633 --> 0.082918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0871684\n",
      "\tspeed: 0.0417s/iter; left time: 107.8785s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863542\n",
      "\tspeed: 0.0234s/iter; left time: 58.2422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0857102 Vali Loss: 0.0822429 Test Loss: 0.1236874\n",
      "Validation loss decreased (0.082918 --> 0.082243).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849192\n",
      "\tspeed: 0.0439s/iter; left time: 103.7367s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846752\n",
      "\tspeed: 0.0235s/iter; left time: 53.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0818745 Test Loss: 0.1264992\n",
      "Validation loss decreased (0.082243 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810420\n",
      "\tspeed: 0.0397s/iter; left time: 85.0791s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817054\n",
      "\tspeed: 0.0217s/iter; left time: 44.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0842583 Vali Loss: 0.0812377 Test Loss: 0.1211978\n",
      "Validation loss decreased (0.081875 --> 0.081238).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0824383\n",
      "\tspeed: 0.0375s/iter; left time: 71.8570s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815587\n",
      "\tspeed: 0.0201s/iter; left time: 36.5041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0837523 Vali Loss: 0.0809542 Test Loss: 0.1222994\n",
      "Validation loss decreased (0.081238 --> 0.080954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0834732\n",
      "\tspeed: 0.0414s/iter; left time: 70.1688s\n",
      "\titers: 200, epoch: 13 | loss: 0.0828774\n",
      "\tspeed: 0.0206s/iter; left time: 32.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0834866 Vali Loss: 0.0810962 Test Loss: 0.1206864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810478\n",
      "\tspeed: 0.0336s/iter; left time: 49.2893s\n",
      "\titers: 200, epoch: 14 | loss: 0.0787730\n",
      "\tspeed: 0.0174s/iter; left time: 23.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0830654 Vali Loss: 0.0801408 Test Loss: 0.1198389\n",
      "Validation loss decreased (0.080954 --> 0.080141).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855980\n",
      "\tspeed: 0.0409s/iter; left time: 50.9005s\n",
      "\titers: 200, epoch: 15 | loss: 0.0813123\n",
      "\tspeed: 0.0192s/iter; left time: 21.9322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0829200 Vali Loss: 0.0803521 Test Loss: 0.1200523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831396\n",
      "\tspeed: 0.0366s/iter; left time: 37.3302s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829206\n",
      "\tspeed: 0.0177s/iter; left time: 16.3138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0823068 Vali Loss: 0.0803707 Test Loss: 0.1218092\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848512\n",
      "\tspeed: 0.0322s/iter; left time: 25.6703s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793137\n",
      "\tspeed: 0.0165s/iter; left time: 11.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0826998 Vali Loss: 0.0802649 Test Loss: 0.1115729\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797599\n",
      "\tspeed: 0.0372s/iter; left time: 21.3441s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824331\n",
      "\tspeed: 0.0194s/iter; left time: 9.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0821136 Vali Loss: 0.0795419 Test Loss: 0.1209204\n",
      "Validation loss decreased (0.080141 --> 0.079542).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788217\n",
      "\tspeed: 0.0364s/iter; left time: 12.6997s\n",
      "\titers: 200, epoch: 19 | loss: 0.0827929\n",
      "\tspeed: 0.0149s/iter; left time: 3.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0817846 Vali Loss: 0.0792163 Test Loss: 0.1182506\n",
      "Validation loss decreased (0.079542 --> 0.079216).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808366\n",
      "\tspeed: 0.0380s/iter; left time: 4.7487s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783563\n",
      "\tspeed: 0.0194s/iter; left time: 0.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0815249 Vali Loss: 0.0790933 Test Loss: 0.1166001\n",
      "Validation loss decreased (0.079216 --> 0.079093).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03416641056537628, rmse:0.184841588139534, mae:0.11660011857748032, rse:0.5430089235305786\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:54.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0410s/iter; left time: 178.9117s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0157s/iter; left time: 66.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0382s/iter; left time: 157.9376s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0184s/iter; left time: 74.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0340s/iter; left time: 132.9604s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0170s/iter; left time: 64.6968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0373s/iter; left time: 137.8699s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0160s/iter; left time: 57.6371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0350s/iter; left time: 121.4370s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0174s/iter; left time: 58.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0394s/iter; left time: 127.9286s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0207s/iter; left time: 64.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0440s/iter; left time: 133.1568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0246s/iter; left time: 71.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0403s/iter; left time: 112.9537s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0211s/iter; left time: 56.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0372s/iter; left time: 95.9795s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0178s/iter; left time: 44.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0357s/iter; left time: 84.0492s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0183s/iter; left time: 41.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0377s/iter; left time: 80.2770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0197s/iter; left time: 40.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0391s/iter; left time: 74.6690s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0171s/iter; left time: 30.8653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0366s/iter; left time: 61.7134s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0179s/iter; left time: 28.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0299s/iter; left time: 43.7162s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0104s/iter; left time: 14.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.67s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0354s/iter; left time: 43.8635s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0210s/iter; left time: 23.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0378s/iter; left time: 38.3619s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0167s/iter; left time: 15.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0360s/iter; left time: 28.5868s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0176s/iter; left time: 12.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0357s/iter; left time: 20.3579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0172s/iter; left time: 8.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0348s/iter; left time: 12.0901s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0175s/iter; left time: 4.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0364s/iter; left time: 4.5111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0176s/iter; left time: 0.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030968520790338516, rmse:0.17597874999046326, mae:0.11744298785924911, rse:0.5170097351074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2899029\n",
      "\tspeed: 0.0249s/iter; left time: 108.7958s\n",
      "\titers: 200, epoch: 1 | loss: 0.2712442\n",
      "\tspeed: 0.0174s/iter; left time: 74.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.2944018 Vali Loss: 0.2256723 Test Loss: 0.2452994\n",
      "Validation loss decreased (inf --> 0.225672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1439804\n",
      "\tspeed: 0.0413s/iter; left time: 170.9676s\n",
      "\titers: 200, epoch: 2 | loss: 0.1288482\n",
      "\tspeed: 0.0222s/iter; left time: 89.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1609331 Vali Loss: 0.1103104 Test Loss: 0.1237899\n",
      "Validation loss decreased (0.225672 --> 0.110310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161442\n",
      "\tspeed: 0.0414s/iter; left time: 161.9318s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086942\n",
      "\tspeed: 0.0186s/iter; left time: 71.1461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.1137597 Vali Loss: 0.0991577 Test Loss: 0.1132361\n",
      "Validation loss decreased (0.110310 --> 0.099158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016965\n",
      "\tspeed: 0.0401s/iter; left time: 147.8937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984646\n",
      "\tspeed: 0.0165s/iter; left time: 59.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.1016837 Vali Loss: 0.0949189 Test Loss: 0.1138231\n",
      "Validation loss decreased (0.099158 --> 0.094919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0982926\n",
      "\tspeed: 0.0378s/iter; left time: 130.9636s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952768\n",
      "\tspeed: 0.0166s/iter; left time: 55.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0965111 Vali Loss: 0.0906598 Test Loss: 0.1149046\n",
      "Validation loss decreased (0.094919 --> 0.090660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932750\n",
      "\tspeed: 0.0366s/iter; left time: 118.7121s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899443\n",
      "\tspeed: 0.0177s/iter; left time: 55.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0935987 Vali Loss: 0.0898600 Test Loss: 0.1154023\n",
      "Validation loss decreased (0.090660 --> 0.089860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968993\n",
      "\tspeed: 0.0359s/iter; left time: 108.4098s\n",
      "\titers: 200, epoch: 7 | loss: 0.0916797\n",
      "\tspeed: 0.0165s/iter; left time: 48.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0919076 Vali Loss: 0.0879064 Test Loss: 0.1174295\n",
      "Validation loss decreased (0.089860 --> 0.087906).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0910260\n",
      "\tspeed: 0.0415s/iter; left time: 116.2290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891242\n",
      "\tspeed: 0.0208s/iter; left time: 56.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0904661 Vali Loss: 0.0868890 Test Loss: 0.1170246\n",
      "Validation loss decreased (0.087906 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919234\n",
      "\tspeed: 0.0399s/iter; left time: 102.8704s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911078\n",
      "\tspeed: 0.0175s/iter; left time: 43.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0899424 Vali Loss: 0.0871161 Test Loss: 0.1129427\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0876352\n",
      "\tspeed: 0.0397s/iter; left time: 93.3437s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899070\n",
      "\tspeed: 0.0201s/iter; left time: 45.3156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0887751 Vali Loss: 0.0863786 Test Loss: 0.1157439\n",
      "Validation loss decreased (0.086889 --> 0.086379).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0875310\n",
      "\tspeed: 0.0397s/iter; left time: 84.6886s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865170\n",
      "\tspeed: 0.0171s/iter; left time: 34.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0889828 Vali Loss: 0.0859895 Test Loss: 0.1167143\n",
      "Validation loss decreased (0.086379 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0884266\n",
      "\tspeed: 0.0365s/iter; left time: 69.5674s\n",
      "\titers: 200, epoch: 12 | loss: 0.0868132\n",
      "\tspeed: 0.0179s/iter; left time: 32.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0875570 Vali Loss: 0.0859610 Test Loss: 0.1155201\n",
      "Validation loss decreased (0.085990 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886559\n",
      "\tspeed: 0.0377s/iter; left time: 63.4989s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892455\n",
      "\tspeed: 0.0181s/iter; left time: 28.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0871522 Vali Loss: 0.0859056 Test Loss: 0.1138303\n",
      "Validation loss decreased (0.085961 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848424\n",
      "\tspeed: 0.0408s/iter; left time: 59.6106s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878144\n",
      "\tspeed: 0.0227s/iter; left time: 30.9062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0867811 Vali Loss: 0.0854875 Test Loss: 0.1154874\n",
      "Validation loss decreased (0.085906 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901568\n",
      "\tspeed: 0.0367s/iter; left time: 45.4521s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834248\n",
      "\tspeed: 0.0103s/iter; left time: 11.7835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0863447 Vali Loss: 0.0854952 Test Loss: 0.1136132\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865058\n",
      "\tspeed: 0.0353s/iter; left time: 35.8833s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858239\n",
      "\tspeed: 0.0176s/iter; left time: 16.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0863616 Vali Loss: 0.0848712 Test Loss: 0.1134736\n",
      "Validation loss decreased (0.085487 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821277\n",
      "\tspeed: 0.0383s/iter; left time: 30.4074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0873138\n",
      "\tspeed: 0.0192s/iter; left time: 13.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0860255 Vali Loss: 0.0847610 Test Loss: 0.1142043\n",
      "Validation loss decreased (0.084871 --> 0.084761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0891386\n",
      "\tspeed: 0.0416s/iter; left time: 23.7205s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899599\n",
      "\tspeed: 0.0191s/iter; left time: 8.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0863818 Vali Loss: 0.0850193 Test Loss: 0.1143596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0856005\n",
      "\tspeed: 0.0369s/iter; left time: 12.7890s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866439\n",
      "\tspeed: 0.0116s/iter; left time: 2.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 223 | Train Loss: 0.0857154 Vali Loss: 0.0848255 Test Loss: 0.1150333\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0883029\n",
      "\tspeed: 0.0343s/iter; left time: 4.2569s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826626\n",
      "\tspeed: 0.0173s/iter; left time: 0.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0856279 Vali Loss: 0.0850217 Test Loss: 0.1158830\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.027704495936632156, rmse:0.16644667088985443, mae:0.1142042800784111, rse:0.4890053868293762\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:54.05s\n",
      "Intermediate time for ES: 00h:11m:44.16s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0389s/iter; left time: 170.4436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0116s/iter; left time: 49.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0287s/iter; left time: 119.3798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0168s/iter; left time: 68.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0348s/iter; left time: 136.7070s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0099s/iter; left time: 37.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0347s/iter; left time: 128.8116s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0210s/iter; left time: 75.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0352s/iter; left time: 122.5149s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0188s/iter; left time: 63.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0386s/iter; left time: 125.9538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0218s/iter; left time: 68.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0378s/iter; left time: 114.8126s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0250s/iter; left time: 73.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0399s/iter; left time: 112.1210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0186s/iter; left time: 50.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0373s/iter; left time: 96.5012s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0200s/iter; left time: 49.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0376s/iter; left time: 88.9604s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0183s/iter; left time: 41.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0363s/iter; left time: 77.7717s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0195s/iter; left time: 39.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0355s/iter; left time: 68.0528s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0184s/iter; left time: 33.4564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0365s/iter; left time: 61.8709s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0194s/iter; left time: 30.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0365s/iter; left time: 53.6102s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0181s/iter; left time: 24.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0357s/iter; left time: 44.3906s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0185s/iter; left time: 21.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0351s/iter; left time: 35.7986s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0193s/iter; left time: 17.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0383s/iter; left time: 30.5273s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0206s/iter; left time: 14.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0397s/iter; left time: 22.7324s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0221s/iter; left time: 10.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0343s/iter; left time: 11.9555s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0174s/iter; left time: 4.3348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0324s/iter; left time: 4.0507s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0098s/iter; left time: 0.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011178242973983288, rmse:0.10572721064090729, mae:0.061787281185388565, rse:0.407892644405365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2411680\n",
      "\tspeed: 0.0231s/iter; left time: 101.0096s\n",
      "\titers: 200, epoch: 1 | loss: 0.2160659\n",
      "\tspeed: 0.0208s/iter; left time: 89.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.2408922 Vali Loss: 0.1782567 Test Loss: 0.1854041\n",
      "Validation loss decreased (inf --> 0.178257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1385794\n",
      "\tspeed: 0.0388s/iter; left time: 161.4071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1014387\n",
      "\tspeed: 0.0189s/iter; left time: 76.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.1401546 Vali Loss: 0.0844240 Test Loss: 0.0928136\n",
      "Validation loss decreased (0.178257 --> 0.084424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963864\n",
      "\tspeed: 0.0276s/iter; left time: 108.7015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779932\n",
      "\tspeed: 0.0098s/iter; left time: 37.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0851412 Vali Loss: 0.0759695 Test Loss: 0.0796487\n",
      "Validation loss decreased (0.084424 --> 0.075970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728357\n",
      "\tspeed: 0.0318s/iter; left time: 117.8008s\n",
      "\titers: 200, epoch: 4 | loss: 0.0701583\n",
      "\tspeed: 0.0099s/iter; left time: 35.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0739212 Vali Loss: 0.0693061 Test Loss: 0.0711936\n",
      "Validation loss decreased (0.075970 --> 0.069306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649703\n",
      "\tspeed: 0.0315s/iter; left time: 109.8802s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600224\n",
      "\tspeed: 0.0172s/iter; left time: 58.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0674395 Vali Loss: 0.0658167 Test Loss: 0.0676115\n",
      "Validation loss decreased (0.069306 --> 0.065817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614809\n",
      "\tspeed: 0.0391s/iter; left time: 127.4692s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617771\n",
      "\tspeed: 0.0201s/iter; left time: 63.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0634119 Vali Loss: 0.0674359 Test Loss: 0.0694659\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605860\n",
      "\tspeed: 0.0372s/iter; left time: 112.8544s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626515\n",
      "\tspeed: 0.0190s/iter; left time: 55.8961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0611253 Vali Loss: 0.0648416 Test Loss: 0.0675831\n",
      "Validation loss decreased (0.065817 --> 0.064842).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599528\n",
      "\tspeed: 0.0367s/iter; left time: 103.1266s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610243\n",
      "\tspeed: 0.0187s/iter; left time: 50.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0588911 Vali Loss: 0.0627734 Test Loss: 0.0656899\n",
      "Validation loss decreased (0.064842 --> 0.062773).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547889\n",
      "\tspeed: 0.0377s/iter; left time: 97.7277s\n",
      "\titers: 200, epoch: 9 | loss: 0.0561625\n",
      "\tspeed: 0.0176s/iter; left time: 43.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0571481 Vali Loss: 0.0612765 Test Loss: 0.0641911\n",
      "Validation loss decreased (0.062773 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564083\n",
      "\tspeed: 0.0388s/iter; left time: 91.7436s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529456\n",
      "\tspeed: 0.0190s/iter; left time: 42.9244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560195 Vali Loss: 0.0609586 Test Loss: 0.0637936\n",
      "Validation loss decreased (0.061277 --> 0.060959).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541631\n",
      "\tspeed: 0.0376s/iter; left time: 80.5173s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595317\n",
      "\tspeed: 0.0177s/iter; left time: 36.2117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0548145 Vali Loss: 0.0604594 Test Loss: 0.0633140\n",
      "Validation loss decreased (0.060959 --> 0.060459).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0551679\n",
      "\tspeed: 0.0384s/iter; left time: 73.6917s\n",
      "\titers: 200, epoch: 12 | loss: 0.0506632\n",
      "\tspeed: 0.0218s/iter; left time: 39.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0540808 Vali Loss: 0.0599905 Test Loss: 0.0628521\n",
      "Validation loss decreased (0.060459 --> 0.059990).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570984\n",
      "\tspeed: 0.0382s/iter; left time: 64.7350s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494264\n",
      "\tspeed: 0.0205s/iter; left time: 32.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0539780 Vali Loss: 0.0598418 Test Loss: 0.0626836\n",
      "Validation loss decreased (0.059990 --> 0.059842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523727\n",
      "\tspeed: 0.0366s/iter; left time: 53.7406s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538516\n",
      "\tspeed: 0.0218s/iter; left time: 29.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0532672 Vali Loss: 0.0598634 Test Loss: 0.0626787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0509895\n",
      "\tspeed: 0.0371s/iter; left time: 46.1446s\n",
      "\titers: 200, epoch: 15 | loss: 0.0479047\n",
      "\tspeed: 0.0197s/iter; left time: 22.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0528779 Vali Loss: 0.0594473 Test Loss: 0.0624075\n",
      "Validation loss decreased (0.059842 --> 0.059447).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509207\n",
      "\tspeed: 0.0341s/iter; left time: 34.7843s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511976\n",
      "\tspeed: 0.0166s/iter; left time: 15.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0526040 Vali Loss: 0.0597805 Test Loss: 0.0625402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0506773\n",
      "\tspeed: 0.0397s/iter; left time: 31.6155s\n",
      "\titers: 200, epoch: 17 | loss: 0.0510104\n",
      "\tspeed: 0.0220s/iter; left time: 15.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0523335 Vali Loss: 0.0592356 Test Loss: 0.0620888\n",
      "Validation loss decreased (0.059447 --> 0.059236).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547306\n",
      "\tspeed: 0.0402s/iter; left time: 23.0326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0486531\n",
      "\tspeed: 0.0195s/iter; left time: 9.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0520337 Vali Loss: 0.0590360 Test Loss: 0.0619049\n",
      "Validation loss decreased (0.059236 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0527190\n",
      "\tspeed: 0.0379s/iter; left time: 13.2286s\n",
      "\titers: 200, epoch: 19 | loss: 0.0546635\n",
      "\tspeed: 0.0202s/iter; left time: 5.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0518412 Vali Loss: 0.0589188 Test Loss: 0.0616275\n",
      "Validation loss decreased (0.059036 --> 0.058919).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517122\n",
      "\tspeed: 0.0396s/iter; left time: 4.9538s\n",
      "\titers: 200, epoch: 20 | loss: 0.0467894\n",
      "\tspeed: 0.0208s/iter; left time: 0.5201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0516144 Vali Loss: 0.0589262 Test Loss: 0.0616789\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011188277043402195, rmse:0.1057746484875679, mae:0.061627473682165146, rse:0.4080756902694702\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:49.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0410s/iter; left time: 179.6207s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0122s/iter; left time: 52.3355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0349s/iter; left time: 145.2442s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0204s/iter; left time: 82.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0371s/iter; left time: 146.0923s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0178s/iter; left time: 68.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0358s/iter; left time: 132.7641s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0199s/iter; left time: 71.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0352s/iter; left time: 122.6290s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0161s/iter; left time: 54.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0349s/iter; left time: 113.8091s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0185s/iter; left time: 58.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0346s/iter; left time: 105.0947s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0180s/iter; left time: 52.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0350s/iter; left time: 98.4671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0164s/iter; left time: 44.3949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0405s/iter; left time: 104.7296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0176s/iter; left time: 43.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0345s/iter; left time: 81.6614s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0174s/iter; left time: 39.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0329s/iter; left time: 70.3369s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0102s/iter; left time: 20.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0332s/iter; left time: 63.6045s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0193s/iter; left time: 35.0804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0351s/iter; left time: 59.4527s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0169s/iter; left time: 26.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0378s/iter; left time: 55.4564s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0201s/iter; left time: 27.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0410s/iter; left time: 51.0554s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0195s/iter; left time: 22.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0353s/iter; left time: 36.0684s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0235s/iter; left time: 21.6031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0399s/iter; left time: 31.7845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0204s/iter; left time: 14.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0360s/iter; left time: 20.6153s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0179s/iter; left time: 8.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0430s/iter; left time: 15.0056s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0199s/iter; left time: 4.9488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0373s/iter; left time: 4.6565s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0203s/iter; left time: 0.5073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020759424194693565, rmse:0.14408130943775177, mae:0.08491359651088715, rse:0.5573447942733765\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2406403\n",
      "\tspeed: 0.0261s/iter; left time: 114.3824s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188262\n",
      "\tspeed: 0.0192s/iter; left time: 82.0616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.2381317 Vali Loss: 0.1789258 Test Loss: 0.1865743\n",
      "Validation loss decreased (inf --> 0.178926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1343914\n",
      "\tspeed: 0.0354s/iter; left time: 147.0162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930818\n",
      "\tspeed: 0.0172s/iter; left time: 69.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1332448 Vali Loss: 0.0972317 Test Loss: 0.1086327\n",
      "Validation loss decreased (0.178926 --> 0.097232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907119\n",
      "\tspeed: 0.0404s/iter; left time: 158.7603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0898331\n",
      "\tspeed: 0.0206s/iter; left time: 78.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0904112 Vali Loss: 0.0884094 Test Loss: 0.0957489\n",
      "Validation loss decreased (0.097232 --> 0.088409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0800296\n",
      "\tspeed: 0.0357s/iter; left time: 132.4830s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827712\n",
      "\tspeed: 0.0174s/iter; left time: 62.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0818481 Vali Loss: 0.0822035 Test Loss: 0.0922612\n",
      "Validation loss decreased (0.088409 --> 0.082203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791426\n",
      "\tspeed: 0.0391s/iter; left time: 136.2516s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790642\n",
      "\tspeed: 0.0194s/iter; left time: 65.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0770117 Vali Loss: 0.0795626 Test Loss: 0.0895083\n",
      "Validation loss decreased (0.082203 --> 0.079563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730632\n",
      "\tspeed: 0.0389s/iter; left time: 126.9005s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708637\n",
      "\tspeed: 0.0182s/iter; left time: 57.5080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0741224 Vali Loss: 0.0787785 Test Loss: 0.0881438\n",
      "Validation loss decreased (0.079563 --> 0.078779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0686050\n",
      "\tspeed: 0.0353s/iter; left time: 107.2848s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743980\n",
      "\tspeed: 0.0183s/iter; left time: 53.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0715071 Vali Loss: 0.0792559 Test Loss: 0.0889636\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750379\n",
      "\tspeed: 0.0407s/iter; left time: 114.6261s\n",
      "\titers: 200, epoch: 8 | loss: 0.0685743\n",
      "\tspeed: 0.0217s/iter; left time: 59.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0700779 Vali Loss: 0.0787402 Test Loss: 0.0882414\n",
      "Validation loss decreased (0.078779 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686822\n",
      "\tspeed: 0.0406s/iter; left time: 105.1337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684529\n",
      "\tspeed: 0.0179s/iter; left time: 44.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0689258 Vali Loss: 0.0775224 Test Loss: 0.0869969\n",
      "Validation loss decreased (0.078740 --> 0.077522).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689297\n",
      "\tspeed: 0.0359s/iter; left time: 84.9816s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664442\n",
      "\tspeed: 0.0185s/iter; left time: 41.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0681905 Vali Loss: 0.0769314 Test Loss: 0.0865170\n",
      "Validation loss decreased (0.077522 --> 0.076931).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694460\n",
      "\tspeed: 0.0399s/iter; left time: 85.4460s\n",
      "\titers: 200, epoch: 11 | loss: 0.0733899\n",
      "\tspeed: 0.0225s/iter; left time: 45.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0677455 Vali Loss: 0.0769557 Test Loss: 0.0862589\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652838\n",
      "\tspeed: 0.0410s/iter; left time: 78.6166s\n",
      "\titers: 200, epoch: 12 | loss: 0.0629617\n",
      "\tspeed: 0.0188s/iter; left time: 34.1104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0668834 Vali Loss: 0.0763795 Test Loss: 0.0861417\n",
      "Validation loss decreased (0.076931 --> 0.076379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643209\n",
      "\tspeed: 0.0386s/iter; left time: 65.3416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618452\n",
      "\tspeed: 0.0179s/iter; left time: 28.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0667896 Vali Loss: 0.0762287 Test Loss: 0.0860246\n",
      "Validation loss decreased (0.076379 --> 0.076229).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677970\n",
      "\tspeed: 0.0340s/iter; left time: 49.8776s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648690\n",
      "\tspeed: 0.0172s/iter; left time: 23.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0661625 Vali Loss: 0.0762512 Test Loss: 0.0858173\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696925\n",
      "\tspeed: 0.0385s/iter; left time: 47.9934s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697655\n",
      "\tspeed: 0.0189s/iter; left time: 21.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0660004 Vali Loss: 0.0760939 Test Loss: 0.0859716\n",
      "Validation loss decreased (0.076229 --> 0.076094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652443\n",
      "\tspeed: 0.0425s/iter; left time: 43.3530s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687751\n",
      "\tspeed: 0.0215s/iter; left time: 19.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0656887 Vali Loss: 0.0760748 Test Loss: 0.0856839\n",
      "Validation loss decreased (0.076094 --> 0.076075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659079\n",
      "\tspeed: 0.0403s/iter; left time: 32.1177s\n",
      "\titers: 200, epoch: 17 | loss: 0.0638563\n",
      "\tspeed: 0.0174s/iter; left time: 12.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0653609 Vali Loss: 0.0753801 Test Loss: 0.0850498\n",
      "Validation loss decreased (0.076075 --> 0.075380).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578677\n",
      "\tspeed: 0.0371s/iter; left time: 21.2815s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645344\n",
      "\tspeed: 0.0102s/iter; left time: 4.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 224 | Train Loss: 0.0651030 Vali Loss: 0.0752875 Test Loss: 0.0849164\n",
      "Validation loss decreased (0.075380 --> 0.075287).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679285\n",
      "\tspeed: 0.0343s/iter; left time: 11.9599s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629789\n",
      "\tspeed: 0.0221s/iter; left time: 5.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0649769 Vali Loss: 0.0752234 Test Loss: 0.0850461\n",
      "Validation loss decreased (0.075287 --> 0.075223).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0604777\n",
      "\tspeed: 0.0382s/iter; left time: 4.7696s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633929\n",
      "\tspeed: 0.0157s/iter; left time: 0.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0648052 Vali Loss: 0.0750941 Test Loss: 0.0847241\n",
      "Validation loss decreased (0.075223 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020768484100699425, rmse:0.1441127508878708, mae:0.08472401648759842, rse:0.557466447353363\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:54.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0424s/iter; left time: 185.1014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0161s/iter; left time: 68.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0345s/iter; left time: 142.9481s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0159s/iter; left time: 64.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0314s/iter; left time: 122.9024s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0215s/iter; left time: 81.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0343s/iter; left time: 126.7948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0168s/iter; left time: 60.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0333s/iter; left time: 115.5416s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0168s/iter; left time: 56.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0362s/iter; left time: 117.5717s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0195s/iter; left time: 61.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0405s/iter; left time: 122.3795s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0175s/iter; left time: 51.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0423s/iter; left time: 118.4797s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0248s/iter; left time: 66.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0415s/iter; left time: 106.9128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0199s/iter; left time: 49.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0385s/iter; left time: 90.7046s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0181s/iter; left time: 40.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0381s/iter; left time: 81.1390s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0189s/iter; left time: 38.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0376s/iter; left time: 71.7758s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0184s/iter; left time: 33.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0389s/iter; left time: 65.5683s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0189s/iter; left time: 29.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0390s/iter; left time: 56.9609s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0184s/iter; left time: 25.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0351s/iter; left time: 43.4834s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0173s/iter; left time: 19.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0391s/iter; left time: 39.7621s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0199s/iter; left time: 18.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0367s/iter; left time: 29.1359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0231s/iter; left time: 15.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0392s/iter; left time: 22.3489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0185s/iter; left time: 8.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0383s/iter; left time: 13.2733s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0223s/iter; left time: 5.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0398s/iter; left time: 4.9350s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0194s/iter; left time: 0.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023141568526625633, rmse:0.15212352573871613, mae:0.09033302962779999, rse:0.5891888737678528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2403809\n",
      "\tspeed: 0.0255s/iter; left time: 111.3851s\n",
      "\titers: 200, epoch: 1 | loss: 0.2154531\n",
      "\tspeed: 0.0215s/iter; left time: 91.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.2422614 Vali Loss: 0.1823216 Test Loss: 0.1888932\n",
      "Validation loss decreased (inf --> 0.182322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229391\n",
      "\tspeed: 0.0388s/iter; left time: 160.6539s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984408\n",
      "\tspeed: 0.0188s/iter; left time: 75.9883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1311886 Vali Loss: 0.1001970 Test Loss: 0.1099112\n",
      "Validation loss decreased (0.182322 --> 0.100197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898930\n",
      "\tspeed: 0.0407s/iter; left time: 159.3684s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917291\n",
      "\tspeed: 0.0199s/iter; left time: 75.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0914624 Vali Loss: 0.0890297 Test Loss: 0.0978792\n",
      "Validation loss decreased (0.100197 --> 0.089030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854143\n",
      "\tspeed: 0.0384s/iter; left time: 141.8712s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808555\n",
      "\tspeed: 0.0188s/iter; left time: 67.4431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0837825 Vali Loss: 0.0859060 Test Loss: 0.0959388\n",
      "Validation loss decreased (0.089030 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808391\n",
      "\tspeed: 0.0388s/iter; left time: 134.4523s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785895\n",
      "\tspeed: 0.0192s/iter; left time: 64.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0792879 Vali Loss: 0.0840676 Test Loss: 0.0946624\n",
      "Validation loss decreased (0.085906 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755854\n",
      "\tspeed: 0.0411s/iter; left time: 133.3556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746735\n",
      "\tspeed: 0.0205s/iter; left time: 64.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0765742 Vali Loss: 0.0853610 Test Loss: 0.0968855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792653\n",
      "\tspeed: 0.0427s/iter; left time: 129.0631s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721418\n",
      "\tspeed: 0.0195s/iter; left time: 56.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0743388 Vali Loss: 0.0818612 Test Loss: 0.0936658\n",
      "Validation loss decreased (0.084068 --> 0.081861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736356\n",
      "\tspeed: 0.0411s/iter; left time: 115.1988s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732522\n",
      "\tspeed: 0.0192s/iter; left time: 51.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0730863 Vali Loss: 0.0821424 Test Loss: 0.0942828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0689212\n",
      "\tspeed: 0.0362s/iter; left time: 93.2388s\n",
      "\titers: 200, epoch: 9 | loss: 0.0701418\n",
      "\tspeed: 0.0175s/iter; left time: 43.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0719471 Vali Loss: 0.0811452 Test Loss: 0.0941387\n",
      "Validation loss decreased (0.081861 --> 0.081145).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0695085\n",
      "\tspeed: 0.0408s/iter; left time: 96.1526s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699557\n",
      "\tspeed: 0.0206s/iter; left time: 46.4315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0711944 Vali Loss: 0.0805143 Test Loss: 0.0936558\n",
      "Validation loss decreased (0.081145 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0710805\n",
      "\tspeed: 0.0393s/iter; left time: 83.6774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656972\n",
      "\tspeed: 0.0176s/iter; left time: 35.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0703731 Vali Loss: 0.0806881 Test Loss: 0.0943752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712831\n",
      "\tspeed: 0.0375s/iter; left time: 71.5739s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711581\n",
      "\tspeed: 0.0193s/iter; left time: 34.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0701223 Vali Loss: 0.0796910 Test Loss: 0.0930109\n",
      "Validation loss decreased (0.080514 --> 0.079691).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698889\n",
      "\tspeed: 0.0392s/iter; left time: 66.1020s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705252\n",
      "\tspeed: 0.0203s/iter; left time: 32.2102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0696029 Vali Loss: 0.0801107 Test Loss: 0.0943232\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0708620\n",
      "\tspeed: 0.0395s/iter; left time: 57.6966s\n",
      "\titers: 200, epoch: 14 | loss: 0.0683931\n",
      "\tspeed: 0.0164s/iter; left time: 22.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0692059 Vali Loss: 0.0794433 Test Loss: 0.0930229\n",
      "Validation loss decreased (0.079691 --> 0.079443).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0689742\n",
      "\tspeed: 0.0378s/iter; left time: 46.8950s\n",
      "\titers: 200, epoch: 15 | loss: 0.0665230\n",
      "\tspeed: 0.0189s/iter; left time: 21.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0690320 Vali Loss: 0.0792129 Test Loss: 0.0928772\n",
      "Validation loss decreased (0.079443 --> 0.079213).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715083\n",
      "\tspeed: 0.0398s/iter; left time: 40.4851s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682462\n",
      "\tspeed: 0.0203s/iter; left time: 18.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0687173 Vali Loss: 0.0790982 Test Loss: 0.0926940\n",
      "Validation loss decreased (0.079213 --> 0.079098).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676954\n",
      "\tspeed: 0.0366s/iter; left time: 29.0513s\n",
      "\titers: 200, epoch: 17 | loss: 0.0672674\n",
      "\tspeed: 0.0183s/iter; left time: 12.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0685975 Vali Loss: 0.0791815 Test Loss: 0.0935558\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662949\n",
      "\tspeed: 0.0385s/iter; left time: 21.9437s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675989\n",
      "\tspeed: 0.0205s/iter; left time: 9.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0684725 Vali Loss: 0.0790181 Test Loss: 0.0932168\n",
      "Validation loss decreased (0.079098 --> 0.079018).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0674201\n",
      "\tspeed: 0.0386s/iter; left time: 13.3882s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678428\n",
      "\tspeed: 0.0189s/iter; left time: 4.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0681966 Vali Loss: 0.0788749 Test Loss: 0.0930523\n",
      "Validation loss decreased (0.079018 --> 0.078875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678935\n",
      "\tspeed: 0.0381s/iter; left time: 4.7190s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656016\n",
      "\tspeed: 0.0175s/iter; left time: 0.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0679420 Vali Loss: 0.0789774 Test Loss: 0.0931080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.025284940376877785, rmse:0.15901239216327667, mae:0.09305231273174286, rse:0.6158700585365295\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:01.99s\n",
      "Intermediate time for FR: 00h:11m:46.03s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0410s/iter; left time: 179.5759s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0158s/iter; left time: 67.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0326s/iter; left time: 135.5249s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0198s/iter; left time: 80.3800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0353s/iter; left time: 138.8371s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0163s/iter; left time: 62.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0325s/iter; left time: 120.5544s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0163s/iter; left time: 58.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0371s/iter; left time: 129.1770s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0208s/iter; left time: 70.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0356s/iter; left time: 115.9873s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0186s/iter; left time: 58.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0395s/iter; left time: 119.8119s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0181s/iter; left time: 53.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0387s/iter; left time: 108.7624s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0199s/iter; left time: 53.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0389s/iter; left time: 100.7789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0198s/iter; left time: 49.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0378s/iter; left time: 89.3845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0200s/iter; left time: 45.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0414s/iter; left time: 88.6775s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0178s/iter; left time: 36.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0416s/iter; left time: 79.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0169s/iter; left time: 30.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0325s/iter; left time: 55.0636s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0118s/iter; left time: 18.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0360s/iter; left time: 52.8824s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0180s/iter; left time: 24.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0363s/iter; left time: 45.1376s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0189s/iter; left time: 21.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0402s/iter; left time: 41.0432s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0190s/iter; left time: 17.4799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0282s/iter; left time: 22.4610s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0097s/iter; left time: 6.7633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0376s/iter; left time: 21.5597s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0223s/iter; left time: 10.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0361s/iter; left time: 12.6071s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0197s/iter; left time: 4.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0397s/iter; left time: 4.9655s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0209s/iter; left time: 0.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011143858544528484, rmse:0.10556447505950928, mae:0.06298493593931198, rse:0.3988761603832245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2797548\n",
      "\tspeed: 0.0217s/iter; left time: 94.8636s\n",
      "\titers: 200, epoch: 1 | loss: 0.2564775\n",
      "\tspeed: 0.0192s/iter; left time: 82.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.2824721 Vali Loss: 0.1925696 Test Loss: 0.1999343\n",
      "Validation loss decreased (inf --> 0.192570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1519092\n",
      "\tspeed: 0.0392s/iter; left time: 162.9826s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138760\n",
      "\tspeed: 0.0174s/iter; left time: 70.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.1577599 Vali Loss: 0.0885143 Test Loss: 0.0898196\n",
      "Validation loss decreased (0.192570 --> 0.088514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994059\n",
      "\tspeed: 0.0357s/iter; left time: 140.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920600\n",
      "\tspeed: 0.0163s/iter; left time: 62.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0987331 Vali Loss: 0.0793598 Test Loss: 0.0813890\n",
      "Validation loss decreased (0.088514 --> 0.079360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862465\n",
      "\tspeed: 0.0354s/iter; left time: 131.3037s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823747\n",
      "\tspeed: 0.0209s/iter; left time: 75.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0878294 Vali Loss: 0.0752087 Test Loss: 0.0770064\n",
      "Validation loss decreased (0.079360 --> 0.075209).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805695\n",
      "\tspeed: 0.0370s/iter; left time: 128.8703s\n",
      "\titers: 200, epoch: 5 | loss: 0.0835280\n",
      "\tspeed: 0.0182s/iter; left time: 61.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0810251 Vali Loss: 0.0726535 Test Loss: 0.0742234\n",
      "Validation loss decreased (0.075209 --> 0.072653).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783956\n",
      "\tspeed: 0.0405s/iter; left time: 132.0361s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783434\n",
      "\tspeed: 0.0222s/iter; left time: 70.0164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0766793 Vali Loss: 0.0699164 Test Loss: 0.0714286\n",
      "Validation loss decreased (0.072653 --> 0.069916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0737392\n",
      "\tspeed: 0.0360s/iter; left time: 109.4658s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715222\n",
      "\tspeed: 0.0183s/iter; left time: 53.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0738872 Vali Loss: 0.0673173 Test Loss: 0.0694845\n",
      "Validation loss decreased (0.069916 --> 0.067317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708480\n",
      "\tspeed: 0.0350s/iter; left time: 98.5778s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682935\n",
      "\tspeed: 0.0196s/iter; left time: 53.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0719646 Vali Loss: 0.0660387 Test Loss: 0.0682573\n",
      "Validation loss decreased (0.067317 --> 0.066039).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645496\n",
      "\tspeed: 0.0374s/iter; left time: 96.7208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698819\n",
      "\tspeed: 0.0182s/iter; left time: 45.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0701305 Vali Loss: 0.0643912 Test Loss: 0.0671896\n",
      "Validation loss decreased (0.066039 --> 0.064391).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676103\n",
      "\tspeed: 0.0360s/iter; left time: 85.0717s\n",
      "\titers: 200, epoch: 10 | loss: 0.0639220\n",
      "\tspeed: 0.0208s/iter; left time: 47.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0692499 Vali Loss: 0.0639208 Test Loss: 0.0666822\n",
      "Validation loss decreased (0.064391 --> 0.063921).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0649667\n",
      "\tspeed: 0.0421s/iter; left time: 90.1681s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642909\n",
      "\tspeed: 0.0219s/iter; left time: 44.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0680481 Vali Loss: 0.0636861 Test Loss: 0.0665629\n",
      "Validation loss decreased (0.063921 --> 0.063686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0633217\n",
      "\tspeed: 0.0375s/iter; left time: 71.9592s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601581\n",
      "\tspeed: 0.0171s/iter; left time: 31.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0671285 Vali Loss: 0.0625936 Test Loss: 0.0653706\n",
      "Validation loss decreased (0.063686 --> 0.062594).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0671477\n",
      "\tspeed: 0.0349s/iter; left time: 59.1071s\n",
      "\titers: 200, epoch: 13 | loss: 0.0621317\n",
      "\tspeed: 0.0194s/iter; left time: 30.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0662944 Vali Loss: 0.0626164 Test Loss: 0.0654073\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650934\n",
      "\tspeed: 0.0351s/iter; left time: 51.6196s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580635\n",
      "\tspeed: 0.0184s/iter; left time: 25.1883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0657543 Vali Loss: 0.0621716 Test Loss: 0.0646343\n",
      "Validation loss decreased (0.062594 --> 0.062172).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0658439\n",
      "\tspeed: 0.0349s/iter; left time: 43.4183s\n",
      "\titers: 200, epoch: 15 | loss: 0.0626161\n",
      "\tspeed: 0.0172s/iter; left time: 19.7016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0653719 Vali Loss: 0.0616256 Test Loss: 0.0642001\n",
      "Validation loss decreased (0.062172 --> 0.061626).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0626120\n",
      "\tspeed: 0.0356s/iter; left time: 36.3321s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643119\n",
      "\tspeed: 0.0188s/iter; left time: 17.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0649188 Vali Loss: 0.0611425 Test Loss: 0.0636172\n",
      "Validation loss decreased (0.061626 --> 0.061142).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716812\n",
      "\tspeed: 0.0383s/iter; left time: 30.5416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630838\n",
      "\tspeed: 0.0174s/iter; left time: 12.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0645986 Vali Loss: 0.0614054 Test Loss: 0.0635941\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649277\n",
      "\tspeed: 0.0377s/iter; left time: 21.5831s\n",
      "\titers: 200, epoch: 18 | loss: 0.0586403\n",
      "\tspeed: 0.0179s/iter; left time: 8.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0643763 Vali Loss: 0.0607071 Test Loss: 0.0632886\n",
      "Validation loss decreased (0.061142 --> 0.060707).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0595899\n",
      "\tspeed: 0.0384s/iter; left time: 13.4102s\n",
      "\titers: 200, epoch: 19 | loss: 0.0584789\n",
      "\tspeed: 0.0196s/iter; left time: 4.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0641533 Vali Loss: 0.0604696 Test Loss: 0.0628338\n",
      "Validation loss decreased (0.060707 --> 0.060470).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0596086\n",
      "\tspeed: 0.0378s/iter; left time: 4.7309s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594903\n",
      "\tspeed: 0.0193s/iter; left time: 0.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0638867 Vali Loss: 0.0604500 Test Loss: 0.0628845\n",
      "Validation loss decreased (0.060470 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011079911142587662, rmse:0.10526115447282791, mae:0.06288447976112366, rse:0.3977300822734833\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:52.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0424s/iter; left time: 185.7683s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0159s/iter; left time: 68.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0343s/iter; left time: 142.3944s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0177s/iter; left time: 71.8964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0352s/iter; left time: 138.3594s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0178s/iter; left time: 68.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0370s/iter; left time: 137.3865s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0207s/iter; left time: 74.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0357s/iter; left time: 124.5631s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0192s/iter; left time: 65.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0345s/iter; left time: 112.5179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0177s/iter; left time: 55.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0305s/iter; left time: 92.6444s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0099s/iter; left time: 29.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0330s/iter; left time: 92.7005s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0165s/iter; left time: 44.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0361s/iter; left time: 93.3468s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0241s/iter; left time: 59.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0346s/iter; left time: 81.7882s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0179s/iter; left time: 40.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0367s/iter; left time: 78.6554s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0185s/iter; left time: 37.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0375s/iter; left time: 71.8172s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0171s/iter; left time: 31.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0343s/iter; left time: 58.0637s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0209s/iter; left time: 33.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0374s/iter; left time: 54.9790s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0165s/iter; left time: 22.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0353s/iter; left time: 43.9769s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0176s/iter; left time: 20.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0356s/iter; left time: 36.3272s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0227s/iter; left time: 20.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0367s/iter; left time: 29.2495s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0174s/iter; left time: 12.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0354s/iter; left time: 20.2864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0182s/iter; left time: 8.6170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0365s/iter; left time: 12.7270s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0192s/iter; left time: 4.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0369s/iter; left time: 4.6127s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0206s/iter; left time: 0.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018444322049617767, rmse:0.13580986857414246, mae:0.0837516337633133, rse:0.5135117769241333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2798630\n",
      "\tspeed: 0.0239s/iter; left time: 104.6756s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552814\n",
      "\tspeed: 0.0184s/iter; left time: 78.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.2785395 Vali Loss: 0.1956593 Test Loss: 0.2025459\n",
      "Validation loss decreased (inf --> 0.195659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1523195\n",
      "\tspeed: 0.0377s/iter; left time: 156.8234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261142\n",
      "\tspeed: 0.0168s/iter; left time: 68.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1576536 Vali Loss: 0.1078425 Test Loss: 0.1150946\n",
      "Validation loss decreased (0.195659 --> 0.107843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147000\n",
      "\tspeed: 0.0375s/iter; left time: 147.2982s\n",
      "\titers: 200, epoch: 3 | loss: 0.1113540\n",
      "\tspeed: 0.0187s/iter; left time: 71.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.1117495 Vali Loss: 0.0957548 Test Loss: 0.1001511\n",
      "Validation loss decreased (0.107843 --> 0.095755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995651\n",
      "\tspeed: 0.0372s/iter; left time: 138.0796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954478\n",
      "\tspeed: 0.0185s/iter; left time: 66.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1004729 Vali Loss: 0.0901986 Test Loss: 0.0926676\n",
      "Validation loss decreased (0.095755 --> 0.090199).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0969215\n",
      "\tspeed: 0.0410s/iter; left time: 142.9546s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928631\n",
      "\tspeed: 0.0200s/iter; left time: 67.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0938142 Vali Loss: 0.0860796 Test Loss: 0.0895533\n",
      "Validation loss decreased (0.090199 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0870151\n",
      "\tspeed: 0.0385s/iter; left time: 125.6743s\n",
      "\titers: 200, epoch: 6 | loss: 0.0875229\n",
      "\tspeed: 0.0171s/iter; left time: 54.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0905203 Vali Loss: 0.0847814 Test Loss: 0.0879801\n",
      "Validation loss decreased (0.086080 --> 0.084781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876240\n",
      "\tspeed: 0.0378s/iter; left time: 114.8192s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924451\n",
      "\tspeed: 0.0175s/iter; left time: 51.3450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0881872 Vali Loss: 0.0827412 Test Loss: 0.0871473\n",
      "Validation loss decreased (0.084781 --> 0.082741).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911712\n",
      "\tspeed: 0.0363s/iter; left time: 102.0720s\n",
      "\titers: 200, epoch: 8 | loss: 0.0860737\n",
      "\tspeed: 0.0167s/iter; left time: 45.2213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0866387 Vali Loss: 0.0817173 Test Loss: 0.0861746\n",
      "Validation loss decreased (0.082741 --> 0.081717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867940\n",
      "\tspeed: 0.0353s/iter; left time: 91.3965s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838338\n",
      "\tspeed: 0.0198s/iter; left time: 49.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0853725 Vali Loss: 0.0804546 Test Loss: 0.0854482\n",
      "Validation loss decreased (0.081717 --> 0.080455).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817206\n",
      "\tspeed: 0.0358s/iter; left time: 84.6040s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812260\n",
      "\tspeed: 0.0160s/iter; left time: 36.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0844308 Vali Loss: 0.0804576 Test Loss: 0.0854035\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823050\n",
      "\tspeed: 0.0352s/iter; left time: 75.3127s\n",
      "\titers: 200, epoch: 11 | loss: 0.0891172\n",
      "\tspeed: 0.0186s/iter; left time: 37.9817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0839546 Vali Loss: 0.0798848 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080455 --> 0.079885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836017\n",
      "\tspeed: 0.0414s/iter; left time: 79.4157s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801083\n",
      "\tspeed: 0.0235s/iter; left time: 42.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0831784 Vali Loss: 0.0796328 Test Loss: 0.0854974\n",
      "Validation loss decreased (0.079885 --> 0.079633).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847356\n",
      "\tspeed: 0.0417s/iter; left time: 70.5412s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833554\n",
      "\tspeed: 0.0206s/iter; left time: 32.7626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0827545 Vali Loss: 0.0793973 Test Loss: 0.0847967\n",
      "Validation loss decreased (0.079633 --> 0.079397).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791785\n",
      "\tspeed: 0.0361s/iter; left time: 52.9787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0865727\n",
      "\tspeed: 0.0186s/iter; left time: 25.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0823615 Vali Loss: 0.0789985 Test Loss: 0.0845724\n",
      "Validation loss decreased (0.079397 --> 0.078999).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0853503\n",
      "\tspeed: 0.0384s/iter; left time: 47.7953s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792778\n",
      "\tspeed: 0.0188s/iter; left time: 21.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0819889 Vali Loss: 0.0791902 Test Loss: 0.0849499\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0856560\n",
      "\tspeed: 0.0327s/iter; left time: 33.3592s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827346\n",
      "\tspeed: 0.0160s/iter; left time: 14.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0816865 Vali Loss: 0.0787904 Test Loss: 0.0842490\n",
      "Validation loss decreased (0.078999 --> 0.078790).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848473\n",
      "\tspeed: 0.0356s/iter; left time: 28.4113s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770277\n",
      "\tspeed: 0.0171s/iter; left time: 11.9268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0814561 Vali Loss: 0.0784145 Test Loss: 0.0843971\n",
      "Validation loss decreased (0.078790 --> 0.078414).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760338\n",
      "\tspeed: 0.0359s/iter; left time: 20.5641s\n",
      "\titers: 200, epoch: 18 | loss: 0.0781984\n",
      "\tspeed: 0.0153s/iter; left time: 7.2369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0810920 Vali Loss: 0.0786268 Test Loss: 0.0844016\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800134\n",
      "\tspeed: 0.0350s/iter; left time: 12.2098s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767878\n",
      "\tspeed: 0.0179s/iter; left time: 4.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0810874 Vali Loss: 0.0781209 Test Loss: 0.0842462\n",
      "Validation loss decreased (0.078414 --> 0.078121).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0753115\n",
      "\tspeed: 0.0375s/iter; left time: 4.6825s\n",
      "\titers: 200, epoch: 20 | loss: 0.0850095\n",
      "\tspeed: 0.0159s/iter; left time: 0.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0807790 Vali Loss: 0.0781104 Test Loss: 0.0839733\n",
      "Validation loss decreased (0.078121 --> 0.078110).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018509913235902786, rmse:0.13605114817619324, mae:0.08397328108549118, rse:0.5144240260124207\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:49.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0442s/iter; left time: 192.6721s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0162s/iter; left time: 69.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0422s/iter; left time: 174.5507s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0211s/iter; left time: 85.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0385s/iter; left time: 150.6576s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0197s/iter; left time: 75.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0394s/iter; left time: 145.2998s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0201s/iter; left time: 72.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0356s/iter; left time: 123.4889s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0161s/iter; left time: 54.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0383s/iter; left time: 124.3866s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0184s/iter; left time: 57.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0356s/iter; left time: 107.5676s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0232s/iter; left time: 67.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0346s/iter; left time: 96.7608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0187s/iter; left time: 50.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0316s/iter; left time: 81.3505s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0180s/iter; left time: 44.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0362s/iter; left time: 85.2823s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0173s/iter; left time: 39.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0363s/iter; left time: 77.4081s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0188s/iter; left time: 38.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0390s/iter; left time: 74.4492s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0196s/iter; left time: 35.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0352s/iter; left time: 59.3546s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0198s/iter; left time: 31.3646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0373s/iter; left time: 54.5007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0192s/iter; left time: 26.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0390s/iter; left time: 48.3688s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0200s/iter; left time: 22.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0395s/iter; left time: 40.1822s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0223s/iter; left time: 20.4584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0408s/iter; left time: 32.3816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0211s/iter; left time: 14.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0394s/iter; left time: 22.4491s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0212s/iter; left time: 9.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0366s/iter; left time: 12.7084s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0163s/iter; left time: 4.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0346s/iter; left time: 4.2951s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0223s/iter; left time: 0.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020099075511097908, rmse:0.14177121222019196, mae:0.08870533108711243, rse:0.5365503430366516\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2813044\n",
      "\tspeed: 0.0188s/iter; left time: 81.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.2537842\n",
      "\tspeed: 0.0191s/iter; left time: 81.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.2827695 Vali Loss: 0.1986171 Test Loss: 0.2049647\n",
      "Validation loss decreased (inf --> 0.198617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426644\n",
      "\tspeed: 0.0362s/iter; left time: 149.5893s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291617\n",
      "\tspeed: 0.0174s/iter; left time: 70.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1570104 Vali Loss: 0.1081954 Test Loss: 0.1133942\n",
      "Validation loss decreased (0.198617 --> 0.108195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168254\n",
      "\tspeed: 0.0397s/iter; left time: 155.3093s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129910\n",
      "\tspeed: 0.0204s/iter; left time: 77.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.1136678 Vali Loss: 0.0983627 Test Loss: 0.1008437\n",
      "Validation loss decreased (0.108195 --> 0.098363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040641\n",
      "\tspeed: 0.0419s/iter; left time: 154.7231s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984779\n",
      "\tspeed: 0.0200s/iter; left time: 71.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.1031041 Vali Loss: 0.0935392 Test Loss: 0.0961893\n",
      "Validation loss decreased (0.098363 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0936531\n",
      "\tspeed: 0.0400s/iter; left time: 138.8695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950231\n",
      "\tspeed: 0.0183s/iter; left time: 61.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0967202 Vali Loss: 0.0893786 Test Loss: 0.0926177\n",
      "Validation loss decreased (0.093539 --> 0.089379).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0924721\n",
      "\tspeed: 0.0391s/iter; left time: 127.0568s\n",
      "\titers: 200, epoch: 6 | loss: 0.0913443\n",
      "\tspeed: 0.0225s/iter; left time: 70.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0941212 Vali Loss: 0.0876763 Test Loss: 0.0913170\n",
      "Validation loss decreased (0.089379 --> 0.087676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0951016\n",
      "\tspeed: 0.0368s/iter; left time: 111.2449s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915995\n",
      "\tspeed: 0.0223s/iter; left time: 65.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0915591 Vali Loss: 0.0875427 Test Loss: 0.0913138\n",
      "Validation loss decreased (0.087676 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927571\n",
      "\tspeed: 0.0383s/iter; left time: 107.1279s\n",
      "\titers: 200, epoch: 8 | loss: 0.0894333\n",
      "\tspeed: 0.0173s/iter; left time: 46.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0900401 Vali Loss: 0.0854019 Test Loss: 0.0900058\n",
      "Validation loss decreased (0.087543 --> 0.085402).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0886705\n",
      "\tspeed: 0.0415s/iter; left time: 106.9194s\n",
      "\titers: 200, epoch: 9 | loss: 0.0879912\n",
      "\tspeed: 0.0224s/iter; left time: 55.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0889541 Vali Loss: 0.0849612 Test Loss: 0.0891515\n",
      "Validation loss decreased (0.085402 --> 0.084961).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0877168\n",
      "\tspeed: 0.0391s/iter; left time: 92.1186s\n",
      "\titers: 200, epoch: 10 | loss: 0.0875674\n",
      "\tspeed: 0.0199s/iter; left time: 44.9062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0881908 Vali Loss: 0.0846811 Test Loss: 0.0888525\n",
      "Validation loss decreased (0.084961 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0898153\n",
      "\tspeed: 0.0368s/iter; left time: 78.4034s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906977\n",
      "\tspeed: 0.0199s/iter; left time: 40.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0876222 Vali Loss: 0.0841912 Test Loss: 0.0885119\n",
      "Validation loss decreased (0.084681 --> 0.084191).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0854267\n",
      "\tspeed: 0.0401s/iter; left time: 76.4783s\n",
      "\titers: 200, epoch: 12 | loss: 0.0921324\n",
      "\tspeed: 0.0220s/iter; left time: 39.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0870224 Vali Loss: 0.0838905 Test Loss: 0.0882123\n",
      "Validation loss decreased (0.084191 --> 0.083890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908491\n",
      "\tspeed: 0.0390s/iter; left time: 65.7444s\n",
      "\titers: 200, epoch: 13 | loss: 0.0868078\n",
      "\tspeed: 0.0193s/iter; left time: 30.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0865049 Vali Loss: 0.0839069 Test Loss: 0.0883935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0854094\n",
      "\tspeed: 0.0372s/iter; left time: 54.3500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844667\n",
      "\tspeed: 0.0183s/iter; left time: 24.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0861975 Vali Loss: 0.0840705 Test Loss: 0.0888260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889031\n",
      "\tspeed: 0.0392s/iter; left time: 48.5088s\n",
      "\titers: 200, epoch: 15 | loss: 0.0843957\n",
      "\tspeed: 0.0202s/iter; left time: 23.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0855418 Vali Loss: 0.0836140 Test Loss: 0.0885775\n",
      "Validation loss decreased (0.083890 --> 0.083614).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0875921\n",
      "\tspeed: 0.0353s/iter; left time: 35.8347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831733\n",
      "\tspeed: 0.0168s/iter; left time: 15.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0853479 Vali Loss: 0.0839115 Test Loss: 0.0888283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0873199\n",
      "\tspeed: 0.0340s/iter; left time: 26.9804s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876978\n",
      "\tspeed: 0.0101s/iter; left time: 6.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 223 | Train Loss: 0.0852551 Vali Loss: 0.0832509 Test Loss: 0.0884188\n",
      "Validation loss decreased (0.083614 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0823902\n",
      "\tspeed: 0.0363s/iter; left time: 20.7115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818335\n",
      "\tspeed: 0.0171s/iter; left time: 8.0195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0849353 Vali Loss: 0.0838093 Test Loss: 0.0887195\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851609\n",
      "\tspeed: 0.0355s/iter; left time: 12.3019s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858866\n",
      "\tspeed: 0.0188s/iter; left time: 4.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0846712 Vali Loss: 0.0832612 Test Loss: 0.0881233\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0836230\n",
      "\tspeed: 0.0386s/iter; left time: 4.7863s\n",
      "\titers: 200, epoch: 20 | loss: 0.0846320\n",
      "\tspeed: 0.0180s/iter; left time: 0.4309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0845549 Vali Loss: 0.0833086 Test Loss: 0.0881949\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019747594371438026, rmse:0.14052613079547882, mae:0.0884188562631607, rse:0.5318382382392883\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:59.29s\n",
      "Intermediate time for IT: 00h:11m:41.06s\n",
      "Total time: 00h:57m:46.54s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.0617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0220  0.1484  0.0926\n",
       "        96        0.0415  0.2037  0.1336\n",
       "        168       0.0448  0.2116  0.1411\n",
       "ES      24        0.0202  0.1422  0.0838\n",
       "        96        0.0300  0.1727  0.1122\n",
       "        168       0.0293  0.1712  0.1158\n",
       "FR      24        0.0112  0.1058  0.0617\n",
       "        96        0.0208  0.1441  0.0848\n",
       "        168       0.0242  0.1556  0.0917\n",
       "GB      24        0.0284  0.1684  0.1077\n",
       "        96        0.0530  0.2302  0.1529\n",
       "        168       0.0548  0.2341  0.1576\n",
       "IT      24        0.0111  0.1054  0.0629\n",
       "        96        0.0185  0.1359  0.0839\n",
       "        168       0.0199  0.1411  0.0886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1554952\n",
      "\tspeed: 0.0431s/iter; left time: 188.7469s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357202\n",
      "\tspeed: 0.0153s/iter; left time: 65.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1541195 Vali Loss: 0.1402045 Test Loss: 0.1497520\n",
      "Validation loss decreased (inf --> 0.140205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869676\n",
      "\tspeed: 0.0344s/iter; left time: 143.0137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847717\n",
      "\tspeed: 0.0165s/iter; left time: 66.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0921203 Vali Loss: 0.0949045 Test Loss: 0.0956562\n",
      "Validation loss decreased (0.140205 --> 0.094904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0774624\n",
      "\tspeed: 0.0384s/iter; left time: 150.8717s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822205\n",
      "\tspeed: 0.0179s/iter; left time: 68.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0812834 Vali Loss: 0.0916223 Test Loss: 0.0926683\n",
      "Validation loss decreased (0.094904 --> 0.091622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0761068\n",
      "\tspeed: 0.0355s/iter; left time: 131.8357s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788112\n",
      "\tspeed: 0.0182s/iter; left time: 65.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0784736 Vali Loss: 0.0895640 Test Loss: 0.0912961\n",
      "Validation loss decreased (0.091622 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777103\n",
      "\tspeed: 0.0415s/iter; left time: 144.7898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0786942\n",
      "\tspeed: 0.0201s/iter; left time: 68.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0769159 Vali Loss: 0.0888526 Test Loss: 0.0907485\n",
      "Validation loss decreased (0.089564 --> 0.088853).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802427\n",
      "\tspeed: 0.0382s/iter; left time: 124.5170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0740417\n",
      "\tspeed: 0.0186s/iter; left time: 58.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0758447 Vali Loss: 0.0882284 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.088853 --> 0.088228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748348\n",
      "\tspeed: 0.0348s/iter; left time: 105.6184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769684\n",
      "\tspeed: 0.0150s/iter; left time: 44.1198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0751689 Vali Loss: 0.0878075 Test Loss: 0.0892610\n",
      "Validation loss decreased (0.088228 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0768212\n",
      "\tspeed: 0.0352s/iter; left time: 98.9953s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734301\n",
      "\tspeed: 0.0150s/iter; left time: 40.5969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0745465 Vali Loss: 0.0876324 Test Loss: 0.0891513\n",
      "Validation loss decreased (0.087807 --> 0.087632).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738977\n",
      "\tspeed: 0.0338s/iter; left time: 87.4820s\n",
      "\titers: 200, epoch: 9 | loss: 0.0720558\n",
      "\tspeed: 0.0191s/iter; left time: 47.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0740447 Vali Loss: 0.0870932 Test Loss: 0.0891499\n",
      "Validation loss decreased (0.087632 --> 0.087093).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726922\n",
      "\tspeed: 0.0403s/iter; left time: 95.4241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0745696\n",
      "\tspeed: 0.0200s/iter; left time: 45.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0736376 Vali Loss: 0.0868243 Test Loss: 0.0889371\n",
      "Validation loss decreased (0.087093 --> 0.086824).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685705\n",
      "\tspeed: 0.0377s/iter; left time: 80.6174s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697067\n",
      "\tspeed: 0.0150s/iter; left time: 30.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0733032 Vali Loss: 0.0868257 Test Loss: 0.0887700\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0702654\n",
      "\tspeed: 0.0384s/iter; left time: 73.6904s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722485\n",
      "\tspeed: 0.0186s/iter; left time: 33.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0729990 Vali Loss: 0.0867122 Test Loss: 0.0885437\n",
      "Validation loss decreased (0.086824 --> 0.086712).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722399\n",
      "\tspeed: 0.0401s/iter; left time: 67.8455s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783269\n",
      "\tspeed: 0.0217s/iter; left time: 34.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0727403 Vali Loss: 0.0864957 Test Loss: 0.0886285\n",
      "Validation loss decreased (0.086712 --> 0.086496).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0701331\n",
      "\tspeed: 0.0392s/iter; left time: 57.6211s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752917\n",
      "\tspeed: 0.0149s/iter; left time: 20.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0725547 Vali Loss: 0.0861861 Test Loss: 0.0884400\n",
      "Validation loss decreased (0.086496 --> 0.086186).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738760\n",
      "\tspeed: 0.0373s/iter; left time: 46.3954s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728909\n",
      "\tspeed: 0.0157s/iter; left time: 17.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0723449 Vali Loss: 0.0862782 Test Loss: 0.0885036\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734793\n",
      "\tspeed: 0.0334s/iter; left time: 34.1015s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676081\n",
      "\tspeed: 0.0150s/iter; left time: 13.8036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0721527 Vali Loss: 0.0864140 Test Loss: 0.0884588\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0718961\n",
      "\tspeed: 0.0374s/iter; left time: 29.8084s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705533\n",
      "\tspeed: 0.0185s/iter; left time: 12.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0720608 Vali Loss: 0.0860744 Test Loss: 0.0882078\n",
      "Validation loss decreased (0.086186 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0697139\n",
      "\tspeed: 0.0353s/iter; left time: 20.2203s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702659\n",
      "\tspeed: 0.0174s/iter; left time: 8.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0719050 Vali Loss: 0.0860787 Test Loss: 0.0882772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0671234\n",
      "\tspeed: 0.0387s/iter; left time: 13.4927s\n",
      "\titers: 200, epoch: 19 | loss: 0.0692945\n",
      "\tspeed: 0.0182s/iter; left time: 4.5320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0717753 Vali Loss: 0.0862968 Test Loss: 0.0883190\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733683\n",
      "\tspeed: 0.0418s/iter; left time: 5.2267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0683619\n",
      "\tspeed: 0.0200s/iter; left time: 0.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0716777 Vali Loss: 0.0859621 Test Loss: 0.0881678\n",
      "Validation loss decreased (0.086074 --> 0.085962).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02103586122393608, rmse:0.145037442445755, mae:0.08816780894994736, rse:0.511857271194458\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1569923\n",
      "\tspeed: 0.0234s/iter; left time: 102.3202s\n",
      "\titers: 200, epoch: 1 | loss: 0.1288551\n",
      "\tspeed: 0.0197s/iter; left time: 84.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1549266 Vali Loss: 0.1411644 Test Loss: 0.1500563\n",
      "Validation loss decreased (inf --> 0.141164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0881527\n",
      "\tspeed: 0.0416s/iter; left time: 173.1000s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912773\n",
      "\tspeed: 0.0201s/iter; left time: 81.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0924410 Vali Loss: 0.0946205 Test Loss: 0.0955073\n",
      "Validation loss decreased (0.141164 --> 0.094620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0822034\n",
      "\tspeed: 0.0365s/iter; left time: 143.3943s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804854\n",
      "\tspeed: 0.0178s/iter; left time: 68.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0812288 Vali Loss: 0.0912640 Test Loss: 0.0926674\n",
      "Validation loss decreased (0.094620 --> 0.091264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729592\n",
      "\tspeed: 0.0386s/iter; left time: 143.0019s\n",
      "\titers: 200, epoch: 4 | loss: 0.0756239\n",
      "\tspeed: 0.0173s/iter; left time: 62.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0785791 Vali Loss: 0.0898872 Test Loss: 0.0911682\n",
      "Validation loss decreased (0.091264 --> 0.089887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767641\n",
      "\tspeed: 0.0413s/iter; left time: 144.0749s\n",
      "\titers: 200, epoch: 5 | loss: 0.0731243\n",
      "\tspeed: 0.0179s/iter; left time: 60.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0770697 Vali Loss: 0.0891297 Test Loss: 0.0905038\n",
      "Validation loss decreased (0.089887 --> 0.089130).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777329\n",
      "\tspeed: 0.0447s/iter; left time: 145.7056s\n",
      "\titers: 200, epoch: 6 | loss: 0.0788753\n",
      "\tspeed: 0.0249s/iter; left time: 78.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0759762 Vali Loss: 0.0886014 Test Loss: 0.0902082\n",
      "Validation loss decreased (0.089130 --> 0.088601).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776498\n",
      "\tspeed: 0.0434s/iter; left time: 131.6891s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724196\n",
      "\tspeed: 0.0193s/iter; left time: 56.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0752084 Vali Loss: 0.0876980 Test Loss: 0.0896836\n",
      "Validation loss decreased (0.088601 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782859\n",
      "\tspeed: 0.0442s/iter; left time: 124.4295s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742921\n",
      "\tspeed: 0.0177s/iter; left time: 47.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0746367 Vali Loss: 0.0875709 Test Loss: 0.0895203\n",
      "Validation loss decreased (0.087698 --> 0.087571).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0741152\n",
      "\tspeed: 0.0442s/iter; left time: 114.4885s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707264\n",
      "\tspeed: 0.0249s/iter; left time: 62.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0741354 Vali Loss: 0.0873647 Test Loss: 0.0891933\n",
      "Validation loss decreased (0.087571 --> 0.087365).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0774268\n",
      "\tspeed: 0.0467s/iter; left time: 110.4193s\n",
      "\titers: 200, epoch: 10 | loss: 0.0757666\n",
      "\tspeed: 0.0212s/iter; left time: 48.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0737080 Vali Loss: 0.0870624 Test Loss: 0.0889512\n",
      "Validation loss decreased (0.087365 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0755409\n",
      "\tspeed: 0.0450s/iter; left time: 96.4365s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718153\n",
      "\tspeed: 0.0245s/iter; left time: 50.0847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 224 | Train Loss: 0.0734132 Vali Loss: 0.0869114 Test Loss: 0.0889660\n",
      "Validation loss decreased (0.087062 --> 0.086911).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758429\n",
      "\tspeed: 0.0456s/iter; left time: 87.3395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731042\n",
      "\tspeed: 0.0210s/iter; left time: 38.1688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0731156 Vali Loss: 0.0867391 Test Loss: 0.0890012\n",
      "Validation loss decreased (0.086911 --> 0.086739).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763908\n",
      "\tspeed: 0.0388s/iter; left time: 65.7452s\n",
      "\titers: 200, epoch: 13 | loss: 0.0706781\n",
      "\tspeed: 0.0174s/iter; left time: 27.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0728514 Vali Loss: 0.0862831 Test Loss: 0.0886576\n",
      "Validation loss decreased (0.086739 --> 0.086283).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0676040\n",
      "\tspeed: 0.0378s/iter; left time: 55.4976s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752216\n",
      "\tspeed: 0.0183s/iter; left time: 25.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0726661 Vali Loss: 0.0865068 Test Loss: 0.0888009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0711630\n",
      "\tspeed: 0.0381s/iter; left time: 47.3744s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687853\n",
      "\tspeed: 0.0217s/iter; left time: 24.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0724174 Vali Loss: 0.0861133 Test Loss: 0.0884617\n",
      "Validation loss decreased (0.086283 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703114\n",
      "\tspeed: 0.0357s/iter; left time: 36.4709s\n",
      "\titers: 200, epoch: 16 | loss: 0.0778182\n",
      "\tspeed: 0.0186s/iter; left time: 17.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0722327 Vali Loss: 0.0861533 Test Loss: 0.0884141\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0752272\n",
      "\tspeed: 0.0412s/iter; left time: 32.8678s\n",
      "\titers: 200, epoch: 17 | loss: 0.0660648\n",
      "\tspeed: 0.0161s/iter; left time: 11.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0721134 Vali Loss: 0.0860939 Test Loss: 0.0884697\n",
      "Validation loss decreased (0.086113 --> 0.086094).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760951\n",
      "\tspeed: 0.0353s/iter; left time: 20.2551s\n",
      "\titers: 200, epoch: 18 | loss: 0.0698126\n",
      "\tspeed: 0.0189s/iter; left time: 8.9336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0719862 Vali Loss: 0.0860885 Test Loss: 0.0884769\n",
      "Validation loss decreased (0.086094 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748066\n",
      "\tspeed: 0.0476s/iter; left time: 16.6085s\n",
      "\titers: 200, epoch: 19 | loss: 0.0722093\n",
      "\tspeed: 0.0248s/iter; left time: 6.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0717882 Vali Loss: 0.0861733 Test Loss: 0.0884549\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718694\n",
      "\tspeed: 0.0397s/iter; left time: 4.9653s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701521\n",
      "\tspeed: 0.0171s/iter; left time: 0.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0717911 Vali Loss: 0.0858655 Test Loss: 0.0882043\n",
      "Validation loss decreased (0.086088 --> 0.085865).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021054714918136597, rmse:0.14510242640972137, mae:0.08820432424545288, rse:0.5120865702629089\n",
      "Intermediate time for DE and pred_len 24: 00h:04m:04.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1617293\n",
      "\tspeed: 0.0433s/iter; left time: 189.9140s\n",
      "\titers: 200, epoch: 1 | loss: 0.1502261\n",
      "\tspeed: 0.0152s/iter; left time: 65.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1589484 Vali Loss: 0.1489534 Test Loss: 0.1608385\n",
      "Validation loss decreased (inf --> 0.148953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1088347\n",
      "\tspeed: 0.0371s/iter; left time: 154.1003s\n",
      "\titers: 200, epoch: 2 | loss: 0.1147311\n",
      "\tspeed: 0.0180s/iter; left time: 72.8770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1169258 Vali Loss: 0.1223775 Test Loss: 0.1303410\n",
      "Validation loss decreased (0.148953 --> 0.122377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055293\n",
      "\tspeed: 0.0377s/iter; left time: 148.3993s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986288\n",
      "\tspeed: 0.0152s/iter; left time: 58.1857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1074978 Vali Loss: 0.1198995 Test Loss: 0.1283483\n",
      "Validation loss decreased (0.122377 --> 0.119899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1030197\n",
      "\tspeed: 0.0406s/iter; left time: 150.4588s\n",
      "\titers: 200, epoch: 4 | loss: 0.1036162\n",
      "\tspeed: 0.0185s/iter; left time: 66.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1053726 Vali Loss: 0.1190406 Test Loss: 0.1278044\n",
      "Validation loss decreased (0.119899 --> 0.119041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044356\n",
      "\tspeed: 0.0385s/iter; left time: 134.1142s\n",
      "\titers: 200, epoch: 5 | loss: 0.1062173\n",
      "\tspeed: 0.0167s/iter; left time: 56.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1040613 Vali Loss: 0.1187894 Test Loss: 0.1276770\n",
      "Validation loss decreased (0.119041 --> 0.118789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023082\n",
      "\tspeed: 0.0353s/iter; left time: 115.2568s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002097\n",
      "\tspeed: 0.0157s/iter; left time: 49.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.1030888 Vali Loss: 0.1175843 Test Loss: 0.1267586\n",
      "Validation loss decreased (0.118789 --> 0.117584).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985272\n",
      "\tspeed: 0.0402s/iter; left time: 122.1258s\n",
      "\titers: 200, epoch: 7 | loss: 0.1033290\n",
      "\tspeed: 0.0204s/iter; left time: 59.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1023778 Vali Loss: 0.1178266 Test Loss: 0.1273874\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0990437\n",
      "\tspeed: 0.0415s/iter; left time: 116.6032s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037220\n",
      "\tspeed: 0.0195s/iter; left time: 52.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1017019 Vali Loss: 0.1178749 Test Loss: 0.1282059\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1000827\n",
      "\tspeed: 0.0406s/iter; left time: 105.2118s\n",
      "\titers: 200, epoch: 9 | loss: 0.1004790\n",
      "\tspeed: 0.0192s/iter; left time: 47.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1011080 Vali Loss: 0.1178433 Test Loss: 0.1280416\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0967632\n",
      "\tspeed: 0.0419s/iter; left time: 99.0451s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985029\n",
      "\tspeed: 0.0199s/iter; left time: 45.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1005722 Vali Loss: 0.1179191 Test Loss: 0.1280248\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0999602\n",
      "\tspeed: 0.0410s/iter; left time: 87.7302s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048836\n",
      "\tspeed: 0.0186s/iter; left time: 37.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1001029 Vali Loss: 0.1170781 Test Loss: 0.1272336\n",
      "Validation loss decreased (0.117584 --> 0.117078).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0998638\n",
      "\tspeed: 0.0444s/iter; left time: 85.0222s\n",
      "\titers: 200, epoch: 12 | loss: 0.0988359\n",
      "\tspeed: 0.0239s/iter; left time: 43.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0995904 Vali Loss: 0.1173029 Test Loss: 0.1276678\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029612\n",
      "\tspeed: 0.0419s/iter; left time: 70.8932s\n",
      "\titers: 200, epoch: 13 | loss: 0.0956578\n",
      "\tspeed: 0.0210s/iter; left time: 33.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0991521 Vali Loss: 0.1173498 Test Loss: 0.1281194\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1017543\n",
      "\tspeed: 0.0473s/iter; left time: 69.5560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952376\n",
      "\tspeed: 0.0235s/iter; left time: 32.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0987826 Vali Loss: 0.1174424 Test Loss: 0.1278649\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1004049\n",
      "\tspeed: 0.0420s/iter; left time: 52.3101s\n",
      "\titers: 200, epoch: 15 | loss: 0.1025560\n",
      "\tspeed: 0.0200s/iter; left time: 22.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0983810 Vali Loss: 0.1175421 Test Loss: 0.1287416\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000547\n",
      "\tspeed: 0.0413s/iter; left time: 42.1258s\n",
      "\titers: 200, epoch: 16 | loss: 0.0976227\n",
      "\tspeed: 0.0224s/iter; left time: 20.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0980522 Vali Loss: 0.1172046 Test Loss: 0.1286765\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037020161747932434, rmse:0.19240623712539673, mae:0.1272336095571518, rse:0.6813493967056274\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1630785\n",
      "\tspeed: 0.0248s/iter; left time: 108.4748s\n",
      "\titers: 200, epoch: 1 | loss: 0.1449552\n",
      "\tspeed: 0.0208s/iter; left time: 88.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1604888 Vali Loss: 0.1499657 Test Loss: 0.1620333\n",
      "Validation loss decreased (inf --> 0.149966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091487\n",
      "\tspeed: 0.0408s/iter; left time: 169.5820s\n",
      "\titers: 200, epoch: 2 | loss: 0.1060006\n",
      "\tspeed: 0.0207s/iter; left time: 83.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1170154 Vali Loss: 0.1222239 Test Loss: 0.1304720\n",
      "Validation loss decreased (0.149966 --> 0.122224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1130211\n",
      "\tspeed: 0.0426s/iter; left time: 167.4582s\n",
      "\titers: 200, epoch: 3 | loss: 0.1058219\n",
      "\tspeed: 0.0205s/iter; left time: 78.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1075553 Vali Loss: 0.1200851 Test Loss: 0.1297144\n",
      "Validation loss decreased (0.122224 --> 0.120085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025496\n",
      "\tspeed: 0.0470s/iter; left time: 174.2754s\n",
      "\titers: 200, epoch: 4 | loss: 0.1057491\n",
      "\tspeed: 0.0173s/iter; left time: 62.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.1053703 Vali Loss: 0.1193173 Test Loss: 0.1299114\n",
      "Validation loss decreased (0.120085 --> 0.119317).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032997\n",
      "\tspeed: 0.0457s/iter; left time: 159.4342s\n",
      "\titers: 200, epoch: 5 | loss: 0.1151524\n",
      "\tspeed: 0.0175s/iter; left time: 59.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.1039783 Vali Loss: 0.1186134 Test Loss: 0.1288320\n",
      "Validation loss decreased (0.119317 --> 0.118613).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036089\n",
      "\tspeed: 0.0434s/iter; left time: 141.4052s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987184\n",
      "\tspeed: 0.0177s/iter; left time: 56.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.1029179 Vali Loss: 0.1180167 Test Loss: 0.1285254\n",
      "Validation loss decreased (0.118613 --> 0.118017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983001\n",
      "\tspeed: 0.0433s/iter; left time: 131.5383s\n",
      "\titers: 200, epoch: 7 | loss: 0.1078606\n",
      "\tspeed: 0.0246s/iter; left time: 72.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.1021746 Vali Loss: 0.1183373 Test Loss: 0.1284593\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1007332\n",
      "\tspeed: 0.0385s/iter; left time: 108.2391s\n",
      "\titers: 200, epoch: 8 | loss: 0.1045842\n",
      "\tspeed: 0.0152s/iter; left time: 41.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1013616 Vali Loss: 0.1189741 Test Loss: 0.1294374\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1018139\n",
      "\tspeed: 0.0384s/iter; left time: 99.3840s\n",
      "\titers: 200, epoch: 9 | loss: 0.1061398\n",
      "\tspeed: 0.0168s/iter; left time: 41.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1007345 Vali Loss: 0.1180770 Test Loss: 0.1282958\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989693\n",
      "\tspeed: 0.0414s/iter; left time: 97.8851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0958580\n",
      "\tspeed: 0.0173s/iter; left time: 39.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1000828 Vali Loss: 0.1182697 Test Loss: 0.1283964\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0962997\n",
      "\tspeed: 0.0366s/iter; left time: 78.3523s\n",
      "\titers: 200, epoch: 11 | loss: 0.1008206\n",
      "\tspeed: 0.0166s/iter; left time: 33.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0995669 Vali Loss: 0.1182233 Test Loss: 0.1287764\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037573326379060745, rmse:0.19383840262889862, mae:0.12852546572685242, rse:0.6864209771156311\n",
      "Intermediate time for DE and pred_len 96: 00h:02m:54.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1630802\n",
      "\tspeed: 0.0426s/iter; left time: 185.8234s\n",
      "\titers: 200, epoch: 1 | loss: 0.1465753\n",
      "\tspeed: 0.0153s/iter; left time: 65.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1605783 Vali Loss: 0.1508962 Test Loss: 0.1630176\n",
      "Validation loss decreased (inf --> 0.150896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295763\n",
      "\tspeed: 0.0363s/iter; left time: 150.1152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168139\n",
      "\tspeed: 0.0178s/iter; left time: 71.9166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1227621 Vali Loss: 0.1269557 Test Loss: 0.1364352\n",
      "Validation loss decreased (0.150896 --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145269\n",
      "\tspeed: 0.0433s/iter; left time: 169.3482s\n",
      "\titers: 200, epoch: 3 | loss: 0.1162174\n",
      "\tspeed: 0.0195s/iter; left time: 74.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.1136734 Vali Loss: 0.1247916 Test Loss: 0.1347414\n",
      "Validation loss decreased (0.126956 --> 0.124792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097216\n",
      "\tspeed: 0.0426s/iter; left time: 157.4378s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118387\n",
      "\tspeed: 0.0197s/iter; left time: 70.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1113515 Vali Loss: 0.1241977 Test Loss: 0.1348312\n",
      "Validation loss decreased (0.124792 --> 0.124198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120783\n",
      "\tspeed: 0.0439s/iter; left time: 152.3621s\n",
      "\titers: 200, epoch: 5 | loss: 0.1105169\n",
      "\tspeed: 0.0201s/iter; left time: 67.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.1099460 Vali Loss: 0.1236693 Test Loss: 0.1346285\n",
      "Validation loss decreased (0.124198 --> 0.123669).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060411\n",
      "\tspeed: 0.0428s/iter; left time: 138.8908s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044471\n",
      "\tspeed: 0.0186s/iter; left time: 58.5657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1088728 Vali Loss: 0.1233766 Test Loss: 0.1346566\n",
      "Validation loss decreased (0.123669 --> 0.123377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1017920\n",
      "\tspeed: 0.0437s/iter; left time: 132.0980s\n",
      "\titers: 200, epoch: 7 | loss: 0.1089835\n",
      "\tspeed: 0.0198s/iter; left time: 57.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1079321 Vali Loss: 0.1237818 Test Loss: 0.1350066\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1103656\n",
      "\tspeed: 0.0477s/iter; left time: 133.6923s\n",
      "\titers: 200, epoch: 8 | loss: 0.1075654\n",
      "\tspeed: 0.0256s/iter; left time: 69.1177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.1071216 Vali Loss: 0.1238213 Test Loss: 0.1350236\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030786\n",
      "\tspeed: 0.0441s/iter; left time: 113.6919s\n",
      "\titers: 200, epoch: 9 | loss: 0.1097195\n",
      "\tspeed: 0.0203s/iter; left time: 50.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.1063707 Vali Loss: 0.1244656 Test Loss: 0.1355901\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035809\n",
      "\tspeed: 0.0422s/iter; left time: 99.2824s\n",
      "\titers: 200, epoch: 10 | loss: 0.1176516\n",
      "\tspeed: 0.0198s/iter; left time: 44.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.1057048 Vali Loss: 0.1241349 Test Loss: 0.1359958\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068485\n",
      "\tspeed: 0.0383s/iter; left time: 81.6387s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104806\n",
      "\tspeed: 0.0167s/iter; left time: 33.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1050271 Vali Loss: 0.1242511 Test Loss: 0.1356018\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039681319147348404, rmse:0.19920170307159424, mae:0.1346566081047058, rse:0.7055884599685669\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1553396\n",
      "\tspeed: 0.0244s/iter; left time: 106.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.1451320\n",
      "\tspeed: 0.0198s/iter; left time: 84.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.1597921 Vali Loss: 0.1508654 Test Loss: 0.1624720\n",
      "Validation loss decreased (inf --> 0.150865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205829\n",
      "\tspeed: 0.0501s/iter; left time: 207.4659s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156526\n",
      "\tspeed: 0.0197s/iter; left time: 79.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1225081 Vali Loss: 0.1261419 Test Loss: 0.1358858\n",
      "Validation loss decreased (0.150865 --> 0.126142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1154702\n",
      "\tspeed: 0.0475s/iter; left time: 185.7840s\n",
      "\titers: 200, epoch: 3 | loss: 0.1208132\n",
      "\tspeed: 0.0178s/iter; left time: 67.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1134476 Vali Loss: 0.1242651 Test Loss: 0.1351330\n",
      "Validation loss decreased (0.126142 --> 0.124265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083553\n",
      "\tspeed: 0.0513s/iter; left time: 189.3084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114645\n",
      "\tspeed: 0.0250s/iter; left time: 89.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.1111535 Vali Loss: 0.1238227 Test Loss: 0.1351298\n",
      "Validation loss decreased (0.124265 --> 0.123823).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088758\n",
      "\tspeed: 0.0477s/iter; left time: 165.4829s\n",
      "\titers: 200, epoch: 5 | loss: 0.1138292\n",
      "\tspeed: 0.0210s/iter; left time: 70.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1096550 Vali Loss: 0.1237200 Test Loss: 0.1350734\n",
      "Validation loss decreased (0.123823 --> 0.123720).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060584\n",
      "\tspeed: 0.0443s/iter; left time: 143.7347s\n",
      "\titers: 200, epoch: 6 | loss: 0.1078526\n",
      "\tspeed: 0.0248s/iter; left time: 77.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.1085108 Vali Loss: 0.1237013 Test Loss: 0.1353167\n",
      "Validation loss decreased (0.123720 --> 0.123701).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056099\n",
      "\tspeed: 0.0464s/iter; left time: 140.4060s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071206\n",
      "\tspeed: 0.0201s/iter; left time: 58.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.1075053 Vali Loss: 0.1243213 Test Loss: 0.1358723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1062378\n",
      "\tspeed: 0.0443s/iter; left time: 124.1228s\n",
      "\titers: 200, epoch: 8 | loss: 0.1031721\n",
      "\tspeed: 0.0239s/iter; left time: 64.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.1066894 Vali Loss: 0.1241120 Test Loss: 0.1356260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1024874\n",
      "\tspeed: 0.0481s/iter; left time: 123.8563s\n",
      "\titers: 200, epoch: 9 | loss: 0.1056722\n",
      "\tspeed: 0.0205s/iter; left time: 50.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.1057593 Vali Loss: 0.1242756 Test Loss: 0.1355877\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090433\n",
      "\tspeed: 0.0482s/iter; left time: 113.3666s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010605\n",
      "\tspeed: 0.0210s/iter; left time: 47.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.1049365 Vali Loss: 0.1248252 Test Loss: 0.1358047\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0981197\n",
      "\tspeed: 0.0480s/iter; left time: 102.3049s\n",
      "\titers: 200, epoch: 11 | loss: 0.1002965\n",
      "\tspeed: 0.0212s/iter; left time: 43.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.1042000 Vali Loss: 0.1250085 Test Loss: 0.1355155\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04008013755083084, rmse:0.20020024478435516, mae:0.1353166252374649, rse:0.7091253995895386\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:35.93s\n",
      "Intermediate time for DE: 00h:09m:35.22s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1408029\n",
      "\tspeed: 0.0424s/iter; left time: 185.6805s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220715\n",
      "\tspeed: 0.0165s/iter; left time: 70.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1394795 Vali Loss: 0.1303381 Test Loss: 0.1521771\n",
      "Validation loss decreased (inf --> 0.130338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0838467\n",
      "\tspeed: 0.0342s/iter; left time: 142.0768s\n",
      "\titers: 200, epoch: 2 | loss: 0.0810687\n",
      "\tspeed: 0.0151s/iter; left time: 61.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0883854 Vali Loss: 0.0922935 Test Loss: 0.1038328\n",
      "Validation loss decreased (0.130338 --> 0.092294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813066\n",
      "\tspeed: 0.0338s/iter; left time: 132.8045s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811429\n",
      "\tspeed: 0.0154s/iter; left time: 58.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0800376 Vali Loss: 0.0906270 Test Loss: 0.1026502\n",
      "Validation loss decreased (0.092294 --> 0.090627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798900\n",
      "\tspeed: 0.0350s/iter; left time: 129.7337s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782969\n",
      "\tspeed: 0.0180s/iter; left time: 64.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0784506 Vali Loss: 0.0899711 Test Loss: 0.1023145\n",
      "Validation loss decreased (0.090627 --> 0.089971).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0802007\n",
      "\tspeed: 0.0393s/iter; left time: 137.0857s\n",
      "\titers: 200, epoch: 5 | loss: 0.0761889\n",
      "\tspeed: 0.0206s/iter; left time: 69.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0775106 Vali Loss: 0.0896766 Test Loss: 0.1023679\n",
      "Validation loss decreased (0.089971 --> 0.089677).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737546\n",
      "\tspeed: 0.0363s/iter; left time: 118.4605s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722272\n",
      "\tspeed: 0.0158s/iter; left time: 49.7961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0767953 Vali Loss: 0.0892543 Test Loss: 0.1016112\n",
      "Validation loss decreased (0.089677 --> 0.089254).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772201\n",
      "\tspeed: 0.0377s/iter; left time: 114.4109s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759338\n",
      "\tspeed: 0.0194s/iter; left time: 57.0688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0762198 Vali Loss: 0.0889135 Test Loss: 0.1021290\n",
      "Validation loss decreased (0.089254 --> 0.088914).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0737974\n",
      "\tspeed: 0.0405s/iter; left time: 113.9475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742771\n",
      "\tspeed: 0.0192s/iter; left time: 52.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0758061 Vali Loss: 0.0888634 Test Loss: 0.1011181\n",
      "Validation loss decreased (0.088914 --> 0.088863).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776098\n",
      "\tspeed: 0.0338s/iter; left time: 87.3904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778834\n",
      "\tspeed: 0.0150s/iter; left time: 37.2914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0754323 Vali Loss: 0.0887642 Test Loss: 0.1017987\n",
      "Validation loss decreased (0.088863 --> 0.088764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783418\n",
      "\tspeed: 0.0398s/iter; left time: 94.0227s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797399\n",
      "\tspeed: 0.0163s/iter; left time: 36.8168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0750985 Vali Loss: 0.0884259 Test Loss: 0.1014588\n",
      "Validation loss decreased (0.088764 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765481\n",
      "\tspeed: 0.0365s/iter; left time: 78.1492s\n",
      "\titers: 200, epoch: 11 | loss: 0.0767598\n",
      "\tspeed: 0.0170s/iter; left time: 34.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0748397 Vali Loss: 0.0884989 Test Loss: 0.1009134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725433\n",
      "\tspeed: 0.0376s/iter; left time: 72.0028s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751468\n",
      "\tspeed: 0.0180s/iter; left time: 32.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0746248 Vali Loss: 0.0884313 Test Loss: 0.1013561\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761357\n",
      "\tspeed: 0.0365s/iter; left time: 61.7116s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725394\n",
      "\tspeed: 0.0150s/iter; left time: 23.8190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0744325 Vali Loss: 0.0881754 Test Loss: 0.1007002\n",
      "Validation loss decreased (0.088426 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779839\n",
      "\tspeed: 0.0379s/iter; left time: 55.6193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749262\n",
      "\tspeed: 0.0159s/iter; left time: 21.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0742962 Vali Loss: 0.0882207 Test Loss: 0.1010617\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0688910\n",
      "\tspeed: 0.0348s/iter; left time: 43.3631s\n",
      "\titers: 200, epoch: 15 | loss: 0.0793659\n",
      "\tspeed: 0.0156s/iter; left time: 17.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0741033 Vali Loss: 0.0882980 Test Loss: 0.1009011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0731619\n",
      "\tspeed: 0.0335s/iter; left time: 34.2294s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750202\n",
      "\tspeed: 0.0150s/iter; left time: 13.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0739156 Vali Loss: 0.0880635 Test Loss: 0.1010218\n",
      "Validation loss decreased (0.088175 --> 0.088063).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808460\n",
      "\tspeed: 0.0389s/iter; left time: 31.0244s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702096\n",
      "\tspeed: 0.0180s/iter; left time: 12.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0738391 Vali Loss: 0.0881552 Test Loss: 0.1009193\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780886\n",
      "\tspeed: 0.0357s/iter; left time: 20.4304s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703475\n",
      "\tspeed: 0.0162s/iter; left time: 7.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0736550 Vali Loss: 0.0880305 Test Loss: 0.1005262\n",
      "Validation loss decreased (0.088063 --> 0.088030).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725428\n",
      "\tspeed: 0.0438s/iter; left time: 15.2935s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751350\n",
      "\tspeed: 0.0228s/iter; left time: 5.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0735561 Vali Loss: 0.0878773 Test Loss: 0.1006675\n",
      "Validation loss decreased (0.088030 --> 0.087877).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739074\n",
      "\tspeed: 0.0408s/iter; left time: 5.0990s\n",
      "\titers: 200, epoch: 20 | loss: 0.0685736\n",
      "\tspeed: 0.0200s/iter; left time: 0.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0734560 Vali Loss: 0.0880576 Test Loss: 0.1006947\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02571168728172779, rmse:0.16034863889217377, mae:0.10066747665405273, rse:0.553157389163971\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1426990\n",
      "\tspeed: 0.0195s/iter; left time: 85.2726s\n",
      "\titers: 200, epoch: 1 | loss: 0.1211217\n",
      "\tspeed: 0.0172s/iter; left time: 73.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1413873 Vali Loss: 0.1313342 Test Loss: 0.1529275\n",
      "Validation loss decreased (inf --> 0.131334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920208\n",
      "\tspeed: 0.0401s/iter; left time: 166.6888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922285\n",
      "\tspeed: 0.0192s/iter; left time: 77.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0886714 Vali Loss: 0.0918820 Test Loss: 0.1031965\n",
      "Validation loss decreased (0.131334 --> 0.091882).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0745580\n",
      "\tspeed: 0.0417s/iter; left time: 164.1112s\n",
      "\titers: 200, epoch: 3 | loss: 0.0770032\n",
      "\tspeed: 0.0201s/iter; left time: 76.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0800178 Vali Loss: 0.0907631 Test Loss: 0.1022072\n",
      "Validation loss decreased (0.091882 --> 0.090763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0781393\n",
      "\tspeed: 0.0411s/iter; left time: 152.2818s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811933\n",
      "\tspeed: 0.0176s/iter; left time: 63.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0783863 Vali Loss: 0.0900284 Test Loss: 0.1022384\n",
      "Validation loss decreased (0.090763 --> 0.090028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737690\n",
      "\tspeed: 0.0382s/iter; left time: 133.0965s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782653\n",
      "\tspeed: 0.0194s/iter; left time: 65.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0774529 Vali Loss: 0.0898817 Test Loss: 0.1026760\n",
      "Validation loss decreased (0.090028 --> 0.089882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752798\n",
      "\tspeed: 0.0395s/iter; left time: 128.7059s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756785\n",
      "\tspeed: 0.0217s/iter; left time: 68.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0895181 Test Loss: 0.1017127\n",
      "Validation loss decreased (0.089882 --> 0.089518).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0777912\n",
      "\tspeed: 0.0470s/iter; left time: 142.7631s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742693\n",
      "\tspeed: 0.0179s/iter; left time: 52.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0762158 Vali Loss: 0.0888710 Test Loss: 0.1015809\n",
      "Validation loss decreased (0.089518 --> 0.088871).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770149\n",
      "\tspeed: 0.0380s/iter; left time: 106.9351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0693960\n",
      "\tspeed: 0.0201s/iter; left time: 54.5469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0758130 Vali Loss: 0.0889070 Test Loss: 0.1015775\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0743423\n",
      "\tspeed: 0.0372s/iter; left time: 96.4258s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789250\n",
      "\tspeed: 0.0180s/iter; left time: 44.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0754435 Vali Loss: 0.0887747 Test Loss: 0.1010644\n",
      "Validation loss decreased (0.088871 --> 0.088775).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688218\n",
      "\tspeed: 0.0387s/iter; left time: 91.5577s\n",
      "\titers: 200, epoch: 10 | loss: 0.0740221\n",
      "\tspeed: 0.0170s/iter; left time: 38.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0751218 Vali Loss: 0.0890175 Test Loss: 0.1013409\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767177\n",
      "\tspeed: 0.0385s/iter; left time: 82.4044s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711599\n",
      "\tspeed: 0.0177s/iter; left time: 36.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0748408 Vali Loss: 0.0884742 Test Loss: 0.1006243\n",
      "Validation loss decreased (0.088775 --> 0.088474).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774689\n",
      "\tspeed: 0.0385s/iter; left time: 73.8126s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763765\n",
      "\tspeed: 0.0154s/iter; left time: 27.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0746103 Vali Loss: 0.0887545 Test Loss: 0.1008374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0736466\n",
      "\tspeed: 0.0358s/iter; left time: 60.6607s\n",
      "\titers: 200, epoch: 13 | loss: 0.0663546\n",
      "\tspeed: 0.0150s/iter; left time: 23.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0743160 Vali Loss: 0.0881196 Test Loss: 0.1011693\n",
      "Validation loss decreased (0.088474 --> 0.088120).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0722639\n",
      "\tspeed: 0.0377s/iter; left time: 55.4206s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726922\n",
      "\tspeed: 0.0184s/iter; left time: 25.2504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0741482 Vali Loss: 0.0883620 Test Loss: 0.1010674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0765208\n",
      "\tspeed: 0.0353s/iter; left time: 43.9686s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766634\n",
      "\tspeed: 0.0150s/iter; left time: 17.1451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0740250 Vali Loss: 0.0881034 Test Loss: 0.1007322\n",
      "Validation loss decreased (0.088120 --> 0.088103).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0711784\n",
      "\tspeed: 0.0361s/iter; left time: 36.8920s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745880\n",
      "\tspeed: 0.0206s/iter; left time: 18.9776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0738376 Vali Loss: 0.0881364 Test Loss: 0.1007151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0753264\n",
      "\tspeed: 0.0364s/iter; left time: 29.0347s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706248\n",
      "\tspeed: 0.0158s/iter; left time: 11.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0738016 Vali Loss: 0.0879273 Test Loss: 0.1009507\n",
      "Validation loss decreased (0.088103 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0711455\n",
      "\tspeed: 0.0366s/iter; left time: 20.9634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0713051\n",
      "\tspeed: 0.0170s/iter; left time: 8.0330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0736541 Vali Loss: 0.0879129 Test Loss: 0.1007606\n",
      "Validation loss decreased (0.087927 --> 0.087913).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0688030\n",
      "\tspeed: 0.0373s/iter; left time: 13.0311s\n",
      "\titers: 200, epoch: 19 | loss: 0.0771854\n",
      "\tspeed: 0.0149s/iter; left time: 3.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0734884 Vali Loss: 0.0880213 Test Loss: 0.1003741\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746141\n",
      "\tspeed: 0.0394s/iter; left time: 4.9288s\n",
      "\titers: 200, epoch: 20 | loss: 0.0727115\n",
      "\tspeed: 0.0148s/iter; left time: 0.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0734077 Vali Loss: 0.0879809 Test Loss: 0.1004589\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02565145492553711, rmse:0.16016072034835815, mae:0.10076063871383667, rse:0.552509069442749\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:52.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1464807\n",
      "\tspeed: 0.0435s/iter; left time: 190.6409s\n",
      "\titers: 200, epoch: 1 | loss: 0.1339110\n",
      "\tspeed: 0.0162s/iter; left time: 69.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1435963 Vali Loss: 0.1385392 Test Loss: 0.1633495\n",
      "Validation loss decreased (inf --> 0.138539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108301\n",
      "\tspeed: 0.0391s/iter; left time: 162.3790s\n",
      "\titers: 200, epoch: 2 | loss: 0.1111001\n",
      "\tspeed: 0.0208s/iter; left time: 84.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1108053 Vali Loss: 0.1185568 Test Loss: 0.1400027\n",
      "Validation loss decreased (0.138539 --> 0.118557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053875\n",
      "\tspeed: 0.0374s/iter; left time: 147.0325s\n",
      "\titers: 200, epoch: 3 | loss: 0.1026320\n",
      "\tspeed: 0.0152s/iter; left time: 58.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.1047060 Vali Loss: 0.1174756 Test Loss: 0.1414031\n",
      "Validation loss decreased (0.118557 --> 0.117476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1013440\n",
      "\tspeed: 0.0400s/iter; left time: 148.4403s\n",
      "\titers: 200, epoch: 4 | loss: 0.1018285\n",
      "\tspeed: 0.0184s/iter; left time: 66.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1030777 Vali Loss: 0.1173579 Test Loss: 0.1412462\n",
      "Validation loss decreased (0.117476 --> 0.117358).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023715\n",
      "\tspeed: 0.0375s/iter; left time: 130.8499s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012354\n",
      "\tspeed: 0.0169s/iter; left time: 57.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.1020954 Vali Loss: 0.1173018 Test Loss: 0.1421996\n",
      "Validation loss decreased (0.117358 --> 0.117302).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1005838\n",
      "\tspeed: 0.0380s/iter; left time: 123.8168s\n",
      "\titers: 200, epoch: 6 | loss: 0.0990829\n",
      "\tspeed: 0.0166s/iter; left time: 52.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1010528 Vali Loss: 0.1163672 Test Loss: 0.1405692\n",
      "Validation loss decreased (0.117302 --> 0.116367).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036074\n",
      "\tspeed: 0.0424s/iter; left time: 128.6447s\n",
      "\titers: 200, epoch: 7 | loss: 0.0971777\n",
      "\tspeed: 0.0189s/iter; left time: 55.6022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1001650 Vali Loss: 0.1160881 Test Loss: 0.1422270\n",
      "Validation loss decreased (0.116367 --> 0.116088).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0971712\n",
      "\tspeed: 0.0382s/iter; left time: 107.3734s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009590\n",
      "\tspeed: 0.0182s/iter; left time: 49.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0993132 Vali Loss: 0.1162736 Test Loss: 0.1431388\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0981892\n",
      "\tspeed: 0.0391s/iter; left time: 101.2879s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977690\n",
      "\tspeed: 0.0182s/iter; left time: 45.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0985008 Vali Loss: 0.1168711 Test Loss: 0.1422294\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0964508\n",
      "\tspeed: 0.0403s/iter; left time: 95.2770s\n",
      "\titers: 200, epoch: 10 | loss: 0.1008207\n",
      "\tspeed: 0.0168s/iter; left time: 38.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0979480 Vali Loss: 0.1169810 Test Loss: 0.1432338\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0970866\n",
      "\tspeed: 0.0395s/iter; left time: 84.6755s\n",
      "\titers: 200, epoch: 11 | loss: 0.1026615\n",
      "\tspeed: 0.0180s/iter; left time: 36.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0973957 Vali Loss: 0.1166952 Test Loss: 0.1422242\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0952063\n",
      "\tspeed: 0.0383s/iter; left time: 73.3493s\n",
      "\titers: 200, epoch: 12 | loss: 0.0954418\n",
      "\tspeed: 0.0165s/iter; left time: 30.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0969392 Vali Loss: 0.1171512 Test Loss: 0.1435936\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0437089167535305, rmse:0.20906677842140198, mae:0.1422269642353058, rse:0.7229820489883423\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1439789\n",
      "\tspeed: 0.0228s/iter; left time: 99.9117s\n",
      "\titers: 200, epoch: 1 | loss: 0.1328941\n",
      "\tspeed: 0.0156s/iter; left time: 66.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1449440 Vali Loss: 0.1393162 Test Loss: 0.1642354\n",
      "Validation loss decreased (inf --> 0.139316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1103907\n",
      "\tspeed: 0.0421s/iter; left time: 175.1712s\n",
      "\titers: 200, epoch: 2 | loss: 0.1076906\n",
      "\tspeed: 0.0195s/iter; left time: 79.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1110408 Vali Loss: 0.1183176 Test Loss: 0.1402512\n",
      "Validation loss decreased (0.139316 --> 0.118318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1067609\n",
      "\tspeed: 0.0430s/iter; left time: 169.3079s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033380\n",
      "\tspeed: 0.0182s/iter; left time: 69.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1046272 Vali Loss: 0.1173224 Test Loss: 0.1405597\n",
      "Validation loss decreased (0.118318 --> 0.117322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016744\n",
      "\tspeed: 0.0430s/iter; left time: 159.3347s\n",
      "\titers: 200, epoch: 4 | loss: 0.1019102\n",
      "\tspeed: 0.0152s/iter; left time: 54.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1028988 Vali Loss: 0.1164952 Test Loss: 0.1403949\n",
      "Validation loss decreased (0.117322 --> 0.116495).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0999806\n",
      "\tspeed: 0.0449s/iter; left time: 156.4266s\n",
      "\titers: 200, epoch: 5 | loss: 0.0994685\n",
      "\tspeed: 0.0183s/iter; left time: 61.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.1016366 Vali Loss: 0.1166272 Test Loss: 0.1419465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0996835\n",
      "\tspeed: 0.0414s/iter; left time: 134.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.1023989\n",
      "\tspeed: 0.0210s/iter; left time: 66.3406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1004053 Vali Loss: 0.1166868 Test Loss: 0.1411362\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1032335\n",
      "\tspeed: 0.0438s/iter; left time: 133.0098s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959763\n",
      "\tspeed: 0.0198s/iter; left time: 58.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0994704 Vali Loss: 0.1167028 Test Loss: 0.1412249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1004868\n",
      "\tspeed: 0.0421s/iter; left time: 118.3224s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041749\n",
      "\tspeed: 0.0239s/iter; left time: 64.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0985223 Vali Loss: 0.1168587 Test Loss: 0.1418633\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0998969\n",
      "\tspeed: 0.0459s/iter; left time: 118.9141s\n",
      "\titers: 200, epoch: 9 | loss: 0.1022366\n",
      "\tspeed: 0.0203s/iter; left time: 50.5367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0977101 Vali Loss: 0.1178647 Test Loss: 0.1424285\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04227694496512413, rmse:0.20561358332633972, mae:0.14039494097232819, rse:0.7110404372215271\n",
      "Intermediate time for GB and pred_len 96: 00h:02m:16.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1477975\n",
      "\tspeed: 0.0437s/iter; left time: 190.7858s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0155s/iter; left time: 65.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1446544 Vali Loss: 0.1404012 Test Loss: 0.1657628\n",
      "Validation loss decreased (inf --> 0.140401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182125\n",
      "\tspeed: 0.0385s/iter; left time: 159.2865s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102384\n",
      "\tspeed: 0.0198s/iter; left time: 79.8195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.1153861 Vali Loss: 0.1230363 Test Loss: 0.1469368\n",
      "Validation loss decreased (0.140401 --> 0.123036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1079936\n",
      "\tspeed: 0.0375s/iter; left time: 146.7049s\n",
      "\titers: 200, epoch: 3 | loss: 0.1093975\n",
      "\tspeed: 0.0190s/iter; left time: 72.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1094925 Vali Loss: 0.1216000 Test Loss: 0.1470946\n",
      "Validation loss decreased (0.123036 --> 0.121600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1063738\n",
      "\tspeed: 0.0418s/iter; left time: 154.2251s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092678\n",
      "\tspeed: 0.0156s/iter; left time: 55.8621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1076454 Vali Loss: 0.1222603 Test Loss: 0.1490110\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1073611\n",
      "\tspeed: 0.0423s/iter; left time: 146.8959s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071665\n",
      "\tspeed: 0.0173s/iter; left time: 58.1757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.1062244 Vali Loss: 0.1216785 Test Loss: 0.1476179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1029608\n",
      "\tspeed: 0.0364s/iter; left time: 118.0313s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022937\n",
      "\tspeed: 0.0154s/iter; left time: 48.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1047133 Vali Loss: 0.1216168 Test Loss: 0.1480931\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014383\n",
      "\tspeed: 0.0357s/iter; left time: 107.7792s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044426\n",
      "\tspeed: 0.0160s/iter; left time: 46.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.1036095 Vali Loss: 0.1215207 Test Loss: 0.1481168\n",
      "Validation loss decreased (0.121600 --> 0.121521).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1046117\n",
      "\tspeed: 0.0379s/iter; left time: 106.1302s\n",
      "\titers: 200, epoch: 8 | loss: 0.1001345\n",
      "\tspeed: 0.0167s/iter; left time: 45.0132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1027809 Vali Loss: 0.1216274 Test Loss: 0.1474974\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1017520\n",
      "\tspeed: 0.0412s/iter; left time: 106.1024s\n",
      "\titers: 200, epoch: 9 | loss: 0.1024707\n",
      "\tspeed: 0.0187s/iter; left time: 46.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1020090 Vali Loss: 0.1216672 Test Loss: 0.1507545\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1014575\n",
      "\tspeed: 0.0414s/iter; left time: 97.4141s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068425\n",
      "\tspeed: 0.0186s/iter; left time: 41.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.1013790 Vali Loss: 0.1224590 Test Loss: 0.1511485\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1007545\n",
      "\tspeed: 0.0361s/iter; left time: 76.9678s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064068\n",
      "\tspeed: 0.0181s/iter; left time: 36.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1008511 Vali Loss: 0.1220196 Test Loss: 0.1480358\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996748\n",
      "\tspeed: 0.0388s/iter; left time: 74.0453s\n",
      "\titers: 200, epoch: 12 | loss: 0.1018326\n",
      "\tspeed: 0.0189s/iter; left time: 34.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1003750 Vali Loss: 0.1224540 Test Loss: 0.1507005\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045974038541316986, rmse:0.21441558003425598, mae:0.14811687171459198, rse:0.7434096336364746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1442559\n",
      "\tspeed: 0.0243s/iter; left time: 106.1808s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326391\n",
      "\tspeed: 0.0216s/iter; left time: 92.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.1444806 Vali Loss: 0.1397840 Test Loss: 0.1651134\n",
      "Validation loss decreased (inf --> 0.139784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1153733\n",
      "\tspeed: 0.0416s/iter; left time: 172.0214s\n",
      "\titers: 200, epoch: 2 | loss: 0.1158109\n",
      "\tspeed: 0.0206s/iter; left time: 82.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1152481 Vali Loss: 0.1229677 Test Loss: 0.1469946\n",
      "Validation loss decreased (0.139784 --> 0.122968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091751\n",
      "\tspeed: 0.0368s/iter; left time: 144.1029s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076952\n",
      "\tspeed: 0.0156s/iter; left time: 59.3233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1093861 Vali Loss: 0.1221740 Test Loss: 0.1474206\n",
      "Validation loss decreased (0.122968 --> 0.122174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1105811\n",
      "\tspeed: 0.0360s/iter; left time: 132.7568s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094957\n",
      "\tspeed: 0.0155s/iter; left time: 55.5114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1075535 Vali Loss: 0.1213268 Test Loss: 0.1465728\n",
      "Validation loss decreased (0.122174 --> 0.121327).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1022354\n",
      "\tspeed: 0.0436s/iter; left time: 151.1733s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052392\n",
      "\tspeed: 0.0181s/iter; left time: 61.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1060023 Vali Loss: 0.1212835 Test Loss: 0.1484088\n",
      "Validation loss decreased (0.121327 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052048\n",
      "\tspeed: 0.0445s/iter; left time: 144.3411s\n",
      "\titers: 200, epoch: 6 | loss: 0.1029654\n",
      "\tspeed: 0.0177s/iter; left time: 55.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1045905 Vali Loss: 0.1220015 Test Loss: 0.1495936\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1045707\n",
      "\tspeed: 0.0430s/iter; left time: 129.9057s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025629\n",
      "\tspeed: 0.0222s/iter; left time: 64.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.1034090 Vali Loss: 0.1213634 Test Loss: 0.1484459\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1005384\n",
      "\tspeed: 0.0391s/iter; left time: 109.3929s\n",
      "\titers: 200, epoch: 8 | loss: 0.1052553\n",
      "\tspeed: 0.0180s/iter; left time: 48.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.1025041 Vali Loss: 0.1215598 Test Loss: 0.1484736\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1018901\n",
      "\tspeed: 0.0399s/iter; left time: 102.9456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990130\n",
      "\tspeed: 0.0174s/iter; left time: 43.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1017117 Vali Loss: 0.1214209 Test Loss: 0.1495841\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0977279\n",
      "\tspeed: 0.0411s/iter; left time: 96.6954s\n",
      "\titers: 200, epoch: 10 | loss: 0.0962834\n",
      "\tspeed: 0.0192s/iter; left time: 43.3529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1010290 Vali Loss: 0.1213298 Test Loss: 0.1499632\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04563125967979431, rmse:0.21361474692821503, mae:0.14840884506702423, rse:0.7406330108642578\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:20.19s\n",
      "Intermediate time for GB: 00h:08m:28.92s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1472617\n",
      "\tspeed: 0.0412s/iter; left time: 180.2869s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270657\n",
      "\tspeed: 0.0127s/iter; left time: 54.5502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1529596 Vali Loss: 0.1144776 Test Loss: 0.1285696\n",
      "Validation loss decreased (inf --> 0.114478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0764008\n",
      "\tspeed: 0.0341s/iter; left time: 141.8398s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672378\n",
      "\tspeed: 0.0179s/iter; left time: 72.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0811919 Vali Loss: 0.0650535 Test Loss: 0.0721725\n",
      "Validation loss decreased (0.114478 --> 0.065053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697924\n",
      "\tspeed: 0.0353s/iter; left time: 138.9887s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655599\n",
      "\tspeed: 0.0138s/iter; left time: 53.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0678223 Vali Loss: 0.0616374 Test Loss: 0.0684299\n",
      "Validation loss decreased (0.065053 --> 0.061637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0617359\n",
      "\tspeed: 0.0341s/iter; left time: 126.3767s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651039\n",
      "\tspeed: 0.0180s/iter; left time: 64.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0643864 Vali Loss: 0.0593651 Test Loss: 0.0659961\n",
      "Validation loss decreased (0.061637 --> 0.059365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612776\n",
      "\tspeed: 0.0348s/iter; left time: 121.1898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621016\n",
      "\tspeed: 0.0161s/iter; left time: 54.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0622860 Vali Loss: 0.0583341 Test Loss: 0.0648153\n",
      "Validation loss decreased (0.059365 --> 0.058334).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601563\n",
      "\tspeed: 0.0374s/iter; left time: 122.1215s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582275\n",
      "\tspeed: 0.0190s/iter; left time: 60.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0573691 Test Loss: 0.0637348\n",
      "Validation loss decreased (0.058334 --> 0.057369).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599583\n",
      "\tspeed: 0.0396s/iter; left time: 120.4027s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620039\n",
      "\tspeed: 0.0201s/iter; left time: 59.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0597635 Vali Loss: 0.0567544 Test Loss: 0.0630717\n",
      "Validation loss decreased (0.057369 --> 0.056754).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591449\n",
      "\tspeed: 0.0396s/iter; left time: 111.3214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0592528\n",
      "\tspeed: 0.0203s/iter; left time: 54.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0589754 Vali Loss: 0.0563358 Test Loss: 0.0625656\n",
      "Validation loss decreased (0.056754 --> 0.056336).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0572533\n",
      "\tspeed: 0.0384s/iter; left time: 99.4849s\n",
      "\titers: 200, epoch: 9 | loss: 0.0543959\n",
      "\tspeed: 0.0196s/iter; left time: 48.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0582308 Vali Loss: 0.0558458 Test Loss: 0.0622937\n",
      "Validation loss decreased (0.056336 --> 0.055846).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586669\n",
      "\tspeed: 0.0363s/iter; left time: 85.8101s\n",
      "\titers: 200, epoch: 10 | loss: 0.0573274\n",
      "\tspeed: 0.0178s/iter; left time: 40.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0577035 Vali Loss: 0.0553874 Test Loss: 0.0618086\n",
      "Validation loss decreased (0.055846 --> 0.055387).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0590035\n",
      "\tspeed: 0.0379s/iter; left time: 81.2151s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585526\n",
      "\tspeed: 0.0204s/iter; left time: 41.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0572359 Vali Loss: 0.0551490 Test Loss: 0.0616998\n",
      "Validation loss decreased (0.055387 --> 0.055149).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0607780\n",
      "\tspeed: 0.0382s/iter; left time: 73.2975s\n",
      "\titers: 200, epoch: 12 | loss: 0.0548319\n",
      "\tspeed: 0.0222s/iter; left time: 40.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0568701 Vali Loss: 0.0549978 Test Loss: 0.0614600\n",
      "Validation loss decreased (0.055149 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575080\n",
      "\tspeed: 0.0389s/iter; left time: 65.8627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571135\n",
      "\tspeed: 0.0204s/iter; left time: 32.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0565177 Vali Loss: 0.0547642 Test Loss: 0.0613089\n",
      "Validation loss decreased (0.054998 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0551755\n",
      "\tspeed: 0.0352s/iter; left time: 51.6431s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569541\n",
      "\tspeed: 0.0184s/iter; left time: 25.2481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0561891 Vali Loss: 0.0546994 Test Loss: 0.0611044\n",
      "Validation loss decreased (0.054764 --> 0.054699).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0515674\n",
      "\tspeed: 0.0373s/iter; left time: 46.4350s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551809\n",
      "\tspeed: 0.0194s/iter; left time: 22.1801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0559423 Vali Loss: 0.0544962 Test Loss: 0.0609704\n",
      "Validation loss decreased (0.054699 --> 0.054496).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0602068\n",
      "\tspeed: 0.0395s/iter; left time: 40.3303s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552587\n",
      "\tspeed: 0.0202s/iter; left time: 18.5892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0557383 Vali Loss: 0.0544265 Test Loss: 0.0608705\n",
      "Validation loss decreased (0.054496 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0534508\n",
      "\tspeed: 0.0394s/iter; left time: 31.3686s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564713\n",
      "\tspeed: 0.0197s/iter; left time: 13.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0555938 Vali Loss: 0.0543226 Test Loss: 0.0608117\n",
      "Validation loss decreased (0.054427 --> 0.054323).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573428\n",
      "\tspeed: 0.0465s/iter; left time: 26.6437s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537848\n",
      "\tspeed: 0.0228s/iter; left time: 10.7701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0554106 Vali Loss: 0.0542706 Test Loss: 0.0606971\n",
      "Validation loss decreased (0.054323 --> 0.054271).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550534\n",
      "\tspeed: 0.0384s/iter; left time: 13.3870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0558107\n",
      "\tspeed: 0.0202s/iter; left time: 5.0294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0552027 Vali Loss: 0.0540916 Test Loss: 0.0605637\n",
      "Validation loss decreased (0.054271 --> 0.054092).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0584598\n",
      "\tspeed: 0.0379s/iter; left time: 4.7429s\n",
      "\titers: 200, epoch: 20 | loss: 0.0512681\n",
      "\tspeed: 0.0166s/iter; left time: 0.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0551428 Vali Loss: 0.0540117 Test Loss: 0.0604790\n",
      "Validation loss decreased (0.054092 --> 0.054012).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009945221245288849, rmse:0.09972573071718216, mae:0.06047904118895531, rse:0.2934807538986206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1553000\n",
      "\tspeed: 0.0218s/iter; left time: 95.3743s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247295\n",
      "\tspeed: 0.0202s/iter; left time: 86.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1551215 Vali Loss: 0.1149629 Test Loss: 0.1298781\n",
      "Validation loss decreased (inf --> 0.114963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0781470\n",
      "\tspeed: 0.0393s/iter; left time: 163.2841s\n",
      "\titers: 200, epoch: 2 | loss: 0.0671686\n",
      "\tspeed: 0.0205s/iter; left time: 83.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0811051 Vali Loss: 0.0649167 Test Loss: 0.0716186\n",
      "Validation loss decreased (0.114963 --> 0.064917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0684837\n",
      "\tspeed: 0.0393s/iter; left time: 154.5540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675542\n",
      "\tspeed: 0.0202s/iter; left time: 77.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0675214 Vali Loss: 0.0610192 Test Loss: 0.0676137\n",
      "Validation loss decreased (0.064917 --> 0.061019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637207\n",
      "\tspeed: 0.0387s/iter; left time: 143.7097s\n",
      "\titers: 200, epoch: 4 | loss: 0.0624713\n",
      "\tspeed: 0.0203s/iter; left time: 73.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0641497 Vali Loss: 0.0590834 Test Loss: 0.0656485\n",
      "Validation loss decreased (0.061019 --> 0.059083).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0607330\n",
      "\tspeed: 0.0377s/iter; left time: 131.3658s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578555\n",
      "\tspeed: 0.0184s/iter; left time: 62.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0619703 Vali Loss: 0.0577241 Test Loss: 0.0642229\n",
      "Validation loss decreased (0.059083 --> 0.057724).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588913\n",
      "\tspeed: 0.0352s/iter; left time: 114.7175s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617361\n",
      "\tspeed: 0.0168s/iter; left time: 52.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0604744 Vali Loss: 0.0567848 Test Loss: 0.0632507\n",
      "Validation loss decreased (0.057724 --> 0.056785).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595140\n",
      "\tspeed: 0.0369s/iter; left time: 111.9496s\n",
      "\titers: 200, epoch: 7 | loss: 0.0564100\n",
      "\tspeed: 0.0180s/iter; left time: 52.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0593902 Vali Loss: 0.0560765 Test Loss: 0.0625553\n",
      "Validation loss decreased (0.056785 --> 0.056077).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591547\n",
      "\tspeed: 0.0396s/iter; left time: 111.2926s\n",
      "\titers: 200, epoch: 8 | loss: 0.0573535\n",
      "\tspeed: 0.0201s/iter; left time: 54.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0585845 Vali Loss: 0.0560133 Test Loss: 0.0626201\n",
      "Validation loss decreased (0.056077 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578105\n",
      "\tspeed: 0.0419s/iter; left time: 108.5637s\n",
      "\titers: 200, epoch: 9 | loss: 0.0604850\n",
      "\tspeed: 0.0222s/iter; left time: 55.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0579322 Vali Loss: 0.0554106 Test Loss: 0.0619923\n",
      "Validation loss decreased (0.056013 --> 0.055411).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0556527\n",
      "\tspeed: 0.0443s/iter; left time: 104.6548s\n",
      "\titers: 200, epoch: 10 | loss: 0.0583164\n",
      "\tspeed: 0.0252s/iter; left time: 56.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0574518 Vali Loss: 0.0549543 Test Loss: 0.0615554\n",
      "Validation loss decreased (0.055411 --> 0.054954).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0548618\n",
      "\tspeed: 0.0438s/iter; left time: 93.8771s\n",
      "\titers: 200, epoch: 11 | loss: 0.0545545\n",
      "\tspeed: 0.0245s/iter; left time: 50.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0569497 Vali Loss: 0.0548729 Test Loss: 0.0612393\n",
      "Validation loss decreased (0.054954 --> 0.054873).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0544791\n",
      "\tspeed: 0.0435s/iter; left time: 83.3301s\n",
      "\titers: 200, epoch: 12 | loss: 0.0538325\n",
      "\tspeed: 0.0212s/iter; left time: 38.5365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0566214 Vali Loss: 0.0546680 Test Loss: 0.0612363\n",
      "Validation loss decreased (0.054873 --> 0.054668).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540088\n",
      "\tspeed: 0.0411s/iter; left time: 69.5690s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555825\n",
      "\tspeed: 0.0197s/iter; left time: 31.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0563721 Vali Loss: 0.0545967 Test Loss: 0.0610147\n",
      "Validation loss decreased (0.054668 --> 0.054597).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0573891\n",
      "\tspeed: 0.0397s/iter; left time: 58.3791s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538194\n",
      "\tspeed: 0.0209s/iter; left time: 28.5463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0560146 Vali Loss: 0.0544852 Test Loss: 0.0608968\n",
      "Validation loss decreased (0.054597 --> 0.054485).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0551107\n",
      "\tspeed: 0.0395s/iter; left time: 49.1692s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553436\n",
      "\tspeed: 0.0202s/iter; left time: 23.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0558149 Vali Loss: 0.0543989 Test Loss: 0.0609039\n",
      "Validation loss decreased (0.054485 --> 0.054399).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0507123\n",
      "\tspeed: 0.0388s/iter; left time: 39.6474s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580228\n",
      "\tspeed: 0.0203s/iter; left time: 18.6932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0556427 Vali Loss: 0.0542605 Test Loss: 0.0608238\n",
      "Validation loss decreased (0.054399 --> 0.054260).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570526\n",
      "\tspeed: 0.0407s/iter; left time: 32.4210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0551444\n",
      "\tspeed: 0.0195s/iter; left time: 13.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0554497 Vali Loss: 0.0540213 Test Loss: 0.0604897\n",
      "Validation loss decreased (0.054260 --> 0.054021).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570715\n",
      "\tspeed: 0.0388s/iter; left time: 22.2410s\n",
      "\titers: 200, epoch: 18 | loss: 0.0547936\n",
      "\tspeed: 0.0203s/iter; left time: 9.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0552571 Vali Loss: 0.0539653 Test Loss: 0.0604616\n",
      "Validation loss decreased (0.054021 --> 0.053965).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0549879\n",
      "\tspeed: 0.0391s/iter; left time: 13.6577s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532886\n",
      "\tspeed: 0.0202s/iter; left time: 5.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0551491 Vali Loss: 0.0540239 Test Loss: 0.0605049\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0501008\n",
      "\tspeed: 0.0385s/iter; left time: 4.8098s\n",
      "\titers: 200, epoch: 20 | loss: 0.0541760\n",
      "\tspeed: 0.0200s/iter; left time: 0.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0550170 Vali Loss: 0.0539391 Test Loss: 0.0604577\n",
      "Validation loss decreased (0.053965 --> 0.053939).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009968351572751999, rmse:0.0998416319489479, mae:0.060457728803157806, rse:0.2938218414783478\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:04.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1598105\n",
      "\tspeed: 0.0401s/iter; left time: 175.4931s\n",
      "\titers: 200, epoch: 1 | loss: 0.1323677\n",
      "\tspeed: 0.0112s/iter; left time: 47.9993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.1563091 Vali Loss: 0.1220054 Test Loss: 0.1378020\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989023\n",
      "\tspeed: 0.0328s/iter; left time: 136.3720s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922406\n",
      "\tspeed: 0.0158s/iter; left time: 63.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0986842 Vali Loss: 0.0867798 Test Loss: 0.0978109\n",
      "Validation loss decreased (0.122005 --> 0.086780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870436\n",
      "\tspeed: 0.0340s/iter; left time: 133.7073s\n",
      "\titers: 200, epoch: 3 | loss: 0.0854841\n",
      "\tspeed: 0.0159s/iter; left time: 60.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0874289 Vali Loss: 0.0815691 Test Loss: 0.0928535\n",
      "Validation loss decreased (0.086780 --> 0.081569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0864892\n",
      "\tspeed: 0.0353s/iter; left time: 131.0243s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789671\n",
      "\tspeed: 0.0178s/iter; left time: 64.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0836981 Vali Loss: 0.0796518 Test Loss: 0.0907823\n",
      "Validation loss decreased (0.081569 --> 0.079652).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813103\n",
      "\tspeed: 0.0408s/iter; left time: 142.0285s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827484\n",
      "\tspeed: 0.0219s/iter; left time: 74.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0816990 Vali Loss: 0.0787125 Test Loss: 0.0895975\n",
      "Validation loss decreased (0.079652 --> 0.078713).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800737\n",
      "\tspeed: 0.0395s/iter; left time: 128.9424s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752990\n",
      "\tspeed: 0.0188s/iter; left time: 59.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0803113 Vali Loss: 0.0778247 Test Loss: 0.0889565\n",
      "Validation loss decreased (0.078713 --> 0.077825).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789210\n",
      "\tspeed: 0.0391s/iter; left time: 118.6672s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756818\n",
      "\tspeed: 0.0196s/iter; left time: 57.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0792497 Vali Loss: 0.0773080 Test Loss: 0.0883113\n",
      "Validation loss decreased (0.077825 --> 0.077308).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0813592\n",
      "\tspeed: 0.0396s/iter; left time: 111.4328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797191\n",
      "\tspeed: 0.0199s/iter; left time: 54.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0784300 Vali Loss: 0.0769897 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.077308 --> 0.076990).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778591\n",
      "\tspeed: 0.0396s/iter; left time: 102.4201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800109\n",
      "\tspeed: 0.0200s/iter; left time: 49.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0777183 Vali Loss: 0.0771957 Test Loss: 0.0878055\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0771751\n",
      "\tspeed: 0.0381s/iter; left time: 90.0467s\n",
      "\titers: 200, epoch: 10 | loss: 0.0770075\n",
      "\tspeed: 0.0202s/iter; left time: 45.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0771960 Vali Loss: 0.0773262 Test Loss: 0.0880145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753757\n",
      "\tspeed: 0.0431s/iter; left time: 92.1770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774721\n",
      "\tspeed: 0.0223s/iter; left time: 45.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0767264 Vali Loss: 0.0769818 Test Loss: 0.0878005\n",
      "Validation loss decreased (0.076990 --> 0.076982).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767876\n",
      "\tspeed: 0.0367s/iter; left time: 70.4280s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779550\n",
      "\tspeed: 0.0195s/iter; left time: 35.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0763607 Vali Loss: 0.0771153 Test Loss: 0.0876895\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749844\n",
      "\tspeed: 0.0345s/iter; left time: 58.4263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752065\n",
      "\tspeed: 0.0190s/iter; left time: 30.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0760326 Vali Loss: 0.0774750 Test Loss: 0.0875740\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715508\n",
      "\tspeed: 0.0392s/iter; left time: 57.5459s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734959\n",
      "\tspeed: 0.0201s/iter; left time: 27.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0756991 Vali Loss: 0.0771718 Test Loss: 0.0875562\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778454\n",
      "\tspeed: 0.0388s/iter; left time: 48.3257s\n",
      "\titers: 200, epoch: 15 | loss: 0.0767315\n",
      "\tspeed: 0.0198s/iter; left time: 22.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0753907 Vali Loss: 0.0773028 Test Loss: 0.0875162\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736728\n",
      "\tspeed: 0.0419s/iter; left time: 42.8196s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731484\n",
      "\tspeed: 0.0185s/iter; left time: 17.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0752085 Vali Loss: 0.0774523 Test Loss: 0.0875667\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01882317289710045, rmse:0.1371975690126419, mae:0.08780049532651901, rse:0.4030451774597168\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1586675\n",
      "\tspeed: 0.0271s/iter; left time: 118.7130s\n",
      "\titers: 200, epoch: 1 | loss: 0.1347368\n",
      "\tspeed: 0.0205s/iter; left time: 87.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1596458 Vali Loss: 0.1252369 Test Loss: 0.1413600\n",
      "Validation loss decreased (inf --> 0.125237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0973105\n",
      "\tspeed: 0.0405s/iter; left time: 168.4245s\n",
      "\titers: 200, epoch: 2 | loss: 0.0919715\n",
      "\tspeed: 0.0176s/iter; left time: 71.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0987873 Vali Loss: 0.0861882 Test Loss: 0.0971636\n",
      "Validation loss decreased (0.125237 --> 0.086188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0884451\n",
      "\tspeed: 0.0405s/iter; left time: 159.3633s\n",
      "\titers: 200, epoch: 3 | loss: 0.0845339\n",
      "\tspeed: 0.0193s/iter; left time: 74.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0872112 Vali Loss: 0.0814862 Test Loss: 0.0928255\n",
      "Validation loss decreased (0.086188 --> 0.081486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0833561\n",
      "\tspeed: 0.0403s/iter; left time: 149.6523s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797457\n",
      "\tspeed: 0.0198s/iter; left time: 71.4450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0836548 Vali Loss: 0.0792064 Test Loss: 0.0904651\n",
      "Validation loss decreased (0.081486 --> 0.079206).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833495\n",
      "\tspeed: 0.0374s/iter; left time: 130.3644s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785904\n",
      "\tspeed: 0.0191s/iter; left time: 64.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0815392 Vali Loss: 0.0780693 Test Loss: 0.0891974\n",
      "Validation loss decreased (0.079206 --> 0.078069).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0823942\n",
      "\tspeed: 0.0445s/iter; left time: 145.1038s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776357\n",
      "\tspeed: 0.0198s/iter; left time: 62.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0802429 Vali Loss: 0.0776718 Test Loss: 0.0885830\n",
      "Validation loss decreased (0.078069 --> 0.077672).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760843\n",
      "\tspeed: 0.0387s/iter; left time: 117.5909s\n",
      "\titers: 200, epoch: 7 | loss: 0.0813600\n",
      "\tspeed: 0.0194s/iter; left time: 57.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0792072 Vali Loss: 0.0770249 Test Loss: 0.0881912\n",
      "Validation loss decreased (0.077672 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847419\n",
      "\tspeed: 0.0442s/iter; left time: 124.3475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0802124\n",
      "\tspeed: 0.0202s/iter; left time: 54.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0783518 Vali Loss: 0.0768772 Test Loss: 0.0881146\n",
      "Validation loss decreased (0.077025 --> 0.076877).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780947\n",
      "\tspeed: 0.0400s/iter; left time: 103.5116s\n",
      "\titers: 200, epoch: 9 | loss: 0.0782000\n",
      "\tspeed: 0.0206s/iter; left time: 51.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0777154 Vali Loss: 0.0767927 Test Loss: 0.0879633\n",
      "Validation loss decreased (0.076877 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743289\n",
      "\tspeed: 0.0382s/iter; left time: 90.3251s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774140\n",
      "\tspeed: 0.0198s/iter; left time: 44.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0771349 Vali Loss: 0.0765736 Test Loss: 0.0879690\n",
      "Validation loss decreased (0.076793 --> 0.076574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775898\n",
      "\tspeed: 0.0400s/iter; left time: 85.5925s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786252\n",
      "\tspeed: 0.0203s/iter; left time: 41.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0767193 Vali Loss: 0.0769068 Test Loss: 0.0878833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767183\n",
      "\tspeed: 0.0392s/iter; left time: 75.1352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0758710\n",
      "\tspeed: 0.0208s/iter; left time: 37.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0762718 Vali Loss: 0.0762427 Test Loss: 0.0877495\n",
      "Validation loss decreased (0.076574 --> 0.076243).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757547\n",
      "\tspeed: 0.0451s/iter; left time: 76.3469s\n",
      "\titers: 200, epoch: 13 | loss: 0.0753049\n",
      "\tspeed: 0.0209s/iter; left time: 33.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0758764 Vali Loss: 0.0763160 Test Loss: 0.0877484\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0757037\n",
      "\tspeed: 0.0426s/iter; left time: 62.5372s\n",
      "\titers: 200, epoch: 14 | loss: 0.0765146\n",
      "\tspeed: 0.0172s/iter; left time: 23.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0755893 Vali Loss: 0.0764946 Test Loss: 0.0880358\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745211\n",
      "\tspeed: 0.0357s/iter; left time: 44.4092s\n",
      "\titers: 200, epoch: 15 | loss: 0.0719035\n",
      "\tspeed: 0.0177s/iter; left time: 20.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0753161 Vali Loss: 0.0766544 Test Loss: 0.0879934\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719958\n",
      "\tspeed: 0.0393s/iter; left time: 40.0923s\n",
      "\titers: 200, epoch: 16 | loss: 0.0726158\n",
      "\tspeed: 0.0177s/iter; left time: 16.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0750091 Vali Loss: 0.0767697 Test Loss: 0.0880393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0725779\n",
      "\tspeed: 0.0372s/iter; left time: 29.6675s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759026\n",
      "\tspeed: 0.0203s/iter; left time: 14.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0748258 Vali Loss: 0.0764923 Test Loss: 0.0879672\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018933413550257683, rmse:0.13759873807430267, mae:0.08774946630001068, rse:0.4042236804962158\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:24.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588590\n",
      "\tspeed: 0.0390s/iter; left time: 170.1002s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345927\n",
      "\tspeed: 0.0105s/iter; left time: 44.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.1578327 Vali Loss: 0.1251587 Test Loss: 0.1401146\n",
      "Validation loss decreased (inf --> 0.125159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031658\n",
      "\tspeed: 0.0318s/iter; left time: 131.4311s\n",
      "\titers: 200, epoch: 2 | loss: 0.0960442\n",
      "\tspeed: 0.0125s/iter; left time: 50.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.1027083 Vali Loss: 0.0920010 Test Loss: 0.1034549\n",
      "Validation loss decreased (0.125159 --> 0.092001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925628\n",
      "\tspeed: 0.0389s/iter; left time: 152.3651s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885058\n",
      "\tspeed: 0.0184s/iter; left time: 70.1950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0920447 Vali Loss: 0.0870601 Test Loss: 0.0977339\n",
      "Validation loss decreased (0.092001 --> 0.087060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0894964\n",
      "\tspeed: 0.0351s/iter; left time: 129.4850s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878705\n",
      "\tspeed: 0.0167s/iter; left time: 59.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0885116 Vali Loss: 0.0853489 Test Loss: 0.0955454\n",
      "Validation loss decreased (0.087060 --> 0.085349).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861767\n",
      "\tspeed: 0.0375s/iter; left time: 129.9464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893044\n",
      "\tspeed: 0.0167s/iter; left time: 56.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0865645 Vali Loss: 0.0847000 Test Loss: 0.0949086\n",
      "Validation loss decreased (0.085349 --> 0.084700).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860761\n",
      "\tspeed: 0.0364s/iter; left time: 118.2401s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822750\n",
      "\tspeed: 0.0170s/iter; left time: 53.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0852246 Vali Loss: 0.0838490 Test Loss: 0.0941687\n",
      "Validation loss decreased (0.084700 --> 0.083849).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844567\n",
      "\tspeed: 0.0330s/iter; left time: 99.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0868250\n",
      "\tspeed: 0.0171s/iter; left time: 49.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0841996 Vali Loss: 0.0832387 Test Loss: 0.0941152\n",
      "Validation loss decreased (0.083849 --> 0.083239).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873774\n",
      "\tspeed: 0.0384s/iter; left time: 107.5862s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820005\n",
      "\tspeed: 0.0178s/iter; left time: 48.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0833750 Vali Loss: 0.0830650 Test Loss: 0.0936024\n",
      "Validation loss decreased (0.083239 --> 0.083065).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829483\n",
      "\tspeed: 0.0353s/iter; left time: 91.0256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805004\n",
      "\tspeed: 0.0171s/iter; left time: 42.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0827375 Vali Loss: 0.0830914 Test Loss: 0.0932296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832330\n",
      "\tspeed: 0.0341s/iter; left time: 80.3511s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844381\n",
      "\tspeed: 0.0193s/iter; left time: 43.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0821893 Vali Loss: 0.0831509 Test Loss: 0.0935011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838833\n",
      "\tspeed: 0.0356s/iter; left time: 75.8287s\n",
      "\titers: 200, epoch: 11 | loss: 0.0842650\n",
      "\tspeed: 0.0179s/iter; left time: 36.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0816421 Vali Loss: 0.0830360 Test Loss: 0.0937280\n",
      "Validation loss decreased (0.083065 --> 0.083036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819793\n",
      "\tspeed: 0.0359s/iter; left time: 68.4249s\n",
      "\titers: 200, epoch: 12 | loss: 0.0781054\n",
      "\tspeed: 0.0185s/iter; left time: 33.4094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0812782 Vali Loss: 0.0829809 Test Loss: 0.0936222\n",
      "Validation loss decreased (0.083036 --> 0.082981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817220\n",
      "\tspeed: 0.0331s/iter; left time: 55.7969s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826705\n",
      "\tspeed: 0.0179s/iter; left time: 28.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0808690 Vali Loss: 0.0833226 Test Loss: 0.0937399\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822457\n",
      "\tspeed: 0.0367s/iter; left time: 53.6800s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779094\n",
      "\tspeed: 0.0189s/iter; left time: 25.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0806014 Vali Loss: 0.0836196 Test Loss: 0.0937464\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0783274\n",
      "\tspeed: 0.0392s/iter; left time: 48.5249s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781628\n",
      "\tspeed: 0.0198s/iter; left time: 22.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0802118 Vali Loss: 0.0835069 Test Loss: 0.0935566\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785731\n",
      "\tspeed: 0.0347s/iter; left time: 35.2629s\n",
      "\titers: 200, epoch: 16 | loss: 0.0764296\n",
      "\tspeed: 0.0178s/iter; left time: 16.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0798898 Vali Loss: 0.0836725 Test Loss: 0.0937837\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801015\n",
      "\tspeed: 0.0375s/iter; left time: 29.7033s\n",
      "\titers: 200, epoch: 17 | loss: 0.0836306\n",
      "\tspeed: 0.0213s/iter; left time: 14.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0796882 Vali Loss: 0.0840067 Test Loss: 0.0938545\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0211891271173954, rmse:0.14556485414505005, mae:0.093622125685215, rse:0.4276564419269562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1613069\n",
      "\tspeed: 0.0216s/iter; left time: 94.2873s\n",
      "\titers: 200, epoch: 1 | loss: 0.1376596\n",
      "\tspeed: 0.0189s/iter; left time: 80.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1605535 Vali Loss: 0.1269490 Test Loss: 0.1422556\n",
      "Validation loss decreased (inf --> 0.126949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1013645\n",
      "\tspeed: 0.0366s/iter; left time: 151.3121s\n",
      "\titers: 200, epoch: 2 | loss: 0.0963595\n",
      "\tspeed: 0.0184s/iter; left time: 74.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1028532 Vali Loss: 0.0920172 Test Loss: 0.1033752\n",
      "Validation loss decreased (0.126949 --> 0.092017).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0923068\n",
      "\tspeed: 0.0366s/iter; left time: 143.3538s\n",
      "\titers: 200, epoch: 3 | loss: 0.0933995\n",
      "\tspeed: 0.0185s/iter; left time: 70.3984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0920053 Vali Loss: 0.0868958 Test Loss: 0.0977857\n",
      "Validation loss decreased (0.092017 --> 0.086896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0858119\n",
      "\tspeed: 0.0430s/iter; left time: 158.6773s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876705\n",
      "\tspeed: 0.0192s/iter; left time: 68.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0883205 Vali Loss: 0.0854360 Test Loss: 0.0955178\n",
      "Validation loss decreased (0.086896 --> 0.085436).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0846782\n",
      "\tspeed: 0.0382s/iter; left time: 132.3570s\n",
      "\titers: 200, epoch: 5 | loss: 0.0885914\n",
      "\tspeed: 0.0180s/iter; left time: 60.6612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0863524 Vali Loss: 0.0841903 Test Loss: 0.0947642\n",
      "Validation loss decreased (0.085436 --> 0.084190).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860462\n",
      "\tspeed: 0.0398s/iter; left time: 129.1049s\n",
      "\titers: 200, epoch: 6 | loss: 0.0850799\n",
      "\tspeed: 0.0223s/iter; left time: 70.2094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0849439 Vali Loss: 0.0839054 Test Loss: 0.0941740\n",
      "Validation loss decreased (0.084190 --> 0.083905).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0822197\n",
      "\tspeed: 0.0412s/iter; left time: 124.5215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831921\n",
      "\tspeed: 0.0193s/iter; left time: 56.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0839672 Vali Loss: 0.0835641 Test Loss: 0.0939951\n",
      "Validation loss decreased (0.083905 --> 0.083564).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825832\n",
      "\tspeed: 0.0352s/iter; left time: 98.5133s\n",
      "\titers: 200, epoch: 8 | loss: 0.0844896\n",
      "\tspeed: 0.0184s/iter; left time: 49.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0831400 Vali Loss: 0.0830377 Test Loss: 0.0934263\n",
      "Validation loss decreased (0.083564 --> 0.083038).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0794877\n",
      "\tspeed: 0.0357s/iter; left time: 92.0337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0802455\n",
      "\tspeed: 0.0206s/iter; left time: 50.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0824504 Vali Loss: 0.0834601 Test Loss: 0.0937234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0830448\n",
      "\tspeed: 0.0444s/iter; left time: 104.4685s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812443\n",
      "\tspeed: 0.0216s/iter; left time: 48.7848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0818277 Vali Loss: 0.0833150 Test Loss: 0.0936633\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0829920\n",
      "\tspeed: 0.0388s/iter; left time: 82.6933s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791270\n",
      "\tspeed: 0.0178s/iter; left time: 36.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0813303 Vali Loss: 0.0831595 Test Loss: 0.0931381\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840791\n",
      "\tspeed: 0.0352s/iter; left time: 67.2430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801293\n",
      "\tspeed: 0.0218s/iter; left time: 39.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0808497 Vali Loss: 0.0831188 Test Loss: 0.0932104\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802847\n",
      "\tspeed: 0.0392s/iter; left time: 66.0855s\n",
      "\titers: 200, epoch: 13 | loss: 0.0823523\n",
      "\tspeed: 0.0186s/iter; left time: 29.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0804999 Vali Loss: 0.0834482 Test Loss: 0.0932803\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020786510780453682, rmse:0.14417527616024017, mae:0.09342631697654724, rse:0.4235740005970001\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:57.19s\n",
      "Intermediate time for ES: 00h:10m:25.68s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1097015\n",
      "\tspeed: 0.0418s/iter; left time: 183.0207s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887853\n",
      "\tspeed: 0.0121s/iter; left time: 51.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1121289 Vali Loss: 0.0946256 Test Loss: 0.1039862\n",
      "Validation loss decreased (inf --> 0.094626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534826\n",
      "\tspeed: 0.0280s/iter; left time: 116.2360s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533698\n",
      "\tspeed: 0.0118s/iter; left time: 47.9502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0595254 Vali Loss: 0.0593359 Test Loss: 0.0626762\n",
      "Validation loss decreased (0.094626 --> 0.059336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0492144\n",
      "\tspeed: 0.0315s/iter; left time: 123.8111s\n",
      "\titers: 200, epoch: 3 | loss: 0.0486399\n",
      "\tspeed: 0.0181s/iter; left time: 69.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0507849 Vali Loss: 0.0569176 Test Loss: 0.0601328\n",
      "Validation loss decreased (0.059336 --> 0.056918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0484496\n",
      "\tspeed: 0.0319s/iter; left time: 118.1421s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481661\n",
      "\tspeed: 0.0120s/iter; left time: 43.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 224 | Train Loss: 0.0485986 Vali Loss: 0.0556101 Test Loss: 0.0590208\n",
      "Validation loss decreased (0.056918 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467192\n",
      "\tspeed: 0.0272s/iter; left time: 94.8465s\n",
      "\titers: 200, epoch: 5 | loss: 0.0484249\n",
      "\tspeed: 0.0159s/iter; left time: 53.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 224 | Train Loss: 0.0472493 Vali Loss: 0.0546849 Test Loss: 0.0583969\n",
      "Validation loss decreased (0.055610 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0475310\n",
      "\tspeed: 0.0342s/iter; left time: 111.6001s\n",
      "\titers: 200, epoch: 6 | loss: 0.0457387\n",
      "\tspeed: 0.0168s/iter; left time: 52.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462754 Vali Loss: 0.0535959 Test Loss: 0.0575769\n",
      "Validation loss decreased (0.054685 --> 0.053596).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0468816\n",
      "\tspeed: 0.0354s/iter; left time: 107.3717s\n",
      "\titers: 200, epoch: 7 | loss: 0.0452926\n",
      "\tspeed: 0.0177s/iter; left time: 51.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0455841 Vali Loss: 0.0534057 Test Loss: 0.0573068\n",
      "Validation loss decreased (0.053596 --> 0.053406).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0474218\n",
      "\tspeed: 0.0393s/iter; left time: 110.6386s\n",
      "\titers: 200, epoch: 8 | loss: 0.0434757\n",
      "\tspeed: 0.0220s/iter; left time: 59.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0450097 Vali Loss: 0.0531013 Test Loss: 0.0570163\n",
      "Validation loss decreased (0.053406 --> 0.053101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0466082\n",
      "\tspeed: 0.0365s/iter; left time: 94.6244s\n",
      "\titers: 200, epoch: 9 | loss: 0.0406892\n",
      "\tspeed: 0.0166s/iter; left time: 41.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0445724 Vali Loss: 0.0529589 Test Loss: 0.0571137\n",
      "Validation loss decreased (0.053101 --> 0.052959).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0472855\n",
      "\tspeed: 0.0346s/iter; left time: 81.8903s\n",
      "\titers: 200, epoch: 10 | loss: 0.0445645\n",
      "\tspeed: 0.0166s/iter; left time: 37.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0441734 Vali Loss: 0.0526272 Test Loss: 0.0568700\n",
      "Validation loss decreased (0.052959 --> 0.052627).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434398\n",
      "\tspeed: 0.0379s/iter; left time: 81.0601s\n",
      "\titers: 200, epoch: 11 | loss: 0.0426368\n",
      "\tspeed: 0.0180s/iter; left time: 36.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0438455 Vali Loss: 0.0523278 Test Loss: 0.0564668\n",
      "Validation loss decreased (0.052627 --> 0.052328).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0431309\n",
      "\tspeed: 0.0389s/iter; left time: 74.5463s\n",
      "\titers: 200, epoch: 12 | loss: 0.0433577\n",
      "\tspeed: 0.0198s/iter; left time: 35.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0436222 Vali Loss: 0.0522362 Test Loss: 0.0562486\n",
      "Validation loss decreased (0.052328 --> 0.052236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0426902\n",
      "\tspeed: 0.0365s/iter; left time: 61.8587s\n",
      "\titers: 200, epoch: 13 | loss: 0.0428892\n",
      "\tspeed: 0.0197s/iter; left time: 31.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0433593 Vali Loss: 0.0520524 Test Loss: 0.0562706\n",
      "Validation loss decreased (0.052236 --> 0.052052).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0434505\n",
      "\tspeed: 0.0392s/iter; left time: 57.6252s\n",
      "\titers: 200, epoch: 14 | loss: 0.0460396\n",
      "\tspeed: 0.0163s/iter; left time: 22.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0431982 Vali Loss: 0.0523667 Test Loss: 0.0561814\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0428227\n",
      "\tspeed: 0.0342s/iter; left time: 42.6195s\n",
      "\titers: 200, epoch: 15 | loss: 0.0418219\n",
      "\tspeed: 0.0181s/iter; left time: 20.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0429733 Vali Loss: 0.0519710 Test Loss: 0.0561296\n",
      "Validation loss decreased (0.052052 --> 0.051971).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0426776\n",
      "\tspeed: 0.0362s/iter; left time: 37.0093s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441703\n",
      "\tspeed: 0.0165s/iter; left time: 15.1767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0428724 Vali Loss: 0.0518400 Test Loss: 0.0559802\n",
      "Validation loss decreased (0.051971 --> 0.051840).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0421949\n",
      "\tspeed: 0.0373s/iter; left time: 29.6885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410631\n",
      "\tspeed: 0.0199s/iter; left time: 13.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0427084 Vali Loss: 0.0517573 Test Loss: 0.0560051\n",
      "Validation loss decreased (0.051840 --> 0.051757).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443506\n",
      "\tspeed: 0.0380s/iter; left time: 21.7822s\n",
      "\titers: 200, epoch: 18 | loss: 0.0417061\n",
      "\tspeed: 0.0198s/iter; left time: 9.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0425945 Vali Loss: 0.0517659 Test Loss: 0.0559824\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0399689\n",
      "\tspeed: 0.0365s/iter; left time: 12.7271s\n",
      "\titers: 200, epoch: 19 | loss: 0.0442903\n",
      "\tspeed: 0.0184s/iter; left time: 4.5755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0424989 Vali Loss: 0.0516519 Test Loss: 0.0558209\n",
      "Validation loss decreased (0.051757 --> 0.051652).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0412286\n",
      "\tspeed: 0.0379s/iter; left time: 4.7428s\n",
      "\titers: 200, epoch: 20 | loss: 0.0390507\n",
      "\tspeed: 0.0206s/iter; left time: 0.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0423428 Vali Loss: 0.0516512 Test Loss: 0.0557739\n",
      "Validation loss decreased (0.051652 --> 0.051651).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010127558372914791, rmse:0.10063577443361282, mae:0.05577389523386955, rse:0.3882500231266022\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1160067\n",
      "\tspeed: 0.0248s/iter; left time: 108.4927s\n",
      "\titers: 200, epoch: 1 | loss: 0.0896998\n",
      "\tspeed: 0.0222s/iter; left time: 95.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.1133017 Vali Loss: 0.0950022 Test Loss: 0.1035725\n",
      "Validation loss decreased (inf --> 0.095002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0571048\n",
      "\tspeed: 0.0418s/iter; left time: 173.7424s\n",
      "\titers: 200, epoch: 2 | loss: 0.0530564\n",
      "\tspeed: 0.0220s/iter; left time: 89.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0595543 Vali Loss: 0.0592502 Test Loss: 0.0625376\n",
      "Validation loss decreased (0.095002 --> 0.059250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0534265\n",
      "\tspeed: 0.0389s/iter; left time: 152.9520s\n",
      "\titers: 200, epoch: 3 | loss: 0.0487475\n",
      "\tspeed: 0.0242s/iter; left time: 92.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0507634 Vali Loss: 0.0569950 Test Loss: 0.0602884\n",
      "Validation loss decreased (0.059250 --> 0.056995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0486558\n",
      "\tspeed: 0.0402s/iter; left time: 149.1860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0471254\n",
      "\tspeed: 0.0218s/iter; left time: 78.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0485903 Vali Loss: 0.0554169 Test Loss: 0.0591204\n",
      "Validation loss decreased (0.056995 --> 0.055417).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0482533\n",
      "\tspeed: 0.0437s/iter; left time: 152.1902s\n",
      "\titers: 200, epoch: 5 | loss: 0.0455832\n",
      "\tspeed: 0.0207s/iter; left time: 70.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0472082 Vali Loss: 0.0548215 Test Loss: 0.0586890\n",
      "Validation loss decreased (0.055417 --> 0.054821).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0467923\n",
      "\tspeed: 0.0399s/iter; left time: 130.0907s\n",
      "\titers: 200, epoch: 6 | loss: 0.0442353\n",
      "\tspeed: 0.0205s/iter; left time: 64.8370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0461966 Vali Loss: 0.0540250 Test Loss: 0.0578917\n",
      "Validation loss decreased (0.054821 --> 0.054025).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0450493\n",
      "\tspeed: 0.0418s/iter; left time: 127.0740s\n",
      "\titers: 200, epoch: 7 | loss: 0.0467357\n",
      "\tspeed: 0.0245s/iter; left time: 71.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0455368 Vali Loss: 0.0533868 Test Loss: 0.0574734\n",
      "Validation loss decreased (0.054025 --> 0.053387).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449342\n",
      "\tspeed: 0.0441s/iter; left time: 124.1939s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489492\n",
      "\tspeed: 0.0190s/iter; left time: 51.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0449747 Vali Loss: 0.0531140 Test Loss: 0.0571540\n",
      "Validation loss decreased (0.053387 --> 0.053114).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0450995\n",
      "\tspeed: 0.0429s/iter; left time: 111.0425s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439877\n",
      "\tspeed: 0.0204s/iter; left time: 50.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0445141 Vali Loss: 0.0529351 Test Loss: 0.0570621\n",
      "Validation loss decreased (0.053114 --> 0.052935).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441738\n",
      "\tspeed: 0.0391s/iter; left time: 92.5075s\n",
      "\titers: 200, epoch: 10 | loss: 0.0432842\n",
      "\tspeed: 0.0213s/iter; left time: 48.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0440936 Vali Loss: 0.0527343 Test Loss: 0.0567664\n",
      "Validation loss decreased (0.052935 --> 0.052734).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0442159\n",
      "\tspeed: 0.0368s/iter; left time: 78.8618s\n",
      "\titers: 200, epoch: 11 | loss: 0.0469867\n",
      "\tspeed: 0.0170s/iter; left time: 34.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0437601 Vali Loss: 0.0524060 Test Loss: 0.0564677\n",
      "Validation loss decreased (0.052734 --> 0.052406).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0442465\n",
      "\tspeed: 0.0383s/iter; left time: 73.4334s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414413\n",
      "\tspeed: 0.0199s/iter; left time: 36.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0434925 Vali Loss: 0.0522480 Test Loss: 0.0564030\n",
      "Validation loss decreased (0.052406 --> 0.052248).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0466450\n",
      "\tspeed: 0.0434s/iter; left time: 73.4066s\n",
      "\titers: 200, epoch: 13 | loss: 0.0407641\n",
      "\tspeed: 0.0209s/iter; left time: 33.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0433079 Vali Loss: 0.0521778 Test Loss: 0.0563392\n",
      "Validation loss decreased (0.052248 --> 0.052178).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0421818\n",
      "\tspeed: 0.0384s/iter; left time: 56.3429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0447528\n",
      "\tspeed: 0.0193s/iter; left time: 26.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0430867 Vali Loss: 0.0519807 Test Loss: 0.0562902\n",
      "Validation loss decreased (0.052178 --> 0.051981).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0419500\n",
      "\tspeed: 0.0369s/iter; left time: 45.9944s\n",
      "\titers: 200, epoch: 15 | loss: 0.0382999\n",
      "\tspeed: 0.0199s/iter; left time: 22.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0429435 Vali Loss: 0.0519662 Test Loss: 0.0560710\n",
      "Validation loss decreased (0.051981 --> 0.051966).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0414118\n",
      "\tspeed: 0.0367s/iter; left time: 37.5119s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415932\n",
      "\tspeed: 0.0188s/iter; left time: 17.2981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0427769 Vali Loss: 0.0518844 Test Loss: 0.0561112\n",
      "Validation loss decreased (0.051966 --> 0.051884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0428831\n",
      "\tspeed: 0.0371s/iter; left time: 29.5346s\n",
      "\titers: 200, epoch: 17 | loss: 0.0412486\n",
      "\tspeed: 0.0192s/iter; left time: 13.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0426684 Vali Loss: 0.0519237 Test Loss: 0.0561049\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0422155\n",
      "\tspeed: 0.0362s/iter; left time: 20.7648s\n",
      "\titers: 200, epoch: 18 | loss: 0.0412015\n",
      "\tspeed: 0.0181s/iter; left time: 8.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0425029 Vali Loss: 0.0517499 Test Loss: 0.0560229\n",
      "Validation loss decreased (0.051884 --> 0.051750).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0433981\n",
      "\tspeed: 0.0390s/iter; left time: 13.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448439\n",
      "\tspeed: 0.0195s/iter; left time: 4.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0423947 Vali Loss: 0.0516780 Test Loss: 0.0559298\n",
      "Validation loss decreased (0.051750 --> 0.051678).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0435514\n",
      "\tspeed: 0.0395s/iter; left time: 4.9417s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383629\n",
      "\tspeed: 0.0197s/iter; left time: 0.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0422725 Vali Loss: 0.0516585 Test Loss: 0.0558056\n",
      "Validation loss decreased (0.051678 --> 0.051658).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010172461159527302, rmse:0.10085862129926682, mae:0.055805619806051254, rse:0.3891097605228424\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:56.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1150345\n",
      "\tspeed: 0.0394s/iter; left time: 172.8298s\n",
      "\titers: 200, epoch: 1 | loss: 0.0994970\n",
      "\tspeed: 0.0164s/iter; left time: 70.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1151521 Vali Loss: 0.1004603 Test Loss: 0.1112473\n",
      "Validation loss decreased (inf --> 0.100460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693080\n",
      "\tspeed: 0.0323s/iter; left time: 134.4223s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724322\n",
      "\tspeed: 0.0163s/iter; left time: 66.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0735030 Vali Loss: 0.0765681 Test Loss: 0.0844831\n",
      "Validation loss decreased (0.100460 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0613564\n",
      "\tspeed: 0.0347s/iter; left time: 136.3488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634928\n",
      "\tspeed: 0.0171s/iter; left time: 65.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0658099 Vali Loss: 0.0732510 Test Loss: 0.0826563\n",
      "Validation loss decreased (0.076568 --> 0.073251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623701\n",
      "\tspeed: 0.0353s/iter; left time: 130.7693s\n",
      "\titers: 200, epoch: 4 | loss: 0.0633448\n",
      "\tspeed: 0.0175s/iter; left time: 63.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0633823 Vali Loss: 0.0719194 Test Loss: 0.0820371\n",
      "Validation loss decreased (0.073251 --> 0.071919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614888\n",
      "\tspeed: 0.0336s/iter; left time: 117.2415s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610972\n",
      "\tspeed: 0.0159s/iter; left time: 53.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0621701 Vali Loss: 0.0716075 Test Loss: 0.0817624\n",
      "Validation loss decreased (0.071919 --> 0.071608).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612228\n",
      "\tspeed: 0.0375s/iter; left time: 122.1802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592582\n",
      "\tspeed: 0.0178s/iter; left time: 56.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0613832 Vali Loss: 0.0709181 Test Loss: 0.0815005\n",
      "Validation loss decreased (0.071608 --> 0.070918).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582864\n",
      "\tspeed: 0.0391s/iter; left time: 118.6923s\n",
      "\titers: 200, epoch: 7 | loss: 0.0598563\n",
      "\tspeed: 0.0177s/iter; left time: 51.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0607176 Vali Loss: 0.0706939 Test Loss: 0.0812478\n",
      "Validation loss decreased (0.070918 --> 0.070694).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0593617\n",
      "\tspeed: 0.0406s/iter; left time: 114.2373s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628847\n",
      "\tspeed: 0.0177s/iter; left time: 47.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0602211 Vali Loss: 0.0707668 Test Loss: 0.0811632\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580503\n",
      "\tspeed: 0.0364s/iter; left time: 94.1637s\n",
      "\titers: 200, epoch: 9 | loss: 0.0611335\n",
      "\tspeed: 0.0283s/iter; left time: 70.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0597630 Vali Loss: 0.0707890 Test Loss: 0.0808218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602699\n",
      "\tspeed: 0.0369s/iter; left time: 87.2444s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593928\n",
      "\tspeed: 0.0153s/iter; left time: 34.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0593691 Vali Loss: 0.0710047 Test Loss: 0.0808480\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0556815\n",
      "\tspeed: 0.0316s/iter; left time: 67.7074s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595476\n",
      "\tspeed: 0.0173s/iter; left time: 35.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0590156 Vali Loss: 0.0708511 Test Loss: 0.0812676\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595886\n",
      "\tspeed: 0.0345s/iter; left time: 66.1296s\n",
      "\titers: 200, epoch: 12 | loss: 0.0590767\n",
      "\tspeed: 0.0178s/iter; left time: 32.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0587250 Vali Loss: 0.0708682 Test Loss: 0.0809419\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019239535555243492, rmse:0.13870665431022644, mae:0.08124779164791107, rse:0.536554217338562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1148729\n",
      "\tspeed: 0.0233s/iter; left time: 101.9021s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003245\n",
      "\tspeed: 0.0192s/iter; left time: 82.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1165598 Vali Loss: 0.1021862 Test Loss: 0.1129931\n",
      "Validation loss decreased (inf --> 0.102186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0688481\n",
      "\tspeed: 0.0380s/iter; left time: 158.1528s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709450\n",
      "\tspeed: 0.0179s/iter; left time: 72.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0736646 Vali Loss: 0.0766138 Test Loss: 0.0844905\n",
      "Validation loss decreased (0.102186 --> 0.076614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0691289\n",
      "\tspeed: 0.0383s/iter; left time: 150.4886s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633437\n",
      "\tspeed: 0.0182s/iter; left time: 69.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0657801 Vali Loss: 0.0733796 Test Loss: 0.0828308\n",
      "Validation loss decreased (0.076614 --> 0.073380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0683975\n",
      "\tspeed: 0.0376s/iter; left time: 139.6381s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621065\n",
      "\tspeed: 0.0194s/iter; left time: 69.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0633182 Vali Loss: 0.0722561 Test Loss: 0.0824362\n",
      "Validation loss decreased (0.073380 --> 0.072256).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0618264\n",
      "\tspeed: 0.0402s/iter; left time: 140.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606453\n",
      "\tspeed: 0.0209s/iter; left time: 70.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0620416 Vali Loss: 0.0716676 Test Loss: 0.0817704\n",
      "Validation loss decreased (0.072256 --> 0.071668).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592361\n",
      "\tspeed: 0.0399s/iter; left time: 130.0835s\n",
      "\titers: 200, epoch: 6 | loss: 0.0624412\n",
      "\tspeed: 0.0195s/iter; left time: 61.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0612315 Vali Loss: 0.0713056 Test Loss: 0.0816796\n",
      "Validation loss decreased (0.071668 --> 0.071306).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0604287\n",
      "\tspeed: 0.0393s/iter; left time: 119.3134s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607347\n",
      "\tspeed: 0.0209s/iter; left time: 61.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0605639 Vali Loss: 0.0711734 Test Loss: 0.0813426\n",
      "Validation loss decreased (0.071306 --> 0.071173).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0594503\n",
      "\tspeed: 0.0406s/iter; left time: 114.0733s\n",
      "\titers: 200, epoch: 8 | loss: 0.0598839\n",
      "\tspeed: 0.0146s/iter; left time: 39.5373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0600136 Vali Loss: 0.0709626 Test Loss: 0.0812785\n",
      "Validation loss decreased (0.071173 --> 0.070963).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0584742\n",
      "\tspeed: 0.0353s/iter; left time: 91.2769s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627953\n",
      "\tspeed: 0.0182s/iter; left time: 45.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0595614 Vali Loss: 0.0710455 Test Loss: 0.0811933\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632053\n",
      "\tspeed: 0.0385s/iter; left time: 91.0941s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543489\n",
      "\tspeed: 0.0178s/iter; left time: 40.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0592101 Vali Loss: 0.0709957 Test Loss: 0.0808683\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582509\n",
      "\tspeed: 0.0347s/iter; left time: 74.3574s\n",
      "\titers: 200, epoch: 11 | loss: 0.0617730\n",
      "\tspeed: 0.0164s/iter; left time: 33.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0588796 Vali Loss: 0.0711482 Test Loss: 0.0814164\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567222\n",
      "\tspeed: 0.0404s/iter; left time: 77.4217s\n",
      "\titers: 200, epoch: 12 | loss: 0.0630319\n",
      "\tspeed: 0.0240s/iter; left time: 43.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0585767 Vali Loss: 0.0710930 Test Loss: 0.0813699\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0621379\n",
      "\tspeed: 0.0359s/iter; left time: 60.7723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0608567\n",
      "\tspeed: 0.0176s/iter; left time: 28.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0583427 Vali Loss: 0.0710956 Test Loss: 0.0811685\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01920846663415432, rmse:0.1385946124792099, mae:0.08127850294113159, rse:0.5361208319664001\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:29.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1184496\n",
      "\tspeed: 0.0431s/iter; left time: 188.1379s\n",
      "\titers: 200, epoch: 1 | loss: 0.0971473\n",
      "\tspeed: 0.0108s/iter; left time: 46.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.1167316 Vali Loss: 0.1032083 Test Loss: 0.1129677\n",
      "Validation loss decreased (inf --> 0.103208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0822949\n",
      "\tspeed: 0.0323s/iter; left time: 133.7894s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746721\n",
      "\tspeed: 0.0156s/iter; left time: 63.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0773156 Vali Loss: 0.0803216 Test Loss: 0.0886327\n",
      "Validation loss decreased (0.103208 --> 0.080322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0713718\n",
      "\tspeed: 0.0361s/iter; left time: 141.3379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0684350\n",
      "\tspeed: 0.0168s/iter; left time: 64.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0697741 Vali Loss: 0.0767432 Test Loss: 0.0876774\n",
      "Validation loss decreased (0.080322 --> 0.076743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674153\n",
      "\tspeed: 0.0351s/iter; left time: 129.4608s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699043\n",
      "\tspeed: 0.0164s/iter; left time: 58.7823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0672569 Vali Loss: 0.0758318 Test Loss: 0.0873202\n",
      "Validation loss decreased (0.076743 --> 0.075832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679794\n",
      "\tspeed: 0.0359s/iter; left time: 124.4353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0696597\n",
      "\tspeed: 0.0125s/iter; left time: 42.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0661320 Vali Loss: 0.0753898 Test Loss: 0.0871050\n",
      "Validation loss decreased (0.075832 --> 0.075390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637402\n",
      "\tspeed: 0.0382s/iter; left time: 123.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0633766\n",
      "\tspeed: 0.0164s/iter; left time: 51.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0652604 Vali Loss: 0.0750106 Test Loss: 0.0866593\n",
      "Validation loss decreased (0.075390 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0654606\n",
      "\tspeed: 0.0368s/iter; left time: 111.2552s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664279\n",
      "\tspeed: 0.0162s/iter; left time: 47.3141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0647009 Vali Loss: 0.0749119 Test Loss: 0.0863478\n",
      "Validation loss decreased (0.075011 --> 0.074912).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0680805\n",
      "\tspeed: 0.0392s/iter; left time: 109.7020s\n",
      "\titers: 200, epoch: 8 | loss: 0.0621320\n",
      "\tspeed: 0.0184s/iter; left time: 49.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0641877 Vali Loss: 0.0751029 Test Loss: 0.0873028\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651313\n",
      "\tspeed: 0.0379s/iter; left time: 97.5498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0634317\n",
      "\tspeed: 0.0206s/iter; left time: 51.1012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0637819 Vali Loss: 0.0752244 Test Loss: 0.0870896\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0616768\n",
      "\tspeed: 0.0342s/iter; left time: 80.6187s\n",
      "\titers: 200, epoch: 10 | loss: 0.0662288\n",
      "\tspeed: 0.0165s/iter; left time: 37.0929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0634420 Vali Loss: 0.0752584 Test Loss: 0.0871234\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0668921\n",
      "\tspeed: 0.0348s/iter; left time: 74.1103s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658013\n",
      "\tspeed: 0.0127s/iter; left time: 25.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 223 | Train Loss: 0.0630799 Vali Loss: 0.0751184 Test Loss: 0.0872565\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644008\n",
      "\tspeed: 0.0272s/iter; left time: 51.8949s\n",
      "\titers: 200, epoch: 12 | loss: 0.0626267\n",
      "\tspeed: 0.0157s/iter; left time: 28.4065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 223 | Train Loss: 0.0627786 Vali Loss: 0.0755117 Test Loss: 0.0872327\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020680325105786324, rmse:0.1438065618276596, mae:0.08634777367115021, rse:0.5569763779640198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1160953\n",
      "\tspeed: 0.0217s/iter; left time: 94.7544s\n",
      "\titers: 200, epoch: 1 | loss: 0.1009110\n",
      "\tspeed: 0.0169s/iter; left time: 71.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1164151 Vali Loss: 0.1032379 Test Loss: 0.1131487\n",
      "Validation loss decreased (inf --> 0.103238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0741741\n",
      "\tspeed: 0.0352s/iter; left time: 145.6878s\n",
      "\titers: 200, epoch: 2 | loss: 0.0729494\n",
      "\tspeed: 0.0189s/iter; left time: 76.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0772838 Vali Loss: 0.0805425 Test Loss: 0.0888041\n",
      "Validation loss decreased (0.103238 --> 0.080543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0694003\n",
      "\tspeed: 0.0381s/iter; left time: 148.9917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0664097\n",
      "\tspeed: 0.0182s/iter; left time: 69.3161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0697527 Vali Loss: 0.0767579 Test Loss: 0.0879858\n",
      "Validation loss decreased (0.080543 --> 0.076758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0693248\n",
      "\tspeed: 0.0392s/iter; left time: 144.8990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655002\n",
      "\tspeed: 0.0175s/iter; left time: 62.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0671989 Vali Loss: 0.0756547 Test Loss: 0.0876561\n",
      "Validation loss decreased (0.076758 --> 0.075655).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649014\n",
      "\tspeed: 0.0396s/iter; left time: 137.2358s\n",
      "\titers: 200, epoch: 5 | loss: 0.0637037\n",
      "\tspeed: 0.0179s/iter; left time: 60.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0660379 Vali Loss: 0.0756096 Test Loss: 0.0877262\n",
      "Validation loss decreased (0.075655 --> 0.075610).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0664085\n",
      "\tspeed: 0.0407s/iter; left time: 132.1649s\n",
      "\titers: 200, epoch: 6 | loss: 0.0656642\n",
      "\tspeed: 0.0182s/iter; left time: 57.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0652658 Vali Loss: 0.0750269 Test Loss: 0.0864704\n",
      "Validation loss decreased (0.075610 --> 0.075027).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0651778\n",
      "\tspeed: 0.0383s/iter; left time: 115.8205s\n",
      "\titers: 200, epoch: 7 | loss: 0.0648179\n",
      "\tspeed: 0.0200s/iter; left time: 58.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0646194 Vali Loss: 0.0750498 Test Loss: 0.0868188\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651356\n",
      "\tspeed: 0.0375s/iter; left time: 105.0459s\n",
      "\titers: 200, epoch: 8 | loss: 0.0656781\n",
      "\tspeed: 0.0175s/iter; left time: 47.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0641468 Vali Loss: 0.0748818 Test Loss: 0.0863336\n",
      "Validation loss decreased (0.075027 --> 0.074882).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0649025\n",
      "\tspeed: 0.0369s/iter; left time: 95.0663s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613403\n",
      "\tspeed: 0.0213s/iter; left time: 52.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0636986 Vali Loss: 0.0751551 Test Loss: 0.0860609\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0618444\n",
      "\tspeed: 0.0388s/iter; left time: 91.3038s\n",
      "\titers: 200, epoch: 10 | loss: 0.0631449\n",
      "\tspeed: 0.0178s/iter; left time: 40.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0633031 Vali Loss: 0.0754076 Test Loss: 0.0857785\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0607330\n",
      "\tspeed: 0.0363s/iter; left time: 77.4088s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658213\n",
      "\tspeed: 0.0197s/iter; left time: 40.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0629210 Vali Loss: 0.0750744 Test Loss: 0.0862985\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0642546\n",
      "\tspeed: 0.0414s/iter; left time: 79.0162s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623738\n",
      "\tspeed: 0.0213s/iter; left time: 38.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0626597 Vali Loss: 0.0751349 Test Loss: 0.0861356\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637437\n",
      "\tspeed: 0.0392s/iter; left time: 66.0896s\n",
      "\titers: 200, epoch: 13 | loss: 0.0632063\n",
      "\tspeed: 0.0198s/iter; left time: 31.4511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0623907 Vali Loss: 0.0750772 Test Loss: 0.0864533\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020546922460198402, rmse:0.14334197342395782, mae:0.08633362501859665, rse:0.5551770329475403\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:27.13s\n",
      "Intermediate time for FR: 00h:08m:53.57s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616937\n",
      "\tspeed: 0.0407s/iter; left time: 178.4584s\n",
      "\titers: 200, epoch: 1 | loss: 0.1293149\n",
      "\tspeed: 0.0119s/iter; left time: 51.1338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 224 | Train Loss: 0.1621773 Vali Loss: 0.1138775 Test Loss: 0.1172790\n",
      "Validation loss decreased (inf --> 0.113878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786218\n",
      "\tspeed: 0.0286s/iter; left time: 118.8473s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0173s/iter; left time: 70.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0831071 Vali Loss: 0.0641884 Test Loss: 0.0671537\n",
      "Validation loss decreased (0.113878 --> 0.064188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700320\n",
      "\tspeed: 0.0365s/iter; left time: 143.5740s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662021\n",
      "\tspeed: 0.0185s/iter; left time: 70.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0678796 Vali Loss: 0.0606680 Test Loss: 0.0635218\n",
      "Validation loss decreased (0.064188 --> 0.060668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612472\n",
      "\tspeed: 0.0373s/iter; left time: 138.2053s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621978\n",
      "\tspeed: 0.0163s/iter; left time: 58.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0645124 Vali Loss: 0.0592873 Test Loss: 0.0619248\n",
      "Validation loss decreased (0.060668 --> 0.059287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0623944\n",
      "\tspeed: 0.0378s/iter; left time: 131.6622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643269\n",
      "\tspeed: 0.0197s/iter; left time: 66.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0625303 Vali Loss: 0.0582227 Test Loss: 0.0607137\n",
      "Validation loss decreased (0.059287 --> 0.058223).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0643557\n",
      "\tspeed: 0.0420s/iter; left time: 137.0096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613264\n",
      "\tspeed: 0.0234s/iter; left time: 73.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0612088 Vali Loss: 0.0574816 Test Loss: 0.0600706\n",
      "Validation loss decreased (0.058223 --> 0.057482).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583737\n",
      "\tspeed: 0.0453s/iter; left time: 137.6595s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589131\n",
      "\tspeed: 0.0253s/iter; left time: 74.1702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0603114 Vali Loss: 0.0568728 Test Loss: 0.0594318\n",
      "Validation loss decreased (0.057482 --> 0.056873).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0602870\n",
      "\tspeed: 0.0402s/iter; left time: 113.2210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0557014\n",
      "\tspeed: 0.0197s/iter; left time: 53.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0596433 Vali Loss: 0.0565994 Test Loss: 0.0593777\n",
      "Validation loss decreased (0.056873 --> 0.056599).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0564329\n",
      "\tspeed: 0.0421s/iter; left time: 108.9296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0571721\n",
      "\tspeed: 0.0236s/iter; left time: 58.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0589292 Vali Loss: 0.0562056 Test Loss: 0.0591851\n",
      "Validation loss decreased (0.056599 --> 0.056206).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0580420\n",
      "\tspeed: 0.0393s/iter; left time: 92.9820s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585416\n",
      "\tspeed: 0.0217s/iter; left time: 49.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0584382 Vali Loss: 0.0559097 Test Loss: 0.0587973\n",
      "Validation loss decreased (0.056206 --> 0.055910).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601182\n",
      "\tspeed: 0.0393s/iter; left time: 84.2334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0593806\n",
      "\tspeed: 0.0202s/iter; left time: 41.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0579796 Vali Loss: 0.0556803 Test Loss: 0.0584713\n",
      "Validation loss decreased (0.055910 --> 0.055680).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591369\n",
      "\tspeed: 0.0443s/iter; left time: 84.8858s\n",
      "\titers: 200, epoch: 12 | loss: 0.0568577\n",
      "\tspeed: 0.0222s/iter; left time: 40.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0576995 Vali Loss: 0.0555104 Test Loss: 0.0582978\n",
      "Validation loss decreased (0.055680 --> 0.055510).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595251\n",
      "\tspeed: 0.0422s/iter; left time: 71.3737s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602591\n",
      "\tspeed: 0.0213s/iter; left time: 33.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0573981 Vali Loss: 0.0553351 Test Loss: 0.0582722\n",
      "Validation loss decreased (0.055510 --> 0.055335).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0583053\n",
      "\tspeed: 0.0389s/iter; left time: 57.2103s\n",
      "\titers: 200, epoch: 14 | loss: 0.0602665\n",
      "\tspeed: 0.0198s/iter; left time: 27.1643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0570490 Vali Loss: 0.0551690 Test Loss: 0.0581385\n",
      "Validation loss decreased (0.055335 --> 0.055169).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0560705\n",
      "\tspeed: 0.0404s/iter; left time: 50.2697s\n",
      "\titers: 200, epoch: 15 | loss: 0.0556168\n",
      "\tspeed: 0.0161s/iter; left time: 18.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0568528 Vali Loss: 0.0549350 Test Loss: 0.0578218\n",
      "Validation loss decreased (0.055169 --> 0.054935).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580549\n",
      "\tspeed: 0.0368s/iter; left time: 37.5227s\n",
      "\titers: 200, epoch: 16 | loss: 0.0600087\n",
      "\tspeed: 0.0212s/iter; left time: 19.4900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0566595 Vali Loss: 0.0549669 Test Loss: 0.0577802\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645831\n",
      "\tspeed: 0.0373s/iter; left time: 29.7151s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576199\n",
      "\tspeed: 0.0097s/iter; left time: 6.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 224 | Train Loss: 0.0564659 Vali Loss: 0.0549089 Test Loss: 0.0576262\n",
      "Validation loss decreased (0.054935 --> 0.054909).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542376\n",
      "\tspeed: 0.0346s/iter; left time: 19.8404s\n",
      "\titers: 200, epoch: 18 | loss: 0.0603156\n",
      "\tspeed: 0.0177s/iter; left time: 8.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0562640 Vali Loss: 0.0548581 Test Loss: 0.0575692\n",
      "Validation loss decreased (0.054909 --> 0.054858).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0547322\n",
      "\tspeed: 0.0363s/iter; left time: 12.6517s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540715\n",
      "\tspeed: 0.0202s/iter; left time: 5.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0561902 Vali Loss: 0.0546502 Test Loss: 0.0575371\n",
      "Validation loss decreased (0.054858 --> 0.054650).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0570445\n",
      "\tspeed: 0.0374s/iter; left time: 4.6800s\n",
      "\titers: 200, epoch: 20 | loss: 0.0555143\n",
      "\tspeed: 0.0208s/iter; left time: 0.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0560226 Vali Loss: 0.0546247 Test Loss: 0.0574184\n",
      "Validation loss decreased (0.054650 --> 0.054625).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010179932229220867, rmse:0.10089565068483353, mae:0.05741839110851288, rse:0.3812349736690521\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1641964\n",
      "\tspeed: 0.0199s/iter; left time: 87.2645s\n",
      "\titers: 200, epoch: 1 | loss: 0.1335033\n",
      "\tspeed: 0.0194s/iter; left time: 82.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1647834 Vali Loss: 0.1140856 Test Loss: 0.1180013\n",
      "Validation loss decreased (inf --> 0.114086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0788176\n",
      "\tspeed: 0.0374s/iter; left time: 155.6334s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722505\n",
      "\tspeed: 0.0100s/iter; left time: 40.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0832242 Vali Loss: 0.0639038 Test Loss: 0.0669096\n",
      "Validation loss decreased (0.114086 --> 0.063904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0667697\n",
      "\tspeed: 0.0403s/iter; left time: 158.4654s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649629\n",
      "\tspeed: 0.0226s/iter; left time: 86.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0675962 Vali Loss: 0.0606419 Test Loss: 0.0631409\n",
      "Validation loss decreased (0.063904 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0617372\n",
      "\tspeed: 0.0357s/iter; left time: 132.4384s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621744\n",
      "\tspeed: 0.0188s/iter; left time: 67.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0641366 Vali Loss: 0.0588051 Test Loss: 0.0615734\n",
      "Validation loss decreased (0.060642 --> 0.058805).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0638878\n",
      "\tspeed: 0.0401s/iter; left time: 139.6350s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591638\n",
      "\tspeed: 0.0231s/iter; left time: 78.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0622737 Vali Loss: 0.0577147 Test Loss: 0.0605669\n",
      "Validation loss decreased (0.058805 --> 0.057715).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633146\n",
      "\tspeed: 0.0386s/iter; left time: 125.8105s\n",
      "\titers: 200, epoch: 6 | loss: 0.0637995\n",
      "\tspeed: 0.0192s/iter; left time: 60.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0610022 Vali Loss: 0.0571649 Test Loss: 0.0599463\n",
      "Validation loss decreased (0.057715 --> 0.057165).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621157\n",
      "\tspeed: 0.0391s/iter; left time: 118.8931s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0197s/iter; left time: 57.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0601525 Vali Loss: 0.0565381 Test Loss: 0.0591958\n",
      "Validation loss decreased (0.057165 --> 0.056538).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0582208\n",
      "\tspeed: 0.0371s/iter; left time: 104.4524s\n",
      "\titers: 200, epoch: 8 | loss: 0.0555900\n",
      "\tspeed: 0.0170s/iter; left time: 46.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0593576 Vali Loss: 0.0562229 Test Loss: 0.0586400\n",
      "Validation loss decreased (0.056538 --> 0.056223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0542082\n",
      "\tspeed: 0.0411s/iter; left time: 106.3717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0591107\n",
      "\tspeed: 0.0238s/iter; left time: 59.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0587323 Vali Loss: 0.0560406 Test Loss: 0.0586930\n",
      "Validation loss decreased (0.056223 --> 0.056041).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0589340\n",
      "\tspeed: 0.0370s/iter; left time: 87.5952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0544693\n",
      "\tspeed: 0.0206s/iter; left time: 46.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0581913 Vali Loss: 0.0557895 Test Loss: 0.0583518\n",
      "Validation loss decreased (0.056041 --> 0.055790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0545925\n",
      "\tspeed: 0.0396s/iter; left time: 84.7749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568754\n",
      "\tspeed: 0.0203s/iter; left time: 41.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0578496 Vali Loss: 0.0554803 Test Loss: 0.0580290\n",
      "Validation loss decreased (0.055790 --> 0.055480).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0530381\n",
      "\tspeed: 0.0390s/iter; left time: 74.6898s\n",
      "\titers: 200, epoch: 12 | loss: 0.0531054\n",
      "\tspeed: 0.0206s/iter; left time: 37.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0574548 Vali Loss: 0.0551434 Test Loss: 0.0578716\n",
      "Validation loss decreased (0.055480 --> 0.055143).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580193\n",
      "\tspeed: 0.0389s/iter; left time: 65.7946s\n",
      "\titers: 200, epoch: 13 | loss: 0.0529509\n",
      "\tspeed: 0.0169s/iter; left time: 26.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0572294 Vali Loss: 0.0551373 Test Loss: 0.0578145\n",
      "Validation loss decreased (0.055143 --> 0.055137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563859\n",
      "\tspeed: 0.0365s/iter; left time: 53.5617s\n",
      "\titers: 200, epoch: 14 | loss: 0.0511928\n",
      "\tspeed: 0.0185s/iter; left time: 25.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0569481 Vali Loss: 0.0550665 Test Loss: 0.0576489\n",
      "Validation loss decreased (0.055137 --> 0.055066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0589813\n",
      "\tspeed: 0.0386s/iter; left time: 48.1042s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532490\n",
      "\tspeed: 0.0165s/iter; left time: 18.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0566507 Vali Loss: 0.0549078 Test Loss: 0.0576441\n",
      "Validation loss decreased (0.055066 --> 0.054908).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541341\n",
      "\tspeed: 0.0399s/iter; left time: 40.7131s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551793\n",
      "\tspeed: 0.0228s/iter; left time: 21.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0564742 Vali Loss: 0.0547731 Test Loss: 0.0575482\n",
      "Validation loss decreased (0.054908 --> 0.054773).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624035\n",
      "\tspeed: 0.0406s/iter; left time: 32.3973s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540801\n",
      "\tspeed: 0.0215s/iter; left time: 14.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0562661 Vali Loss: 0.0548215 Test Loss: 0.0573372\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542855\n",
      "\tspeed: 0.0383s/iter; left time: 21.9485s\n",
      "\titers: 200, epoch: 18 | loss: 0.0525319\n",
      "\tspeed: 0.0197s/iter; left time: 9.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0561894 Vali Loss: 0.0547226 Test Loss: 0.0573225\n",
      "Validation loss decreased (0.054773 --> 0.054723).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0528437\n",
      "\tspeed: 0.0362s/iter; left time: 12.6284s\n",
      "\titers: 200, epoch: 19 | loss: 0.0514670\n",
      "\tspeed: 0.0200s/iter; left time: 4.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0559581 Vali Loss: 0.0548397 Test Loss: 0.0573655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0514763\n",
      "\tspeed: 0.0390s/iter; left time: 4.8805s\n",
      "\titers: 200, epoch: 20 | loss: 0.0547461\n",
      "\tspeed: 0.0193s/iter; left time: 0.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0559040 Vali Loss: 0.0546618 Test Loss: 0.0573808\n",
      "Validation loss decreased (0.054723 --> 0.054662).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010223758406937122, rmse:0.10111260414123535, mae:0.0573807992041111, rse:0.38205471634864807\n",
      "Intermediate time for IT and pred_len 24: 00h:04m:03.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1697901\n",
      "\tspeed: 0.0385s/iter; left time: 168.5173s\n",
      "\titers: 200, epoch: 1 | loss: 0.1417536\n",
      "\tspeed: 0.0166s/iter; left time: 71.2380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1661587 Vali Loss: 0.1205689 Test Loss: 0.1254019\n",
      "Validation loss decreased (inf --> 0.120569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0981152\n",
      "\tspeed: 0.0368s/iter; left time: 152.8899s\n",
      "\titers: 200, epoch: 2 | loss: 0.0931919\n",
      "\tspeed: 0.0189s/iter; left time: 76.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1010543 Vali Loss: 0.0828838 Test Loss: 0.0878194\n",
      "Validation loss decreased (0.120569 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0871705\n",
      "\tspeed: 0.0337s/iter; left time: 132.4766s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823159\n",
      "\tspeed: 0.0174s/iter; left time: 66.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0867661 Vali Loss: 0.0794811 Test Loss: 0.0843781\n",
      "Validation loss decreased (0.082884 --> 0.079481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838890\n",
      "\tspeed: 0.0344s/iter; left time: 127.7357s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801001\n",
      "\tspeed: 0.0183s/iter; left time: 66.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0835624 Vali Loss: 0.0781997 Test Loss: 0.0834986\n",
      "Validation loss decreased (0.079481 --> 0.078200).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819419\n",
      "\tspeed: 0.0388s/iter; left time: 135.1468s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834576\n",
      "\tspeed: 0.0199s/iter; left time: 67.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0817635 Vali Loss: 0.0775758 Test Loss: 0.0826953\n",
      "Validation loss decreased (0.078200 --> 0.077576).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838633\n",
      "\tspeed: 0.0406s/iter; left time: 132.4235s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800622\n",
      "\tspeed: 0.0201s/iter; left time: 63.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0805275 Vali Loss: 0.0772487 Test Loss: 0.0826419\n",
      "Validation loss decreased (0.077576 --> 0.077249).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770448\n",
      "\tspeed: 0.0364s/iter; left time: 110.6709s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791029\n",
      "\tspeed: 0.0183s/iter; left time: 53.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0796021 Vali Loss: 0.0769699 Test Loss: 0.0821760\n",
      "Validation loss decreased (0.077249 --> 0.076970).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800148\n",
      "\tspeed: 0.0354s/iter; left time: 99.6873s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800654\n",
      "\tspeed: 0.0182s/iter; left time: 49.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0788863 Vali Loss: 0.0766922 Test Loss: 0.0817522\n",
      "Validation loss decreased (0.076970 --> 0.076692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763567\n",
      "\tspeed: 0.0368s/iter; left time: 95.2910s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756575\n",
      "\tspeed: 0.0173s/iter; left time: 43.1033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0782481 Vali Loss: 0.0764618 Test Loss: 0.0816592\n",
      "Validation loss decreased (0.076692 --> 0.076462).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781845\n",
      "\tspeed: 0.0368s/iter; left time: 87.0937s\n",
      "\titers: 200, epoch: 10 | loss: 0.0800031\n",
      "\tspeed: 0.0178s/iter; left time: 40.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0776947 Vali Loss: 0.0764062 Test Loss: 0.0814688\n",
      "Validation loss decreased (0.076462 --> 0.076406).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0756868\n",
      "\tspeed: 0.0344s/iter; left time: 73.7293s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766438\n",
      "\tspeed: 0.0172s/iter; left time: 35.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0772751 Vali Loss: 0.0763349 Test Loss: 0.0814497\n",
      "Validation loss decreased (0.076406 --> 0.076335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758763\n",
      "\tspeed: 0.0378s/iter; left time: 72.4018s\n",
      "\titers: 200, epoch: 12 | loss: 0.0747020\n",
      "\tspeed: 0.0229s/iter; left time: 41.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0767900 Vali Loss: 0.0761060 Test Loss: 0.0813051\n",
      "Validation loss decreased (0.076335 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789600\n",
      "\tspeed: 0.0346s/iter; left time: 58.6115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759603\n",
      "\tspeed: 0.0186s/iter; left time: 29.6360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0764186 Vali Loss: 0.0763179 Test Loss: 0.0813079\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0704881\n",
      "\tspeed: 0.0330s/iter; left time: 48.4398s\n",
      "\titers: 200, epoch: 14 | loss: 0.0755752\n",
      "\tspeed: 0.0163s/iter; left time: 22.3258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0761283 Vali Loss: 0.0763324 Test Loss: 0.0812085\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780939\n",
      "\tspeed: 0.0338s/iter; left time: 42.0733s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711667\n",
      "\tspeed: 0.0197s/iter; left time: 22.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0758143 Vali Loss: 0.0761845 Test Loss: 0.0810637\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718904\n",
      "\tspeed: 0.0373s/iter; left time: 38.1175s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772383\n",
      "\tspeed: 0.0194s/iter; left time: 17.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0754854 Vali Loss: 0.0761187 Test Loss: 0.0811562\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0739559\n",
      "\tspeed: 0.0343s/iter; left time: 27.3185s\n",
      "\titers: 200, epoch: 17 | loss: 0.0751932\n",
      "\tspeed: 0.0175s/iter; left time: 12.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0752675 Vali Loss: 0.0761033 Test Loss: 0.0810552\n",
      "Validation loss decreased (0.076106 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773290\n",
      "\tspeed: 0.0375s/iter; left time: 21.4907s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747019\n",
      "\tspeed: 0.0212s/iter; left time: 10.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0750758 Vali Loss: 0.0761617 Test Loss: 0.0808548\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718658\n",
      "\tspeed: 0.0363s/iter; left time: 12.6814s\n",
      "\titers: 200, epoch: 19 | loss: 0.0726776\n",
      "\tspeed: 0.0177s/iter; left time: 4.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0749217 Vali Loss: 0.0761442 Test Loss: 0.0809737\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0708190\n",
      "\tspeed: 0.0370s/iter; left time: 4.6229s\n",
      "\titers: 200, epoch: 20 | loss: 0.0749490\n",
      "\tspeed: 0.0173s/iter; left time: 0.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0747592 Vali Loss: 0.0761574 Test Loss: 0.0809266\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01855003833770752, rmse:0.1361985206604004, mae:0.08105520159006119, rse:0.5149813294410706\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1661306\n",
      "\tspeed: 0.0232s/iter; left time: 101.8154s\n",
      "\titers: 200, epoch: 1 | loss: 0.1386319\n",
      "\tspeed: 0.0175s/iter; left time: 74.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.1651341 Vali Loss: 0.1197583 Test Loss: 0.1245669\n",
      "Validation loss decreased (inf --> 0.119758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1045495\n",
      "\tspeed: 0.0340s/iter; left time: 141.3500s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894544\n",
      "\tspeed: 0.0187s/iter; left time: 75.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1007104 Vali Loss: 0.0831975 Test Loss: 0.0876287\n",
      "Validation loss decreased (0.119758 --> 0.083197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895628\n",
      "\tspeed: 0.0391s/iter; left time: 153.9495s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883310\n",
      "\tspeed: 0.0195s/iter; left time: 74.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0868945 Vali Loss: 0.0797571 Test Loss: 0.0844172\n",
      "Validation loss decreased (0.083197 --> 0.079757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838891\n",
      "\tspeed: 0.0367s/iter; left time: 135.9451s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815687\n",
      "\tspeed: 0.0190s/iter; left time: 68.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0836585 Vali Loss: 0.0788186 Test Loss: 0.0832072\n",
      "Validation loss decreased (0.079757 --> 0.078819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0853383\n",
      "\tspeed: 0.0420s/iter; left time: 146.2293s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836618\n",
      "\tspeed: 0.0227s/iter; left time: 76.8968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0817977 Vali Loss: 0.0779793 Test Loss: 0.0823592\n",
      "Validation loss decreased (0.078819 --> 0.077979).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0799382\n",
      "\tspeed: 0.0365s/iter; left time: 119.0475s\n",
      "\titers: 200, epoch: 6 | loss: 0.0796745\n",
      "\tspeed: 0.0197s/iter; left time: 62.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0805553 Vali Loss: 0.0775715 Test Loss: 0.0818063\n",
      "Validation loss decreased (0.077979 --> 0.077571).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789978\n",
      "\tspeed: 0.0387s/iter; left time: 117.4943s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822624\n",
      "\tspeed: 0.0195s/iter; left time: 57.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0795909 Vali Loss: 0.0772382 Test Loss: 0.0816769\n",
      "Validation loss decreased (0.077571 --> 0.077238).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0809646\n",
      "\tspeed: 0.0355s/iter; left time: 99.9311s\n",
      "\titers: 200, epoch: 8 | loss: 0.0785988\n",
      "\tspeed: 0.0191s/iter; left time: 51.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0788885 Vali Loss: 0.0769175 Test Loss: 0.0814598\n",
      "Validation loss decreased (0.077238 --> 0.076918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779506\n",
      "\tspeed: 0.0382s/iter; left time: 98.9569s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763271\n",
      "\tspeed: 0.0211s/iter; left time: 52.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0782254 Vali Loss: 0.0768817 Test Loss: 0.0814819\n",
      "Validation loss decreased (0.076918 --> 0.076882).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0753714\n",
      "\tspeed: 0.0368s/iter; left time: 87.0330s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751342\n",
      "\tspeed: 0.0187s/iter; left time: 42.3103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0776683 Vali Loss: 0.0767503 Test Loss: 0.0815030\n",
      "Validation loss decreased (0.076882 --> 0.076750).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765918\n",
      "\tspeed: 0.0397s/iter; left time: 84.9774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0812272\n",
      "\tspeed: 0.0192s/iter; left time: 39.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0772731 Vali Loss: 0.0767325 Test Loss: 0.0814589\n",
      "Validation loss decreased (0.076750 --> 0.076732).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0783693\n",
      "\tspeed: 0.0384s/iter; left time: 73.6026s\n",
      "\titers: 200, epoch: 12 | loss: 0.0734948\n",
      "\tspeed: 0.0182s/iter; left time: 33.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0768016 Vali Loss: 0.0769572 Test Loss: 0.0814164\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0762682\n",
      "\tspeed: 0.0369s/iter; left time: 62.4542s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757583\n",
      "\tspeed: 0.0224s/iter; left time: 35.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0764821 Vali Loss: 0.0768085 Test Loss: 0.0809592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732451\n",
      "\tspeed: 0.0368s/iter; left time: 54.0851s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793516\n",
      "\tspeed: 0.0176s/iter; left time: 24.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0761137 Vali Loss: 0.0766792 Test Loss: 0.0813959\n",
      "Validation loss decreased (0.076732 --> 0.076679).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787787\n",
      "\tspeed: 0.0361s/iter; left time: 44.8844s\n",
      "\titers: 200, epoch: 15 | loss: 0.0742458\n",
      "\tspeed: 0.0195s/iter; left time: 22.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0758414 Vali Loss: 0.0766514 Test Loss: 0.0813937\n",
      "Validation loss decreased (0.076679 --> 0.076651).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0796000\n",
      "\tspeed: 0.0399s/iter; left time: 40.7328s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760873\n",
      "\tspeed: 0.0238s/iter; left time: 21.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0756022 Vali Loss: 0.0764964 Test Loss: 0.0812079\n",
      "Validation loss decreased (0.076651 --> 0.076496).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0781542\n",
      "\tspeed: 0.0401s/iter; left time: 31.9758s\n",
      "\titers: 200, epoch: 17 | loss: 0.0724886\n",
      "\tspeed: 0.0183s/iter; left time: 12.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0753410 Vali Loss: 0.0765277 Test Loss: 0.0811398\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0719991\n",
      "\tspeed: 0.0361s/iter; left time: 20.6850s\n",
      "\titers: 200, epoch: 18 | loss: 0.0713724\n",
      "\tspeed: 0.0204s/iter; left time: 9.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0751817 Vali Loss: 0.0764079 Test Loss: 0.0810717\n",
      "Validation loss decreased (0.076496 --> 0.076408).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0755875\n",
      "\tspeed: 0.0349s/iter; left time: 12.1809s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723778\n",
      "\tspeed: 0.0202s/iter; left time: 5.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0749577 Vali Loss: 0.0764176 Test Loss: 0.0811530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685743\n",
      "\tspeed: 0.0349s/iter; left time: 4.3606s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783250\n",
      "\tspeed: 0.0183s/iter; left time: 0.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0747055 Vali Loss: 0.0764246 Test Loss: 0.0810651\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01851717382669449, rmse:0.13607782125473022, mae:0.08107174187898636, rse:0.5145248770713806\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:54.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1688796\n",
      "\tspeed: 0.0524s/iter; left time: 228.4612s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379916\n",
      "\tspeed: 0.0179s/iter; left time: 76.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1675218 Vali Loss: 0.1228508 Test Loss: 0.1272653\n",
      "Validation loss decreased (inf --> 0.122851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052821\n",
      "\tspeed: 0.0341s/iter; left time: 141.1931s\n",
      "\titers: 200, epoch: 2 | loss: 0.0951657\n",
      "\tspeed: 0.0175s/iter; left time: 70.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1046993 Vali Loss: 0.0870518 Test Loss: 0.0914203\n",
      "Validation loss decreased (0.122851 --> 0.087052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0941121\n",
      "\tspeed: 0.0368s/iter; left time: 144.0445s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910775\n",
      "\tspeed: 0.0168s/iter; left time: 64.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0910649 Vali Loss: 0.0845050 Test Loss: 0.0885898\n",
      "Validation loss decreased (0.087052 --> 0.084505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0896367\n",
      "\tspeed: 0.0350s/iter; left time: 129.2230s\n",
      "\titers: 200, epoch: 4 | loss: 0.0880488\n",
      "\tspeed: 0.0171s/iter; left time: 61.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0877382 Vali Loss: 0.0837493 Test Loss: 0.0879036\n",
      "Validation loss decreased (0.084505 --> 0.083749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0890387\n",
      "\tspeed: 0.0377s/iter; left time: 130.7502s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900611\n",
      "\tspeed: 0.0184s/iter; left time: 62.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0859197 Vali Loss: 0.0826701 Test Loss: 0.0875381\n",
      "Validation loss decreased (0.083749 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836859\n",
      "\tspeed: 0.0316s/iter; left time: 102.6923s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846288\n",
      "\tspeed: 0.0111s/iter; left time: 35.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0846551 Vali Loss: 0.0824386 Test Loss: 0.0872829\n",
      "Validation loss decreased (0.082670 --> 0.082439).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834522\n",
      "\tspeed: 0.0378s/iter; left time: 114.2194s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817988\n",
      "\tspeed: 0.0195s/iter; left time: 56.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0837010 Vali Loss: 0.0825027 Test Loss: 0.0870421\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834716\n",
      "\tspeed: 0.0378s/iter; left time: 105.8932s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836445\n",
      "\tspeed: 0.0200s/iter; left time: 53.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0828991 Vali Loss: 0.0822424 Test Loss: 0.0870820\n",
      "Validation loss decreased (0.082439 --> 0.082242).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822689\n",
      "\tspeed: 0.0389s/iter; left time: 100.1896s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835607\n",
      "\tspeed: 0.0203s/iter; left time: 50.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0822176 Vali Loss: 0.0821146 Test Loss: 0.0869594\n",
      "Validation loss decreased (0.082242 --> 0.082115).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775967\n",
      "\tspeed: 0.0401s/iter; left time: 94.4580s\n",
      "\titers: 200, epoch: 10 | loss: 0.0858709\n",
      "\tspeed: 0.0205s/iter; left time: 46.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0816483 Vali Loss: 0.0820896 Test Loss: 0.0869541\n",
      "Validation loss decreased (0.082115 --> 0.082090).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0805347\n",
      "\tspeed: 0.0391s/iter; left time: 83.2751s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823051\n",
      "\tspeed: 0.0198s/iter; left time: 40.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0812410 Vali Loss: 0.0822447 Test Loss: 0.0866475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830619\n",
      "\tspeed: 0.0387s/iter; left time: 73.8354s\n",
      "\titers: 200, epoch: 12 | loss: 0.0789892\n",
      "\tspeed: 0.0198s/iter; left time: 35.7956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0807341 Vali Loss: 0.0823029 Test Loss: 0.0866804\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0821077\n",
      "\tspeed: 0.0394s/iter; left time: 66.3502s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781240\n",
      "\tspeed: 0.0206s/iter; left time: 32.6972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0803641 Vali Loss: 0.0823105 Test Loss: 0.0865855\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0829568\n",
      "\tspeed: 0.0386s/iter; left time: 56.4477s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800612\n",
      "\tspeed: 0.0201s/iter; left time: 27.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0800562 Vali Loss: 0.0821699 Test Loss: 0.0866186\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798516\n",
      "\tspeed: 0.0381s/iter; left time: 47.2445s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776321\n",
      "\tspeed: 0.0200s/iter; left time: 22.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0797893 Vali Loss: 0.0821470 Test Loss: 0.0864509\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020483501255512238, rmse:0.14312058687210083, mae:0.08695410192012787, rse:0.5416572093963623\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1724669\n",
      "\tspeed: 0.0221s/iter; left time: 96.3204s\n",
      "\titers: 200, epoch: 1 | loss: 0.1416290\n",
      "\tspeed: 0.0203s/iter; left time: 86.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1694798 Vali Loss: 0.1243570 Test Loss: 0.1289007\n",
      "Validation loss decreased (inf --> 0.124357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1026877\n",
      "\tspeed: 0.0462s/iter; left time: 190.9989s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915753\n",
      "\tspeed: 0.0203s/iter; left time: 81.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1042934 Vali Loss: 0.0872191 Test Loss: 0.0917560\n",
      "Validation loss decreased (0.124357 --> 0.087219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0883309\n",
      "\tspeed: 0.0415s/iter; left time: 162.4037s\n",
      "\titers: 200, epoch: 3 | loss: 0.0881051\n",
      "\tspeed: 0.0198s/iter; left time: 75.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0909396 Vali Loss: 0.0846750 Test Loss: 0.0889084\n",
      "Validation loss decreased (0.087219 --> 0.084675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0875771\n",
      "\tspeed: 0.0374s/iter; left time: 137.9218s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866809\n",
      "\tspeed: 0.0200s/iter; left time: 71.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0878508 Vali Loss: 0.0835724 Test Loss: 0.0881749\n",
      "Validation loss decreased (0.084675 --> 0.083572).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0848562\n",
      "\tspeed: 0.0381s/iter; left time: 132.1252s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861553\n",
      "\tspeed: 0.0179s/iter; left time: 60.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0860751 Vali Loss: 0.0829801 Test Loss: 0.0878574\n",
      "Validation loss decreased (0.083572 --> 0.082980).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831566\n",
      "\tspeed: 0.0416s/iter; left time: 134.9711s\n",
      "\titers: 200, epoch: 6 | loss: 0.0829432\n",
      "\tspeed: 0.0202s/iter; left time: 63.4200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0848205 Vali Loss: 0.0825640 Test Loss: 0.0878789\n",
      "Validation loss decreased (0.082980 --> 0.082564).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0827256\n",
      "\tspeed: 0.0422s/iter; left time: 127.5211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0855440\n",
      "\tspeed: 0.0197s/iter; left time: 57.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0838323 Vali Loss: 0.0826807 Test Loss: 0.0877832\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843407\n",
      "\tspeed: 0.0417s/iter; left time: 116.8176s\n",
      "\titers: 200, epoch: 8 | loss: 0.0877665\n",
      "\tspeed: 0.0216s/iter; left time: 58.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0831006 Vali Loss: 0.0826668 Test Loss: 0.0877134\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820760\n",
      "\tspeed: 0.0355s/iter; left time: 91.3889s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794650\n",
      "\tspeed: 0.0226s/iter; left time: 55.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0823812 Vali Loss: 0.0821069 Test Loss: 0.0877879\n",
      "Validation loss decreased (0.082564 --> 0.082107).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0803931\n",
      "\tspeed: 0.0407s/iter; left time: 95.7799s\n",
      "\titers: 200, epoch: 10 | loss: 0.0818995\n",
      "\tspeed: 0.0212s/iter; left time: 47.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0817312 Vali Loss: 0.0822692 Test Loss: 0.0878709\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779449\n",
      "\tspeed: 0.0457s/iter; left time: 97.3979s\n",
      "\titers: 200, epoch: 11 | loss: 0.0796292\n",
      "\tspeed: 0.0223s/iter; left time: 45.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0812737 Vali Loss: 0.0821334 Test Loss: 0.0877849\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0841580\n",
      "\tspeed: 0.0405s/iter; left time: 77.1938s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793426\n",
      "\tspeed: 0.0212s/iter; left time: 38.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0807289 Vali Loss: 0.0820043 Test Loss: 0.0874370\n",
      "Validation loss decreased (0.082107 --> 0.082004).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0835612\n",
      "\tspeed: 0.0424s/iter; left time: 71.3795s\n",
      "\titers: 200, epoch: 13 | loss: 0.0807545\n",
      "\tspeed: 0.0187s/iter; left time: 29.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0803368 Vali Loss: 0.0819112 Test Loss: 0.0878224\n",
      "Validation loss decreased (0.082004 --> 0.081911).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0794411\n",
      "\tspeed: 0.0398s/iter; left time: 58.2503s\n",
      "\titers: 200, epoch: 14 | loss: 0.0796110\n",
      "\tspeed: 0.0199s/iter; left time: 27.0565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0799793 Vali Loss: 0.0819589 Test Loss: 0.0877723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778464\n",
      "\tspeed: 0.0436s/iter; left time: 54.0256s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784918\n",
      "\tspeed: 0.0240s/iter; left time: 27.3149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 223 | Train Loss: 0.0797116 Vali Loss: 0.0819184 Test Loss: 0.0877586\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0804187\n",
      "\tspeed: 0.0445s/iter; left time: 45.2187s\n",
      "\titers: 200, epoch: 16 | loss: 0.0771086\n",
      "\tspeed: 0.0232s/iter; left time: 21.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0793933 Vali Loss: 0.0818374 Test Loss: 0.0877305\n",
      "Validation loss decreased (0.081911 --> 0.081837).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0803828\n",
      "\tspeed: 0.0406s/iter; left time: 32.1623s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838717\n",
      "\tspeed: 0.0201s/iter; left time: 13.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0791174 Vali Loss: 0.0817423 Test Loss: 0.0878350\n",
      "Validation loss decreased (0.081837 --> 0.081742).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839292\n",
      "\tspeed: 0.0409s/iter; left time: 23.3351s\n",
      "\titers: 200, epoch: 18 | loss: 0.0799814\n",
      "\tspeed: 0.0203s/iter; left time: 9.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0788918 Vali Loss: 0.0817828 Test Loss: 0.0877931\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0774314\n",
      "\tspeed: 0.0406s/iter; left time: 14.0977s\n",
      "\titers: 200, epoch: 19 | loss: 0.0771165\n",
      "\tspeed: 0.0209s/iter; left time: 5.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0786805 Vali Loss: 0.0818339 Test Loss: 0.0878775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814192\n",
      "\tspeed: 0.0403s/iter; left time: 4.9922s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786837\n",
      "\tspeed: 0.0202s/iter; left time: 0.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0784942 Vali Loss: 0.0819315 Test Loss: 0.0879045\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021050533279776573, rmse:0.14508801698684692, mae:0.08783499896526337, rse:0.5491032600402832\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:40.51s\n",
      "Intermediate time for IT: 00h:11m:37.68s\n",
      "Total time: 00h:49m:01.07s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.0721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1467  0.0904\n",
       "        96        0.0394  0.1984  0.1308\n",
       "        168       0.0423  0.2057  0.1380\n",
       "ES      24        0.0151  0.1210  0.0721\n",
       "        96        0.0244  0.1551  0.1000\n",
       "        168       0.0252  0.1580  0.1047\n",
       "FR      24        0.0107  0.1032  0.0587\n",
       "        96        0.0200  0.1414  0.0830\n",
       "        168       0.0224  0.1496  0.0890\n",
       "GB      24        0.0270  0.1643  0.1042\n",
       "        96        0.0480  0.2188  0.1471\n",
       "        168       0.0503  0.2241  0.1529\n",
       "IT      24        0.0107  0.1032  0.0602\n",
       "        96        0.0185  0.1360  0.0825\n",
       "        168       0.0203  0.1426  0.0880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0433s/iter; left time: 189.4831s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0155s/iter; left time: 66.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0346s/iter; left time: 143.6340s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0149s/iter; left time: 60.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0357s/iter; left time: 140.2519s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0169s/iter; left time: 64.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0344s/iter; left time: 127.6084s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0148s/iter; left time: 53.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0371s/iter; left time: 129.3574s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0199s/iter; left time: 67.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0373s/iter; left time: 121.7229s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0173s/iter; left time: 54.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0406s/iter; left time: 123.2912s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0228s/iter; left time: 66.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0370s/iter; left time: 104.0922s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0176s/iter; left time: 47.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0406s/iter; left time: 105.1654s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0170s/iter; left time: 42.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0384s/iter; left time: 90.7968s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0175s/iter; left time: 39.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0344s/iter; left time: 73.6936s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0165s/iter; left time: 33.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0406s/iter; left time: 77.7621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0203s/iter; left time: 36.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0399s/iter; left time: 67.5293s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0204s/iter; left time: 32.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0400s/iter; left time: 58.8179s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0201s/iter; left time: 27.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0368s/iter; left time: 45.7714s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0150s/iter; left time: 17.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0406s/iter; left time: 41.4387s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0187s/iter; left time: 17.1879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0417s/iter; left time: 33.2736s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0188s/iter; left time: 13.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0346s/iter; left time: 19.8085s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0147s/iter; left time: 6.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0373s/iter; left time: 13.0124s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0191s/iter; left time: 4.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0395s/iter; left time: 4.9421s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0176s/iter; left time: 0.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02197897806763649, rmse:0.14825308322906494, mae:0.09260880947113037, rse:0.5232056975364685\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2721842\n",
      "\tspeed: 0.0243s/iter; left time: 106.3451s\n",
      "\titers: 200, epoch: 1 | loss: 0.2545170\n",
      "\tspeed: 0.0229s/iter; left time: 98.2050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.2761312 Vali Loss: 0.2322660 Test Loss: 0.2356385\n",
      "Validation loss decreased (inf --> 0.232266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482331\n",
      "\tspeed: 0.0436s/iter; left time: 181.3371s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319499\n",
      "\tspeed: 0.0168s/iter; left time: 68.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1566612 Vali Loss: 0.1185808 Test Loss: 0.1211408\n",
      "Validation loss decreased (0.232266 --> 0.118581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1081690\n",
      "\tspeed: 0.0416s/iter; left time: 163.4521s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004020\n",
      "\tspeed: 0.0203s/iter; left time: 77.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.1067749 Vali Loss: 0.1074769 Test Loss: 0.1081204\n",
      "Validation loss decreased (0.118581 --> 0.107477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891181\n",
      "\tspeed: 0.0407s/iter; left time: 151.0011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888426\n",
      "\tspeed: 0.0221s/iter; left time: 79.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0955432 Vali Loss: 0.1000804 Test Loss: 0.1024884\n",
      "Validation loss decreased (0.107477 --> 0.100080).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895891\n",
      "\tspeed: 0.0455s/iter; left time: 158.5022s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858524\n",
      "\tspeed: 0.0239s/iter; left time: 81.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0902970 Vali Loss: 0.1001018 Test Loss: 0.1025615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886195\n",
      "\tspeed: 0.0386s/iter; left time: 126.0170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897056\n",
      "\tspeed: 0.0180s/iter; left time: 56.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0877654 Vali Loss: 0.0981362 Test Loss: 0.1006853\n",
      "Validation loss decreased (0.100080 --> 0.098136).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0878300\n",
      "\tspeed: 0.0404s/iter; left time: 122.5511s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826553\n",
      "\tspeed: 0.0179s/iter; left time: 52.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0857944 Vali Loss: 0.0958969 Test Loss: 0.0983018\n",
      "Validation loss decreased (0.098136 --> 0.095897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869670\n",
      "\tspeed: 0.0380s/iter; left time: 106.8424s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836679\n",
      "\tspeed: 0.0155s/iter; left time: 42.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0840915 Vali Loss: 0.0946294 Test Loss: 0.0966067\n",
      "Validation loss decreased (0.095897 --> 0.094629).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806168\n",
      "\tspeed: 0.0346s/iter; left time: 89.6746s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788730\n",
      "\tspeed: 0.0148s/iter; left time: 36.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0832127 Vali Loss: 0.0942125 Test Loss: 0.0963571\n",
      "Validation loss decreased (0.094629 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0863781\n",
      "\tspeed: 0.0393s/iter; left time: 92.8334s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827872\n",
      "\tspeed: 0.0175s/iter; left time: 39.6821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0823142 Vali Loss: 0.0934206 Test Loss: 0.0951447\n",
      "Validation loss decreased (0.094213 --> 0.093421).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0842941\n",
      "\tspeed: 0.0419s/iter; left time: 89.8029s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798917\n",
      "\tspeed: 0.0194s/iter; left time: 39.6135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0812334 Vali Loss: 0.0930360 Test Loss: 0.0947575\n",
      "Validation loss decreased (0.093421 --> 0.093036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834161\n",
      "\tspeed: 0.0394s/iter; left time: 75.4573s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799981\n",
      "\tspeed: 0.0187s/iter; left time: 33.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0807119 Vali Loss: 0.0929712 Test Loss: 0.0947066\n",
      "Validation loss decreased (0.093036 --> 0.092971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815257\n",
      "\tspeed: 0.0393s/iter; left time: 66.4868s\n",
      "\titers: 200, epoch: 13 | loss: 0.0776588\n",
      "\tspeed: 0.0211s/iter; left time: 33.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0801480 Vali Loss: 0.0923747 Test Loss: 0.0944369\n",
      "Validation loss decreased (0.092971 --> 0.092375).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754340\n",
      "\tspeed: 0.0400s/iter; left time: 58.7758s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819355\n",
      "\tspeed: 0.0202s/iter; left time: 27.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0798022 Vali Loss: 0.0923370 Test Loss: 0.0939305\n",
      "Validation loss decreased (0.092375 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803141\n",
      "\tspeed: 0.0408s/iter; left time: 50.7472s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758411\n",
      "\tspeed: 0.0185s/iter; left time: 21.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0792215 Vali Loss: 0.0938695 Test Loss: 0.0954283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0765127\n",
      "\tspeed: 0.0409s/iter; left time: 41.7632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0853249\n",
      "\tspeed: 0.0218s/iter; left time: 20.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0790664 Vali Loss: 0.0919052 Test Loss: 0.0936920\n",
      "Validation loss decreased (0.092337 --> 0.091905).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0840101\n",
      "\tspeed: 0.0400s/iter; left time: 31.8896s\n",
      "\titers: 200, epoch: 17 | loss: 0.0743264\n",
      "\tspeed: 0.0179s/iter; left time: 12.4585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0785786 Vali Loss: 0.0913657 Test Loss: 0.0932587\n",
      "Validation loss decreased (0.091905 --> 0.091366).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0817556\n",
      "\tspeed: 0.0350s/iter; left time: 20.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0756749\n",
      "\tspeed: 0.0148s/iter; left time: 6.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0783503 Vali Loss: 0.0909367 Test Loss: 0.0929703\n",
      "Validation loss decreased (0.091366 --> 0.090937).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806383\n",
      "\tspeed: 0.0398s/iter; left time: 13.8950s\n",
      "\titers: 200, epoch: 19 | loss: 0.0788134\n",
      "\tspeed: 0.0181s/iter; left time: 4.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0782910 Vali Loss: 0.0909684 Test Loss: 0.0929274\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790623\n",
      "\tspeed: 0.0404s/iter; left time: 5.0553s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762136\n",
      "\tspeed: 0.0197s/iter; left time: 0.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0779857 Vali Loss: 0.0904959 Test Loss: 0.0925888\n",
      "Validation loss decreased (0.090937 --> 0.090496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02206687070429325, rmse:0.14854921400547028, mae:0.09258876740932465, rse:0.5242507457733154\n",
      "Intermediate time for DE and pred_len 24: 00h:04m:01.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0430s/iter; left time: 188.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0151s/iter; left time: 64.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0363s/iter; left time: 150.7416s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0158s/iter; left time: 63.9616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0351s/iter; left time: 138.0269s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0161s/iter; left time: 61.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0378s/iter; left time: 140.1385s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0169s/iter; left time: 60.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0415s/iter; left time: 144.5488s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0173s/iter; left time: 58.7146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0412s/iter; left time: 134.3089s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0193s/iter; left time: 61.0326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0417s/iter; left time: 126.4996s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0211s/iter; left time: 62.0929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0438s/iter; left time: 123.3161s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0182s/iter; left time: 49.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0403s/iter; left time: 104.2546s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0210s/iter; left time: 52.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0422s/iter; left time: 99.7800s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0216s/iter; left time: 48.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0380s/iter; left time: 81.4220s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0192s/iter; left time: 39.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0343s/iter; left time: 65.7672s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0149s/iter; left time: 27.1640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0393s/iter; left time: 66.4822s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0181s/iter; left time: 28.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0415s/iter; left time: 60.9568s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0239s/iter; left time: 32.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0439s/iter; left time: 54.6762s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0186s/iter; left time: 21.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0382s/iter; left time: 39.0436s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0150s/iter; left time: 13.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0401s/iter; left time: 31.9453s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0203s/iter; left time: 14.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0436s/iter; left time: 24.9728s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0175s/iter; left time: 8.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0430s/iter; left time: 14.9942s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0224s/iter; left time: 5.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0434s/iter; left time: 5.4207s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0189s/iter; left time: 0.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04150562733411789, rmse:0.2037293016910553, mae:0.13349591195583344, rse:0.721446692943573\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2745755\n",
      "\tspeed: 0.0231s/iter; left time: 101.1925s\n",
      "\titers: 200, epoch: 1 | loss: 0.2692268\n",
      "\tspeed: 0.0205s/iter; left time: 87.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.2751624 Vali Loss: 0.2348203 Test Loss: 0.2388337\n",
      "Validation loss decreased (inf --> 0.234820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551890\n",
      "\tspeed: 0.0430s/iter; left time: 178.6480s\n",
      "\titers: 200, epoch: 2 | loss: 0.1321813\n",
      "\tspeed: 0.0205s/iter; left time: 83.3544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.1654698 Vali Loss: 0.1417630 Test Loss: 0.1481800\n",
      "Validation loss decreased (0.234820 --> 0.141763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1215974\n",
      "\tspeed: 0.0414s/iter; left time: 162.6355s\n",
      "\titers: 200, epoch: 3 | loss: 0.1256834\n",
      "\tspeed: 0.0180s/iter; left time: 68.8743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1263876 Vali Loss: 0.1325889 Test Loss: 0.1409987\n",
      "Validation loss decreased (0.141763 --> 0.132589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1135110\n",
      "\tspeed: 0.0366s/iter; left time: 135.8143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192949\n",
      "\tspeed: 0.0197s/iter; left time: 71.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1174851 Vali Loss: 0.1272122 Test Loss: 0.1361652\n",
      "Validation loss decreased (0.132589 --> 0.127212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163965\n",
      "\tspeed: 0.0412s/iter; left time: 143.5414s\n",
      "\titers: 200, epoch: 5 | loss: 0.1152640\n",
      "\tspeed: 0.0170s/iter; left time: 57.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1131541 Vali Loss: 0.1246094 Test Loss: 0.1332051\n",
      "Validation loss decreased (0.127212 --> 0.124609).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112591\n",
      "\tspeed: 0.0460s/iter; left time: 150.0819s\n",
      "\titers: 200, epoch: 6 | loss: 0.1082482\n",
      "\tspeed: 0.0208s/iter; left time: 65.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1111110 Vali Loss: 0.1238740 Test Loss: 0.1333937\n",
      "Validation loss decreased (0.124609 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057189\n",
      "\tspeed: 0.0440s/iter; left time: 133.6901s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117747\n",
      "\tspeed: 0.0217s/iter; left time: 63.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.1091282 Vali Loss: 0.1267143 Test Loss: 0.1375530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1141506\n",
      "\tspeed: 0.0425s/iter; left time: 119.5498s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009115\n",
      "\tspeed: 0.0194s/iter; left time: 52.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1081073 Vali Loss: 0.1231339 Test Loss: 0.1339826\n",
      "Validation loss decreased (0.123874 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1019052\n",
      "\tspeed: 0.0418s/iter; left time: 108.3479s\n",
      "\titers: 200, epoch: 9 | loss: 0.1077909\n",
      "\tspeed: 0.0195s/iter; left time: 48.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1073068 Vali Loss: 0.1232993 Test Loss: 0.1331413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1092062\n",
      "\tspeed: 0.0459s/iter; left time: 108.6111s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068623\n",
      "\tspeed: 0.0207s/iter; left time: 46.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.1064968 Vali Loss: 0.1219509 Test Loss: 0.1326125\n",
      "Validation loss decreased (0.123134 --> 0.121951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040168\n",
      "\tspeed: 0.0438s/iter; left time: 93.7702s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067823\n",
      "\tspeed: 0.0196s/iter; left time: 40.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1059778 Vali Loss: 0.1218960 Test Loss: 0.1338872\n",
      "Validation loss decreased (0.121951 --> 0.121896).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011791\n",
      "\tspeed: 0.0429s/iter; left time: 82.2716s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045789\n",
      "\tspeed: 0.0198s/iter; left time: 35.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1055520 Vali Loss: 0.1224215 Test Loss: 0.1361842\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020355\n",
      "\tspeed: 0.0422s/iter; left time: 71.3961s\n",
      "\titers: 200, epoch: 13 | loss: 0.1006409\n",
      "\tspeed: 0.0192s/iter; left time: 30.6429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1050931 Vali Loss: 0.1211242 Test Loss: 0.1328582\n",
      "Validation loss decreased (0.121896 --> 0.121124).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023372\n",
      "\tspeed: 0.0430s/iter; left time: 63.2301s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056428\n",
      "\tspeed: 0.0200s/iter; left time: 27.3520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1046984 Vali Loss: 0.1215836 Test Loss: 0.1348134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028019\n",
      "\tspeed: 0.0424s/iter; left time: 52.7950s\n",
      "\titers: 200, epoch: 15 | loss: 0.1016776\n",
      "\tspeed: 0.0204s/iter; left time: 23.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.1043435 Vali Loss: 0.1219964 Test Loss: 0.1366068\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1028563\n",
      "\tspeed: 0.0417s/iter; left time: 42.5348s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091383\n",
      "\tspeed: 0.0203s/iter; left time: 18.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1043203 Vali Loss: 0.1209410 Test Loss: 0.1350278\n",
      "Validation loss decreased (0.121124 --> 0.120941).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068253\n",
      "\tspeed: 0.0427s/iter; left time: 34.0030s\n",
      "\titers: 200, epoch: 17 | loss: 0.1018474\n",
      "\tspeed: 0.0199s/iter; left time: 13.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1039987 Vali Loss: 0.1214914 Test Loss: 0.1367325\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1014489\n",
      "\tspeed: 0.0429s/iter; left time: 24.5558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990626\n",
      "\tspeed: 0.0180s/iter; left time: 8.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1036466 Vali Loss: 0.1200883 Test Loss: 0.1337987\n",
      "Validation loss decreased (0.120941 --> 0.120088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1060394\n",
      "\tspeed: 0.0420s/iter; left time: 14.6721s\n",
      "\titers: 200, epoch: 19 | loss: 0.1063231\n",
      "\tspeed: 0.0203s/iter; left time: 5.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.1036820 Vali Loss: 0.1203940 Test Loss: 0.1338672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1069428\n",
      "\tspeed: 0.0446s/iter; left time: 5.5812s\n",
      "\titers: 200, epoch: 20 | loss: 0.1037648\n",
      "\tspeed: 0.0219s/iter; left time: 0.5476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1033537 Vali Loss: 0.1214264 Test Loss: 0.1366773\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04148979112505913, rmse:0.20369042456150055, mae:0.1337987184524536, rse:0.7213089466094971\n",
      "Intermediate time for DE and pred_len 96: 00h:04m:15.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0439s/iter; left time: 191.5382s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0152s/iter; left time: 64.8704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0377s/iter; left time: 155.8441s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0162s/iter; left time: 65.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0376s/iter; left time: 147.3971s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0162s/iter; left time: 61.6237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0406s/iter; left time: 150.0676s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0174s/iter; left time: 62.5027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0362s/iter; left time: 125.5862s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0153s/iter; left time: 51.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0391s/iter; left time: 126.8707s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0196s/iter; left time: 61.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0369s/iter; left time: 111.4829s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0170s/iter; left time: 49.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0430s/iter; left time: 120.3620s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0196s/iter; left time: 52.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0443s/iter; left time: 114.0898s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0219s/iter; left time: 54.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0420s/iter; left time: 98.9149s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0224s/iter; left time: 50.5666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0387s/iter; left time: 82.4958s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0176s/iter; left time: 35.8090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0394s/iter; left time: 75.2060s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0220s/iter; left time: 39.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0391s/iter; left time: 65.9126s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0192s/iter; left time: 30.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0452s/iter; left time: 66.0310s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0166s/iter; left time: 22.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0378s/iter; left time: 46.8659s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0168s/iter; left time: 19.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0403s/iter; left time: 40.8990s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0160s/iter; left time: 14.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0366s/iter; left time: 29.0507s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0187s/iter; left time: 12.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0402s/iter; left time: 22.9373s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0193s/iter; left time: 9.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0355s/iter; left time: 12.3296s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0152s/iter; left time: 3.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04356519505381584, rmse:0.2087227702140808, mae:0.1395985186100006, rse:0.7393128275871277\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812734\n",
      "\tspeed: 0.0232s/iter; left time: 101.0154s\n",
      "\titers: 200, epoch: 1 | loss: 0.2648552\n",
      "\tspeed: 0.0195s/iter; left time: 82.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.2822170 Vali Loss: 0.2397827 Test Loss: 0.2450302\n",
      "Validation loss decreased (inf --> 0.239783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632033\n",
      "\tspeed: 0.0471s/iter; left time: 194.9388s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432949\n",
      "\tspeed: 0.0201s/iter; left time: 81.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1688149 Vali Loss: 0.1457720 Test Loss: 0.1536164\n",
      "Validation loss decreased (0.239783 --> 0.145772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1266351\n",
      "\tspeed: 0.0414s/iter; left time: 162.2200s\n",
      "\titers: 200, epoch: 3 | loss: 0.1198552\n",
      "\tspeed: 0.0170s/iter; left time: 64.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1316933 Vali Loss: 0.1368362 Test Loss: 0.1507061\n",
      "Validation loss decreased (0.145772 --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1193674\n",
      "\tspeed: 0.0445s/iter; left time: 164.2317s\n",
      "\titers: 200, epoch: 4 | loss: 0.1206695\n",
      "\tspeed: 0.0182s/iter; left time: 65.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1227247 Vali Loss: 0.1357975 Test Loss: 0.1491872\n",
      "Validation loss decreased (0.136836 --> 0.135798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187348\n",
      "\tspeed: 0.0410s/iter; left time: 142.2345s\n",
      "\titers: 200, epoch: 5 | loss: 0.1190373\n",
      "\tspeed: 0.0179s/iter; left time: 60.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1191489 Vali Loss: 0.1308743 Test Loss: 0.1448017\n",
      "Validation loss decreased (0.135798 --> 0.130874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146746\n",
      "\tspeed: 0.0375s/iter; left time: 121.6796s\n",
      "\titers: 200, epoch: 6 | loss: 0.1148309\n",
      "\tspeed: 0.0152s/iter; left time: 47.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1166092 Vali Loss: 0.1314674 Test Loss: 0.1459267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1175115\n",
      "\tspeed: 0.0387s/iter; left time: 116.8615s\n",
      "\titers: 200, epoch: 7 | loss: 0.1088397\n",
      "\tspeed: 0.0181s/iter; left time: 52.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1151693 Vali Loss: 0.1312253 Test Loss: 0.1448718\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1191927\n",
      "\tspeed: 0.0398s/iter; left time: 111.5100s\n",
      "\titers: 200, epoch: 8 | loss: 0.1117679\n",
      "\tspeed: 0.0174s/iter; left time: 47.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1141006 Vali Loss: 0.1306444 Test Loss: 0.1441707\n",
      "Validation loss decreased (0.130874 --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1125659\n",
      "\tspeed: 0.0387s/iter; left time: 99.6633s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103978\n",
      "\tspeed: 0.0180s/iter; left time: 44.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1131375 Vali Loss: 0.1308488 Test Loss: 0.1439586\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097929\n",
      "\tspeed: 0.0390s/iter; left time: 91.8675s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076796\n",
      "\tspeed: 0.0198s/iter; left time: 44.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1123829 Vali Loss: 0.1314475 Test Loss: 0.1447518\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068592\n",
      "\tspeed: 0.0413s/iter; left time: 87.9852s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085388\n",
      "\tspeed: 0.0231s/iter; left time: 46.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.1117776 Vali Loss: 0.1311427 Test Loss: 0.1450391\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080086\n",
      "\tspeed: 0.0432s/iter; left time: 82.4600s\n",
      "\titers: 200, epoch: 12 | loss: 0.1089400\n",
      "\tspeed: 0.0164s/iter; left time: 29.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1112884 Vali Loss: 0.1306694 Test Loss: 0.1443284\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1129659\n",
      "\tspeed: 0.0410s/iter; left time: 69.0417s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087663\n",
      "\tspeed: 0.0205s/iter; left time: 32.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1107222 Vali Loss: 0.1300552 Test Loss: 0.1437648\n",
      "Validation loss decreased (0.130644 --> 0.130055).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1106686\n",
      "\tspeed: 0.0391s/iter; left time: 57.1526s\n",
      "\titers: 200, epoch: 14 | loss: 0.1079151\n",
      "\tspeed: 0.0164s/iter; left time: 22.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.1102911 Vali Loss: 0.1309756 Test Loss: 0.1456672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1096638\n",
      "\tspeed: 0.0417s/iter; left time: 51.6157s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065728\n",
      "\tspeed: 0.0165s/iter; left time: 18.7695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1099320 Vali Loss: 0.1304136 Test Loss: 0.1437775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1128930\n",
      "\tspeed: 0.0394s/iter; left time: 40.0729s\n",
      "\titers: 200, epoch: 16 | loss: 0.1056558\n",
      "\tspeed: 0.0172s/iter; left time: 15.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1095359 Vali Loss: 0.1290297 Test Loss: 0.1434999\n",
      "Validation loss decreased (0.130055 --> 0.129030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1129074\n",
      "\tspeed: 0.0367s/iter; left time: 29.0794s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060182\n",
      "\tspeed: 0.0152s/iter; left time: 10.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1093078 Vali Loss: 0.1279821 Test Loss: 0.1426028\n",
      "Validation loss decreased (0.129030 --> 0.127982).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089246\n",
      "\tspeed: 0.0375s/iter; left time: 21.3832s\n",
      "\titers: 200, epoch: 18 | loss: 0.1129903\n",
      "\tspeed: 0.0177s/iter; left time: 8.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.1088755 Vali Loss: 0.1292565 Test Loss: 0.1439340\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1071319\n",
      "\tspeed: 0.0373s/iter; left time: 12.9416s\n",
      "\titers: 200, epoch: 19 | loss: 0.1072017\n",
      "\tspeed: 0.0170s/iter; left time: 4.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1088933 Vali Loss: 0.1299791 Test Loss: 0.1445618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1044815\n",
      "\tspeed: 0.0412s/iter; left time: 5.1139s\n",
      "\titers: 200, epoch: 20 | loss: 0.1130169\n",
      "\tspeed: 0.0201s/iter; left time: 0.4823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1085727 Vali Loss: 0.1287442 Test Loss: 0.1427801\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046037085354328156, rmse:0.2145625501871109, mae:0.1426028162240982, rse:0.7599977850914001\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:59.59s\n",
      "Intermediate time for DE: 00h:12m:16.41s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0435s/iter; left time: 190.3553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0148s/iter; left time: 63.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0327s/iter; left time: 135.9060s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0163s/iter; left time: 66.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0368s/iter; left time: 144.6387s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0149s/iter; left time: 57.1036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0402s/iter; left time: 149.0718s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0257s/iter; left time: 92.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0353s/iter; left time: 122.9316s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0159s/iter; left time: 53.7507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0395s/iter; left time: 128.7514s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0187s/iter; left time: 59.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0409s/iter; left time: 124.2592s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0198s/iter; left time: 58.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0431s/iter; left time: 121.1090s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0213s/iter; left time: 57.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0401s/iter; left time: 103.8674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0204s/iter; left time: 50.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0402s/iter; left time: 94.9955s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0202s/iter; left time: 45.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0418s/iter; left time: 89.4398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0200s/iter; left time: 40.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0419s/iter; left time: 80.2351s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0196s/iter; left time: 35.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0396s/iter; left time: 67.0201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0189s/iter; left time: 30.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0443s/iter; left time: 65.1099s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0195s/iter; left time: 26.7234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0406s/iter; left time: 50.5078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0201s/iter; left time: 23.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0405s/iter; left time: 41.3443s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0196s/iter; left time: 18.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0420s/iter; left time: 33.4928s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0221s/iter; left time: 15.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0412s/iter; left time: 23.5835s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0206s/iter; left time: 9.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0402s/iter; left time: 14.0362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0239s/iter; left time: 5.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0416s/iter; left time: 5.2052s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0223s/iter; left time: 0.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026859937235713005, rmse:0.1638900190591812, mae:0.10591384768486023, rse:0.5653740763664246\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2846910\n",
      "\tspeed: 0.0228s/iter; left time: 99.8951s\n",
      "\titers: 200, epoch: 1 | loss: 0.2726133\n",
      "\tspeed: 0.0201s/iter; left time: 86.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.2926167 Vali Loss: 0.2415705 Test Loss: 0.2631590\n",
      "Validation loss decreased (inf --> 0.241570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474976\n",
      "\tspeed: 0.0414s/iter; left time: 172.1532s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268219\n",
      "\tspeed: 0.0199s/iter; left time: 80.7015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.1575704 Vali Loss: 0.1085933 Test Loss: 0.1230968\n",
      "Validation loss decreased (0.241570 --> 0.108593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0972578\n",
      "\tspeed: 0.0406s/iter; left time: 159.4984s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915387\n",
      "\tspeed: 0.0204s/iter; left time: 78.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1023461 Vali Loss: 0.1003349 Test Loss: 0.1123432\n",
      "Validation loss decreased (0.108593 --> 0.100335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907324\n",
      "\tspeed: 0.0447s/iter; left time: 165.7056s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907905\n",
      "\tspeed: 0.0229s/iter; left time: 82.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0922343 Vali Loss: 0.0962823 Test Loss: 0.1112334\n",
      "Validation loss decreased (0.100335 --> 0.096282).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833255\n",
      "\tspeed: 0.0431s/iter; left time: 150.2721s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889493\n",
      "\tspeed: 0.0215s/iter; left time: 72.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0880692 Vali Loss: 0.0964027 Test Loss: 0.1125074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861537\n",
      "\tspeed: 0.0437s/iter; left time: 142.6286s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848577\n",
      "\tspeed: 0.0244s/iter; left time: 77.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0863465 Vali Loss: 0.0961963 Test Loss: 0.1143982\n",
      "Validation loss decreased (0.096282 --> 0.096196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867636\n",
      "\tspeed: 0.0465s/iter; left time: 141.0816s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810365\n",
      "\tspeed: 0.0240s/iter; left time: 70.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0849434 Vali Loss: 0.0958150 Test Loss: 0.1149141\n",
      "Validation loss decreased (0.096196 --> 0.095815).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857168\n",
      "\tspeed: 0.0387s/iter; left time: 108.9611s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765620\n",
      "\tspeed: 0.0220s/iter; left time: 59.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0839813 Vali Loss: 0.0954577 Test Loss: 0.1139534\n",
      "Validation loss decreased (0.095815 --> 0.095458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816585\n",
      "\tspeed: 0.0420s/iter; left time: 108.7967s\n",
      "\titers: 200, epoch: 9 | loss: 0.0860098\n",
      "\tspeed: 0.0200s/iter; left time: 49.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0829976 Vali Loss: 0.0949424 Test Loss: 0.1124260\n",
      "Validation loss decreased (0.095458 --> 0.094942).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758343\n",
      "\tspeed: 0.0431s/iter; left time: 101.9933s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839384\n",
      "\tspeed: 0.0176s/iter; left time: 39.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0826377 Vali Loss: 0.0951414 Test Loss: 0.1145257\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811790\n",
      "\tspeed: 0.0433s/iter; left time: 92.7424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0772140\n",
      "\tspeed: 0.0238s/iter; left time: 48.5164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0818311 Vali Loss: 0.0955937 Test Loss: 0.1145437\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838942\n",
      "\tspeed: 0.0423s/iter; left time: 81.1573s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844036\n",
      "\tspeed: 0.0163s/iter; left time: 29.6119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0815183 Vali Loss: 0.0939972 Test Loss: 0.1111869\n",
      "Validation loss decreased (0.094942 --> 0.093997).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823378\n",
      "\tspeed: 0.0391s/iter; left time: 66.1277s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742934\n",
      "\tspeed: 0.0184s/iter; left time: 29.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0810441 Vali Loss: 0.0945207 Test Loss: 0.1117665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795040\n",
      "\tspeed: 0.0372s/iter; left time: 54.6020s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800683\n",
      "\tspeed: 0.0237s/iter; left time: 32.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0807827 Vali Loss: 0.0942772 Test Loss: 0.1117615\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812870\n",
      "\tspeed: 0.0442s/iter; left time: 55.0757s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817963\n",
      "\tspeed: 0.0197s/iter; left time: 22.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0804734 Vali Loss: 0.0958008 Test Loss: 0.1114092\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0762049\n",
      "\tspeed: 0.0399s/iter; left time: 40.7580s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810765\n",
      "\tspeed: 0.0201s/iter; left time: 18.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0802297 Vali Loss: 0.0947608 Test Loss: 0.1110980\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810842\n",
      "\tspeed: 0.0399s/iter; left time: 31.8312s\n",
      "\titers: 200, epoch: 17 | loss: 0.0765186\n",
      "\tspeed: 0.0179s/iter; left time: 12.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0800327 Vali Loss: 0.0935502 Test Loss: 0.1104114\n",
      "Validation loss decreased (0.093997 --> 0.093550).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781353\n",
      "\tspeed: 0.0368s/iter; left time: 21.0863s\n",
      "\titers: 200, epoch: 18 | loss: 0.0784078\n",
      "\tspeed: 0.0224s/iter; left time: 10.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0798923 Vali Loss: 0.0934620 Test Loss: 0.1093775\n",
      "Validation loss decreased (0.093550 --> 0.093462).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748001\n",
      "\tspeed: 0.0401s/iter; left time: 13.9884s\n",
      "\titers: 200, epoch: 19 | loss: 0.0821338\n",
      "\tspeed: 0.0206s/iter; left time: 5.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0798001 Vali Loss: 0.0938784 Test Loss: 0.1097977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804354\n",
      "\tspeed: 0.0374s/iter; left time: 4.6728s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798344\n",
      "\tspeed: 0.0175s/iter; left time: 0.4369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0795825 Vali Loss: 0.0931064 Test Loss: 0.1094512\n",
      "Validation loss decreased (0.093462 --> 0.093106).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029882589355111122, rmse:0.17286580801010132, mae:0.10945114493370056, rse:0.5963380336761475\n",
      "Intermediate time for GB and pred_len 24: 00h:04m:15.07s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0430s/iter; left time: 188.4884s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0152s/iter; left time: 65.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0358s/iter; left time: 148.7707s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0164s/iter; left time: 66.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0376s/iter; left time: 147.8545s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0163s/iter; left time: 62.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0402s/iter; left time: 149.1697s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0186s/iter; left time: 67.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0405s/iter; left time: 140.9723s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0170s/iter; left time: 57.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0388s/iter; left time: 126.4360s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0169s/iter; left time: 53.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0425s/iter; left time: 129.0258s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0202s/iter; left time: 59.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0442s/iter; left time: 124.2065s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0175s/iter; left time: 47.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0427s/iter; left time: 110.5375s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0198s/iter; left time: 49.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0402s/iter; left time: 95.0017s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0168s/iter; left time: 38.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0358s/iter; left time: 76.5532s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0211s/iter; left time: 43.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0355s/iter; left time: 68.0435s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0150s/iter; left time: 27.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0347s/iter; left time: 58.8282s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0150s/iter; left time: 23.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0398s/iter; left time: 58.4047s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0171s/iter; left time: 23.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0372s/iter; left time: 46.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0171s/iter; left time: 19.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0384s/iter; left time: 39.1689s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0150s/iter; left time: 13.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2884372\n",
      "\tspeed: 0.0267s/iter; left time: 117.0733s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747863\n",
      "\tspeed: 0.0177s/iter; left time: 75.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.2938896 Vali Loss: 0.2499466 Test Loss: 0.2730130\n",
      "Validation loss decreased (inf --> 0.249947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520033\n",
      "\tspeed: 0.0412s/iter; left time: 171.0818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1356943\n",
      "\tspeed: 0.0178s/iter; left time: 72.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1651964 Vali Loss: 0.1318234 Test Loss: 0.1534363\n",
      "Validation loss decreased (0.249947 --> 0.131823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1237962\n",
      "\tspeed: 0.0358s/iter; left time: 140.8860s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129839\n",
      "\tspeed: 0.0151s/iter; left time: 57.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.1195505 Vali Loss: 0.1288494 Test Loss: 0.1563801\n",
      "Validation loss decreased (0.131823 --> 0.128849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1170108\n",
      "\tspeed: 0.0395s/iter; left time: 146.4454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1174021\n",
      "\tspeed: 0.0185s/iter; left time: 66.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.1124832 Vali Loss: 0.1280748 Test Loss: 0.1573510\n",
      "Validation loss decreased (0.128849 --> 0.128075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121775\n",
      "\tspeed: 0.0392s/iter; left time: 136.4653s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137156\n",
      "\tspeed: 0.0167s/iter; left time: 56.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1097073 Vali Loss: 0.1282495 Test Loss: 0.1588879\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1099907\n",
      "\tspeed: 0.0440s/iter; left time: 143.4599s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046706\n",
      "\tspeed: 0.0192s/iter; left time: 60.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.1083800 Vali Loss: 0.1289193 Test Loss: 0.1627320\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1065593\n",
      "\tspeed: 0.0402s/iter; left time: 121.9594s\n",
      "\titers: 200, epoch: 7 | loss: 0.1135744\n",
      "\tspeed: 0.0177s/iter; left time: 51.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1073907 Vali Loss: 0.1286131 Test Loss: 0.1610762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1053690\n",
      "\tspeed: 0.0411s/iter; left time: 115.6703s\n",
      "\titers: 200, epoch: 8 | loss: 0.1122044\n",
      "\tspeed: 0.0166s/iter; left time: 44.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1064029 Vali Loss: 0.1285266 Test Loss: 0.1602909\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083794\n",
      "\tspeed: 0.0368s/iter; left time: 95.1511s\n",
      "\titers: 200, epoch: 9 | loss: 0.1089216\n",
      "\tspeed: 0.0187s/iter; left time: 46.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1057083 Vali Loss: 0.1278156 Test Loss: 0.1567183\n",
      "Validation loss decreased (0.128075 --> 0.127816).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061578\n",
      "\tspeed: 0.0383s/iter; left time: 90.5282s\n",
      "\titers: 200, epoch: 10 | loss: 0.1020783\n",
      "\tspeed: 0.0162s/iter; left time: 36.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1050890 Vali Loss: 0.1274880 Test Loss: 0.1587726\n",
      "Validation loss decreased (0.127816 --> 0.127488).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040444\n",
      "\tspeed: 0.0422s/iter; left time: 90.3190s\n",
      "\titers: 200, epoch: 11 | loss: 0.1054638\n",
      "\tspeed: 0.0198s/iter; left time: 40.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1047036 Vali Loss: 0.1277202 Test Loss: 0.1562177\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1064437\n",
      "\tspeed: 0.0417s/iter; left time: 79.9505s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029790\n",
      "\tspeed: 0.0154s/iter; left time: 28.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1041447 Vali Loss: 0.1276648 Test Loss: 0.1580956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009996\n",
      "\tspeed: 0.0377s/iter; left time: 63.8546s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043827\n",
      "\tspeed: 0.0173s/iter; left time: 27.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1039346 Vali Loss: 0.1263682 Test Loss: 0.1542069\n",
      "Validation loss decreased (0.127488 --> 0.126368).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028414\n",
      "\tspeed: 0.0379s/iter; left time: 55.6054s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043060\n",
      "\tspeed: 0.0164s/iter; left time: 22.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1265923 Test Loss: 0.1548574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1049191\n",
      "\tspeed: 0.0402s/iter; left time: 49.9972s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034089\n",
      "\tspeed: 0.0183s/iter; left time: 20.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1032026 Vali Loss: 0.1266271 Test Loss: 0.1559636\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0956138\n",
      "\tspeed: 0.0410s/iter; left time: 41.8472s\n",
      "\titers: 200, epoch: 16 | loss: 0.0995768\n",
      "\tspeed: 0.0196s/iter; left time: 18.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.1030918 Vali Loss: 0.1263742 Test Loss: 0.1539116\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0985429\n",
      "\tspeed: 0.0407s/iter; left time: 32.4426s\n",
      "\titers: 200, epoch: 17 | loss: 0.0990500\n",
      "\tspeed: 0.0197s/iter; left time: 13.7169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1027496 Vali Loss: 0.1258379 Test Loss: 0.1540648\n",
      "Validation loss decreased (0.126368 --> 0.125838).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1027168\n",
      "\tspeed: 0.0371s/iter; left time: 21.2536s\n",
      "\titers: 200, epoch: 18 | loss: 0.1045104\n",
      "\tspeed: 0.0151s/iter; left time: 7.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1025700 Vali Loss: 0.1264045 Test Loss: 0.1539411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973583\n",
      "\tspeed: 0.0401s/iter; left time: 14.0009s\n",
      "\titers: 200, epoch: 19 | loss: 0.1044858\n",
      "\tspeed: 0.0194s/iter; left time: 4.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1024406 Vali Loss: 0.1257624 Test Loss: 0.1536622\n",
      "Validation loss decreased (0.125838 --> 0.125762).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1020775\n",
      "\tspeed: 0.0403s/iter; left time: 5.0356s\n",
      "\titers: 200, epoch: 20 | loss: 0.1067188\n",
      "\tspeed: 0.0173s/iter; left time: 0.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1022315 Vali Loss: 0.1262378 Test Loss: 0.1535022\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05444870516657829, rmse:0.2333424687385559, mae:0.15366211533546448, rse:0.8069307208061218\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:36.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0438s/iter; left time: 191.2010s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0152s/iter; left time: 64.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0362s/iter; left time: 149.9088s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0154s/iter; left time: 62.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0358s/iter; left time: 140.1314s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0161s/iter; left time: 61.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0384s/iter; left time: 141.7215s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0188s/iter; left time: 67.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0393s/iter; left time: 136.4173s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0171s/iter; left time: 57.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0369s/iter; left time: 119.6598s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0163s/iter; left time: 51.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0347s/iter; left time: 104.8698s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0152s/iter; left time: 44.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0350s/iter; left time: 97.9654s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0158s/iter; left time: 42.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0368s/iter; left time: 94.8146s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0181s/iter; left time: 44.9458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0375s/iter; left time: 88.2266s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0163s/iter; left time: 36.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0428s/iter; left time: 91.3031s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0181s/iter; left time: 36.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0398s/iter; left time: 75.8478s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0167s/iter; left time: 30.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0365s/iter; left time: 61.4309s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0165s/iter; left time: 26.1725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2910986\n",
      "\tspeed: 0.0211s/iter; left time: 91.9743s\n",
      "\titers: 200, epoch: 1 | loss: 0.2834949\n",
      "\tspeed: 0.0173s/iter; left time: 73.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.2923341 Vali Loss: 0.2478191 Test Loss: 0.2692312\n",
      "Validation loss decreased (inf --> 0.247819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1509961\n",
      "\tspeed: 0.0372s/iter; left time: 153.8542s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339484\n",
      "\tspeed: 0.0173s/iter; left time: 69.7183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1644157 Vali Loss: 0.1374244 Test Loss: 0.1619911\n",
      "Validation loss decreased (0.247819 --> 0.137424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1268936\n",
      "\tspeed: 0.0398s/iter; left time: 155.7353s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223414\n",
      "\tspeed: 0.0175s/iter; left time: 66.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1241407 Vali Loss: 0.1313642 Test Loss: 0.1588054\n",
      "Validation loss decreased (0.137424 --> 0.131364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162787\n",
      "\tspeed: 0.0452s/iter; left time: 166.9792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1151809\n",
      "\tspeed: 0.0188s/iter; left time: 67.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1166980 Vali Loss: 0.1309440 Test Loss: 0.1621463\n",
      "Validation loss decreased (0.131364 --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1171696\n",
      "\tspeed: 0.0398s/iter; left time: 138.0942s\n",
      "\titers: 200, epoch: 5 | loss: 0.1122425\n",
      "\tspeed: 0.0162s/iter; left time: 54.5908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1139985 Vali Loss: 0.1325590 Test Loss: 0.1652431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128479\n",
      "\tspeed: 0.0376s/iter; left time: 121.9385s\n",
      "\titers: 200, epoch: 6 | loss: 0.1111952\n",
      "\tspeed: 0.0167s/iter; left time: 52.4481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1127247 Vali Loss: 0.1303820 Test Loss: 0.1614654\n",
      "Validation loss decreased (0.130944 --> 0.130382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101843\n",
      "\tspeed: 0.0437s/iter; left time: 132.1834s\n",
      "\titers: 200, epoch: 7 | loss: 0.1144683\n",
      "\tspeed: 0.0197s/iter; left time: 57.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.1113464 Vali Loss: 0.1307575 Test Loss: 0.1610118\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114429\n",
      "\tspeed: 0.0357s/iter; left time: 99.9061s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068022\n",
      "\tspeed: 0.0162s/iter; left time: 43.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1105503 Vali Loss: 0.1301013 Test Loss: 0.1594315\n",
      "Validation loss decreased (0.130382 --> 0.130101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1073766\n",
      "\tspeed: 0.0354s/iter; left time: 91.2837s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039732\n",
      "\tspeed: 0.0152s/iter; left time: 37.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1099073 Vali Loss: 0.1295959 Test Loss: 0.1585122\n",
      "Validation loss decreased (0.130101 --> 0.129596).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061911\n",
      "\tspeed: 0.0376s/iter; left time: 88.5103s\n",
      "\titers: 200, epoch: 10 | loss: 0.1109751\n",
      "\tspeed: 0.0160s/iter; left time: 36.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.1095424 Vali Loss: 0.1308877 Test Loss: 0.1626594\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129102\n",
      "\tspeed: 0.0367s/iter; left time: 78.2824s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085048\n",
      "\tspeed: 0.0153s/iter; left time: 30.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1089675 Vali Loss: 0.1291195 Test Loss: 0.1578232\n",
      "Validation loss decreased (0.129596 --> 0.129120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1070272\n",
      "\tspeed: 0.0356s/iter; left time: 67.8739s\n",
      "\titers: 200, epoch: 12 | loss: 0.1068779\n",
      "\tspeed: 0.0202s/iter; left time: 36.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1084242 Vali Loss: 0.1284974 Test Loss: 0.1579687\n",
      "Validation loss decreased (0.129120 --> 0.128497).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1096114\n",
      "\tspeed: 0.0418s/iter; left time: 70.3747s\n",
      "\titers: 200, epoch: 13 | loss: 0.1048709\n",
      "\tspeed: 0.0200s/iter; left time: 31.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1081906 Vali Loss: 0.1276691 Test Loss: 0.1578244\n",
      "Validation loss decreased (0.128497 --> 0.127669).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1105448\n",
      "\tspeed: 0.0368s/iter; left time: 53.7339s\n",
      "\titers: 200, epoch: 14 | loss: 0.1075893\n",
      "\tspeed: 0.0176s/iter; left time: 23.9206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1080442 Vali Loss: 0.1281609 Test Loss: 0.1572570\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1092115\n",
      "\tspeed: 0.0383s/iter; left time: 47.4332s\n",
      "\titers: 200, epoch: 15 | loss: 0.1053336\n",
      "\tspeed: 0.0175s/iter; left time: 19.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1076674 Vali Loss: 0.1286696 Test Loss: 0.1582996\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044834\n",
      "\tspeed: 0.0363s/iter; left time: 36.8615s\n",
      "\titers: 200, epoch: 16 | loss: 0.1047895\n",
      "\tspeed: 0.0165s/iter; left time: 15.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1073679 Vali Loss: 0.1284060 Test Loss: 0.1590570\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1063645\n",
      "\tspeed: 0.0374s/iter; left time: 29.6349s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060797\n",
      "\tspeed: 0.0178s/iter; left time: 12.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1071399 Vali Loss: 0.1274910 Test Loss: 0.1575341\n",
      "Validation loss decreased (0.127669 --> 0.127491).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051314\n",
      "\tspeed: 0.0391s/iter; left time: 22.3002s\n",
      "\titers: 200, epoch: 18 | loss: 0.1067741\n",
      "\tspeed: 0.0167s/iter; left time: 7.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1070178 Vali Loss: 0.1272823 Test Loss: 0.1581545\n",
      "Validation loss decreased (0.127491 --> 0.127282).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1085588\n",
      "\tspeed: 0.0391s/iter; left time: 13.5558s\n",
      "\titers: 200, epoch: 19 | loss: 0.1043933\n",
      "\tspeed: 0.0196s/iter; left time: 4.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1068289 Vali Loss: 0.1283977 Test Loss: 0.1593443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073587\n",
      "\tspeed: 0.0384s/iter; left time: 4.7576s\n",
      "\titers: 200, epoch: 20 | loss: 0.1076517\n",
      "\tspeed: 0.0181s/iter; left time: 0.4347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1066923 Vali Loss: 0.1281582 Test Loss: 0.1594106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05579496920108795, rmse:0.23620958626270294, mae:0.1581544131040573, rse:0.8189725875854492\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:15.10s\n",
      "Intermediate time for GB: 00h:11m:06.95s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0437s/iter; left time: 191.3045s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0156s/iter; left time: 66.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0329s/iter; left time: 136.5774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0158s/iter; left time: 63.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0343s/iter; left time: 135.0492s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0182s/iter; left time: 69.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0414s/iter; left time: 153.5005s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0228s/iter; left time: 82.2494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0399s/iter; left time: 138.9380s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0163s/iter; left time: 55.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0393s/iter; left time: 128.0170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0201s/iter; left time: 63.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0376s/iter; left time: 114.3001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0164s/iter; left time: 48.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0329s/iter; left time: 92.6402s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0192s/iter; left time: 52.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0370s/iter; left time: 95.8548s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0180s/iter; left time: 44.8744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0367s/iter; left time: 86.8036s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0186s/iter; left time: 42.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0404s/iter; left time: 86.5660s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0216s/iter; left time: 44.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0389s/iter; left time: 74.5842s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0193s/iter; left time: 35.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0354s/iter; left time: 59.8559s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0110s/iter; left time: 17.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0377s/iter; left time: 55.3768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0239s/iter; left time: 32.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0388s/iter; left time: 48.3152s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0198s/iter; left time: 22.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0378s/iter; left time: 38.5486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0193s/iter; left time: 17.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0386s/iter; left time: 30.7793s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0204s/iter; left time: 14.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0401s/iter; left time: 22.9997s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0207s/iter; left time: 9.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0376s/iter; left time: 13.1137s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0200s/iter; left time: 4.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0399s/iter; left time: 4.9875s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0182s/iter; left time: 0.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02119249477982521, rmse:0.14557641744613647, mae:0.08472280204296112, rse:0.4284138083457947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2933527\n",
      "\tspeed: 0.0215s/iter; left time: 94.3211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2704865\n",
      "\tspeed: 0.0245s/iter; left time: 104.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.2947414 Vali Loss: 0.2184829 Test Loss: 0.2361712\n",
      "Validation loss decreased (inf --> 0.218483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535339\n",
      "\tspeed: 0.0402s/iter; left time: 167.3059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133334\n",
      "\tspeed: 0.0243s/iter; left time: 98.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1637773 Vali Loss: 0.0885669 Test Loss: 0.0970050\n",
      "Validation loss decreased (0.218483 --> 0.088567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1018822\n",
      "\tspeed: 0.0428s/iter; left time: 168.2722s\n",
      "\titers: 200, epoch: 3 | loss: 0.0948918\n",
      "\tspeed: 0.0180s/iter; left time: 68.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1007216 Vali Loss: 0.0790505 Test Loss: 0.0879022\n",
      "Validation loss decreased (0.088567 --> 0.079051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878256\n",
      "\tspeed: 0.0343s/iter; left time: 127.0957s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835657\n",
      "\tspeed: 0.0164s/iter; left time: 59.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0883169 Vali Loss: 0.0730279 Test Loss: 0.0804366\n",
      "Validation loss decreased (0.079051 --> 0.073028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824891\n",
      "\tspeed: 0.0420s/iter; left time: 146.4944s\n",
      "\titers: 200, epoch: 5 | loss: 0.0751157\n",
      "\tspeed: 0.0207s/iter; left time: 70.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0807013 Vali Loss: 0.0705443 Test Loss: 0.0847321\n",
      "Validation loss decreased (0.073028 --> 0.070544).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0724511\n",
      "\tspeed: 0.0372s/iter; left time: 121.4034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762253\n",
      "\tspeed: 0.0177s/iter; left time: 55.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0764399 Vali Loss: 0.0675259 Test Loss: 0.0945590\n",
      "Validation loss decreased (0.070544 --> 0.067526).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760236\n",
      "\tspeed: 0.0377s/iter; left time: 114.3453s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679494\n",
      "\tspeed: 0.0204s/iter; left time: 59.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0736369 Vali Loss: 0.0678774 Test Loss: 0.0992442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708459\n",
      "\tspeed: 0.0347s/iter; left time: 97.5696s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680928\n",
      "\tspeed: 0.0188s/iter; left time: 51.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0709821 Vali Loss: 0.0655568 Test Loss: 0.0969620\n",
      "Validation loss decreased (0.067526 --> 0.065557).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0714074\n",
      "\tspeed: 0.0390s/iter; left time: 100.9205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749444\n",
      "\tspeed: 0.0204s/iter; left time: 50.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0694430 Vali Loss: 0.0641238 Test Loss: 0.0946040\n",
      "Validation loss decreased (0.065557 --> 0.064124).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666802\n",
      "\tspeed: 0.0385s/iter; left time: 91.1316s\n",
      "\titers: 200, epoch: 10 | loss: 0.0671037\n",
      "\tspeed: 0.0167s/iter; left time: 37.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0686812 Vali Loss: 0.0635217 Test Loss: 0.0920826\n",
      "Validation loss decreased (0.064124 --> 0.063522).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657643\n",
      "\tspeed: 0.0380s/iter; left time: 81.3744s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640680\n",
      "\tspeed: 0.0185s/iter; left time: 37.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0677449 Vali Loss: 0.0631191 Test Loss: 0.0914283\n",
      "Validation loss decreased (0.063522 --> 0.063119).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628503\n",
      "\tspeed: 0.0390s/iter; left time: 74.7482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0651587\n",
      "\tspeed: 0.0203s/iter; left time: 36.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0672804 Vali Loss: 0.0626110 Test Loss: 0.0832856\n",
      "Validation loss decreased (0.063119 --> 0.062611).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0623292\n",
      "\tspeed: 0.0406s/iter; left time: 68.8180s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658564\n",
      "\tspeed: 0.0239s/iter; left time: 38.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0664633 Vali Loss: 0.0621283 Test Loss: 0.0837443\n",
      "Validation loss decreased (0.062611 --> 0.062128).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687133\n",
      "\tspeed: 0.0394s/iter; left time: 57.9428s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648790\n",
      "\tspeed: 0.0235s/iter; left time: 32.1941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0656932 Vali Loss: 0.0620166 Test Loss: 0.0845872\n",
      "Validation loss decreased (0.062128 --> 0.062017).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649449\n",
      "\tspeed: 0.0394s/iter; left time: 49.0829s\n",
      "\titers: 200, epoch: 15 | loss: 0.0653902\n",
      "\tspeed: 0.0211s/iter; left time: 24.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0656366 Vali Loss: 0.0617880 Test Loss: 0.0808425\n",
      "Validation loss decreased (0.062017 --> 0.061788).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618114\n",
      "\tspeed: 0.0378s/iter; left time: 38.5603s\n",
      "\titers: 200, epoch: 16 | loss: 0.0655272\n",
      "\tspeed: 0.0198s/iter; left time: 18.2481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0655247 Vali Loss: 0.0616549 Test Loss: 0.0858418\n",
      "Validation loss decreased (0.061788 --> 0.061655).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0677098\n",
      "\tspeed: 0.0368s/iter; left time: 29.3474s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637103\n",
      "\tspeed: 0.0168s/iter; left time: 11.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0648700 Vali Loss: 0.0612696 Test Loss: 0.0789498\n",
      "Validation loss decreased (0.061655 --> 0.061270).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0684756\n",
      "\tspeed: 0.0432s/iter; left time: 24.7682s\n",
      "\titers: 200, epoch: 18 | loss: 0.0658208\n",
      "\tspeed: 0.0195s/iter; left time: 9.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0648673 Vali Loss: 0.0613987 Test Loss: 0.0799385\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0637714\n",
      "\tspeed: 0.0363s/iter; left time: 12.6523s\n",
      "\titers: 200, epoch: 19 | loss: 0.0642970\n",
      "\tspeed: 0.0198s/iter; left time: 4.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0642515 Vali Loss: 0.0606022 Test Loss: 0.0827977\n",
      "Validation loss decreased (0.061270 --> 0.060602).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0594665\n",
      "\tspeed: 0.0372s/iter; left time: 4.6555s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622201\n",
      "\tspeed: 0.0204s/iter; left time: 0.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0640075 Vali Loss: 0.0609228 Test Loss: 0.0824307\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019271206110715866, rmse:0.13882076740264893, mae:0.08279767632484436, rse:0.4085327386856079\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:01.82s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0397s/iter; left time: 173.8464s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0113s/iter; left time: 48.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0335s/iter; left time: 139.3860s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0161s/iter; left time: 65.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0343s/iter; left time: 134.9389s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0169s/iter; left time: 64.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0328s/iter; left time: 121.7328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0169s/iter; left time: 61.0446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0350s/iter; left time: 122.0642s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0161s/iter; left time: 54.6138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0337s/iter; left time: 109.8750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0188s/iter; left time: 59.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0376s/iter; left time: 114.0644s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0163s/iter; left time: 47.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0374s/iter; left time: 105.1360s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0199s/iter; left time: 53.9384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0356s/iter; left time: 92.2550s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0196s/iter; left time: 48.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0268s/iter; left time: 63.4740s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0101s/iter; left time: 22.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.46s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0306s/iter; left time: 65.4659s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0172s/iter; left time: 35.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0326s/iter; left time: 62.5681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0176s/iter; left time: 31.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0337s/iter; left time: 56.9777s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0172s/iter; left time: 27.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0385s/iter; left time: 56.5588s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0205s/iter; left time: 28.0079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0359s/iter; left time: 44.7522s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0179s/iter; left time: 20.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0349s/iter; left time: 35.6507s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0202s/iter; left time: 18.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0373s/iter; left time: 29.7417s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0197s/iter; left time: 13.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0343s/iter; left time: 19.6523s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0179s/iter; left time: 8.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0374s/iter; left time: 13.0392s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0184s/iter; left time: 4.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0361s/iter; left time: 4.5100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0173s/iter; left time: 0.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.025789545848965645, rmse:0.1605912446975708, mae:0.10785099118947983, rse:0.47176873683929443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2952403\n",
      "\tspeed: 0.0204s/iter; left time: 89.3050s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667057\n",
      "\tspeed: 0.0167s/iter; left time: 71.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.2909098 Vali Loss: 0.2230923 Test Loss: 0.2409381\n",
      "Validation loss decreased (inf --> 0.223092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1491593\n",
      "\tspeed: 0.0435s/iter; left time: 180.7254s\n",
      "\titers: 200, epoch: 2 | loss: 0.1210495\n",
      "\tspeed: 0.0177s/iter; left time: 71.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1614247 Vali Loss: 0.1116909 Test Loss: 0.1254427\n",
      "Validation loss decreased (0.223092 --> 0.111691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085087\n",
      "\tspeed: 0.0351s/iter; left time: 138.0536s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104036\n",
      "\tspeed: 0.0101s/iter; left time: 38.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.1113403 Vali Loss: 0.0953680 Test Loss: 0.1103432\n",
      "Validation loss decreased (0.111691 --> 0.095368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050000\n",
      "\tspeed: 0.0360s/iter; left time: 133.4909s\n",
      "\titers: 200, epoch: 4 | loss: 0.0989005\n",
      "\tspeed: 0.0211s/iter; left time: 76.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0994751 Vali Loss: 0.0900774 Test Loss: 0.1305989\n",
      "Validation loss decreased (0.095368 --> 0.090077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0924402\n",
      "\tspeed: 0.0369s/iter; left time: 128.4269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0925185\n",
      "\tspeed: 0.0168s/iter; left time: 56.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0936407 Vali Loss: 0.0879273 Test Loss: 0.1221537\n",
      "Validation loss decreased (0.090077 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856230\n",
      "\tspeed: 0.0371s/iter; left time: 120.8805s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879899\n",
      "\tspeed: 0.0206s/iter; left time: 65.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0899839 Vali Loss: 0.0851904 Test Loss: 0.1239189\n",
      "Validation loss decreased (0.087927 --> 0.085190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0908499\n",
      "\tspeed: 0.0372s/iter; left time: 112.8778s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900486\n",
      "\tspeed: 0.0204s/iter; left time: 60.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0885243 Vali Loss: 0.0836331 Test Loss: 0.1237736\n",
      "Validation loss decreased (0.085190 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901688\n",
      "\tspeed: 0.0365s/iter; left time: 102.7552s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838144\n",
      "\tspeed: 0.0181s/iter; left time: 49.2199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0868885 Vali Loss: 0.0829176 Test Loss: 0.1260237\n",
      "Validation loss decreased (0.083633 --> 0.082918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0871684\n",
      "\tspeed: 0.0366s/iter; left time: 94.8117s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863542\n",
      "\tspeed: 0.0194s/iter; left time: 48.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0857102 Vali Loss: 0.0822429 Test Loss: 0.1236874\n",
      "Validation loss decreased (0.082918 --> 0.082243).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849192\n",
      "\tspeed: 0.0385s/iter; left time: 91.0671s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846752\n",
      "\tspeed: 0.0187s/iter; left time: 42.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0818745 Test Loss: 0.1264992\n",
      "Validation loss decreased (0.082243 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810420\n",
      "\tspeed: 0.0405s/iter; left time: 86.6379s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817054\n",
      "\tspeed: 0.0195s/iter; left time: 39.8980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0842583 Vali Loss: 0.0812377 Test Loss: 0.1211978\n",
      "Validation loss decreased (0.081875 --> 0.081238).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0824383\n",
      "\tspeed: 0.0373s/iter; left time: 71.4403s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815587\n",
      "\tspeed: 0.0168s/iter; left time: 30.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0837523 Vali Loss: 0.0809542 Test Loss: 0.1222994\n",
      "Validation loss decreased (0.081238 --> 0.080954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0834732\n",
      "\tspeed: 0.0344s/iter; left time: 58.3174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0828774\n",
      "\tspeed: 0.0165s/iter; left time: 26.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0834866 Vali Loss: 0.0810962 Test Loss: 0.1206864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810478\n",
      "\tspeed: 0.0377s/iter; left time: 55.3448s\n",
      "\titers: 200, epoch: 14 | loss: 0.0787730\n",
      "\tspeed: 0.0103s/iter; left time: 14.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0830654 Vali Loss: 0.0801408 Test Loss: 0.1198389\n",
      "Validation loss decreased (0.080954 --> 0.080141).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855980\n",
      "\tspeed: 0.0369s/iter; left time: 45.9033s\n",
      "\titers: 200, epoch: 15 | loss: 0.0813123\n",
      "\tspeed: 0.0175s/iter; left time: 19.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0829200 Vali Loss: 0.0803521 Test Loss: 0.1200523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831396\n",
      "\tspeed: 0.0368s/iter; left time: 37.6019s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829206\n",
      "\tspeed: 0.0179s/iter; left time: 16.5022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0823068 Vali Loss: 0.0803707 Test Loss: 0.1218092\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848512\n",
      "\tspeed: 0.0332s/iter; left time: 26.4427s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793137\n",
      "\tspeed: 0.0164s/iter; left time: 11.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0826998 Vali Loss: 0.0802649 Test Loss: 0.1115729\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797599\n",
      "\tspeed: 0.0348s/iter; left time: 19.9687s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824331\n",
      "\tspeed: 0.0182s/iter; left time: 8.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0821136 Vali Loss: 0.0795419 Test Loss: 0.1209204\n",
      "Validation loss decreased (0.080141 --> 0.079542).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788217\n",
      "\tspeed: 0.0390s/iter; left time: 13.6023s\n",
      "\titers: 200, epoch: 19 | loss: 0.0827929\n",
      "\tspeed: 0.0222s/iter; left time: 5.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0817846 Vali Loss: 0.0792163 Test Loss: 0.1182506\n",
      "Validation loss decreased (0.079542 --> 0.079216).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808366\n",
      "\tspeed: 0.0445s/iter; left time: 5.5686s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783563\n",
      "\tspeed: 0.0200s/iter; left time: 0.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0815249 Vali Loss: 0.0790933 Test Loss: 0.1166001\n",
      "Validation loss decreased (0.079216 --> 0.079093).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03416641056537628, rmse:0.184841588139534, mae:0.11660011857748032, rse:0.5430089235305786\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:45.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0409s/iter; left time: 178.2966s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0194s/iter; left time: 82.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0407s/iter; left time: 168.5810s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0171s/iter; left time: 68.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0332s/iter; left time: 129.8593s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0250s/iter; left time: 95.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0448s/iter; left time: 165.3255s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0251s/iter; left time: 90.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0448s/iter; left time: 155.3468s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0230s/iter; left time: 77.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0458s/iter; left time: 148.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0242s/iter; left time: 75.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0329s/iter; left time: 99.4984s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0225s/iter; left time: 65.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0377s/iter; left time: 105.4556s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0191s/iter; left time: 51.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0429s/iter; left time: 110.6555s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0238s/iter; left time: 59.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0406s/iter; left time: 95.6032s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0184s/iter; left time: 41.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0377s/iter; left time: 80.3619s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0187s/iter; left time: 37.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0373s/iter; left time: 71.1802s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0114s/iter; left time: 20.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0334s/iter; left time: 56.2187s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0169s/iter; left time: 26.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0374s/iter; left time: 54.7015s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0179s/iter; left time: 24.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0382s/iter; left time: 47.2873s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0178s/iter; left time: 20.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0349s/iter; left time: 35.4389s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0195s/iter; left time: 17.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0434s/iter; left time: 34.3828s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0187s/iter; left time: 12.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0339s/iter; left time: 19.3211s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0170s/iter; left time: 7.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0372s/iter; left time: 12.9222s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0215s/iter; left time: 5.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0391s/iter; left time: 4.8529s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0189s/iter; left time: 0.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030968520790338516, rmse:0.17597874999046326, mae:0.11744298785924911, rse:0.5170097351074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2899029\n",
      "\tspeed: 0.0254s/iter; left time: 110.6952s\n",
      "\titers: 200, epoch: 1 | loss: 0.2712442\n",
      "\tspeed: 0.0171s/iter; left time: 72.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.2944018 Vali Loss: 0.2256723 Test Loss: 0.2452994\n",
      "Validation loss decreased (inf --> 0.225672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1439804\n",
      "\tspeed: 0.0367s/iter; left time: 152.0122s\n",
      "\titers: 200, epoch: 2 | loss: 0.1288482\n",
      "\tspeed: 0.0177s/iter; left time: 71.6389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1609331 Vali Loss: 0.1103104 Test Loss: 0.1237899\n",
      "Validation loss decreased (0.225672 --> 0.110310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161442\n",
      "\tspeed: 0.0408s/iter; left time: 159.6453s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086942\n",
      "\tspeed: 0.0207s/iter; left time: 79.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1137597 Vali Loss: 0.0991577 Test Loss: 0.1132361\n",
      "Validation loss decreased (0.110310 --> 0.099158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016965\n",
      "\tspeed: 0.0378s/iter; left time: 139.7031s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984646\n",
      "\tspeed: 0.0169s/iter; left time: 60.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1016837 Vali Loss: 0.0949189 Test Loss: 0.1138231\n",
      "Validation loss decreased (0.099158 --> 0.094919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0982926\n",
      "\tspeed: 0.0404s/iter; left time: 140.3132s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952768\n",
      "\tspeed: 0.0177s/iter; left time: 59.6714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0965111 Vali Loss: 0.0906598 Test Loss: 0.1149046\n",
      "Validation loss decreased (0.094919 --> 0.090660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932750\n",
      "\tspeed: 0.0381s/iter; left time: 123.7322s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899443\n",
      "\tspeed: 0.0191s/iter; left time: 60.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0935987 Vali Loss: 0.0898600 Test Loss: 0.1154023\n",
      "Validation loss decreased (0.090660 --> 0.089860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968993\n",
      "\tspeed: 0.0395s/iter; left time: 119.5003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0916797\n",
      "\tspeed: 0.0197s/iter; left time: 57.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0919076 Vali Loss: 0.0879064 Test Loss: 0.1174295\n",
      "Validation loss decreased (0.089860 --> 0.087906).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0910260\n",
      "\tspeed: 0.0378s/iter; left time: 105.8466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891242\n",
      "\tspeed: 0.0200s/iter; left time: 54.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0904661 Vali Loss: 0.0868890 Test Loss: 0.1170246\n",
      "Validation loss decreased (0.087906 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919234\n",
      "\tspeed: 0.0405s/iter; left time: 104.3527s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911078\n",
      "\tspeed: 0.0230s/iter; left time: 56.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0899424 Vali Loss: 0.0871161 Test Loss: 0.1129427\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0876352\n",
      "\tspeed: 0.0428s/iter; left time: 100.7205s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899070\n",
      "\tspeed: 0.0227s/iter; left time: 51.2441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0887751 Vali Loss: 0.0863786 Test Loss: 0.1157439\n",
      "Validation loss decreased (0.086889 --> 0.086379).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0875310\n",
      "\tspeed: 0.0386s/iter; left time: 82.1818s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865170\n",
      "\tspeed: 0.0176s/iter; left time: 35.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0889828 Vali Loss: 0.0859895 Test Loss: 0.1167143\n",
      "Validation loss decreased (0.086379 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0884266\n",
      "\tspeed: 0.0410s/iter; left time: 78.2395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0868132\n",
      "\tspeed: 0.0189s/iter; left time: 34.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0875570 Vali Loss: 0.0859610 Test Loss: 0.1155201\n",
      "Validation loss decreased (0.085990 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886559\n",
      "\tspeed: 0.0395s/iter; left time: 66.5445s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892455\n",
      "\tspeed: 0.0215s/iter; left time: 34.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0871522 Vali Loss: 0.0859056 Test Loss: 0.1138303\n",
      "Validation loss decreased (0.085961 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848424\n",
      "\tspeed: 0.0382s/iter; left time: 55.8113s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878144\n",
      "\tspeed: 0.0173s/iter; left time: 23.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0867811 Vali Loss: 0.0854875 Test Loss: 0.1154874\n",
      "Validation loss decreased (0.085906 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901568\n",
      "\tspeed: 0.0383s/iter; left time: 47.4129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834248\n",
      "\tspeed: 0.0196s/iter; left time: 22.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0863447 Vali Loss: 0.0854952 Test Loss: 0.1136132\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865058\n",
      "\tspeed: 0.0389s/iter; left time: 39.5532s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858239\n",
      "\tspeed: 0.0203s/iter; left time: 18.6204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0863616 Vali Loss: 0.0848712 Test Loss: 0.1134736\n",
      "Validation loss decreased (0.085487 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821277\n",
      "\tspeed: 0.0413s/iter; left time: 32.7476s\n",
      "\titers: 200, epoch: 17 | loss: 0.0873138\n",
      "\tspeed: 0.0187s/iter; left time: 12.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0860255 Vali Loss: 0.0847610 Test Loss: 0.1142043\n",
      "Validation loss decreased (0.084871 --> 0.084761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0891386\n",
      "\tspeed: 0.0352s/iter; left time: 20.0840s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899599\n",
      "\tspeed: 0.0173s/iter; left time: 8.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0863818 Vali Loss: 0.0850193 Test Loss: 0.1143596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0856005\n",
      "\tspeed: 0.0364s/iter; left time: 12.6310s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866439\n",
      "\tspeed: 0.0102s/iter; left time: 2.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 223 | Train Loss: 0.0857154 Vali Loss: 0.0848255 Test Loss: 0.1150333\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0883029\n",
      "\tspeed: 0.0372s/iter; left time: 4.6180s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826626\n",
      "\tspeed: 0.0184s/iter; left time: 0.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0856279 Vali Loss: 0.0850217 Test Loss: 0.1158830\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.027704495936632156, rmse:0.16644667088985443, mae:0.1142042800784111, rse:0.4890053868293762\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:03.80s\n",
      "Intermediate time for ES: 00h:11m:50.64s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0411s/iter; left time: 180.1633s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0157s/iter; left time: 67.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0321s/iter; left time: 133.5690s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0153s/iter; left time: 62.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0347s/iter; left time: 136.4971s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0164s/iter; left time: 63.0509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0353s/iter; left time: 130.9645s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0164s/iter; left time: 59.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0343s/iter; left time: 119.4631s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0179s/iter; left time: 60.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0356s/iter; left time: 116.0798s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0162s/iter; left time: 51.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0386s/iter; left time: 117.2982s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0227s/iter; left time: 66.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0366s/iter; left time: 102.8152s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0179s/iter; left time: 48.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0357s/iter; left time: 92.4968s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0169s/iter; left time: 41.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0350s/iter; left time: 82.7631s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0182s/iter; left time: 41.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0344s/iter; left time: 73.6516s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0188s/iter; left time: 38.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0352s/iter; left time: 67.3897s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0187s/iter; left time: 34.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0365s/iter; left time: 61.8136s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0178s/iter; left time: 28.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0315s/iter; left time: 46.2743s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0156s/iter; left time: 21.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0364s/iter; left time: 45.3628s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0190s/iter; left time: 21.7042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0358s/iter; left time: 36.5022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0174s/iter; left time: 16.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0347s/iter; left time: 27.6201s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0184s/iter; left time: 12.8006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0338s/iter; left time: 19.3927s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0196s/iter; left time: 9.2886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0372s/iter; left time: 12.9835s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0230s/iter; left time: 5.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0366s/iter; left time: 4.5750s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0171s/iter; left time: 0.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011178242973983288, rmse:0.10572721064090729, mae:0.061787281185388565, rse:0.407892644405365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2411680\n",
      "\tspeed: 0.0206s/iter; left time: 90.3629s\n",
      "\titers: 200, epoch: 1 | loss: 0.2160659\n",
      "\tspeed: 0.0194s/iter; left time: 83.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.2408922 Vali Loss: 0.1782567 Test Loss: 0.1854041\n",
      "Validation loss decreased (inf --> 0.178257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1385794\n",
      "\tspeed: 0.0333s/iter; left time: 138.4459s\n",
      "\titers: 200, epoch: 2 | loss: 0.1014387\n",
      "\tspeed: 0.0162s/iter; left time: 65.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1401546 Vali Loss: 0.0844240 Test Loss: 0.0928136\n",
      "Validation loss decreased (0.178257 --> 0.084424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963864\n",
      "\tspeed: 0.0358s/iter; left time: 140.7603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779932\n",
      "\tspeed: 0.0176s/iter; left time: 67.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0851412 Vali Loss: 0.0759695 Test Loss: 0.0796487\n",
      "Validation loss decreased (0.084424 --> 0.075970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728357\n",
      "\tspeed: 0.0361s/iter; left time: 134.0024s\n",
      "\titers: 200, epoch: 4 | loss: 0.0701583\n",
      "\tspeed: 0.0217s/iter; left time: 78.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0739212 Vali Loss: 0.0693061 Test Loss: 0.0711936\n",
      "Validation loss decreased (0.075970 --> 0.069306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649703\n",
      "\tspeed: 0.0393s/iter; left time: 136.9867s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600224\n",
      "\tspeed: 0.0206s/iter; left time: 69.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0674395 Vali Loss: 0.0658167 Test Loss: 0.0676115\n",
      "Validation loss decreased (0.069306 --> 0.065817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614809\n",
      "\tspeed: 0.0272s/iter; left time: 88.8241s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617771\n",
      "\tspeed: 0.0098s/iter; left time: 30.9497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0634119 Vali Loss: 0.0674359 Test Loss: 0.0694659\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605860\n",
      "\tspeed: 0.0339s/iter; left time: 102.9394s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626515\n",
      "\tspeed: 0.0184s/iter; left time: 54.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0611253 Vali Loss: 0.0648416 Test Loss: 0.0675831\n",
      "Validation loss decreased (0.065817 --> 0.064842).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599528\n",
      "\tspeed: 0.0397s/iter; left time: 111.5973s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610243\n",
      "\tspeed: 0.0202s/iter; left time: 54.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0588911 Vali Loss: 0.0627734 Test Loss: 0.0656899\n",
      "Validation loss decreased (0.064842 --> 0.062773).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547889\n",
      "\tspeed: 0.0358s/iter; left time: 92.5568s\n",
      "\titers: 200, epoch: 9 | loss: 0.0561625\n",
      "\tspeed: 0.0169s/iter; left time: 41.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0571481 Vali Loss: 0.0612765 Test Loss: 0.0641911\n",
      "Validation loss decreased (0.062773 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564083\n",
      "\tspeed: 0.0391s/iter; left time: 92.5144s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529456\n",
      "\tspeed: 0.0226s/iter; left time: 51.2521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0560195 Vali Loss: 0.0609586 Test Loss: 0.0637936\n",
      "Validation loss decreased (0.061277 --> 0.060959).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541631\n",
      "\tspeed: 0.0412s/iter; left time: 88.1395s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595317\n",
      "\tspeed: 0.0172s/iter; left time: 35.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0548145 Vali Loss: 0.0604594 Test Loss: 0.0633140\n",
      "Validation loss decreased (0.060959 --> 0.060459).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0551679\n",
      "\tspeed: 0.0360s/iter; left time: 69.0031s\n",
      "\titers: 200, epoch: 12 | loss: 0.0506632\n",
      "\tspeed: 0.0202s/iter; left time: 36.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0540808 Vali Loss: 0.0599905 Test Loss: 0.0628521\n",
      "Validation loss decreased (0.060459 --> 0.059990).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570984\n",
      "\tspeed: 0.0402s/iter; left time: 68.0589s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494264\n",
      "\tspeed: 0.0198s/iter; left time: 31.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0539780 Vali Loss: 0.0598418 Test Loss: 0.0626836\n",
      "Validation loss decreased (0.059990 --> 0.059842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523727\n",
      "\tspeed: 0.0361s/iter; left time: 53.0909s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538516\n",
      "\tspeed: 0.0184s/iter; left time: 25.2173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0532672 Vali Loss: 0.0598634 Test Loss: 0.0626787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0509895\n",
      "\tspeed: 0.0351s/iter; left time: 43.7359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0479047\n",
      "\tspeed: 0.0175s/iter; left time: 19.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528779 Vali Loss: 0.0594473 Test Loss: 0.0624075\n",
      "Validation loss decreased (0.059842 --> 0.059447).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509207\n",
      "\tspeed: 0.0430s/iter; left time: 43.8795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511976\n",
      "\tspeed: 0.0235s/iter; left time: 21.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0526040 Vali Loss: 0.0597805 Test Loss: 0.0625402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0506773\n",
      "\tspeed: 0.0391s/iter; left time: 31.1416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0510104\n",
      "\tspeed: 0.0174s/iter; left time: 12.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0523335 Vali Loss: 0.0592356 Test Loss: 0.0620888\n",
      "Validation loss decreased (0.059447 --> 0.059236).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547306\n",
      "\tspeed: 0.0375s/iter; left time: 21.4689s\n",
      "\titers: 200, epoch: 18 | loss: 0.0486531\n",
      "\tspeed: 0.0206s/iter; left time: 9.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0520337 Vali Loss: 0.0590360 Test Loss: 0.0619049\n",
      "Validation loss decreased (0.059236 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0527190\n",
      "\tspeed: 0.0399s/iter; left time: 13.9154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0546635\n",
      "\tspeed: 0.0209s/iter; left time: 5.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0518412 Vali Loss: 0.0589188 Test Loss: 0.0616275\n",
      "Validation loss decreased (0.059036 --> 0.058919).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517122\n",
      "\tspeed: 0.0369s/iter; left time: 4.6182s\n",
      "\titers: 200, epoch: 20 | loss: 0.0467894\n",
      "\tspeed: 0.0175s/iter; left time: 0.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0516144 Vali Loss: 0.0589262 Test Loss: 0.0616789\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011188277043402195, rmse:0.1057746484875679, mae:0.061627473682165146, rse:0.4080756902694702\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:48.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0433s/iter; left time: 189.6333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0156s/iter; left time: 66.9746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0285s/iter; left time: 118.3378s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0101s/iter; left time: 41.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.50s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0334s/iter; left time: 131.2917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0168s/iter; left time: 64.3798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0353s/iter; left time: 130.9741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0179s/iter; left time: 64.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0372s/iter; left time: 129.5779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0172s/iter; left time: 58.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0387s/iter; left time: 126.1875s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0203s/iter; left time: 64.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0368s/iter; left time: 111.6742s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0172s/iter; left time: 50.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0359s/iter; left time: 101.0960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0203s/iter; left time: 55.1739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0347s/iter; left time: 89.7728s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0160s/iter; left time: 39.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0386s/iter; left time: 91.1772s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0186s/iter; left time: 42.0772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0353s/iter; left time: 75.6603s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0186s/iter; left time: 37.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0350s/iter; left time: 67.0952s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0173s/iter; left time: 31.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0357s/iter; left time: 60.4834s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0175s/iter; left time: 27.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0352s/iter; left time: 51.7130s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0159s/iter; left time: 21.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0362s/iter; left time: 45.1111s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0192s/iter; left time: 22.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0373s/iter; left time: 38.0980s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0207s/iter; left time: 19.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0393s/iter; left time: 31.3164s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0179s/iter; left time: 12.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0360s/iter; left time: 20.6224s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0168s/iter; left time: 7.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0363s/iter; left time: 12.6672s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0196s/iter; left time: 4.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0359s/iter; left time: 4.4875s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0168s/iter; left time: 0.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020759424194693565, rmse:0.14408130943775177, mae:0.08491359651088715, rse:0.5573447942733765\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2406403\n",
      "\tspeed: 0.0230s/iter; left time: 100.7112s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188262\n",
      "\tspeed: 0.0176s/iter; left time: 75.2445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.2381317 Vali Loss: 0.1789258 Test Loss: 0.1865743\n",
      "Validation loss decreased (inf --> 0.178926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1343914\n",
      "\tspeed: 0.0433s/iter; left time: 179.8364s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930818\n",
      "\tspeed: 0.0177s/iter; left time: 71.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1332448 Vali Loss: 0.0972317 Test Loss: 0.1086327\n",
      "Validation loss decreased (0.178926 --> 0.097232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907119\n",
      "\tspeed: 0.0414s/iter; left time: 162.8802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0898331\n",
      "\tspeed: 0.0135s/iter; left time: 51.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0904112 Vali Loss: 0.0884094 Test Loss: 0.0957489\n",
      "Validation loss decreased (0.097232 --> 0.088409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0800296\n",
      "\tspeed: 0.0383s/iter; left time: 142.2116s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827712\n",
      "\tspeed: 0.0166s/iter; left time: 59.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0818481 Vali Loss: 0.0822035 Test Loss: 0.0922612\n",
      "Validation loss decreased (0.088409 --> 0.082203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791426\n",
      "\tspeed: 0.0347s/iter; left time: 120.9045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790642\n",
      "\tspeed: 0.0178s/iter; left time: 60.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0770117 Vali Loss: 0.0795626 Test Loss: 0.0895083\n",
      "Validation loss decreased (0.082203 --> 0.079563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730632\n",
      "\tspeed: 0.0362s/iter; left time: 118.0433s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708637\n",
      "\tspeed: 0.0179s/iter; left time: 56.5925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0741224 Vali Loss: 0.0787785 Test Loss: 0.0881438\n",
      "Validation loss decreased (0.079563 --> 0.078779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0686050\n",
      "\tspeed: 0.0365s/iter; left time: 110.8007s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743980\n",
      "\tspeed: 0.0176s/iter; left time: 51.8059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0715071 Vali Loss: 0.0792559 Test Loss: 0.0889636\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750379\n",
      "\tspeed: 0.0354s/iter; left time: 99.6687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0685743\n",
      "\tspeed: 0.0167s/iter; left time: 45.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0700779 Vali Loss: 0.0787402 Test Loss: 0.0882414\n",
      "Validation loss decreased (0.078779 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686822\n",
      "\tspeed: 0.0346s/iter; left time: 89.4876s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684529\n",
      "\tspeed: 0.0177s/iter; left time: 44.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0689258 Vali Loss: 0.0775224 Test Loss: 0.0869969\n",
      "Validation loss decreased (0.078740 --> 0.077522).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689297\n",
      "\tspeed: 0.0371s/iter; left time: 87.6534s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664442\n",
      "\tspeed: 0.0206s/iter; left time: 46.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0681905 Vali Loss: 0.0769314 Test Loss: 0.0865170\n",
      "Validation loss decreased (0.077522 --> 0.076931).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694460\n",
      "\tspeed: 0.0425s/iter; left time: 90.9632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0733899\n",
      "\tspeed: 0.0209s/iter; left time: 42.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0677455 Vali Loss: 0.0769557 Test Loss: 0.0862589\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652838\n",
      "\tspeed: 0.0356s/iter; left time: 68.1971s\n",
      "\titers: 200, epoch: 12 | loss: 0.0629617\n",
      "\tspeed: 0.0163s/iter; left time: 29.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0668834 Vali Loss: 0.0763795 Test Loss: 0.0861417\n",
      "Validation loss decreased (0.076931 --> 0.076379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643209\n",
      "\tspeed: 0.0394s/iter; left time: 66.7805s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618452\n",
      "\tspeed: 0.0185s/iter; left time: 29.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0667896 Vali Loss: 0.0762287 Test Loss: 0.0860246\n",
      "Validation loss decreased (0.076379 --> 0.076229).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677970\n",
      "\tspeed: 0.0374s/iter; left time: 54.9118s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648690\n",
      "\tspeed: 0.0170s/iter; left time: 23.3041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0661625 Vali Loss: 0.0762512 Test Loss: 0.0858173\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696925\n",
      "\tspeed: 0.0330s/iter; left time: 41.0334s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697655\n",
      "\tspeed: 0.0126s/iter; left time: 14.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 224 | Train Loss: 0.0660004 Vali Loss: 0.0760939 Test Loss: 0.0859716\n",
      "Validation loss decreased (0.076229 --> 0.076094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652443\n",
      "\tspeed: 0.0362s/iter; left time: 37.0054s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687751\n",
      "\tspeed: 0.0185s/iter; left time: 17.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0656887 Vali Loss: 0.0760748 Test Loss: 0.0856839\n",
      "Validation loss decreased (0.076094 --> 0.076075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659079\n",
      "\tspeed: 0.0425s/iter; left time: 33.8817s\n",
      "\titers: 200, epoch: 17 | loss: 0.0638563\n",
      "\tspeed: 0.0204s/iter; left time: 14.2531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0653609 Vali Loss: 0.0753801 Test Loss: 0.0850498\n",
      "Validation loss decreased (0.076075 --> 0.075380).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578677\n",
      "\tspeed: 0.0429s/iter; left time: 24.5603s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645344\n",
      "\tspeed: 0.0206s/iter; left time: 9.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0651030 Vali Loss: 0.0752875 Test Loss: 0.0849164\n",
      "Validation loss decreased (0.075380 --> 0.075287).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679285\n",
      "\tspeed: 0.0381s/iter; left time: 13.2944s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629789\n",
      "\tspeed: 0.0189s/iter; left time: 4.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0649769 Vali Loss: 0.0752234 Test Loss: 0.0850461\n",
      "Validation loss decreased (0.075287 --> 0.075223).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0604777\n",
      "\tspeed: 0.0420s/iter; left time: 5.2439s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633929\n",
      "\tspeed: 0.0228s/iter; left time: 0.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0648052 Vali Loss: 0.0750941 Test Loss: 0.0847241\n",
      "Validation loss decreased (0.075223 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020768484100699425, rmse:0.1441127508878708, mae:0.08472401648759842, rse:0.557466447353363\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:50.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0429s/iter; left time: 186.9511s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0197s/iter; left time: 84.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0352s/iter; left time: 145.5875s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0138s/iter; left time: 55.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0308s/iter; left time: 120.5068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0164s/iter; left time: 62.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0373s/iter; left time: 137.6077s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0205s/iter; left time: 73.5942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0301s/iter; left time: 104.4480s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0128s/iter; left time: 43.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0390s/iter; left time: 126.6729s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0181s/iter; left time: 56.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0395s/iter; left time: 119.3942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0204s/iter; left time: 59.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0299s/iter; left time: 83.6982s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0160s/iter; left time: 43.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0393s/iter; left time: 101.1564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0215s/iter; left time: 53.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0362s/iter; left time: 85.1936s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0184s/iter; left time: 41.5790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0397s/iter; left time: 84.6464s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0212s/iter; left time: 42.9622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0364s/iter; left time: 69.3656s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0221s/iter; left time: 40.0146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0416s/iter; left time: 70.1324s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0239s/iter; left time: 37.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0369s/iter; left time: 53.8790s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0220s/iter; left time: 29.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0353s/iter; left time: 43.7812s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0166s/iter; left time: 18.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0384s/iter; left time: 39.0585s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0205s/iter; left time: 18.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0384s/iter; left time: 30.4659s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0172s/iter; left time: 11.9438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0382s/iter; left time: 21.7958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0200s/iter; left time: 9.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0362s/iter; left time: 12.5470s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0184s/iter; left time: 4.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0405s/iter; left time: 5.0222s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0237s/iter; left time: 0.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023141568526625633, rmse:0.15212352573871613, mae:0.09033302962779999, rse:0.5891888737678528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2403809\n",
      "\tspeed: 0.0287s/iter; left time: 125.3333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2154531\n",
      "\tspeed: 0.0193s/iter; left time: 82.0615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.2422614 Vali Loss: 0.1823216 Test Loss: 0.1888932\n",
      "Validation loss decreased (inf --> 0.182322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229391\n",
      "\tspeed: 0.0366s/iter; left time: 151.5587s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984408\n",
      "\tspeed: 0.0184s/iter; left time: 74.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1311886 Vali Loss: 0.1001970 Test Loss: 0.1099112\n",
      "Validation loss decreased (0.182322 --> 0.100197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898930\n",
      "\tspeed: 0.0379s/iter; left time: 148.2770s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917291\n",
      "\tspeed: 0.0206s/iter; left time: 78.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0914624 Vali Loss: 0.0890297 Test Loss: 0.0978792\n",
      "Validation loss decreased (0.100197 --> 0.089030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854143\n",
      "\tspeed: 0.0362s/iter; left time: 133.6721s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808555\n",
      "\tspeed: 0.0181s/iter; left time: 64.9064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0837825 Vali Loss: 0.0859060 Test Loss: 0.0959388\n",
      "Validation loss decreased (0.089030 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808391\n",
      "\tspeed: 0.0366s/iter; left time: 127.1186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785895\n",
      "\tspeed: 0.0174s/iter; left time: 58.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0792879 Vali Loss: 0.0840676 Test Loss: 0.0946624\n",
      "Validation loss decreased (0.085906 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755854\n",
      "\tspeed: 0.0369s/iter; left time: 119.9223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746735\n",
      "\tspeed: 0.0186s/iter; left time: 58.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0765742 Vali Loss: 0.0853610 Test Loss: 0.0968855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792653\n",
      "\tspeed: 0.0402s/iter; left time: 121.6135s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721418\n",
      "\tspeed: 0.0222s/iter; left time: 64.9495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0743388 Vali Loss: 0.0818612 Test Loss: 0.0936658\n",
      "Validation loss decreased (0.084068 --> 0.081861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736356\n",
      "\tspeed: 0.0411s/iter; left time: 115.0086s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732522\n",
      "\tspeed: 0.0192s/iter; left time: 51.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0730863 Vali Loss: 0.0821424 Test Loss: 0.0942828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0689212\n",
      "\tspeed: 0.0351s/iter; left time: 90.4486s\n",
      "\titers: 200, epoch: 9 | loss: 0.0701418\n",
      "\tspeed: 0.0194s/iter; left time: 48.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0719471 Vali Loss: 0.0811452 Test Loss: 0.0941387\n",
      "Validation loss decreased (0.081861 --> 0.081145).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0695085\n",
      "\tspeed: 0.0362s/iter; left time: 85.1182s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699557\n",
      "\tspeed: 0.0178s/iter; left time: 40.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0711944 Vali Loss: 0.0805143 Test Loss: 0.0936558\n",
      "Validation loss decreased (0.081145 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0710805\n",
      "\tspeed: 0.0335s/iter; left time: 71.4245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656972\n",
      "\tspeed: 0.0123s/iter; left time: 25.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 223 | Train Loss: 0.0703731 Vali Loss: 0.0806881 Test Loss: 0.0943752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712831\n",
      "\tspeed: 0.0365s/iter; left time: 69.5955s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711581\n",
      "\tspeed: 0.0178s/iter; left time: 32.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0701223 Vali Loss: 0.0796910 Test Loss: 0.0930109\n",
      "Validation loss decreased (0.080514 --> 0.079691).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698889\n",
      "\tspeed: 0.0355s/iter; left time: 59.8107s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705252\n",
      "\tspeed: 0.0179s/iter; left time: 28.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0696029 Vali Loss: 0.0801107 Test Loss: 0.0943232\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0708620\n",
      "\tspeed: 0.0372s/iter; left time: 54.4246s\n",
      "\titers: 200, epoch: 14 | loss: 0.0683931\n",
      "\tspeed: 0.0204s/iter; left time: 27.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0692059 Vali Loss: 0.0794433 Test Loss: 0.0930229\n",
      "Validation loss decreased (0.079691 --> 0.079443).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0689742\n",
      "\tspeed: 0.0399s/iter; left time: 49.4199s\n",
      "\titers: 200, epoch: 15 | loss: 0.0665230\n",
      "\tspeed: 0.0172s/iter; left time: 19.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0690320 Vali Loss: 0.0792129 Test Loss: 0.0928772\n",
      "Validation loss decreased (0.079443 --> 0.079213).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715083\n",
      "\tspeed: 0.0376s/iter; left time: 38.2296s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682462\n",
      "\tspeed: 0.0196s/iter; left time: 17.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0687173 Vali Loss: 0.0790982 Test Loss: 0.0926940\n",
      "Validation loss decreased (0.079213 --> 0.079098).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676954\n",
      "\tspeed: 0.0383s/iter; left time: 30.3890s\n",
      "\titers: 200, epoch: 17 | loss: 0.0672674\n",
      "\tspeed: 0.0180s/iter; left time: 12.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0685975 Vali Loss: 0.0791815 Test Loss: 0.0935558\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662949\n",
      "\tspeed: 0.0347s/iter; left time: 19.7915s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675989\n",
      "\tspeed: 0.0178s/iter; left time: 8.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0684725 Vali Loss: 0.0790181 Test Loss: 0.0932168\n",
      "Validation loss decreased (0.079098 --> 0.079018).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0674201\n",
      "\tspeed: 0.0355s/iter; left time: 12.3216s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678428\n",
      "\tspeed: 0.0185s/iter; left time: 4.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0681966 Vali Loss: 0.0788749 Test Loss: 0.0930523\n",
      "Validation loss decreased (0.079018 --> 0.078875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678935\n",
      "\tspeed: 0.0401s/iter; left time: 4.9665s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656016\n",
      "\tspeed: 0.0184s/iter; left time: 0.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0679420 Vali Loss: 0.0789774 Test Loss: 0.0931080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.025284940376877785, rmse:0.15901239216327667, mae:0.09305231273174286, rse:0.6158700585365295\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:55.03s\n",
      "Intermediate time for FR: 00h:11m:34.56s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0396s/iter; left time: 173.6948s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0115s/iter; left time: 49.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0361s/iter; left time: 150.2084s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0189s/iter; left time: 76.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0330s/iter; left time: 129.9814s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0157s/iter; left time: 60.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0342s/iter; left time: 126.9105s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0172s/iter; left time: 62.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0340s/iter; left time: 118.5002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0171s/iter; left time: 57.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0286s/iter; left time: 93.1979s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0243s/iter; left time: 76.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0346s/iter; left time: 105.1945s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0159s/iter; left time: 46.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0330s/iter; left time: 92.6893s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0162s/iter; left time: 43.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0349s/iter; left time: 90.3916s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0194s/iter; left time: 48.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0364s/iter; left time: 86.0386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0209s/iter; left time: 47.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0389s/iter; left time: 83.3571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0155s/iter; left time: 31.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0382s/iter; left time: 73.2141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0196s/iter; left time: 35.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0355s/iter; left time: 60.1384s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0100s/iter; left time: 15.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0331s/iter; left time: 48.6536s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0178s/iter; left time: 24.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0343s/iter; left time: 42.7145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0171s/iter; left time: 19.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0369s/iter; left time: 37.7210s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0181s/iter; left time: 16.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0363s/iter; left time: 28.9486s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0191s/iter; left time: 13.3265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0387s/iter; left time: 22.1770s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0185s/iter; left time: 8.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0314s/iter; left time: 10.9676s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0162s/iter; left time: 4.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0356s/iter; left time: 4.4533s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0160s/iter; left time: 0.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011143858544528484, rmse:0.10556447505950928, mae:0.06298493593931198, rse:0.3988761603832245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2797548\n",
      "\tspeed: 0.0225s/iter; left time: 98.6428s\n",
      "\titers: 200, epoch: 1 | loss: 0.2564775\n",
      "\tspeed: 0.0169s/iter; left time: 72.5572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.2824721 Vali Loss: 0.1925696 Test Loss: 0.1999343\n",
      "Validation loss decreased (inf --> 0.192570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1519092\n",
      "\tspeed: 0.0356s/iter; left time: 147.9756s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138760\n",
      "\tspeed: 0.0186s/iter; left time: 75.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1577599 Vali Loss: 0.0885143 Test Loss: 0.0898196\n",
      "Validation loss decreased (0.192570 --> 0.088514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994059\n",
      "\tspeed: 0.0395s/iter; left time: 155.5060s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920600\n",
      "\tspeed: 0.0183s/iter; left time: 69.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0987331 Vali Loss: 0.0793598 Test Loss: 0.0813890\n",
      "Validation loss decreased (0.088514 --> 0.079360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862465\n",
      "\tspeed: 0.0388s/iter; left time: 144.0705s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823747\n",
      "\tspeed: 0.0219s/iter; left time: 78.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0878294 Vali Loss: 0.0752087 Test Loss: 0.0770064\n",
      "Validation loss decreased (0.079360 --> 0.075209).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805695\n",
      "\tspeed: 0.0356s/iter; left time: 123.9224s\n",
      "\titers: 200, epoch: 5 | loss: 0.0835280\n",
      "\tspeed: 0.0190s/iter; left time: 64.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0810251 Vali Loss: 0.0726535 Test Loss: 0.0742234\n",
      "Validation loss decreased (0.075209 --> 0.072653).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783956\n",
      "\tspeed: 0.0350s/iter; left time: 114.2656s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783434\n",
      "\tspeed: 0.0181s/iter; left time: 57.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0766793 Vali Loss: 0.0699164 Test Loss: 0.0714286\n",
      "Validation loss decreased (0.072653 --> 0.069916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0737392\n",
      "\tspeed: 0.0362s/iter; left time: 109.8210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715222\n",
      "\tspeed: 0.0166s/iter; left time: 48.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0738872 Vali Loss: 0.0673173 Test Loss: 0.0694845\n",
      "Validation loss decreased (0.069916 --> 0.067317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708480\n",
      "\tspeed: 0.0329s/iter; left time: 92.4522s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682935\n",
      "\tspeed: 0.0161s/iter; left time: 43.6458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0719646 Vali Loss: 0.0660387 Test Loss: 0.0682573\n",
      "Validation loss decreased (0.067317 --> 0.066039).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645496\n",
      "\tspeed: 0.0361s/iter; left time: 93.4366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698819\n",
      "\tspeed: 0.0176s/iter; left time: 43.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0701305 Vali Loss: 0.0643912 Test Loss: 0.0671896\n",
      "Validation loss decreased (0.066039 --> 0.064391).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676103\n",
      "\tspeed: 0.0381s/iter; left time: 90.2130s\n",
      "\titers: 200, epoch: 10 | loss: 0.0639220\n",
      "\tspeed: 0.0204s/iter; left time: 46.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0692499 Vali Loss: 0.0639208 Test Loss: 0.0666822\n",
      "Validation loss decreased (0.064391 --> 0.063921).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0649667\n",
      "\tspeed: 0.0399s/iter; left time: 85.4800s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642909\n",
      "\tspeed: 0.0189s/iter; left time: 38.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0680481 Vali Loss: 0.0636861 Test Loss: 0.0665629\n",
      "Validation loss decreased (0.063921 --> 0.063686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0633217\n",
      "\tspeed: 0.0336s/iter; left time: 64.5001s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601581\n",
      "\tspeed: 0.0168s/iter; left time: 30.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0671285 Vali Loss: 0.0625936 Test Loss: 0.0653706\n",
      "Validation loss decreased (0.063686 --> 0.062594).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0671477\n",
      "\tspeed: 0.0366s/iter; left time: 61.9518s\n",
      "\titers: 200, epoch: 13 | loss: 0.0621317\n",
      "\tspeed: 0.0222s/iter; left time: 35.4376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0662944 Vali Loss: 0.0626164 Test Loss: 0.0654073\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650934\n",
      "\tspeed: 0.0333s/iter; left time: 48.9785s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580635\n",
      "\tspeed: 0.0173s/iter; left time: 23.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0657543 Vali Loss: 0.0621716 Test Loss: 0.0646343\n",
      "Validation loss decreased (0.062594 --> 0.062172).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0658439\n",
      "\tspeed: 0.0344s/iter; left time: 42.7789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0626161\n",
      "\tspeed: 0.0178s/iter; left time: 20.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0653719 Vali Loss: 0.0616256 Test Loss: 0.0642001\n",
      "Validation loss decreased (0.062172 --> 0.061626).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0626120\n",
      "\tspeed: 0.0306s/iter; left time: 31.2013s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643119\n",
      "\tspeed: 0.0098s/iter; left time: 9.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0649188 Vali Loss: 0.0611425 Test Loss: 0.0636172\n",
      "Validation loss decreased (0.061626 --> 0.061142).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716812\n",
      "\tspeed: 0.0353s/iter; left time: 28.1321s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630838\n",
      "\tspeed: 0.0199s/iter; left time: 13.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0645986 Vali Loss: 0.0614054 Test Loss: 0.0635941\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649277\n",
      "\tspeed: 0.0374s/iter; left time: 21.4081s\n",
      "\titers: 200, epoch: 18 | loss: 0.0586403\n",
      "\tspeed: 0.0192s/iter; left time: 9.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0643763 Vali Loss: 0.0607071 Test Loss: 0.0632886\n",
      "Validation loss decreased (0.061142 --> 0.060707).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0595899\n",
      "\tspeed: 0.0351s/iter; left time: 12.2401s\n",
      "\titers: 200, epoch: 19 | loss: 0.0584789\n",
      "\tspeed: 0.0177s/iter; left time: 4.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0641533 Vali Loss: 0.0604696 Test Loss: 0.0628338\n",
      "Validation loss decreased (0.060707 --> 0.060470).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0596086\n",
      "\tspeed: 0.0383s/iter; left time: 4.7905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594903\n",
      "\tspeed: 0.0151s/iter; left time: 0.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0638867 Vali Loss: 0.0604500 Test Loss: 0.0628845\n",
      "Validation loss decreased (0.060470 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011079911142587662, rmse:0.10526115447282791, mae:0.06288447976112366, rse:0.3977300822734833\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:42.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0404s/iter; left time: 177.0480s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0135s/iter; left time: 57.6457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0318s/iter; left time: 132.2362s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0119s/iter; left time: 48.3405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0343s/iter; left time: 134.7188s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0173s/iter; left time: 66.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0353s/iter; left time: 130.9028s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0162s/iter; left time: 58.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0351s/iter; left time: 122.1523s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0182s/iter; left time: 61.5547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0330s/iter; left time: 107.5714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0159s/iter; left time: 50.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0364s/iter; left time: 110.4730s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0168s/iter; left time: 49.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0372s/iter; left time: 104.7506s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0188s/iter; left time: 51.0357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0362s/iter; left time: 93.7808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0188s/iter; left time: 46.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0318s/iter; left time: 75.1964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0102s/iter; left time: 23.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0338s/iter; left time: 72.2765s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0166s/iter; left time: 33.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0392s/iter; left time: 75.2042s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0207s/iter; left time: 37.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0393s/iter; left time: 66.4763s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0206s/iter; left time: 32.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0409s/iter; left time: 60.1194s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0208s/iter; left time: 28.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0360s/iter; left time: 44.8682s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0216s/iter; left time: 24.7207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0370s/iter; left time: 37.7275s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0203s/iter; left time: 18.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0377s/iter; left time: 30.0604s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0188s/iter; left time: 13.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0395s/iter; left time: 22.6435s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0201s/iter; left time: 9.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0376s/iter; left time: 13.1317s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0183s/iter; left time: 4.5534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0351s/iter; left time: 4.3879s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0174s/iter; left time: 0.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018444322049617767, rmse:0.13580986857414246, mae:0.0837516337633133, rse:0.5135117769241333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2798630\n",
      "\tspeed: 0.0234s/iter; left time: 102.6526s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552814\n",
      "\tspeed: 0.0163s/iter; left time: 69.7467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.2785395 Vali Loss: 0.1956593 Test Loss: 0.2025459\n",
      "Validation loss decreased (inf --> 0.195659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1523195\n",
      "\tspeed: 0.0408s/iter; left time: 169.6055s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261142\n",
      "\tspeed: 0.0180s/iter; left time: 73.2253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.1576536 Vali Loss: 0.1078425 Test Loss: 0.1150946\n",
      "Validation loss decreased (0.195659 --> 0.107843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147000\n",
      "\tspeed: 0.0354s/iter; left time: 139.3425s\n",
      "\titers: 200, epoch: 3 | loss: 0.1113540\n",
      "\tspeed: 0.0170s/iter; left time: 65.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1117495 Vali Loss: 0.0957548 Test Loss: 0.1001511\n",
      "Validation loss decreased (0.107843 --> 0.095755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995651\n",
      "\tspeed: 0.0370s/iter; left time: 137.3680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954478\n",
      "\tspeed: 0.0182s/iter; left time: 65.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1004729 Vali Loss: 0.0901986 Test Loss: 0.0926676\n",
      "Validation loss decreased (0.095755 --> 0.090199).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0969215\n",
      "\tspeed: 0.0386s/iter; left time: 134.3633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928631\n",
      "\tspeed: 0.0206s/iter; left time: 69.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0938142 Vali Loss: 0.0860796 Test Loss: 0.0895533\n",
      "Validation loss decreased (0.090199 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0870151\n",
      "\tspeed: 0.0284s/iter; left time: 92.4786s\n",
      "\titers: 200, epoch: 6 | loss: 0.0875229\n",
      "\tspeed: 0.0178s/iter; left time: 56.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0905203 Vali Loss: 0.0847814 Test Loss: 0.0879801\n",
      "Validation loss decreased (0.086080 --> 0.084781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876240\n",
      "\tspeed: 0.0377s/iter; left time: 114.5815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924451\n",
      "\tspeed: 0.0169s/iter; left time: 49.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0881872 Vali Loss: 0.0827412 Test Loss: 0.0871473\n",
      "Validation loss decreased (0.084781 --> 0.082741).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911712\n",
      "\tspeed: 0.0358s/iter; left time: 100.6126s\n",
      "\titers: 200, epoch: 8 | loss: 0.0860737\n",
      "\tspeed: 0.0178s/iter; left time: 48.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0866387 Vali Loss: 0.0817173 Test Loss: 0.0861746\n",
      "Validation loss decreased (0.082741 --> 0.081717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867940\n",
      "\tspeed: 0.0341s/iter; left time: 88.3317s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838338\n",
      "\tspeed: 0.0168s/iter; left time: 41.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0853725 Vali Loss: 0.0804546 Test Loss: 0.0854482\n",
      "Validation loss decreased (0.081717 --> 0.080455).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817206\n",
      "\tspeed: 0.0364s/iter; left time: 86.0294s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812260\n",
      "\tspeed: 0.0173s/iter; left time: 39.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0844308 Vali Loss: 0.0804576 Test Loss: 0.0854035\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823050\n",
      "\tspeed: 0.0364s/iter; left time: 78.0030s\n",
      "\titers: 200, epoch: 11 | loss: 0.0891172\n",
      "\tspeed: 0.0171s/iter; left time: 34.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0839546 Vali Loss: 0.0798848 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080455 --> 0.079885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836017\n",
      "\tspeed: 0.0359s/iter; left time: 68.8174s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801083\n",
      "\tspeed: 0.0192s/iter; left time: 34.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0831784 Vali Loss: 0.0796328 Test Loss: 0.0854974\n",
      "Validation loss decreased (0.079885 --> 0.079633).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847356\n",
      "\tspeed: 0.0380s/iter; left time: 64.3992s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833554\n",
      "\tspeed: 0.0169s/iter; left time: 26.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0827545 Vali Loss: 0.0793973 Test Loss: 0.0847967\n",
      "Validation loss decreased (0.079633 --> 0.079397).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791785\n",
      "\tspeed: 0.0349s/iter; left time: 51.2328s\n",
      "\titers: 200, epoch: 14 | loss: 0.0865727\n",
      "\tspeed: 0.0176s/iter; left time: 24.0852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0823615 Vali Loss: 0.0789985 Test Loss: 0.0845724\n",
      "Validation loss decreased (0.079397 --> 0.078999).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0853503\n",
      "\tspeed: 0.0366s/iter; left time: 45.5915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792778\n",
      "\tspeed: 0.0173s/iter; left time: 19.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0819889 Vali Loss: 0.0791902 Test Loss: 0.0849499\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0856560\n",
      "\tspeed: 0.0403s/iter; left time: 41.1114s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827346\n",
      "\tspeed: 0.0204s/iter; left time: 18.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0816865 Vali Loss: 0.0787904 Test Loss: 0.0842490\n",
      "Validation loss decreased (0.078999 --> 0.078790).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848473\n",
      "\tspeed: 0.0388s/iter; left time: 30.8988s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770277\n",
      "\tspeed: 0.0202s/iter; left time: 14.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0814561 Vali Loss: 0.0784145 Test Loss: 0.0843971\n",
      "Validation loss decreased (0.078790 --> 0.078414).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760338\n",
      "\tspeed: 0.0386s/iter; left time: 22.1347s\n",
      "\titers: 200, epoch: 18 | loss: 0.0781984\n",
      "\tspeed: 0.0184s/iter; left time: 8.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0810920 Vali Loss: 0.0786268 Test Loss: 0.0844016\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800134\n",
      "\tspeed: 0.0384s/iter; left time: 13.4095s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767878\n",
      "\tspeed: 0.0195s/iter; left time: 4.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0810874 Vali Loss: 0.0781209 Test Loss: 0.0842462\n",
      "Validation loss decreased (0.078414 --> 0.078121).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0753115\n",
      "\tspeed: 0.0365s/iter; left time: 4.5596s\n",
      "\titers: 200, epoch: 20 | loss: 0.0850095\n",
      "\tspeed: 0.0186s/iter; left time: 0.4641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0807790 Vali Loss: 0.0781104 Test Loss: 0.0839733\n",
      "Validation loss decreased (0.078121 --> 0.078110).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018509913235902786, rmse:0.13605114817619324, mae:0.08397328108549118, rse:0.5144240260124207\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:48.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0419s/iter; left time: 182.6315s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0170s/iter; left time: 72.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0368s/iter; left time: 152.4655s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0183s/iter; left time: 73.7435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0418s/iter; left time: 163.6557s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0187s/iter; left time: 71.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0369s/iter; left time: 136.1239s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0183s/iter; left time: 65.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0386s/iter; left time: 133.8685s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0191s/iter; left time: 64.5082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0382s/iter; left time: 123.8349s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0161s/iter; left time: 50.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0422s/iter; left time: 127.5245s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0225s/iter; left time: 65.6778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0380s/iter; left time: 106.3493s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0168s/iter; left time: 45.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0355s/iter; left time: 91.5564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0181s/iter; left time: 44.7516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0381s/iter; left time: 89.7250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0176s/iter; left time: 39.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0398s/iter; left time: 84.7522s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0197s/iter; left time: 40.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0395s/iter; left time: 75.3079s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0194s/iter; left time: 35.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0363s/iter; left time: 61.1904s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0177s/iter; left time: 28.1020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0387s/iter; left time: 56.5955s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0200s/iter; left time: 27.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0397s/iter; left time: 49.2184s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0201s/iter; left time: 22.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0391s/iter; left time: 39.7543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0187s/iter; left time: 17.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0375s/iter; left time: 29.7350s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0188s/iter; left time: 13.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0376s/iter; left time: 21.4124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0194s/iter; left time: 9.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0394s/iter; left time: 13.6689s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0199s/iter; left time: 4.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0386s/iter; left time: 4.7844s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0194s/iter; left time: 0.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020099075511097908, rmse:0.14177121222019196, mae:0.08870533108711243, rse:0.5365503430366516\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2813044\n",
      "\tspeed: 0.0229s/iter; left time: 99.9398s\n",
      "\titers: 200, epoch: 1 | loss: 0.2537842\n",
      "\tspeed: 0.0202s/iter; left time: 85.9223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.2827695 Vali Loss: 0.1986171 Test Loss: 0.2049647\n",
      "Validation loss decreased (inf --> 0.198617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426644\n",
      "\tspeed: 0.0405s/iter; left time: 167.7063s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291617\n",
      "\tspeed: 0.0202s/iter; left time: 81.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1570104 Vali Loss: 0.1081954 Test Loss: 0.1133942\n",
      "Validation loss decreased (0.198617 --> 0.108195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168254\n",
      "\tspeed: 0.0404s/iter; left time: 158.3028s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129910\n",
      "\tspeed: 0.0199s/iter; left time: 75.8324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1136678 Vali Loss: 0.0983627 Test Loss: 0.1008437\n",
      "Validation loss decreased (0.108195 --> 0.098363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040641\n",
      "\tspeed: 0.0435s/iter; left time: 160.6158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984779\n",
      "\tspeed: 0.0178s/iter; left time: 63.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1031041 Vali Loss: 0.0935392 Test Loss: 0.0961893\n",
      "Validation loss decreased (0.098363 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0936531\n",
      "\tspeed: 0.0389s/iter; left time: 135.0783s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950231\n",
      "\tspeed: 0.0201s/iter; left time: 67.7309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0967202 Vali Loss: 0.0893786 Test Loss: 0.0926177\n",
      "Validation loss decreased (0.093539 --> 0.089379).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0924721\n",
      "\tspeed: 0.0402s/iter; left time: 130.4695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0913443\n",
      "\tspeed: 0.0209s/iter; left time: 65.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0941212 Vali Loss: 0.0876763 Test Loss: 0.0913170\n",
      "Validation loss decreased (0.089379 --> 0.087676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0951016\n",
      "\tspeed: 0.0399s/iter; left time: 120.5680s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915995\n",
      "\tspeed: 0.0198s/iter; left time: 57.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0915591 Vali Loss: 0.0875427 Test Loss: 0.0913138\n",
      "Validation loss decreased (0.087676 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927571\n",
      "\tspeed: 0.0410s/iter; left time: 114.6984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0894333\n",
      "\tspeed: 0.0198s/iter; left time: 53.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0900401 Vali Loss: 0.0854019 Test Loss: 0.0900058\n",
      "Validation loss decreased (0.087543 --> 0.085402).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0886705\n",
      "\tspeed: 0.0409s/iter; left time: 105.4171s\n",
      "\titers: 200, epoch: 9 | loss: 0.0879912\n",
      "\tspeed: 0.0203s/iter; left time: 50.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0889541 Vali Loss: 0.0849612 Test Loss: 0.0891515\n",
      "Validation loss decreased (0.085402 --> 0.084961).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0877168\n",
      "\tspeed: 0.0404s/iter; left time: 95.0838s\n",
      "\titers: 200, epoch: 10 | loss: 0.0875674\n",
      "\tspeed: 0.0205s/iter; left time: 46.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0881908 Vali Loss: 0.0846811 Test Loss: 0.0888525\n",
      "Validation loss decreased (0.084961 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0898153\n",
      "\tspeed: 0.0399s/iter; left time: 85.0774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906977\n",
      "\tspeed: 0.0192s/iter; left time: 39.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0876222 Vali Loss: 0.0841912 Test Loss: 0.0885119\n",
      "Validation loss decreased (0.084681 --> 0.084191).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0854267\n",
      "\tspeed: 0.0400s/iter; left time: 76.3177s\n",
      "\titers: 200, epoch: 12 | loss: 0.0921324\n",
      "\tspeed: 0.0194s/iter; left time: 35.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0870224 Vali Loss: 0.0838905 Test Loss: 0.0882123\n",
      "Validation loss decreased (0.084191 --> 0.083890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908491\n",
      "\tspeed: 0.0402s/iter; left time: 67.7130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0868078\n",
      "\tspeed: 0.0194s/iter; left time: 30.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0865049 Vali Loss: 0.0839069 Test Loss: 0.0883935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0854094\n",
      "\tspeed: 0.0398s/iter; left time: 58.2553s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844667\n",
      "\tspeed: 0.0197s/iter; left time: 26.7745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0861975 Vali Loss: 0.0840705 Test Loss: 0.0888260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889031\n",
      "\tspeed: 0.0397s/iter; left time: 49.1403s\n",
      "\titers: 200, epoch: 15 | loss: 0.0843957\n",
      "\tspeed: 0.0202s/iter; left time: 23.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0855418 Vali Loss: 0.0836140 Test Loss: 0.0885775\n",
      "Validation loss decreased (0.083890 --> 0.083614).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0875921\n",
      "\tspeed: 0.0408s/iter; left time: 41.4238s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831733\n",
      "\tspeed: 0.0207s/iter; left time: 18.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0853479 Vali Loss: 0.0839115 Test Loss: 0.0888283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0873199\n",
      "\tspeed: 0.0402s/iter; left time: 31.8651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876978\n",
      "\tspeed: 0.0189s/iter; left time: 13.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0852551 Vali Loss: 0.0832509 Test Loss: 0.0884188\n",
      "Validation loss decreased (0.083614 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0823902\n",
      "\tspeed: 0.0398s/iter; left time: 22.6634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818335\n",
      "\tspeed: 0.0207s/iter; left time: 9.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0849353 Vali Loss: 0.0838093 Test Loss: 0.0887195\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851609\n",
      "\tspeed: 0.0322s/iter; left time: 11.1699s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858866\n",
      "\tspeed: 0.0101s/iter; left time: 2.5044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 223 | Train Loss: 0.0846712 Vali Loss: 0.0832612 Test Loss: 0.0881233\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0836230\n",
      "\tspeed: 0.0398s/iter; left time: 4.9385s\n",
      "\titers: 200, epoch: 20 | loss: 0.0846320\n",
      "\tspeed: 0.0215s/iter; left time: 0.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0845549 Vali Loss: 0.0833086 Test Loss: 0.0881949\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019747594371438026, rmse:0.14052613079547882, mae:0.0884188562631607, rse:0.5318382382392883\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:05.17s\n",
      "Intermediate time for IT: 00h:11m:36.77s\n",
      "Total time: 00h:58m:25.34s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1657</td>\n",
       "      <td>0.1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0217  0.1473  0.0911\n",
       "        96             0.0401  0.2002  0.1317\n",
       "        168            0.0432  0.2077  0.1391\n",
       "ES      24             0.0168  0.1281  0.0760\n",
       "        96             0.0263  0.1609  0.1041\n",
       "        168            0.0266  0.1624  0.1084\n",
       "FR      24             0.0108  0.1041  0.0597\n",
       "        96             0.0203  0.1423  0.0836\n",
       "        168            0.0230  0.1516  0.0899\n",
       "GB      24             0.0275  0.1657  0.1054\n",
       "        96             0.0497  0.2226  0.1490\n",
       "        168            0.0518  0.2274  0.1545\n",
       "IT      24             0.0108  0.1039  0.0611\n",
       "        96             0.0185  0.1360  0.0829\n",
       "        168            0.0202  0.1421  0.0882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patch_len = 1\n",
    "stride = 1\n",
    "#batch_size = 64\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE\n",
    "# 24\n",
    "# Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
    "#Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
    "#96\n",
    "# Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
