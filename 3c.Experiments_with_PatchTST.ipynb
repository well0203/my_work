{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0425s/iter; left time: 186.3442s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0147s/iter; left time: 62.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0336s/iter; left time: 139.6125s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0162s/iter; left time: 65.6242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0352s/iter; left time: 138.5111s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0196s/iter; left time: 75.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0372s/iter; left time: 137.9160s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0185s/iter; left time: 66.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0409s/iter; left time: 142.6269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0177s/iter; left time: 59.8200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0365s/iter; left time: 119.0118s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0186s/iter; left time: 58.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0356s/iter; left time: 108.0049s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0174s/iter; left time: 51.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0360s/iter; left time: 101.2319s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0192s/iter; left time: 52.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0370s/iter; left time: 95.6674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0180s/iter; left time: 44.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0352s/iter; left time: 83.2606s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0181s/iter; left time: 40.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0363s/iter; left time: 77.6939s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0185s/iter; left time: 37.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0402s/iter; left time: 77.0498s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0166s/iter; left time: 30.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0385s/iter; left time: 65.2465s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0159s/iter; left time: 25.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0420s/iter; left time: 61.6369s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0202s/iter; left time: 27.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0377s/iter; left time: 46.9912s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0194s/iter; left time: 22.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0369s/iter; left time: 37.6850s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0177s/iter; left time: 16.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0325s/iter; left time: 25.9253s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0147s/iter; left time: 10.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0339s/iter; left time: 19.4218s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0175s/iter; left time: 8.2969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0420s/iter; left time: 14.6607s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0227s/iter; left time: 5.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0420s/iter; left time: 5.2486s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0198s/iter; left time: 0.4942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02197897806763649, rmse:0.14825308322906494, mae:0.09260880947113037, rse:0.5232056975364685\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2721842\n",
      "\tspeed: 0.0240s/iter; left time: 104.9852s\n",
      "\titers: 200, epoch: 1 | loss: 0.2545170\n",
      "\tspeed: 0.0218s/iter; left time: 93.4615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.2761312 Vali Loss: 0.2322660 Test Loss: 0.2356385\n",
      "Validation loss decreased (inf --> 0.232266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482331\n",
      "\tspeed: 0.0355s/iter; left time: 147.6405s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319499\n",
      "\tspeed: 0.0149s/iter; left time: 60.3281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1566612 Vali Loss: 0.1185808 Test Loss: 0.1211408\n",
      "Validation loss decreased (0.232266 --> 0.118581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1081690\n",
      "\tspeed: 0.0360s/iter; left time: 141.6233s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004020\n",
      "\tspeed: 0.0192s/iter; left time: 73.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1067749 Vali Loss: 0.1074769 Test Loss: 0.1081204\n",
      "Validation loss decreased (0.118581 --> 0.107477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891181\n",
      "\tspeed: 0.0348s/iter; left time: 128.8989s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888426\n",
      "\tspeed: 0.0166s/iter; left time: 59.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.0955432 Vali Loss: 0.1000804 Test Loss: 0.1024884\n",
      "Validation loss decreased (0.107477 --> 0.100080).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895891\n",
      "\tspeed: 0.0377s/iter; left time: 131.2394s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858524\n",
      "\tspeed: 0.0191s/iter; left time: 64.6147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0902970 Vali Loss: 0.1001018 Test Loss: 0.1025615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886195\n",
      "\tspeed: 0.0368s/iter; left time: 120.0273s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897056\n",
      "\tspeed: 0.0187s/iter; left time: 59.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0877654 Vali Loss: 0.0981362 Test Loss: 0.1006853\n",
      "Validation loss decreased (0.100080 --> 0.098136).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0878300\n",
      "\tspeed: 0.0372s/iter; left time: 113.0827s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826553\n",
      "\tspeed: 0.0174s/iter; left time: 51.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0857944 Vali Loss: 0.0958969 Test Loss: 0.0983018\n",
      "Validation loss decreased (0.098136 --> 0.095897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869670\n",
      "\tspeed: 0.0372s/iter; left time: 104.5667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836679\n",
      "\tspeed: 0.0185s/iter; left time: 50.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0840915 Vali Loss: 0.0946294 Test Loss: 0.0966067\n",
      "Validation loss decreased (0.095897 --> 0.094629).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806168\n",
      "\tspeed: 0.0325s/iter; left time: 84.2252s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788730\n",
      "\tspeed: 0.0147s/iter; left time: 36.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0832127 Vali Loss: 0.0942125 Test Loss: 0.0963571\n",
      "Validation loss decreased (0.094629 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0863781\n",
      "\tspeed: 0.0347s/iter; left time: 81.9788s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827872\n",
      "\tspeed: 0.0147s/iter; left time: 33.2494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 224 | Train Loss: 0.0823142 Vali Loss: 0.0934206 Test Loss: 0.0951447\n",
      "Validation loss decreased (0.094213 --> 0.093421).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0842941\n",
      "\tspeed: 0.0376s/iter; left time: 80.4039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798917\n",
      "\tspeed: 0.0213s/iter; left time: 43.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0812334 Vali Loss: 0.0930360 Test Loss: 0.0947575\n",
      "Validation loss decreased (0.093421 --> 0.093036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834161\n",
      "\tspeed: 0.0396s/iter; left time: 75.9682s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799981\n",
      "\tspeed: 0.0207s/iter; left time: 37.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0807119 Vali Loss: 0.0929712 Test Loss: 0.0947066\n",
      "Validation loss decreased (0.093036 --> 0.092971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815257\n",
      "\tspeed: 0.0427s/iter; left time: 72.2253s\n",
      "\titers: 200, epoch: 13 | loss: 0.0776588\n",
      "\tspeed: 0.0180s/iter; left time: 28.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0801480 Vali Loss: 0.0923747 Test Loss: 0.0944369\n",
      "Validation loss decreased (0.092971 --> 0.092375).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754340\n",
      "\tspeed: 0.0394s/iter; left time: 57.8197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819355\n",
      "\tspeed: 0.0170s/iter; left time: 23.3345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0798022 Vali Loss: 0.0923370 Test Loss: 0.0939305\n",
      "Validation loss decreased (0.092375 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803141\n",
      "\tspeed: 0.0380s/iter; left time: 47.3277s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758411\n",
      "\tspeed: 0.0209s/iter; left time: 23.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0792215 Vali Loss: 0.0938695 Test Loss: 0.0954283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0765127\n",
      "\tspeed: 0.0372s/iter; left time: 38.0095s\n",
      "\titers: 200, epoch: 16 | loss: 0.0853249\n",
      "\tspeed: 0.0176s/iter; left time: 16.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0790664 Vali Loss: 0.0919052 Test Loss: 0.0936920\n",
      "Validation loss decreased (0.092337 --> 0.091905).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0840101\n",
      "\tspeed: 0.0358s/iter; left time: 28.5016s\n",
      "\titers: 200, epoch: 17 | loss: 0.0743264\n",
      "\tspeed: 0.0217s/iter; left time: 15.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0785786 Vali Loss: 0.0913657 Test Loss: 0.0932587\n",
      "Validation loss decreased (0.091905 --> 0.091366).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0817556\n",
      "\tspeed: 0.0387s/iter; left time: 22.1612s\n",
      "\titers: 200, epoch: 18 | loss: 0.0756749\n",
      "\tspeed: 0.0168s/iter; left time: 7.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0783503 Vali Loss: 0.0909367 Test Loss: 0.0929703\n",
      "Validation loss decreased (0.091366 --> 0.090937).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806383\n",
      "\tspeed: 0.0397s/iter; left time: 13.8603s\n",
      "\titers: 200, epoch: 19 | loss: 0.0788134\n",
      "\tspeed: 0.0243s/iter; left time: 6.0394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0782910 Vali Loss: 0.0909684 Test Loss: 0.0929274\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790623\n",
      "\tspeed: 0.0360s/iter; left time: 4.4990s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762136\n",
      "\tspeed: 0.0170s/iter; left time: 0.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0779857 Vali Loss: 0.0904959 Test Loss: 0.0925888\n",
      "Validation loss decreased (0.090937 --> 0.090496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02206687070429325, rmse:0.14854921400547028, mae:0.09258876740932465, rse:0.5242507457733154\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:52.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0434s/iter; left time: 190.3141s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0150s/iter; left time: 64.0342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0360s/iter; left time: 149.6428s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0167s/iter; left time: 67.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0361s/iter; left time: 141.7978s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0187s/iter; left time: 71.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0418s/iter; left time: 154.9258s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0178s/iter; left time: 64.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0363s/iter; left time: 126.4420s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0202s/iter; left time: 68.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0380s/iter; left time: 123.8193s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0162s/iter; left time: 51.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0360s/iter; left time: 109.1829s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0162s/iter; left time: 47.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0390s/iter; left time: 109.6243s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0170s/iter; left time: 46.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0367s/iter; left time: 94.9922s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0150s/iter; left time: 37.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0365s/iter; left time: 86.2110s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0178s/iter; left time: 40.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0407s/iter; left time: 87.1434s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0186s/iter; left time: 38.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0357s/iter; left time: 68.4599s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0168s/iter; left time: 30.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0353s/iter; left time: 59.8180s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0160s/iter; left time: 25.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0355s/iter; left time: 52.0884s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0179s/iter; left time: 24.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0378s/iter; left time: 47.0716s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0226s/iter; left time: 25.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0380s/iter; left time: 38.8147s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0158s/iter; left time: 14.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0383s/iter; left time: 30.5138s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0156s/iter; left time: 10.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0368s/iter; left time: 21.0625s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0169s/iter; left time: 7.9763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0397s/iter; left time: 13.8496s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0196s/iter; left time: 4.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0341s/iter; left time: 4.2672s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0191s/iter; left time: 0.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04150562733411789, rmse:0.2037293016910553, mae:0.13349591195583344, rse:0.721446692943573\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2745755\n",
      "\tspeed: 0.0235s/iter; left time: 103.1565s\n",
      "\titers: 200, epoch: 1 | loss: 0.2692268\n",
      "\tspeed: 0.0231s/iter; left time: 98.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.2751624 Vali Loss: 0.2348203 Test Loss: 0.2388337\n",
      "Validation loss decreased (inf --> 0.234820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551890\n",
      "\tspeed: 0.0400s/iter; left time: 166.3750s\n",
      "\titers: 200, epoch: 2 | loss: 0.1321813\n",
      "\tspeed: 0.0160s/iter; left time: 64.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1654698 Vali Loss: 0.1417630 Test Loss: 0.1481800\n",
      "Validation loss decreased (0.234820 --> 0.141763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1215974\n",
      "\tspeed: 0.0370s/iter; left time: 145.4642s\n",
      "\titers: 200, epoch: 3 | loss: 0.1256834\n",
      "\tspeed: 0.0167s/iter; left time: 64.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1263876 Vali Loss: 0.1325889 Test Loss: 0.1409987\n",
      "Validation loss decreased (0.141763 --> 0.132589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1135110\n",
      "\tspeed: 0.0414s/iter; left time: 153.4803s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192949\n",
      "\tspeed: 0.0224s/iter; left time: 80.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.1174851 Vali Loss: 0.1272122 Test Loss: 0.1361652\n",
      "Validation loss decreased (0.132589 --> 0.127212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163965\n",
      "\tspeed: 0.0444s/iter; left time: 154.6167s\n",
      "\titers: 200, epoch: 5 | loss: 0.1152640\n",
      "\tspeed: 0.0207s/iter; left time: 70.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.1131541 Vali Loss: 0.1246094 Test Loss: 0.1332051\n",
      "Validation loss decreased (0.127212 --> 0.124609).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112591\n",
      "\tspeed: 0.0413s/iter; left time: 134.6318s\n",
      "\titers: 200, epoch: 6 | loss: 0.1082482\n",
      "\tspeed: 0.0193s/iter; left time: 61.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1111110 Vali Loss: 0.1238740 Test Loss: 0.1333937\n",
      "Validation loss decreased (0.124609 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057189\n",
      "\tspeed: 0.0411s/iter; left time: 124.8942s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117747\n",
      "\tspeed: 0.0182s/iter; left time: 53.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1091282 Vali Loss: 0.1267143 Test Loss: 0.1375530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1141506\n",
      "\tspeed: 0.0384s/iter; left time: 108.1486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009115\n",
      "\tspeed: 0.0183s/iter; left time: 49.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1081073 Vali Loss: 0.1231339 Test Loss: 0.1339826\n",
      "Validation loss decreased (0.123874 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1019052\n",
      "\tspeed: 0.0375s/iter; left time: 97.1743s\n",
      "\titers: 200, epoch: 9 | loss: 0.1077909\n",
      "\tspeed: 0.0184s/iter; left time: 45.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1073068 Vali Loss: 0.1232993 Test Loss: 0.1331413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1092062\n",
      "\tspeed: 0.0391s/iter; left time: 92.4493s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068623\n",
      "\tspeed: 0.0197s/iter; left time: 44.7243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.1064968 Vali Loss: 0.1219509 Test Loss: 0.1326125\n",
      "Validation loss decreased (0.123134 --> 0.121951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040168\n",
      "\tspeed: 0.0360s/iter; left time: 77.1446s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067823\n",
      "\tspeed: 0.0150s/iter; left time: 30.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1059778 Vali Loss: 0.1218960 Test Loss: 0.1338872\n",
      "Validation loss decreased (0.121951 --> 0.121896).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011791\n",
      "\tspeed: 0.0370s/iter; left time: 70.8505s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045789\n",
      "\tspeed: 0.0178s/iter; left time: 32.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1055520 Vali Loss: 0.1224215 Test Loss: 0.1361842\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020355\n",
      "\tspeed: 0.0396s/iter; left time: 66.9582s\n",
      "\titers: 200, epoch: 13 | loss: 0.1006409\n",
      "\tspeed: 0.0177s/iter; left time: 28.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.1050931 Vali Loss: 0.1211242 Test Loss: 0.1328582\n",
      "Validation loss decreased (0.121896 --> 0.121124).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023372\n",
      "\tspeed: 0.0402s/iter; left time: 59.1163s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056428\n",
      "\tspeed: 0.0174s/iter; left time: 23.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1046984 Vali Loss: 0.1215836 Test Loss: 0.1348134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028019\n",
      "\tspeed: 0.0377s/iter; left time: 46.9137s\n",
      "\titers: 200, epoch: 15 | loss: 0.1016776\n",
      "\tspeed: 0.0183s/iter; left time: 20.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1043435 Vali Loss: 0.1219964 Test Loss: 0.1366068\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1028563\n",
      "\tspeed: 0.0355s/iter; left time: 36.2853s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091383\n",
      "\tspeed: 0.0152s/iter; left time: 13.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1043203 Vali Loss: 0.1209410 Test Loss: 0.1350278\n",
      "Validation loss decreased (0.121124 --> 0.120941).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068253\n",
      "\tspeed: 0.0388s/iter; left time: 30.9340s\n",
      "\titers: 200, epoch: 17 | loss: 0.1018474\n",
      "\tspeed: 0.0183s/iter; left time: 12.7437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1039987 Vali Loss: 0.1214914 Test Loss: 0.1367325\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1014489\n",
      "\tspeed: 0.0365s/iter; left time: 20.9099s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990626\n",
      "\tspeed: 0.0150s/iter; left time: 7.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1036466 Vali Loss: 0.1200883 Test Loss: 0.1337987\n",
      "Validation loss decreased (0.120941 --> 0.120088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1060394\n",
      "\tspeed: 0.0358s/iter; left time: 12.4978s\n",
      "\titers: 200, epoch: 19 | loss: 0.1063231\n",
      "\tspeed: 0.0172s/iter; left time: 4.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.1036820 Vali Loss: 0.1203940 Test Loss: 0.1338672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1069428\n",
      "\tspeed: 0.0374s/iter; left time: 4.6735s\n",
      "\titers: 200, epoch: 20 | loss: 0.1037648\n",
      "\tspeed: 0.0178s/iter; left time: 0.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.1033537 Vali Loss: 0.1214264 Test Loss: 0.1366773\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04148979112505913, rmse:0.20369042456150055, mae:0.1337987184524536, rse:0.7213089466094971\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:56.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0434s/iter; left time: 189.2073s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0153s/iter; left time: 65.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0352s/iter; left time: 145.7541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0152s/iter; left time: 61.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0349s/iter; left time: 136.5407s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0153s/iter; left time: 58.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0385s/iter; left time: 142.0827s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0152s/iter; left time: 54.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0348s/iter; left time: 120.8552s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0201s/iter; left time: 67.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0371s/iter; left time: 120.2849s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0152s/iter; left time: 47.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0378s/iter; left time: 114.2307s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0164s/iter; left time: 47.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0393s/iter; left time: 110.1425s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0200s/iter; left time: 53.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0374s/iter; left time: 96.2940s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0165s/iter; left time: 40.9024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0375s/iter; left time: 88.1992s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0171s/iter; left time: 38.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0417s/iter; left time: 88.9434s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0190s/iter; left time: 38.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0350s/iter; left time: 66.8163s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0194s/iter; left time: 35.0513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0403s/iter; left time: 67.8308s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0152s/iter; left time: 24.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0365s/iter; left time: 53.3737s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0154s/iter; left time: 20.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0372s/iter; left time: 46.0534s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0169s/iter; left time: 19.2656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0393s/iter; left time: 39.9785s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0191s/iter; left time: 17.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0373s/iter; left time: 29.5417s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0182s/iter; left time: 12.6162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0376s/iter; left time: 21.4098s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0179s/iter; left time: 8.3986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0404s/iter; left time: 14.0241s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0151s/iter; left time: 3.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04356519505381584, rmse:0.2087227702140808, mae:0.1395985186100006, rse:0.7393128275871277\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812734\n",
      "\tspeed: 0.0215s/iter; left time: 93.9062s\n",
      "\titers: 200, epoch: 1 | loss: 0.2648552\n",
      "\tspeed: 0.0193s/iter; left time: 82.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.2822170 Vali Loss: 0.2397827 Test Loss: 0.2450302\n",
      "Validation loss decreased (inf --> 0.239783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632033\n",
      "\tspeed: 0.0429s/iter; left time: 177.3251s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432949\n",
      "\tspeed: 0.0170s/iter; left time: 68.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1688149 Vali Loss: 0.1457720 Test Loss: 0.1536164\n",
      "Validation loss decreased (0.239783 --> 0.145772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1266351\n",
      "\tspeed: 0.0383s/iter; left time: 149.9207s\n",
      "\titers: 200, epoch: 3 | loss: 0.1198552\n",
      "\tspeed: 0.0180s/iter; left time: 68.6526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1316933 Vali Loss: 0.1368362 Test Loss: 0.1507061\n",
      "Validation loss decreased (0.145772 --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1193674\n",
      "\tspeed: 0.0433s/iter; left time: 159.7624s\n",
      "\titers: 200, epoch: 4 | loss: 0.1206695\n",
      "\tspeed: 0.0193s/iter; left time: 69.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1227247 Vali Loss: 0.1357975 Test Loss: 0.1491872\n",
      "Validation loss decreased (0.136836 --> 0.135798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187348\n",
      "\tspeed: 0.0390s/iter; left time: 135.3528s\n",
      "\titers: 200, epoch: 5 | loss: 0.1190373\n",
      "\tspeed: 0.0177s/iter; left time: 59.4858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1191489 Vali Loss: 0.1308743 Test Loss: 0.1448017\n",
      "Validation loss decreased (0.135798 --> 0.130874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146746\n",
      "\tspeed: 0.0376s/iter; left time: 121.9025s\n",
      "\titers: 200, epoch: 6 | loss: 0.1148309\n",
      "\tspeed: 0.0152s/iter; left time: 47.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1166092 Vali Loss: 0.1314674 Test Loss: 0.1459267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1175115\n",
      "\tspeed: 0.0407s/iter; left time: 122.9642s\n",
      "\titers: 200, epoch: 7 | loss: 0.1088397\n",
      "\tspeed: 0.0194s/iter; left time: 56.7015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1151693 Vali Loss: 0.1312253 Test Loss: 0.1448718\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1191927\n",
      "\tspeed: 0.0422s/iter; left time: 118.1438s\n",
      "\titers: 200, epoch: 8 | loss: 0.1117679\n",
      "\tspeed: 0.0194s/iter; left time: 52.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1141006 Vali Loss: 0.1306444 Test Loss: 0.1441707\n",
      "Validation loss decreased (0.130874 --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1125659\n",
      "\tspeed: 0.0412s/iter; left time: 106.1390s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103978\n",
      "\tspeed: 0.0197s/iter; left time: 48.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.1131375 Vali Loss: 0.1308488 Test Loss: 0.1439586\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097929\n",
      "\tspeed: 0.0371s/iter; left time: 87.3929s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076796\n",
      "\tspeed: 0.0171s/iter; left time: 38.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1123829 Vali Loss: 0.1314475 Test Loss: 0.1447518\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068592\n",
      "\tspeed: 0.0436s/iter; left time: 92.8487s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085388\n",
      "\tspeed: 0.0229s/iter; left time: 46.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.1117776 Vali Loss: 0.1311427 Test Loss: 0.1450391\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080086\n",
      "\tspeed: 0.0375s/iter; left time: 71.4826s\n",
      "\titers: 200, epoch: 12 | loss: 0.1089400\n",
      "\tspeed: 0.0180s/iter; left time: 32.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1112884 Vali Loss: 0.1306694 Test Loss: 0.1443284\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1129659\n",
      "\tspeed: 0.0447s/iter; left time: 75.2401s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087663\n",
      "\tspeed: 0.0225s/iter; left time: 35.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1107222 Vali Loss: 0.1300552 Test Loss: 0.1437648\n",
      "Validation loss decreased (0.130644 --> 0.130055).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1106686\n",
      "\tspeed: 0.0391s/iter; left time: 57.1431s\n",
      "\titers: 200, epoch: 14 | loss: 0.1079151\n",
      "\tspeed: 0.0170s/iter; left time: 23.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.1102911 Vali Loss: 0.1309756 Test Loss: 0.1456672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1096638\n",
      "\tspeed: 0.0378s/iter; left time: 46.8410s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065728\n",
      "\tspeed: 0.0168s/iter; left time: 19.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1099320 Vali Loss: 0.1304136 Test Loss: 0.1437775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1128930\n",
      "\tspeed: 0.0380s/iter; left time: 38.5860s\n",
      "\titers: 200, epoch: 16 | loss: 0.1056558\n",
      "\tspeed: 0.0155s/iter; left time: 14.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.1095359 Vali Loss: 0.1290297 Test Loss: 0.1434999\n",
      "Validation loss decreased (0.130055 --> 0.129030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1129074\n",
      "\tspeed: 0.0377s/iter; left time: 29.9343s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060182\n",
      "\tspeed: 0.0173s/iter; left time: 12.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1093078 Vali Loss: 0.1279821 Test Loss: 0.1426028\n",
      "Validation loss decreased (0.129030 --> 0.127982).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089246\n",
      "\tspeed: 0.0386s/iter; left time: 22.0086s\n",
      "\titers: 200, epoch: 18 | loss: 0.1129903\n",
      "\tspeed: 0.0166s/iter; left time: 7.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.1088755 Vali Loss: 0.1292565 Test Loss: 0.1439340\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1071319\n",
      "\tspeed: 0.0382s/iter; left time: 13.2416s\n",
      "\titers: 200, epoch: 19 | loss: 0.1072017\n",
      "\tspeed: 0.0169s/iter; left time: 4.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1088933 Vali Loss: 0.1299791 Test Loss: 0.1445618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1044815\n",
      "\tspeed: 0.0402s/iter; left time: 4.9789s\n",
      "\titers: 200, epoch: 20 | loss: 0.1130169\n",
      "\tspeed: 0.0153s/iter; left time: 0.3666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.1085727 Vali Loss: 0.1287442 Test Loss: 0.1427801\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046037085354328156, rmse:0.2145625501871109, mae:0.1426028162240982, rse:0.7599977850914001\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:52.32s\n",
      "Intermediate time for DE: 00h:11m:41.48s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0419s/iter; left time: 183.4743s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0148s/iter; left time: 63.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0352s/iter; left time: 146.4228s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0166s/iter; left time: 67.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0353s/iter; left time: 138.7091s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0162s/iter; left time: 62.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0346s/iter; left time: 128.2672s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0148s/iter; left time: 53.4397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0381s/iter; left time: 132.6051s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0174s/iter; left time: 59.0135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0378s/iter; left time: 123.2190s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0186s/iter; left time: 58.8762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0361s/iter; left time: 109.5462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0163s/iter; left time: 47.9565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0387s/iter; left time: 108.8325s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0185s/iter; left time: 50.2520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0392s/iter; left time: 101.5800s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0169s/iter; left time: 42.1018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0399s/iter; left time: 94.3928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0201s/iter; left time: 45.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0381s/iter; left time: 81.6356s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0199s/iter; left time: 40.5385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0363s/iter; left time: 69.6433s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0186s/iter; left time: 33.8804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0384s/iter; left time: 64.9685s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0194s/iter; left time: 30.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0343s/iter; left time: 50.3897s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0154s/iter; left time: 21.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0347s/iter; left time: 43.2111s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0147s/iter; left time: 16.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0371s/iter; left time: 37.8707s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0163s/iter; left time: 14.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0341s/iter; left time: 27.1531s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0148s/iter; left time: 10.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0370s/iter; left time: 21.1810s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0191s/iter; left time: 9.0471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0379s/iter; left time: 13.2122s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0153s/iter; left time: 3.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0368s/iter; left time: 4.5993s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0148s/iter; left time: 0.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026859937235713005, rmse:0.1638900190591812, mae:0.10591384768486023, rse:0.5653740763664246\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2846910\n",
      "\tspeed: 0.0209s/iter; left time: 91.7064s\n",
      "\titers: 200, epoch: 1 | loss: 0.2726133\n",
      "\tspeed: 0.0158s/iter; left time: 67.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.2926167 Vali Loss: 0.2415705 Test Loss: 0.2631590\n",
      "Validation loss decreased (inf --> 0.241570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474976\n",
      "\tspeed: 0.0376s/iter; left time: 156.3673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268219\n",
      "\tspeed: 0.0178s/iter; left time: 72.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.1575704 Vali Loss: 0.1085933 Test Loss: 0.1230968\n",
      "Validation loss decreased (0.241570 --> 0.108593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0972578\n",
      "\tspeed: 0.0377s/iter; left time: 148.1305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915387\n",
      "\tspeed: 0.0173s/iter; left time: 66.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1023461 Vali Loss: 0.1003349 Test Loss: 0.1123432\n",
      "Validation loss decreased (0.108593 --> 0.100335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907324\n",
      "\tspeed: 0.0397s/iter; left time: 147.2404s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907905\n",
      "\tspeed: 0.0198s/iter; left time: 71.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0922343 Vali Loss: 0.0962823 Test Loss: 0.1112334\n",
      "Validation loss decreased (0.100335 --> 0.096282).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833255\n",
      "\tspeed: 0.0375s/iter; left time: 130.5555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889493\n",
      "\tspeed: 0.0168s/iter; left time: 56.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0880692 Vali Loss: 0.0964027 Test Loss: 0.1125074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861537\n",
      "\tspeed: 0.0381s/iter; left time: 124.1791s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848577\n",
      "\tspeed: 0.0181s/iter; left time: 57.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0863465 Vali Loss: 0.0961963 Test Loss: 0.1143982\n",
      "Validation loss decreased (0.096282 --> 0.096196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867636\n",
      "\tspeed: 0.0359s/iter; left time: 109.0779s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810365\n",
      "\tspeed: 0.0148s/iter; left time: 43.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0849434 Vali Loss: 0.0958150 Test Loss: 0.1149141\n",
      "Validation loss decreased (0.096196 --> 0.095815).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857168\n",
      "\tspeed: 0.0385s/iter; left time: 108.4043s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765620\n",
      "\tspeed: 0.0205s/iter; left time: 55.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0839813 Vali Loss: 0.0954577 Test Loss: 0.1139534\n",
      "Validation loss decreased (0.095815 --> 0.095458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816585\n",
      "\tspeed: 0.0401s/iter; left time: 103.7107s\n",
      "\titers: 200, epoch: 9 | loss: 0.0860098\n",
      "\tspeed: 0.0172s/iter; left time: 42.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0829976 Vali Loss: 0.0949424 Test Loss: 0.1124260\n",
      "Validation loss decreased (0.095458 --> 0.094942).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758343\n",
      "\tspeed: 0.0376s/iter; left time: 88.9079s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839384\n",
      "\tspeed: 0.0171s/iter; left time: 38.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0826377 Vali Loss: 0.0951414 Test Loss: 0.1145257\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811790\n",
      "\tspeed: 0.0366s/iter; left time: 78.4086s\n",
      "\titers: 200, epoch: 11 | loss: 0.0772140\n",
      "\tspeed: 0.0169s/iter; left time: 34.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0818311 Vali Loss: 0.0955937 Test Loss: 0.1145437\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838942\n",
      "\tspeed: 0.0393s/iter; left time: 75.4245s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844036\n",
      "\tspeed: 0.0148s/iter; left time: 26.8373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0815183 Vali Loss: 0.0939972 Test Loss: 0.1111869\n",
      "Validation loss decreased (0.094942 --> 0.093997).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823378\n",
      "\tspeed: 0.0342s/iter; left time: 57.8470s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742934\n",
      "\tspeed: 0.0149s/iter; left time: 23.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0810441 Vali Loss: 0.0945207 Test Loss: 0.1117665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795040\n",
      "\tspeed: 0.0378s/iter; left time: 55.4870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800683\n",
      "\tspeed: 0.0192s/iter; left time: 26.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0807827 Vali Loss: 0.0942772 Test Loss: 0.1117615\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812870\n",
      "\tspeed: 0.0376s/iter; left time: 46.8602s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817963\n",
      "\tspeed: 0.0206s/iter; left time: 23.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0804734 Vali Loss: 0.0958008 Test Loss: 0.1114092\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0762049\n",
      "\tspeed: 0.0363s/iter; left time: 37.0384s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810765\n",
      "\tspeed: 0.0167s/iter; left time: 15.3521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0802297 Vali Loss: 0.0947608 Test Loss: 0.1110980\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810842\n",
      "\tspeed: 0.0392s/iter; left time: 31.2205s\n",
      "\titers: 200, epoch: 17 | loss: 0.0765186\n",
      "\tspeed: 0.0162s/iter; left time: 11.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0800327 Vali Loss: 0.0935502 Test Loss: 0.1104114\n",
      "Validation loss decreased (0.093997 --> 0.093550).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781353\n",
      "\tspeed: 0.0354s/iter; left time: 20.2928s\n",
      "\titers: 200, epoch: 18 | loss: 0.0784078\n",
      "\tspeed: 0.0172s/iter; left time: 8.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0798923 Vali Loss: 0.0934620 Test Loss: 0.1093775\n",
      "Validation loss decreased (0.093550 --> 0.093462).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748001\n",
      "\tspeed: 0.0402s/iter; left time: 14.0236s\n",
      "\titers: 200, epoch: 19 | loss: 0.0821338\n",
      "\tspeed: 0.0196s/iter; left time: 4.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0798001 Vali Loss: 0.0938784 Test Loss: 0.1097977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804354\n",
      "\tspeed: 0.0373s/iter; left time: 4.6662s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798344\n",
      "\tspeed: 0.0153s/iter; left time: 0.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0795825 Vali Loss: 0.0931064 Test Loss: 0.1094512\n",
      "Validation loss decreased (0.093462 --> 0.093106).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029882589355111122, rmse:0.17286580801010132, mae:0.10945114493370056, rse:0.5963380336761475\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:49.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0430s/iter; left time: 188.5474s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0150s/iter; left time: 64.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0355s/iter; left time: 147.5405s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0157s/iter; left time: 63.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0361s/iter; left time: 141.8351s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0168s/iter; left time: 64.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0356s/iter; left time: 131.9749s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0162s/iter; left time: 58.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0346s/iter; left time: 120.4759s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0150s/iter; left time: 50.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0396s/iter; left time: 129.0400s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0164s/iter; left time: 51.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0378s/iter; left time: 114.9110s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0188s/iter; left time: 55.3132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0366s/iter; left time: 102.8540s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0164s/iter; left time: 44.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0424s/iter; left time: 109.6519s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0175s/iter; left time: 43.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0371s/iter; left time: 87.7814s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0152s/iter; left time: 34.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0354s/iter; left time: 75.8158s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0167s/iter; left time: 34.0205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0380s/iter; left time: 72.9154s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0158s/iter; left time: 28.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0383s/iter; left time: 64.8504s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0217s/iter; left time: 34.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0408s/iter; left time: 59.9570s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0182s/iter; left time: 24.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0343s/iter; left time: 42.7084s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0177s/iter; left time: 20.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0369s/iter; left time: 37.7032s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0159s/iter; left time: 14.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2884372\n",
      "\tspeed: 0.0257s/iter; left time: 112.7879s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747863\n",
      "\tspeed: 0.0176s/iter; left time: 75.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.2938896 Vali Loss: 0.2499466 Test Loss: 0.2730130\n",
      "Validation loss decreased (inf --> 0.249947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520033\n",
      "\tspeed: 0.0413s/iter; left time: 171.8261s\n",
      "\titers: 200, epoch: 2 | loss: 0.1356943\n",
      "\tspeed: 0.0198s/iter; left time: 80.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1651964 Vali Loss: 0.1318234 Test Loss: 0.1534363\n",
      "Validation loss decreased (0.249947 --> 0.131823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1237962\n",
      "\tspeed: 0.0393s/iter; left time: 154.4481s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129839\n",
      "\tspeed: 0.0176s/iter; left time: 67.4369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1195505 Vali Loss: 0.1288494 Test Loss: 0.1563801\n",
      "Validation loss decreased (0.131823 --> 0.128849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1170108\n",
      "\tspeed: 0.0362s/iter; left time: 134.3832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1174021\n",
      "\tspeed: 0.0160s/iter; left time: 57.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1124832 Vali Loss: 0.1280748 Test Loss: 0.1573510\n",
      "Validation loss decreased (0.128849 --> 0.128075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121775\n",
      "\tspeed: 0.0409s/iter; left time: 142.4109s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137156\n",
      "\tspeed: 0.0202s/iter; left time: 68.3345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1097073 Vali Loss: 0.1282495 Test Loss: 0.1588879\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1099907\n",
      "\tspeed: 0.0351s/iter; left time: 114.5354s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046706\n",
      "\tspeed: 0.0149s/iter; left time: 47.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1083800 Vali Loss: 0.1289193 Test Loss: 0.1627320\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1065593\n",
      "\tspeed: 0.0388s/iter; left time: 117.9460s\n",
      "\titers: 200, epoch: 7 | loss: 0.1135744\n",
      "\tspeed: 0.0225s/iter; left time: 65.9947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.1073907 Vali Loss: 0.1286131 Test Loss: 0.1610762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1053690\n",
      "\tspeed: 0.0344s/iter; left time: 96.7885s\n",
      "\titers: 200, epoch: 8 | loss: 0.1122044\n",
      "\tspeed: 0.0149s/iter; left time: 40.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.1064029 Vali Loss: 0.1285266 Test Loss: 0.1602909\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083794\n",
      "\tspeed: 0.0362s/iter; left time: 93.6266s\n",
      "\titers: 200, epoch: 9 | loss: 0.1089216\n",
      "\tspeed: 0.0176s/iter; left time: 43.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1057083 Vali Loss: 0.1278156 Test Loss: 0.1567183\n",
      "Validation loss decreased (0.128075 --> 0.127816).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061578\n",
      "\tspeed: 0.0362s/iter; left time: 85.5576s\n",
      "\titers: 200, epoch: 10 | loss: 0.1020783\n",
      "\tspeed: 0.0179s/iter; left time: 40.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1050890 Vali Loss: 0.1274880 Test Loss: 0.1587726\n",
      "Validation loss decreased (0.127816 --> 0.127488).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040444\n",
      "\tspeed: 0.0411s/iter; left time: 88.0374s\n",
      "\titers: 200, epoch: 11 | loss: 0.1054638\n",
      "\tspeed: 0.0196s/iter; left time: 40.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1047036 Vali Loss: 0.1277202 Test Loss: 0.1562177\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1064437\n",
      "\tspeed: 0.0374s/iter; left time: 71.6716s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029790\n",
      "\tspeed: 0.0150s/iter; left time: 27.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.1041447 Vali Loss: 0.1276648 Test Loss: 0.1580956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009996\n",
      "\tspeed: 0.0430s/iter; left time: 72.7680s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043827\n",
      "\tspeed: 0.0228s/iter; left time: 36.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1039346 Vali Loss: 0.1263682 Test Loss: 0.1542069\n",
      "Validation loss decreased (0.127488 --> 0.126368).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028414\n",
      "\tspeed: 0.0491s/iter; left time: 72.1637s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043060\n",
      "\tspeed: 0.0241s/iter; left time: 33.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1265923 Test Loss: 0.1548574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1049191\n",
      "\tspeed: 0.0411s/iter; left time: 51.1296s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034089\n",
      "\tspeed: 0.0186s/iter; left time: 21.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1032026 Vali Loss: 0.1266271 Test Loss: 0.1559636\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0956138\n",
      "\tspeed: 0.0414s/iter; left time: 42.3062s\n",
      "\titers: 200, epoch: 16 | loss: 0.0995768\n",
      "\tspeed: 0.0222s/iter; left time: 20.4676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1030918 Vali Loss: 0.1263742 Test Loss: 0.1539116\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0985429\n",
      "\tspeed: 0.0391s/iter; left time: 31.1634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0990500\n",
      "\tspeed: 0.0182s/iter; left time: 12.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1027496 Vali Loss: 0.1258379 Test Loss: 0.1540648\n",
      "Validation loss decreased (0.126368 --> 0.125838).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1027168\n",
      "\tspeed: 0.0388s/iter; left time: 22.2377s\n",
      "\titers: 200, epoch: 18 | loss: 0.1045104\n",
      "\tspeed: 0.0192s/iter; left time: 9.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.1025700 Vali Loss: 0.1264045 Test Loss: 0.1539411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973583\n",
      "\tspeed: 0.0405s/iter; left time: 14.1415s\n",
      "\titers: 200, epoch: 19 | loss: 0.1044858\n",
      "\tspeed: 0.0192s/iter; left time: 4.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1024406 Vali Loss: 0.1257624 Test Loss: 0.1536622\n",
      "Validation loss decreased (0.125838 --> 0.125762).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1020775\n",
      "\tspeed: 0.0402s/iter; left time: 5.0212s\n",
      "\titers: 200, epoch: 20 | loss: 0.1067188\n",
      "\tspeed: 0.0163s/iter; left time: 0.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1022315 Vali Loss: 0.1262378 Test Loss: 0.1535022\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05444870516657829, rmse:0.2333424687385559, mae:0.15366211533546448, rse:0.8069307208061218\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:35.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0442s/iter; left time: 192.5491s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0153s/iter; left time: 65.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0370s/iter; left time: 153.2001s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0154s/iter; left time: 62.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0378s/iter; left time: 148.0475s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0152s/iter; left time: 58.0914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0346s/iter; left time: 127.7711s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0152s/iter; left time: 54.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0385s/iter; left time: 133.3915s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0186s/iter; left time: 62.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0392s/iter; left time: 127.3192s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0156s/iter; left time: 49.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0394s/iter; left time: 118.9614s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0202s/iter; left time: 59.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0436s/iter; left time: 122.0930s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0173s/iter; left time: 46.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0392s/iter; left time: 100.8971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0169s/iter; left time: 41.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0367s/iter; left time: 86.3427s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0173s/iter; left time: 39.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0354s/iter; left time: 75.4878s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0155s/iter; left time: 31.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0347s/iter; left time: 66.1984s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0152s/iter; left time: 27.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0398s/iter; left time: 67.0667s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0169s/iter; left time: 26.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2910986\n",
      "\tspeed: 0.0207s/iter; left time: 90.2693s\n",
      "\titers: 200, epoch: 1 | loss: 0.2834949\n",
      "\tspeed: 0.0178s/iter; left time: 75.9692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.2923341 Vali Loss: 0.2478191 Test Loss: 0.2692312\n",
      "Validation loss decreased (inf --> 0.247819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1509961\n",
      "\tspeed: 0.0398s/iter; left time: 164.7404s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339484\n",
      "\tspeed: 0.0171s/iter; left time: 69.1170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1644157 Vali Loss: 0.1374244 Test Loss: 0.1619911\n",
      "Validation loss decreased (0.247819 --> 0.137424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1268936\n",
      "\tspeed: 0.0435s/iter; left time: 170.3688s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223414\n",
      "\tspeed: 0.0211s/iter; left time: 80.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.1241407 Vali Loss: 0.1313642 Test Loss: 0.1588054\n",
      "Validation loss decreased (0.137424 --> 0.131364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162787\n",
      "\tspeed: 0.0455s/iter; left time: 168.1084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1151809\n",
      "\tspeed: 0.0193s/iter; left time: 69.1527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.1166980 Vali Loss: 0.1309440 Test Loss: 0.1621463\n",
      "Validation loss decreased (0.131364 --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1171696\n",
      "\tspeed: 0.0433s/iter; left time: 150.1149s\n",
      "\titers: 200, epoch: 5 | loss: 0.1122425\n",
      "\tspeed: 0.0214s/iter; left time: 72.0375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.1139985 Vali Loss: 0.1325590 Test Loss: 0.1652431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128479\n",
      "\tspeed: 0.0441s/iter; left time: 143.0990s\n",
      "\titers: 200, epoch: 6 | loss: 0.1111952\n",
      "\tspeed: 0.0197s/iter; left time: 61.9634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1127247 Vali Loss: 0.1303820 Test Loss: 0.1614654\n",
      "Validation loss decreased (0.130944 --> 0.130382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101843\n",
      "\tspeed: 0.0436s/iter; left time: 131.7685s\n",
      "\titers: 200, epoch: 7 | loss: 0.1144683\n",
      "\tspeed: 0.0198s/iter; left time: 57.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.1113464 Vali Loss: 0.1307575 Test Loss: 0.1610118\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114429\n",
      "\tspeed: 0.0429s/iter; left time: 120.2410s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068022\n",
      "\tspeed: 0.0199s/iter; left time: 53.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.1105503 Vali Loss: 0.1301013 Test Loss: 0.1594315\n",
      "Validation loss decreased (0.130382 --> 0.130101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1073766\n",
      "\tspeed: 0.0434s/iter; left time: 111.9315s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039732\n",
      "\tspeed: 0.0196s/iter; left time: 48.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1099073 Vali Loss: 0.1295959 Test Loss: 0.1585122\n",
      "Validation loss decreased (0.130101 --> 0.129596).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061911\n",
      "\tspeed: 0.0436s/iter; left time: 102.5790s\n",
      "\titers: 200, epoch: 10 | loss: 0.1109751\n",
      "\tspeed: 0.0200s/iter; left time: 45.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1095424 Vali Loss: 0.1308877 Test Loss: 0.1626594\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129102\n",
      "\tspeed: 0.0426s/iter; left time: 90.8034s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085048\n",
      "\tspeed: 0.0193s/iter; left time: 39.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1089675 Vali Loss: 0.1291195 Test Loss: 0.1578232\n",
      "Validation loss decreased (0.129596 --> 0.129120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1070272\n",
      "\tspeed: 0.0424s/iter; left time: 80.9687s\n",
      "\titers: 200, epoch: 12 | loss: 0.1068779\n",
      "\tspeed: 0.0213s/iter; left time: 38.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.1084242 Vali Loss: 0.1284974 Test Loss: 0.1579687\n",
      "Validation loss decreased (0.129120 --> 0.128497).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1096114\n",
      "\tspeed: 0.0445s/iter; left time: 75.0221s\n",
      "\titers: 200, epoch: 13 | loss: 0.1048709\n",
      "\tspeed: 0.0198s/iter; left time: 31.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1081906 Vali Loss: 0.1276691 Test Loss: 0.1578244\n",
      "Validation loss decreased (0.128497 --> 0.127669).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1105448\n",
      "\tspeed: 0.0429s/iter; left time: 62.7782s\n",
      "\titers: 200, epoch: 14 | loss: 0.1075893\n",
      "\tspeed: 0.0197s/iter; left time: 26.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1080442 Vali Loss: 0.1281609 Test Loss: 0.1572570\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1092115\n",
      "\tspeed: 0.0423s/iter; left time: 52.3640s\n",
      "\titers: 200, epoch: 15 | loss: 0.1053336\n",
      "\tspeed: 0.0202s/iter; left time: 23.0467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1076674 Vali Loss: 0.1286696 Test Loss: 0.1582996\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044834\n",
      "\tspeed: 0.0449s/iter; left time: 45.5981s\n",
      "\titers: 200, epoch: 16 | loss: 0.1047895\n",
      "\tspeed: 0.0248s/iter; left time: 22.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.1073679 Vali Loss: 0.1284060 Test Loss: 0.1590570\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1063645\n",
      "\tspeed: 0.0392s/iter; left time: 31.0738s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060797\n",
      "\tspeed: 0.0174s/iter; left time: 12.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1071399 Vali Loss: 0.1274910 Test Loss: 0.1575341\n",
      "Validation loss decreased (0.127669 --> 0.127491).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051314\n",
      "\tspeed: 0.0406s/iter; left time: 23.1175s\n",
      "\titers: 200, epoch: 18 | loss: 0.1067741\n",
      "\tspeed: 0.0200s/iter; left time: 9.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.1070178 Vali Loss: 0.1272823 Test Loss: 0.1581545\n",
      "Validation loss decreased (0.127491 --> 0.127282).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1085588\n",
      "\tspeed: 0.0424s/iter; left time: 14.7107s\n",
      "\titers: 200, epoch: 19 | loss: 0.1043933\n",
      "\tspeed: 0.0199s/iter; left time: 4.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1068289 Vali Loss: 0.1283977 Test Loss: 0.1593443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073587\n",
      "\tspeed: 0.0417s/iter; left time: 5.1744s\n",
      "\titers: 200, epoch: 20 | loss: 0.1076517\n",
      "\tspeed: 0.0201s/iter; left time: 0.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1066923 Vali Loss: 0.1281582 Test Loss: 0.1594106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05579496920108795, rmse:0.23620958626270294, mae:0.1581544131040573, rse:0.8189725875854492\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:29.51s\n",
      "Intermediate time for GB: 00h:10m:53.81s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0422s/iter; left time: 184.8017s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0158s/iter; left time: 67.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0335s/iter; left time: 139.1603s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0185s/iter; left time: 75.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0361s/iter; left time: 141.8640s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0200s/iter; left time: 76.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0405s/iter; left time: 150.3698s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0192s/iter; left time: 69.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0351s/iter; left time: 122.2895s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0179s/iter; left time: 60.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0390s/iter; left time: 127.1359s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0173s/iter; left time: 54.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0377s/iter; left time: 114.5358s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0195s/iter; left time: 57.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0392s/iter; left time: 110.2013s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0203s/iter; left time: 55.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0390s/iter; left time: 100.8476s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0208s/iter; left time: 51.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0381s/iter; left time: 90.1899s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0195s/iter; left time: 44.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0382s/iter; left time: 81.7295s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0202s/iter; left time: 41.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0377s/iter; left time: 72.3255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0202s/iter; left time: 36.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0410s/iter; left time: 69.4850s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0208s/iter; left time: 33.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0330s/iter; left time: 48.5477s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0171s/iter; left time: 23.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0413s/iter; left time: 51.4679s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0200s/iter; left time: 22.8844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0417s/iter; left time: 42.5280s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0242s/iter; left time: 22.2751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0385s/iter; left time: 30.6890s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0173s/iter; left time: 12.0500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0404s/iter; left time: 23.1778s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0219s/iter; left time: 10.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0373s/iter; left time: 13.0044s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0222s/iter; left time: 5.5359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0378s/iter; left time: 4.7191s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0176s/iter; left time: 0.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02119249477982521, rmse:0.14557641744613647, mae:0.08472280204296112, rse:0.4284138083457947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2933527\n",
      "\tspeed: 0.0201s/iter; left time: 88.0106s\n",
      "\titers: 200, epoch: 1 | loss: 0.2704865\n",
      "\tspeed: 0.0176s/iter; left time: 75.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.2947414 Vali Loss: 0.2184829 Test Loss: 0.2361712\n",
      "Validation loss decreased (inf --> 0.218483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535339\n",
      "\tspeed: 0.0396s/iter; left time: 164.6121s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133334\n",
      "\tspeed: 0.0183s/iter; left time: 74.2201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1637773 Vali Loss: 0.0885669 Test Loss: 0.0970050\n",
      "Validation loss decreased (0.218483 --> 0.088567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1018822\n",
      "\tspeed: 0.0377s/iter; left time: 148.4018s\n",
      "\titers: 200, epoch: 3 | loss: 0.0948918\n",
      "\tspeed: 0.0189s/iter; left time: 72.6322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1007216 Vali Loss: 0.0790505 Test Loss: 0.0879022\n",
      "Validation loss decreased (0.088567 --> 0.079051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878256\n",
      "\tspeed: 0.0400s/iter; left time: 148.1847s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835657\n",
      "\tspeed: 0.0182s/iter; left time: 65.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0883169 Vali Loss: 0.0730279 Test Loss: 0.0804366\n",
      "Validation loss decreased (0.079051 --> 0.073028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824891\n",
      "\tspeed: 0.0409s/iter; left time: 142.6297s\n",
      "\titers: 200, epoch: 5 | loss: 0.0751157\n",
      "\tspeed: 0.0219s/iter; left time: 74.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0807013 Vali Loss: 0.0705443 Test Loss: 0.0847321\n",
      "Validation loss decreased (0.073028 --> 0.070544).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0724511\n",
      "\tspeed: 0.0346s/iter; left time: 112.9735s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762253\n",
      "\tspeed: 0.0181s/iter; left time: 57.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0764399 Vali Loss: 0.0675259 Test Loss: 0.0945590\n",
      "Validation loss decreased (0.070544 --> 0.067526).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760236\n",
      "\tspeed: 0.0389s/iter; left time: 118.1804s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679494\n",
      "\tspeed: 0.0166s/iter; left time: 48.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0736369 Vali Loss: 0.0678774 Test Loss: 0.0992442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708459\n",
      "\tspeed: 0.0360s/iter; left time: 101.3354s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680928\n",
      "\tspeed: 0.0169s/iter; left time: 45.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0709821 Vali Loss: 0.0655568 Test Loss: 0.0969620\n",
      "Validation loss decreased (0.067526 --> 0.065557).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0714074\n",
      "\tspeed: 0.0317s/iter; left time: 82.1935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749444\n",
      "\tspeed: 0.0191s/iter; left time: 47.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0694430 Vali Loss: 0.0641238 Test Loss: 0.0946040\n",
      "Validation loss decreased (0.065557 --> 0.064124).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666802\n",
      "\tspeed: 0.0361s/iter; left time: 85.4878s\n",
      "\titers: 200, epoch: 10 | loss: 0.0671037\n",
      "\tspeed: 0.0209s/iter; left time: 47.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0686812 Vali Loss: 0.0635217 Test Loss: 0.0920826\n",
      "Validation loss decreased (0.064124 --> 0.063522).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657643\n",
      "\tspeed: 0.0382s/iter; left time: 81.7464s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640680\n",
      "\tspeed: 0.0183s/iter; left time: 37.3703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0677449 Vali Loss: 0.0631191 Test Loss: 0.0914283\n",
      "Validation loss decreased (0.063522 --> 0.063119).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628503\n",
      "\tspeed: 0.0347s/iter; left time: 66.5373s\n",
      "\titers: 200, epoch: 12 | loss: 0.0651587\n",
      "\tspeed: 0.0195s/iter; left time: 35.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0672804 Vali Loss: 0.0626110 Test Loss: 0.0832856\n",
      "Validation loss decreased (0.063119 --> 0.062611).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0623292\n",
      "\tspeed: 0.0368s/iter; left time: 62.3830s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658564\n",
      "\tspeed: 0.0175s/iter; left time: 27.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0664633 Vali Loss: 0.0621283 Test Loss: 0.0837443\n",
      "Validation loss decreased (0.062611 --> 0.062128).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687133\n",
      "\tspeed: 0.0369s/iter; left time: 54.2308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648790\n",
      "\tspeed: 0.0194s/iter; left time: 26.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0656932 Vali Loss: 0.0620166 Test Loss: 0.0845872\n",
      "Validation loss decreased (0.062128 --> 0.062017).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649449\n",
      "\tspeed: 0.0321s/iter; left time: 40.0241s\n",
      "\titers: 200, epoch: 15 | loss: 0.0653902\n",
      "\tspeed: 0.0100s/iter; left time: 11.4417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0656366 Vali Loss: 0.0617880 Test Loss: 0.0808425\n",
      "Validation loss decreased (0.062017 --> 0.061788).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618114\n",
      "\tspeed: 0.0325s/iter; left time: 33.1834s\n",
      "\titers: 200, epoch: 16 | loss: 0.0655272\n",
      "\tspeed: 0.0110s/iter; left time: 10.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0655247 Vali Loss: 0.0616549 Test Loss: 0.0858418\n",
      "Validation loss decreased (0.061788 --> 0.061655).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0677098\n",
      "\tspeed: 0.0362s/iter; left time: 28.8845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637103\n",
      "\tspeed: 0.0185s/iter; left time: 12.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0648700 Vali Loss: 0.0612696 Test Loss: 0.0789498\n",
      "Validation loss decreased (0.061655 --> 0.061270).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0684756\n",
      "\tspeed: 0.0392s/iter; left time: 22.4876s\n",
      "\titers: 200, epoch: 18 | loss: 0.0658208\n",
      "\tspeed: 0.0200s/iter; left time: 9.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0648673 Vali Loss: 0.0613987 Test Loss: 0.0799385\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0637714\n",
      "\tspeed: 0.0380s/iter; left time: 13.2577s\n",
      "\titers: 200, epoch: 19 | loss: 0.0642970\n",
      "\tspeed: 0.0197s/iter; left time: 4.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0642515 Vali Loss: 0.0606022 Test Loss: 0.0827977\n",
      "Validation loss decreased (0.061270 --> 0.060602).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0594665\n",
      "\tspeed: 0.0383s/iter; left time: 4.7878s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622201\n",
      "\tspeed: 0.0175s/iter; left time: 0.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0640075 Vali Loss: 0.0609228 Test Loss: 0.0824307\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019271206110715866, rmse:0.13882076740264893, mae:0.08279767632484436, rse:0.4085327386856079\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:55.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0426s/iter; left time: 186.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0117s/iter; left time: 50.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0315s/iter; left time: 130.9415s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0158s/iter; left time: 64.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0331s/iter; left time: 130.1391s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0164s/iter; left time: 62.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0348s/iter; left time: 129.2279s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0208s/iter; left time: 74.8950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0345s/iter; left time: 120.2348s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0161s/iter; left time: 54.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0322s/iter; left time: 105.0155s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0175s/iter; left time: 55.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0369s/iter; left time: 111.9894s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0225s/iter; left time: 66.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0382s/iter; left time: 107.5352s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0186s/iter; left time: 50.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0350s/iter; left time: 90.5386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0181s/iter; left time: 45.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0348s/iter; left time: 82.3695s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0163s/iter; left time: 36.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0336s/iter; left time: 71.8577s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0162s/iter; left time: 33.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0340s/iter; left time: 65.2305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0198s/iter; left time: 35.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0386s/iter; left time: 65.3967s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0205s/iter; left time: 32.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0369s/iter; left time: 54.2181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0193s/iter; left time: 26.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0376s/iter; left time: 46.8436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0196s/iter; left time: 22.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0416s/iter; left time: 42.4258s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0266s/iter; left time: 24.5067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0390s/iter; left time: 31.0719s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0220s/iter; left time: 15.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0357s/iter; left time: 20.4440s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0187s/iter; left time: 8.8381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0387s/iter; left time: 13.4946s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0196s/iter; left time: 4.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0372s/iter; left time: 4.6512s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0196s/iter; left time: 0.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.025789545848965645, rmse:0.1605912446975708, mae:0.10785099118947983, rse:0.47176873683929443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2952403\n",
      "\tspeed: 0.0204s/iter; left time: 89.3438s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667057\n",
      "\tspeed: 0.0197s/iter; left time: 84.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.2909098 Vali Loss: 0.2230923 Test Loss: 0.2409381\n",
      "Validation loss decreased (inf --> 0.223092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1491593\n",
      "\tspeed: 0.0407s/iter; left time: 169.1740s\n",
      "\titers: 200, epoch: 2 | loss: 0.1210495\n",
      "\tspeed: 0.0182s/iter; left time: 73.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1614247 Vali Loss: 0.1116909 Test Loss: 0.1254427\n",
      "Validation loss decreased (0.223092 --> 0.111691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085087\n",
      "\tspeed: 0.0364s/iter; left time: 143.0639s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104036\n",
      "\tspeed: 0.0211s/iter; left time: 80.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1113403 Vali Loss: 0.0953680 Test Loss: 0.1103432\n",
      "Validation loss decreased (0.111691 --> 0.095368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050000\n",
      "\tspeed: 0.0433s/iter; left time: 160.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.0989005\n",
      "\tspeed: 0.0230s/iter; left time: 82.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0994751 Vali Loss: 0.0900774 Test Loss: 0.1305989\n",
      "Validation loss decreased (0.095368 --> 0.090077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0924402\n",
      "\tspeed: 0.0336s/iter; left time: 117.1968s\n",
      "\titers: 200, epoch: 5 | loss: 0.0925185\n",
      "\tspeed: 0.0116s/iter; left time: 39.2989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 224 | Train Loss: 0.0936407 Vali Loss: 0.0879273 Test Loss: 0.1221537\n",
      "Validation loss decreased (0.090077 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856230\n",
      "\tspeed: 0.0355s/iter; left time: 115.6163s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879899\n",
      "\tspeed: 0.0186s/iter; left time: 58.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0899839 Vali Loss: 0.0851904 Test Loss: 0.1239189\n",
      "Validation loss decreased (0.087927 --> 0.085190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0908499\n",
      "\tspeed: 0.0381s/iter; left time: 115.6458s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900486\n",
      "\tspeed: 0.0194s/iter; left time: 57.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0885243 Vali Loss: 0.0836331 Test Loss: 0.1237736\n",
      "Validation loss decreased (0.085190 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901688\n",
      "\tspeed: 0.0370s/iter; left time: 103.9528s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838144\n",
      "\tspeed: 0.0184s/iter; left time: 49.8065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0868885 Vali Loss: 0.0829176 Test Loss: 0.1260237\n",
      "Validation loss decreased (0.083633 --> 0.082918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0871684\n",
      "\tspeed: 0.0417s/iter; left time: 107.8785s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863542\n",
      "\tspeed: 0.0234s/iter; left time: 58.2422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0857102 Vali Loss: 0.0822429 Test Loss: 0.1236874\n",
      "Validation loss decreased (0.082918 --> 0.082243).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849192\n",
      "\tspeed: 0.0439s/iter; left time: 103.7367s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846752\n",
      "\tspeed: 0.0235s/iter; left time: 53.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0818745 Test Loss: 0.1264992\n",
      "Validation loss decreased (0.082243 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810420\n",
      "\tspeed: 0.0397s/iter; left time: 85.0791s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817054\n",
      "\tspeed: 0.0217s/iter; left time: 44.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0842583 Vali Loss: 0.0812377 Test Loss: 0.1211978\n",
      "Validation loss decreased (0.081875 --> 0.081238).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0824383\n",
      "\tspeed: 0.0375s/iter; left time: 71.8570s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815587\n",
      "\tspeed: 0.0201s/iter; left time: 36.5041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0837523 Vali Loss: 0.0809542 Test Loss: 0.1222994\n",
      "Validation loss decreased (0.081238 --> 0.080954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0834732\n",
      "\tspeed: 0.0414s/iter; left time: 70.1688s\n",
      "\titers: 200, epoch: 13 | loss: 0.0828774\n",
      "\tspeed: 0.0206s/iter; left time: 32.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0834866 Vali Loss: 0.0810962 Test Loss: 0.1206864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810478\n",
      "\tspeed: 0.0336s/iter; left time: 49.2893s\n",
      "\titers: 200, epoch: 14 | loss: 0.0787730\n",
      "\tspeed: 0.0174s/iter; left time: 23.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0830654 Vali Loss: 0.0801408 Test Loss: 0.1198389\n",
      "Validation loss decreased (0.080954 --> 0.080141).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855980\n",
      "\tspeed: 0.0409s/iter; left time: 50.9005s\n",
      "\titers: 200, epoch: 15 | loss: 0.0813123\n",
      "\tspeed: 0.0192s/iter; left time: 21.9322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0829200 Vali Loss: 0.0803521 Test Loss: 0.1200523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831396\n",
      "\tspeed: 0.0366s/iter; left time: 37.3302s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829206\n",
      "\tspeed: 0.0177s/iter; left time: 16.3138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0823068 Vali Loss: 0.0803707 Test Loss: 0.1218092\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848512\n",
      "\tspeed: 0.0322s/iter; left time: 25.6703s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793137\n",
      "\tspeed: 0.0165s/iter; left time: 11.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0826998 Vali Loss: 0.0802649 Test Loss: 0.1115729\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797599\n",
      "\tspeed: 0.0372s/iter; left time: 21.3441s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824331\n",
      "\tspeed: 0.0194s/iter; left time: 9.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0821136 Vali Loss: 0.0795419 Test Loss: 0.1209204\n",
      "Validation loss decreased (0.080141 --> 0.079542).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788217\n",
      "\tspeed: 0.0364s/iter; left time: 12.6997s\n",
      "\titers: 200, epoch: 19 | loss: 0.0827929\n",
      "\tspeed: 0.0149s/iter; left time: 3.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0817846 Vali Loss: 0.0792163 Test Loss: 0.1182506\n",
      "Validation loss decreased (0.079542 --> 0.079216).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808366\n",
      "\tspeed: 0.0380s/iter; left time: 4.7487s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783563\n",
      "\tspeed: 0.0194s/iter; left time: 0.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0815249 Vali Loss: 0.0790933 Test Loss: 0.1166001\n",
      "Validation loss decreased (0.079216 --> 0.079093).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03416641056537628, rmse:0.184841588139534, mae:0.11660011857748032, rse:0.5430089235305786\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:54.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0410s/iter; left time: 178.9117s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0157s/iter; left time: 66.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0382s/iter; left time: 157.9376s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0184s/iter; left time: 74.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0340s/iter; left time: 132.9604s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0170s/iter; left time: 64.6968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0373s/iter; left time: 137.8699s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0160s/iter; left time: 57.6371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0350s/iter; left time: 121.4370s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0174s/iter; left time: 58.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0394s/iter; left time: 127.9286s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0207s/iter; left time: 64.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0440s/iter; left time: 133.1568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0246s/iter; left time: 71.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0403s/iter; left time: 112.9537s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0211s/iter; left time: 56.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0372s/iter; left time: 95.9795s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0178s/iter; left time: 44.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0357s/iter; left time: 84.0492s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0183s/iter; left time: 41.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0377s/iter; left time: 80.2770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0197s/iter; left time: 40.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0391s/iter; left time: 74.6690s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0171s/iter; left time: 30.8653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0366s/iter; left time: 61.7134s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0179s/iter; left time: 28.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0299s/iter; left time: 43.7162s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0104s/iter; left time: 14.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.67s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0354s/iter; left time: 43.8635s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0210s/iter; left time: 23.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0378s/iter; left time: 38.3619s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0167s/iter; left time: 15.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0360s/iter; left time: 28.5868s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0176s/iter; left time: 12.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0357s/iter; left time: 20.3579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0172s/iter; left time: 8.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0348s/iter; left time: 12.0901s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0175s/iter; left time: 4.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0364s/iter; left time: 4.5111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0176s/iter; left time: 0.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030968520790338516, rmse:0.17597874999046326, mae:0.11744298785924911, rse:0.5170097351074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2899029\n",
      "\tspeed: 0.0249s/iter; left time: 108.7958s\n",
      "\titers: 200, epoch: 1 | loss: 0.2712442\n",
      "\tspeed: 0.0174s/iter; left time: 74.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.2944018 Vali Loss: 0.2256723 Test Loss: 0.2452994\n",
      "Validation loss decreased (inf --> 0.225672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1439804\n",
      "\tspeed: 0.0413s/iter; left time: 170.9676s\n",
      "\titers: 200, epoch: 2 | loss: 0.1288482\n",
      "\tspeed: 0.0222s/iter; left time: 89.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1609331 Vali Loss: 0.1103104 Test Loss: 0.1237899\n",
      "Validation loss decreased (0.225672 --> 0.110310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161442\n",
      "\tspeed: 0.0414s/iter; left time: 161.9318s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086942\n",
      "\tspeed: 0.0186s/iter; left time: 71.1461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.1137597 Vali Loss: 0.0991577 Test Loss: 0.1132361\n",
      "Validation loss decreased (0.110310 --> 0.099158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016965\n",
      "\tspeed: 0.0401s/iter; left time: 147.8937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984646\n",
      "\tspeed: 0.0165s/iter; left time: 59.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.1016837 Vali Loss: 0.0949189 Test Loss: 0.1138231\n",
      "Validation loss decreased (0.099158 --> 0.094919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0982926\n",
      "\tspeed: 0.0378s/iter; left time: 130.9636s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952768\n",
      "\tspeed: 0.0166s/iter; left time: 55.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0965111 Vali Loss: 0.0906598 Test Loss: 0.1149046\n",
      "Validation loss decreased (0.094919 --> 0.090660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932750\n",
      "\tspeed: 0.0366s/iter; left time: 118.7121s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899443\n",
      "\tspeed: 0.0177s/iter; left time: 55.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0935987 Vali Loss: 0.0898600 Test Loss: 0.1154023\n",
      "Validation loss decreased (0.090660 --> 0.089860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968993\n",
      "\tspeed: 0.0359s/iter; left time: 108.4098s\n",
      "\titers: 200, epoch: 7 | loss: 0.0916797\n",
      "\tspeed: 0.0165s/iter; left time: 48.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0919076 Vali Loss: 0.0879064 Test Loss: 0.1174295\n",
      "Validation loss decreased (0.089860 --> 0.087906).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0910260\n",
      "\tspeed: 0.0415s/iter; left time: 116.2290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891242\n",
      "\tspeed: 0.0208s/iter; left time: 56.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0904661 Vali Loss: 0.0868890 Test Loss: 0.1170246\n",
      "Validation loss decreased (0.087906 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919234\n",
      "\tspeed: 0.0399s/iter; left time: 102.8704s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911078\n",
      "\tspeed: 0.0175s/iter; left time: 43.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0899424 Vali Loss: 0.0871161 Test Loss: 0.1129427\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0876352\n",
      "\tspeed: 0.0397s/iter; left time: 93.3437s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899070\n",
      "\tspeed: 0.0201s/iter; left time: 45.3156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0887751 Vali Loss: 0.0863786 Test Loss: 0.1157439\n",
      "Validation loss decreased (0.086889 --> 0.086379).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0875310\n",
      "\tspeed: 0.0397s/iter; left time: 84.6886s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865170\n",
      "\tspeed: 0.0171s/iter; left time: 34.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0889828 Vali Loss: 0.0859895 Test Loss: 0.1167143\n",
      "Validation loss decreased (0.086379 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0884266\n",
      "\tspeed: 0.0365s/iter; left time: 69.5674s\n",
      "\titers: 200, epoch: 12 | loss: 0.0868132\n",
      "\tspeed: 0.0179s/iter; left time: 32.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0875570 Vali Loss: 0.0859610 Test Loss: 0.1155201\n",
      "Validation loss decreased (0.085990 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886559\n",
      "\tspeed: 0.0377s/iter; left time: 63.4989s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892455\n",
      "\tspeed: 0.0181s/iter; left time: 28.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0871522 Vali Loss: 0.0859056 Test Loss: 0.1138303\n",
      "Validation loss decreased (0.085961 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848424\n",
      "\tspeed: 0.0408s/iter; left time: 59.6106s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878144\n",
      "\tspeed: 0.0227s/iter; left time: 30.9062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0867811 Vali Loss: 0.0854875 Test Loss: 0.1154874\n",
      "Validation loss decreased (0.085906 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901568\n",
      "\tspeed: 0.0367s/iter; left time: 45.4521s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834248\n",
      "\tspeed: 0.0103s/iter; left time: 11.7835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0863447 Vali Loss: 0.0854952 Test Loss: 0.1136132\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865058\n",
      "\tspeed: 0.0353s/iter; left time: 35.8833s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858239\n",
      "\tspeed: 0.0176s/iter; left time: 16.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0863616 Vali Loss: 0.0848712 Test Loss: 0.1134736\n",
      "Validation loss decreased (0.085487 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821277\n",
      "\tspeed: 0.0383s/iter; left time: 30.4074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0873138\n",
      "\tspeed: 0.0192s/iter; left time: 13.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0860255 Vali Loss: 0.0847610 Test Loss: 0.1142043\n",
      "Validation loss decreased (0.084871 --> 0.084761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0891386\n",
      "\tspeed: 0.0416s/iter; left time: 23.7205s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899599\n",
      "\tspeed: 0.0191s/iter; left time: 8.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0863818 Vali Loss: 0.0850193 Test Loss: 0.1143596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0856005\n",
      "\tspeed: 0.0369s/iter; left time: 12.7890s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866439\n",
      "\tspeed: 0.0116s/iter; left time: 2.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 223 | Train Loss: 0.0857154 Vali Loss: 0.0848255 Test Loss: 0.1150333\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0883029\n",
      "\tspeed: 0.0343s/iter; left time: 4.2569s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826626\n",
      "\tspeed: 0.0173s/iter; left time: 0.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0856279 Vali Loss: 0.0850217 Test Loss: 0.1158830\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.027704495936632156, rmse:0.16644667088985443, mae:0.1142042800784111, rse:0.4890053868293762\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:54.05s\n",
      "Intermediate time for ES: 00h:11m:44.16s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0389s/iter; left time: 170.4436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0116s/iter; left time: 49.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0287s/iter; left time: 119.3798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0168s/iter; left time: 68.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0348s/iter; left time: 136.7070s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0099s/iter; left time: 37.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0347s/iter; left time: 128.8116s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0210s/iter; left time: 75.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0352s/iter; left time: 122.5149s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0188s/iter; left time: 63.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0386s/iter; left time: 125.9538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0218s/iter; left time: 68.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0378s/iter; left time: 114.8126s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0250s/iter; left time: 73.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0399s/iter; left time: 112.1210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0186s/iter; left time: 50.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0373s/iter; left time: 96.5012s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0200s/iter; left time: 49.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0376s/iter; left time: 88.9604s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0183s/iter; left time: 41.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0363s/iter; left time: 77.7717s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0195s/iter; left time: 39.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0355s/iter; left time: 68.0528s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0184s/iter; left time: 33.4564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0365s/iter; left time: 61.8709s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0194s/iter; left time: 30.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0365s/iter; left time: 53.6102s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0181s/iter; left time: 24.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0357s/iter; left time: 44.3906s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0185s/iter; left time: 21.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0351s/iter; left time: 35.7986s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0193s/iter; left time: 17.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0383s/iter; left time: 30.5273s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0206s/iter; left time: 14.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0397s/iter; left time: 22.7324s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0221s/iter; left time: 10.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0343s/iter; left time: 11.9555s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0174s/iter; left time: 4.3348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0324s/iter; left time: 4.0507s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0098s/iter; left time: 0.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011178242973983288, rmse:0.10572721064090729, mae:0.061787281185388565, rse:0.407892644405365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2411680\n",
      "\tspeed: 0.0231s/iter; left time: 101.0096s\n",
      "\titers: 200, epoch: 1 | loss: 0.2160659\n",
      "\tspeed: 0.0208s/iter; left time: 89.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.2408922 Vali Loss: 0.1782567 Test Loss: 0.1854041\n",
      "Validation loss decreased (inf --> 0.178257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1385794\n",
      "\tspeed: 0.0388s/iter; left time: 161.4071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1014387\n",
      "\tspeed: 0.0189s/iter; left time: 76.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.1401546 Vali Loss: 0.0844240 Test Loss: 0.0928136\n",
      "Validation loss decreased (0.178257 --> 0.084424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963864\n",
      "\tspeed: 0.0276s/iter; left time: 108.7015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779932\n",
      "\tspeed: 0.0098s/iter; left time: 37.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0851412 Vali Loss: 0.0759695 Test Loss: 0.0796487\n",
      "Validation loss decreased (0.084424 --> 0.075970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728357\n",
      "\tspeed: 0.0318s/iter; left time: 117.8008s\n",
      "\titers: 200, epoch: 4 | loss: 0.0701583\n",
      "\tspeed: 0.0099s/iter; left time: 35.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0739212 Vali Loss: 0.0693061 Test Loss: 0.0711936\n",
      "Validation loss decreased (0.075970 --> 0.069306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649703\n",
      "\tspeed: 0.0315s/iter; left time: 109.8802s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600224\n",
      "\tspeed: 0.0172s/iter; left time: 58.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0674395 Vali Loss: 0.0658167 Test Loss: 0.0676115\n",
      "Validation loss decreased (0.069306 --> 0.065817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614809\n",
      "\tspeed: 0.0391s/iter; left time: 127.4692s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617771\n",
      "\tspeed: 0.0201s/iter; left time: 63.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0634119 Vali Loss: 0.0674359 Test Loss: 0.0694659\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605860\n",
      "\tspeed: 0.0372s/iter; left time: 112.8544s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626515\n",
      "\tspeed: 0.0190s/iter; left time: 55.8961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0611253 Vali Loss: 0.0648416 Test Loss: 0.0675831\n",
      "Validation loss decreased (0.065817 --> 0.064842).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599528\n",
      "\tspeed: 0.0367s/iter; left time: 103.1266s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610243\n",
      "\tspeed: 0.0187s/iter; left time: 50.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0588911 Vali Loss: 0.0627734 Test Loss: 0.0656899\n",
      "Validation loss decreased (0.064842 --> 0.062773).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547889\n",
      "\tspeed: 0.0377s/iter; left time: 97.7277s\n",
      "\titers: 200, epoch: 9 | loss: 0.0561625\n",
      "\tspeed: 0.0176s/iter; left time: 43.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0571481 Vali Loss: 0.0612765 Test Loss: 0.0641911\n",
      "Validation loss decreased (0.062773 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564083\n",
      "\tspeed: 0.0388s/iter; left time: 91.7436s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529456\n",
      "\tspeed: 0.0190s/iter; left time: 42.9244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560195 Vali Loss: 0.0609586 Test Loss: 0.0637936\n",
      "Validation loss decreased (0.061277 --> 0.060959).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541631\n",
      "\tspeed: 0.0376s/iter; left time: 80.5173s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595317\n",
      "\tspeed: 0.0177s/iter; left time: 36.2117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0548145 Vali Loss: 0.0604594 Test Loss: 0.0633140\n",
      "Validation loss decreased (0.060959 --> 0.060459).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0551679\n",
      "\tspeed: 0.0384s/iter; left time: 73.6917s\n",
      "\titers: 200, epoch: 12 | loss: 0.0506632\n",
      "\tspeed: 0.0218s/iter; left time: 39.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0540808 Vali Loss: 0.0599905 Test Loss: 0.0628521\n",
      "Validation loss decreased (0.060459 --> 0.059990).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570984\n",
      "\tspeed: 0.0382s/iter; left time: 64.7350s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494264\n",
      "\tspeed: 0.0205s/iter; left time: 32.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0539780 Vali Loss: 0.0598418 Test Loss: 0.0626836\n",
      "Validation loss decreased (0.059990 --> 0.059842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523727\n",
      "\tspeed: 0.0366s/iter; left time: 53.7406s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538516\n",
      "\tspeed: 0.0218s/iter; left time: 29.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0532672 Vali Loss: 0.0598634 Test Loss: 0.0626787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0509895\n",
      "\tspeed: 0.0371s/iter; left time: 46.1446s\n",
      "\titers: 200, epoch: 15 | loss: 0.0479047\n",
      "\tspeed: 0.0197s/iter; left time: 22.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0528779 Vali Loss: 0.0594473 Test Loss: 0.0624075\n",
      "Validation loss decreased (0.059842 --> 0.059447).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509207\n",
      "\tspeed: 0.0341s/iter; left time: 34.7843s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511976\n",
      "\tspeed: 0.0166s/iter; left time: 15.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0526040 Vali Loss: 0.0597805 Test Loss: 0.0625402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0506773\n",
      "\tspeed: 0.0397s/iter; left time: 31.6155s\n",
      "\titers: 200, epoch: 17 | loss: 0.0510104\n",
      "\tspeed: 0.0220s/iter; left time: 15.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0523335 Vali Loss: 0.0592356 Test Loss: 0.0620888\n",
      "Validation loss decreased (0.059447 --> 0.059236).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547306\n",
      "\tspeed: 0.0402s/iter; left time: 23.0326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0486531\n",
      "\tspeed: 0.0195s/iter; left time: 9.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0520337 Vali Loss: 0.0590360 Test Loss: 0.0619049\n",
      "Validation loss decreased (0.059236 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0527190\n",
      "\tspeed: 0.0379s/iter; left time: 13.2286s\n",
      "\titers: 200, epoch: 19 | loss: 0.0546635\n",
      "\tspeed: 0.0202s/iter; left time: 5.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0518412 Vali Loss: 0.0589188 Test Loss: 0.0616275\n",
      "Validation loss decreased (0.059036 --> 0.058919).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517122\n",
      "\tspeed: 0.0396s/iter; left time: 4.9538s\n",
      "\titers: 200, epoch: 20 | loss: 0.0467894\n",
      "\tspeed: 0.0208s/iter; left time: 0.5201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0516144 Vali Loss: 0.0589262 Test Loss: 0.0616789\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011188277043402195, rmse:0.1057746484875679, mae:0.061627473682165146, rse:0.4080756902694702\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:49.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0410s/iter; left time: 179.6207s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0122s/iter; left time: 52.3355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0349s/iter; left time: 145.2442s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0204s/iter; left time: 82.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0371s/iter; left time: 146.0923s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0178s/iter; left time: 68.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0358s/iter; left time: 132.7641s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0199s/iter; left time: 71.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0352s/iter; left time: 122.6290s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0161s/iter; left time: 54.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0349s/iter; left time: 113.8091s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0185s/iter; left time: 58.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0346s/iter; left time: 105.0947s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0180s/iter; left time: 52.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0350s/iter; left time: 98.4671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0164s/iter; left time: 44.3949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0405s/iter; left time: 104.7296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0176s/iter; left time: 43.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0345s/iter; left time: 81.6614s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0174s/iter; left time: 39.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0329s/iter; left time: 70.3369s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0102s/iter; left time: 20.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0332s/iter; left time: 63.6045s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0193s/iter; left time: 35.0804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0351s/iter; left time: 59.4527s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0169s/iter; left time: 26.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0378s/iter; left time: 55.4564s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0201s/iter; left time: 27.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0410s/iter; left time: 51.0554s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0195s/iter; left time: 22.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0353s/iter; left time: 36.0684s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0235s/iter; left time: 21.6031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0399s/iter; left time: 31.7845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0204s/iter; left time: 14.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0360s/iter; left time: 20.6153s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0179s/iter; left time: 8.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0430s/iter; left time: 15.0056s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0199s/iter; left time: 4.9488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0373s/iter; left time: 4.6565s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0203s/iter; left time: 0.5073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020759424194693565, rmse:0.14408130943775177, mae:0.08491359651088715, rse:0.5573447942733765\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2406403\n",
      "\tspeed: 0.0261s/iter; left time: 114.3824s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188262\n",
      "\tspeed: 0.0192s/iter; left time: 82.0616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.2381317 Vali Loss: 0.1789258 Test Loss: 0.1865743\n",
      "Validation loss decreased (inf --> 0.178926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1343914\n",
      "\tspeed: 0.0354s/iter; left time: 147.0162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930818\n",
      "\tspeed: 0.0172s/iter; left time: 69.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1332448 Vali Loss: 0.0972317 Test Loss: 0.1086327\n",
      "Validation loss decreased (0.178926 --> 0.097232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907119\n",
      "\tspeed: 0.0404s/iter; left time: 158.7603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0898331\n",
      "\tspeed: 0.0206s/iter; left time: 78.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0904112 Vali Loss: 0.0884094 Test Loss: 0.0957489\n",
      "Validation loss decreased (0.097232 --> 0.088409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0800296\n",
      "\tspeed: 0.0357s/iter; left time: 132.4830s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827712\n",
      "\tspeed: 0.0174s/iter; left time: 62.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0818481 Vali Loss: 0.0822035 Test Loss: 0.0922612\n",
      "Validation loss decreased (0.088409 --> 0.082203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791426\n",
      "\tspeed: 0.0391s/iter; left time: 136.2516s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790642\n",
      "\tspeed: 0.0194s/iter; left time: 65.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0770117 Vali Loss: 0.0795626 Test Loss: 0.0895083\n",
      "Validation loss decreased (0.082203 --> 0.079563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730632\n",
      "\tspeed: 0.0389s/iter; left time: 126.9005s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708637\n",
      "\tspeed: 0.0182s/iter; left time: 57.5080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0741224 Vali Loss: 0.0787785 Test Loss: 0.0881438\n",
      "Validation loss decreased (0.079563 --> 0.078779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0686050\n",
      "\tspeed: 0.0353s/iter; left time: 107.2848s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743980\n",
      "\tspeed: 0.0183s/iter; left time: 53.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0715071 Vali Loss: 0.0792559 Test Loss: 0.0889636\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750379\n",
      "\tspeed: 0.0407s/iter; left time: 114.6261s\n",
      "\titers: 200, epoch: 8 | loss: 0.0685743\n",
      "\tspeed: 0.0217s/iter; left time: 59.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0700779 Vali Loss: 0.0787402 Test Loss: 0.0882414\n",
      "Validation loss decreased (0.078779 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686822\n",
      "\tspeed: 0.0406s/iter; left time: 105.1337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684529\n",
      "\tspeed: 0.0179s/iter; left time: 44.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0689258 Vali Loss: 0.0775224 Test Loss: 0.0869969\n",
      "Validation loss decreased (0.078740 --> 0.077522).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689297\n",
      "\tspeed: 0.0359s/iter; left time: 84.9816s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664442\n",
      "\tspeed: 0.0185s/iter; left time: 41.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0681905 Vali Loss: 0.0769314 Test Loss: 0.0865170\n",
      "Validation loss decreased (0.077522 --> 0.076931).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694460\n",
      "\tspeed: 0.0399s/iter; left time: 85.4460s\n",
      "\titers: 200, epoch: 11 | loss: 0.0733899\n",
      "\tspeed: 0.0225s/iter; left time: 45.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0677455 Vali Loss: 0.0769557 Test Loss: 0.0862589\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652838\n",
      "\tspeed: 0.0410s/iter; left time: 78.6166s\n",
      "\titers: 200, epoch: 12 | loss: 0.0629617\n",
      "\tspeed: 0.0188s/iter; left time: 34.1104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0668834 Vali Loss: 0.0763795 Test Loss: 0.0861417\n",
      "Validation loss decreased (0.076931 --> 0.076379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643209\n",
      "\tspeed: 0.0386s/iter; left time: 65.3416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618452\n",
      "\tspeed: 0.0179s/iter; left time: 28.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0667896 Vali Loss: 0.0762287 Test Loss: 0.0860246\n",
      "Validation loss decreased (0.076379 --> 0.076229).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677970\n",
      "\tspeed: 0.0340s/iter; left time: 49.8776s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648690\n",
      "\tspeed: 0.0172s/iter; left time: 23.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0661625 Vali Loss: 0.0762512 Test Loss: 0.0858173\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696925\n",
      "\tspeed: 0.0385s/iter; left time: 47.9934s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697655\n",
      "\tspeed: 0.0189s/iter; left time: 21.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0660004 Vali Loss: 0.0760939 Test Loss: 0.0859716\n",
      "Validation loss decreased (0.076229 --> 0.076094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652443\n",
      "\tspeed: 0.0425s/iter; left time: 43.3530s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687751\n",
      "\tspeed: 0.0215s/iter; left time: 19.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0656887 Vali Loss: 0.0760748 Test Loss: 0.0856839\n",
      "Validation loss decreased (0.076094 --> 0.076075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659079\n",
      "\tspeed: 0.0403s/iter; left time: 32.1177s\n",
      "\titers: 200, epoch: 17 | loss: 0.0638563\n",
      "\tspeed: 0.0174s/iter; left time: 12.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0653609 Vali Loss: 0.0753801 Test Loss: 0.0850498\n",
      "Validation loss decreased (0.076075 --> 0.075380).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578677\n",
      "\tspeed: 0.0371s/iter; left time: 21.2815s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645344\n",
      "\tspeed: 0.0102s/iter; left time: 4.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 224 | Train Loss: 0.0651030 Vali Loss: 0.0752875 Test Loss: 0.0849164\n",
      "Validation loss decreased (0.075380 --> 0.075287).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679285\n",
      "\tspeed: 0.0343s/iter; left time: 11.9599s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629789\n",
      "\tspeed: 0.0221s/iter; left time: 5.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0649769 Vali Loss: 0.0752234 Test Loss: 0.0850461\n",
      "Validation loss decreased (0.075287 --> 0.075223).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0604777\n",
      "\tspeed: 0.0382s/iter; left time: 4.7696s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633929\n",
      "\tspeed: 0.0157s/iter; left time: 0.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0648052 Vali Loss: 0.0750941 Test Loss: 0.0847241\n",
      "Validation loss decreased (0.075223 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020768484100699425, rmse:0.1441127508878708, mae:0.08472401648759842, rse:0.557466447353363\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:54.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0424s/iter; left time: 185.1014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0161s/iter; left time: 68.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0345s/iter; left time: 142.9481s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0159s/iter; left time: 64.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0314s/iter; left time: 122.9024s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0215s/iter; left time: 81.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0343s/iter; left time: 126.7948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0168s/iter; left time: 60.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0333s/iter; left time: 115.5416s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0168s/iter; left time: 56.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0362s/iter; left time: 117.5717s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0195s/iter; left time: 61.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0405s/iter; left time: 122.3795s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0175s/iter; left time: 51.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0423s/iter; left time: 118.4797s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0248s/iter; left time: 66.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0415s/iter; left time: 106.9128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0199s/iter; left time: 49.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0385s/iter; left time: 90.7046s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0181s/iter; left time: 40.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0381s/iter; left time: 81.1390s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0189s/iter; left time: 38.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0376s/iter; left time: 71.7758s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0184s/iter; left time: 33.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0389s/iter; left time: 65.5683s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0189s/iter; left time: 29.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0390s/iter; left time: 56.9609s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0184s/iter; left time: 25.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0351s/iter; left time: 43.4834s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0173s/iter; left time: 19.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0391s/iter; left time: 39.7621s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0199s/iter; left time: 18.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0367s/iter; left time: 29.1359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0231s/iter; left time: 15.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0392s/iter; left time: 22.3489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0185s/iter; left time: 8.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0383s/iter; left time: 13.2733s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0223s/iter; left time: 5.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0398s/iter; left time: 4.9350s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0194s/iter; left time: 0.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023141568526625633, rmse:0.15212352573871613, mae:0.09033302962779999, rse:0.5891888737678528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2403809\n",
      "\tspeed: 0.0255s/iter; left time: 111.3851s\n",
      "\titers: 200, epoch: 1 | loss: 0.2154531\n",
      "\tspeed: 0.0215s/iter; left time: 91.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.2422614 Vali Loss: 0.1823216 Test Loss: 0.1888932\n",
      "Validation loss decreased (inf --> 0.182322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229391\n",
      "\tspeed: 0.0388s/iter; left time: 160.6539s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984408\n",
      "\tspeed: 0.0188s/iter; left time: 75.9883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1311886 Vali Loss: 0.1001970 Test Loss: 0.1099112\n",
      "Validation loss decreased (0.182322 --> 0.100197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898930\n",
      "\tspeed: 0.0407s/iter; left time: 159.3684s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917291\n",
      "\tspeed: 0.0199s/iter; left time: 75.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0914624 Vali Loss: 0.0890297 Test Loss: 0.0978792\n",
      "Validation loss decreased (0.100197 --> 0.089030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854143\n",
      "\tspeed: 0.0384s/iter; left time: 141.8712s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808555\n",
      "\tspeed: 0.0188s/iter; left time: 67.4431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0837825 Vali Loss: 0.0859060 Test Loss: 0.0959388\n",
      "Validation loss decreased (0.089030 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808391\n",
      "\tspeed: 0.0388s/iter; left time: 134.4523s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785895\n",
      "\tspeed: 0.0192s/iter; left time: 64.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0792879 Vali Loss: 0.0840676 Test Loss: 0.0946624\n",
      "Validation loss decreased (0.085906 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755854\n",
      "\tspeed: 0.0411s/iter; left time: 133.3556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746735\n",
      "\tspeed: 0.0205s/iter; left time: 64.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0765742 Vali Loss: 0.0853610 Test Loss: 0.0968855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792653\n",
      "\tspeed: 0.0427s/iter; left time: 129.0631s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721418\n",
      "\tspeed: 0.0195s/iter; left time: 56.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0743388 Vali Loss: 0.0818612 Test Loss: 0.0936658\n",
      "Validation loss decreased (0.084068 --> 0.081861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736356\n",
      "\tspeed: 0.0411s/iter; left time: 115.1988s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732522\n",
      "\tspeed: 0.0192s/iter; left time: 51.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0730863 Vali Loss: 0.0821424 Test Loss: 0.0942828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0689212\n",
      "\tspeed: 0.0362s/iter; left time: 93.2388s\n",
      "\titers: 200, epoch: 9 | loss: 0.0701418\n",
      "\tspeed: 0.0175s/iter; left time: 43.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0719471 Vali Loss: 0.0811452 Test Loss: 0.0941387\n",
      "Validation loss decreased (0.081861 --> 0.081145).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0695085\n",
      "\tspeed: 0.0408s/iter; left time: 96.1526s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699557\n",
      "\tspeed: 0.0206s/iter; left time: 46.4315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0711944 Vali Loss: 0.0805143 Test Loss: 0.0936558\n",
      "Validation loss decreased (0.081145 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0710805\n",
      "\tspeed: 0.0393s/iter; left time: 83.6774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656972\n",
      "\tspeed: 0.0176s/iter; left time: 35.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0703731 Vali Loss: 0.0806881 Test Loss: 0.0943752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712831\n",
      "\tspeed: 0.0375s/iter; left time: 71.5739s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711581\n",
      "\tspeed: 0.0193s/iter; left time: 34.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0701223 Vali Loss: 0.0796910 Test Loss: 0.0930109\n",
      "Validation loss decreased (0.080514 --> 0.079691).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698889\n",
      "\tspeed: 0.0392s/iter; left time: 66.1020s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705252\n",
      "\tspeed: 0.0203s/iter; left time: 32.2102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0696029 Vali Loss: 0.0801107 Test Loss: 0.0943232\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0708620\n",
      "\tspeed: 0.0395s/iter; left time: 57.6966s\n",
      "\titers: 200, epoch: 14 | loss: 0.0683931\n",
      "\tspeed: 0.0164s/iter; left time: 22.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0692059 Vali Loss: 0.0794433 Test Loss: 0.0930229\n",
      "Validation loss decreased (0.079691 --> 0.079443).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0689742\n",
      "\tspeed: 0.0378s/iter; left time: 46.8950s\n",
      "\titers: 200, epoch: 15 | loss: 0.0665230\n",
      "\tspeed: 0.0189s/iter; left time: 21.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0690320 Vali Loss: 0.0792129 Test Loss: 0.0928772\n",
      "Validation loss decreased (0.079443 --> 0.079213).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715083\n",
      "\tspeed: 0.0398s/iter; left time: 40.4851s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682462\n",
      "\tspeed: 0.0203s/iter; left time: 18.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0687173 Vali Loss: 0.0790982 Test Loss: 0.0926940\n",
      "Validation loss decreased (0.079213 --> 0.079098).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676954\n",
      "\tspeed: 0.0366s/iter; left time: 29.0513s\n",
      "\titers: 200, epoch: 17 | loss: 0.0672674\n",
      "\tspeed: 0.0183s/iter; left time: 12.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0685975 Vali Loss: 0.0791815 Test Loss: 0.0935558\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662949\n",
      "\tspeed: 0.0385s/iter; left time: 21.9437s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675989\n",
      "\tspeed: 0.0205s/iter; left time: 9.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0684725 Vali Loss: 0.0790181 Test Loss: 0.0932168\n",
      "Validation loss decreased (0.079098 --> 0.079018).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0674201\n",
      "\tspeed: 0.0386s/iter; left time: 13.3882s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678428\n",
      "\tspeed: 0.0189s/iter; left time: 4.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0681966 Vali Loss: 0.0788749 Test Loss: 0.0930523\n",
      "Validation loss decreased (0.079018 --> 0.078875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678935\n",
      "\tspeed: 0.0381s/iter; left time: 4.7190s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656016\n",
      "\tspeed: 0.0175s/iter; left time: 0.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0679420 Vali Loss: 0.0789774 Test Loss: 0.0931080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.025284940376877785, rmse:0.15901239216327667, mae:0.09305231273174286, rse:0.6158700585365295\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:01.99s\n",
      "Intermediate time for FR: 00h:11m:46.03s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0410s/iter; left time: 179.5759s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0158s/iter; left time: 67.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0326s/iter; left time: 135.5249s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0198s/iter; left time: 80.3800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0353s/iter; left time: 138.8371s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0163s/iter; left time: 62.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0325s/iter; left time: 120.5544s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0163s/iter; left time: 58.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0371s/iter; left time: 129.1770s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0208s/iter; left time: 70.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0356s/iter; left time: 115.9873s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0186s/iter; left time: 58.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0395s/iter; left time: 119.8119s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0181s/iter; left time: 53.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0387s/iter; left time: 108.7624s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0199s/iter; left time: 53.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0389s/iter; left time: 100.7789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0198s/iter; left time: 49.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0378s/iter; left time: 89.3845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0200s/iter; left time: 45.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0414s/iter; left time: 88.6775s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0178s/iter; left time: 36.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0416s/iter; left time: 79.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0169s/iter; left time: 30.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0325s/iter; left time: 55.0636s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0118s/iter; left time: 18.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0360s/iter; left time: 52.8824s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0180s/iter; left time: 24.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0363s/iter; left time: 45.1376s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0189s/iter; left time: 21.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0402s/iter; left time: 41.0432s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0190s/iter; left time: 17.4799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0282s/iter; left time: 22.4610s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0097s/iter; left time: 6.7633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0376s/iter; left time: 21.5597s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0223s/iter; left time: 10.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0361s/iter; left time: 12.6071s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0197s/iter; left time: 4.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0397s/iter; left time: 4.9655s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0209s/iter; left time: 0.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011143858544528484, rmse:0.10556447505950928, mae:0.06298493593931198, rse:0.3988761603832245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2797548\n",
      "\tspeed: 0.0217s/iter; left time: 94.8636s\n",
      "\titers: 200, epoch: 1 | loss: 0.2564775\n",
      "\tspeed: 0.0192s/iter; left time: 82.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.2824721 Vali Loss: 0.1925696 Test Loss: 0.1999343\n",
      "Validation loss decreased (inf --> 0.192570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1519092\n",
      "\tspeed: 0.0392s/iter; left time: 162.9826s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138760\n",
      "\tspeed: 0.0174s/iter; left time: 70.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.1577599 Vali Loss: 0.0885143 Test Loss: 0.0898196\n",
      "Validation loss decreased (0.192570 --> 0.088514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994059\n",
      "\tspeed: 0.0357s/iter; left time: 140.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920600\n",
      "\tspeed: 0.0163s/iter; left time: 62.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0987331 Vali Loss: 0.0793598 Test Loss: 0.0813890\n",
      "Validation loss decreased (0.088514 --> 0.079360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862465\n",
      "\tspeed: 0.0354s/iter; left time: 131.3037s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823747\n",
      "\tspeed: 0.0209s/iter; left time: 75.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0878294 Vali Loss: 0.0752087 Test Loss: 0.0770064\n",
      "Validation loss decreased (0.079360 --> 0.075209).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805695\n",
      "\tspeed: 0.0370s/iter; left time: 128.8703s\n",
      "\titers: 200, epoch: 5 | loss: 0.0835280\n",
      "\tspeed: 0.0182s/iter; left time: 61.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0810251 Vali Loss: 0.0726535 Test Loss: 0.0742234\n",
      "Validation loss decreased (0.075209 --> 0.072653).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783956\n",
      "\tspeed: 0.0405s/iter; left time: 132.0361s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783434\n",
      "\tspeed: 0.0222s/iter; left time: 70.0164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0766793 Vali Loss: 0.0699164 Test Loss: 0.0714286\n",
      "Validation loss decreased (0.072653 --> 0.069916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0737392\n",
      "\tspeed: 0.0360s/iter; left time: 109.4658s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715222\n",
      "\tspeed: 0.0183s/iter; left time: 53.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0738872 Vali Loss: 0.0673173 Test Loss: 0.0694845\n",
      "Validation loss decreased (0.069916 --> 0.067317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708480\n",
      "\tspeed: 0.0350s/iter; left time: 98.5778s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682935\n",
      "\tspeed: 0.0196s/iter; left time: 53.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0719646 Vali Loss: 0.0660387 Test Loss: 0.0682573\n",
      "Validation loss decreased (0.067317 --> 0.066039).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645496\n",
      "\tspeed: 0.0374s/iter; left time: 96.7208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698819\n",
      "\tspeed: 0.0182s/iter; left time: 45.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0701305 Vali Loss: 0.0643912 Test Loss: 0.0671896\n",
      "Validation loss decreased (0.066039 --> 0.064391).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676103\n",
      "\tspeed: 0.0360s/iter; left time: 85.0717s\n",
      "\titers: 200, epoch: 10 | loss: 0.0639220\n",
      "\tspeed: 0.0208s/iter; left time: 47.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0692499 Vali Loss: 0.0639208 Test Loss: 0.0666822\n",
      "Validation loss decreased (0.064391 --> 0.063921).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0649667\n",
      "\tspeed: 0.0421s/iter; left time: 90.1681s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642909\n",
      "\tspeed: 0.0219s/iter; left time: 44.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0680481 Vali Loss: 0.0636861 Test Loss: 0.0665629\n",
      "Validation loss decreased (0.063921 --> 0.063686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0633217\n",
      "\tspeed: 0.0375s/iter; left time: 71.9592s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601581\n",
      "\tspeed: 0.0171s/iter; left time: 31.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0671285 Vali Loss: 0.0625936 Test Loss: 0.0653706\n",
      "Validation loss decreased (0.063686 --> 0.062594).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0671477\n",
      "\tspeed: 0.0349s/iter; left time: 59.1071s\n",
      "\titers: 200, epoch: 13 | loss: 0.0621317\n",
      "\tspeed: 0.0194s/iter; left time: 30.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0662944 Vali Loss: 0.0626164 Test Loss: 0.0654073\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650934\n",
      "\tspeed: 0.0351s/iter; left time: 51.6196s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580635\n",
      "\tspeed: 0.0184s/iter; left time: 25.1883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0657543 Vali Loss: 0.0621716 Test Loss: 0.0646343\n",
      "Validation loss decreased (0.062594 --> 0.062172).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0658439\n",
      "\tspeed: 0.0349s/iter; left time: 43.4183s\n",
      "\titers: 200, epoch: 15 | loss: 0.0626161\n",
      "\tspeed: 0.0172s/iter; left time: 19.7016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0653719 Vali Loss: 0.0616256 Test Loss: 0.0642001\n",
      "Validation loss decreased (0.062172 --> 0.061626).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0626120\n",
      "\tspeed: 0.0356s/iter; left time: 36.3321s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643119\n",
      "\tspeed: 0.0188s/iter; left time: 17.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0649188 Vali Loss: 0.0611425 Test Loss: 0.0636172\n",
      "Validation loss decreased (0.061626 --> 0.061142).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716812\n",
      "\tspeed: 0.0383s/iter; left time: 30.5416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630838\n",
      "\tspeed: 0.0174s/iter; left time: 12.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0645986 Vali Loss: 0.0614054 Test Loss: 0.0635941\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649277\n",
      "\tspeed: 0.0377s/iter; left time: 21.5831s\n",
      "\titers: 200, epoch: 18 | loss: 0.0586403\n",
      "\tspeed: 0.0179s/iter; left time: 8.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0643763 Vali Loss: 0.0607071 Test Loss: 0.0632886\n",
      "Validation loss decreased (0.061142 --> 0.060707).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0595899\n",
      "\tspeed: 0.0384s/iter; left time: 13.4102s\n",
      "\titers: 200, epoch: 19 | loss: 0.0584789\n",
      "\tspeed: 0.0196s/iter; left time: 4.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0641533 Vali Loss: 0.0604696 Test Loss: 0.0628338\n",
      "Validation loss decreased (0.060707 --> 0.060470).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0596086\n",
      "\tspeed: 0.0378s/iter; left time: 4.7309s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594903\n",
      "\tspeed: 0.0193s/iter; left time: 0.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0638867 Vali Loss: 0.0604500 Test Loss: 0.0628845\n",
      "Validation loss decreased (0.060470 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011079911142587662, rmse:0.10526115447282791, mae:0.06288447976112366, rse:0.3977300822734833\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:52.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0424s/iter; left time: 185.7683s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0159s/iter; left time: 68.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0343s/iter; left time: 142.3944s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0177s/iter; left time: 71.8964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0352s/iter; left time: 138.3594s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0178s/iter; left time: 68.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0370s/iter; left time: 137.3865s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0207s/iter; left time: 74.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0357s/iter; left time: 124.5631s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0192s/iter; left time: 65.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0345s/iter; left time: 112.5179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0177s/iter; left time: 55.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0305s/iter; left time: 92.6444s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0099s/iter; left time: 29.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0330s/iter; left time: 92.7005s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0165s/iter; left time: 44.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0361s/iter; left time: 93.3468s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0241s/iter; left time: 59.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0346s/iter; left time: 81.7882s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0179s/iter; left time: 40.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0367s/iter; left time: 78.6554s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0185s/iter; left time: 37.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0375s/iter; left time: 71.8172s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0171s/iter; left time: 31.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0343s/iter; left time: 58.0637s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0209s/iter; left time: 33.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0374s/iter; left time: 54.9790s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0165s/iter; left time: 22.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0353s/iter; left time: 43.9769s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0176s/iter; left time: 20.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0356s/iter; left time: 36.3272s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0227s/iter; left time: 20.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0367s/iter; left time: 29.2495s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0174s/iter; left time: 12.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0354s/iter; left time: 20.2864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0182s/iter; left time: 8.6170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0365s/iter; left time: 12.7270s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0192s/iter; left time: 4.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0369s/iter; left time: 4.6127s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0206s/iter; left time: 0.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018444322049617767, rmse:0.13580986857414246, mae:0.0837516337633133, rse:0.5135117769241333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2798630\n",
      "\tspeed: 0.0239s/iter; left time: 104.6756s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552814\n",
      "\tspeed: 0.0184s/iter; left time: 78.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.2785395 Vali Loss: 0.1956593 Test Loss: 0.2025459\n",
      "Validation loss decreased (inf --> 0.195659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1523195\n",
      "\tspeed: 0.0377s/iter; left time: 156.8234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261142\n",
      "\tspeed: 0.0168s/iter; left time: 68.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1576536 Vali Loss: 0.1078425 Test Loss: 0.1150946\n",
      "Validation loss decreased (0.195659 --> 0.107843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147000\n",
      "\tspeed: 0.0375s/iter; left time: 147.2982s\n",
      "\titers: 200, epoch: 3 | loss: 0.1113540\n",
      "\tspeed: 0.0187s/iter; left time: 71.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.1117495 Vali Loss: 0.0957548 Test Loss: 0.1001511\n",
      "Validation loss decreased (0.107843 --> 0.095755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995651\n",
      "\tspeed: 0.0372s/iter; left time: 138.0796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954478\n",
      "\tspeed: 0.0185s/iter; left time: 66.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1004729 Vali Loss: 0.0901986 Test Loss: 0.0926676\n",
      "Validation loss decreased (0.095755 --> 0.090199).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0969215\n",
      "\tspeed: 0.0410s/iter; left time: 142.9546s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928631\n",
      "\tspeed: 0.0200s/iter; left time: 67.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0938142 Vali Loss: 0.0860796 Test Loss: 0.0895533\n",
      "Validation loss decreased (0.090199 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0870151\n",
      "\tspeed: 0.0385s/iter; left time: 125.6743s\n",
      "\titers: 200, epoch: 6 | loss: 0.0875229\n",
      "\tspeed: 0.0171s/iter; left time: 54.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0905203 Vali Loss: 0.0847814 Test Loss: 0.0879801\n",
      "Validation loss decreased (0.086080 --> 0.084781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876240\n",
      "\tspeed: 0.0378s/iter; left time: 114.8192s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924451\n",
      "\tspeed: 0.0175s/iter; left time: 51.3450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0881872 Vali Loss: 0.0827412 Test Loss: 0.0871473\n",
      "Validation loss decreased (0.084781 --> 0.082741).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911712\n",
      "\tspeed: 0.0363s/iter; left time: 102.0720s\n",
      "\titers: 200, epoch: 8 | loss: 0.0860737\n",
      "\tspeed: 0.0167s/iter; left time: 45.2213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0866387 Vali Loss: 0.0817173 Test Loss: 0.0861746\n",
      "Validation loss decreased (0.082741 --> 0.081717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867940\n",
      "\tspeed: 0.0353s/iter; left time: 91.3965s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838338\n",
      "\tspeed: 0.0198s/iter; left time: 49.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0853725 Vali Loss: 0.0804546 Test Loss: 0.0854482\n",
      "Validation loss decreased (0.081717 --> 0.080455).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817206\n",
      "\tspeed: 0.0358s/iter; left time: 84.6040s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812260\n",
      "\tspeed: 0.0160s/iter; left time: 36.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0844308 Vali Loss: 0.0804576 Test Loss: 0.0854035\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823050\n",
      "\tspeed: 0.0352s/iter; left time: 75.3127s\n",
      "\titers: 200, epoch: 11 | loss: 0.0891172\n",
      "\tspeed: 0.0186s/iter; left time: 37.9817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0839546 Vali Loss: 0.0798848 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080455 --> 0.079885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836017\n",
      "\tspeed: 0.0414s/iter; left time: 79.4157s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801083\n",
      "\tspeed: 0.0235s/iter; left time: 42.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0831784 Vali Loss: 0.0796328 Test Loss: 0.0854974\n",
      "Validation loss decreased (0.079885 --> 0.079633).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847356\n",
      "\tspeed: 0.0417s/iter; left time: 70.5412s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833554\n",
      "\tspeed: 0.0206s/iter; left time: 32.7626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0827545 Vali Loss: 0.0793973 Test Loss: 0.0847967\n",
      "Validation loss decreased (0.079633 --> 0.079397).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791785\n",
      "\tspeed: 0.0361s/iter; left time: 52.9787s\n",
      "\titers: 200, epoch: 14 | loss: 0.0865727\n",
      "\tspeed: 0.0186s/iter; left time: 25.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0823615 Vali Loss: 0.0789985 Test Loss: 0.0845724\n",
      "Validation loss decreased (0.079397 --> 0.078999).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0853503\n",
      "\tspeed: 0.0384s/iter; left time: 47.7953s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792778\n",
      "\tspeed: 0.0188s/iter; left time: 21.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0819889 Vali Loss: 0.0791902 Test Loss: 0.0849499\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0856560\n",
      "\tspeed: 0.0327s/iter; left time: 33.3592s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827346\n",
      "\tspeed: 0.0160s/iter; left time: 14.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0816865 Vali Loss: 0.0787904 Test Loss: 0.0842490\n",
      "Validation loss decreased (0.078999 --> 0.078790).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848473\n",
      "\tspeed: 0.0356s/iter; left time: 28.4113s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770277\n",
      "\tspeed: 0.0171s/iter; left time: 11.9268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0814561 Vali Loss: 0.0784145 Test Loss: 0.0843971\n",
      "Validation loss decreased (0.078790 --> 0.078414).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760338\n",
      "\tspeed: 0.0359s/iter; left time: 20.5641s\n",
      "\titers: 200, epoch: 18 | loss: 0.0781984\n",
      "\tspeed: 0.0153s/iter; left time: 7.2369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0810920 Vali Loss: 0.0786268 Test Loss: 0.0844016\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800134\n",
      "\tspeed: 0.0350s/iter; left time: 12.2098s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767878\n",
      "\tspeed: 0.0179s/iter; left time: 4.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0810874 Vali Loss: 0.0781209 Test Loss: 0.0842462\n",
      "Validation loss decreased (0.078414 --> 0.078121).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0753115\n",
      "\tspeed: 0.0375s/iter; left time: 4.6825s\n",
      "\titers: 200, epoch: 20 | loss: 0.0850095\n",
      "\tspeed: 0.0159s/iter; left time: 0.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0807790 Vali Loss: 0.0781104 Test Loss: 0.0839733\n",
      "Validation loss decreased (0.078121 --> 0.078110).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018509913235902786, rmse:0.13605114817619324, mae:0.08397328108549118, rse:0.5144240260124207\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:49.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0442s/iter; left time: 192.6721s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0162s/iter; left time: 69.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0422s/iter; left time: 174.5507s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0211s/iter; left time: 85.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0385s/iter; left time: 150.6576s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0197s/iter; left time: 75.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0394s/iter; left time: 145.2998s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0201s/iter; left time: 72.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0356s/iter; left time: 123.4889s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0161s/iter; left time: 54.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0383s/iter; left time: 124.3866s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0184s/iter; left time: 57.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0356s/iter; left time: 107.5676s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0232s/iter; left time: 67.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0346s/iter; left time: 96.7608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0187s/iter; left time: 50.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0316s/iter; left time: 81.3505s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0180s/iter; left time: 44.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0362s/iter; left time: 85.2823s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0173s/iter; left time: 39.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0363s/iter; left time: 77.4081s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0188s/iter; left time: 38.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0390s/iter; left time: 74.4492s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0196s/iter; left time: 35.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0352s/iter; left time: 59.3546s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0198s/iter; left time: 31.3646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0373s/iter; left time: 54.5007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0192s/iter; left time: 26.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0390s/iter; left time: 48.3688s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0200s/iter; left time: 22.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0395s/iter; left time: 40.1822s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0223s/iter; left time: 20.4584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0408s/iter; left time: 32.3816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0211s/iter; left time: 14.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0394s/iter; left time: 22.4491s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0212s/iter; left time: 9.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0366s/iter; left time: 12.7084s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0163s/iter; left time: 4.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0346s/iter; left time: 4.2951s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0223s/iter; left time: 0.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020099075511097908, rmse:0.14177121222019196, mae:0.08870533108711243, rse:0.5365503430366516\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2813044\n",
      "\tspeed: 0.0188s/iter; left time: 81.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.2537842\n",
      "\tspeed: 0.0191s/iter; left time: 81.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.2827695 Vali Loss: 0.1986171 Test Loss: 0.2049647\n",
      "Validation loss decreased (inf --> 0.198617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426644\n",
      "\tspeed: 0.0362s/iter; left time: 149.5893s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291617\n",
      "\tspeed: 0.0174s/iter; left time: 70.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1570104 Vali Loss: 0.1081954 Test Loss: 0.1133942\n",
      "Validation loss decreased (0.198617 --> 0.108195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168254\n",
      "\tspeed: 0.0397s/iter; left time: 155.3093s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129910\n",
      "\tspeed: 0.0204s/iter; left time: 77.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.1136678 Vali Loss: 0.0983627 Test Loss: 0.1008437\n",
      "Validation loss decreased (0.108195 --> 0.098363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040641\n",
      "\tspeed: 0.0419s/iter; left time: 154.7231s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984779\n",
      "\tspeed: 0.0200s/iter; left time: 71.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.1031041 Vali Loss: 0.0935392 Test Loss: 0.0961893\n",
      "Validation loss decreased (0.098363 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0936531\n",
      "\tspeed: 0.0400s/iter; left time: 138.8695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950231\n",
      "\tspeed: 0.0183s/iter; left time: 61.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0967202 Vali Loss: 0.0893786 Test Loss: 0.0926177\n",
      "Validation loss decreased (0.093539 --> 0.089379).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0924721\n",
      "\tspeed: 0.0391s/iter; left time: 127.0568s\n",
      "\titers: 200, epoch: 6 | loss: 0.0913443\n",
      "\tspeed: 0.0225s/iter; left time: 70.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0941212 Vali Loss: 0.0876763 Test Loss: 0.0913170\n",
      "Validation loss decreased (0.089379 --> 0.087676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0951016\n",
      "\tspeed: 0.0368s/iter; left time: 111.2449s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915995\n",
      "\tspeed: 0.0223s/iter; left time: 65.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0915591 Vali Loss: 0.0875427 Test Loss: 0.0913138\n",
      "Validation loss decreased (0.087676 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927571\n",
      "\tspeed: 0.0383s/iter; left time: 107.1279s\n",
      "\titers: 200, epoch: 8 | loss: 0.0894333\n",
      "\tspeed: 0.0173s/iter; left time: 46.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0900401 Vali Loss: 0.0854019 Test Loss: 0.0900058\n",
      "Validation loss decreased (0.087543 --> 0.085402).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0886705\n",
      "\tspeed: 0.0415s/iter; left time: 106.9194s\n",
      "\titers: 200, epoch: 9 | loss: 0.0879912\n",
      "\tspeed: 0.0224s/iter; left time: 55.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0889541 Vali Loss: 0.0849612 Test Loss: 0.0891515\n",
      "Validation loss decreased (0.085402 --> 0.084961).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0877168\n",
      "\tspeed: 0.0391s/iter; left time: 92.1186s\n",
      "\titers: 200, epoch: 10 | loss: 0.0875674\n",
      "\tspeed: 0.0199s/iter; left time: 44.9062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0881908 Vali Loss: 0.0846811 Test Loss: 0.0888525\n",
      "Validation loss decreased (0.084961 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0898153\n",
      "\tspeed: 0.0368s/iter; left time: 78.4034s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906977\n",
      "\tspeed: 0.0199s/iter; left time: 40.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0876222 Vali Loss: 0.0841912 Test Loss: 0.0885119\n",
      "Validation loss decreased (0.084681 --> 0.084191).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0854267\n",
      "\tspeed: 0.0401s/iter; left time: 76.4783s\n",
      "\titers: 200, epoch: 12 | loss: 0.0921324\n",
      "\tspeed: 0.0220s/iter; left time: 39.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0870224 Vali Loss: 0.0838905 Test Loss: 0.0882123\n",
      "Validation loss decreased (0.084191 --> 0.083890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908491\n",
      "\tspeed: 0.0390s/iter; left time: 65.7444s\n",
      "\titers: 200, epoch: 13 | loss: 0.0868078\n",
      "\tspeed: 0.0193s/iter; left time: 30.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0865049 Vali Loss: 0.0839069 Test Loss: 0.0883935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0854094\n",
      "\tspeed: 0.0372s/iter; left time: 54.3500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844667\n",
      "\tspeed: 0.0183s/iter; left time: 24.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0861975 Vali Loss: 0.0840705 Test Loss: 0.0888260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889031\n",
      "\tspeed: 0.0392s/iter; left time: 48.5088s\n",
      "\titers: 200, epoch: 15 | loss: 0.0843957\n",
      "\tspeed: 0.0202s/iter; left time: 23.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0855418 Vali Loss: 0.0836140 Test Loss: 0.0885775\n",
      "Validation loss decreased (0.083890 --> 0.083614).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0875921\n",
      "\tspeed: 0.0353s/iter; left time: 35.8347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831733\n",
      "\tspeed: 0.0168s/iter; left time: 15.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0853479 Vali Loss: 0.0839115 Test Loss: 0.0888283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0873199\n",
      "\tspeed: 0.0340s/iter; left time: 26.9804s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876978\n",
      "\tspeed: 0.0101s/iter; left time: 6.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 223 | Train Loss: 0.0852551 Vali Loss: 0.0832509 Test Loss: 0.0884188\n",
      "Validation loss decreased (0.083614 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0823902\n",
      "\tspeed: 0.0363s/iter; left time: 20.7115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818335\n",
      "\tspeed: 0.0171s/iter; left time: 8.0195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0849353 Vali Loss: 0.0838093 Test Loss: 0.0887195\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851609\n",
      "\tspeed: 0.0355s/iter; left time: 12.3019s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858866\n",
      "\tspeed: 0.0188s/iter; left time: 4.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0846712 Vali Loss: 0.0832612 Test Loss: 0.0881233\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0836230\n",
      "\tspeed: 0.0386s/iter; left time: 4.7863s\n",
      "\titers: 200, epoch: 20 | loss: 0.0846320\n",
      "\tspeed: 0.0180s/iter; left time: 0.4309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0845549 Vali Loss: 0.0833086 Test Loss: 0.0881949\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019747594371438026, rmse:0.14052613079547882, mae:0.0884188562631607, rse:0.5318382382392883\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:59.29s\n",
      "Intermediate time for IT: 00h:11m:41.06s\n",
      "Total time: 00h:57m:46.54s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.0617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0220  0.1484  0.0926\n",
       "        96        0.0415  0.2037  0.1336\n",
       "        168       0.0448  0.2116  0.1411\n",
       "ES      24        0.0202  0.1422  0.0838\n",
       "        96        0.0300  0.1727  0.1122\n",
       "        168       0.0293  0.1712  0.1158\n",
       "FR      24        0.0112  0.1058  0.0617\n",
       "        96        0.0208  0.1441  0.0848\n",
       "        168       0.0242  0.1556  0.0917\n",
       "GB      24        0.0284  0.1684  0.1077\n",
       "        96        0.0530  0.2302  0.1529\n",
       "        168       0.0548  0.2341  0.1576\n",
       "IT      24        0.0111  0.1054  0.0629\n",
       "        96        0.0185  0.1359  0.0839\n",
       "        168       0.0199  0.1411  0.0886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1554952\n",
      "\tspeed: 0.0431s/iter; left time: 188.7469s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357202\n",
      "\tspeed: 0.0153s/iter; left time: 65.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1541195 Vali Loss: 0.1402045 Test Loss: 0.1497520\n",
      "Validation loss decreased (inf --> 0.140205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869676\n",
      "\tspeed: 0.0344s/iter; left time: 143.0137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847717\n",
      "\tspeed: 0.0165s/iter; left time: 66.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0921203 Vali Loss: 0.0949045 Test Loss: 0.0956562\n",
      "Validation loss decreased (0.140205 --> 0.094904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0774624\n",
      "\tspeed: 0.0384s/iter; left time: 150.8717s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822205\n",
      "\tspeed: 0.0179s/iter; left time: 68.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0812834 Vali Loss: 0.0916223 Test Loss: 0.0926683\n",
      "Validation loss decreased (0.094904 --> 0.091622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0761068\n",
      "\tspeed: 0.0355s/iter; left time: 131.8357s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788112\n",
      "\tspeed: 0.0182s/iter; left time: 65.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0784736 Vali Loss: 0.0895640 Test Loss: 0.0912961\n",
      "Validation loss decreased (0.091622 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777103\n",
      "\tspeed: 0.0415s/iter; left time: 144.7898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0786942\n",
      "\tspeed: 0.0201s/iter; left time: 68.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0769159 Vali Loss: 0.0888526 Test Loss: 0.0907485\n",
      "Validation loss decreased (0.089564 --> 0.088853).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802427\n",
      "\tspeed: 0.0382s/iter; left time: 124.5170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0740417\n",
      "\tspeed: 0.0186s/iter; left time: 58.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0758447 Vali Loss: 0.0882284 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.088853 --> 0.088228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748348\n",
      "\tspeed: 0.0348s/iter; left time: 105.6184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769684\n",
      "\tspeed: 0.0150s/iter; left time: 44.1198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0751689 Vali Loss: 0.0878075 Test Loss: 0.0892610\n",
      "Validation loss decreased (0.088228 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0768212\n",
      "\tspeed: 0.0352s/iter; left time: 98.9953s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734301\n",
      "\tspeed: 0.0150s/iter; left time: 40.5969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0745465 Vali Loss: 0.0876324 Test Loss: 0.0891513\n",
      "Validation loss decreased (0.087807 --> 0.087632).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738977\n",
      "\tspeed: 0.0338s/iter; left time: 87.4820s\n",
      "\titers: 200, epoch: 9 | loss: 0.0720558\n",
      "\tspeed: 0.0191s/iter; left time: 47.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0740447 Vali Loss: 0.0870932 Test Loss: 0.0891499\n",
      "Validation loss decreased (0.087632 --> 0.087093).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726922\n",
      "\tspeed: 0.0403s/iter; left time: 95.4241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0745696\n",
      "\tspeed: 0.0200s/iter; left time: 45.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0736376 Vali Loss: 0.0868243 Test Loss: 0.0889371\n",
      "Validation loss decreased (0.087093 --> 0.086824).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685705\n",
      "\tspeed: 0.0377s/iter; left time: 80.6174s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697067\n",
      "\tspeed: 0.0150s/iter; left time: 30.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0733032 Vali Loss: 0.0868257 Test Loss: 0.0887700\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0702654\n",
      "\tspeed: 0.0384s/iter; left time: 73.6904s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722485\n",
      "\tspeed: 0.0186s/iter; left time: 33.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0729990 Vali Loss: 0.0867122 Test Loss: 0.0885437\n",
      "Validation loss decreased (0.086824 --> 0.086712).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722399\n",
      "\tspeed: 0.0401s/iter; left time: 67.8455s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783269\n",
      "\tspeed: 0.0217s/iter; left time: 34.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0727403 Vali Loss: 0.0864957 Test Loss: 0.0886285\n",
      "Validation loss decreased (0.086712 --> 0.086496).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0701331\n",
      "\tspeed: 0.0392s/iter; left time: 57.6211s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752917\n",
      "\tspeed: 0.0149s/iter; left time: 20.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0725547 Vali Loss: 0.0861861 Test Loss: 0.0884400\n",
      "Validation loss decreased (0.086496 --> 0.086186).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738760\n",
      "\tspeed: 0.0373s/iter; left time: 46.3954s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728909\n",
      "\tspeed: 0.0157s/iter; left time: 17.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0723449 Vali Loss: 0.0862782 Test Loss: 0.0885036\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734793\n",
      "\tspeed: 0.0334s/iter; left time: 34.1015s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676081\n",
      "\tspeed: 0.0150s/iter; left time: 13.8036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0721527 Vali Loss: 0.0864140 Test Loss: 0.0884588\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0718961\n",
      "\tspeed: 0.0374s/iter; left time: 29.8084s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705533\n",
      "\tspeed: 0.0185s/iter; left time: 12.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0720608 Vali Loss: 0.0860744 Test Loss: 0.0882078\n",
      "Validation loss decreased (0.086186 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0697139\n",
      "\tspeed: 0.0353s/iter; left time: 20.2203s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702659\n",
      "\tspeed: 0.0174s/iter; left time: 8.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0719050 Vali Loss: 0.0860787 Test Loss: 0.0882772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0671234\n",
      "\tspeed: 0.0387s/iter; left time: 13.4927s\n",
      "\titers: 200, epoch: 19 | loss: 0.0692945\n",
      "\tspeed: 0.0182s/iter; left time: 4.5320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0717753 Vali Loss: 0.0862968 Test Loss: 0.0883190\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733683\n",
      "\tspeed: 0.0418s/iter; left time: 5.2267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0683619\n",
      "\tspeed: 0.0200s/iter; left time: 0.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0716777 Vali Loss: 0.0859621 Test Loss: 0.0881678\n",
      "Validation loss decreased (0.086074 --> 0.085962).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02103586122393608, rmse:0.145037442445755, mae:0.08816780894994736, rse:0.511857271194458\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1569923\n",
      "\tspeed: 0.0234s/iter; left time: 102.3202s\n",
      "\titers: 200, epoch: 1 | loss: 0.1288551\n",
      "\tspeed: 0.0197s/iter; left time: 84.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1549266 Vali Loss: 0.1411644 Test Loss: 0.1500563\n",
      "Validation loss decreased (inf --> 0.141164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0881527\n",
      "\tspeed: 0.0416s/iter; left time: 173.1000s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912773\n",
      "\tspeed: 0.0201s/iter; left time: 81.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0924410 Vali Loss: 0.0946205 Test Loss: 0.0955073\n",
      "Validation loss decreased (0.141164 --> 0.094620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0822034\n",
      "\tspeed: 0.0365s/iter; left time: 143.3943s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804854\n",
      "\tspeed: 0.0178s/iter; left time: 68.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0812288 Vali Loss: 0.0912640 Test Loss: 0.0926674\n",
      "Validation loss decreased (0.094620 --> 0.091264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729592\n",
      "\tspeed: 0.0386s/iter; left time: 143.0019s\n",
      "\titers: 200, epoch: 4 | loss: 0.0756239\n",
      "\tspeed: 0.0173s/iter; left time: 62.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0785791 Vali Loss: 0.0898872 Test Loss: 0.0911682\n",
      "Validation loss decreased (0.091264 --> 0.089887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767641\n",
      "\tspeed: 0.0413s/iter; left time: 144.0749s\n",
      "\titers: 200, epoch: 5 | loss: 0.0731243\n",
      "\tspeed: 0.0179s/iter; left time: 60.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0770697 Vali Loss: 0.0891297 Test Loss: 0.0905038\n",
      "Validation loss decreased (0.089887 --> 0.089130).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777329\n",
      "\tspeed: 0.0447s/iter; left time: 145.7056s\n",
      "\titers: 200, epoch: 6 | loss: 0.0788753\n",
      "\tspeed: 0.0249s/iter; left time: 78.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0759762 Vali Loss: 0.0886014 Test Loss: 0.0902082\n",
      "Validation loss decreased (0.089130 --> 0.088601).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776498\n",
      "\tspeed: 0.0434s/iter; left time: 131.6891s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724196\n",
      "\tspeed: 0.0193s/iter; left time: 56.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0752084 Vali Loss: 0.0876980 Test Loss: 0.0896836\n",
      "Validation loss decreased (0.088601 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782859\n",
      "\tspeed: 0.0442s/iter; left time: 124.4295s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742921\n",
      "\tspeed: 0.0177s/iter; left time: 47.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0746367 Vali Loss: 0.0875709 Test Loss: 0.0895203\n",
      "Validation loss decreased (0.087698 --> 0.087571).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0741152\n",
      "\tspeed: 0.0442s/iter; left time: 114.4885s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707264\n",
      "\tspeed: 0.0249s/iter; left time: 62.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0741354 Vali Loss: 0.0873647 Test Loss: 0.0891933\n",
      "Validation loss decreased (0.087571 --> 0.087365).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0774268\n",
      "\tspeed: 0.0467s/iter; left time: 110.4193s\n",
      "\titers: 200, epoch: 10 | loss: 0.0757666\n",
      "\tspeed: 0.0212s/iter; left time: 48.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0737080 Vali Loss: 0.0870624 Test Loss: 0.0889512\n",
      "Validation loss decreased (0.087365 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0755409\n",
      "\tspeed: 0.0450s/iter; left time: 96.4365s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718153\n",
      "\tspeed: 0.0245s/iter; left time: 50.0847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 224 | Train Loss: 0.0734132 Vali Loss: 0.0869114 Test Loss: 0.0889660\n",
      "Validation loss decreased (0.087062 --> 0.086911).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758429\n",
      "\tspeed: 0.0456s/iter; left time: 87.3395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731042\n",
      "\tspeed: 0.0210s/iter; left time: 38.1688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0731156 Vali Loss: 0.0867391 Test Loss: 0.0890012\n",
      "Validation loss decreased (0.086911 --> 0.086739).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763908\n",
      "\tspeed: 0.0388s/iter; left time: 65.7452s\n",
      "\titers: 200, epoch: 13 | loss: 0.0706781\n",
      "\tspeed: 0.0174s/iter; left time: 27.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0728514 Vali Loss: 0.0862831 Test Loss: 0.0886576\n",
      "Validation loss decreased (0.086739 --> 0.086283).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0676040\n",
      "\tspeed: 0.0378s/iter; left time: 55.4976s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752216\n",
      "\tspeed: 0.0183s/iter; left time: 25.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0726661 Vali Loss: 0.0865068 Test Loss: 0.0888009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0711630\n",
      "\tspeed: 0.0381s/iter; left time: 47.3744s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687853\n",
      "\tspeed: 0.0217s/iter; left time: 24.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0724174 Vali Loss: 0.0861133 Test Loss: 0.0884617\n",
      "Validation loss decreased (0.086283 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703114\n",
      "\tspeed: 0.0357s/iter; left time: 36.4709s\n",
      "\titers: 200, epoch: 16 | loss: 0.0778182\n",
      "\tspeed: 0.0186s/iter; left time: 17.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0722327 Vali Loss: 0.0861533 Test Loss: 0.0884141\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0752272\n",
      "\tspeed: 0.0412s/iter; left time: 32.8678s\n",
      "\titers: 200, epoch: 17 | loss: 0.0660648\n",
      "\tspeed: 0.0161s/iter; left time: 11.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0721134 Vali Loss: 0.0860939 Test Loss: 0.0884697\n",
      "Validation loss decreased (0.086113 --> 0.086094).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760951\n",
      "\tspeed: 0.0353s/iter; left time: 20.2551s\n",
      "\titers: 200, epoch: 18 | loss: 0.0698126\n",
      "\tspeed: 0.0189s/iter; left time: 8.9336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0719862 Vali Loss: 0.0860885 Test Loss: 0.0884769\n",
      "Validation loss decreased (0.086094 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748066\n",
      "\tspeed: 0.0476s/iter; left time: 16.6085s\n",
      "\titers: 200, epoch: 19 | loss: 0.0722093\n",
      "\tspeed: 0.0248s/iter; left time: 6.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0717882 Vali Loss: 0.0861733 Test Loss: 0.0884549\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718694\n",
      "\tspeed: 0.0397s/iter; left time: 4.9653s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701521\n",
      "\tspeed: 0.0171s/iter; left time: 0.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0717911 Vali Loss: 0.0858655 Test Loss: 0.0882043\n",
      "Validation loss decreased (0.086088 --> 0.085865).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021054714918136597, rmse:0.14510242640972137, mae:0.08820432424545288, rse:0.5120865702629089\n",
      "Intermediate time for DE and pred_len 24: 00h:04m:04.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1617293\n",
      "\tspeed: 0.0433s/iter; left time: 189.9140s\n",
      "\titers: 200, epoch: 1 | loss: 0.1502261\n",
      "\tspeed: 0.0152s/iter; left time: 65.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1589484 Vali Loss: 0.1489534 Test Loss: 0.1608385\n",
      "Validation loss decreased (inf --> 0.148953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1088347\n",
      "\tspeed: 0.0371s/iter; left time: 154.1003s\n",
      "\titers: 200, epoch: 2 | loss: 0.1147311\n",
      "\tspeed: 0.0180s/iter; left time: 72.8770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1169258 Vali Loss: 0.1223775 Test Loss: 0.1303410\n",
      "Validation loss decreased (0.148953 --> 0.122377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055293\n",
      "\tspeed: 0.0377s/iter; left time: 148.3993s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986288\n",
      "\tspeed: 0.0152s/iter; left time: 58.1857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 224 | Train Loss: 0.1074978 Vali Loss: 0.1198995 Test Loss: 0.1283483\n",
      "Validation loss decreased (0.122377 --> 0.119899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1030197\n",
      "\tspeed: 0.0406s/iter; left time: 150.4588s\n",
      "\titers: 200, epoch: 4 | loss: 0.1036162\n",
      "\tspeed: 0.0185s/iter; left time: 66.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.1053726 Vali Loss: 0.1190406 Test Loss: 0.1278044\n",
      "Validation loss decreased (0.119899 --> 0.119041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044356\n",
      "\tspeed: 0.0385s/iter; left time: 134.1142s\n",
      "\titers: 200, epoch: 5 | loss: 0.1062173\n",
      "\tspeed: 0.0167s/iter; left time: 56.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.1040613 Vali Loss: 0.1187894 Test Loss: 0.1276770\n",
      "Validation loss decreased (0.119041 --> 0.118789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023082\n",
      "\tspeed: 0.0353s/iter; left time: 115.2568s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002097\n",
      "\tspeed: 0.0157s/iter; left time: 49.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.1030888 Vali Loss: 0.1175843 Test Loss: 0.1267586\n",
      "Validation loss decreased (0.118789 --> 0.117584).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985272\n",
      "\tspeed: 0.0402s/iter; left time: 122.1258s\n",
      "\titers: 200, epoch: 7 | loss: 0.1033290\n",
      "\tspeed: 0.0204s/iter; left time: 59.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1023778 Vali Loss: 0.1178266 Test Loss: 0.1273874\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0990437\n",
      "\tspeed: 0.0415s/iter; left time: 116.6032s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037220\n",
      "\tspeed: 0.0195s/iter; left time: 52.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1017019 Vali Loss: 0.1178749 Test Loss: 0.1282059\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1000827\n",
      "\tspeed: 0.0406s/iter; left time: 105.2118s\n",
      "\titers: 200, epoch: 9 | loss: 0.1004790\n",
      "\tspeed: 0.0192s/iter; left time: 47.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1011080 Vali Loss: 0.1178433 Test Loss: 0.1280416\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0967632\n",
      "\tspeed: 0.0419s/iter; left time: 99.0451s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985029\n",
      "\tspeed: 0.0199s/iter; left time: 45.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1005722 Vali Loss: 0.1179191 Test Loss: 0.1280248\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0999602\n",
      "\tspeed: 0.0410s/iter; left time: 87.7302s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048836\n",
      "\tspeed: 0.0186s/iter; left time: 37.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1001029 Vali Loss: 0.1170781 Test Loss: 0.1272336\n",
      "Validation loss decreased (0.117584 --> 0.117078).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0998638\n",
      "\tspeed: 0.0444s/iter; left time: 85.0222s\n",
      "\titers: 200, epoch: 12 | loss: 0.0988359\n",
      "\tspeed: 0.0239s/iter; left time: 43.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0995904 Vali Loss: 0.1173029 Test Loss: 0.1276678\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029612\n",
      "\tspeed: 0.0419s/iter; left time: 70.8932s\n",
      "\titers: 200, epoch: 13 | loss: 0.0956578\n",
      "\tspeed: 0.0210s/iter; left time: 33.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0991521 Vali Loss: 0.1173498 Test Loss: 0.1281194\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1017543\n",
      "\tspeed: 0.0473s/iter; left time: 69.5560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952376\n",
      "\tspeed: 0.0235s/iter; left time: 32.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0987826 Vali Loss: 0.1174424 Test Loss: 0.1278649\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1004049\n",
      "\tspeed: 0.0420s/iter; left time: 52.3101s\n",
      "\titers: 200, epoch: 15 | loss: 0.1025560\n",
      "\tspeed: 0.0200s/iter; left time: 22.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0983810 Vali Loss: 0.1175421 Test Loss: 0.1287416\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000547\n",
      "\tspeed: 0.0413s/iter; left time: 42.1258s\n",
      "\titers: 200, epoch: 16 | loss: 0.0976227\n",
      "\tspeed: 0.0224s/iter; left time: 20.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0980522 Vali Loss: 0.1172046 Test Loss: 0.1286765\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037020161747932434, rmse:0.19240623712539673, mae:0.1272336095571518, rse:0.6813493967056274\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1630785\n",
      "\tspeed: 0.0248s/iter; left time: 108.4748s\n",
      "\titers: 200, epoch: 1 | loss: 0.1449552\n",
      "\tspeed: 0.0208s/iter; left time: 88.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1604888 Vali Loss: 0.1499657 Test Loss: 0.1620333\n",
      "Validation loss decreased (inf --> 0.149966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091487\n",
      "\tspeed: 0.0408s/iter; left time: 169.5820s\n",
      "\titers: 200, epoch: 2 | loss: 0.1060006\n",
      "\tspeed: 0.0207s/iter; left time: 83.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1170154 Vali Loss: 0.1222239 Test Loss: 0.1304720\n",
      "Validation loss decreased (0.149966 --> 0.122224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1130211\n",
      "\tspeed: 0.0426s/iter; left time: 167.4582s\n",
      "\titers: 200, epoch: 3 | loss: 0.1058219\n",
      "\tspeed: 0.0205s/iter; left time: 78.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1075553 Vali Loss: 0.1200851 Test Loss: 0.1297144\n",
      "Validation loss decreased (0.122224 --> 0.120085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025496\n",
      "\tspeed: 0.0470s/iter; left time: 174.2754s\n",
      "\titers: 200, epoch: 4 | loss: 0.1057491\n",
      "\tspeed: 0.0173s/iter; left time: 62.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.1053703 Vali Loss: 0.1193173 Test Loss: 0.1299114\n",
      "Validation loss decreased (0.120085 --> 0.119317).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032997\n",
      "\tspeed: 0.0457s/iter; left time: 159.4342s\n",
      "\titers: 200, epoch: 5 | loss: 0.1151524\n",
      "\tspeed: 0.0175s/iter; left time: 59.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.1039783 Vali Loss: 0.1186134 Test Loss: 0.1288320\n",
      "Validation loss decreased (0.119317 --> 0.118613).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036089\n",
      "\tspeed: 0.0434s/iter; left time: 141.4052s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987184\n",
      "\tspeed: 0.0177s/iter; left time: 56.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.1029179 Vali Loss: 0.1180167 Test Loss: 0.1285254\n",
      "Validation loss decreased (0.118613 --> 0.118017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983001\n",
      "\tspeed: 0.0433s/iter; left time: 131.5383s\n",
      "\titers: 200, epoch: 7 | loss: 0.1078606\n",
      "\tspeed: 0.0246s/iter; left time: 72.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.1021746 Vali Loss: 0.1183373 Test Loss: 0.1284593\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1007332\n",
      "\tspeed: 0.0385s/iter; left time: 108.2391s\n",
      "\titers: 200, epoch: 8 | loss: 0.1045842\n",
      "\tspeed: 0.0152s/iter; left time: 41.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.1013616 Vali Loss: 0.1189741 Test Loss: 0.1294374\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1018139\n",
      "\tspeed: 0.0384s/iter; left time: 99.3840s\n",
      "\titers: 200, epoch: 9 | loss: 0.1061398\n",
      "\tspeed: 0.0168s/iter; left time: 41.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1007345 Vali Loss: 0.1180770 Test Loss: 0.1282958\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989693\n",
      "\tspeed: 0.0414s/iter; left time: 97.8851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0958580\n",
      "\tspeed: 0.0173s/iter; left time: 39.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1000828 Vali Loss: 0.1182697 Test Loss: 0.1283964\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0962997\n",
      "\tspeed: 0.0366s/iter; left time: 78.3523s\n",
      "\titers: 200, epoch: 11 | loss: 0.1008206\n",
      "\tspeed: 0.0166s/iter; left time: 33.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0995669 Vali Loss: 0.1182233 Test Loss: 0.1287764\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037573326379060745, rmse:0.19383840262889862, mae:0.12852546572685242, rse:0.6864209771156311\n",
      "Intermediate time for DE and pred_len 96: 00h:02m:54.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1630802\n",
      "\tspeed: 0.0426s/iter; left time: 185.8234s\n",
      "\titers: 200, epoch: 1 | loss: 0.1465753\n",
      "\tspeed: 0.0153s/iter; left time: 65.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1605783 Vali Loss: 0.1508962 Test Loss: 0.1630176\n",
      "Validation loss decreased (inf --> 0.150896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295763\n",
      "\tspeed: 0.0363s/iter; left time: 150.1152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168139\n",
      "\tspeed: 0.0178s/iter; left time: 71.9166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1227621 Vali Loss: 0.1269557 Test Loss: 0.1364352\n",
      "Validation loss decreased (0.150896 --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145269\n",
      "\tspeed: 0.0433s/iter; left time: 169.3482s\n",
      "\titers: 200, epoch: 3 | loss: 0.1162174\n",
      "\tspeed: 0.0195s/iter; left time: 74.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.1136734 Vali Loss: 0.1247916 Test Loss: 0.1347414\n",
      "Validation loss decreased (0.126956 --> 0.124792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097216\n",
      "\tspeed: 0.0426s/iter; left time: 157.4378s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118387\n",
      "\tspeed: 0.0197s/iter; left time: 70.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1113515 Vali Loss: 0.1241977 Test Loss: 0.1348312\n",
      "Validation loss decreased (0.124792 --> 0.124198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120783\n",
      "\tspeed: 0.0439s/iter; left time: 152.3621s\n",
      "\titers: 200, epoch: 5 | loss: 0.1105169\n",
      "\tspeed: 0.0201s/iter; left time: 67.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.1099460 Vali Loss: 0.1236693 Test Loss: 0.1346285\n",
      "Validation loss decreased (0.124198 --> 0.123669).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060411\n",
      "\tspeed: 0.0428s/iter; left time: 138.8908s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044471\n",
      "\tspeed: 0.0186s/iter; left time: 58.5657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.1088728 Vali Loss: 0.1233766 Test Loss: 0.1346566\n",
      "Validation loss decreased (0.123669 --> 0.123377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1017920\n",
      "\tspeed: 0.0437s/iter; left time: 132.0980s\n",
      "\titers: 200, epoch: 7 | loss: 0.1089835\n",
      "\tspeed: 0.0198s/iter; left time: 57.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1079321 Vali Loss: 0.1237818 Test Loss: 0.1350066\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1103656\n",
      "\tspeed: 0.0477s/iter; left time: 133.6923s\n",
      "\titers: 200, epoch: 8 | loss: 0.1075654\n",
      "\tspeed: 0.0256s/iter; left time: 69.1177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.1071216 Vali Loss: 0.1238213 Test Loss: 0.1350236\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030786\n",
      "\tspeed: 0.0441s/iter; left time: 113.6919s\n",
      "\titers: 200, epoch: 9 | loss: 0.1097195\n",
      "\tspeed: 0.0203s/iter; left time: 50.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.1063707 Vali Loss: 0.1244656 Test Loss: 0.1355901\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035809\n",
      "\tspeed: 0.0422s/iter; left time: 99.2824s\n",
      "\titers: 200, epoch: 10 | loss: 0.1176516\n",
      "\tspeed: 0.0198s/iter; left time: 44.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.1057048 Vali Loss: 0.1241349 Test Loss: 0.1359958\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068485\n",
      "\tspeed: 0.0383s/iter; left time: 81.6387s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104806\n",
      "\tspeed: 0.0167s/iter; left time: 33.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.1050271 Vali Loss: 0.1242511 Test Loss: 0.1356018\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039681319147348404, rmse:0.19920170307159424, mae:0.1346566081047058, rse:0.7055884599685669\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1553396\n",
      "\tspeed: 0.0244s/iter; left time: 106.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.1451320\n",
      "\tspeed: 0.0198s/iter; left time: 84.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.1597921 Vali Loss: 0.1508654 Test Loss: 0.1624720\n",
      "Validation loss decreased (inf --> 0.150865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205829\n",
      "\tspeed: 0.0501s/iter; left time: 207.4659s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156526\n",
      "\tspeed: 0.0197s/iter; left time: 79.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1225081 Vali Loss: 0.1261419 Test Loss: 0.1358858\n",
      "Validation loss decreased (0.150865 --> 0.126142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1154702\n",
      "\tspeed: 0.0475s/iter; left time: 185.7840s\n",
      "\titers: 200, epoch: 3 | loss: 0.1208132\n",
      "\tspeed: 0.0178s/iter; left time: 67.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1134476 Vali Loss: 0.1242651 Test Loss: 0.1351330\n",
      "Validation loss decreased (0.126142 --> 0.124265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083553\n",
      "\tspeed: 0.0513s/iter; left time: 189.3084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114645\n",
      "\tspeed: 0.0250s/iter; left time: 89.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.1111535 Vali Loss: 0.1238227 Test Loss: 0.1351298\n",
      "Validation loss decreased (0.124265 --> 0.123823).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088758\n",
      "\tspeed: 0.0477s/iter; left time: 165.4829s\n",
      "\titers: 200, epoch: 5 | loss: 0.1138292\n",
      "\tspeed: 0.0210s/iter; left time: 70.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1096550 Vali Loss: 0.1237200 Test Loss: 0.1350734\n",
      "Validation loss decreased (0.123823 --> 0.123720).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060584\n",
      "\tspeed: 0.0443s/iter; left time: 143.7347s\n",
      "\titers: 200, epoch: 6 | loss: 0.1078526\n",
      "\tspeed: 0.0248s/iter; left time: 77.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.1085108 Vali Loss: 0.1237013 Test Loss: 0.1353167\n",
      "Validation loss decreased (0.123720 --> 0.123701).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056099\n",
      "\tspeed: 0.0464s/iter; left time: 140.4060s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071206\n",
      "\tspeed: 0.0201s/iter; left time: 58.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.1075053 Vali Loss: 0.1243213 Test Loss: 0.1358723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1062378\n",
      "\tspeed: 0.0443s/iter; left time: 124.1228s\n",
      "\titers: 200, epoch: 8 | loss: 0.1031721\n",
      "\tspeed: 0.0239s/iter; left time: 64.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.1066894 Vali Loss: 0.1241120 Test Loss: 0.1356260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1024874\n",
      "\tspeed: 0.0481s/iter; left time: 123.8563s\n",
      "\titers: 200, epoch: 9 | loss: 0.1056722\n",
      "\tspeed: 0.0205s/iter; left time: 50.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.1057593 Vali Loss: 0.1242756 Test Loss: 0.1355877\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090433\n",
      "\tspeed: 0.0482s/iter; left time: 113.3666s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010605\n",
      "\tspeed: 0.0210s/iter; left time: 47.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.1049365 Vali Loss: 0.1248252 Test Loss: 0.1358047\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0981197\n",
      "\tspeed: 0.0480s/iter; left time: 102.3049s\n",
      "\titers: 200, epoch: 11 | loss: 0.1002965\n",
      "\tspeed: 0.0212s/iter; left time: 43.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.1042000 Vali Loss: 0.1250085 Test Loss: 0.1355155\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04008013755083084, rmse:0.20020024478435516, mae:0.1353166252374649, rse:0.7091253995895386\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:35.93s\n",
      "Intermediate time for DE: 00h:09m:35.22s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1408029\n",
      "\tspeed: 0.0424s/iter; left time: 185.6805s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220715\n",
      "\tspeed: 0.0165s/iter; left time: 70.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1394795 Vali Loss: 0.1303381 Test Loss: 0.1521771\n",
      "Validation loss decreased (inf --> 0.130338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0838467\n",
      "\tspeed: 0.0342s/iter; left time: 142.0768s\n",
      "\titers: 200, epoch: 2 | loss: 0.0810687\n",
      "\tspeed: 0.0151s/iter; left time: 61.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0883854 Vali Loss: 0.0922935 Test Loss: 0.1038328\n",
      "Validation loss decreased (0.130338 --> 0.092294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813066\n",
      "\tspeed: 0.0338s/iter; left time: 132.8045s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811429\n",
      "\tspeed: 0.0154s/iter; left time: 58.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0800376 Vali Loss: 0.0906270 Test Loss: 0.1026502\n",
      "Validation loss decreased (0.092294 --> 0.090627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798900\n",
      "\tspeed: 0.0350s/iter; left time: 129.7337s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782969\n",
      "\tspeed: 0.0180s/iter; left time: 64.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0784506 Vali Loss: 0.0899711 Test Loss: 0.1023145\n",
      "Validation loss decreased (0.090627 --> 0.089971).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0802007\n",
      "\tspeed: 0.0393s/iter; left time: 137.0857s\n",
      "\titers: 200, epoch: 5 | loss: 0.0761889\n",
      "\tspeed: 0.0206s/iter; left time: 69.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0775106 Vali Loss: 0.0896766 Test Loss: 0.1023679\n",
      "Validation loss decreased (0.089971 --> 0.089677).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737546\n",
      "\tspeed: 0.0363s/iter; left time: 118.4605s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722272\n",
      "\tspeed: 0.0158s/iter; left time: 49.7961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0767953 Vali Loss: 0.0892543 Test Loss: 0.1016112\n",
      "Validation loss decreased (0.089677 --> 0.089254).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772201\n",
      "\tspeed: 0.0377s/iter; left time: 114.4109s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759338\n",
      "\tspeed: 0.0194s/iter; left time: 57.0688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0762198 Vali Loss: 0.0889135 Test Loss: 0.1021290\n",
      "Validation loss decreased (0.089254 --> 0.088914).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0737974\n",
      "\tspeed: 0.0405s/iter; left time: 113.9475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742771\n",
      "\tspeed: 0.0192s/iter; left time: 52.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0758061 Vali Loss: 0.0888634 Test Loss: 0.1011181\n",
      "Validation loss decreased (0.088914 --> 0.088863).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776098\n",
      "\tspeed: 0.0338s/iter; left time: 87.3904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778834\n",
      "\tspeed: 0.0150s/iter; left time: 37.2914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0754323 Vali Loss: 0.0887642 Test Loss: 0.1017987\n",
      "Validation loss decreased (0.088863 --> 0.088764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783418\n",
      "\tspeed: 0.0398s/iter; left time: 94.0227s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797399\n",
      "\tspeed: 0.0163s/iter; left time: 36.8168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0750985 Vali Loss: 0.0884259 Test Loss: 0.1014588\n",
      "Validation loss decreased (0.088764 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765481\n",
      "\tspeed: 0.0365s/iter; left time: 78.1492s\n",
      "\titers: 200, epoch: 11 | loss: 0.0767598\n",
      "\tspeed: 0.0170s/iter; left time: 34.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0748397 Vali Loss: 0.0884989 Test Loss: 0.1009134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725433\n",
      "\tspeed: 0.0376s/iter; left time: 72.0028s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751468\n",
      "\tspeed: 0.0180s/iter; left time: 32.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0746248 Vali Loss: 0.0884313 Test Loss: 0.1013561\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761357\n",
      "\tspeed: 0.0365s/iter; left time: 61.7116s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725394\n",
      "\tspeed: 0.0150s/iter; left time: 23.8190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0744325 Vali Loss: 0.0881754 Test Loss: 0.1007002\n",
      "Validation loss decreased (0.088426 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779839\n",
      "\tspeed: 0.0379s/iter; left time: 55.6193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749262\n",
      "\tspeed: 0.0159s/iter; left time: 21.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0742962 Vali Loss: 0.0882207 Test Loss: 0.1010617\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0688910\n",
      "\tspeed: 0.0348s/iter; left time: 43.3631s\n",
      "\titers: 200, epoch: 15 | loss: 0.0793659\n",
      "\tspeed: 0.0156s/iter; left time: 17.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0741033 Vali Loss: 0.0882980 Test Loss: 0.1009011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0731619\n",
      "\tspeed: 0.0335s/iter; left time: 34.2294s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750202\n",
      "\tspeed: 0.0150s/iter; left time: 13.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0739156 Vali Loss: 0.0880635 Test Loss: 0.1010218\n",
      "Validation loss decreased (0.088175 --> 0.088063).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808460\n",
      "\tspeed: 0.0389s/iter; left time: 31.0244s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702096\n",
      "\tspeed: 0.0180s/iter; left time: 12.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0738391 Vali Loss: 0.0881552 Test Loss: 0.1009193\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780886\n",
      "\tspeed: 0.0357s/iter; left time: 20.4304s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703475\n",
      "\tspeed: 0.0162s/iter; left time: 7.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0736550 Vali Loss: 0.0880305 Test Loss: 0.1005262\n",
      "Validation loss decreased (0.088063 --> 0.088030).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725428\n",
      "\tspeed: 0.0438s/iter; left time: 15.2935s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751350\n",
      "\tspeed: 0.0228s/iter; left time: 5.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0735561 Vali Loss: 0.0878773 Test Loss: 0.1006675\n",
      "Validation loss decreased (0.088030 --> 0.087877).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739074\n",
      "\tspeed: 0.0408s/iter; left time: 5.0990s\n",
      "\titers: 200, epoch: 20 | loss: 0.0685736\n",
      "\tspeed: 0.0200s/iter; left time: 0.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0734560 Vali Loss: 0.0880576 Test Loss: 0.1006947\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02571168728172779, rmse:0.16034863889217377, mae:0.10066747665405273, rse:0.553157389163971\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1426990\n",
      "\tspeed: 0.0195s/iter; left time: 85.2726s\n",
      "\titers: 200, epoch: 1 | loss: 0.1211217\n",
      "\tspeed: 0.0172s/iter; left time: 73.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1413873 Vali Loss: 0.1313342 Test Loss: 0.1529275\n",
      "Validation loss decreased (inf --> 0.131334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920208\n",
      "\tspeed: 0.0401s/iter; left time: 166.6888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922285\n",
      "\tspeed: 0.0192s/iter; left time: 77.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0886714 Vali Loss: 0.0918820 Test Loss: 0.1031965\n",
      "Validation loss decreased (0.131334 --> 0.091882).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0745580\n",
      "\tspeed: 0.0417s/iter; left time: 164.1112s\n",
      "\titers: 200, epoch: 3 | loss: 0.0770032\n",
      "\tspeed: 0.0201s/iter; left time: 76.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0800178 Vali Loss: 0.0907631 Test Loss: 0.1022072\n",
      "Validation loss decreased (0.091882 --> 0.090763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0781393\n",
      "\tspeed: 0.0411s/iter; left time: 152.2818s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811933\n",
      "\tspeed: 0.0176s/iter; left time: 63.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0783863 Vali Loss: 0.0900284 Test Loss: 0.1022384\n",
      "Validation loss decreased (0.090763 --> 0.090028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737690\n",
      "\tspeed: 0.0382s/iter; left time: 133.0965s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782653\n",
      "\tspeed: 0.0194s/iter; left time: 65.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0774529 Vali Loss: 0.0898817 Test Loss: 0.1026760\n",
      "Validation loss decreased (0.090028 --> 0.089882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752798\n",
      "\tspeed: 0.0395s/iter; left time: 128.7059s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756785\n",
      "\tspeed: 0.0217s/iter; left time: 68.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0895181 Test Loss: 0.1017127\n",
      "Validation loss decreased (0.089882 --> 0.089518).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0777912\n",
      "\tspeed: 0.0470s/iter; left time: 142.7631s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742693\n",
      "\tspeed: 0.0179s/iter; left time: 52.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0762158 Vali Loss: 0.0888710 Test Loss: 0.1015809\n",
      "Validation loss decreased (0.089518 --> 0.088871).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770149\n",
      "\tspeed: 0.0380s/iter; left time: 106.9351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0693960\n",
      "\tspeed: 0.0201s/iter; left time: 54.5469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0758130 Vali Loss: 0.0889070 Test Loss: 0.1015775\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0743423\n",
      "\tspeed: 0.0372s/iter; left time: 96.4258s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789250\n",
      "\tspeed: 0.0180s/iter; left time: 44.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0754435 Vali Loss: 0.0887747 Test Loss: 0.1010644\n",
      "Validation loss decreased (0.088871 --> 0.088775).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688218\n",
      "\tspeed: 0.0387s/iter; left time: 91.5577s\n",
      "\titers: 200, epoch: 10 | loss: 0.0740221\n",
      "\tspeed: 0.0170s/iter; left time: 38.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0751218 Vali Loss: 0.0890175 Test Loss: 0.1013409\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767177\n",
      "\tspeed: 0.0385s/iter; left time: 82.4044s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711599\n",
      "\tspeed: 0.0177s/iter; left time: 36.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0748408 Vali Loss: 0.0884742 Test Loss: 0.1006243\n",
      "Validation loss decreased (0.088775 --> 0.088474).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774689\n",
      "\tspeed: 0.0385s/iter; left time: 73.8126s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763765\n",
      "\tspeed: 0.0154s/iter; left time: 27.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0746103 Vali Loss: 0.0887545 Test Loss: 0.1008374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0736466\n",
      "\tspeed: 0.0358s/iter; left time: 60.6607s\n",
      "\titers: 200, epoch: 13 | loss: 0.0663546\n",
      "\tspeed: 0.0150s/iter; left time: 23.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.0743160 Vali Loss: 0.0881196 Test Loss: 0.1011693\n",
      "Validation loss decreased (0.088474 --> 0.088120).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0722639\n",
      "\tspeed: 0.0377s/iter; left time: 55.4206s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726922\n",
      "\tspeed: 0.0184s/iter; left time: 25.2504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0741482 Vali Loss: 0.0883620 Test Loss: 0.1010674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0765208\n",
      "\tspeed: 0.0353s/iter; left time: 43.9686s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766634\n",
      "\tspeed: 0.0150s/iter; left time: 17.1451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0740250 Vali Loss: 0.0881034 Test Loss: 0.1007322\n",
      "Validation loss decreased (0.088120 --> 0.088103).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0711784\n",
      "\tspeed: 0.0361s/iter; left time: 36.8920s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745880\n",
      "\tspeed: 0.0206s/iter; left time: 18.9776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0738376 Vali Loss: 0.0881364 Test Loss: 0.1007151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0753264\n",
      "\tspeed: 0.0364s/iter; left time: 29.0347s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706248\n",
      "\tspeed: 0.0158s/iter; left time: 11.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0738016 Vali Loss: 0.0879273 Test Loss: 0.1009507\n",
      "Validation loss decreased (0.088103 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0711455\n",
      "\tspeed: 0.0366s/iter; left time: 20.9634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0713051\n",
      "\tspeed: 0.0170s/iter; left time: 8.0330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0736541 Vali Loss: 0.0879129 Test Loss: 0.1007606\n",
      "Validation loss decreased (0.087927 --> 0.087913).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0688030\n",
      "\tspeed: 0.0373s/iter; left time: 13.0311s\n",
      "\titers: 200, epoch: 19 | loss: 0.0771854\n",
      "\tspeed: 0.0149s/iter; left time: 3.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0734884 Vali Loss: 0.0880213 Test Loss: 0.1003741\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746141\n",
      "\tspeed: 0.0394s/iter; left time: 4.9288s\n",
      "\titers: 200, epoch: 20 | loss: 0.0727115\n",
      "\tspeed: 0.0148s/iter; left time: 0.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0734077 Vali Loss: 0.0879809 Test Loss: 0.1004589\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02565145492553711, rmse:0.16016072034835815, mae:0.10076063871383667, rse:0.552509069442749\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:52.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1464807\n",
      "\tspeed: 0.0435s/iter; left time: 190.6409s\n",
      "\titers: 200, epoch: 1 | loss: 0.1339110\n",
      "\tspeed: 0.0162s/iter; left time: 69.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1435963 Vali Loss: 0.1385392 Test Loss: 0.1633495\n",
      "Validation loss decreased (inf --> 0.138539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108301\n",
      "\tspeed: 0.0391s/iter; left time: 162.3790s\n",
      "\titers: 200, epoch: 2 | loss: 0.1111001\n",
      "\tspeed: 0.0208s/iter; left time: 84.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1108053 Vali Loss: 0.1185568 Test Loss: 0.1400027\n",
      "Validation loss decreased (0.138539 --> 0.118557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053875\n",
      "\tspeed: 0.0374s/iter; left time: 147.0325s\n",
      "\titers: 200, epoch: 3 | loss: 0.1026320\n",
      "\tspeed: 0.0152s/iter; left time: 58.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.1047060 Vali Loss: 0.1174756 Test Loss: 0.1414031\n",
      "Validation loss decreased (0.118557 --> 0.117476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1013440\n",
      "\tspeed: 0.0400s/iter; left time: 148.4403s\n",
      "\titers: 200, epoch: 4 | loss: 0.1018285\n",
      "\tspeed: 0.0184s/iter; left time: 66.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1030777 Vali Loss: 0.1173579 Test Loss: 0.1412462\n",
      "Validation loss decreased (0.117476 --> 0.117358).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023715\n",
      "\tspeed: 0.0375s/iter; left time: 130.8499s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012354\n",
      "\tspeed: 0.0169s/iter; left time: 57.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.1020954 Vali Loss: 0.1173018 Test Loss: 0.1421996\n",
      "Validation loss decreased (0.117358 --> 0.117302).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1005838\n",
      "\tspeed: 0.0380s/iter; left time: 123.8168s\n",
      "\titers: 200, epoch: 6 | loss: 0.0990829\n",
      "\tspeed: 0.0166s/iter; left time: 52.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1010528 Vali Loss: 0.1163672 Test Loss: 0.1405692\n",
      "Validation loss decreased (0.117302 --> 0.116367).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036074\n",
      "\tspeed: 0.0424s/iter; left time: 128.6447s\n",
      "\titers: 200, epoch: 7 | loss: 0.0971777\n",
      "\tspeed: 0.0189s/iter; left time: 55.6022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1001650 Vali Loss: 0.1160881 Test Loss: 0.1422270\n",
      "Validation loss decreased (0.116367 --> 0.116088).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0971712\n",
      "\tspeed: 0.0382s/iter; left time: 107.3734s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009590\n",
      "\tspeed: 0.0182s/iter; left time: 49.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0993132 Vali Loss: 0.1162736 Test Loss: 0.1431388\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0981892\n",
      "\tspeed: 0.0391s/iter; left time: 101.2879s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977690\n",
      "\tspeed: 0.0182s/iter; left time: 45.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0985008 Vali Loss: 0.1168711 Test Loss: 0.1422294\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0964508\n",
      "\tspeed: 0.0403s/iter; left time: 95.2770s\n",
      "\titers: 200, epoch: 10 | loss: 0.1008207\n",
      "\tspeed: 0.0168s/iter; left time: 38.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0979480 Vali Loss: 0.1169810 Test Loss: 0.1432338\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0970866\n",
      "\tspeed: 0.0395s/iter; left time: 84.6755s\n",
      "\titers: 200, epoch: 11 | loss: 0.1026615\n",
      "\tspeed: 0.0180s/iter; left time: 36.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0973957 Vali Loss: 0.1166952 Test Loss: 0.1422242\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0952063\n",
      "\tspeed: 0.0383s/iter; left time: 73.3493s\n",
      "\titers: 200, epoch: 12 | loss: 0.0954418\n",
      "\tspeed: 0.0165s/iter; left time: 30.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0969392 Vali Loss: 0.1171512 Test Loss: 0.1435936\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0437089167535305, rmse:0.20906677842140198, mae:0.1422269642353058, rse:0.7229820489883423\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1439789\n",
      "\tspeed: 0.0228s/iter; left time: 99.9117s\n",
      "\titers: 200, epoch: 1 | loss: 0.1328941\n",
      "\tspeed: 0.0156s/iter; left time: 66.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1449440 Vali Loss: 0.1393162 Test Loss: 0.1642354\n",
      "Validation loss decreased (inf --> 0.139316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1103907\n",
      "\tspeed: 0.0421s/iter; left time: 175.1712s\n",
      "\titers: 200, epoch: 2 | loss: 0.1076906\n",
      "\tspeed: 0.0195s/iter; left time: 79.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1110408 Vali Loss: 0.1183176 Test Loss: 0.1402512\n",
      "Validation loss decreased (0.139316 --> 0.118318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1067609\n",
      "\tspeed: 0.0430s/iter; left time: 169.3079s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033380\n",
      "\tspeed: 0.0182s/iter; left time: 69.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1046272 Vali Loss: 0.1173224 Test Loss: 0.1405597\n",
      "Validation loss decreased (0.118318 --> 0.117322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016744\n",
      "\tspeed: 0.0430s/iter; left time: 159.3347s\n",
      "\titers: 200, epoch: 4 | loss: 0.1019102\n",
      "\tspeed: 0.0152s/iter; left time: 54.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1028988 Vali Loss: 0.1164952 Test Loss: 0.1403949\n",
      "Validation loss decreased (0.117322 --> 0.116495).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0999806\n",
      "\tspeed: 0.0449s/iter; left time: 156.4266s\n",
      "\titers: 200, epoch: 5 | loss: 0.0994685\n",
      "\tspeed: 0.0183s/iter; left time: 61.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.1016366 Vali Loss: 0.1166272 Test Loss: 0.1419465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0996835\n",
      "\tspeed: 0.0414s/iter; left time: 134.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.1023989\n",
      "\tspeed: 0.0210s/iter; left time: 66.3406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.1004053 Vali Loss: 0.1166868 Test Loss: 0.1411362\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1032335\n",
      "\tspeed: 0.0438s/iter; left time: 133.0098s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959763\n",
      "\tspeed: 0.0198s/iter; left time: 58.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0994704 Vali Loss: 0.1167028 Test Loss: 0.1412249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1004868\n",
      "\tspeed: 0.0421s/iter; left time: 118.3224s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041749\n",
      "\tspeed: 0.0239s/iter; left time: 64.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0985223 Vali Loss: 0.1168587 Test Loss: 0.1418633\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0998969\n",
      "\tspeed: 0.0459s/iter; left time: 118.9141s\n",
      "\titers: 200, epoch: 9 | loss: 0.1022366\n",
      "\tspeed: 0.0203s/iter; left time: 50.5367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0977101 Vali Loss: 0.1178647 Test Loss: 0.1424285\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04227694496512413, rmse:0.20561358332633972, mae:0.14039494097232819, rse:0.7110404372215271\n",
      "Intermediate time for GB and pred_len 96: 00h:02m:16.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1477975\n",
      "\tspeed: 0.0437s/iter; left time: 190.7858s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0155s/iter; left time: 65.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1446544 Vali Loss: 0.1404012 Test Loss: 0.1657628\n",
      "Validation loss decreased (inf --> 0.140401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182125\n",
      "\tspeed: 0.0385s/iter; left time: 159.2865s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102384\n",
      "\tspeed: 0.0198s/iter; left time: 79.8195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.1153861 Vali Loss: 0.1230363 Test Loss: 0.1469368\n",
      "Validation loss decreased (0.140401 --> 0.123036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1079936\n",
      "\tspeed: 0.0375s/iter; left time: 146.7049s\n",
      "\titers: 200, epoch: 3 | loss: 0.1093975\n",
      "\tspeed: 0.0190s/iter; left time: 72.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1094925 Vali Loss: 0.1216000 Test Loss: 0.1470946\n",
      "Validation loss decreased (0.123036 --> 0.121600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1063738\n",
      "\tspeed: 0.0418s/iter; left time: 154.2251s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092678\n",
      "\tspeed: 0.0156s/iter; left time: 55.8621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1076454 Vali Loss: 0.1222603 Test Loss: 0.1490110\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1073611\n",
      "\tspeed: 0.0423s/iter; left time: 146.8959s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071665\n",
      "\tspeed: 0.0173s/iter; left time: 58.1757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.1062244 Vali Loss: 0.1216785 Test Loss: 0.1476179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1029608\n",
      "\tspeed: 0.0364s/iter; left time: 118.0313s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022937\n",
      "\tspeed: 0.0154s/iter; left time: 48.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1047133 Vali Loss: 0.1216168 Test Loss: 0.1480931\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014383\n",
      "\tspeed: 0.0357s/iter; left time: 107.7792s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044426\n",
      "\tspeed: 0.0160s/iter; left time: 46.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.1036095 Vali Loss: 0.1215207 Test Loss: 0.1481168\n",
      "Validation loss decreased (0.121600 --> 0.121521).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1046117\n",
      "\tspeed: 0.0379s/iter; left time: 106.1302s\n",
      "\titers: 200, epoch: 8 | loss: 0.1001345\n",
      "\tspeed: 0.0167s/iter; left time: 45.0132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1027809 Vali Loss: 0.1216274 Test Loss: 0.1474974\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1017520\n",
      "\tspeed: 0.0412s/iter; left time: 106.1024s\n",
      "\titers: 200, epoch: 9 | loss: 0.1024707\n",
      "\tspeed: 0.0187s/iter; left time: 46.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1020090 Vali Loss: 0.1216672 Test Loss: 0.1507545\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1014575\n",
      "\tspeed: 0.0414s/iter; left time: 97.4141s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068425\n",
      "\tspeed: 0.0186s/iter; left time: 41.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.1013790 Vali Loss: 0.1224590 Test Loss: 0.1511485\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1007545\n",
      "\tspeed: 0.0361s/iter; left time: 76.9678s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064068\n",
      "\tspeed: 0.0181s/iter; left time: 36.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1008511 Vali Loss: 0.1220196 Test Loss: 0.1480358\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996748\n",
      "\tspeed: 0.0388s/iter; left time: 74.0453s\n",
      "\titers: 200, epoch: 12 | loss: 0.1018326\n",
      "\tspeed: 0.0189s/iter; left time: 34.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1003750 Vali Loss: 0.1224540 Test Loss: 0.1507005\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045974038541316986, rmse:0.21441558003425598, mae:0.14811687171459198, rse:0.7434096336364746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1442559\n",
      "\tspeed: 0.0243s/iter; left time: 106.1808s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326391\n",
      "\tspeed: 0.0216s/iter; left time: 92.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.1444806 Vali Loss: 0.1397840 Test Loss: 0.1651134\n",
      "Validation loss decreased (inf --> 0.139784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1153733\n",
      "\tspeed: 0.0416s/iter; left time: 172.0214s\n",
      "\titers: 200, epoch: 2 | loss: 0.1158109\n",
      "\tspeed: 0.0206s/iter; left time: 82.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1152481 Vali Loss: 0.1229677 Test Loss: 0.1469946\n",
      "Validation loss decreased (0.139784 --> 0.122968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091751\n",
      "\tspeed: 0.0368s/iter; left time: 144.1029s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076952\n",
      "\tspeed: 0.0156s/iter; left time: 59.3233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1093861 Vali Loss: 0.1221740 Test Loss: 0.1474206\n",
      "Validation loss decreased (0.122968 --> 0.122174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1105811\n",
      "\tspeed: 0.0360s/iter; left time: 132.7568s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094957\n",
      "\tspeed: 0.0155s/iter; left time: 55.5114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1075535 Vali Loss: 0.1213268 Test Loss: 0.1465728\n",
      "Validation loss decreased (0.122174 --> 0.121327).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1022354\n",
      "\tspeed: 0.0436s/iter; left time: 151.1733s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052392\n",
      "\tspeed: 0.0181s/iter; left time: 61.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1060023 Vali Loss: 0.1212835 Test Loss: 0.1484088\n",
      "Validation loss decreased (0.121327 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052048\n",
      "\tspeed: 0.0445s/iter; left time: 144.3411s\n",
      "\titers: 200, epoch: 6 | loss: 0.1029654\n",
      "\tspeed: 0.0177s/iter; left time: 55.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1045905 Vali Loss: 0.1220015 Test Loss: 0.1495936\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1045707\n",
      "\tspeed: 0.0430s/iter; left time: 129.9057s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025629\n",
      "\tspeed: 0.0222s/iter; left time: 64.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.1034090 Vali Loss: 0.1213634 Test Loss: 0.1484459\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1005384\n",
      "\tspeed: 0.0391s/iter; left time: 109.3929s\n",
      "\titers: 200, epoch: 8 | loss: 0.1052553\n",
      "\tspeed: 0.0180s/iter; left time: 48.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.1025041 Vali Loss: 0.1215598 Test Loss: 0.1484736\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1018901\n",
      "\tspeed: 0.0399s/iter; left time: 102.9456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990130\n",
      "\tspeed: 0.0174s/iter; left time: 43.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1017117 Vali Loss: 0.1214209 Test Loss: 0.1495841\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0977279\n",
      "\tspeed: 0.0411s/iter; left time: 96.6954s\n",
      "\titers: 200, epoch: 10 | loss: 0.0962834\n",
      "\tspeed: 0.0192s/iter; left time: 43.3529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1010290 Vali Loss: 0.1213298 Test Loss: 0.1499632\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04563125967979431, rmse:0.21361474692821503, mae:0.14840884506702423, rse:0.7406330108642578\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:20.19s\n",
      "Intermediate time for GB: 00h:08m:28.92s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1472617\n",
      "\tspeed: 0.0412s/iter; left time: 180.2869s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270657\n",
      "\tspeed: 0.0127s/iter; left time: 54.5502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1529596 Vali Loss: 0.1144776 Test Loss: 0.1285696\n",
      "Validation loss decreased (inf --> 0.114478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0764008\n",
      "\tspeed: 0.0341s/iter; left time: 141.8398s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672378\n",
      "\tspeed: 0.0179s/iter; left time: 72.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0811919 Vali Loss: 0.0650535 Test Loss: 0.0721725\n",
      "Validation loss decreased (0.114478 --> 0.065053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697924\n",
      "\tspeed: 0.0353s/iter; left time: 138.9887s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655599\n",
      "\tspeed: 0.0138s/iter; left time: 53.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0678223 Vali Loss: 0.0616374 Test Loss: 0.0684299\n",
      "Validation loss decreased (0.065053 --> 0.061637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0617359\n",
      "\tspeed: 0.0341s/iter; left time: 126.3767s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651039\n",
      "\tspeed: 0.0180s/iter; left time: 64.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0643864 Vali Loss: 0.0593651 Test Loss: 0.0659961\n",
      "Validation loss decreased (0.061637 --> 0.059365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612776\n",
      "\tspeed: 0.0348s/iter; left time: 121.1898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621016\n",
      "\tspeed: 0.0161s/iter; left time: 54.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0622860 Vali Loss: 0.0583341 Test Loss: 0.0648153\n",
      "Validation loss decreased (0.059365 --> 0.058334).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601563\n",
      "\tspeed: 0.0374s/iter; left time: 122.1215s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582275\n",
      "\tspeed: 0.0190s/iter; left time: 60.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0573691 Test Loss: 0.0637348\n",
      "Validation loss decreased (0.058334 --> 0.057369).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599583\n",
      "\tspeed: 0.0396s/iter; left time: 120.4027s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620039\n",
      "\tspeed: 0.0201s/iter; left time: 59.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0597635 Vali Loss: 0.0567544 Test Loss: 0.0630717\n",
      "Validation loss decreased (0.057369 --> 0.056754).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591449\n",
      "\tspeed: 0.0396s/iter; left time: 111.3214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0592528\n",
      "\tspeed: 0.0203s/iter; left time: 54.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0589754 Vali Loss: 0.0563358 Test Loss: 0.0625656\n",
      "Validation loss decreased (0.056754 --> 0.056336).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0572533\n",
      "\tspeed: 0.0384s/iter; left time: 99.4849s\n",
      "\titers: 200, epoch: 9 | loss: 0.0543959\n",
      "\tspeed: 0.0196s/iter; left time: 48.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0582308 Vali Loss: 0.0558458 Test Loss: 0.0622937\n",
      "Validation loss decreased (0.056336 --> 0.055846).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586669\n",
      "\tspeed: 0.0363s/iter; left time: 85.8101s\n",
      "\titers: 200, epoch: 10 | loss: 0.0573274\n",
      "\tspeed: 0.0178s/iter; left time: 40.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0577035 Vali Loss: 0.0553874 Test Loss: 0.0618086\n",
      "Validation loss decreased (0.055846 --> 0.055387).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0590035\n",
      "\tspeed: 0.0379s/iter; left time: 81.2151s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585526\n",
      "\tspeed: 0.0204s/iter; left time: 41.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0572359 Vali Loss: 0.0551490 Test Loss: 0.0616998\n",
      "Validation loss decreased (0.055387 --> 0.055149).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0607780\n",
      "\tspeed: 0.0382s/iter; left time: 73.2975s\n",
      "\titers: 200, epoch: 12 | loss: 0.0548319\n",
      "\tspeed: 0.0222s/iter; left time: 40.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0568701 Vali Loss: 0.0549978 Test Loss: 0.0614600\n",
      "Validation loss decreased (0.055149 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575080\n",
      "\tspeed: 0.0389s/iter; left time: 65.8627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571135\n",
      "\tspeed: 0.0204s/iter; left time: 32.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0565177 Vali Loss: 0.0547642 Test Loss: 0.0613089\n",
      "Validation loss decreased (0.054998 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0551755\n",
      "\tspeed: 0.0352s/iter; left time: 51.6431s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569541\n",
      "\tspeed: 0.0184s/iter; left time: 25.2481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0561891 Vali Loss: 0.0546994 Test Loss: 0.0611044\n",
      "Validation loss decreased (0.054764 --> 0.054699).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0515674\n",
      "\tspeed: 0.0373s/iter; left time: 46.4350s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551809\n",
      "\tspeed: 0.0194s/iter; left time: 22.1801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0559423 Vali Loss: 0.0544962 Test Loss: 0.0609704\n",
      "Validation loss decreased (0.054699 --> 0.054496).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0602068\n",
      "\tspeed: 0.0395s/iter; left time: 40.3303s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552587\n",
      "\tspeed: 0.0202s/iter; left time: 18.5892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0557383 Vali Loss: 0.0544265 Test Loss: 0.0608705\n",
      "Validation loss decreased (0.054496 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0534508\n",
      "\tspeed: 0.0394s/iter; left time: 31.3686s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564713\n",
      "\tspeed: 0.0197s/iter; left time: 13.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0555938 Vali Loss: 0.0543226 Test Loss: 0.0608117\n",
      "Validation loss decreased (0.054427 --> 0.054323).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573428\n",
      "\tspeed: 0.0465s/iter; left time: 26.6437s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537848\n",
      "\tspeed: 0.0228s/iter; left time: 10.7701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0554106 Vali Loss: 0.0542706 Test Loss: 0.0606971\n",
      "Validation loss decreased (0.054323 --> 0.054271).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550534\n",
      "\tspeed: 0.0384s/iter; left time: 13.3870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0558107\n",
      "\tspeed: 0.0202s/iter; left time: 5.0294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0552027 Vali Loss: 0.0540916 Test Loss: 0.0605637\n",
      "Validation loss decreased (0.054271 --> 0.054092).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0584598\n",
      "\tspeed: 0.0379s/iter; left time: 4.7429s\n",
      "\titers: 200, epoch: 20 | loss: 0.0512681\n",
      "\tspeed: 0.0166s/iter; left time: 0.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0551428 Vali Loss: 0.0540117 Test Loss: 0.0604790\n",
      "Validation loss decreased (0.054092 --> 0.054012).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009945221245288849, rmse:0.09972573071718216, mae:0.06047904118895531, rse:0.2934807538986206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1553000\n",
      "\tspeed: 0.0218s/iter; left time: 95.3743s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247295\n",
      "\tspeed: 0.0202s/iter; left time: 86.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1551215 Vali Loss: 0.1149629 Test Loss: 0.1298781\n",
      "Validation loss decreased (inf --> 0.114963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0781470\n",
      "\tspeed: 0.0393s/iter; left time: 163.2841s\n",
      "\titers: 200, epoch: 2 | loss: 0.0671686\n",
      "\tspeed: 0.0205s/iter; left time: 83.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0811051 Vali Loss: 0.0649167 Test Loss: 0.0716186\n",
      "Validation loss decreased (0.114963 --> 0.064917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0684837\n",
      "\tspeed: 0.0393s/iter; left time: 154.5540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675542\n",
      "\tspeed: 0.0202s/iter; left time: 77.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0675214 Vali Loss: 0.0610192 Test Loss: 0.0676137\n",
      "Validation loss decreased (0.064917 --> 0.061019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637207\n",
      "\tspeed: 0.0387s/iter; left time: 143.7097s\n",
      "\titers: 200, epoch: 4 | loss: 0.0624713\n",
      "\tspeed: 0.0203s/iter; left time: 73.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0641497 Vali Loss: 0.0590834 Test Loss: 0.0656485\n",
      "Validation loss decreased (0.061019 --> 0.059083).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0607330\n",
      "\tspeed: 0.0377s/iter; left time: 131.3658s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578555\n",
      "\tspeed: 0.0184s/iter; left time: 62.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0619703 Vali Loss: 0.0577241 Test Loss: 0.0642229\n",
      "Validation loss decreased (0.059083 --> 0.057724).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588913\n",
      "\tspeed: 0.0352s/iter; left time: 114.7175s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617361\n",
      "\tspeed: 0.0168s/iter; left time: 52.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0604744 Vali Loss: 0.0567848 Test Loss: 0.0632507\n",
      "Validation loss decreased (0.057724 --> 0.056785).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595140\n",
      "\tspeed: 0.0369s/iter; left time: 111.9496s\n",
      "\titers: 200, epoch: 7 | loss: 0.0564100\n",
      "\tspeed: 0.0180s/iter; left time: 52.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0593902 Vali Loss: 0.0560765 Test Loss: 0.0625553\n",
      "Validation loss decreased (0.056785 --> 0.056077).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591547\n",
      "\tspeed: 0.0396s/iter; left time: 111.2926s\n",
      "\titers: 200, epoch: 8 | loss: 0.0573535\n",
      "\tspeed: 0.0201s/iter; left time: 54.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0585845 Vali Loss: 0.0560133 Test Loss: 0.0626201\n",
      "Validation loss decreased (0.056077 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578105\n",
      "\tspeed: 0.0419s/iter; left time: 108.5637s\n",
      "\titers: 200, epoch: 9 | loss: 0.0604850\n",
      "\tspeed: 0.0222s/iter; left time: 55.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0579322 Vali Loss: 0.0554106 Test Loss: 0.0619923\n",
      "Validation loss decreased (0.056013 --> 0.055411).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0556527\n",
      "\tspeed: 0.0443s/iter; left time: 104.6548s\n",
      "\titers: 200, epoch: 10 | loss: 0.0583164\n",
      "\tspeed: 0.0252s/iter; left time: 56.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0574518 Vali Loss: 0.0549543 Test Loss: 0.0615554\n",
      "Validation loss decreased (0.055411 --> 0.054954).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0548618\n",
      "\tspeed: 0.0438s/iter; left time: 93.8771s\n",
      "\titers: 200, epoch: 11 | loss: 0.0545545\n",
      "\tspeed: 0.0245s/iter; left time: 50.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0569497 Vali Loss: 0.0548729 Test Loss: 0.0612393\n",
      "Validation loss decreased (0.054954 --> 0.054873).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0544791\n",
      "\tspeed: 0.0435s/iter; left time: 83.3301s\n",
      "\titers: 200, epoch: 12 | loss: 0.0538325\n",
      "\tspeed: 0.0212s/iter; left time: 38.5365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0566214 Vali Loss: 0.0546680 Test Loss: 0.0612363\n",
      "Validation loss decreased (0.054873 --> 0.054668).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540088\n",
      "\tspeed: 0.0411s/iter; left time: 69.5690s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555825\n",
      "\tspeed: 0.0197s/iter; left time: 31.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0563721 Vali Loss: 0.0545967 Test Loss: 0.0610147\n",
      "Validation loss decreased (0.054668 --> 0.054597).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0573891\n",
      "\tspeed: 0.0397s/iter; left time: 58.3791s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538194\n",
      "\tspeed: 0.0209s/iter; left time: 28.5463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0560146 Vali Loss: 0.0544852 Test Loss: 0.0608968\n",
      "Validation loss decreased (0.054597 --> 0.054485).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0551107\n",
      "\tspeed: 0.0395s/iter; left time: 49.1692s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553436\n",
      "\tspeed: 0.0202s/iter; left time: 23.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0558149 Vali Loss: 0.0543989 Test Loss: 0.0609039\n",
      "Validation loss decreased (0.054485 --> 0.054399).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0507123\n",
      "\tspeed: 0.0388s/iter; left time: 39.6474s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580228\n",
      "\tspeed: 0.0203s/iter; left time: 18.6932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0556427 Vali Loss: 0.0542605 Test Loss: 0.0608238\n",
      "Validation loss decreased (0.054399 --> 0.054260).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570526\n",
      "\tspeed: 0.0407s/iter; left time: 32.4210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0551444\n",
      "\tspeed: 0.0195s/iter; left time: 13.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0554497 Vali Loss: 0.0540213 Test Loss: 0.0604897\n",
      "Validation loss decreased (0.054260 --> 0.054021).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570715\n",
      "\tspeed: 0.0388s/iter; left time: 22.2410s\n",
      "\titers: 200, epoch: 18 | loss: 0.0547936\n",
      "\tspeed: 0.0203s/iter; left time: 9.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0552571 Vali Loss: 0.0539653 Test Loss: 0.0604616\n",
      "Validation loss decreased (0.054021 --> 0.053965).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0549879\n",
      "\tspeed: 0.0391s/iter; left time: 13.6577s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532886\n",
      "\tspeed: 0.0202s/iter; left time: 5.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0551491 Vali Loss: 0.0540239 Test Loss: 0.0605049\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0501008\n",
      "\tspeed: 0.0385s/iter; left time: 4.8098s\n",
      "\titers: 200, epoch: 20 | loss: 0.0541760\n",
      "\tspeed: 0.0200s/iter; left time: 0.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0550170 Vali Loss: 0.0539391 Test Loss: 0.0604577\n",
      "Validation loss decreased (0.053965 --> 0.053939).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009968351572751999, rmse:0.0998416319489479, mae:0.060457728803157806, rse:0.2938218414783478\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:04.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1598105\n",
      "\tspeed: 0.0401s/iter; left time: 175.4931s\n",
      "\titers: 200, epoch: 1 | loss: 0.1323677\n",
      "\tspeed: 0.0112s/iter; left time: 47.9993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.1563091 Vali Loss: 0.1220054 Test Loss: 0.1378020\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989023\n",
      "\tspeed: 0.0328s/iter; left time: 136.3720s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922406\n",
      "\tspeed: 0.0158s/iter; left time: 63.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0986842 Vali Loss: 0.0867798 Test Loss: 0.0978109\n",
      "Validation loss decreased (0.122005 --> 0.086780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870436\n",
      "\tspeed: 0.0340s/iter; left time: 133.7073s\n",
      "\titers: 200, epoch: 3 | loss: 0.0854841\n",
      "\tspeed: 0.0159s/iter; left time: 60.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 224 | Train Loss: 0.0874289 Vali Loss: 0.0815691 Test Loss: 0.0928535\n",
      "Validation loss decreased (0.086780 --> 0.081569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0864892\n",
      "\tspeed: 0.0353s/iter; left time: 131.0243s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789671\n",
      "\tspeed: 0.0178s/iter; left time: 64.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0836981 Vali Loss: 0.0796518 Test Loss: 0.0907823\n",
      "Validation loss decreased (0.081569 --> 0.079652).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813103\n",
      "\tspeed: 0.0408s/iter; left time: 142.0285s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827484\n",
      "\tspeed: 0.0219s/iter; left time: 74.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0816990 Vali Loss: 0.0787125 Test Loss: 0.0895975\n",
      "Validation loss decreased (0.079652 --> 0.078713).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800737\n",
      "\tspeed: 0.0395s/iter; left time: 128.9424s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752990\n",
      "\tspeed: 0.0188s/iter; left time: 59.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0803113 Vali Loss: 0.0778247 Test Loss: 0.0889565\n",
      "Validation loss decreased (0.078713 --> 0.077825).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789210\n",
      "\tspeed: 0.0391s/iter; left time: 118.6672s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756818\n",
      "\tspeed: 0.0196s/iter; left time: 57.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0792497 Vali Loss: 0.0773080 Test Loss: 0.0883113\n",
      "Validation loss decreased (0.077825 --> 0.077308).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0813592\n",
      "\tspeed: 0.0396s/iter; left time: 111.4328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797191\n",
      "\tspeed: 0.0199s/iter; left time: 54.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0784300 Vali Loss: 0.0769897 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.077308 --> 0.076990).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778591\n",
      "\tspeed: 0.0396s/iter; left time: 102.4201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800109\n",
      "\tspeed: 0.0200s/iter; left time: 49.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0777183 Vali Loss: 0.0771957 Test Loss: 0.0878055\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0771751\n",
      "\tspeed: 0.0381s/iter; left time: 90.0467s\n",
      "\titers: 200, epoch: 10 | loss: 0.0770075\n",
      "\tspeed: 0.0202s/iter; left time: 45.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0771960 Vali Loss: 0.0773262 Test Loss: 0.0880145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753757\n",
      "\tspeed: 0.0431s/iter; left time: 92.1770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774721\n",
      "\tspeed: 0.0223s/iter; left time: 45.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0767264 Vali Loss: 0.0769818 Test Loss: 0.0878005\n",
      "Validation loss decreased (0.076990 --> 0.076982).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767876\n",
      "\tspeed: 0.0367s/iter; left time: 70.4280s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779550\n",
      "\tspeed: 0.0195s/iter; left time: 35.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0763607 Vali Loss: 0.0771153 Test Loss: 0.0876895\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749844\n",
      "\tspeed: 0.0345s/iter; left time: 58.4263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752065\n",
      "\tspeed: 0.0190s/iter; left time: 30.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0760326 Vali Loss: 0.0774750 Test Loss: 0.0875740\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715508\n",
      "\tspeed: 0.0392s/iter; left time: 57.5459s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734959\n",
      "\tspeed: 0.0201s/iter; left time: 27.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0756991 Vali Loss: 0.0771718 Test Loss: 0.0875562\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778454\n",
      "\tspeed: 0.0388s/iter; left time: 48.3257s\n",
      "\titers: 200, epoch: 15 | loss: 0.0767315\n",
      "\tspeed: 0.0198s/iter; left time: 22.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0753907 Vali Loss: 0.0773028 Test Loss: 0.0875162\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736728\n",
      "\tspeed: 0.0419s/iter; left time: 42.8196s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731484\n",
      "\tspeed: 0.0185s/iter; left time: 17.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0752085 Vali Loss: 0.0774523 Test Loss: 0.0875667\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01882317289710045, rmse:0.1371975690126419, mae:0.08780049532651901, rse:0.4030451774597168\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1586675\n",
      "\tspeed: 0.0271s/iter; left time: 118.7130s\n",
      "\titers: 200, epoch: 1 | loss: 0.1347368\n",
      "\tspeed: 0.0205s/iter; left time: 87.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1596458 Vali Loss: 0.1252369 Test Loss: 0.1413600\n",
      "Validation loss decreased (inf --> 0.125237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0973105\n",
      "\tspeed: 0.0405s/iter; left time: 168.4245s\n",
      "\titers: 200, epoch: 2 | loss: 0.0919715\n",
      "\tspeed: 0.0176s/iter; left time: 71.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0987873 Vali Loss: 0.0861882 Test Loss: 0.0971636\n",
      "Validation loss decreased (0.125237 --> 0.086188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0884451\n",
      "\tspeed: 0.0405s/iter; left time: 159.3633s\n",
      "\titers: 200, epoch: 3 | loss: 0.0845339\n",
      "\tspeed: 0.0193s/iter; left time: 74.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0872112 Vali Loss: 0.0814862 Test Loss: 0.0928255\n",
      "Validation loss decreased (0.086188 --> 0.081486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0833561\n",
      "\tspeed: 0.0403s/iter; left time: 149.6523s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797457\n",
      "\tspeed: 0.0198s/iter; left time: 71.4450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0836548 Vali Loss: 0.0792064 Test Loss: 0.0904651\n",
      "Validation loss decreased (0.081486 --> 0.079206).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833495\n",
      "\tspeed: 0.0374s/iter; left time: 130.3644s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785904\n",
      "\tspeed: 0.0191s/iter; left time: 64.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0815392 Vali Loss: 0.0780693 Test Loss: 0.0891974\n",
      "Validation loss decreased (0.079206 --> 0.078069).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0823942\n",
      "\tspeed: 0.0445s/iter; left time: 145.1038s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776357\n",
      "\tspeed: 0.0198s/iter; left time: 62.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0802429 Vali Loss: 0.0776718 Test Loss: 0.0885830\n",
      "Validation loss decreased (0.078069 --> 0.077672).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760843\n",
      "\tspeed: 0.0387s/iter; left time: 117.5909s\n",
      "\titers: 200, epoch: 7 | loss: 0.0813600\n",
      "\tspeed: 0.0194s/iter; left time: 57.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0792072 Vali Loss: 0.0770249 Test Loss: 0.0881912\n",
      "Validation loss decreased (0.077672 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847419\n",
      "\tspeed: 0.0442s/iter; left time: 124.3475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0802124\n",
      "\tspeed: 0.0202s/iter; left time: 54.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0783518 Vali Loss: 0.0768772 Test Loss: 0.0881146\n",
      "Validation loss decreased (0.077025 --> 0.076877).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780947\n",
      "\tspeed: 0.0400s/iter; left time: 103.5116s\n",
      "\titers: 200, epoch: 9 | loss: 0.0782000\n",
      "\tspeed: 0.0206s/iter; left time: 51.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0777154 Vali Loss: 0.0767927 Test Loss: 0.0879633\n",
      "Validation loss decreased (0.076877 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743289\n",
      "\tspeed: 0.0382s/iter; left time: 90.3251s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774140\n",
      "\tspeed: 0.0198s/iter; left time: 44.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0771349 Vali Loss: 0.0765736 Test Loss: 0.0879690\n",
      "Validation loss decreased (0.076793 --> 0.076574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0775898\n",
      "\tspeed: 0.0400s/iter; left time: 85.5925s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786252\n",
      "\tspeed: 0.0203s/iter; left time: 41.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0767193 Vali Loss: 0.0769068 Test Loss: 0.0878833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767183\n",
      "\tspeed: 0.0392s/iter; left time: 75.1352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0758710\n",
      "\tspeed: 0.0208s/iter; left time: 37.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0762718 Vali Loss: 0.0762427 Test Loss: 0.0877495\n",
      "Validation loss decreased (0.076574 --> 0.076243).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757547\n",
      "\tspeed: 0.0451s/iter; left time: 76.3469s\n",
      "\titers: 200, epoch: 13 | loss: 0.0753049\n",
      "\tspeed: 0.0209s/iter; left time: 33.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0758764 Vali Loss: 0.0763160 Test Loss: 0.0877484\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0757037\n",
      "\tspeed: 0.0426s/iter; left time: 62.5372s\n",
      "\titers: 200, epoch: 14 | loss: 0.0765146\n",
      "\tspeed: 0.0172s/iter; left time: 23.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0755893 Vali Loss: 0.0764946 Test Loss: 0.0880358\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745211\n",
      "\tspeed: 0.0357s/iter; left time: 44.4092s\n",
      "\titers: 200, epoch: 15 | loss: 0.0719035\n",
      "\tspeed: 0.0177s/iter; left time: 20.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0753161 Vali Loss: 0.0766544 Test Loss: 0.0879934\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719958\n",
      "\tspeed: 0.0393s/iter; left time: 40.0923s\n",
      "\titers: 200, epoch: 16 | loss: 0.0726158\n",
      "\tspeed: 0.0177s/iter; left time: 16.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0750091 Vali Loss: 0.0767697 Test Loss: 0.0880393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0725779\n",
      "\tspeed: 0.0372s/iter; left time: 29.6675s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759026\n",
      "\tspeed: 0.0203s/iter; left time: 14.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0748258 Vali Loss: 0.0764923 Test Loss: 0.0879672\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018933413550257683, rmse:0.13759873807430267, mae:0.08774946630001068, rse:0.4042236804962158\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:24.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588590\n",
      "\tspeed: 0.0390s/iter; left time: 170.1002s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345927\n",
      "\tspeed: 0.0105s/iter; left time: 44.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.1578327 Vali Loss: 0.1251587 Test Loss: 0.1401146\n",
      "Validation loss decreased (inf --> 0.125159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031658\n",
      "\tspeed: 0.0318s/iter; left time: 131.4311s\n",
      "\titers: 200, epoch: 2 | loss: 0.0960442\n",
      "\tspeed: 0.0125s/iter; left time: 50.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.1027083 Vali Loss: 0.0920010 Test Loss: 0.1034549\n",
      "Validation loss decreased (0.125159 --> 0.092001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925628\n",
      "\tspeed: 0.0389s/iter; left time: 152.3651s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885058\n",
      "\tspeed: 0.0184s/iter; left time: 70.1950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0920447 Vali Loss: 0.0870601 Test Loss: 0.0977339\n",
      "Validation loss decreased (0.092001 --> 0.087060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0894964\n",
      "\tspeed: 0.0351s/iter; left time: 129.4850s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878705\n",
      "\tspeed: 0.0167s/iter; left time: 59.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0885116 Vali Loss: 0.0853489 Test Loss: 0.0955454\n",
      "Validation loss decreased (0.087060 --> 0.085349).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861767\n",
      "\tspeed: 0.0375s/iter; left time: 129.9464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893044\n",
      "\tspeed: 0.0167s/iter; left time: 56.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0865645 Vali Loss: 0.0847000 Test Loss: 0.0949086\n",
      "Validation loss decreased (0.085349 --> 0.084700).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860761\n",
      "\tspeed: 0.0364s/iter; left time: 118.2401s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822750\n",
      "\tspeed: 0.0170s/iter; left time: 53.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0852246 Vali Loss: 0.0838490 Test Loss: 0.0941687\n",
      "Validation loss decreased (0.084700 --> 0.083849).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844567\n",
      "\tspeed: 0.0330s/iter; left time: 99.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0868250\n",
      "\tspeed: 0.0171s/iter; left time: 49.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0841996 Vali Loss: 0.0832387 Test Loss: 0.0941152\n",
      "Validation loss decreased (0.083849 --> 0.083239).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873774\n",
      "\tspeed: 0.0384s/iter; left time: 107.5862s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820005\n",
      "\tspeed: 0.0178s/iter; left time: 48.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0833750 Vali Loss: 0.0830650 Test Loss: 0.0936024\n",
      "Validation loss decreased (0.083239 --> 0.083065).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829483\n",
      "\tspeed: 0.0353s/iter; left time: 91.0256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805004\n",
      "\tspeed: 0.0171s/iter; left time: 42.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0827375 Vali Loss: 0.0830914 Test Loss: 0.0932296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832330\n",
      "\tspeed: 0.0341s/iter; left time: 80.3511s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844381\n",
      "\tspeed: 0.0193s/iter; left time: 43.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0821893 Vali Loss: 0.0831509 Test Loss: 0.0935011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838833\n",
      "\tspeed: 0.0356s/iter; left time: 75.8287s\n",
      "\titers: 200, epoch: 11 | loss: 0.0842650\n",
      "\tspeed: 0.0179s/iter; left time: 36.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0816421 Vali Loss: 0.0830360 Test Loss: 0.0937280\n",
      "Validation loss decreased (0.083065 --> 0.083036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819793\n",
      "\tspeed: 0.0359s/iter; left time: 68.4249s\n",
      "\titers: 200, epoch: 12 | loss: 0.0781054\n",
      "\tspeed: 0.0185s/iter; left time: 33.4094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0812782 Vali Loss: 0.0829809 Test Loss: 0.0936222\n",
      "Validation loss decreased (0.083036 --> 0.082981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817220\n",
      "\tspeed: 0.0331s/iter; left time: 55.7969s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826705\n",
      "\tspeed: 0.0179s/iter; left time: 28.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0808690 Vali Loss: 0.0833226 Test Loss: 0.0937399\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822457\n",
      "\tspeed: 0.0367s/iter; left time: 53.6800s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779094\n",
      "\tspeed: 0.0189s/iter; left time: 25.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0806014 Vali Loss: 0.0836196 Test Loss: 0.0937464\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0783274\n",
      "\tspeed: 0.0392s/iter; left time: 48.5249s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781628\n",
      "\tspeed: 0.0198s/iter; left time: 22.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0802118 Vali Loss: 0.0835069 Test Loss: 0.0935566\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785731\n",
      "\tspeed: 0.0347s/iter; left time: 35.2629s\n",
      "\titers: 200, epoch: 16 | loss: 0.0764296\n",
      "\tspeed: 0.0178s/iter; left time: 16.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0798898 Vali Loss: 0.0836725 Test Loss: 0.0937837\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801015\n",
      "\tspeed: 0.0375s/iter; left time: 29.7033s\n",
      "\titers: 200, epoch: 17 | loss: 0.0836306\n",
      "\tspeed: 0.0213s/iter; left time: 14.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0796882 Vali Loss: 0.0840067 Test Loss: 0.0938545\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0211891271173954, rmse:0.14556485414505005, mae:0.093622125685215, rse:0.4276564419269562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1613069\n",
      "\tspeed: 0.0216s/iter; left time: 94.2873s\n",
      "\titers: 200, epoch: 1 | loss: 0.1376596\n",
      "\tspeed: 0.0189s/iter; left time: 80.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1605535 Vali Loss: 0.1269490 Test Loss: 0.1422556\n",
      "Validation loss decreased (inf --> 0.126949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1013645\n",
      "\tspeed: 0.0366s/iter; left time: 151.3121s\n",
      "\titers: 200, epoch: 2 | loss: 0.0963595\n",
      "\tspeed: 0.0184s/iter; left time: 74.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1028532 Vali Loss: 0.0920172 Test Loss: 0.1033752\n",
      "Validation loss decreased (0.126949 --> 0.092017).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0923068\n",
      "\tspeed: 0.0366s/iter; left time: 143.3538s\n",
      "\titers: 200, epoch: 3 | loss: 0.0933995\n",
      "\tspeed: 0.0185s/iter; left time: 70.3984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0920053 Vali Loss: 0.0868958 Test Loss: 0.0977857\n",
      "Validation loss decreased (0.092017 --> 0.086896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0858119\n",
      "\tspeed: 0.0430s/iter; left time: 158.6773s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876705\n",
      "\tspeed: 0.0192s/iter; left time: 68.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0883205 Vali Loss: 0.0854360 Test Loss: 0.0955178\n",
      "Validation loss decreased (0.086896 --> 0.085436).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0846782\n",
      "\tspeed: 0.0382s/iter; left time: 132.3570s\n",
      "\titers: 200, epoch: 5 | loss: 0.0885914\n",
      "\tspeed: 0.0180s/iter; left time: 60.6612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0863524 Vali Loss: 0.0841903 Test Loss: 0.0947642\n",
      "Validation loss decreased (0.085436 --> 0.084190).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860462\n",
      "\tspeed: 0.0398s/iter; left time: 129.1049s\n",
      "\titers: 200, epoch: 6 | loss: 0.0850799\n",
      "\tspeed: 0.0223s/iter; left time: 70.2094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0849439 Vali Loss: 0.0839054 Test Loss: 0.0941740\n",
      "Validation loss decreased (0.084190 --> 0.083905).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0822197\n",
      "\tspeed: 0.0412s/iter; left time: 124.5215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831921\n",
      "\tspeed: 0.0193s/iter; left time: 56.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0839672 Vali Loss: 0.0835641 Test Loss: 0.0939951\n",
      "Validation loss decreased (0.083905 --> 0.083564).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825832\n",
      "\tspeed: 0.0352s/iter; left time: 98.5133s\n",
      "\titers: 200, epoch: 8 | loss: 0.0844896\n",
      "\tspeed: 0.0184s/iter; left time: 49.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0831400 Vali Loss: 0.0830377 Test Loss: 0.0934263\n",
      "Validation loss decreased (0.083564 --> 0.083038).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0794877\n",
      "\tspeed: 0.0357s/iter; left time: 92.0337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0802455\n",
      "\tspeed: 0.0206s/iter; left time: 50.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0824504 Vali Loss: 0.0834601 Test Loss: 0.0937234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0830448\n",
      "\tspeed: 0.0444s/iter; left time: 104.4685s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812443\n",
      "\tspeed: 0.0216s/iter; left time: 48.7848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0818277 Vali Loss: 0.0833150 Test Loss: 0.0936633\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0829920\n",
      "\tspeed: 0.0388s/iter; left time: 82.6933s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791270\n",
      "\tspeed: 0.0178s/iter; left time: 36.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0813303 Vali Loss: 0.0831595 Test Loss: 0.0931381\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840791\n",
      "\tspeed: 0.0352s/iter; left time: 67.2430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801293\n",
      "\tspeed: 0.0218s/iter; left time: 39.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0808497 Vali Loss: 0.0831188 Test Loss: 0.0932104\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802847\n",
      "\tspeed: 0.0392s/iter; left time: 66.0855s\n",
      "\titers: 200, epoch: 13 | loss: 0.0823523\n",
      "\tspeed: 0.0186s/iter; left time: 29.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0804999 Vali Loss: 0.0834482 Test Loss: 0.0932803\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020786510780453682, rmse:0.14417527616024017, mae:0.09342631697654724, rse:0.4235740005970001\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:57.19s\n",
      "Intermediate time for ES: 00h:10m:25.68s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1097015\n",
      "\tspeed: 0.0418s/iter; left time: 183.0207s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887853\n",
      "\tspeed: 0.0121s/iter; left time: 51.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1121289 Vali Loss: 0.0946256 Test Loss: 0.1039862\n",
      "Validation loss decreased (inf --> 0.094626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534826\n",
      "\tspeed: 0.0280s/iter; left time: 116.2360s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533698\n",
      "\tspeed: 0.0118s/iter; left time: 47.9502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0595254 Vali Loss: 0.0593359 Test Loss: 0.0626762\n",
      "Validation loss decreased (0.094626 --> 0.059336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0492144\n",
      "\tspeed: 0.0315s/iter; left time: 123.8111s\n",
      "\titers: 200, epoch: 3 | loss: 0.0486399\n",
      "\tspeed: 0.0181s/iter; left time: 69.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0507849 Vali Loss: 0.0569176 Test Loss: 0.0601328\n",
      "Validation loss decreased (0.059336 --> 0.056918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0484496\n",
      "\tspeed: 0.0319s/iter; left time: 118.1421s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481661\n",
      "\tspeed: 0.0120s/iter; left time: 43.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 224 | Train Loss: 0.0485986 Vali Loss: 0.0556101 Test Loss: 0.0590208\n",
      "Validation loss decreased (0.056918 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467192\n",
      "\tspeed: 0.0272s/iter; left time: 94.8465s\n",
      "\titers: 200, epoch: 5 | loss: 0.0484249\n",
      "\tspeed: 0.0159s/iter; left time: 53.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 224 | Train Loss: 0.0472493 Vali Loss: 0.0546849 Test Loss: 0.0583969\n",
      "Validation loss decreased (0.055610 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0475310\n",
      "\tspeed: 0.0342s/iter; left time: 111.6001s\n",
      "\titers: 200, epoch: 6 | loss: 0.0457387\n",
      "\tspeed: 0.0168s/iter; left time: 52.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462754 Vali Loss: 0.0535959 Test Loss: 0.0575769\n",
      "Validation loss decreased (0.054685 --> 0.053596).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0468816\n",
      "\tspeed: 0.0354s/iter; left time: 107.3717s\n",
      "\titers: 200, epoch: 7 | loss: 0.0452926\n",
      "\tspeed: 0.0177s/iter; left time: 51.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0455841 Vali Loss: 0.0534057 Test Loss: 0.0573068\n",
      "Validation loss decreased (0.053596 --> 0.053406).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0474218\n",
      "\tspeed: 0.0393s/iter; left time: 110.6386s\n",
      "\titers: 200, epoch: 8 | loss: 0.0434757\n",
      "\tspeed: 0.0220s/iter; left time: 59.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0450097 Vali Loss: 0.0531013 Test Loss: 0.0570163\n",
      "Validation loss decreased (0.053406 --> 0.053101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0466082\n",
      "\tspeed: 0.0365s/iter; left time: 94.6244s\n",
      "\titers: 200, epoch: 9 | loss: 0.0406892\n",
      "\tspeed: 0.0166s/iter; left time: 41.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0445724 Vali Loss: 0.0529589 Test Loss: 0.0571137\n",
      "Validation loss decreased (0.053101 --> 0.052959).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0472855\n",
      "\tspeed: 0.0346s/iter; left time: 81.8903s\n",
      "\titers: 200, epoch: 10 | loss: 0.0445645\n",
      "\tspeed: 0.0166s/iter; left time: 37.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0441734 Vali Loss: 0.0526272 Test Loss: 0.0568700\n",
      "Validation loss decreased (0.052959 --> 0.052627).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434398\n",
      "\tspeed: 0.0379s/iter; left time: 81.0601s\n",
      "\titers: 200, epoch: 11 | loss: 0.0426368\n",
      "\tspeed: 0.0180s/iter; left time: 36.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0438455 Vali Loss: 0.0523278 Test Loss: 0.0564668\n",
      "Validation loss decreased (0.052627 --> 0.052328).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0431309\n",
      "\tspeed: 0.0389s/iter; left time: 74.5463s\n",
      "\titers: 200, epoch: 12 | loss: 0.0433577\n",
      "\tspeed: 0.0198s/iter; left time: 35.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0436222 Vali Loss: 0.0522362 Test Loss: 0.0562486\n",
      "Validation loss decreased (0.052328 --> 0.052236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0426902\n",
      "\tspeed: 0.0365s/iter; left time: 61.8587s\n",
      "\titers: 200, epoch: 13 | loss: 0.0428892\n",
      "\tspeed: 0.0197s/iter; left time: 31.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0433593 Vali Loss: 0.0520524 Test Loss: 0.0562706\n",
      "Validation loss decreased (0.052236 --> 0.052052).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0434505\n",
      "\tspeed: 0.0392s/iter; left time: 57.6252s\n",
      "\titers: 200, epoch: 14 | loss: 0.0460396\n",
      "\tspeed: 0.0163s/iter; left time: 22.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0431982 Vali Loss: 0.0523667 Test Loss: 0.0561814\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0428227\n",
      "\tspeed: 0.0342s/iter; left time: 42.6195s\n",
      "\titers: 200, epoch: 15 | loss: 0.0418219\n",
      "\tspeed: 0.0181s/iter; left time: 20.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0429733 Vali Loss: 0.0519710 Test Loss: 0.0561296\n",
      "Validation loss decreased (0.052052 --> 0.051971).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0426776\n",
      "\tspeed: 0.0362s/iter; left time: 37.0093s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441703\n",
      "\tspeed: 0.0165s/iter; left time: 15.1767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0428724 Vali Loss: 0.0518400 Test Loss: 0.0559802\n",
      "Validation loss decreased (0.051971 --> 0.051840).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0421949\n",
      "\tspeed: 0.0373s/iter; left time: 29.6885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410631\n",
      "\tspeed: 0.0199s/iter; left time: 13.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0427084 Vali Loss: 0.0517573 Test Loss: 0.0560051\n",
      "Validation loss decreased (0.051840 --> 0.051757).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443506\n",
      "\tspeed: 0.0380s/iter; left time: 21.7822s\n",
      "\titers: 200, epoch: 18 | loss: 0.0417061\n",
      "\tspeed: 0.0198s/iter; left time: 9.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0425945 Vali Loss: 0.0517659 Test Loss: 0.0559824\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0399689\n",
      "\tspeed: 0.0365s/iter; left time: 12.7271s\n",
      "\titers: 200, epoch: 19 | loss: 0.0442903\n",
      "\tspeed: 0.0184s/iter; left time: 4.5755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0424989 Vali Loss: 0.0516519 Test Loss: 0.0558209\n",
      "Validation loss decreased (0.051757 --> 0.051652).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0412286\n",
      "\tspeed: 0.0379s/iter; left time: 4.7428s\n",
      "\titers: 200, epoch: 20 | loss: 0.0390507\n",
      "\tspeed: 0.0206s/iter; left time: 0.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0423428 Vali Loss: 0.0516512 Test Loss: 0.0557739\n",
      "Validation loss decreased (0.051652 --> 0.051651).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010127558372914791, rmse:0.10063577443361282, mae:0.05577389523386955, rse:0.3882500231266022\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1160067\n",
      "\tspeed: 0.0248s/iter; left time: 108.4927s\n",
      "\titers: 200, epoch: 1 | loss: 0.0896998\n",
      "\tspeed: 0.0222s/iter; left time: 95.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.1133017 Vali Loss: 0.0950022 Test Loss: 0.1035725\n",
      "Validation loss decreased (inf --> 0.095002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0571048\n",
      "\tspeed: 0.0418s/iter; left time: 173.7424s\n",
      "\titers: 200, epoch: 2 | loss: 0.0530564\n",
      "\tspeed: 0.0220s/iter; left time: 89.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0595543 Vali Loss: 0.0592502 Test Loss: 0.0625376\n",
      "Validation loss decreased (0.095002 --> 0.059250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0534265\n",
      "\tspeed: 0.0389s/iter; left time: 152.9520s\n",
      "\titers: 200, epoch: 3 | loss: 0.0487475\n",
      "\tspeed: 0.0242s/iter; left time: 92.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0507634 Vali Loss: 0.0569950 Test Loss: 0.0602884\n",
      "Validation loss decreased (0.059250 --> 0.056995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0486558\n",
      "\tspeed: 0.0402s/iter; left time: 149.1860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0471254\n",
      "\tspeed: 0.0218s/iter; left time: 78.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0485903 Vali Loss: 0.0554169 Test Loss: 0.0591204\n",
      "Validation loss decreased (0.056995 --> 0.055417).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0482533\n",
      "\tspeed: 0.0437s/iter; left time: 152.1902s\n",
      "\titers: 200, epoch: 5 | loss: 0.0455832\n",
      "\tspeed: 0.0207s/iter; left time: 70.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0472082 Vali Loss: 0.0548215 Test Loss: 0.0586890\n",
      "Validation loss decreased (0.055417 --> 0.054821).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0467923\n",
      "\tspeed: 0.0399s/iter; left time: 130.0907s\n",
      "\titers: 200, epoch: 6 | loss: 0.0442353\n",
      "\tspeed: 0.0205s/iter; left time: 64.8370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0461966 Vali Loss: 0.0540250 Test Loss: 0.0578917\n",
      "Validation loss decreased (0.054821 --> 0.054025).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0450493\n",
      "\tspeed: 0.0418s/iter; left time: 127.0740s\n",
      "\titers: 200, epoch: 7 | loss: 0.0467357\n",
      "\tspeed: 0.0245s/iter; left time: 71.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0455368 Vali Loss: 0.0533868 Test Loss: 0.0574734\n",
      "Validation loss decreased (0.054025 --> 0.053387).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449342\n",
      "\tspeed: 0.0441s/iter; left time: 124.1939s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489492\n",
      "\tspeed: 0.0190s/iter; left time: 51.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0449747 Vali Loss: 0.0531140 Test Loss: 0.0571540\n",
      "Validation loss decreased (0.053387 --> 0.053114).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0450995\n",
      "\tspeed: 0.0429s/iter; left time: 111.0425s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439877\n",
      "\tspeed: 0.0204s/iter; left time: 50.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0445141 Vali Loss: 0.0529351 Test Loss: 0.0570621\n",
      "Validation loss decreased (0.053114 --> 0.052935).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441738\n",
      "\tspeed: 0.0391s/iter; left time: 92.5075s\n",
      "\titers: 200, epoch: 10 | loss: 0.0432842\n",
      "\tspeed: 0.0213s/iter; left time: 48.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0440936 Vali Loss: 0.0527343 Test Loss: 0.0567664\n",
      "Validation loss decreased (0.052935 --> 0.052734).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0442159\n",
      "\tspeed: 0.0368s/iter; left time: 78.8618s\n",
      "\titers: 200, epoch: 11 | loss: 0.0469867\n",
      "\tspeed: 0.0170s/iter; left time: 34.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0437601 Vali Loss: 0.0524060 Test Loss: 0.0564677\n",
      "Validation loss decreased (0.052734 --> 0.052406).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0442465\n",
      "\tspeed: 0.0383s/iter; left time: 73.4334s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414413\n",
      "\tspeed: 0.0199s/iter; left time: 36.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0434925 Vali Loss: 0.0522480 Test Loss: 0.0564030\n",
      "Validation loss decreased (0.052406 --> 0.052248).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0466450\n",
      "\tspeed: 0.0434s/iter; left time: 73.4066s\n",
      "\titers: 200, epoch: 13 | loss: 0.0407641\n",
      "\tspeed: 0.0209s/iter; left time: 33.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0433079 Vali Loss: 0.0521778 Test Loss: 0.0563392\n",
      "Validation loss decreased (0.052248 --> 0.052178).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0421818\n",
      "\tspeed: 0.0384s/iter; left time: 56.3429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0447528\n",
      "\tspeed: 0.0193s/iter; left time: 26.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0430867 Vali Loss: 0.0519807 Test Loss: 0.0562902\n",
      "Validation loss decreased (0.052178 --> 0.051981).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0419500\n",
      "\tspeed: 0.0369s/iter; left time: 45.9944s\n",
      "\titers: 200, epoch: 15 | loss: 0.0382999\n",
      "\tspeed: 0.0199s/iter; left time: 22.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0429435 Vali Loss: 0.0519662 Test Loss: 0.0560710\n",
      "Validation loss decreased (0.051981 --> 0.051966).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0414118\n",
      "\tspeed: 0.0367s/iter; left time: 37.5119s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415932\n",
      "\tspeed: 0.0188s/iter; left time: 17.2981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0427769 Vali Loss: 0.0518844 Test Loss: 0.0561112\n",
      "Validation loss decreased (0.051966 --> 0.051884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0428831\n",
      "\tspeed: 0.0371s/iter; left time: 29.5346s\n",
      "\titers: 200, epoch: 17 | loss: 0.0412486\n",
      "\tspeed: 0.0192s/iter; left time: 13.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0426684 Vali Loss: 0.0519237 Test Loss: 0.0561049\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0422155\n",
      "\tspeed: 0.0362s/iter; left time: 20.7648s\n",
      "\titers: 200, epoch: 18 | loss: 0.0412015\n",
      "\tspeed: 0.0181s/iter; left time: 8.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0425029 Vali Loss: 0.0517499 Test Loss: 0.0560229\n",
      "Validation loss decreased (0.051884 --> 0.051750).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0433981\n",
      "\tspeed: 0.0390s/iter; left time: 13.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448439\n",
      "\tspeed: 0.0195s/iter; left time: 4.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0423947 Vali Loss: 0.0516780 Test Loss: 0.0559298\n",
      "Validation loss decreased (0.051750 --> 0.051678).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0435514\n",
      "\tspeed: 0.0395s/iter; left time: 4.9417s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383629\n",
      "\tspeed: 0.0197s/iter; left time: 0.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0422725 Vali Loss: 0.0516585 Test Loss: 0.0558056\n",
      "Validation loss decreased (0.051678 --> 0.051658).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010172461159527302, rmse:0.10085862129926682, mae:0.055805619806051254, rse:0.3891097605228424\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:56.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1150345\n",
      "\tspeed: 0.0394s/iter; left time: 172.8298s\n",
      "\titers: 200, epoch: 1 | loss: 0.0994970\n",
      "\tspeed: 0.0164s/iter; left time: 70.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 224 | Train Loss: 0.1151521 Vali Loss: 0.1004603 Test Loss: 0.1112473\n",
      "Validation loss decreased (inf --> 0.100460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693080\n",
      "\tspeed: 0.0323s/iter; left time: 134.4223s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724322\n",
      "\tspeed: 0.0163s/iter; left time: 66.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0735030 Vali Loss: 0.0765681 Test Loss: 0.0844831\n",
      "Validation loss decreased (0.100460 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0613564\n",
      "\tspeed: 0.0347s/iter; left time: 136.3488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634928\n",
      "\tspeed: 0.0171s/iter; left time: 65.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0658099 Vali Loss: 0.0732510 Test Loss: 0.0826563\n",
      "Validation loss decreased (0.076568 --> 0.073251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623701\n",
      "\tspeed: 0.0353s/iter; left time: 130.7693s\n",
      "\titers: 200, epoch: 4 | loss: 0.0633448\n",
      "\tspeed: 0.0175s/iter; left time: 63.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0633823 Vali Loss: 0.0719194 Test Loss: 0.0820371\n",
      "Validation loss decreased (0.073251 --> 0.071919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614888\n",
      "\tspeed: 0.0336s/iter; left time: 117.2415s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610972\n",
      "\tspeed: 0.0159s/iter; left time: 53.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0621701 Vali Loss: 0.0716075 Test Loss: 0.0817624\n",
      "Validation loss decreased (0.071919 --> 0.071608).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612228\n",
      "\tspeed: 0.0375s/iter; left time: 122.1802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592582\n",
      "\tspeed: 0.0178s/iter; left time: 56.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0613832 Vali Loss: 0.0709181 Test Loss: 0.0815005\n",
      "Validation loss decreased (0.071608 --> 0.070918).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582864\n",
      "\tspeed: 0.0391s/iter; left time: 118.6923s\n",
      "\titers: 200, epoch: 7 | loss: 0.0598563\n",
      "\tspeed: 0.0177s/iter; left time: 51.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0607176 Vali Loss: 0.0706939 Test Loss: 0.0812478\n",
      "Validation loss decreased (0.070918 --> 0.070694).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0593617\n",
      "\tspeed: 0.0406s/iter; left time: 114.2373s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628847\n",
      "\tspeed: 0.0177s/iter; left time: 47.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0602211 Vali Loss: 0.0707668 Test Loss: 0.0811632\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580503\n",
      "\tspeed: 0.0364s/iter; left time: 94.1637s\n",
      "\titers: 200, epoch: 9 | loss: 0.0611335\n",
      "\tspeed: 0.0283s/iter; left time: 70.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0597630 Vali Loss: 0.0707890 Test Loss: 0.0808218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602699\n",
      "\tspeed: 0.0369s/iter; left time: 87.2444s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593928\n",
      "\tspeed: 0.0153s/iter; left time: 34.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 224 | Train Loss: 0.0593691 Vali Loss: 0.0710047 Test Loss: 0.0808480\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0556815\n",
      "\tspeed: 0.0316s/iter; left time: 67.7074s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595476\n",
      "\tspeed: 0.0173s/iter; left time: 35.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 224 | Train Loss: 0.0590156 Vali Loss: 0.0708511 Test Loss: 0.0812676\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595886\n",
      "\tspeed: 0.0345s/iter; left time: 66.1296s\n",
      "\titers: 200, epoch: 12 | loss: 0.0590767\n",
      "\tspeed: 0.0178s/iter; left time: 32.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0587250 Vali Loss: 0.0708682 Test Loss: 0.0809419\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019239535555243492, rmse:0.13870665431022644, mae:0.08124779164791107, rse:0.536554217338562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1148729\n",
      "\tspeed: 0.0233s/iter; left time: 101.9021s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003245\n",
      "\tspeed: 0.0192s/iter; left time: 82.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1165598 Vali Loss: 0.1021862 Test Loss: 0.1129931\n",
      "Validation loss decreased (inf --> 0.102186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0688481\n",
      "\tspeed: 0.0380s/iter; left time: 158.1528s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709450\n",
      "\tspeed: 0.0179s/iter; left time: 72.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0736646 Vali Loss: 0.0766138 Test Loss: 0.0844905\n",
      "Validation loss decreased (0.102186 --> 0.076614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0691289\n",
      "\tspeed: 0.0383s/iter; left time: 150.4886s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633437\n",
      "\tspeed: 0.0182s/iter; left time: 69.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0657801 Vali Loss: 0.0733796 Test Loss: 0.0828308\n",
      "Validation loss decreased (0.076614 --> 0.073380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0683975\n",
      "\tspeed: 0.0376s/iter; left time: 139.6381s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621065\n",
      "\tspeed: 0.0194s/iter; left time: 69.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0633182 Vali Loss: 0.0722561 Test Loss: 0.0824362\n",
      "Validation loss decreased (0.073380 --> 0.072256).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0618264\n",
      "\tspeed: 0.0402s/iter; left time: 140.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606453\n",
      "\tspeed: 0.0209s/iter; left time: 70.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0620416 Vali Loss: 0.0716676 Test Loss: 0.0817704\n",
      "Validation loss decreased (0.072256 --> 0.071668).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592361\n",
      "\tspeed: 0.0399s/iter; left time: 130.0835s\n",
      "\titers: 200, epoch: 6 | loss: 0.0624412\n",
      "\tspeed: 0.0195s/iter; left time: 61.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0612315 Vali Loss: 0.0713056 Test Loss: 0.0816796\n",
      "Validation loss decreased (0.071668 --> 0.071306).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0604287\n",
      "\tspeed: 0.0393s/iter; left time: 119.3134s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607347\n",
      "\tspeed: 0.0209s/iter; left time: 61.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0605639 Vali Loss: 0.0711734 Test Loss: 0.0813426\n",
      "Validation loss decreased (0.071306 --> 0.071173).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0594503\n",
      "\tspeed: 0.0406s/iter; left time: 114.0733s\n",
      "\titers: 200, epoch: 8 | loss: 0.0598839\n",
      "\tspeed: 0.0146s/iter; left time: 39.5373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.0600136 Vali Loss: 0.0709626 Test Loss: 0.0812785\n",
      "Validation loss decreased (0.071173 --> 0.070963).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0584742\n",
      "\tspeed: 0.0353s/iter; left time: 91.2769s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627953\n",
      "\tspeed: 0.0182s/iter; left time: 45.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0595614 Vali Loss: 0.0710455 Test Loss: 0.0811933\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632053\n",
      "\tspeed: 0.0385s/iter; left time: 91.0941s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543489\n",
      "\tspeed: 0.0178s/iter; left time: 40.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0592101 Vali Loss: 0.0709957 Test Loss: 0.0808683\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582509\n",
      "\tspeed: 0.0347s/iter; left time: 74.3574s\n",
      "\titers: 200, epoch: 11 | loss: 0.0617730\n",
      "\tspeed: 0.0164s/iter; left time: 33.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0588796 Vali Loss: 0.0711482 Test Loss: 0.0814164\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567222\n",
      "\tspeed: 0.0404s/iter; left time: 77.4217s\n",
      "\titers: 200, epoch: 12 | loss: 0.0630319\n",
      "\tspeed: 0.0240s/iter; left time: 43.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0585767 Vali Loss: 0.0710930 Test Loss: 0.0813699\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0621379\n",
      "\tspeed: 0.0359s/iter; left time: 60.7723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0608567\n",
      "\tspeed: 0.0176s/iter; left time: 28.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0583427 Vali Loss: 0.0710956 Test Loss: 0.0811685\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01920846663415432, rmse:0.1385946124792099, mae:0.08127850294113159, rse:0.5361208319664001\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:29.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1184496\n",
      "\tspeed: 0.0431s/iter; left time: 188.1379s\n",
      "\titers: 200, epoch: 1 | loss: 0.0971473\n",
      "\tspeed: 0.0108s/iter; left time: 46.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.1167316 Vali Loss: 0.1032083 Test Loss: 0.1129677\n",
      "Validation loss decreased (inf --> 0.103208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0822949\n",
      "\tspeed: 0.0323s/iter; left time: 133.7894s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746721\n",
      "\tspeed: 0.0156s/iter; left time: 63.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0773156 Vali Loss: 0.0803216 Test Loss: 0.0886327\n",
      "Validation loss decreased (0.103208 --> 0.080322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0713718\n",
      "\tspeed: 0.0361s/iter; left time: 141.3379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0684350\n",
      "\tspeed: 0.0168s/iter; left time: 64.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0697741 Vali Loss: 0.0767432 Test Loss: 0.0876774\n",
      "Validation loss decreased (0.080322 --> 0.076743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674153\n",
      "\tspeed: 0.0351s/iter; left time: 129.4608s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699043\n",
      "\tspeed: 0.0164s/iter; left time: 58.7823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0672569 Vali Loss: 0.0758318 Test Loss: 0.0873202\n",
      "Validation loss decreased (0.076743 --> 0.075832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679794\n",
      "\tspeed: 0.0359s/iter; left time: 124.4353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0696597\n",
      "\tspeed: 0.0125s/iter; left time: 42.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0661320 Vali Loss: 0.0753898 Test Loss: 0.0871050\n",
      "Validation loss decreased (0.075832 --> 0.075390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637402\n",
      "\tspeed: 0.0382s/iter; left time: 123.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0633766\n",
      "\tspeed: 0.0164s/iter; left time: 51.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0652604 Vali Loss: 0.0750106 Test Loss: 0.0866593\n",
      "Validation loss decreased (0.075390 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0654606\n",
      "\tspeed: 0.0368s/iter; left time: 111.2552s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664279\n",
      "\tspeed: 0.0162s/iter; left time: 47.3141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0647009 Vali Loss: 0.0749119 Test Loss: 0.0863478\n",
      "Validation loss decreased (0.075011 --> 0.074912).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0680805\n",
      "\tspeed: 0.0392s/iter; left time: 109.7020s\n",
      "\titers: 200, epoch: 8 | loss: 0.0621320\n",
      "\tspeed: 0.0184s/iter; left time: 49.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0641877 Vali Loss: 0.0751029 Test Loss: 0.0873028\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651313\n",
      "\tspeed: 0.0379s/iter; left time: 97.5498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0634317\n",
      "\tspeed: 0.0206s/iter; left time: 51.1012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0637819 Vali Loss: 0.0752244 Test Loss: 0.0870896\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0616768\n",
      "\tspeed: 0.0342s/iter; left time: 80.6187s\n",
      "\titers: 200, epoch: 10 | loss: 0.0662288\n",
      "\tspeed: 0.0165s/iter; left time: 37.0929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0634420 Vali Loss: 0.0752584 Test Loss: 0.0871234\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0668921\n",
      "\tspeed: 0.0348s/iter; left time: 74.1103s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658013\n",
      "\tspeed: 0.0127s/iter; left time: 25.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 223 | Train Loss: 0.0630799 Vali Loss: 0.0751184 Test Loss: 0.0872565\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644008\n",
      "\tspeed: 0.0272s/iter; left time: 51.8949s\n",
      "\titers: 200, epoch: 12 | loss: 0.0626267\n",
      "\tspeed: 0.0157s/iter; left time: 28.4065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 223 | Train Loss: 0.0627786 Vali Loss: 0.0755117 Test Loss: 0.0872327\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020680325105786324, rmse:0.1438065618276596, mae:0.08634777367115021, rse:0.5569763779640198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1160953\n",
      "\tspeed: 0.0217s/iter; left time: 94.7544s\n",
      "\titers: 200, epoch: 1 | loss: 0.1009110\n",
      "\tspeed: 0.0169s/iter; left time: 71.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1164151 Vali Loss: 0.1032379 Test Loss: 0.1131487\n",
      "Validation loss decreased (inf --> 0.103238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0741741\n",
      "\tspeed: 0.0352s/iter; left time: 145.6878s\n",
      "\titers: 200, epoch: 2 | loss: 0.0729494\n",
      "\tspeed: 0.0189s/iter; left time: 76.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0772838 Vali Loss: 0.0805425 Test Loss: 0.0888041\n",
      "Validation loss decreased (0.103238 --> 0.080543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0694003\n",
      "\tspeed: 0.0381s/iter; left time: 148.9917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0664097\n",
      "\tspeed: 0.0182s/iter; left time: 69.3161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0697527 Vali Loss: 0.0767579 Test Loss: 0.0879858\n",
      "Validation loss decreased (0.080543 --> 0.076758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0693248\n",
      "\tspeed: 0.0392s/iter; left time: 144.8990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655002\n",
      "\tspeed: 0.0175s/iter; left time: 62.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0671989 Vali Loss: 0.0756547 Test Loss: 0.0876561\n",
      "Validation loss decreased (0.076758 --> 0.075655).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649014\n",
      "\tspeed: 0.0396s/iter; left time: 137.2358s\n",
      "\titers: 200, epoch: 5 | loss: 0.0637037\n",
      "\tspeed: 0.0179s/iter; left time: 60.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0660379 Vali Loss: 0.0756096 Test Loss: 0.0877262\n",
      "Validation loss decreased (0.075655 --> 0.075610).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0664085\n",
      "\tspeed: 0.0407s/iter; left time: 132.1649s\n",
      "\titers: 200, epoch: 6 | loss: 0.0656642\n",
      "\tspeed: 0.0182s/iter; left time: 57.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0652658 Vali Loss: 0.0750269 Test Loss: 0.0864704\n",
      "Validation loss decreased (0.075610 --> 0.075027).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0651778\n",
      "\tspeed: 0.0383s/iter; left time: 115.8205s\n",
      "\titers: 200, epoch: 7 | loss: 0.0648179\n",
      "\tspeed: 0.0200s/iter; left time: 58.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0646194 Vali Loss: 0.0750498 Test Loss: 0.0868188\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651356\n",
      "\tspeed: 0.0375s/iter; left time: 105.0459s\n",
      "\titers: 200, epoch: 8 | loss: 0.0656781\n",
      "\tspeed: 0.0175s/iter; left time: 47.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0641468 Vali Loss: 0.0748818 Test Loss: 0.0863336\n",
      "Validation loss decreased (0.075027 --> 0.074882).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0649025\n",
      "\tspeed: 0.0369s/iter; left time: 95.0663s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613403\n",
      "\tspeed: 0.0213s/iter; left time: 52.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0636986 Vali Loss: 0.0751551 Test Loss: 0.0860609\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0618444\n",
      "\tspeed: 0.0388s/iter; left time: 91.3038s\n",
      "\titers: 200, epoch: 10 | loss: 0.0631449\n",
      "\tspeed: 0.0178s/iter; left time: 40.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0633031 Vali Loss: 0.0754076 Test Loss: 0.0857785\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0607330\n",
      "\tspeed: 0.0363s/iter; left time: 77.4088s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658213\n",
      "\tspeed: 0.0197s/iter; left time: 40.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0629210 Vali Loss: 0.0750744 Test Loss: 0.0862985\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0642546\n",
      "\tspeed: 0.0414s/iter; left time: 79.0162s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623738\n",
      "\tspeed: 0.0213s/iter; left time: 38.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0626597 Vali Loss: 0.0751349 Test Loss: 0.0861356\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637437\n",
      "\tspeed: 0.0392s/iter; left time: 66.0896s\n",
      "\titers: 200, epoch: 13 | loss: 0.0632063\n",
      "\tspeed: 0.0198s/iter; left time: 31.4511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0623907 Vali Loss: 0.0750772 Test Loss: 0.0864533\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020546922460198402, rmse:0.14334197342395782, mae:0.08633362501859665, rse:0.5551770329475403\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:27.13s\n",
      "Intermediate time for FR: 00h:08m:53.57s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616937\n",
      "\tspeed: 0.0407s/iter; left time: 178.4584s\n",
      "\titers: 200, epoch: 1 | loss: 0.1293149\n",
      "\tspeed: 0.0119s/iter; left time: 51.1338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 224 | Train Loss: 0.1621773 Vali Loss: 0.1138775 Test Loss: 0.1172790\n",
      "Validation loss decreased (inf --> 0.113878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786218\n",
      "\tspeed: 0.0286s/iter; left time: 118.8473s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0173s/iter; left time: 70.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0831071 Vali Loss: 0.0641884 Test Loss: 0.0671537\n",
      "Validation loss decreased (0.113878 --> 0.064188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700320\n",
      "\tspeed: 0.0365s/iter; left time: 143.5740s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662021\n",
      "\tspeed: 0.0185s/iter; left time: 70.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0678796 Vali Loss: 0.0606680 Test Loss: 0.0635218\n",
      "Validation loss decreased (0.064188 --> 0.060668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612472\n",
      "\tspeed: 0.0373s/iter; left time: 138.2053s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621978\n",
      "\tspeed: 0.0163s/iter; left time: 58.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0645124 Vali Loss: 0.0592873 Test Loss: 0.0619248\n",
      "Validation loss decreased (0.060668 --> 0.059287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0623944\n",
      "\tspeed: 0.0378s/iter; left time: 131.6622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643269\n",
      "\tspeed: 0.0197s/iter; left time: 66.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0625303 Vali Loss: 0.0582227 Test Loss: 0.0607137\n",
      "Validation loss decreased (0.059287 --> 0.058223).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0643557\n",
      "\tspeed: 0.0420s/iter; left time: 137.0096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613264\n",
      "\tspeed: 0.0234s/iter; left time: 73.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0612088 Vali Loss: 0.0574816 Test Loss: 0.0600706\n",
      "Validation loss decreased (0.058223 --> 0.057482).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583737\n",
      "\tspeed: 0.0453s/iter; left time: 137.6595s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589131\n",
      "\tspeed: 0.0253s/iter; left time: 74.1702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0603114 Vali Loss: 0.0568728 Test Loss: 0.0594318\n",
      "Validation loss decreased (0.057482 --> 0.056873).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0602870\n",
      "\tspeed: 0.0402s/iter; left time: 113.2210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0557014\n",
      "\tspeed: 0.0197s/iter; left time: 53.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0596433 Vali Loss: 0.0565994 Test Loss: 0.0593777\n",
      "Validation loss decreased (0.056873 --> 0.056599).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0564329\n",
      "\tspeed: 0.0421s/iter; left time: 108.9296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0571721\n",
      "\tspeed: 0.0236s/iter; left time: 58.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0589292 Vali Loss: 0.0562056 Test Loss: 0.0591851\n",
      "Validation loss decreased (0.056599 --> 0.056206).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0580420\n",
      "\tspeed: 0.0393s/iter; left time: 92.9820s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585416\n",
      "\tspeed: 0.0217s/iter; left time: 49.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0584382 Vali Loss: 0.0559097 Test Loss: 0.0587973\n",
      "Validation loss decreased (0.056206 --> 0.055910).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601182\n",
      "\tspeed: 0.0393s/iter; left time: 84.2334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0593806\n",
      "\tspeed: 0.0202s/iter; left time: 41.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0579796 Vali Loss: 0.0556803 Test Loss: 0.0584713\n",
      "Validation loss decreased (0.055910 --> 0.055680).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591369\n",
      "\tspeed: 0.0443s/iter; left time: 84.8858s\n",
      "\titers: 200, epoch: 12 | loss: 0.0568577\n",
      "\tspeed: 0.0222s/iter; left time: 40.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0576995 Vali Loss: 0.0555104 Test Loss: 0.0582978\n",
      "Validation loss decreased (0.055680 --> 0.055510).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595251\n",
      "\tspeed: 0.0422s/iter; left time: 71.3737s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602591\n",
      "\tspeed: 0.0213s/iter; left time: 33.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0573981 Vali Loss: 0.0553351 Test Loss: 0.0582722\n",
      "Validation loss decreased (0.055510 --> 0.055335).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0583053\n",
      "\tspeed: 0.0389s/iter; left time: 57.2103s\n",
      "\titers: 200, epoch: 14 | loss: 0.0602665\n",
      "\tspeed: 0.0198s/iter; left time: 27.1643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0570490 Vali Loss: 0.0551690 Test Loss: 0.0581385\n",
      "Validation loss decreased (0.055335 --> 0.055169).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0560705\n",
      "\tspeed: 0.0404s/iter; left time: 50.2697s\n",
      "\titers: 200, epoch: 15 | loss: 0.0556168\n",
      "\tspeed: 0.0161s/iter; left time: 18.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0568528 Vali Loss: 0.0549350 Test Loss: 0.0578218\n",
      "Validation loss decreased (0.055169 --> 0.054935).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580549\n",
      "\tspeed: 0.0368s/iter; left time: 37.5227s\n",
      "\titers: 200, epoch: 16 | loss: 0.0600087\n",
      "\tspeed: 0.0212s/iter; left time: 19.4900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0566595 Vali Loss: 0.0549669 Test Loss: 0.0577802\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645831\n",
      "\tspeed: 0.0373s/iter; left time: 29.7151s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576199\n",
      "\tspeed: 0.0097s/iter; left time: 6.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 224 | Train Loss: 0.0564659 Vali Loss: 0.0549089 Test Loss: 0.0576262\n",
      "Validation loss decreased (0.054935 --> 0.054909).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542376\n",
      "\tspeed: 0.0346s/iter; left time: 19.8404s\n",
      "\titers: 200, epoch: 18 | loss: 0.0603156\n",
      "\tspeed: 0.0177s/iter; left time: 8.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0562640 Vali Loss: 0.0548581 Test Loss: 0.0575692\n",
      "Validation loss decreased (0.054909 --> 0.054858).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0547322\n",
      "\tspeed: 0.0363s/iter; left time: 12.6517s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540715\n",
      "\tspeed: 0.0202s/iter; left time: 5.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0561902 Vali Loss: 0.0546502 Test Loss: 0.0575371\n",
      "Validation loss decreased (0.054858 --> 0.054650).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0570445\n",
      "\tspeed: 0.0374s/iter; left time: 4.6800s\n",
      "\titers: 200, epoch: 20 | loss: 0.0555143\n",
      "\tspeed: 0.0208s/iter; left time: 0.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0560226 Vali Loss: 0.0546247 Test Loss: 0.0574184\n",
      "Validation loss decreased (0.054650 --> 0.054625).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010179932229220867, rmse:0.10089565068483353, mae:0.05741839110851288, rse:0.3812349736690521\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1641964\n",
      "\tspeed: 0.0199s/iter; left time: 87.2645s\n",
      "\titers: 200, epoch: 1 | loss: 0.1335033\n",
      "\tspeed: 0.0194s/iter; left time: 82.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.1647834 Vali Loss: 0.1140856 Test Loss: 0.1180013\n",
      "Validation loss decreased (inf --> 0.114086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0788176\n",
      "\tspeed: 0.0374s/iter; left time: 155.6334s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722505\n",
      "\tspeed: 0.0100s/iter; left time: 40.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0832242 Vali Loss: 0.0639038 Test Loss: 0.0669096\n",
      "Validation loss decreased (0.114086 --> 0.063904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0667697\n",
      "\tspeed: 0.0403s/iter; left time: 158.4654s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649629\n",
      "\tspeed: 0.0226s/iter; left time: 86.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0675962 Vali Loss: 0.0606419 Test Loss: 0.0631409\n",
      "Validation loss decreased (0.063904 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0617372\n",
      "\tspeed: 0.0357s/iter; left time: 132.4384s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621744\n",
      "\tspeed: 0.0188s/iter; left time: 67.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0641366 Vali Loss: 0.0588051 Test Loss: 0.0615734\n",
      "Validation loss decreased (0.060642 --> 0.058805).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0638878\n",
      "\tspeed: 0.0401s/iter; left time: 139.6350s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591638\n",
      "\tspeed: 0.0231s/iter; left time: 78.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0622737 Vali Loss: 0.0577147 Test Loss: 0.0605669\n",
      "Validation loss decreased (0.058805 --> 0.057715).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633146\n",
      "\tspeed: 0.0386s/iter; left time: 125.8105s\n",
      "\titers: 200, epoch: 6 | loss: 0.0637995\n",
      "\tspeed: 0.0192s/iter; left time: 60.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0610022 Vali Loss: 0.0571649 Test Loss: 0.0599463\n",
      "Validation loss decreased (0.057715 --> 0.057165).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621157\n",
      "\tspeed: 0.0391s/iter; left time: 118.8931s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0197s/iter; left time: 57.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0601525 Vali Loss: 0.0565381 Test Loss: 0.0591958\n",
      "Validation loss decreased (0.057165 --> 0.056538).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0582208\n",
      "\tspeed: 0.0371s/iter; left time: 104.4524s\n",
      "\titers: 200, epoch: 8 | loss: 0.0555900\n",
      "\tspeed: 0.0170s/iter; left time: 46.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0593576 Vali Loss: 0.0562229 Test Loss: 0.0586400\n",
      "Validation loss decreased (0.056538 --> 0.056223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0542082\n",
      "\tspeed: 0.0411s/iter; left time: 106.3717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0591107\n",
      "\tspeed: 0.0238s/iter; left time: 59.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0587323 Vali Loss: 0.0560406 Test Loss: 0.0586930\n",
      "Validation loss decreased (0.056223 --> 0.056041).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0589340\n",
      "\tspeed: 0.0370s/iter; left time: 87.5952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0544693\n",
      "\tspeed: 0.0206s/iter; left time: 46.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0581913 Vali Loss: 0.0557895 Test Loss: 0.0583518\n",
      "Validation loss decreased (0.056041 --> 0.055790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0545925\n",
      "\tspeed: 0.0396s/iter; left time: 84.7749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568754\n",
      "\tspeed: 0.0203s/iter; left time: 41.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0578496 Vali Loss: 0.0554803 Test Loss: 0.0580290\n",
      "Validation loss decreased (0.055790 --> 0.055480).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0530381\n",
      "\tspeed: 0.0390s/iter; left time: 74.6898s\n",
      "\titers: 200, epoch: 12 | loss: 0.0531054\n",
      "\tspeed: 0.0206s/iter; left time: 37.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0574548 Vali Loss: 0.0551434 Test Loss: 0.0578716\n",
      "Validation loss decreased (0.055480 --> 0.055143).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580193\n",
      "\tspeed: 0.0389s/iter; left time: 65.7946s\n",
      "\titers: 200, epoch: 13 | loss: 0.0529509\n",
      "\tspeed: 0.0169s/iter; left time: 26.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0572294 Vali Loss: 0.0551373 Test Loss: 0.0578145\n",
      "Validation loss decreased (0.055143 --> 0.055137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563859\n",
      "\tspeed: 0.0365s/iter; left time: 53.5617s\n",
      "\titers: 200, epoch: 14 | loss: 0.0511928\n",
      "\tspeed: 0.0185s/iter; left time: 25.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0569481 Vali Loss: 0.0550665 Test Loss: 0.0576489\n",
      "Validation loss decreased (0.055137 --> 0.055066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0589813\n",
      "\tspeed: 0.0386s/iter; left time: 48.1042s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532490\n",
      "\tspeed: 0.0165s/iter; left time: 18.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0566507 Vali Loss: 0.0549078 Test Loss: 0.0576441\n",
      "Validation loss decreased (0.055066 --> 0.054908).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0541341\n",
      "\tspeed: 0.0399s/iter; left time: 40.7131s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551793\n",
      "\tspeed: 0.0228s/iter; left time: 21.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0564742 Vali Loss: 0.0547731 Test Loss: 0.0575482\n",
      "Validation loss decreased (0.054908 --> 0.054773).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624035\n",
      "\tspeed: 0.0406s/iter; left time: 32.3973s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540801\n",
      "\tspeed: 0.0215s/iter; left time: 14.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0562661 Vali Loss: 0.0548215 Test Loss: 0.0573372\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542855\n",
      "\tspeed: 0.0383s/iter; left time: 21.9485s\n",
      "\titers: 200, epoch: 18 | loss: 0.0525319\n",
      "\tspeed: 0.0197s/iter; left time: 9.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0561894 Vali Loss: 0.0547226 Test Loss: 0.0573225\n",
      "Validation loss decreased (0.054773 --> 0.054723).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0528437\n",
      "\tspeed: 0.0362s/iter; left time: 12.6284s\n",
      "\titers: 200, epoch: 19 | loss: 0.0514670\n",
      "\tspeed: 0.0200s/iter; left time: 4.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0559581 Vali Loss: 0.0548397 Test Loss: 0.0573655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0514763\n",
      "\tspeed: 0.0390s/iter; left time: 4.8805s\n",
      "\titers: 200, epoch: 20 | loss: 0.0547461\n",
      "\tspeed: 0.0193s/iter; left time: 0.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0559040 Vali Loss: 0.0546618 Test Loss: 0.0573808\n",
      "Validation loss decreased (0.054723 --> 0.054662).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010223758406937122, rmse:0.10111260414123535, mae:0.0573807992041111, rse:0.38205471634864807\n",
      "Intermediate time for IT and pred_len 24: 00h:04m:03.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1697901\n",
      "\tspeed: 0.0385s/iter; left time: 168.5173s\n",
      "\titers: 200, epoch: 1 | loss: 0.1417536\n",
      "\tspeed: 0.0166s/iter; left time: 71.2380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.1661587 Vali Loss: 0.1205689 Test Loss: 0.1254019\n",
      "Validation loss decreased (inf --> 0.120569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0981152\n",
      "\tspeed: 0.0368s/iter; left time: 152.8899s\n",
      "\titers: 200, epoch: 2 | loss: 0.0931919\n",
      "\tspeed: 0.0189s/iter; left time: 76.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1010543 Vali Loss: 0.0828838 Test Loss: 0.0878194\n",
      "Validation loss decreased (0.120569 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0871705\n",
      "\tspeed: 0.0337s/iter; left time: 132.4766s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823159\n",
      "\tspeed: 0.0174s/iter; left time: 66.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0867661 Vali Loss: 0.0794811 Test Loss: 0.0843781\n",
      "Validation loss decreased (0.082884 --> 0.079481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838890\n",
      "\tspeed: 0.0344s/iter; left time: 127.7357s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801001\n",
      "\tspeed: 0.0183s/iter; left time: 66.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0835624 Vali Loss: 0.0781997 Test Loss: 0.0834986\n",
      "Validation loss decreased (0.079481 --> 0.078200).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819419\n",
      "\tspeed: 0.0388s/iter; left time: 135.1468s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834576\n",
      "\tspeed: 0.0199s/iter; left time: 67.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0817635 Vali Loss: 0.0775758 Test Loss: 0.0826953\n",
      "Validation loss decreased (0.078200 --> 0.077576).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838633\n",
      "\tspeed: 0.0406s/iter; left time: 132.4235s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800622\n",
      "\tspeed: 0.0201s/iter; left time: 63.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0805275 Vali Loss: 0.0772487 Test Loss: 0.0826419\n",
      "Validation loss decreased (0.077576 --> 0.077249).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770448\n",
      "\tspeed: 0.0364s/iter; left time: 110.6709s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791029\n",
      "\tspeed: 0.0183s/iter; left time: 53.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0796021 Vali Loss: 0.0769699 Test Loss: 0.0821760\n",
      "Validation loss decreased (0.077249 --> 0.076970).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800148\n",
      "\tspeed: 0.0354s/iter; left time: 99.6873s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800654\n",
      "\tspeed: 0.0182s/iter; left time: 49.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0788863 Vali Loss: 0.0766922 Test Loss: 0.0817522\n",
      "Validation loss decreased (0.076970 --> 0.076692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763567\n",
      "\tspeed: 0.0368s/iter; left time: 95.2910s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756575\n",
      "\tspeed: 0.0173s/iter; left time: 43.1033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0782481 Vali Loss: 0.0764618 Test Loss: 0.0816592\n",
      "Validation loss decreased (0.076692 --> 0.076462).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781845\n",
      "\tspeed: 0.0368s/iter; left time: 87.0937s\n",
      "\titers: 200, epoch: 10 | loss: 0.0800031\n",
      "\tspeed: 0.0178s/iter; left time: 40.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0776947 Vali Loss: 0.0764062 Test Loss: 0.0814688\n",
      "Validation loss decreased (0.076462 --> 0.076406).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0756868\n",
      "\tspeed: 0.0344s/iter; left time: 73.7293s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766438\n",
      "\tspeed: 0.0172s/iter; left time: 35.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0772751 Vali Loss: 0.0763349 Test Loss: 0.0814497\n",
      "Validation loss decreased (0.076406 --> 0.076335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758763\n",
      "\tspeed: 0.0378s/iter; left time: 72.4018s\n",
      "\titers: 200, epoch: 12 | loss: 0.0747020\n",
      "\tspeed: 0.0229s/iter; left time: 41.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0767900 Vali Loss: 0.0761060 Test Loss: 0.0813051\n",
      "Validation loss decreased (0.076335 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789600\n",
      "\tspeed: 0.0346s/iter; left time: 58.6115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759603\n",
      "\tspeed: 0.0186s/iter; left time: 29.6360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0764186 Vali Loss: 0.0763179 Test Loss: 0.0813079\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0704881\n",
      "\tspeed: 0.0330s/iter; left time: 48.4398s\n",
      "\titers: 200, epoch: 14 | loss: 0.0755752\n",
      "\tspeed: 0.0163s/iter; left time: 22.3258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0761283 Vali Loss: 0.0763324 Test Loss: 0.0812085\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780939\n",
      "\tspeed: 0.0338s/iter; left time: 42.0733s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711667\n",
      "\tspeed: 0.0197s/iter; left time: 22.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0758143 Vali Loss: 0.0761845 Test Loss: 0.0810637\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718904\n",
      "\tspeed: 0.0373s/iter; left time: 38.1175s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772383\n",
      "\tspeed: 0.0194s/iter; left time: 17.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0754854 Vali Loss: 0.0761187 Test Loss: 0.0811562\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0739559\n",
      "\tspeed: 0.0343s/iter; left time: 27.3185s\n",
      "\titers: 200, epoch: 17 | loss: 0.0751932\n",
      "\tspeed: 0.0175s/iter; left time: 12.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0752675 Vali Loss: 0.0761033 Test Loss: 0.0810552\n",
      "Validation loss decreased (0.076106 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773290\n",
      "\tspeed: 0.0375s/iter; left time: 21.4907s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747019\n",
      "\tspeed: 0.0212s/iter; left time: 10.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0750758 Vali Loss: 0.0761617 Test Loss: 0.0808548\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718658\n",
      "\tspeed: 0.0363s/iter; left time: 12.6814s\n",
      "\titers: 200, epoch: 19 | loss: 0.0726776\n",
      "\tspeed: 0.0177s/iter; left time: 4.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0749217 Vali Loss: 0.0761442 Test Loss: 0.0809737\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0708190\n",
      "\tspeed: 0.0370s/iter; left time: 4.6229s\n",
      "\titers: 200, epoch: 20 | loss: 0.0749490\n",
      "\tspeed: 0.0173s/iter; left time: 0.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0747592 Vali Loss: 0.0761574 Test Loss: 0.0809266\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01855003833770752, rmse:0.1361985206604004, mae:0.08105520159006119, rse:0.5149813294410706\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1661306\n",
      "\tspeed: 0.0232s/iter; left time: 101.8154s\n",
      "\titers: 200, epoch: 1 | loss: 0.1386319\n",
      "\tspeed: 0.0175s/iter; left time: 74.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.1651341 Vali Loss: 0.1197583 Test Loss: 0.1245669\n",
      "Validation loss decreased (inf --> 0.119758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1045495\n",
      "\tspeed: 0.0340s/iter; left time: 141.3500s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894544\n",
      "\tspeed: 0.0187s/iter; left time: 75.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1007104 Vali Loss: 0.0831975 Test Loss: 0.0876287\n",
      "Validation loss decreased (0.119758 --> 0.083197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895628\n",
      "\tspeed: 0.0391s/iter; left time: 153.9495s\n",
      "\titers: 200, epoch: 3 | loss: 0.0883310\n",
      "\tspeed: 0.0195s/iter; left time: 74.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0868945 Vali Loss: 0.0797571 Test Loss: 0.0844172\n",
      "Validation loss decreased (0.083197 --> 0.079757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838891\n",
      "\tspeed: 0.0367s/iter; left time: 135.9451s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815687\n",
      "\tspeed: 0.0190s/iter; left time: 68.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0836585 Vali Loss: 0.0788186 Test Loss: 0.0832072\n",
      "Validation loss decreased (0.079757 --> 0.078819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0853383\n",
      "\tspeed: 0.0420s/iter; left time: 146.2293s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836618\n",
      "\tspeed: 0.0227s/iter; left time: 76.8968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0817977 Vali Loss: 0.0779793 Test Loss: 0.0823592\n",
      "Validation loss decreased (0.078819 --> 0.077979).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0799382\n",
      "\tspeed: 0.0365s/iter; left time: 119.0475s\n",
      "\titers: 200, epoch: 6 | loss: 0.0796745\n",
      "\tspeed: 0.0197s/iter; left time: 62.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0805553 Vali Loss: 0.0775715 Test Loss: 0.0818063\n",
      "Validation loss decreased (0.077979 --> 0.077571).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789978\n",
      "\tspeed: 0.0387s/iter; left time: 117.4943s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822624\n",
      "\tspeed: 0.0195s/iter; left time: 57.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0795909 Vali Loss: 0.0772382 Test Loss: 0.0816769\n",
      "Validation loss decreased (0.077571 --> 0.077238).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0809646\n",
      "\tspeed: 0.0355s/iter; left time: 99.9311s\n",
      "\titers: 200, epoch: 8 | loss: 0.0785988\n",
      "\tspeed: 0.0191s/iter; left time: 51.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0788885 Vali Loss: 0.0769175 Test Loss: 0.0814598\n",
      "Validation loss decreased (0.077238 --> 0.076918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779506\n",
      "\tspeed: 0.0382s/iter; left time: 98.9569s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763271\n",
      "\tspeed: 0.0211s/iter; left time: 52.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0782254 Vali Loss: 0.0768817 Test Loss: 0.0814819\n",
      "Validation loss decreased (0.076918 --> 0.076882).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0753714\n",
      "\tspeed: 0.0368s/iter; left time: 87.0330s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751342\n",
      "\tspeed: 0.0187s/iter; left time: 42.3103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0776683 Vali Loss: 0.0767503 Test Loss: 0.0815030\n",
      "Validation loss decreased (0.076882 --> 0.076750).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765918\n",
      "\tspeed: 0.0397s/iter; left time: 84.9774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0812272\n",
      "\tspeed: 0.0192s/iter; left time: 39.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0772731 Vali Loss: 0.0767325 Test Loss: 0.0814589\n",
      "Validation loss decreased (0.076750 --> 0.076732).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0783693\n",
      "\tspeed: 0.0384s/iter; left time: 73.6026s\n",
      "\titers: 200, epoch: 12 | loss: 0.0734948\n",
      "\tspeed: 0.0182s/iter; left time: 33.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0768016 Vali Loss: 0.0769572 Test Loss: 0.0814164\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0762682\n",
      "\tspeed: 0.0369s/iter; left time: 62.4542s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757583\n",
      "\tspeed: 0.0224s/iter; left time: 35.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0764821 Vali Loss: 0.0768085 Test Loss: 0.0809592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732451\n",
      "\tspeed: 0.0368s/iter; left time: 54.0851s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793516\n",
      "\tspeed: 0.0176s/iter; left time: 24.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0761137 Vali Loss: 0.0766792 Test Loss: 0.0813959\n",
      "Validation loss decreased (0.076732 --> 0.076679).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787787\n",
      "\tspeed: 0.0361s/iter; left time: 44.8844s\n",
      "\titers: 200, epoch: 15 | loss: 0.0742458\n",
      "\tspeed: 0.0195s/iter; left time: 22.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0758414 Vali Loss: 0.0766514 Test Loss: 0.0813937\n",
      "Validation loss decreased (0.076679 --> 0.076651).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0796000\n",
      "\tspeed: 0.0399s/iter; left time: 40.7328s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760873\n",
      "\tspeed: 0.0238s/iter; left time: 21.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0756022 Vali Loss: 0.0764964 Test Loss: 0.0812079\n",
      "Validation loss decreased (0.076651 --> 0.076496).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0781542\n",
      "\tspeed: 0.0401s/iter; left time: 31.9758s\n",
      "\titers: 200, epoch: 17 | loss: 0.0724886\n",
      "\tspeed: 0.0183s/iter; left time: 12.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0753410 Vali Loss: 0.0765277 Test Loss: 0.0811398\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0719991\n",
      "\tspeed: 0.0361s/iter; left time: 20.6850s\n",
      "\titers: 200, epoch: 18 | loss: 0.0713724\n",
      "\tspeed: 0.0204s/iter; left time: 9.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0751817 Vali Loss: 0.0764079 Test Loss: 0.0810717\n",
      "Validation loss decreased (0.076496 --> 0.076408).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0755875\n",
      "\tspeed: 0.0349s/iter; left time: 12.1809s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723778\n",
      "\tspeed: 0.0202s/iter; left time: 5.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0749577 Vali Loss: 0.0764176 Test Loss: 0.0811530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685743\n",
      "\tspeed: 0.0349s/iter; left time: 4.3606s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783250\n",
      "\tspeed: 0.0183s/iter; left time: 0.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0747055 Vali Loss: 0.0764246 Test Loss: 0.0810651\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01851717382669449, rmse:0.13607782125473022, mae:0.08107174187898636, rse:0.5145248770713806\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:54.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1688796\n",
      "\tspeed: 0.0524s/iter; left time: 228.4612s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379916\n",
      "\tspeed: 0.0179s/iter; left time: 76.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1675218 Vali Loss: 0.1228508 Test Loss: 0.1272653\n",
      "Validation loss decreased (inf --> 0.122851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052821\n",
      "\tspeed: 0.0341s/iter; left time: 141.1931s\n",
      "\titers: 200, epoch: 2 | loss: 0.0951657\n",
      "\tspeed: 0.0175s/iter; left time: 70.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1046993 Vali Loss: 0.0870518 Test Loss: 0.0914203\n",
      "Validation loss decreased (0.122851 --> 0.087052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0941121\n",
      "\tspeed: 0.0368s/iter; left time: 144.0445s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910775\n",
      "\tspeed: 0.0168s/iter; left time: 64.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0910649 Vali Loss: 0.0845050 Test Loss: 0.0885898\n",
      "Validation loss decreased (0.087052 --> 0.084505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0896367\n",
      "\tspeed: 0.0350s/iter; left time: 129.2230s\n",
      "\titers: 200, epoch: 4 | loss: 0.0880488\n",
      "\tspeed: 0.0171s/iter; left time: 61.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0877382 Vali Loss: 0.0837493 Test Loss: 0.0879036\n",
      "Validation loss decreased (0.084505 --> 0.083749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0890387\n",
      "\tspeed: 0.0377s/iter; left time: 130.7502s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900611\n",
      "\tspeed: 0.0184s/iter; left time: 62.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0859197 Vali Loss: 0.0826701 Test Loss: 0.0875381\n",
      "Validation loss decreased (0.083749 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836859\n",
      "\tspeed: 0.0316s/iter; left time: 102.6923s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846288\n",
      "\tspeed: 0.0111s/iter; left time: 35.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0846551 Vali Loss: 0.0824386 Test Loss: 0.0872829\n",
      "Validation loss decreased (0.082670 --> 0.082439).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834522\n",
      "\tspeed: 0.0378s/iter; left time: 114.2194s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817988\n",
      "\tspeed: 0.0195s/iter; left time: 56.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0837010 Vali Loss: 0.0825027 Test Loss: 0.0870421\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834716\n",
      "\tspeed: 0.0378s/iter; left time: 105.8932s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836445\n",
      "\tspeed: 0.0200s/iter; left time: 53.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0828991 Vali Loss: 0.0822424 Test Loss: 0.0870820\n",
      "Validation loss decreased (0.082439 --> 0.082242).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822689\n",
      "\tspeed: 0.0389s/iter; left time: 100.1896s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835607\n",
      "\tspeed: 0.0203s/iter; left time: 50.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0822176 Vali Loss: 0.0821146 Test Loss: 0.0869594\n",
      "Validation loss decreased (0.082242 --> 0.082115).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775967\n",
      "\tspeed: 0.0401s/iter; left time: 94.4580s\n",
      "\titers: 200, epoch: 10 | loss: 0.0858709\n",
      "\tspeed: 0.0205s/iter; left time: 46.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0816483 Vali Loss: 0.0820896 Test Loss: 0.0869541\n",
      "Validation loss decreased (0.082115 --> 0.082090).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0805347\n",
      "\tspeed: 0.0391s/iter; left time: 83.2751s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823051\n",
      "\tspeed: 0.0198s/iter; left time: 40.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0812410 Vali Loss: 0.0822447 Test Loss: 0.0866475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830619\n",
      "\tspeed: 0.0387s/iter; left time: 73.8354s\n",
      "\titers: 200, epoch: 12 | loss: 0.0789892\n",
      "\tspeed: 0.0198s/iter; left time: 35.7956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0807341 Vali Loss: 0.0823029 Test Loss: 0.0866804\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0821077\n",
      "\tspeed: 0.0394s/iter; left time: 66.3502s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781240\n",
      "\tspeed: 0.0206s/iter; left time: 32.6972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0803641 Vali Loss: 0.0823105 Test Loss: 0.0865855\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0829568\n",
      "\tspeed: 0.0386s/iter; left time: 56.4477s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800612\n",
      "\tspeed: 0.0201s/iter; left time: 27.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0800562 Vali Loss: 0.0821699 Test Loss: 0.0866186\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798516\n",
      "\tspeed: 0.0381s/iter; left time: 47.2445s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776321\n",
      "\tspeed: 0.0200s/iter; left time: 22.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0797893 Vali Loss: 0.0821470 Test Loss: 0.0864509\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020483501255512238, rmse:0.14312058687210083, mae:0.08695410192012787, rse:0.5416572093963623\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1724669\n",
      "\tspeed: 0.0221s/iter; left time: 96.3204s\n",
      "\titers: 200, epoch: 1 | loss: 0.1416290\n",
      "\tspeed: 0.0203s/iter; left time: 86.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.1694798 Vali Loss: 0.1243570 Test Loss: 0.1289007\n",
      "Validation loss decreased (inf --> 0.124357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1026877\n",
      "\tspeed: 0.0462s/iter; left time: 190.9989s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915753\n",
      "\tspeed: 0.0203s/iter; left time: 81.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1042934 Vali Loss: 0.0872191 Test Loss: 0.0917560\n",
      "Validation loss decreased (0.124357 --> 0.087219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0883309\n",
      "\tspeed: 0.0415s/iter; left time: 162.4037s\n",
      "\titers: 200, epoch: 3 | loss: 0.0881051\n",
      "\tspeed: 0.0198s/iter; left time: 75.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0909396 Vali Loss: 0.0846750 Test Loss: 0.0889084\n",
      "Validation loss decreased (0.087219 --> 0.084675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0875771\n",
      "\tspeed: 0.0374s/iter; left time: 137.9218s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866809\n",
      "\tspeed: 0.0200s/iter; left time: 71.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0878508 Vali Loss: 0.0835724 Test Loss: 0.0881749\n",
      "Validation loss decreased (0.084675 --> 0.083572).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0848562\n",
      "\tspeed: 0.0381s/iter; left time: 132.1252s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861553\n",
      "\tspeed: 0.0179s/iter; left time: 60.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0860751 Vali Loss: 0.0829801 Test Loss: 0.0878574\n",
      "Validation loss decreased (0.083572 --> 0.082980).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831566\n",
      "\tspeed: 0.0416s/iter; left time: 134.9711s\n",
      "\titers: 200, epoch: 6 | loss: 0.0829432\n",
      "\tspeed: 0.0202s/iter; left time: 63.4200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0848205 Vali Loss: 0.0825640 Test Loss: 0.0878789\n",
      "Validation loss decreased (0.082980 --> 0.082564).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0827256\n",
      "\tspeed: 0.0422s/iter; left time: 127.5211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0855440\n",
      "\tspeed: 0.0197s/iter; left time: 57.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0838323 Vali Loss: 0.0826807 Test Loss: 0.0877832\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843407\n",
      "\tspeed: 0.0417s/iter; left time: 116.8176s\n",
      "\titers: 200, epoch: 8 | loss: 0.0877665\n",
      "\tspeed: 0.0216s/iter; left time: 58.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0831006 Vali Loss: 0.0826668 Test Loss: 0.0877134\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820760\n",
      "\tspeed: 0.0355s/iter; left time: 91.3889s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794650\n",
      "\tspeed: 0.0226s/iter; left time: 55.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0823812 Vali Loss: 0.0821069 Test Loss: 0.0877879\n",
      "Validation loss decreased (0.082564 --> 0.082107).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0803931\n",
      "\tspeed: 0.0407s/iter; left time: 95.7799s\n",
      "\titers: 200, epoch: 10 | loss: 0.0818995\n",
      "\tspeed: 0.0212s/iter; left time: 47.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0817312 Vali Loss: 0.0822692 Test Loss: 0.0878709\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779449\n",
      "\tspeed: 0.0457s/iter; left time: 97.3979s\n",
      "\titers: 200, epoch: 11 | loss: 0.0796292\n",
      "\tspeed: 0.0223s/iter; left time: 45.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0812737 Vali Loss: 0.0821334 Test Loss: 0.0877849\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0841580\n",
      "\tspeed: 0.0405s/iter; left time: 77.1938s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793426\n",
      "\tspeed: 0.0212s/iter; left time: 38.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0807289 Vali Loss: 0.0820043 Test Loss: 0.0874370\n",
      "Validation loss decreased (0.082107 --> 0.082004).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0835612\n",
      "\tspeed: 0.0424s/iter; left time: 71.3795s\n",
      "\titers: 200, epoch: 13 | loss: 0.0807545\n",
      "\tspeed: 0.0187s/iter; left time: 29.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0803368 Vali Loss: 0.0819112 Test Loss: 0.0878224\n",
      "Validation loss decreased (0.082004 --> 0.081911).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0794411\n",
      "\tspeed: 0.0398s/iter; left time: 58.2503s\n",
      "\titers: 200, epoch: 14 | loss: 0.0796110\n",
      "\tspeed: 0.0199s/iter; left time: 27.0565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0799793 Vali Loss: 0.0819589 Test Loss: 0.0877723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778464\n",
      "\tspeed: 0.0436s/iter; left time: 54.0256s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784918\n",
      "\tspeed: 0.0240s/iter; left time: 27.3149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 223 | Train Loss: 0.0797116 Vali Loss: 0.0819184 Test Loss: 0.0877586\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0804187\n",
      "\tspeed: 0.0445s/iter; left time: 45.2187s\n",
      "\titers: 200, epoch: 16 | loss: 0.0771086\n",
      "\tspeed: 0.0232s/iter; left time: 21.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0793933 Vali Loss: 0.0818374 Test Loss: 0.0877305\n",
      "Validation loss decreased (0.081911 --> 0.081837).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0803828\n",
      "\tspeed: 0.0406s/iter; left time: 32.1623s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838717\n",
      "\tspeed: 0.0201s/iter; left time: 13.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0791174 Vali Loss: 0.0817423 Test Loss: 0.0878350\n",
      "Validation loss decreased (0.081837 --> 0.081742).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839292\n",
      "\tspeed: 0.0409s/iter; left time: 23.3351s\n",
      "\titers: 200, epoch: 18 | loss: 0.0799814\n",
      "\tspeed: 0.0203s/iter; left time: 9.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0788918 Vali Loss: 0.0817828 Test Loss: 0.0877931\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0774314\n",
      "\tspeed: 0.0406s/iter; left time: 14.0977s\n",
      "\titers: 200, epoch: 19 | loss: 0.0771165\n",
      "\tspeed: 0.0209s/iter; left time: 5.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0786805 Vali Loss: 0.0818339 Test Loss: 0.0878775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814192\n",
      "\tspeed: 0.0403s/iter; left time: 4.9922s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786837\n",
      "\tspeed: 0.0202s/iter; left time: 0.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0784942 Vali Loss: 0.0819315 Test Loss: 0.0879045\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021050533279776573, rmse:0.14508801698684692, mae:0.08783499896526337, rse:0.5491032600402832\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:40.51s\n",
      "Intermediate time for IT: 00h:11m:37.68s\n",
      "Total time: 00h:49m:01.07s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.0721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1467  0.0904\n",
       "        96        0.0394  0.1984  0.1308\n",
       "        168       0.0423  0.2057  0.1380\n",
       "ES      24        0.0151  0.1210  0.0721\n",
       "        96        0.0244  0.1551  0.1000\n",
       "        168       0.0252  0.1580  0.1047\n",
       "FR      24        0.0107  0.1032  0.0587\n",
       "        96        0.0200  0.1414  0.0830\n",
       "        168       0.0224  0.1496  0.0890\n",
       "GB      24        0.0270  0.1643  0.1042\n",
       "        96        0.0480  0.2188  0.1471\n",
       "        168       0.0503  0.2241  0.1529\n",
       "IT      24        0.0107  0.1032  0.0602\n",
       "        96        0.0185  0.1360  0.0825\n",
       "        168       0.0203  0.1426  0.0880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2770460\n",
      "\tspeed: 0.0433s/iter; left time: 189.4831s\n",
      "\titers: 200, epoch: 1 | loss: 0.2465269\n",
      "\tspeed: 0.0155s/iter; left time: 66.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.2753203 Vali Loss: 0.2299168 Test Loss: 0.2334900\n",
      "Validation loss decreased (inf --> 0.229917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431389\n",
      "\tspeed: 0.0346s/iter; left time: 143.6340s\n",
      "\titers: 200, epoch: 2 | loss: 0.1224534\n",
      "\tspeed: 0.0149s/iter; left time: 60.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.1556899 Vali Loss: 0.1173089 Test Loss: 0.1195047\n",
      "Validation loss decreased (0.229917 --> 0.117309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007133\n",
      "\tspeed: 0.0357s/iter; left time: 140.2519s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040038\n",
      "\tspeed: 0.0169s/iter; left time: 64.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1058084 Vali Loss: 0.1046565 Test Loss: 0.1059239\n",
      "Validation loss decreased (0.117309 --> 0.104657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922542\n",
      "\tspeed: 0.0344s/iter; left time: 127.6084s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948372\n",
      "\tspeed: 0.0148s/iter; left time: 53.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0949547 Vali Loss: 0.1006684 Test Loss: 0.1030676\n",
      "Validation loss decreased (0.104657 --> 0.100668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901036\n",
      "\tspeed: 0.0371s/iter; left time: 129.3574s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934353\n",
      "\tspeed: 0.0199s/iter; left time: 67.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0901855 Vali Loss: 0.0990986 Test Loss: 0.1021713\n",
      "Validation loss decreased (0.100668 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897130\n",
      "\tspeed: 0.0373s/iter; left time: 121.7229s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862946\n",
      "\tspeed: 0.0173s/iter; left time: 54.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0876308 Vali Loss: 0.0969279 Test Loss: 0.0988763\n",
      "Validation loss decreased (0.099099 --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844309\n",
      "\tspeed: 0.0406s/iter; left time: 123.2912s\n",
      "\titers: 200, epoch: 7 | loss: 0.0863574\n",
      "\tspeed: 0.0228s/iter; left time: 66.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0854974 Vali Loss: 0.0954770 Test Loss: 0.0974672\n",
      "Validation loss decreased (0.096928 --> 0.095477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873678\n",
      "\tspeed: 0.0370s/iter; left time: 104.0922s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831719\n",
      "\tspeed: 0.0176s/iter; left time: 47.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0842651 Vali Loss: 0.0951447 Test Loss: 0.0966019\n",
      "Validation loss decreased (0.095477 --> 0.095145).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824181\n",
      "\tspeed: 0.0406s/iter; left time: 105.1654s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804010\n",
      "\tspeed: 0.0170s/iter; left time: 42.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0828271 Vali Loss: 0.0942097 Test Loss: 0.0959965\n",
      "Validation loss decreased (0.095145 --> 0.094210).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809996\n",
      "\tspeed: 0.0384s/iter; left time: 90.7968s\n",
      "\titers: 200, epoch: 10 | loss: 0.0824365\n",
      "\tspeed: 0.0175s/iter; left time: 39.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0819656 Vali Loss: 0.0934424 Test Loss: 0.0955138\n",
      "Validation loss decreased (0.094210 --> 0.093442).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746146\n",
      "\tspeed: 0.0344s/iter; left time: 73.6936s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776770\n",
      "\tspeed: 0.0165s/iter; left time: 33.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0813062 Vali Loss: 0.0924850 Test Loss: 0.0944346\n",
      "Validation loss decreased (0.093442 --> 0.092485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764295\n",
      "\tspeed: 0.0406s/iter; left time: 77.7621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814218\n",
      "\tspeed: 0.0203s/iter; left time: 36.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0805977 Vali Loss: 0.0920954 Test Loss: 0.0938083\n",
      "Validation loss decreased (0.092485 --> 0.092095).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789664\n",
      "\tspeed: 0.0399s/iter; left time: 67.5293s\n",
      "\titers: 200, epoch: 13 | loss: 0.0841235\n",
      "\tspeed: 0.0204s/iter; left time: 32.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0800637 Vali Loss: 0.0921366 Test Loss: 0.0937309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783255\n",
      "\tspeed: 0.0400s/iter; left time: 58.8179s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866280\n",
      "\tspeed: 0.0201s/iter; left time: 27.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0799236 Vali Loss: 0.0931700 Test Loss: 0.0945515\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0824540\n",
      "\tspeed: 0.0368s/iter; left time: 45.7714s\n",
      "\titers: 200, epoch: 15 | loss: 0.0831191\n",
      "\tspeed: 0.0150s/iter; left time: 17.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 224 | Train Loss: 0.0793097 Vali Loss: 0.0933185 Test Loss: 0.0947299\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0815473\n",
      "\tspeed: 0.0406s/iter; left time: 41.4387s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750347\n",
      "\tspeed: 0.0187s/iter; left time: 17.1879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0790787 Vali Loss: 0.0923562 Test Loss: 0.0937883\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808074\n",
      "\tspeed: 0.0417s/iter; left time: 33.2736s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775904\n",
      "\tspeed: 0.0188s/iter; left time: 13.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0785762 Vali Loss: 0.0908945 Test Loss: 0.0925812\n",
      "Validation loss decreased (0.092095 --> 0.090894).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756037\n",
      "\tspeed: 0.0346s/iter; left time: 19.8085s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805556\n",
      "\tspeed: 0.0147s/iter; left time: 6.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0785004 Vali Loss: 0.0908220 Test Loss: 0.0929297\n",
      "Validation loss decreased (0.090894 --> 0.090822).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737558\n",
      "\tspeed: 0.0373s/iter; left time: 13.0124s\n",
      "\titers: 200, epoch: 19 | loss: 0.0755234\n",
      "\tspeed: 0.0191s/iter; left time: 4.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0781579 Vali Loss: 0.0911392 Test Loss: 0.0930117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0787621\n",
      "\tspeed: 0.0395s/iter; left time: 4.9421s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729006\n",
      "\tspeed: 0.0176s/iter; left time: 0.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0779672 Vali Loss: 0.0904612 Test Loss: 0.0926088\n",
      "Validation loss decreased (0.090822 --> 0.090461).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02197897806763649, rmse:0.14825308322906494, mae:0.09260880947113037, rse:0.5232056975364685\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2721842\n",
      "\tspeed: 0.0243s/iter; left time: 106.3451s\n",
      "\titers: 200, epoch: 1 | loss: 0.2545170\n",
      "\tspeed: 0.0229s/iter; left time: 98.2050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.2761312 Vali Loss: 0.2322660 Test Loss: 0.2356385\n",
      "Validation loss decreased (inf --> 0.232266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482331\n",
      "\tspeed: 0.0436s/iter; left time: 181.3371s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319499\n",
      "\tspeed: 0.0168s/iter; left time: 68.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1566612 Vali Loss: 0.1185808 Test Loss: 0.1211408\n",
      "Validation loss decreased (0.232266 --> 0.118581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1081690\n",
      "\tspeed: 0.0416s/iter; left time: 163.4521s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004020\n",
      "\tspeed: 0.0203s/iter; left time: 77.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.1067749 Vali Loss: 0.1074769 Test Loss: 0.1081204\n",
      "Validation loss decreased (0.118581 --> 0.107477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891181\n",
      "\tspeed: 0.0407s/iter; left time: 151.0011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888426\n",
      "\tspeed: 0.0221s/iter; left time: 79.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0955432 Vali Loss: 0.1000804 Test Loss: 0.1024884\n",
      "Validation loss decreased (0.107477 --> 0.100080).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895891\n",
      "\tspeed: 0.0455s/iter; left time: 158.5022s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858524\n",
      "\tspeed: 0.0239s/iter; left time: 81.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0902970 Vali Loss: 0.1001018 Test Loss: 0.1025615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886195\n",
      "\tspeed: 0.0386s/iter; left time: 126.0170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897056\n",
      "\tspeed: 0.0180s/iter; left time: 56.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0877654 Vali Loss: 0.0981362 Test Loss: 0.1006853\n",
      "Validation loss decreased (0.100080 --> 0.098136).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0878300\n",
      "\tspeed: 0.0404s/iter; left time: 122.5511s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826553\n",
      "\tspeed: 0.0179s/iter; left time: 52.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0857944 Vali Loss: 0.0958969 Test Loss: 0.0983018\n",
      "Validation loss decreased (0.098136 --> 0.095897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869670\n",
      "\tspeed: 0.0380s/iter; left time: 106.8424s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836679\n",
      "\tspeed: 0.0155s/iter; left time: 42.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0840915 Vali Loss: 0.0946294 Test Loss: 0.0966067\n",
      "Validation loss decreased (0.095897 --> 0.094629).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0806168\n",
      "\tspeed: 0.0346s/iter; left time: 89.6746s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788730\n",
      "\tspeed: 0.0148s/iter; left time: 36.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0832127 Vali Loss: 0.0942125 Test Loss: 0.0963571\n",
      "Validation loss decreased (0.094629 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0863781\n",
      "\tspeed: 0.0393s/iter; left time: 92.8334s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827872\n",
      "\tspeed: 0.0175s/iter; left time: 39.6821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0823142 Vali Loss: 0.0934206 Test Loss: 0.0951447\n",
      "Validation loss decreased (0.094213 --> 0.093421).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0842941\n",
      "\tspeed: 0.0419s/iter; left time: 89.8029s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798917\n",
      "\tspeed: 0.0194s/iter; left time: 39.6135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0812334 Vali Loss: 0.0930360 Test Loss: 0.0947575\n",
      "Validation loss decreased (0.093421 --> 0.093036).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834161\n",
      "\tspeed: 0.0394s/iter; left time: 75.4573s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799981\n",
      "\tspeed: 0.0187s/iter; left time: 33.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0807119 Vali Loss: 0.0929712 Test Loss: 0.0947066\n",
      "Validation loss decreased (0.093036 --> 0.092971).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815257\n",
      "\tspeed: 0.0393s/iter; left time: 66.4868s\n",
      "\titers: 200, epoch: 13 | loss: 0.0776588\n",
      "\tspeed: 0.0211s/iter; left time: 33.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0801480 Vali Loss: 0.0923747 Test Loss: 0.0944369\n",
      "Validation loss decreased (0.092971 --> 0.092375).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754340\n",
      "\tspeed: 0.0400s/iter; left time: 58.7758s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819355\n",
      "\tspeed: 0.0202s/iter; left time: 27.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0798022 Vali Loss: 0.0923370 Test Loss: 0.0939305\n",
      "Validation loss decreased (0.092375 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803141\n",
      "\tspeed: 0.0408s/iter; left time: 50.7472s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758411\n",
      "\tspeed: 0.0185s/iter; left time: 21.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0792215 Vali Loss: 0.0938695 Test Loss: 0.0954283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0765127\n",
      "\tspeed: 0.0409s/iter; left time: 41.7632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0853249\n",
      "\tspeed: 0.0218s/iter; left time: 20.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0790664 Vali Loss: 0.0919052 Test Loss: 0.0936920\n",
      "Validation loss decreased (0.092337 --> 0.091905).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0840101\n",
      "\tspeed: 0.0400s/iter; left time: 31.8896s\n",
      "\titers: 200, epoch: 17 | loss: 0.0743264\n",
      "\tspeed: 0.0179s/iter; left time: 12.4585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0785786 Vali Loss: 0.0913657 Test Loss: 0.0932587\n",
      "Validation loss decreased (0.091905 --> 0.091366).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0817556\n",
      "\tspeed: 0.0350s/iter; left time: 20.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0756749\n",
      "\tspeed: 0.0148s/iter; left time: 6.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 224 | Train Loss: 0.0783503 Vali Loss: 0.0909367 Test Loss: 0.0929703\n",
      "Validation loss decreased (0.091366 --> 0.090937).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806383\n",
      "\tspeed: 0.0398s/iter; left time: 13.8950s\n",
      "\titers: 200, epoch: 19 | loss: 0.0788134\n",
      "\tspeed: 0.0181s/iter; left time: 4.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0782910 Vali Loss: 0.0909684 Test Loss: 0.0929274\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790623\n",
      "\tspeed: 0.0404s/iter; left time: 5.0553s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762136\n",
      "\tspeed: 0.0197s/iter; left time: 0.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0779857 Vali Loss: 0.0904959 Test Loss: 0.0925888\n",
      "Validation loss decreased (0.090937 --> 0.090496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02206687070429325, rmse:0.14854921400547028, mae:0.09258876740932465, rse:0.5242507457733154\n",
      "Intermediate time for DE and pred_len 24: 00h:04m:01.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736132\n",
      "\tspeed: 0.0430s/iter; left time: 188.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666865\n",
      "\tspeed: 0.0151s/iter; left time: 64.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.2768083 Vali Loss: 0.2378515 Test Loss: 0.2420694\n",
      "Validation loss decreased (inf --> 0.237852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507936\n",
      "\tspeed: 0.0363s/iter; left time: 150.7416s\n",
      "\titers: 200, epoch: 2 | loss: 0.1408254\n",
      "\tspeed: 0.0158s/iter; left time: 63.9616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1661271 Vali Loss: 0.1429472 Test Loss: 0.1494990\n",
      "Validation loss decreased (0.237852 --> 0.142947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1299124\n",
      "\tspeed: 0.0351s/iter; left time: 138.0269s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142595\n",
      "\tspeed: 0.0161s/iter; left time: 61.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.1275650 Vali Loss: 0.1335137 Test Loss: 0.1425615\n",
      "Validation loss decreased (0.142947 --> 0.133514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1179868\n",
      "\tspeed: 0.0378s/iter; left time: 140.1385s\n",
      "\titers: 200, epoch: 4 | loss: 0.1146645\n",
      "\tspeed: 0.0169s/iter; left time: 60.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.1182946 Vali Loss: 0.1284872 Test Loss: 0.1368864\n",
      "Validation loss decreased (0.133514 --> 0.128487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154613\n",
      "\tspeed: 0.0415s/iter; left time: 144.5488s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144108\n",
      "\tspeed: 0.0173s/iter; left time: 58.7146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.1142573 Vali Loss: 0.1287418 Test Loss: 0.1378416\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1127394\n",
      "\tspeed: 0.0412s/iter; left time: 134.3089s\n",
      "\titers: 200, epoch: 6 | loss: 0.1117376\n",
      "\tspeed: 0.0193s/iter; left time: 61.0326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1113606 Vali Loss: 0.1263889 Test Loss: 0.1358710\n",
      "Validation loss decreased (0.128487 --> 0.126389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1064209\n",
      "\tspeed: 0.0417s/iter; left time: 126.4996s\n",
      "\titers: 200, epoch: 7 | loss: 0.1077087\n",
      "\tspeed: 0.0211s/iter; left time: 62.0929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1098816 Vali Loss: 0.1245850 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.126389 --> 0.124585).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1071428\n",
      "\tspeed: 0.0438s/iter; left time: 123.3161s\n",
      "\titers: 200, epoch: 8 | loss: 0.1098332\n",
      "\tspeed: 0.0182s/iter; left time: 49.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.1085256 Vali Loss: 0.1228764 Test Loss: 0.1325587\n",
      "Validation loss decreased (0.124585 --> 0.122876).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091046\n",
      "\tspeed: 0.0403s/iter; left time: 104.2546s\n",
      "\titers: 200, epoch: 9 | loss: 0.1058773\n",
      "\tspeed: 0.0210s/iter; left time: 52.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.1076194 Vali Loss: 0.1230676 Test Loss: 0.1331647\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024526\n",
      "\tspeed: 0.0422s/iter; left time: 99.7800s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046620\n",
      "\tspeed: 0.0216s/iter; left time: 48.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.1068050 Vali Loss: 0.1238115 Test Loss: 0.1339175\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1050917\n",
      "\tspeed: 0.0380s/iter; left time: 81.4220s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087852\n",
      "\tspeed: 0.0192s/iter; left time: 39.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.1062710 Vali Loss: 0.1224169 Test Loss: 0.1335183\n",
      "Validation loss decreased (0.122876 --> 0.122417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1041678\n",
      "\tspeed: 0.0343s/iter; left time: 65.7672s\n",
      "\titers: 200, epoch: 12 | loss: 0.1055144\n",
      "\tspeed: 0.0149s/iter; left time: 27.1640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.1057814 Vali Loss: 0.1235624 Test Loss: 0.1354222\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099656\n",
      "\tspeed: 0.0393s/iter; left time: 66.4822s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019942\n",
      "\tspeed: 0.0181s/iter; left time: 28.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1053657 Vali Loss: 0.1217388 Test Loss: 0.1321293\n",
      "Validation loss decreased (0.122417 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065030\n",
      "\tspeed: 0.0415s/iter; left time: 60.9568s\n",
      "\titers: 200, epoch: 14 | loss: 0.1019161\n",
      "\tspeed: 0.0239s/iter; left time: 32.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.1048474 Vali Loss: 0.1213972 Test Loss: 0.1328275\n",
      "Validation loss decreased (0.121739 --> 0.121397).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064735\n",
      "\tspeed: 0.0439s/iter; left time: 54.6762s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097839\n",
      "\tspeed: 0.0186s/iter; left time: 21.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1045160 Vali Loss: 0.1222460 Test Loss: 0.1343367\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067084\n",
      "\tspeed: 0.0382s/iter; left time: 39.0436s\n",
      "\titers: 200, epoch: 16 | loss: 0.1051808\n",
      "\tspeed: 0.0150s/iter; left time: 13.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.1043004 Vali Loss: 0.1228778 Test Loss: 0.1355899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1024750\n",
      "\tspeed: 0.0401s/iter; left time: 31.9453s\n",
      "\titers: 200, epoch: 17 | loss: 0.1082835\n",
      "\tspeed: 0.0203s/iter; left time: 14.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.1040723 Vali Loss: 0.1217327 Test Loss: 0.1341039\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077258\n",
      "\tspeed: 0.0436s/iter; left time: 24.9728s\n",
      "\titers: 200, epoch: 18 | loss: 0.1071076\n",
      "\tspeed: 0.0175s/iter; left time: 8.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.1038721 Vali Loss: 0.1219171 Test Loss: 0.1344398\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1007329\n",
      "\tspeed: 0.0430s/iter; left time: 14.9942s\n",
      "\titers: 200, epoch: 19 | loss: 0.0997031\n",
      "\tspeed: 0.0224s/iter; left time: 5.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.1036606 Vali Loss: 0.1212491 Test Loss: 0.1334959\n",
      "Validation loss decreased (0.121397 --> 0.121249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997653\n",
      "\tspeed: 0.0434s/iter; left time: 5.4207s\n",
      "\titers: 200, epoch: 20 | loss: 0.0990844\n",
      "\tspeed: 0.0189s/iter; left time: 0.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.1034119 Vali Loss: 0.1213758 Test Loss: 0.1340542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04150562733411789, rmse:0.2037293016910553, mae:0.13349591195583344, rse:0.721446692943573\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2745755\n",
      "\tspeed: 0.0231s/iter; left time: 101.1925s\n",
      "\titers: 200, epoch: 1 | loss: 0.2692268\n",
      "\tspeed: 0.0205s/iter; left time: 87.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.2751624 Vali Loss: 0.2348203 Test Loss: 0.2388337\n",
      "Validation loss decreased (inf --> 0.234820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551890\n",
      "\tspeed: 0.0430s/iter; left time: 178.6480s\n",
      "\titers: 200, epoch: 2 | loss: 0.1321813\n",
      "\tspeed: 0.0205s/iter; left time: 83.3544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.1654698 Vali Loss: 0.1417630 Test Loss: 0.1481800\n",
      "Validation loss decreased (0.234820 --> 0.141763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1215974\n",
      "\tspeed: 0.0414s/iter; left time: 162.6355s\n",
      "\titers: 200, epoch: 3 | loss: 0.1256834\n",
      "\tspeed: 0.0180s/iter; left time: 68.8743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1263876 Vali Loss: 0.1325889 Test Loss: 0.1409987\n",
      "Validation loss decreased (0.141763 --> 0.132589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1135110\n",
      "\tspeed: 0.0366s/iter; left time: 135.8143s\n",
      "\titers: 200, epoch: 4 | loss: 0.1192949\n",
      "\tspeed: 0.0197s/iter; left time: 71.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1174851 Vali Loss: 0.1272122 Test Loss: 0.1361652\n",
      "Validation loss decreased (0.132589 --> 0.127212).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163965\n",
      "\tspeed: 0.0412s/iter; left time: 143.5414s\n",
      "\titers: 200, epoch: 5 | loss: 0.1152640\n",
      "\tspeed: 0.0170s/iter; left time: 57.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1131541 Vali Loss: 0.1246094 Test Loss: 0.1332051\n",
      "Validation loss decreased (0.127212 --> 0.124609).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112591\n",
      "\tspeed: 0.0460s/iter; left time: 150.0819s\n",
      "\titers: 200, epoch: 6 | loss: 0.1082482\n",
      "\tspeed: 0.0208s/iter; left time: 65.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1111110 Vali Loss: 0.1238740 Test Loss: 0.1333937\n",
      "Validation loss decreased (0.124609 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057189\n",
      "\tspeed: 0.0440s/iter; left time: 133.6901s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117747\n",
      "\tspeed: 0.0217s/iter; left time: 63.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.1091282 Vali Loss: 0.1267143 Test Loss: 0.1375530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1141506\n",
      "\tspeed: 0.0425s/iter; left time: 119.5498s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009115\n",
      "\tspeed: 0.0194s/iter; left time: 52.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1081073 Vali Loss: 0.1231339 Test Loss: 0.1339826\n",
      "Validation loss decreased (0.123874 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1019052\n",
      "\tspeed: 0.0418s/iter; left time: 108.3479s\n",
      "\titers: 200, epoch: 9 | loss: 0.1077909\n",
      "\tspeed: 0.0195s/iter; left time: 48.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1073068 Vali Loss: 0.1232993 Test Loss: 0.1331413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1092062\n",
      "\tspeed: 0.0459s/iter; left time: 108.6111s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068623\n",
      "\tspeed: 0.0207s/iter; left time: 46.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.1064968 Vali Loss: 0.1219509 Test Loss: 0.1326125\n",
      "Validation loss decreased (0.123134 --> 0.121951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040168\n",
      "\tspeed: 0.0438s/iter; left time: 93.7702s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067823\n",
      "\tspeed: 0.0196s/iter; left time: 40.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1059778 Vali Loss: 0.1218960 Test Loss: 0.1338872\n",
      "Validation loss decreased (0.121951 --> 0.121896).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011791\n",
      "\tspeed: 0.0429s/iter; left time: 82.2716s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045789\n",
      "\tspeed: 0.0198s/iter; left time: 35.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.1055520 Vali Loss: 0.1224215 Test Loss: 0.1361842\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020355\n",
      "\tspeed: 0.0422s/iter; left time: 71.3961s\n",
      "\titers: 200, epoch: 13 | loss: 0.1006409\n",
      "\tspeed: 0.0192s/iter; left time: 30.6429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.1050931 Vali Loss: 0.1211242 Test Loss: 0.1328582\n",
      "Validation loss decreased (0.121896 --> 0.121124).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1023372\n",
      "\tspeed: 0.0430s/iter; left time: 63.2301s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056428\n",
      "\tspeed: 0.0200s/iter; left time: 27.3520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1046984 Vali Loss: 0.1215836 Test Loss: 0.1348134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028019\n",
      "\tspeed: 0.0424s/iter; left time: 52.7950s\n",
      "\titers: 200, epoch: 15 | loss: 0.1016776\n",
      "\tspeed: 0.0204s/iter; left time: 23.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.1043435 Vali Loss: 0.1219964 Test Loss: 0.1366068\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1028563\n",
      "\tspeed: 0.0417s/iter; left time: 42.5348s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091383\n",
      "\tspeed: 0.0203s/iter; left time: 18.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1043203 Vali Loss: 0.1209410 Test Loss: 0.1350278\n",
      "Validation loss decreased (0.121124 --> 0.120941).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1068253\n",
      "\tspeed: 0.0427s/iter; left time: 34.0030s\n",
      "\titers: 200, epoch: 17 | loss: 0.1018474\n",
      "\tspeed: 0.0199s/iter; left time: 13.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1039987 Vali Loss: 0.1214914 Test Loss: 0.1367325\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1014489\n",
      "\tspeed: 0.0429s/iter; left time: 24.5558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990626\n",
      "\tspeed: 0.0180s/iter; left time: 8.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1036466 Vali Loss: 0.1200883 Test Loss: 0.1337987\n",
      "Validation loss decreased (0.120941 --> 0.120088).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1060394\n",
      "\tspeed: 0.0420s/iter; left time: 14.6721s\n",
      "\titers: 200, epoch: 19 | loss: 0.1063231\n",
      "\tspeed: 0.0203s/iter; left time: 5.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.1036820 Vali Loss: 0.1203940 Test Loss: 0.1338672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1069428\n",
      "\tspeed: 0.0446s/iter; left time: 5.5812s\n",
      "\titers: 200, epoch: 20 | loss: 0.1037648\n",
      "\tspeed: 0.0219s/iter; left time: 0.5476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1033537 Vali Loss: 0.1214264 Test Loss: 0.1366773\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04148979112505913, rmse:0.20369042456150055, mae:0.1337987184524536, rse:0.7213089466094971\n",
      "Intermediate time for DE and pred_len 96: 00h:04m:15.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2775596\n",
      "\tspeed: 0.0439s/iter; left time: 191.5382s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569817\n",
      "\tspeed: 0.0152s/iter; left time: 64.8704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.2765906 Vali Loss: 0.2382076 Test Loss: 0.2423068\n",
      "Validation loss decreased (inf --> 0.238208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1659802\n",
      "\tspeed: 0.0377s/iter; left time: 155.8441s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432662\n",
      "\tspeed: 0.0162s/iter; left time: 65.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.1672125 Vali Loss: 0.1447522 Test Loss: 0.1532751\n",
      "Validation loss decreased (0.238208 --> 0.144752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1307262\n",
      "\tspeed: 0.0376s/iter; left time: 147.3971s\n",
      "\titers: 200, epoch: 3 | loss: 0.1302076\n",
      "\tspeed: 0.0162s/iter; left time: 61.6237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.1312369 Vali Loss: 0.1360940 Test Loss: 0.1473139\n",
      "Validation loss decreased (0.144752 --> 0.136094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1212680\n",
      "\tspeed: 0.0406s/iter; left time: 150.0676s\n",
      "\titers: 200, epoch: 4 | loss: 0.1224551\n",
      "\tspeed: 0.0174s/iter; left time: 62.5027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1229487 Vali Loss: 0.1332138 Test Loss: 0.1448441\n",
      "Validation loss decreased (0.136094 --> 0.133214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205248\n",
      "\tspeed: 0.0362s/iter; left time: 125.5862s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178578\n",
      "\tspeed: 0.0153s/iter; left time: 51.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.1188213 Vali Loss: 0.1316868 Test Loss: 0.1432350\n",
      "Validation loss decreased (0.133214 --> 0.131687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139779\n",
      "\tspeed: 0.0391s/iter; left time: 126.8707s\n",
      "\titers: 200, epoch: 6 | loss: 0.1160806\n",
      "\tspeed: 0.0196s/iter; left time: 61.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.1166615 Vali Loss: 0.1312616 Test Loss: 0.1434518\n",
      "Validation loss decreased (0.131687 --> 0.131262).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101308\n",
      "\tspeed: 0.0369s/iter; left time: 111.4829s\n",
      "\titers: 200, epoch: 7 | loss: 0.1176211\n",
      "\tspeed: 0.0170s/iter; left time: 49.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1149890 Vali Loss: 0.1308758 Test Loss: 0.1414910\n",
      "Validation loss decreased (0.131262 --> 0.130876).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1170567\n",
      "\tspeed: 0.0430s/iter; left time: 120.3620s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133619\n",
      "\tspeed: 0.0196s/iter; left time: 52.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1136990 Vali Loss: 0.1320824 Test Loss: 0.1430046\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1098235\n",
      "\tspeed: 0.0443s/iter; left time: 114.0898s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161616\n",
      "\tspeed: 0.0219s/iter; left time: 54.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.1129141 Vali Loss: 0.1336947 Test Loss: 0.1457070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097349\n",
      "\tspeed: 0.0420s/iter; left time: 98.9149s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251913\n",
      "\tspeed: 0.0224s/iter; left time: 50.5666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1124273 Vali Loss: 0.1302290 Test Loss: 0.1421578\n",
      "Validation loss decreased (0.130876 --> 0.130229).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1120517\n",
      "\tspeed: 0.0387s/iter; left time: 82.4958s\n",
      "\titers: 200, epoch: 11 | loss: 0.1183278\n",
      "\tspeed: 0.0176s/iter; left time: 35.8090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1116025 Vali Loss: 0.1312475 Test Loss: 0.1426525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102902\n",
      "\tspeed: 0.0394s/iter; left time: 75.2060s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114199\n",
      "\tspeed: 0.0220s/iter; left time: 39.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.1110861 Vali Loss: 0.1303061 Test Loss: 0.1418720\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1119011\n",
      "\tspeed: 0.0391s/iter; left time: 65.9126s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101568\n",
      "\tspeed: 0.0192s/iter; left time: 30.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.1106874 Vali Loss: 0.1296490 Test Loss: 0.1413447\n",
      "Validation loss decreased (0.130229 --> 0.129649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083368\n",
      "\tspeed: 0.0452s/iter; left time: 66.0310s\n",
      "\titers: 200, epoch: 14 | loss: 0.1085108\n",
      "\tspeed: 0.0166s/iter; left time: 22.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.1103532 Vali Loss: 0.1285899 Test Loss: 0.1395985\n",
      "Validation loss decreased (0.129649 --> 0.128590).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037617\n",
      "\tspeed: 0.0378s/iter; left time: 46.8659s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034313\n",
      "\tspeed: 0.0168s/iter; left time: 19.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1100171 Vali Loss: 0.1288376 Test Loss: 0.1399395\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060215\n",
      "\tspeed: 0.0403s/iter; left time: 40.8990s\n",
      "\titers: 200, epoch: 16 | loss: 0.1082558\n",
      "\tspeed: 0.0160s/iter; left time: 14.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1096838 Vali Loss: 0.1306675 Test Loss: 0.1433185\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1085655\n",
      "\tspeed: 0.0366s/iter; left time: 29.0507s\n",
      "\titers: 200, epoch: 17 | loss: 0.1068608\n",
      "\tspeed: 0.0187s/iter; left time: 12.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1094086 Vali Loss: 0.1302110 Test Loss: 0.1429073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073974\n",
      "\tspeed: 0.0402s/iter; left time: 22.9373s\n",
      "\titers: 200, epoch: 18 | loss: 0.1043494\n",
      "\tspeed: 0.0193s/iter; left time: 9.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.1092473 Vali Loss: 0.1295644 Test Loss: 0.1412514\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1114719\n",
      "\tspeed: 0.0355s/iter; left time: 12.3296s\n",
      "\titers: 200, epoch: 19 | loss: 0.1051146\n",
      "\tspeed: 0.0152s/iter; left time: 3.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 223 | Train Loss: 0.1089294 Vali Loss: 0.1286464 Test Loss: 0.1404462\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04356519505381584, rmse:0.2087227702140808, mae:0.1395985186100006, rse:0.7393128275871277\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812734\n",
      "\tspeed: 0.0232s/iter; left time: 101.0154s\n",
      "\titers: 200, epoch: 1 | loss: 0.2648552\n",
      "\tspeed: 0.0195s/iter; left time: 82.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.2822170 Vali Loss: 0.2397827 Test Loss: 0.2450302\n",
      "Validation loss decreased (inf --> 0.239783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632033\n",
      "\tspeed: 0.0471s/iter; left time: 194.9388s\n",
      "\titers: 200, epoch: 2 | loss: 0.1432949\n",
      "\tspeed: 0.0201s/iter; left time: 81.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1688149 Vali Loss: 0.1457720 Test Loss: 0.1536164\n",
      "Validation loss decreased (0.239783 --> 0.145772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1266351\n",
      "\tspeed: 0.0414s/iter; left time: 162.2200s\n",
      "\titers: 200, epoch: 3 | loss: 0.1198552\n",
      "\tspeed: 0.0170s/iter; left time: 64.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1316933 Vali Loss: 0.1368362 Test Loss: 0.1507061\n",
      "Validation loss decreased (0.145772 --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1193674\n",
      "\tspeed: 0.0445s/iter; left time: 164.2317s\n",
      "\titers: 200, epoch: 4 | loss: 0.1206695\n",
      "\tspeed: 0.0182s/iter; left time: 65.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.1227247 Vali Loss: 0.1357975 Test Loss: 0.1491872\n",
      "Validation loss decreased (0.136836 --> 0.135798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187348\n",
      "\tspeed: 0.0410s/iter; left time: 142.2345s\n",
      "\titers: 200, epoch: 5 | loss: 0.1190373\n",
      "\tspeed: 0.0179s/iter; left time: 60.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1191489 Vali Loss: 0.1308743 Test Loss: 0.1448017\n",
      "Validation loss decreased (0.135798 --> 0.130874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146746\n",
      "\tspeed: 0.0375s/iter; left time: 121.6796s\n",
      "\titers: 200, epoch: 6 | loss: 0.1148309\n",
      "\tspeed: 0.0152s/iter; left time: 47.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1166092 Vali Loss: 0.1314674 Test Loss: 0.1459267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1175115\n",
      "\tspeed: 0.0387s/iter; left time: 116.8615s\n",
      "\titers: 200, epoch: 7 | loss: 0.1088397\n",
      "\tspeed: 0.0181s/iter; left time: 52.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1151693 Vali Loss: 0.1312253 Test Loss: 0.1448718\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1191927\n",
      "\tspeed: 0.0398s/iter; left time: 111.5100s\n",
      "\titers: 200, epoch: 8 | loss: 0.1117679\n",
      "\tspeed: 0.0174s/iter; left time: 47.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1141006 Vali Loss: 0.1306444 Test Loss: 0.1441707\n",
      "Validation loss decreased (0.130874 --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1125659\n",
      "\tspeed: 0.0387s/iter; left time: 99.6633s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103978\n",
      "\tspeed: 0.0180s/iter; left time: 44.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1131375 Vali Loss: 0.1308488 Test Loss: 0.1439586\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1097929\n",
      "\tspeed: 0.0390s/iter; left time: 91.8675s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076796\n",
      "\tspeed: 0.0198s/iter; left time: 44.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1123829 Vali Loss: 0.1314475 Test Loss: 0.1447518\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068592\n",
      "\tspeed: 0.0413s/iter; left time: 87.9852s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085388\n",
      "\tspeed: 0.0231s/iter; left time: 46.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.1117776 Vali Loss: 0.1311427 Test Loss: 0.1450391\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080086\n",
      "\tspeed: 0.0432s/iter; left time: 82.4600s\n",
      "\titers: 200, epoch: 12 | loss: 0.1089400\n",
      "\tspeed: 0.0164s/iter; left time: 29.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.1112884 Vali Loss: 0.1306694 Test Loss: 0.1443284\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1129659\n",
      "\tspeed: 0.0410s/iter; left time: 69.0417s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087663\n",
      "\tspeed: 0.0205s/iter; left time: 32.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.1107222 Vali Loss: 0.1300552 Test Loss: 0.1437648\n",
      "Validation loss decreased (0.130644 --> 0.130055).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1106686\n",
      "\tspeed: 0.0391s/iter; left time: 57.1526s\n",
      "\titers: 200, epoch: 14 | loss: 0.1079151\n",
      "\tspeed: 0.0164s/iter; left time: 22.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.1102911 Vali Loss: 0.1309756 Test Loss: 0.1456672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1096638\n",
      "\tspeed: 0.0417s/iter; left time: 51.6157s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065728\n",
      "\tspeed: 0.0165s/iter; left time: 18.7695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1099320 Vali Loss: 0.1304136 Test Loss: 0.1437775\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1128930\n",
      "\tspeed: 0.0394s/iter; left time: 40.0729s\n",
      "\titers: 200, epoch: 16 | loss: 0.1056558\n",
      "\tspeed: 0.0172s/iter; left time: 15.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1095359 Vali Loss: 0.1290297 Test Loss: 0.1434999\n",
      "Validation loss decreased (0.130055 --> 0.129030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1129074\n",
      "\tspeed: 0.0367s/iter; left time: 29.0794s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060182\n",
      "\tspeed: 0.0152s/iter; left time: 10.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1093078 Vali Loss: 0.1279821 Test Loss: 0.1426028\n",
      "Validation loss decreased (0.129030 --> 0.127982).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089246\n",
      "\tspeed: 0.0375s/iter; left time: 21.3832s\n",
      "\titers: 200, epoch: 18 | loss: 0.1129903\n",
      "\tspeed: 0.0177s/iter; left time: 8.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.1088755 Vali Loss: 0.1292565 Test Loss: 0.1439340\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1071319\n",
      "\tspeed: 0.0373s/iter; left time: 12.9416s\n",
      "\titers: 200, epoch: 19 | loss: 0.1072017\n",
      "\tspeed: 0.0170s/iter; left time: 4.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1088933 Vali Loss: 0.1299791 Test Loss: 0.1445618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1044815\n",
      "\tspeed: 0.0412s/iter; left time: 5.1139s\n",
      "\titers: 200, epoch: 20 | loss: 0.1130169\n",
      "\tspeed: 0.0201s/iter; left time: 0.4823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1085727 Vali Loss: 0.1287442 Test Loss: 0.1427801\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046037085354328156, rmse:0.2145625501871109, mae:0.1426028162240982, rse:0.7599977850914001\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:59.59s\n",
      "Intermediate time for DE: 00h:12m:16.41s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2922991\n",
      "\tspeed: 0.0435s/iter; left time: 190.3553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2676132\n",
      "\tspeed: 0.0148s/iter; left time: 63.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.2917547 Vali Loss: 0.2406866 Test Loss: 0.2605934\n",
      "Validation loss decreased (inf --> 0.240687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1394869\n",
      "\tspeed: 0.0327s/iter; left time: 135.9060s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168394\n",
      "\tspeed: 0.0163s/iter; left time: 66.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 224 | Train Loss: 0.1571284 Vali Loss: 0.1102135 Test Loss: 0.1260506\n",
      "Validation loss decreased (0.240687 --> 0.110213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012487\n",
      "\tspeed: 0.0368s/iter; left time: 144.6387s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989198\n",
      "\tspeed: 0.0149s/iter; left time: 57.1036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.1026627 Vali Loss: 0.0972727 Test Loss: 0.1094594\n",
      "Validation loss decreased (0.110213 --> 0.097273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936888\n",
      "\tspeed: 0.0402s/iter; left time: 149.0718s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910165\n",
      "\tspeed: 0.0257s/iter; left time: 92.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0920333 Vali Loss: 0.0957121 Test Loss: 0.1082890\n",
      "Validation loss decreased (0.097273 --> 0.095712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878356\n",
      "\tspeed: 0.0353s/iter; left time: 122.9316s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851627\n",
      "\tspeed: 0.0159s/iter; left time: 53.7507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0884273 Vali Loss: 0.0955175 Test Loss: 0.1085468\n",
      "Validation loss decreased (0.095712 --> 0.095517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843207\n",
      "\tspeed: 0.0395s/iter; left time: 128.7514s\n",
      "\titers: 200, epoch: 6 | loss: 0.0818552\n",
      "\tspeed: 0.0187s/iter; left time: 59.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0866632 Vali Loss: 0.0946864 Test Loss: 0.1076631\n",
      "Validation loss decreased (0.095517 --> 0.094686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854201\n",
      "\tspeed: 0.0409s/iter; left time: 124.2592s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0198s/iter; left time: 58.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0848726 Vali Loss: 0.0945327 Test Loss: 0.1070153\n",
      "Validation loss decreased (0.094686 --> 0.094533).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828772\n",
      "\tspeed: 0.0431s/iter; left time: 121.1090s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833236\n",
      "\tspeed: 0.0213s/iter; left time: 57.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0838698 Vali Loss: 0.0937342 Test Loss: 0.1066275\n",
      "Validation loss decreased (0.094533 --> 0.093734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843508\n",
      "\tspeed: 0.0401s/iter; left time: 103.8674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866819\n",
      "\tspeed: 0.0204s/iter; left time: 50.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0827420 Vali Loss: 0.0952876 Test Loss: 0.1079009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0852804\n",
      "\tspeed: 0.0402s/iter; left time: 94.9955s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849879\n",
      "\tspeed: 0.0202s/iter; left time: 45.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0822287 Vali Loss: 0.0932017 Test Loss: 0.1066308\n",
      "Validation loss decreased (0.093734 --> 0.093202).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843942\n",
      "\tspeed: 0.0418s/iter; left time: 89.4398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0854915\n",
      "\tspeed: 0.0200s/iter; left time: 40.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0819387 Vali Loss: 0.0930846 Test Loss: 0.1059252\n",
      "Validation loss decreased (0.093202 --> 0.093085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810088\n",
      "\tspeed: 0.0419s/iter; left time: 80.2351s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814437\n",
      "\tspeed: 0.0196s/iter; left time: 35.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0813424 Vali Loss: 0.0933515 Test Loss: 0.1059433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0859062\n",
      "\tspeed: 0.0396s/iter; left time: 67.0201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0786974\n",
      "\tspeed: 0.0189s/iter; left time: 30.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0813130 Vali Loss: 0.0929570 Test Loss: 0.1060662\n",
      "Validation loss decreased (0.093085 --> 0.092957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0844461\n",
      "\tspeed: 0.0443s/iter; left time: 65.1099s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814904\n",
      "\tspeed: 0.0195s/iter; left time: 26.7234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0807832 Vali Loss: 0.0933856 Test Loss: 0.1062095\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0758336\n",
      "\tspeed: 0.0406s/iter; left time: 50.5078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877146\n",
      "\tspeed: 0.0201s/iter; left time: 23.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0804611 Vali Loss: 0.0937966 Test Loss: 0.1061317\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782495\n",
      "\tspeed: 0.0405s/iter; left time: 41.3443s\n",
      "\titers: 200, epoch: 16 | loss: 0.0797304\n",
      "\tspeed: 0.0196s/iter; left time: 18.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802571 Vali Loss: 0.0926483 Test Loss: 0.1059138\n",
      "Validation loss decreased (0.092957 --> 0.092648).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0867152\n",
      "\tspeed: 0.0420s/iter; left time: 33.4928s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758702\n",
      "\tspeed: 0.0221s/iter; left time: 15.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0799219 Vali Loss: 0.0926626 Test Loss: 0.1059690\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863227\n",
      "\tspeed: 0.0412s/iter; left time: 23.5835s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760747\n",
      "\tspeed: 0.0206s/iter; left time: 9.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0930944 Test Loss: 0.1060596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784171\n",
      "\tspeed: 0.0402s/iter; left time: 14.0362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0806827\n",
      "\tspeed: 0.0239s/iter; left time: 5.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0795418 Vali Loss: 0.0929014 Test Loss: 0.1061235\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0783778\n",
      "\tspeed: 0.0416s/iter; left time: 5.2052s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744846\n",
      "\tspeed: 0.0223s/iter; left time: 0.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0794190 Vali Loss: 0.0928615 Test Loss: 0.1061006\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026859937235713005, rmse:0.1638900190591812, mae:0.10591384768486023, rse:0.5653740763664246\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2846910\n",
      "\tspeed: 0.0228s/iter; left time: 99.8951s\n",
      "\titers: 200, epoch: 1 | loss: 0.2726133\n",
      "\tspeed: 0.0201s/iter; left time: 86.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.2926167 Vali Loss: 0.2415705 Test Loss: 0.2631590\n",
      "Validation loss decreased (inf --> 0.241570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474976\n",
      "\tspeed: 0.0414s/iter; left time: 172.1532s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268219\n",
      "\tspeed: 0.0199s/iter; left time: 80.7015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.1575704 Vali Loss: 0.1085933 Test Loss: 0.1230968\n",
      "Validation loss decreased (0.241570 --> 0.108593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0972578\n",
      "\tspeed: 0.0406s/iter; left time: 159.4984s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915387\n",
      "\tspeed: 0.0204s/iter; left time: 78.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.1023461 Vali Loss: 0.1003349 Test Loss: 0.1123432\n",
      "Validation loss decreased (0.108593 --> 0.100335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907324\n",
      "\tspeed: 0.0447s/iter; left time: 165.7056s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907905\n",
      "\tspeed: 0.0229s/iter; left time: 82.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0922343 Vali Loss: 0.0962823 Test Loss: 0.1112334\n",
      "Validation loss decreased (0.100335 --> 0.096282).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833255\n",
      "\tspeed: 0.0431s/iter; left time: 150.2721s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889493\n",
      "\tspeed: 0.0215s/iter; left time: 72.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0880692 Vali Loss: 0.0964027 Test Loss: 0.1125074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861537\n",
      "\tspeed: 0.0437s/iter; left time: 142.6286s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848577\n",
      "\tspeed: 0.0244s/iter; left time: 77.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0863465 Vali Loss: 0.0961963 Test Loss: 0.1143982\n",
      "Validation loss decreased (0.096282 --> 0.096196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867636\n",
      "\tspeed: 0.0465s/iter; left time: 141.0816s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810365\n",
      "\tspeed: 0.0240s/iter; left time: 70.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0849434 Vali Loss: 0.0958150 Test Loss: 0.1149141\n",
      "Validation loss decreased (0.096196 --> 0.095815).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857168\n",
      "\tspeed: 0.0387s/iter; left time: 108.9611s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765620\n",
      "\tspeed: 0.0220s/iter; left time: 59.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0839813 Vali Loss: 0.0954577 Test Loss: 0.1139534\n",
      "Validation loss decreased (0.095815 --> 0.095458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816585\n",
      "\tspeed: 0.0420s/iter; left time: 108.7967s\n",
      "\titers: 200, epoch: 9 | loss: 0.0860098\n",
      "\tspeed: 0.0200s/iter; left time: 49.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0829976 Vali Loss: 0.0949424 Test Loss: 0.1124260\n",
      "Validation loss decreased (0.095458 --> 0.094942).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758343\n",
      "\tspeed: 0.0431s/iter; left time: 101.9933s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839384\n",
      "\tspeed: 0.0176s/iter; left time: 39.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0826377 Vali Loss: 0.0951414 Test Loss: 0.1145257\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811790\n",
      "\tspeed: 0.0433s/iter; left time: 92.7424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0772140\n",
      "\tspeed: 0.0238s/iter; left time: 48.5164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 224 | Train Loss: 0.0818311 Vali Loss: 0.0955937 Test Loss: 0.1145437\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838942\n",
      "\tspeed: 0.0423s/iter; left time: 81.1573s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844036\n",
      "\tspeed: 0.0163s/iter; left time: 29.6119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0815183 Vali Loss: 0.0939972 Test Loss: 0.1111869\n",
      "Validation loss decreased (0.094942 --> 0.093997).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823378\n",
      "\tspeed: 0.0391s/iter; left time: 66.1277s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742934\n",
      "\tspeed: 0.0184s/iter; left time: 29.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0810441 Vali Loss: 0.0945207 Test Loss: 0.1117665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795040\n",
      "\tspeed: 0.0372s/iter; left time: 54.6020s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800683\n",
      "\tspeed: 0.0237s/iter; left time: 32.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0807827 Vali Loss: 0.0942772 Test Loss: 0.1117615\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812870\n",
      "\tspeed: 0.0442s/iter; left time: 55.0757s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817963\n",
      "\tspeed: 0.0197s/iter; left time: 22.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0804734 Vali Loss: 0.0958008 Test Loss: 0.1114092\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0762049\n",
      "\tspeed: 0.0399s/iter; left time: 40.7580s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810765\n",
      "\tspeed: 0.0201s/iter; left time: 18.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0802297 Vali Loss: 0.0947608 Test Loss: 0.1110980\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810842\n",
      "\tspeed: 0.0399s/iter; left time: 31.8312s\n",
      "\titers: 200, epoch: 17 | loss: 0.0765186\n",
      "\tspeed: 0.0179s/iter; left time: 12.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0800327 Vali Loss: 0.0935502 Test Loss: 0.1104114\n",
      "Validation loss decreased (0.093997 --> 0.093550).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781353\n",
      "\tspeed: 0.0368s/iter; left time: 21.0863s\n",
      "\titers: 200, epoch: 18 | loss: 0.0784078\n",
      "\tspeed: 0.0224s/iter; left time: 10.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0798923 Vali Loss: 0.0934620 Test Loss: 0.1093775\n",
      "Validation loss decreased (0.093550 --> 0.093462).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0748001\n",
      "\tspeed: 0.0401s/iter; left time: 13.9884s\n",
      "\titers: 200, epoch: 19 | loss: 0.0821338\n",
      "\tspeed: 0.0206s/iter; left time: 5.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0798001 Vali Loss: 0.0938784 Test Loss: 0.1097977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804354\n",
      "\tspeed: 0.0374s/iter; left time: 4.6728s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798344\n",
      "\tspeed: 0.0175s/iter; left time: 0.4369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0795825 Vali Loss: 0.0931064 Test Loss: 0.1094512\n",
      "Validation loss decreased (0.093462 --> 0.093106).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029882589355111122, rmse:0.17286580801010132, mae:0.10945114493370056, rse:0.5963380336761475\n",
      "Intermediate time for GB and pred_len 24: 00h:04m:15.07s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2905738\n",
      "\tspeed: 0.0430s/iter; left time: 188.4884s\n",
      "\titers: 200, epoch: 1 | loss: 0.2795239\n",
      "\tspeed: 0.0152s/iter; left time: 65.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.2927094 Vali Loss: 0.2496913 Test Loss: 0.2716323\n",
      "Validation loss decreased (inf --> 0.249691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543338\n",
      "\tspeed: 0.0358s/iter; left time: 148.7707s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355800\n",
      "\tspeed: 0.0164s/iter; left time: 66.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.1647835 Vali Loss: 0.1327218 Test Loss: 0.1546685\n",
      "Validation loss decreased (0.249691 --> 0.132722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231015\n",
      "\tspeed: 0.0376s/iter; left time: 147.8545s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142928\n",
      "\tspeed: 0.0163s/iter; left time: 62.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1205984 Vali Loss: 0.1253889 Test Loss: 0.1498923\n",
      "Validation loss decreased (0.132722 --> 0.125389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117683\n",
      "\tspeed: 0.0402s/iter; left time: 149.1697s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108735\n",
      "\tspeed: 0.0186s/iter; left time: 67.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.1130525 Vali Loss: 0.1236322 Test Loss: 0.1471900\n",
      "Validation loss decreased (0.125389 --> 0.123632).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1125513\n",
      "\tspeed: 0.0405s/iter; left time: 140.9723s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073470\n",
      "\tspeed: 0.0170s/iter; left time: 57.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1103534 Vali Loss: 0.1233914 Test Loss: 0.1453717\n",
      "Validation loss decreased (0.123632 --> 0.123391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089396\n",
      "\tspeed: 0.0388s/iter; left time: 126.4360s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076947\n",
      "\tspeed: 0.0169s/iter; left time: 53.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1086955 Vali Loss: 0.1249568 Test Loss: 0.1494265\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1097222\n",
      "\tspeed: 0.0425s/iter; left time: 129.0258s\n",
      "\titers: 200, epoch: 7 | loss: 0.1052158\n",
      "\tspeed: 0.0202s/iter; left time: 59.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.1078495 Vali Loss: 0.1228989 Test Loss: 0.1473706\n",
      "Validation loss decreased (0.123391 --> 0.122899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039853\n",
      "\tspeed: 0.0442s/iter; left time: 124.2065s\n",
      "\titers: 200, epoch: 8 | loss: 0.1081562\n",
      "\tspeed: 0.0175s/iter; left time: 47.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.1068872 Vali Loss: 0.1229032 Test Loss: 0.1486415\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063279\n",
      "\tspeed: 0.0427s/iter; left time: 110.5375s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039845\n",
      "\tspeed: 0.0198s/iter; left time: 49.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.1058605 Vali Loss: 0.1238546 Test Loss: 0.1496020\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040630\n",
      "\tspeed: 0.0402s/iter; left time: 95.0017s\n",
      "\titers: 200, epoch: 10 | loss: 0.1092972\n",
      "\tspeed: 0.0168s/iter; left time: 38.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1051489 Vali Loss: 0.1242632 Test Loss: 0.1526208\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037293\n",
      "\tspeed: 0.0358s/iter; left time: 76.5532s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081740\n",
      "\tspeed: 0.0211s/iter; left time: 43.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.1047050 Vali Loss: 0.1228776 Test Loss: 0.1521158\n",
      "Validation loss decreased (0.122899 --> 0.122878).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020854\n",
      "\tspeed: 0.0355s/iter; left time: 68.0435s\n",
      "\titers: 200, epoch: 12 | loss: 0.1035387\n",
      "\tspeed: 0.0150s/iter; left time: 27.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.1043232 Vali Loss: 0.1251580 Test Loss: 0.1549925\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1054577\n",
      "\tspeed: 0.0347s/iter; left time: 58.8282s\n",
      "\titers: 200, epoch: 13 | loss: 0.1030499\n",
      "\tspeed: 0.0150s/iter; left time: 23.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.1040331 Vali Loss: 0.1259337 Test Loss: 0.1572803\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028762\n",
      "\tspeed: 0.0398s/iter; left time: 58.4047s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005717\n",
      "\tspeed: 0.0171s/iter; left time: 23.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1037315 Vali Loss: 0.1248601 Test Loss: 0.1567430\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050472\n",
      "\tspeed: 0.0372s/iter; left time: 46.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.1046154\n",
      "\tspeed: 0.0171s/iter; left time: 19.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.1033158 Vali Loss: 0.1253818 Test Loss: 0.1575122\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1025380\n",
      "\tspeed: 0.0384s/iter; left time: 39.1689s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013871\n",
      "\tspeed: 0.0150s/iter; left time: 13.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.1032884 Vali Loss: 0.1257692 Test Loss: 0.1583786\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051575470715761185, rmse:0.2271023392677307, mae:0.1521158665418625, rse:0.785351574420929\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2884372\n",
      "\tspeed: 0.0267s/iter; left time: 117.0733s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747863\n",
      "\tspeed: 0.0177s/iter; left time: 75.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.2938896 Vali Loss: 0.2499466 Test Loss: 0.2730130\n",
      "Validation loss decreased (inf --> 0.249947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520033\n",
      "\tspeed: 0.0412s/iter; left time: 171.0818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1356943\n",
      "\tspeed: 0.0178s/iter; left time: 72.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.1651964 Vali Loss: 0.1318234 Test Loss: 0.1534363\n",
      "Validation loss decreased (0.249947 --> 0.131823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1237962\n",
      "\tspeed: 0.0358s/iter; left time: 140.8860s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129839\n",
      "\tspeed: 0.0151s/iter; left time: 57.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.1195505 Vali Loss: 0.1288494 Test Loss: 0.1563801\n",
      "Validation loss decreased (0.131823 --> 0.128849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1170108\n",
      "\tspeed: 0.0395s/iter; left time: 146.4454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1174021\n",
      "\tspeed: 0.0185s/iter; left time: 66.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.1124832 Vali Loss: 0.1280748 Test Loss: 0.1573510\n",
      "Validation loss decreased (0.128849 --> 0.128075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121775\n",
      "\tspeed: 0.0392s/iter; left time: 136.4653s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137156\n",
      "\tspeed: 0.0167s/iter; left time: 56.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1097073 Vali Loss: 0.1282495 Test Loss: 0.1588879\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1099907\n",
      "\tspeed: 0.0440s/iter; left time: 143.4599s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046706\n",
      "\tspeed: 0.0192s/iter; left time: 60.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.1083800 Vali Loss: 0.1289193 Test Loss: 0.1627320\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1065593\n",
      "\tspeed: 0.0402s/iter; left time: 121.9594s\n",
      "\titers: 200, epoch: 7 | loss: 0.1135744\n",
      "\tspeed: 0.0177s/iter; left time: 51.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1073907 Vali Loss: 0.1286131 Test Loss: 0.1610762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1053690\n",
      "\tspeed: 0.0411s/iter; left time: 115.6703s\n",
      "\titers: 200, epoch: 8 | loss: 0.1122044\n",
      "\tspeed: 0.0166s/iter; left time: 44.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1064029 Vali Loss: 0.1285266 Test Loss: 0.1602909\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083794\n",
      "\tspeed: 0.0368s/iter; left time: 95.1511s\n",
      "\titers: 200, epoch: 9 | loss: 0.1089216\n",
      "\tspeed: 0.0187s/iter; left time: 46.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1057083 Vali Loss: 0.1278156 Test Loss: 0.1567183\n",
      "Validation loss decreased (0.128075 --> 0.127816).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061578\n",
      "\tspeed: 0.0383s/iter; left time: 90.5282s\n",
      "\titers: 200, epoch: 10 | loss: 0.1020783\n",
      "\tspeed: 0.0162s/iter; left time: 36.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1050890 Vali Loss: 0.1274880 Test Loss: 0.1587726\n",
      "Validation loss decreased (0.127816 --> 0.127488).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1040444\n",
      "\tspeed: 0.0422s/iter; left time: 90.3190s\n",
      "\titers: 200, epoch: 11 | loss: 0.1054638\n",
      "\tspeed: 0.0198s/iter; left time: 40.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1047036 Vali Loss: 0.1277202 Test Loss: 0.1562177\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1064437\n",
      "\tspeed: 0.0417s/iter; left time: 79.9505s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029790\n",
      "\tspeed: 0.0154s/iter; left time: 28.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1041447 Vali Loss: 0.1276648 Test Loss: 0.1580956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009996\n",
      "\tspeed: 0.0377s/iter; left time: 63.8546s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043827\n",
      "\tspeed: 0.0173s/iter; left time: 27.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1039346 Vali Loss: 0.1263682 Test Loss: 0.1542069\n",
      "Validation loss decreased (0.127488 --> 0.126368).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1028414\n",
      "\tspeed: 0.0379s/iter; left time: 55.6054s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043060\n",
      "\tspeed: 0.0164s/iter; left time: 22.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1265923 Test Loss: 0.1548574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1049191\n",
      "\tspeed: 0.0402s/iter; left time: 49.9972s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034089\n",
      "\tspeed: 0.0183s/iter; left time: 20.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.1032026 Vali Loss: 0.1266271 Test Loss: 0.1559636\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0956138\n",
      "\tspeed: 0.0410s/iter; left time: 41.8472s\n",
      "\titers: 200, epoch: 16 | loss: 0.0995768\n",
      "\tspeed: 0.0196s/iter; left time: 18.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.1030918 Vali Loss: 0.1263742 Test Loss: 0.1539116\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0985429\n",
      "\tspeed: 0.0407s/iter; left time: 32.4426s\n",
      "\titers: 200, epoch: 17 | loss: 0.0990500\n",
      "\tspeed: 0.0197s/iter; left time: 13.7169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.1027496 Vali Loss: 0.1258379 Test Loss: 0.1540648\n",
      "Validation loss decreased (0.126368 --> 0.125838).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1027168\n",
      "\tspeed: 0.0371s/iter; left time: 21.2536s\n",
      "\titers: 200, epoch: 18 | loss: 0.1045104\n",
      "\tspeed: 0.0151s/iter; left time: 7.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 224 | Train Loss: 0.1025700 Vali Loss: 0.1264045 Test Loss: 0.1539411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973583\n",
      "\tspeed: 0.0401s/iter; left time: 14.0009s\n",
      "\titers: 200, epoch: 19 | loss: 0.1044858\n",
      "\tspeed: 0.0194s/iter; left time: 4.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.1024406 Vali Loss: 0.1257624 Test Loss: 0.1536622\n",
      "Validation loss decreased (0.125838 --> 0.125762).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1020775\n",
      "\tspeed: 0.0403s/iter; left time: 5.0356s\n",
      "\titers: 200, epoch: 20 | loss: 0.1067188\n",
      "\tspeed: 0.0173s/iter; left time: 0.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1022315 Vali Loss: 0.1262378 Test Loss: 0.1535022\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05444870516657829, rmse:0.2333424687385559, mae:0.15366211533546448, rse:0.8069307208061218\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:36.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936226\n",
      "\tspeed: 0.0438s/iter; left time: 191.2010s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744738\n",
      "\tspeed: 0.0152s/iter; left time: 64.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.2923195 Vali Loss: 0.2512568 Test Loss: 0.2713609\n",
      "Validation loss decreased (inf --> 0.251257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1544174\n",
      "\tspeed: 0.0362s/iter; left time: 149.9088s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344596\n",
      "\tspeed: 0.0154s/iter; left time: 62.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.1638412 Vali Loss: 0.1355720 Test Loss: 0.1590577\n",
      "Validation loss decreased (0.251257 --> 0.135572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217984\n",
      "\tspeed: 0.0358s/iter; left time: 140.1314s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199135\n",
      "\tspeed: 0.0161s/iter; left time: 61.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.1237435 Vali Loss: 0.1320853 Test Loss: 0.1594250\n",
      "Validation loss decreased (0.135572 --> 0.132085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164371\n",
      "\tspeed: 0.0384s/iter; left time: 141.7215s\n",
      "\titers: 200, epoch: 4 | loss: 0.1179138\n",
      "\tspeed: 0.0188s/iter; left time: 67.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.1173361 Vali Loss: 0.1301982 Test Loss: 0.1590181\n",
      "Validation loss decreased (0.132085 --> 0.130198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156407\n",
      "\tspeed: 0.0393s/iter; left time: 136.4173s\n",
      "\titers: 200, epoch: 5 | loss: 0.1160789\n",
      "\tspeed: 0.0171s/iter; left time: 57.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1142800 Vali Loss: 0.1292110 Test Loss: 0.1585684\n",
      "Validation loss decreased (0.130198 --> 0.129211).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114794\n",
      "\tspeed: 0.0369s/iter; left time: 119.6598s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116027\n",
      "\tspeed: 0.0163s/iter; left time: 51.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.1129644 Vali Loss: 0.1298441 Test Loss: 0.1576752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104282\n",
      "\tspeed: 0.0347s/iter; left time: 104.8698s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106339\n",
      "\tspeed: 0.0152s/iter; left time: 44.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.1119161 Vali Loss: 0.1286768 Test Loss: 0.1565256\n",
      "Validation loss decreased (0.129211 --> 0.128677).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1134205\n",
      "\tspeed: 0.0350s/iter; left time: 97.9654s\n",
      "\titers: 200, epoch: 8 | loss: 0.1067536\n",
      "\tspeed: 0.0158s/iter; left time: 42.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.1107069 Vali Loss: 0.1279850 Test Loss: 0.1570184\n",
      "Validation loss decreased (0.128677 --> 0.127985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1083541\n",
      "\tspeed: 0.0368s/iter; left time: 94.8146s\n",
      "\titers: 200, epoch: 9 | loss: 0.1134817\n",
      "\tspeed: 0.0181s/iter; left time: 44.9458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1100107 Vali Loss: 0.1282056 Test Loss: 0.1577516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1102495\n",
      "\tspeed: 0.0375s/iter; left time: 88.2266s\n",
      "\titers: 200, epoch: 10 | loss: 0.1155696\n",
      "\tspeed: 0.0163s/iter; left time: 36.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.1095580 Vali Loss: 0.1285466 Test Loss: 0.1575716\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099085\n",
      "\tspeed: 0.0428s/iter; left time: 91.3031s\n",
      "\titers: 200, epoch: 11 | loss: 0.1146683\n",
      "\tspeed: 0.0181s/iter; left time: 36.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1088179 Vali Loss: 0.1285248 Test Loss: 0.1578455\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066065\n",
      "\tspeed: 0.0398s/iter; left time: 75.8478s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095320\n",
      "\tspeed: 0.0167s/iter; left time: 30.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1085192 Vali Loss: 0.1295127 Test Loss: 0.1583694\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1082307\n",
      "\tspeed: 0.0365s/iter; left time: 61.4309s\n",
      "\titers: 200, epoch: 13 | loss: 0.1064241\n",
      "\tspeed: 0.0165s/iter; left time: 26.1725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.1081421 Vali Loss: 0.1291330 Test Loss: 0.1589368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05382132530212402, rmse:0.23199424147605896, mae:0.15701839327812195, rse:0.8043572902679443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2910986\n",
      "\tspeed: 0.0211s/iter; left time: 91.9743s\n",
      "\titers: 200, epoch: 1 | loss: 0.2834949\n",
      "\tspeed: 0.0173s/iter; left time: 73.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.2923341 Vali Loss: 0.2478191 Test Loss: 0.2692312\n",
      "Validation loss decreased (inf --> 0.247819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1509961\n",
      "\tspeed: 0.0372s/iter; left time: 153.8542s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339484\n",
      "\tspeed: 0.0173s/iter; left time: 69.7183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1644157 Vali Loss: 0.1374244 Test Loss: 0.1619911\n",
      "Validation loss decreased (0.247819 --> 0.137424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1268936\n",
      "\tspeed: 0.0398s/iter; left time: 155.7353s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223414\n",
      "\tspeed: 0.0175s/iter; left time: 66.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1241407 Vali Loss: 0.1313642 Test Loss: 0.1588054\n",
      "Validation loss decreased (0.137424 --> 0.131364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162787\n",
      "\tspeed: 0.0452s/iter; left time: 166.9792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1151809\n",
      "\tspeed: 0.0188s/iter; left time: 67.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1166980 Vali Loss: 0.1309440 Test Loss: 0.1621463\n",
      "Validation loss decreased (0.131364 --> 0.130944).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1171696\n",
      "\tspeed: 0.0398s/iter; left time: 138.0942s\n",
      "\titers: 200, epoch: 5 | loss: 0.1122425\n",
      "\tspeed: 0.0162s/iter; left time: 54.5908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.1139985 Vali Loss: 0.1325590 Test Loss: 0.1652431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128479\n",
      "\tspeed: 0.0376s/iter; left time: 121.9385s\n",
      "\titers: 200, epoch: 6 | loss: 0.1111952\n",
      "\tspeed: 0.0167s/iter; left time: 52.4481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1127247 Vali Loss: 0.1303820 Test Loss: 0.1614654\n",
      "Validation loss decreased (0.130944 --> 0.130382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1101843\n",
      "\tspeed: 0.0437s/iter; left time: 132.1834s\n",
      "\titers: 200, epoch: 7 | loss: 0.1144683\n",
      "\tspeed: 0.0197s/iter; left time: 57.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.1113464 Vali Loss: 0.1307575 Test Loss: 0.1610118\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114429\n",
      "\tspeed: 0.0357s/iter; left time: 99.9061s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068022\n",
      "\tspeed: 0.0162s/iter; left time: 43.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1105503 Vali Loss: 0.1301013 Test Loss: 0.1594315\n",
      "Validation loss decreased (0.130382 --> 0.130101).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1073766\n",
      "\tspeed: 0.0354s/iter; left time: 91.2837s\n",
      "\titers: 200, epoch: 9 | loss: 0.1039732\n",
      "\tspeed: 0.0152s/iter; left time: 37.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.1099073 Vali Loss: 0.1295959 Test Loss: 0.1585122\n",
      "Validation loss decreased (0.130101 --> 0.129596).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061911\n",
      "\tspeed: 0.0376s/iter; left time: 88.5103s\n",
      "\titers: 200, epoch: 10 | loss: 0.1109751\n",
      "\tspeed: 0.0160s/iter; left time: 36.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.1095424 Vali Loss: 0.1308877 Test Loss: 0.1626594\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129102\n",
      "\tspeed: 0.0367s/iter; left time: 78.2824s\n",
      "\titers: 200, epoch: 11 | loss: 0.1085048\n",
      "\tspeed: 0.0153s/iter; left time: 30.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.1089675 Vali Loss: 0.1291195 Test Loss: 0.1578232\n",
      "Validation loss decreased (0.129596 --> 0.129120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1070272\n",
      "\tspeed: 0.0356s/iter; left time: 67.8739s\n",
      "\titers: 200, epoch: 12 | loss: 0.1068779\n",
      "\tspeed: 0.0202s/iter; left time: 36.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1084242 Vali Loss: 0.1284974 Test Loss: 0.1579687\n",
      "Validation loss decreased (0.129120 --> 0.128497).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1096114\n",
      "\tspeed: 0.0418s/iter; left time: 70.3747s\n",
      "\titers: 200, epoch: 13 | loss: 0.1048709\n",
      "\tspeed: 0.0200s/iter; left time: 31.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.1081906 Vali Loss: 0.1276691 Test Loss: 0.1578244\n",
      "Validation loss decreased (0.128497 --> 0.127669).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1105448\n",
      "\tspeed: 0.0368s/iter; left time: 53.7339s\n",
      "\titers: 200, epoch: 14 | loss: 0.1075893\n",
      "\tspeed: 0.0176s/iter; left time: 23.9206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1080442 Vali Loss: 0.1281609 Test Loss: 0.1572570\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1092115\n",
      "\tspeed: 0.0383s/iter; left time: 47.4332s\n",
      "\titers: 200, epoch: 15 | loss: 0.1053336\n",
      "\tspeed: 0.0175s/iter; left time: 19.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1076674 Vali Loss: 0.1286696 Test Loss: 0.1582996\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044834\n",
      "\tspeed: 0.0363s/iter; left time: 36.8615s\n",
      "\titers: 200, epoch: 16 | loss: 0.1047895\n",
      "\tspeed: 0.0165s/iter; left time: 15.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.1073679 Vali Loss: 0.1284060 Test Loss: 0.1590570\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1063645\n",
      "\tspeed: 0.0374s/iter; left time: 29.6349s\n",
      "\titers: 200, epoch: 17 | loss: 0.1060797\n",
      "\tspeed: 0.0178s/iter; left time: 12.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.1071399 Vali Loss: 0.1274910 Test Loss: 0.1575341\n",
      "Validation loss decreased (0.127669 --> 0.127491).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051314\n",
      "\tspeed: 0.0391s/iter; left time: 22.3002s\n",
      "\titers: 200, epoch: 18 | loss: 0.1067741\n",
      "\tspeed: 0.0167s/iter; left time: 7.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1070178 Vali Loss: 0.1272823 Test Loss: 0.1581545\n",
      "Validation loss decreased (0.127491 --> 0.127282).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1085588\n",
      "\tspeed: 0.0391s/iter; left time: 13.5558s\n",
      "\titers: 200, epoch: 19 | loss: 0.1043933\n",
      "\tspeed: 0.0196s/iter; left time: 4.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.1068289 Vali Loss: 0.1283977 Test Loss: 0.1593443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073587\n",
      "\tspeed: 0.0384s/iter; left time: 4.7576s\n",
      "\titers: 200, epoch: 20 | loss: 0.1076517\n",
      "\tspeed: 0.0181s/iter; left time: 0.4347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1066923 Vali Loss: 0.1281582 Test Loss: 0.1594106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05579496920108795, rmse:0.23620958626270294, mae:0.1581544131040573, rse:0.8189725875854492\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:15.10s\n",
      "Intermediate time for GB: 00h:11m:06.95s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2816537\n",
      "\tspeed: 0.0437s/iter; left time: 191.3045s\n",
      "\titers: 200, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0156s/iter; left time: 66.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.2917258 Vali Loss: 0.2170972 Test Loss: 0.2391800\n",
      "Validation loss decreased (inf --> 0.217097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1574472\n",
      "\tspeed: 0.0329s/iter; left time: 136.5774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123857\n",
      "\tspeed: 0.0158s/iter; left time: 63.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.1609734 Vali Loss: 0.0927930 Test Loss: 0.1000194\n",
      "Validation loss decreased (0.217097 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019466\n",
      "\tspeed: 0.0343s/iter; left time: 135.0492s\n",
      "\titers: 200, epoch: 3 | loss: 0.0919263\n",
      "\tspeed: 0.0182s/iter; left time: 69.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0998914 Vali Loss: 0.0770251 Test Loss: 0.0855755\n",
      "Validation loss decreased (0.092793 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0861650\n",
      "\tspeed: 0.0414s/iter; left time: 153.5005s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835952\n",
      "\tspeed: 0.0228s/iter; left time: 82.2494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0872143 Vali Loss: 0.0741842 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.077025 --> 0.074184).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845740\n",
      "\tspeed: 0.0399s/iter; left time: 138.9380s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783989\n",
      "\tspeed: 0.0163s/iter; left time: 55.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0795157 Vali Loss: 0.0684784 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.074184 --> 0.068478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753257\n",
      "\tspeed: 0.0393s/iter; left time: 128.0170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748651\n",
      "\tspeed: 0.0201s/iter; left time: 63.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0746348 Vali Loss: 0.0672434 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.068478 --> 0.067243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718566\n",
      "\tspeed: 0.0376s/iter; left time: 114.3001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724667\n",
      "\tspeed: 0.0164s/iter; left time: 48.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0721539 Vali Loss: 0.0666095 Test Loss: 0.0906922\n",
      "Validation loss decreased (0.067243 --> 0.066610).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0734818\n",
      "\tspeed: 0.0329s/iter; left time: 92.6402s\n",
      "\titers: 200, epoch: 8 | loss: 0.0720059\n",
      "\tspeed: 0.0192s/iter; left time: 52.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0704396 Vali Loss: 0.0657082 Test Loss: 0.0917255\n",
      "Validation loss decreased (0.066610 --> 0.065708).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675057\n",
      "\tspeed: 0.0370s/iter; left time: 95.8548s\n",
      "\titers: 200, epoch: 9 | loss: 0.0643212\n",
      "\tspeed: 0.0180s/iter; left time: 44.8744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0693166 Vali Loss: 0.0649313 Test Loss: 0.0863003\n",
      "Validation loss decreased (0.065708 --> 0.064931).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687554\n",
      "\tspeed: 0.0367s/iter; left time: 86.8036s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685104\n",
      "\tspeed: 0.0186s/iter; left time: 42.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0680906 Vali Loss: 0.0643823 Test Loss: 0.0900691\n",
      "Validation loss decreased (0.064931 --> 0.064382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664427\n",
      "\tspeed: 0.0404s/iter; left time: 86.5660s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691743\n",
      "\tspeed: 0.0216s/iter; left time: 44.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0676709 Vali Loss: 0.0632091 Test Loss: 0.0935959\n",
      "Validation loss decreased (0.064382 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0707499\n",
      "\tspeed: 0.0389s/iter; left time: 74.5842s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638112\n",
      "\tspeed: 0.0193s/iter; left time: 35.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0672324 Vali Loss: 0.0627501 Test Loss: 0.0857713\n",
      "Validation loss decreased (0.063209 --> 0.062750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650462\n",
      "\tspeed: 0.0354s/iter; left time: 59.8559s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675523\n",
      "\tspeed: 0.0110s/iter; left time: 17.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0662420 Vali Loss: 0.0625596 Test Loss: 0.0846391\n",
      "Validation loss decreased (0.062750 --> 0.062560).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0665506\n",
      "\tspeed: 0.0377s/iter; left time: 55.3768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0663700\n",
      "\tspeed: 0.0239s/iter; left time: 32.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0658864 Vali Loss: 0.0624904 Test Loss: 0.0822836\n",
      "Validation loss decreased (0.062560 --> 0.062490).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0637703\n",
      "\tspeed: 0.0388s/iter; left time: 48.3152s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659867\n",
      "\tspeed: 0.0198s/iter; left time: 22.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0652197 Vali Loss: 0.0617861 Test Loss: 0.0895860\n",
      "Validation loss decreased (0.062490 --> 0.061786).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718536\n",
      "\tspeed: 0.0378s/iter; left time: 38.5486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0611549\n",
      "\tspeed: 0.0193s/iter; left time: 17.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0656305 Vali Loss: 0.0615660 Test Loss: 0.0864745\n",
      "Validation loss decreased (0.061786 --> 0.061566).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0626319\n",
      "\tspeed: 0.0386s/iter; left time: 30.7793s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653634\n",
      "\tspeed: 0.0204s/iter; left time: 14.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0648041 Vali Loss: 0.0613562 Test Loss: 0.0854439\n",
      "Validation loss decreased (0.061566 --> 0.061356).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657745\n",
      "\tspeed: 0.0401s/iter; left time: 22.9997s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607997\n",
      "\tspeed: 0.0207s/iter; left time: 9.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0644721 Vali Loss: 0.0610599 Test Loss: 0.0849441\n",
      "Validation loss decreased (0.061356 --> 0.061060).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0638746\n",
      "\tspeed: 0.0376s/iter; left time: 13.1137s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644753\n",
      "\tspeed: 0.0200s/iter; left time: 4.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0642390 Vali Loss: 0.0605969 Test Loss: 0.0843782\n",
      "Validation loss decreased (0.061060 --> 0.060597).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0670037\n",
      "\tspeed: 0.0399s/iter; left time: 4.9875s\n",
      "\titers: 200, epoch: 20 | loss: 0.0605354\n",
      "\tspeed: 0.0182s/iter; left time: 0.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0639852 Vali Loss: 0.0605502 Test Loss: 0.0847228\n",
      "Validation loss decreased (0.060597 --> 0.060550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02119249477982521, rmse:0.14557641744613647, mae:0.08472280204296112, rse:0.4284138083457947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2933527\n",
      "\tspeed: 0.0215s/iter; left time: 94.3211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2704865\n",
      "\tspeed: 0.0245s/iter; left time: 104.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.2947414 Vali Loss: 0.2184829 Test Loss: 0.2361712\n",
      "Validation loss decreased (inf --> 0.218483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535339\n",
      "\tspeed: 0.0402s/iter; left time: 167.3059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133334\n",
      "\tspeed: 0.0243s/iter; left time: 98.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1637773 Vali Loss: 0.0885669 Test Loss: 0.0970050\n",
      "Validation loss decreased (0.218483 --> 0.088567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1018822\n",
      "\tspeed: 0.0428s/iter; left time: 168.2722s\n",
      "\titers: 200, epoch: 3 | loss: 0.0948918\n",
      "\tspeed: 0.0180s/iter; left time: 68.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.1007216 Vali Loss: 0.0790505 Test Loss: 0.0879022\n",
      "Validation loss decreased (0.088567 --> 0.079051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878256\n",
      "\tspeed: 0.0343s/iter; left time: 127.0957s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835657\n",
      "\tspeed: 0.0164s/iter; left time: 59.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0883169 Vali Loss: 0.0730279 Test Loss: 0.0804366\n",
      "Validation loss decreased (0.079051 --> 0.073028).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824891\n",
      "\tspeed: 0.0420s/iter; left time: 146.4944s\n",
      "\titers: 200, epoch: 5 | loss: 0.0751157\n",
      "\tspeed: 0.0207s/iter; left time: 70.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0807013 Vali Loss: 0.0705443 Test Loss: 0.0847321\n",
      "Validation loss decreased (0.073028 --> 0.070544).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0724511\n",
      "\tspeed: 0.0372s/iter; left time: 121.4034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762253\n",
      "\tspeed: 0.0177s/iter; left time: 55.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0764399 Vali Loss: 0.0675259 Test Loss: 0.0945590\n",
      "Validation loss decreased (0.070544 --> 0.067526).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760236\n",
      "\tspeed: 0.0377s/iter; left time: 114.3453s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679494\n",
      "\tspeed: 0.0204s/iter; left time: 59.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0736369 Vali Loss: 0.0678774 Test Loss: 0.0992442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708459\n",
      "\tspeed: 0.0347s/iter; left time: 97.5696s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680928\n",
      "\tspeed: 0.0188s/iter; left time: 51.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0709821 Vali Loss: 0.0655568 Test Loss: 0.0969620\n",
      "Validation loss decreased (0.067526 --> 0.065557).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0714074\n",
      "\tspeed: 0.0390s/iter; left time: 100.9205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749444\n",
      "\tspeed: 0.0204s/iter; left time: 50.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0694430 Vali Loss: 0.0641238 Test Loss: 0.0946040\n",
      "Validation loss decreased (0.065557 --> 0.064124).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666802\n",
      "\tspeed: 0.0385s/iter; left time: 91.1316s\n",
      "\titers: 200, epoch: 10 | loss: 0.0671037\n",
      "\tspeed: 0.0167s/iter; left time: 37.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0686812 Vali Loss: 0.0635217 Test Loss: 0.0920826\n",
      "Validation loss decreased (0.064124 --> 0.063522).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657643\n",
      "\tspeed: 0.0380s/iter; left time: 81.3744s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640680\n",
      "\tspeed: 0.0185s/iter; left time: 37.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0677449 Vali Loss: 0.0631191 Test Loss: 0.0914283\n",
      "Validation loss decreased (0.063522 --> 0.063119).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628503\n",
      "\tspeed: 0.0390s/iter; left time: 74.7482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0651587\n",
      "\tspeed: 0.0203s/iter; left time: 36.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0672804 Vali Loss: 0.0626110 Test Loss: 0.0832856\n",
      "Validation loss decreased (0.063119 --> 0.062611).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0623292\n",
      "\tspeed: 0.0406s/iter; left time: 68.8180s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658564\n",
      "\tspeed: 0.0239s/iter; left time: 38.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0664633 Vali Loss: 0.0621283 Test Loss: 0.0837443\n",
      "Validation loss decreased (0.062611 --> 0.062128).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687133\n",
      "\tspeed: 0.0394s/iter; left time: 57.9428s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648790\n",
      "\tspeed: 0.0235s/iter; left time: 32.1941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0656932 Vali Loss: 0.0620166 Test Loss: 0.0845872\n",
      "Validation loss decreased (0.062128 --> 0.062017).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649449\n",
      "\tspeed: 0.0394s/iter; left time: 49.0829s\n",
      "\titers: 200, epoch: 15 | loss: 0.0653902\n",
      "\tspeed: 0.0211s/iter; left time: 24.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0656366 Vali Loss: 0.0617880 Test Loss: 0.0808425\n",
      "Validation loss decreased (0.062017 --> 0.061788).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618114\n",
      "\tspeed: 0.0378s/iter; left time: 38.5603s\n",
      "\titers: 200, epoch: 16 | loss: 0.0655272\n",
      "\tspeed: 0.0198s/iter; left time: 18.2481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0655247 Vali Loss: 0.0616549 Test Loss: 0.0858418\n",
      "Validation loss decreased (0.061788 --> 0.061655).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0677098\n",
      "\tspeed: 0.0368s/iter; left time: 29.3474s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637103\n",
      "\tspeed: 0.0168s/iter; left time: 11.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0648700 Vali Loss: 0.0612696 Test Loss: 0.0789498\n",
      "Validation loss decreased (0.061655 --> 0.061270).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0684756\n",
      "\tspeed: 0.0432s/iter; left time: 24.7682s\n",
      "\titers: 200, epoch: 18 | loss: 0.0658208\n",
      "\tspeed: 0.0195s/iter; left time: 9.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0648673 Vali Loss: 0.0613987 Test Loss: 0.0799385\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0637714\n",
      "\tspeed: 0.0363s/iter; left time: 12.6523s\n",
      "\titers: 200, epoch: 19 | loss: 0.0642970\n",
      "\tspeed: 0.0198s/iter; left time: 4.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0642515 Vali Loss: 0.0606022 Test Loss: 0.0827977\n",
      "Validation loss decreased (0.061270 --> 0.060602).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0594665\n",
      "\tspeed: 0.0372s/iter; left time: 4.6555s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622201\n",
      "\tspeed: 0.0204s/iter; left time: 0.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0640075 Vali Loss: 0.0609228 Test Loss: 0.0824307\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019271206110715866, rmse:0.13882076740264893, mae:0.08279767632484436, rse:0.4085327386856079\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:01.82s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2927844\n",
      "\tspeed: 0.0397s/iter; left time: 173.8464s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679563\n",
      "\tspeed: 0.0113s/iter; left time: 48.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 224 | Train Loss: 0.2934492 Vali Loss: 0.2265779 Test Loss: 0.2473311\n",
      "Validation loss decreased (inf --> 0.226578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487017\n",
      "\tspeed: 0.0335s/iter; left time: 139.3860s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234444\n",
      "\tspeed: 0.0161s/iter; left time: 65.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.1612512 Vali Loss: 0.1090392 Test Loss: 0.1224254\n",
      "Validation loss decreased (0.226578 --> 0.109039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138383\n",
      "\tspeed: 0.0343s/iter; left time: 134.9389s\n",
      "\titers: 200, epoch: 3 | loss: 0.1022470\n",
      "\tspeed: 0.0169s/iter; left time: 64.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.1110889 Vali Loss: 0.0956589 Test Loss: 0.1095202\n",
      "Validation loss decreased (0.109039 --> 0.095659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025926\n",
      "\tspeed: 0.0328s/iter; left time: 121.7328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920612\n",
      "\tspeed: 0.0169s/iter; left time: 61.0446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0995970 Vali Loss: 0.0899858 Test Loss: 0.1131441\n",
      "Validation loss decreased (0.095659 --> 0.089986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931545\n",
      "\tspeed: 0.0350s/iter; left time: 122.0642s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931527\n",
      "\tspeed: 0.0161s/iter; left time: 54.6138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0936053 Vali Loss: 0.0867605 Test Loss: 0.1130654\n",
      "Validation loss decreased (0.089986 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0860886\n",
      "\tspeed: 0.0337s/iter; left time: 109.8750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838229\n",
      "\tspeed: 0.0188s/iter; left time: 59.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0907358 Vali Loss: 0.0863985 Test Loss: 0.1194768\n",
      "Validation loss decreased (0.086760 --> 0.086398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899213\n",
      "\tspeed: 0.0376s/iter; left time: 114.0644s\n",
      "\titers: 200, epoch: 7 | loss: 0.0872641\n",
      "\tspeed: 0.0163s/iter; left time: 47.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0888319 Vali Loss: 0.0841723 Test Loss: 0.1173581\n",
      "Validation loss decreased (0.086398 --> 0.084172).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0906646\n",
      "\tspeed: 0.0374s/iter; left time: 105.1360s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893356\n",
      "\tspeed: 0.0199s/iter; left time: 53.9384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0875708 Vali Loss: 0.0830635 Test Loss: 0.1180833\n",
      "Validation loss decreased (0.084172 --> 0.083064).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864103\n",
      "\tspeed: 0.0356s/iter; left time: 92.2550s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893488\n",
      "\tspeed: 0.0196s/iter; left time: 48.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0864884 Vali Loss: 0.0826783 Test Loss: 0.1157510\n",
      "Validation loss decreased (0.083064 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850294\n",
      "\tspeed: 0.0268s/iter; left time: 63.4740s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833892\n",
      "\tspeed: 0.0101s/iter; left time: 22.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.46s\n",
      "Steps: 224 | Train Loss: 0.0856588 Vali Loss: 0.0814340 Test Loss: 0.1142541\n",
      "Validation loss decreased (0.082678 --> 0.081434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822709\n",
      "\tspeed: 0.0306s/iter; left time: 65.4659s\n",
      "\titers: 200, epoch: 11 | loss: 0.0829068\n",
      "\tspeed: 0.0172s/iter; left time: 35.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0849818 Vali Loss: 0.0810934 Test Loss: 0.1146406\n",
      "Validation loss decreased (0.081434 --> 0.081093).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835356\n",
      "\tspeed: 0.0326s/iter; left time: 62.5681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870471\n",
      "\tspeed: 0.0176s/iter; left time: 31.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0847184 Vali Loss: 0.0808101 Test Loss: 0.1107150\n",
      "Validation loss decreased (0.081093 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819400\n",
      "\tspeed: 0.0337s/iter; left time: 56.9777s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813070\n",
      "\tspeed: 0.0172s/iter; left time: 27.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0840173 Vali Loss: 0.0814793 Test Loss: 0.1169226\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805689\n",
      "\tspeed: 0.0385s/iter; left time: 56.5588s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824032\n",
      "\tspeed: 0.0205s/iter; left time: 28.0079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0836631 Vali Loss: 0.0809369 Test Loss: 0.1085788\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0854935\n",
      "\tspeed: 0.0359s/iter; left time: 44.7522s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844008\n",
      "\tspeed: 0.0179s/iter; left time: 20.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0832510 Vali Loss: 0.0802453 Test Loss: 0.1106235\n",
      "Validation loss decreased (0.080810 --> 0.080245).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829299\n",
      "\tspeed: 0.0349s/iter; left time: 35.6507s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801041\n",
      "\tspeed: 0.0202s/iter; left time: 18.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0828200 Vali Loss: 0.0801053 Test Loss: 0.1111452\n",
      "Validation loss decreased (0.080245 --> 0.080105).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866814\n",
      "\tspeed: 0.0373s/iter; left time: 29.7417s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850418\n",
      "\tspeed: 0.0197s/iter; left time: 13.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0826171 Vali Loss: 0.0796503 Test Loss: 0.1088848\n",
      "Validation loss decreased (0.080105 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0879665\n",
      "\tspeed: 0.0343s/iter; left time: 19.6523s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845622\n",
      "\tspeed: 0.0179s/iter; left time: 8.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0825477 Vali Loss: 0.0795592 Test Loss: 0.1078510\n",
      "Validation loss decreased (0.079650 --> 0.079559).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0793740\n",
      "\tspeed: 0.0374s/iter; left time: 13.0392s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800034\n",
      "\tspeed: 0.0184s/iter; left time: 4.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0821412 Vali Loss: 0.0797035 Test Loss: 0.1090518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0791183\n",
      "\tspeed: 0.0361s/iter; left time: 4.5100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785760\n",
      "\tspeed: 0.0173s/iter; left time: 0.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0821128 Vali Loss: 0.0796858 Test Loss: 0.1067025\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.025789545848965645, rmse:0.1605912446975708, mae:0.10785099118947983, rse:0.47176873683929443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2952403\n",
      "\tspeed: 0.0204s/iter; left time: 89.3050s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667057\n",
      "\tspeed: 0.0167s/iter; left time: 71.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.2909098 Vali Loss: 0.2230923 Test Loss: 0.2409381\n",
      "Validation loss decreased (inf --> 0.223092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1491593\n",
      "\tspeed: 0.0435s/iter; left time: 180.7254s\n",
      "\titers: 200, epoch: 2 | loss: 0.1210495\n",
      "\tspeed: 0.0177s/iter; left time: 71.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.1614247 Vali Loss: 0.1116909 Test Loss: 0.1254427\n",
      "Validation loss decreased (0.223092 --> 0.111691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085087\n",
      "\tspeed: 0.0351s/iter; left time: 138.0536s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104036\n",
      "\tspeed: 0.0101s/iter; left time: 38.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.1113403 Vali Loss: 0.0953680 Test Loss: 0.1103432\n",
      "Validation loss decreased (0.111691 --> 0.095368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050000\n",
      "\tspeed: 0.0360s/iter; left time: 133.4909s\n",
      "\titers: 200, epoch: 4 | loss: 0.0989005\n",
      "\tspeed: 0.0211s/iter; left time: 76.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0994751 Vali Loss: 0.0900774 Test Loss: 0.1305989\n",
      "Validation loss decreased (0.095368 --> 0.090077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0924402\n",
      "\tspeed: 0.0369s/iter; left time: 128.4269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0925185\n",
      "\tspeed: 0.0168s/iter; left time: 56.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0936407 Vali Loss: 0.0879273 Test Loss: 0.1221537\n",
      "Validation loss decreased (0.090077 --> 0.087927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856230\n",
      "\tspeed: 0.0371s/iter; left time: 120.8805s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879899\n",
      "\tspeed: 0.0206s/iter; left time: 65.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0899839 Vali Loss: 0.0851904 Test Loss: 0.1239189\n",
      "Validation loss decreased (0.087927 --> 0.085190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0908499\n",
      "\tspeed: 0.0372s/iter; left time: 112.8778s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900486\n",
      "\tspeed: 0.0204s/iter; left time: 60.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0885243 Vali Loss: 0.0836331 Test Loss: 0.1237736\n",
      "Validation loss decreased (0.085190 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901688\n",
      "\tspeed: 0.0365s/iter; left time: 102.7552s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838144\n",
      "\tspeed: 0.0181s/iter; left time: 49.2199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0868885 Vali Loss: 0.0829176 Test Loss: 0.1260237\n",
      "Validation loss decreased (0.083633 --> 0.082918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0871684\n",
      "\tspeed: 0.0366s/iter; left time: 94.8117s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863542\n",
      "\tspeed: 0.0194s/iter; left time: 48.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0857102 Vali Loss: 0.0822429 Test Loss: 0.1236874\n",
      "Validation loss decreased (0.082918 --> 0.082243).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849192\n",
      "\tspeed: 0.0385s/iter; left time: 91.0671s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846752\n",
      "\tspeed: 0.0187s/iter; left time: 42.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0818745 Test Loss: 0.1264992\n",
      "Validation loss decreased (0.082243 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0810420\n",
      "\tspeed: 0.0405s/iter; left time: 86.6379s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817054\n",
      "\tspeed: 0.0195s/iter; left time: 39.8980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0842583 Vali Loss: 0.0812377 Test Loss: 0.1211978\n",
      "Validation loss decreased (0.081875 --> 0.081238).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0824383\n",
      "\tspeed: 0.0373s/iter; left time: 71.4403s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815587\n",
      "\tspeed: 0.0168s/iter; left time: 30.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0837523 Vali Loss: 0.0809542 Test Loss: 0.1222994\n",
      "Validation loss decreased (0.081238 --> 0.080954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0834732\n",
      "\tspeed: 0.0344s/iter; left time: 58.3174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0828774\n",
      "\tspeed: 0.0165s/iter; left time: 26.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0834866 Vali Loss: 0.0810962 Test Loss: 0.1206864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810478\n",
      "\tspeed: 0.0377s/iter; left time: 55.3448s\n",
      "\titers: 200, epoch: 14 | loss: 0.0787730\n",
      "\tspeed: 0.0103s/iter; left time: 14.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0830654 Vali Loss: 0.0801408 Test Loss: 0.1198389\n",
      "Validation loss decreased (0.080954 --> 0.080141).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855980\n",
      "\tspeed: 0.0369s/iter; left time: 45.9033s\n",
      "\titers: 200, epoch: 15 | loss: 0.0813123\n",
      "\tspeed: 0.0175s/iter; left time: 19.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0829200 Vali Loss: 0.0803521 Test Loss: 0.1200523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831396\n",
      "\tspeed: 0.0368s/iter; left time: 37.6019s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829206\n",
      "\tspeed: 0.0179s/iter; left time: 16.5022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0823068 Vali Loss: 0.0803707 Test Loss: 0.1218092\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848512\n",
      "\tspeed: 0.0332s/iter; left time: 26.4427s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793137\n",
      "\tspeed: 0.0164s/iter; left time: 11.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0826998 Vali Loss: 0.0802649 Test Loss: 0.1115729\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797599\n",
      "\tspeed: 0.0348s/iter; left time: 19.9687s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824331\n",
      "\tspeed: 0.0182s/iter; left time: 8.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0821136 Vali Loss: 0.0795419 Test Loss: 0.1209204\n",
      "Validation loss decreased (0.080141 --> 0.079542).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788217\n",
      "\tspeed: 0.0390s/iter; left time: 13.6023s\n",
      "\titers: 200, epoch: 19 | loss: 0.0827929\n",
      "\tspeed: 0.0222s/iter; left time: 5.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0817846 Vali Loss: 0.0792163 Test Loss: 0.1182506\n",
      "Validation loss decreased (0.079542 --> 0.079216).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808366\n",
      "\tspeed: 0.0445s/iter; left time: 5.5686s\n",
      "\titers: 200, epoch: 20 | loss: 0.0783563\n",
      "\tspeed: 0.0200s/iter; left time: 0.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0815249 Vali Loss: 0.0790933 Test Loss: 0.1166001\n",
      "Validation loss decreased (0.079216 --> 0.079093).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03416641056537628, rmse:0.184841588139534, mae:0.11660011857748032, rse:0.5430089235305786\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:45.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2964666\n",
      "\tspeed: 0.0409s/iter; left time: 178.2966s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703550\n",
      "\tspeed: 0.0194s/iter; left time: 82.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.2932033 Vali Loss: 0.2296769 Test Loss: 0.2486475\n",
      "Validation loss decreased (inf --> 0.229677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1435062\n",
      "\tspeed: 0.0407s/iter; left time: 168.5810s\n",
      "\titers: 200, epoch: 2 | loss: 0.1256136\n",
      "\tspeed: 0.0171s/iter; left time: 68.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.1602287 Vali Loss: 0.1148994 Test Loss: 0.1295309\n",
      "Validation loss decreased (0.229677 --> 0.114899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1132072\n",
      "\tspeed: 0.0332s/iter; left time: 129.8593s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039122\n",
      "\tspeed: 0.0250s/iter; left time: 95.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1127486 Vali Loss: 0.0988917 Test Loss: 0.1155232\n",
      "Validation loss decreased (0.114899 --> 0.098892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027603\n",
      "\tspeed: 0.0448s/iter; left time: 165.3255s\n",
      "\titers: 200, epoch: 4 | loss: 0.1008714\n",
      "\tspeed: 0.0251s/iter; left time: 90.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.1012387 Vali Loss: 0.0938790 Test Loss: 0.1264149\n",
      "Validation loss decreased (0.098892 --> 0.093879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958840\n",
      "\tspeed: 0.0448s/iter; left time: 155.3468s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973659\n",
      "\tspeed: 0.0230s/iter; left time: 77.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0963128 Vali Loss: 0.0907867 Test Loss: 0.1215907\n",
      "Validation loss decreased (0.093879 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933186\n",
      "\tspeed: 0.0458s/iter; left time: 148.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0898358\n",
      "\tspeed: 0.0242s/iter; left time: 75.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0933747 Vali Loss: 0.0888366 Test Loss: 0.1204036\n",
      "Validation loss decreased (0.090787 --> 0.088837).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917813\n",
      "\tspeed: 0.0329s/iter; left time: 99.4984s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924730\n",
      "\tspeed: 0.0225s/iter; left time: 65.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0915984 Vali Loss: 0.0875202 Test Loss: 0.1187944\n",
      "Validation loss decreased (0.088837 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0955173\n",
      "\tspeed: 0.0377s/iter; left time: 105.4556s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889457\n",
      "\tspeed: 0.0191s/iter; left time: 51.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0904488 Vali Loss: 0.0872620 Test Loss: 0.1198251\n",
      "Validation loss decreased (0.087520 --> 0.087262).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0901060\n",
      "\tspeed: 0.0429s/iter; left time: 110.6555s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878746\n",
      "\tspeed: 0.0238s/iter; left time: 59.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 223 | Train Loss: 0.0895769 Vali Loss: 0.0867827 Test Loss: 0.1200372\n",
      "Validation loss decreased (0.087262 --> 0.086783).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916062\n",
      "\tspeed: 0.0406s/iter; left time: 95.6032s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925188\n",
      "\tspeed: 0.0184s/iter; left time: 41.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0890155 Vali Loss: 0.0861873 Test Loss: 0.1205486\n",
      "Validation loss decreased (0.086783 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894895\n",
      "\tspeed: 0.0377s/iter; left time: 80.3619s\n",
      "\titers: 200, epoch: 11 | loss: 0.0912286\n",
      "\tspeed: 0.0187s/iter; left time: 37.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0885857 Vali Loss: 0.0863503 Test Loss: 0.1218668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908254\n",
      "\tspeed: 0.0373s/iter; left time: 71.1802s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871320\n",
      "\tspeed: 0.0114s/iter; left time: 20.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 223 | Train Loss: 0.0881494 Vali Loss: 0.0862960 Test Loss: 0.1188767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0895550\n",
      "\tspeed: 0.0334s/iter; left time: 56.2187s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892237\n",
      "\tspeed: 0.0169s/iter; left time: 26.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0877858 Vali Loss: 0.0857503 Test Loss: 0.1192278\n",
      "Validation loss decreased (0.086187 --> 0.085750).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894100\n",
      "\tspeed: 0.0374s/iter; left time: 54.7015s\n",
      "\titers: 200, epoch: 14 | loss: 0.0862612\n",
      "\tspeed: 0.0179s/iter; left time: 24.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0871041 Vali Loss: 0.0859365 Test Loss: 0.1178160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0836563\n",
      "\tspeed: 0.0382s/iter; left time: 47.2873s\n",
      "\titers: 200, epoch: 15 | loss: 0.0918337\n",
      "\tspeed: 0.0178s/iter; left time: 20.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0868419 Vali Loss: 0.0858512 Test Loss: 0.1171652\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838884\n",
      "\tspeed: 0.0349s/iter; left time: 35.4389s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845526\n",
      "\tspeed: 0.0195s/iter; left time: 17.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0866787 Vali Loss: 0.0852616 Test Loss: 0.1175829\n",
      "Validation loss decreased (0.085750 --> 0.085262).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0875345\n",
      "\tspeed: 0.0434s/iter; left time: 34.3828s\n",
      "\titers: 200, epoch: 17 | loss: 0.0893185\n",
      "\tspeed: 0.0187s/iter; left time: 12.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0863222 Vali Loss: 0.0855332 Test Loss: 0.1191674\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0844390\n",
      "\tspeed: 0.0339s/iter; left time: 19.3211s\n",
      "\titers: 200, epoch: 18 | loss: 0.0853876\n",
      "\tspeed: 0.0170s/iter; left time: 7.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0864187 Vali Loss: 0.0852716 Test Loss: 0.1193218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0858874\n",
      "\tspeed: 0.0372s/iter; left time: 12.9222s\n",
      "\titers: 200, epoch: 19 | loss: 0.0856907\n",
      "\tspeed: 0.0215s/iter; left time: 5.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0860364 Vali Loss: 0.0854634 Test Loss: 0.1194723\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0850303\n",
      "\tspeed: 0.0391s/iter; left time: 4.8529s\n",
      "\titers: 200, epoch: 20 | loss: 0.0862366\n",
      "\tspeed: 0.0189s/iter; left time: 0.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0858274 Vali Loss: 0.0850522 Test Loss: 0.1174430\n",
      "Validation loss decreased (0.085262 --> 0.085052).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030968520790338516, rmse:0.17597874999046326, mae:0.11744298785924911, rse:0.5170097351074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2899029\n",
      "\tspeed: 0.0254s/iter; left time: 110.6952s\n",
      "\titers: 200, epoch: 1 | loss: 0.2712442\n",
      "\tspeed: 0.0171s/iter; left time: 72.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.2944018 Vali Loss: 0.2256723 Test Loss: 0.2452994\n",
      "Validation loss decreased (inf --> 0.225672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1439804\n",
      "\tspeed: 0.0367s/iter; left time: 152.0122s\n",
      "\titers: 200, epoch: 2 | loss: 0.1288482\n",
      "\tspeed: 0.0177s/iter; left time: 71.6389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1609331 Vali Loss: 0.1103104 Test Loss: 0.1237899\n",
      "Validation loss decreased (0.225672 --> 0.110310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1161442\n",
      "\tspeed: 0.0408s/iter; left time: 159.6453s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086942\n",
      "\tspeed: 0.0207s/iter; left time: 79.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1137597 Vali Loss: 0.0991577 Test Loss: 0.1132361\n",
      "Validation loss decreased (0.110310 --> 0.099158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016965\n",
      "\tspeed: 0.0378s/iter; left time: 139.7031s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984646\n",
      "\tspeed: 0.0169s/iter; left time: 60.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1016837 Vali Loss: 0.0949189 Test Loss: 0.1138231\n",
      "Validation loss decreased (0.099158 --> 0.094919).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0982926\n",
      "\tspeed: 0.0404s/iter; left time: 140.3132s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952768\n",
      "\tspeed: 0.0177s/iter; left time: 59.6714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0965111 Vali Loss: 0.0906598 Test Loss: 0.1149046\n",
      "Validation loss decreased (0.094919 --> 0.090660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932750\n",
      "\tspeed: 0.0381s/iter; left time: 123.7322s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899443\n",
      "\tspeed: 0.0191s/iter; left time: 60.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0935987 Vali Loss: 0.0898600 Test Loss: 0.1154023\n",
      "Validation loss decreased (0.090660 --> 0.089860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968993\n",
      "\tspeed: 0.0395s/iter; left time: 119.5003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0916797\n",
      "\tspeed: 0.0197s/iter; left time: 57.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0919076 Vali Loss: 0.0879064 Test Loss: 0.1174295\n",
      "Validation loss decreased (0.089860 --> 0.087906).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0910260\n",
      "\tspeed: 0.0378s/iter; left time: 105.8466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891242\n",
      "\tspeed: 0.0200s/iter; left time: 54.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0904661 Vali Loss: 0.0868890 Test Loss: 0.1170246\n",
      "Validation loss decreased (0.087906 --> 0.086889).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919234\n",
      "\tspeed: 0.0405s/iter; left time: 104.3527s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911078\n",
      "\tspeed: 0.0230s/iter; left time: 56.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0899424 Vali Loss: 0.0871161 Test Loss: 0.1129427\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0876352\n",
      "\tspeed: 0.0428s/iter; left time: 100.7205s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899070\n",
      "\tspeed: 0.0227s/iter; left time: 51.2441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0887751 Vali Loss: 0.0863786 Test Loss: 0.1157439\n",
      "Validation loss decreased (0.086889 --> 0.086379).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0875310\n",
      "\tspeed: 0.0386s/iter; left time: 82.1818s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865170\n",
      "\tspeed: 0.0176s/iter; left time: 35.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0889828 Vali Loss: 0.0859895 Test Loss: 0.1167143\n",
      "Validation loss decreased (0.086379 --> 0.085990).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0884266\n",
      "\tspeed: 0.0410s/iter; left time: 78.2395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0868132\n",
      "\tspeed: 0.0189s/iter; left time: 34.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0875570 Vali Loss: 0.0859610 Test Loss: 0.1155201\n",
      "Validation loss decreased (0.085990 --> 0.085961).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886559\n",
      "\tspeed: 0.0395s/iter; left time: 66.5445s\n",
      "\titers: 200, epoch: 13 | loss: 0.0892455\n",
      "\tspeed: 0.0215s/iter; left time: 34.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0871522 Vali Loss: 0.0859056 Test Loss: 0.1138303\n",
      "Validation loss decreased (0.085961 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848424\n",
      "\tspeed: 0.0382s/iter; left time: 55.8113s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878144\n",
      "\tspeed: 0.0173s/iter; left time: 23.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0867811 Vali Loss: 0.0854875 Test Loss: 0.1154874\n",
      "Validation loss decreased (0.085906 --> 0.085487).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901568\n",
      "\tspeed: 0.0383s/iter; left time: 47.4129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0834248\n",
      "\tspeed: 0.0196s/iter; left time: 22.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0863447 Vali Loss: 0.0854952 Test Loss: 0.1136132\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865058\n",
      "\tspeed: 0.0389s/iter; left time: 39.5532s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858239\n",
      "\tspeed: 0.0203s/iter; left time: 18.6204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0863616 Vali Loss: 0.0848712 Test Loss: 0.1134736\n",
      "Validation loss decreased (0.085487 --> 0.084871).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821277\n",
      "\tspeed: 0.0413s/iter; left time: 32.7476s\n",
      "\titers: 200, epoch: 17 | loss: 0.0873138\n",
      "\tspeed: 0.0187s/iter; left time: 12.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0860255 Vali Loss: 0.0847610 Test Loss: 0.1142043\n",
      "Validation loss decreased (0.084871 --> 0.084761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0891386\n",
      "\tspeed: 0.0352s/iter; left time: 20.0840s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899599\n",
      "\tspeed: 0.0173s/iter; left time: 8.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0863818 Vali Loss: 0.0850193 Test Loss: 0.1143596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0856005\n",
      "\tspeed: 0.0364s/iter; left time: 12.6310s\n",
      "\titers: 200, epoch: 19 | loss: 0.0866439\n",
      "\tspeed: 0.0102s/iter; left time: 2.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 223 | Train Loss: 0.0857154 Vali Loss: 0.0848255 Test Loss: 0.1150333\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0883029\n",
      "\tspeed: 0.0372s/iter; left time: 4.6180s\n",
      "\titers: 200, epoch: 20 | loss: 0.0826626\n",
      "\tspeed: 0.0184s/iter; left time: 0.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0856279 Vali Loss: 0.0850217 Test Loss: 0.1158830\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.027704495936632156, rmse:0.16644667088985443, mae:0.1142042800784111, rse:0.4890053868293762\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:03.80s\n",
      "Intermediate time for ES: 00h:11m:50.64s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2364616\n",
      "\tspeed: 0.0411s/iter; left time: 180.1633s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121348\n",
      "\tspeed: 0.0157s/iter; left time: 67.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.2392200 Vali Loss: 0.1770049 Test Loss: 0.1852981\n",
      "Validation loss decreased (inf --> 0.177005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303243\n",
      "\tspeed: 0.0321s/iter; left time: 133.5690s\n",
      "\titers: 200, epoch: 2 | loss: 0.1033051\n",
      "\tspeed: 0.0153s/iter; left time: 62.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 224 | Train Loss: 0.1388394 Vali Loss: 0.0869760 Test Loss: 0.0945034\n",
      "Validation loss decreased (0.177005 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825731\n",
      "\tspeed: 0.0347s/iter; left time: 136.4971s\n",
      "\titers: 200, epoch: 3 | loss: 0.0793041\n",
      "\tspeed: 0.0164s/iter; left time: 63.0509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0860847 Vali Loss: 0.0778278 Test Loss: 0.0814873\n",
      "Validation loss decreased (0.086976 --> 0.077828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733635\n",
      "\tspeed: 0.0353s/iter; left time: 130.9645s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690225\n",
      "\tspeed: 0.0164s/iter; left time: 59.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0731323 Vali Loss: 0.0684923 Test Loss: 0.0716434\n",
      "Validation loss decreased (0.077828 --> 0.068492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0726537\n",
      "\tspeed: 0.0343s/iter; left time: 119.4631s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635449\n",
      "\tspeed: 0.0179s/iter; left time: 60.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0644002 Test Loss: 0.0683116\n",
      "Validation loss decreased (0.068492 --> 0.064400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636231\n",
      "\tspeed: 0.0356s/iter; left time: 116.0798s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626314\n",
      "\tspeed: 0.0162s/iter; left time: 51.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0622666 Vali Loss: 0.0631550 Test Loss: 0.0668301\n",
      "Validation loss decreased (0.064400 --> 0.063155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607215\n",
      "\tspeed: 0.0386s/iter; left time: 117.2982s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0227s/iter; left time: 66.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0593463 Vali Loss: 0.0620536 Test Loss: 0.0652200\n",
      "Validation loss decreased (0.063155 --> 0.062054).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608385\n",
      "\tspeed: 0.0366s/iter; left time: 102.8152s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549202\n",
      "\tspeed: 0.0179s/iter; left time: 48.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0577960 Vali Loss: 0.0636440 Test Loss: 0.0661433\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620685\n",
      "\tspeed: 0.0357s/iter; left time: 92.4968s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503389\n",
      "\tspeed: 0.0169s/iter; left time: 41.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0561813 Vali Loss: 0.0612333 Test Loss: 0.0644666\n",
      "Validation loss decreased (0.062054 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570746\n",
      "\tspeed: 0.0350s/iter; left time: 82.7631s\n",
      "\titers: 200, epoch: 10 | loss: 0.0552205\n",
      "\tspeed: 0.0182s/iter; left time: 41.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0549689 Vali Loss: 0.0609174 Test Loss: 0.0637794\n",
      "Validation loss decreased (0.061233 --> 0.060917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0524915\n",
      "\tspeed: 0.0344s/iter; left time: 73.6516s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527370\n",
      "\tspeed: 0.0188s/iter; left time: 38.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0542130 Vali Loss: 0.0599264 Test Loss: 0.0629058\n",
      "Validation loss decreased (0.060917 --> 0.059926).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527429\n",
      "\tspeed: 0.0352s/iter; left time: 67.3897s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555589\n",
      "\tspeed: 0.0187s/iter; left time: 34.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0534315 Vali Loss: 0.0598321 Test Loss: 0.0628119\n",
      "Validation loss decreased (0.059926 --> 0.059832).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517376\n",
      "\tspeed: 0.0365s/iter; left time: 61.8136s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528381\n",
      "\tspeed: 0.0178s/iter; left time: 28.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0528232 Vali Loss: 0.0596219 Test Loss: 0.0625450\n",
      "Validation loss decreased (0.059832 --> 0.059622).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0521673\n",
      "\tspeed: 0.0315s/iter; left time: 46.2743s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553276\n",
      "\tspeed: 0.0156s/iter; left time: 21.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0526405 Vali Loss: 0.0594241 Test Loss: 0.0623918\n",
      "Validation loss decreased (0.059622 --> 0.059424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0519940\n",
      "\tspeed: 0.0364s/iter; left time: 45.3628s\n",
      "\titers: 200, epoch: 15 | loss: 0.0506013\n",
      "\tspeed: 0.0190s/iter; left time: 21.7042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0522685 Vali Loss: 0.0591635 Test Loss: 0.0621569\n",
      "Validation loss decreased (0.059424 --> 0.059163).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545860\n",
      "\tspeed: 0.0358s/iter; left time: 36.5022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539856\n",
      "\tspeed: 0.0174s/iter; left time: 16.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0518227 Vali Loss: 0.0591432 Test Loss: 0.0621068\n",
      "Validation loss decreased (0.059163 --> 0.059143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0507968\n",
      "\tspeed: 0.0347s/iter; left time: 27.6201s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521749\n",
      "\tspeed: 0.0184s/iter; left time: 12.8006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0516960 Vali Loss: 0.0588562 Test Loss: 0.0617873\n",
      "Validation loss decreased (0.059143 --> 0.058856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0580295\n",
      "\tspeed: 0.0338s/iter; left time: 19.3927s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526130\n",
      "\tspeed: 0.0196s/iter; left time: 9.2886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0591153 Test Loss: 0.0621751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0477699\n",
      "\tspeed: 0.0372s/iter; left time: 12.9835s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534439\n",
      "\tspeed: 0.0230s/iter; left time: 5.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0513691 Vali Loss: 0.0590905 Test Loss: 0.0620888\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0499527\n",
      "\tspeed: 0.0366s/iter; left time: 4.5750s\n",
      "\titers: 200, epoch: 20 | loss: 0.0473068\n",
      "\tspeed: 0.0171s/iter; left time: 0.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0512984 Vali Loss: 0.0588608 Test Loss: 0.0618575\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011178242973983288, rmse:0.10572721064090729, mae:0.061787281185388565, rse:0.407892644405365\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2411680\n",
      "\tspeed: 0.0206s/iter; left time: 90.3629s\n",
      "\titers: 200, epoch: 1 | loss: 0.2160659\n",
      "\tspeed: 0.0194s/iter; left time: 83.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.2408922 Vali Loss: 0.1782567 Test Loss: 0.1854041\n",
      "Validation loss decreased (inf --> 0.178257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1385794\n",
      "\tspeed: 0.0333s/iter; left time: 138.4459s\n",
      "\titers: 200, epoch: 2 | loss: 0.1014387\n",
      "\tspeed: 0.0162s/iter; left time: 65.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.1401546 Vali Loss: 0.0844240 Test Loss: 0.0928136\n",
      "Validation loss decreased (0.178257 --> 0.084424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963864\n",
      "\tspeed: 0.0358s/iter; left time: 140.7603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779932\n",
      "\tspeed: 0.0176s/iter; left time: 67.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0851412 Vali Loss: 0.0759695 Test Loss: 0.0796487\n",
      "Validation loss decreased (0.084424 --> 0.075970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728357\n",
      "\tspeed: 0.0361s/iter; left time: 134.0024s\n",
      "\titers: 200, epoch: 4 | loss: 0.0701583\n",
      "\tspeed: 0.0217s/iter; left time: 78.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0739212 Vali Loss: 0.0693061 Test Loss: 0.0711936\n",
      "Validation loss decreased (0.075970 --> 0.069306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649703\n",
      "\tspeed: 0.0393s/iter; left time: 136.9867s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600224\n",
      "\tspeed: 0.0206s/iter; left time: 69.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0674395 Vali Loss: 0.0658167 Test Loss: 0.0676115\n",
      "Validation loss decreased (0.069306 --> 0.065817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614809\n",
      "\tspeed: 0.0272s/iter; left time: 88.8241s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617771\n",
      "\tspeed: 0.0098s/iter; left time: 30.9497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.42s\n",
      "Steps: 224 | Train Loss: 0.0634119 Vali Loss: 0.0674359 Test Loss: 0.0694659\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605860\n",
      "\tspeed: 0.0339s/iter; left time: 102.9394s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626515\n",
      "\tspeed: 0.0184s/iter; left time: 54.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0611253 Vali Loss: 0.0648416 Test Loss: 0.0675831\n",
      "Validation loss decreased (0.065817 --> 0.064842).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599528\n",
      "\tspeed: 0.0397s/iter; left time: 111.5973s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610243\n",
      "\tspeed: 0.0202s/iter; left time: 54.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0588911 Vali Loss: 0.0627734 Test Loss: 0.0656899\n",
      "Validation loss decreased (0.064842 --> 0.062773).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547889\n",
      "\tspeed: 0.0358s/iter; left time: 92.5568s\n",
      "\titers: 200, epoch: 9 | loss: 0.0561625\n",
      "\tspeed: 0.0169s/iter; left time: 41.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0571481 Vali Loss: 0.0612765 Test Loss: 0.0641911\n",
      "Validation loss decreased (0.062773 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564083\n",
      "\tspeed: 0.0391s/iter; left time: 92.5144s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529456\n",
      "\tspeed: 0.0226s/iter; left time: 51.2521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0560195 Vali Loss: 0.0609586 Test Loss: 0.0637936\n",
      "Validation loss decreased (0.061277 --> 0.060959).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541631\n",
      "\tspeed: 0.0412s/iter; left time: 88.1395s\n",
      "\titers: 200, epoch: 11 | loss: 0.0595317\n",
      "\tspeed: 0.0172s/iter; left time: 35.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0548145 Vali Loss: 0.0604594 Test Loss: 0.0633140\n",
      "Validation loss decreased (0.060959 --> 0.060459).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0551679\n",
      "\tspeed: 0.0360s/iter; left time: 69.0031s\n",
      "\titers: 200, epoch: 12 | loss: 0.0506632\n",
      "\tspeed: 0.0202s/iter; left time: 36.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0540808 Vali Loss: 0.0599905 Test Loss: 0.0628521\n",
      "Validation loss decreased (0.060459 --> 0.059990).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570984\n",
      "\tspeed: 0.0402s/iter; left time: 68.0589s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494264\n",
      "\tspeed: 0.0198s/iter; left time: 31.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0539780 Vali Loss: 0.0598418 Test Loss: 0.0626836\n",
      "Validation loss decreased (0.059990 --> 0.059842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523727\n",
      "\tspeed: 0.0361s/iter; left time: 53.0909s\n",
      "\titers: 200, epoch: 14 | loss: 0.0538516\n",
      "\tspeed: 0.0184s/iter; left time: 25.2173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0532672 Vali Loss: 0.0598634 Test Loss: 0.0626787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0509895\n",
      "\tspeed: 0.0351s/iter; left time: 43.7359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0479047\n",
      "\tspeed: 0.0175s/iter; left time: 19.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528779 Vali Loss: 0.0594473 Test Loss: 0.0624075\n",
      "Validation loss decreased (0.059842 --> 0.059447).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509207\n",
      "\tspeed: 0.0430s/iter; left time: 43.8795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511976\n",
      "\tspeed: 0.0235s/iter; left time: 21.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0526040 Vali Loss: 0.0597805 Test Loss: 0.0625402\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0506773\n",
      "\tspeed: 0.0391s/iter; left time: 31.1416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0510104\n",
      "\tspeed: 0.0174s/iter; left time: 12.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0523335 Vali Loss: 0.0592356 Test Loss: 0.0620888\n",
      "Validation loss decreased (0.059447 --> 0.059236).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547306\n",
      "\tspeed: 0.0375s/iter; left time: 21.4689s\n",
      "\titers: 200, epoch: 18 | loss: 0.0486531\n",
      "\tspeed: 0.0206s/iter; left time: 9.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0520337 Vali Loss: 0.0590360 Test Loss: 0.0619049\n",
      "Validation loss decreased (0.059236 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0527190\n",
      "\tspeed: 0.0399s/iter; left time: 13.9154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0546635\n",
      "\tspeed: 0.0209s/iter; left time: 5.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0518412 Vali Loss: 0.0589188 Test Loss: 0.0616275\n",
      "Validation loss decreased (0.059036 --> 0.058919).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517122\n",
      "\tspeed: 0.0369s/iter; left time: 4.6182s\n",
      "\titers: 200, epoch: 20 | loss: 0.0467894\n",
      "\tspeed: 0.0175s/iter; left time: 0.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0516144 Vali Loss: 0.0589262 Test Loss: 0.0616789\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011188277043402195, rmse:0.1057746484875679, mae:0.061627473682165146, rse:0.4080756902694702\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:48.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2376123\n",
      "\tspeed: 0.0433s/iter; left time: 189.6333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2176388\n",
      "\tspeed: 0.0156s/iter; left time: 66.9746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.2399932 Vali Loss: 0.1820386 Test Loss: 0.1900109\n",
      "Validation loss decreased (inf --> 0.182039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265507\n",
      "\tspeed: 0.0285s/iter; left time: 118.3378s\n",
      "\titers: 200, epoch: 2 | loss: 0.1035292\n",
      "\tspeed: 0.0101s/iter; left time: 41.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.50s\n",
      "Steps: 224 | Train Loss: 0.1321868 Vali Loss: 0.0978255 Test Loss: 0.1090021\n",
      "Validation loss decreased (0.182039 --> 0.097825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846779\n",
      "\tspeed: 0.0334s/iter; left time: 131.2917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833393\n",
      "\tspeed: 0.0168s/iter; left time: 64.3798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0898577 Vali Loss: 0.0874486 Test Loss: 0.0943267\n",
      "Validation loss decreased (0.097825 --> 0.087449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866304\n",
      "\tspeed: 0.0353s/iter; left time: 130.9741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785125\n",
      "\tspeed: 0.0179s/iter; left time: 64.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0817217 Vali Loss: 0.0812725 Test Loss: 0.0922101\n",
      "Validation loss decreased (0.087449 --> 0.081272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759404\n",
      "\tspeed: 0.0372s/iter; left time: 129.5779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724709\n",
      "\tspeed: 0.0172s/iter; left time: 58.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0761617 Vali Loss: 0.0798818 Test Loss: 0.0892022\n",
      "Validation loss decreased (0.081272 --> 0.079882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730126\n",
      "\tspeed: 0.0387s/iter; left time: 126.1875s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706904\n",
      "\tspeed: 0.0203s/iter; left time: 64.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0733255 Vali Loss: 0.0813803 Test Loss: 0.0906584\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0694209\n",
      "\tspeed: 0.0368s/iter; left time: 111.6742s\n",
      "\titers: 200, epoch: 7 | loss: 0.0688913\n",
      "\tspeed: 0.0172s/iter; left time: 50.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0713795 Vali Loss: 0.0783019 Test Loss: 0.0876185\n",
      "Validation loss decreased (0.079882 --> 0.078302).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692374\n",
      "\tspeed: 0.0359s/iter; left time: 101.0960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723100\n",
      "\tspeed: 0.0203s/iter; left time: 55.1739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0698780 Vali Loss: 0.0797364 Test Loss: 0.0891378\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673978\n",
      "\tspeed: 0.0347s/iter; left time: 89.7728s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718123\n",
      "\tspeed: 0.0160s/iter; left time: 39.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 224 | Train Loss: 0.0689383 Vali Loss: 0.0772867 Test Loss: 0.0865917\n",
      "Validation loss decreased (0.078302 --> 0.077287).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0669109\n",
      "\tspeed: 0.0386s/iter; left time: 91.1772s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688583\n",
      "\tspeed: 0.0186s/iter; left time: 42.0772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0679880 Vali Loss: 0.0769814 Test Loss: 0.0862253\n",
      "Validation loss decreased (0.077287 --> 0.076981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655633\n",
      "\tspeed: 0.0353s/iter; left time: 75.6603s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697610\n",
      "\tspeed: 0.0186s/iter; left time: 37.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0672705 Vali Loss: 0.0770186 Test Loss: 0.0866094\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0671214\n",
      "\tspeed: 0.0350s/iter; left time: 67.0952s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657846\n",
      "\tspeed: 0.0173s/iter; left time: 31.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0667600 Vali Loss: 0.0767011 Test Loss: 0.0858800\n",
      "Validation loss decreased (0.076981 --> 0.076701).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0652994\n",
      "\tspeed: 0.0357s/iter; left time: 60.4834s\n",
      "\titers: 200, epoch: 13 | loss: 0.0626735\n",
      "\tspeed: 0.0175s/iter; left time: 27.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0664647 Vali Loss: 0.0761145 Test Loss: 0.0853630\n",
      "Validation loss decreased (0.076701 --> 0.076114).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677260\n",
      "\tspeed: 0.0352s/iter; left time: 51.7130s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664584\n",
      "\tspeed: 0.0159s/iter; left time: 21.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 224 | Train Loss: 0.0661434 Vali Loss: 0.0760438 Test Loss: 0.0854855\n",
      "Validation loss decreased (0.076114 --> 0.076044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0650310\n",
      "\tspeed: 0.0362s/iter; left time: 45.1111s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645760\n",
      "\tspeed: 0.0192s/iter; left time: 22.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0657940 Vali Loss: 0.0758434 Test Loss: 0.0854522\n",
      "Validation loss decreased (0.076044 --> 0.075843).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683786\n",
      "\tspeed: 0.0373s/iter; left time: 38.0980s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633495\n",
      "\tspeed: 0.0207s/iter; left time: 19.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0652890 Vali Loss: 0.0757317 Test Loss: 0.0853963\n",
      "Validation loss decreased (0.075843 --> 0.075732).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653206\n",
      "\tspeed: 0.0393s/iter; left time: 31.3164s\n",
      "\titers: 200, epoch: 17 | loss: 0.0686818\n",
      "\tspeed: 0.0179s/iter; left time: 12.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0651356 Vali Loss: 0.0761950 Test Loss: 0.0856272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0641906\n",
      "\tspeed: 0.0360s/iter; left time: 20.6224s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686619\n",
      "\tspeed: 0.0168s/iter; left time: 7.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0650996 Vali Loss: 0.0756082 Test Loss: 0.0850791\n",
      "Validation loss decreased (0.075732 --> 0.075608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0610050\n",
      "\tspeed: 0.0363s/iter; left time: 12.6672s\n",
      "\titers: 200, epoch: 19 | loss: 0.0601536\n",
      "\tspeed: 0.0196s/iter; left time: 4.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0647289 Vali Loss: 0.0752691 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.075608 --> 0.075269).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650624\n",
      "\tspeed: 0.0359s/iter; left time: 4.4875s\n",
      "\titers: 200, epoch: 20 | loss: 0.0631445\n",
      "\tspeed: 0.0168s/iter; left time: 0.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0646341 Vali Loss: 0.0755274 Test Loss: 0.0852032\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020759424194693565, rmse:0.14408130943775177, mae:0.08491359651088715, rse:0.5573447942733765\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2406403\n",
      "\tspeed: 0.0230s/iter; left time: 100.7112s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188262\n",
      "\tspeed: 0.0176s/iter; left time: 75.2445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.2381317 Vali Loss: 0.1789258 Test Loss: 0.1865743\n",
      "Validation loss decreased (inf --> 0.178926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1343914\n",
      "\tspeed: 0.0433s/iter; left time: 179.8364s\n",
      "\titers: 200, epoch: 2 | loss: 0.0930818\n",
      "\tspeed: 0.0177s/iter; left time: 71.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.1332448 Vali Loss: 0.0972317 Test Loss: 0.1086327\n",
      "Validation loss decreased (0.178926 --> 0.097232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907119\n",
      "\tspeed: 0.0414s/iter; left time: 162.8802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0898331\n",
      "\tspeed: 0.0135s/iter; left time: 51.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0904112 Vali Loss: 0.0884094 Test Loss: 0.0957489\n",
      "Validation loss decreased (0.097232 --> 0.088409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0800296\n",
      "\tspeed: 0.0383s/iter; left time: 142.2116s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827712\n",
      "\tspeed: 0.0166s/iter; left time: 59.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0818481 Vali Loss: 0.0822035 Test Loss: 0.0922612\n",
      "Validation loss decreased (0.088409 --> 0.082203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791426\n",
      "\tspeed: 0.0347s/iter; left time: 120.9045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790642\n",
      "\tspeed: 0.0178s/iter; left time: 60.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0770117 Vali Loss: 0.0795626 Test Loss: 0.0895083\n",
      "Validation loss decreased (0.082203 --> 0.079563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730632\n",
      "\tspeed: 0.0362s/iter; left time: 118.0433s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708637\n",
      "\tspeed: 0.0179s/iter; left time: 56.5925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0741224 Vali Loss: 0.0787785 Test Loss: 0.0881438\n",
      "Validation loss decreased (0.079563 --> 0.078779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0686050\n",
      "\tspeed: 0.0365s/iter; left time: 110.8007s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743980\n",
      "\tspeed: 0.0176s/iter; left time: 51.8059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0715071 Vali Loss: 0.0792559 Test Loss: 0.0889636\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750379\n",
      "\tspeed: 0.0354s/iter; left time: 99.6687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0685743\n",
      "\tspeed: 0.0167s/iter; left time: 45.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0700779 Vali Loss: 0.0787402 Test Loss: 0.0882414\n",
      "Validation loss decreased (0.078779 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686822\n",
      "\tspeed: 0.0346s/iter; left time: 89.4876s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684529\n",
      "\tspeed: 0.0177s/iter; left time: 44.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0689258 Vali Loss: 0.0775224 Test Loss: 0.0869969\n",
      "Validation loss decreased (0.078740 --> 0.077522).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689297\n",
      "\tspeed: 0.0371s/iter; left time: 87.6534s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664442\n",
      "\tspeed: 0.0206s/iter; left time: 46.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0681905 Vali Loss: 0.0769314 Test Loss: 0.0865170\n",
      "Validation loss decreased (0.077522 --> 0.076931).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694460\n",
      "\tspeed: 0.0425s/iter; left time: 90.9632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0733899\n",
      "\tspeed: 0.0209s/iter; left time: 42.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0677455 Vali Loss: 0.0769557 Test Loss: 0.0862589\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652838\n",
      "\tspeed: 0.0356s/iter; left time: 68.1971s\n",
      "\titers: 200, epoch: 12 | loss: 0.0629617\n",
      "\tspeed: 0.0163s/iter; left time: 29.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0668834 Vali Loss: 0.0763795 Test Loss: 0.0861417\n",
      "Validation loss decreased (0.076931 --> 0.076379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643209\n",
      "\tspeed: 0.0394s/iter; left time: 66.7805s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618452\n",
      "\tspeed: 0.0185s/iter; left time: 29.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0667896 Vali Loss: 0.0762287 Test Loss: 0.0860246\n",
      "Validation loss decreased (0.076379 --> 0.076229).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677970\n",
      "\tspeed: 0.0374s/iter; left time: 54.9118s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648690\n",
      "\tspeed: 0.0170s/iter; left time: 23.3041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0661625 Vali Loss: 0.0762512 Test Loss: 0.0858173\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696925\n",
      "\tspeed: 0.0330s/iter; left time: 41.0334s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697655\n",
      "\tspeed: 0.0126s/iter; left time: 14.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 224 | Train Loss: 0.0660004 Vali Loss: 0.0760939 Test Loss: 0.0859716\n",
      "Validation loss decreased (0.076229 --> 0.076094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0652443\n",
      "\tspeed: 0.0362s/iter; left time: 37.0054s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687751\n",
      "\tspeed: 0.0185s/iter; left time: 17.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0656887 Vali Loss: 0.0760748 Test Loss: 0.0856839\n",
      "Validation loss decreased (0.076094 --> 0.076075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659079\n",
      "\tspeed: 0.0425s/iter; left time: 33.8817s\n",
      "\titers: 200, epoch: 17 | loss: 0.0638563\n",
      "\tspeed: 0.0204s/iter; left time: 14.2531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0653609 Vali Loss: 0.0753801 Test Loss: 0.0850498\n",
      "Validation loss decreased (0.076075 --> 0.075380).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578677\n",
      "\tspeed: 0.0429s/iter; left time: 24.5603s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645344\n",
      "\tspeed: 0.0206s/iter; left time: 9.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0651030 Vali Loss: 0.0752875 Test Loss: 0.0849164\n",
      "Validation loss decreased (0.075380 --> 0.075287).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679285\n",
      "\tspeed: 0.0381s/iter; left time: 13.2944s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629789\n",
      "\tspeed: 0.0189s/iter; left time: 4.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0649769 Vali Loss: 0.0752234 Test Loss: 0.0850461\n",
      "Validation loss decreased (0.075287 --> 0.075223).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0604777\n",
      "\tspeed: 0.0420s/iter; left time: 5.2439s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633929\n",
      "\tspeed: 0.0228s/iter; left time: 0.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0648052 Vali Loss: 0.0750941 Test Loss: 0.0847241\n",
      "Validation loss decreased (0.075223 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020768484100699425, rmse:0.1441127508878708, mae:0.08472401648759842, rse:0.557466447353363\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:50.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2415983\n",
      "\tspeed: 0.0429s/iter; left time: 186.9511s\n",
      "\titers: 200, epoch: 1 | loss: 0.2171375\n",
      "\tspeed: 0.0197s/iter; left time: 84.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.2396583 Vali Loss: 0.1837324 Test Loss: 0.1892370\n",
      "Validation loss decreased (inf --> 0.183732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308411\n",
      "\tspeed: 0.0352s/iter; left time: 145.5875s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008430\n",
      "\tspeed: 0.0138s/iter; left time: 55.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.1290515 Vali Loss: 0.1001020 Test Loss: 0.1102373\n",
      "Validation loss decreased (0.183732 --> 0.100102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921982\n",
      "\tspeed: 0.0308s/iter; left time: 120.5068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871918\n",
      "\tspeed: 0.0164s/iter; left time: 62.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0915927 Vali Loss: 0.0885639 Test Loss: 0.0966656\n",
      "Validation loss decreased (0.100102 --> 0.088564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855776\n",
      "\tspeed: 0.0373s/iter; left time: 137.6077s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837535\n",
      "\tspeed: 0.0205s/iter; left time: 73.5942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0834356 Vali Loss: 0.0840129 Test Loss: 0.0964303\n",
      "Validation loss decreased (0.088564 --> 0.084013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791744\n",
      "\tspeed: 0.0301s/iter; left time: 104.4480s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818138\n",
      "\tspeed: 0.0128s/iter; left time: 43.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0787496 Vali Loss: 0.0833566 Test Loss: 0.0940999\n",
      "Validation loss decreased (0.084013 --> 0.083357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733721\n",
      "\tspeed: 0.0390s/iter; left time: 126.6729s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746970\n",
      "\tspeed: 0.0181s/iter; left time: 56.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0759646 Vali Loss: 0.0820459 Test Loss: 0.0931131\n",
      "Validation loss decreased (0.083357 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0735331\n",
      "\tspeed: 0.0395s/iter; left time: 119.3942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753593\n",
      "\tspeed: 0.0204s/iter; left time: 59.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0739412 Vali Loss: 0.0815248 Test Loss: 0.0922228\n",
      "Validation loss decreased (0.082046 --> 0.081525).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788458\n",
      "\tspeed: 0.0299s/iter; left time: 83.6982s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706467\n",
      "\tspeed: 0.0160s/iter; left time: 43.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 223 | Train Loss: 0.0726488 Vali Loss: 0.0809920 Test Loss: 0.0920340\n",
      "Validation loss decreased (0.081525 --> 0.080992).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731968\n",
      "\tspeed: 0.0393s/iter; left time: 101.1564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705744\n",
      "\tspeed: 0.0215s/iter; left time: 53.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0718527 Vali Loss: 0.0807292 Test Loss: 0.0924453\n",
      "Validation loss decreased (0.080992 --> 0.080729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0689927\n",
      "\tspeed: 0.0362s/iter; left time: 85.1936s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748475\n",
      "\tspeed: 0.0184s/iter; left time: 41.5790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0710256 Vali Loss: 0.0807077 Test Loss: 0.0923059\n",
      "Validation loss decreased (0.080729 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746388\n",
      "\tspeed: 0.0397s/iter; left time: 84.6464s\n",
      "\titers: 200, epoch: 11 | loss: 0.0722722\n",
      "\tspeed: 0.0212s/iter; left time: 42.9622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0800194 Test Loss: 0.0915396\n",
      "Validation loss decreased (0.080708 --> 0.080019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725398\n",
      "\tspeed: 0.0364s/iter; left time: 69.3656s\n",
      "\titers: 200, epoch: 12 | loss: 0.0681525\n",
      "\tspeed: 0.0221s/iter; left time: 40.0146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0699171 Vali Loss: 0.0795278 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.080019 --> 0.079528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700694\n",
      "\tspeed: 0.0416s/iter; left time: 70.1324s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731358\n",
      "\tspeed: 0.0239s/iter; left time: 37.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0692579 Vali Loss: 0.0792205 Test Loss: 0.0908709\n",
      "Validation loss decreased (0.079528 --> 0.079221).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677352\n",
      "\tspeed: 0.0369s/iter; left time: 53.8790s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672651\n",
      "\tspeed: 0.0220s/iter; left time: 29.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0693273 Vali Loss: 0.0799549 Test Loss: 0.0911924\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686877\n",
      "\tspeed: 0.0353s/iter; left time: 43.7812s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673233\n",
      "\tspeed: 0.0166s/iter; left time: 18.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0687886 Vali Loss: 0.0789855 Test Loss: 0.0902842\n",
      "Validation loss decreased (0.079221 --> 0.078985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693234\n",
      "\tspeed: 0.0384s/iter; left time: 39.0585s\n",
      "\titers: 200, epoch: 16 | loss: 0.0656006\n",
      "\tspeed: 0.0205s/iter; left time: 18.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0684875 Vali Loss: 0.0789118 Test Loss: 0.0907163\n",
      "Validation loss decreased (0.078985 --> 0.078912).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690468\n",
      "\tspeed: 0.0384s/iter; left time: 30.4659s\n",
      "\titers: 200, epoch: 17 | loss: 0.0690186\n",
      "\tspeed: 0.0172s/iter; left time: 11.9438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0688395 Vali Loss: 0.0789351 Test Loss: 0.0913039\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677685\n",
      "\tspeed: 0.0382s/iter; left time: 21.7958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652733\n",
      "\tspeed: 0.0200s/iter; left time: 9.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0681415 Vali Loss: 0.0787291 Test Loss: 0.0902462\n",
      "Validation loss decreased (0.078912 --> 0.078729).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698953\n",
      "\tspeed: 0.0362s/iter; left time: 12.5470s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713138\n",
      "\tspeed: 0.0184s/iter; left time: 4.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0681629 Vali Loss: 0.0787422 Test Loss: 0.0906234\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0692991\n",
      "\tspeed: 0.0405s/iter; left time: 5.0222s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691924\n",
      "\tspeed: 0.0237s/iter; left time: 0.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0678958 Vali Loss: 0.0786230 Test Loss: 0.0903330\n",
      "Validation loss decreased (0.078729 --> 0.078623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023141568526625633, rmse:0.15212352573871613, mae:0.09033302962779999, rse:0.5891888737678528\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2403809\n",
      "\tspeed: 0.0287s/iter; left time: 125.3333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2154531\n",
      "\tspeed: 0.0193s/iter; left time: 82.0615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.2422614 Vali Loss: 0.1823216 Test Loss: 0.1888932\n",
      "Validation loss decreased (inf --> 0.182322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229391\n",
      "\tspeed: 0.0366s/iter; left time: 151.5587s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984408\n",
      "\tspeed: 0.0184s/iter; left time: 74.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1311886 Vali Loss: 0.1001970 Test Loss: 0.1099112\n",
      "Validation loss decreased (0.182322 --> 0.100197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898930\n",
      "\tspeed: 0.0379s/iter; left time: 148.2770s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917291\n",
      "\tspeed: 0.0206s/iter; left time: 78.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0914624 Vali Loss: 0.0890297 Test Loss: 0.0978792\n",
      "Validation loss decreased (0.100197 --> 0.089030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854143\n",
      "\tspeed: 0.0362s/iter; left time: 133.6721s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808555\n",
      "\tspeed: 0.0181s/iter; left time: 64.9064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0837825 Vali Loss: 0.0859060 Test Loss: 0.0959388\n",
      "Validation loss decreased (0.089030 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808391\n",
      "\tspeed: 0.0366s/iter; left time: 127.1186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785895\n",
      "\tspeed: 0.0174s/iter; left time: 58.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0792879 Vali Loss: 0.0840676 Test Loss: 0.0946624\n",
      "Validation loss decreased (0.085906 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755854\n",
      "\tspeed: 0.0369s/iter; left time: 119.9223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746735\n",
      "\tspeed: 0.0186s/iter; left time: 58.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0765742 Vali Loss: 0.0853610 Test Loss: 0.0968855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792653\n",
      "\tspeed: 0.0402s/iter; left time: 121.6135s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721418\n",
      "\tspeed: 0.0222s/iter; left time: 64.9495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0743388 Vali Loss: 0.0818612 Test Loss: 0.0936658\n",
      "Validation loss decreased (0.084068 --> 0.081861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736356\n",
      "\tspeed: 0.0411s/iter; left time: 115.0086s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732522\n",
      "\tspeed: 0.0192s/iter; left time: 51.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0730863 Vali Loss: 0.0821424 Test Loss: 0.0942828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0689212\n",
      "\tspeed: 0.0351s/iter; left time: 90.4486s\n",
      "\titers: 200, epoch: 9 | loss: 0.0701418\n",
      "\tspeed: 0.0194s/iter; left time: 48.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0719471 Vali Loss: 0.0811452 Test Loss: 0.0941387\n",
      "Validation loss decreased (0.081861 --> 0.081145).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0695085\n",
      "\tspeed: 0.0362s/iter; left time: 85.1182s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699557\n",
      "\tspeed: 0.0178s/iter; left time: 40.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0711944 Vali Loss: 0.0805143 Test Loss: 0.0936558\n",
      "Validation loss decreased (0.081145 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0710805\n",
      "\tspeed: 0.0335s/iter; left time: 71.4245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656972\n",
      "\tspeed: 0.0123s/iter; left time: 25.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 223 | Train Loss: 0.0703731 Vali Loss: 0.0806881 Test Loss: 0.0943752\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712831\n",
      "\tspeed: 0.0365s/iter; left time: 69.5955s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711581\n",
      "\tspeed: 0.0178s/iter; left time: 32.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0701223 Vali Loss: 0.0796910 Test Loss: 0.0930109\n",
      "Validation loss decreased (0.080514 --> 0.079691).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698889\n",
      "\tspeed: 0.0355s/iter; left time: 59.8107s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705252\n",
      "\tspeed: 0.0179s/iter; left time: 28.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0696029 Vali Loss: 0.0801107 Test Loss: 0.0943232\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0708620\n",
      "\tspeed: 0.0372s/iter; left time: 54.4246s\n",
      "\titers: 200, epoch: 14 | loss: 0.0683931\n",
      "\tspeed: 0.0204s/iter; left time: 27.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0692059 Vali Loss: 0.0794433 Test Loss: 0.0930229\n",
      "Validation loss decreased (0.079691 --> 0.079443).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0689742\n",
      "\tspeed: 0.0399s/iter; left time: 49.4199s\n",
      "\titers: 200, epoch: 15 | loss: 0.0665230\n",
      "\tspeed: 0.0172s/iter; left time: 19.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0690320 Vali Loss: 0.0792129 Test Loss: 0.0928772\n",
      "Validation loss decreased (0.079443 --> 0.079213).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715083\n",
      "\tspeed: 0.0376s/iter; left time: 38.2296s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682462\n",
      "\tspeed: 0.0196s/iter; left time: 17.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0687173 Vali Loss: 0.0790982 Test Loss: 0.0926940\n",
      "Validation loss decreased (0.079213 --> 0.079098).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676954\n",
      "\tspeed: 0.0383s/iter; left time: 30.3890s\n",
      "\titers: 200, epoch: 17 | loss: 0.0672674\n",
      "\tspeed: 0.0180s/iter; left time: 12.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0685975 Vali Loss: 0.0791815 Test Loss: 0.0935558\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662949\n",
      "\tspeed: 0.0347s/iter; left time: 19.7915s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675989\n",
      "\tspeed: 0.0178s/iter; left time: 8.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0684725 Vali Loss: 0.0790181 Test Loss: 0.0932168\n",
      "Validation loss decreased (0.079098 --> 0.079018).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0674201\n",
      "\tspeed: 0.0355s/iter; left time: 12.3216s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678428\n",
      "\tspeed: 0.0185s/iter; left time: 4.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0681966 Vali Loss: 0.0788749 Test Loss: 0.0930523\n",
      "Validation loss decreased (0.079018 --> 0.078875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678935\n",
      "\tspeed: 0.0401s/iter; left time: 4.9665s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656016\n",
      "\tspeed: 0.0184s/iter; left time: 0.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0679420 Vali Loss: 0.0789774 Test Loss: 0.0931080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.025284940376877785, rmse:0.15901239216327667, mae:0.09305231273174286, rse:0.6158700585365295\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:55.03s\n",
      "Intermediate time for FR: 00h:11m:34.56s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2695078\n",
      "\tspeed: 0.0396s/iter; left time: 173.6948s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527815\n",
      "\tspeed: 0.0115s/iter; left time: 49.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.2790294 Vali Loss: 0.1914239 Test Loss: 0.1981633\n",
      "Validation loss decreased (inf --> 0.191424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480391\n",
      "\tspeed: 0.0361s/iter; left time: 150.2084s\n",
      "\titers: 200, epoch: 2 | loss: 0.1127619\n",
      "\tspeed: 0.0189s/iter; left time: 76.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1554886 Vali Loss: 0.0975372 Test Loss: 0.1004008\n",
      "Validation loss decreased (0.191424 --> 0.097537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012118\n",
      "\tspeed: 0.0330s/iter; left time: 129.9814s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938744\n",
      "\tspeed: 0.0157s/iter; left time: 60.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0982717 Vali Loss: 0.0792012 Test Loss: 0.0820112\n",
      "Validation loss decreased (0.097537 --> 0.079201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845128\n",
      "\tspeed: 0.0342s/iter; left time: 126.9105s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819414\n",
      "\tspeed: 0.0172s/iter; left time: 62.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0864264 Vali Loss: 0.0739832 Test Loss: 0.0760879\n",
      "Validation loss decreased (0.079201 --> 0.073983).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850693\n",
      "\tspeed: 0.0340s/iter; left time: 118.5002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784278\n",
      "\tspeed: 0.0171s/iter; left time: 57.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0796801 Vali Loss: 0.0709331 Test Loss: 0.0732638\n",
      "Validation loss decreased (0.073983 --> 0.070933).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794061\n",
      "\tspeed: 0.0286s/iter; left time: 93.1979s\n",
      "\titers: 200, epoch: 6 | loss: 0.0746430\n",
      "\tspeed: 0.0243s/iter; left time: 76.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0754969 Vali Loss: 0.0684564 Test Loss: 0.0712235\n",
      "Validation loss decreased (0.070933 --> 0.068456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713257\n",
      "\tspeed: 0.0346s/iter; left time: 105.1945s\n",
      "\titers: 200, epoch: 7 | loss: 0.0735685\n",
      "\tspeed: 0.0159s/iter; left time: 46.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0732122 Vali Loss: 0.0671184 Test Loss: 0.0697729\n",
      "Validation loss decreased (0.068456 --> 0.067118).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736657\n",
      "\tspeed: 0.0330s/iter; left time: 92.6893s\n",
      "\titers: 200, epoch: 8 | loss: 0.0640603\n",
      "\tspeed: 0.0162s/iter; left time: 43.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0714827 Vali Loss: 0.0656314 Test Loss: 0.0683883\n",
      "Validation loss decreased (0.067118 --> 0.065631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681269\n",
      "\tspeed: 0.0349s/iter; left time: 90.3916s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682837\n",
      "\tspeed: 0.0194s/iter; left time: 48.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0697727 Vali Loss: 0.0651581 Test Loss: 0.0677156\n",
      "Validation loss decreased (0.065631 --> 0.065158).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658835\n",
      "\tspeed: 0.0364s/iter; left time: 86.0386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686328\n",
      "\tspeed: 0.0209s/iter; left time: 47.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0685098 Vali Loss: 0.0636927 Test Loss: 0.0664533\n",
      "Validation loss decreased (0.065158 --> 0.063693).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679269\n",
      "\tspeed: 0.0389s/iter; left time: 83.3571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0681390\n",
      "\tspeed: 0.0155s/iter; left time: 31.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0674964 Vali Loss: 0.0630472 Test Loss: 0.0659242\n",
      "Validation loss decreased (0.063693 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0687467\n",
      "\tspeed: 0.0382s/iter; left time: 73.2141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654976\n",
      "\tspeed: 0.0196s/iter; left time: 35.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0668542 Vali Loss: 0.0631576 Test Loss: 0.0658351\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685944\n",
      "\tspeed: 0.0355s/iter; left time: 60.1384s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666020\n",
      "\tspeed: 0.0100s/iter; left time: 15.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 224 | Train Loss: 0.0661510 Vali Loss: 0.0625378 Test Loss: 0.0647952\n",
      "Validation loss decreased (0.063047 --> 0.062538).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661565\n",
      "\tspeed: 0.0331s/iter; left time: 48.6536s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672748\n",
      "\tspeed: 0.0178s/iter; left time: 24.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0655631 Vali Loss: 0.0617294 Test Loss: 0.0643431\n",
      "Validation loss decreased (0.062538 --> 0.061729).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649039\n",
      "\tspeed: 0.0343s/iter; left time: 42.7145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619932\n",
      "\tspeed: 0.0171s/iter; left time: 19.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0650988 Vali Loss: 0.0613002 Test Loss: 0.0638504\n",
      "Validation loss decreased (0.061729 --> 0.061300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0638169\n",
      "\tspeed: 0.0369s/iter; left time: 37.7210s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698117\n",
      "\tspeed: 0.0181s/iter; left time: 16.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0644789 Vali Loss: 0.0611151 Test Loss: 0.0636669\n",
      "Validation loss decreased (0.061300 --> 0.061115).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712146\n",
      "\tspeed: 0.0363s/iter; left time: 28.9486s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726731\n",
      "\tspeed: 0.0191s/iter; left time: 13.3265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0642380 Vali Loss: 0.0611685 Test Loss: 0.0636596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624971\n",
      "\tspeed: 0.0387s/iter; left time: 22.1770s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669889\n",
      "\tspeed: 0.0185s/iter; left time: 8.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0642110 Vali Loss: 0.0606077 Test Loss: 0.0631849\n",
      "Validation loss decreased (0.061115 --> 0.060608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0623439\n",
      "\tspeed: 0.0314s/iter; left time: 10.9676s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613840\n",
      "\tspeed: 0.0162s/iter; left time: 4.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 224 | Train Loss: 0.0639550 Vali Loss: 0.0603431 Test Loss: 0.0629849\n",
      "Validation loss decreased (0.060608 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0628911\n",
      "\tspeed: 0.0356s/iter; left time: 4.4533s\n",
      "\titers: 200, epoch: 20 | loss: 0.0603223\n",
      "\tspeed: 0.0160s/iter; left time: 0.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0634122 Vali Loss: 0.0605309 Test Loss: 0.0629420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011143858544528484, rmse:0.10556447505950928, mae:0.06298493593931198, rse:0.3988761603832245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2797548\n",
      "\tspeed: 0.0225s/iter; left time: 98.6428s\n",
      "\titers: 200, epoch: 1 | loss: 0.2564775\n",
      "\tspeed: 0.0169s/iter; left time: 72.5572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.2824721 Vali Loss: 0.1925696 Test Loss: 0.1999343\n",
      "Validation loss decreased (inf --> 0.192570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1519092\n",
      "\tspeed: 0.0356s/iter; left time: 147.9756s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138760\n",
      "\tspeed: 0.0186s/iter; left time: 75.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1577599 Vali Loss: 0.0885143 Test Loss: 0.0898196\n",
      "Validation loss decreased (0.192570 --> 0.088514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994059\n",
      "\tspeed: 0.0395s/iter; left time: 155.5060s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920600\n",
      "\tspeed: 0.0183s/iter; left time: 69.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0987331 Vali Loss: 0.0793598 Test Loss: 0.0813890\n",
      "Validation loss decreased (0.088514 --> 0.079360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862465\n",
      "\tspeed: 0.0388s/iter; left time: 144.0705s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823747\n",
      "\tspeed: 0.0219s/iter; left time: 78.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0878294 Vali Loss: 0.0752087 Test Loss: 0.0770064\n",
      "Validation loss decreased (0.079360 --> 0.075209).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805695\n",
      "\tspeed: 0.0356s/iter; left time: 123.9224s\n",
      "\titers: 200, epoch: 5 | loss: 0.0835280\n",
      "\tspeed: 0.0190s/iter; left time: 64.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0810251 Vali Loss: 0.0726535 Test Loss: 0.0742234\n",
      "Validation loss decreased (0.075209 --> 0.072653).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0783956\n",
      "\tspeed: 0.0350s/iter; left time: 114.2656s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783434\n",
      "\tspeed: 0.0181s/iter; left time: 57.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0766793 Vali Loss: 0.0699164 Test Loss: 0.0714286\n",
      "Validation loss decreased (0.072653 --> 0.069916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0737392\n",
      "\tspeed: 0.0362s/iter; left time: 109.8210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715222\n",
      "\tspeed: 0.0166s/iter; left time: 48.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0738872 Vali Loss: 0.0673173 Test Loss: 0.0694845\n",
      "Validation loss decreased (0.069916 --> 0.067317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0708480\n",
      "\tspeed: 0.0329s/iter; left time: 92.4522s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682935\n",
      "\tspeed: 0.0161s/iter; left time: 43.6458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0719646 Vali Loss: 0.0660387 Test Loss: 0.0682573\n",
      "Validation loss decreased (0.067317 --> 0.066039).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645496\n",
      "\tspeed: 0.0361s/iter; left time: 93.4366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698819\n",
      "\tspeed: 0.0176s/iter; left time: 43.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0701305 Vali Loss: 0.0643912 Test Loss: 0.0671896\n",
      "Validation loss decreased (0.066039 --> 0.064391).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676103\n",
      "\tspeed: 0.0381s/iter; left time: 90.2130s\n",
      "\titers: 200, epoch: 10 | loss: 0.0639220\n",
      "\tspeed: 0.0204s/iter; left time: 46.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0692499 Vali Loss: 0.0639208 Test Loss: 0.0666822\n",
      "Validation loss decreased (0.064391 --> 0.063921).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0649667\n",
      "\tspeed: 0.0399s/iter; left time: 85.4800s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642909\n",
      "\tspeed: 0.0189s/iter; left time: 38.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0680481 Vali Loss: 0.0636861 Test Loss: 0.0665629\n",
      "Validation loss decreased (0.063921 --> 0.063686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0633217\n",
      "\tspeed: 0.0336s/iter; left time: 64.5001s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601581\n",
      "\tspeed: 0.0168s/iter; left time: 30.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 224 | Train Loss: 0.0671285 Vali Loss: 0.0625936 Test Loss: 0.0653706\n",
      "Validation loss decreased (0.063686 --> 0.062594).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0671477\n",
      "\tspeed: 0.0366s/iter; left time: 61.9518s\n",
      "\titers: 200, epoch: 13 | loss: 0.0621317\n",
      "\tspeed: 0.0222s/iter; left time: 35.4376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0662944 Vali Loss: 0.0626164 Test Loss: 0.0654073\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650934\n",
      "\tspeed: 0.0333s/iter; left time: 48.9785s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580635\n",
      "\tspeed: 0.0173s/iter; left time: 23.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0657543 Vali Loss: 0.0621716 Test Loss: 0.0646343\n",
      "Validation loss decreased (0.062594 --> 0.062172).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0658439\n",
      "\tspeed: 0.0344s/iter; left time: 42.7789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0626161\n",
      "\tspeed: 0.0178s/iter; left time: 20.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0653719 Vali Loss: 0.0616256 Test Loss: 0.0642001\n",
      "Validation loss decreased (0.062172 --> 0.061626).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0626120\n",
      "\tspeed: 0.0306s/iter; left time: 31.2013s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643119\n",
      "\tspeed: 0.0098s/iter; left time: 9.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0649188 Vali Loss: 0.0611425 Test Loss: 0.0636172\n",
      "Validation loss decreased (0.061626 --> 0.061142).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716812\n",
      "\tspeed: 0.0353s/iter; left time: 28.1321s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630838\n",
      "\tspeed: 0.0199s/iter; left time: 13.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 224 | Train Loss: 0.0645986 Vali Loss: 0.0614054 Test Loss: 0.0635941\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649277\n",
      "\tspeed: 0.0374s/iter; left time: 21.4081s\n",
      "\titers: 200, epoch: 18 | loss: 0.0586403\n",
      "\tspeed: 0.0192s/iter; left time: 9.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0643763 Vali Loss: 0.0607071 Test Loss: 0.0632886\n",
      "Validation loss decreased (0.061142 --> 0.060707).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0595899\n",
      "\tspeed: 0.0351s/iter; left time: 12.2401s\n",
      "\titers: 200, epoch: 19 | loss: 0.0584789\n",
      "\tspeed: 0.0177s/iter; left time: 4.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0641533 Vali Loss: 0.0604696 Test Loss: 0.0628338\n",
      "Validation loss decreased (0.060707 --> 0.060470).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0596086\n",
      "\tspeed: 0.0383s/iter; left time: 4.7905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594903\n",
      "\tspeed: 0.0151s/iter; left time: 0.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0638867 Vali Loss: 0.0604500 Test Loss: 0.0628845\n",
      "Validation loss decreased (0.060470 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011079911142587662, rmse:0.10526115447282791, mae:0.06288447976112366, rse:0.3977300822734833\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:42.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2820992\n",
      "\tspeed: 0.0404s/iter; left time: 177.0480s\n",
      "\titers: 200, epoch: 1 | loss: 0.2535297\n",
      "\tspeed: 0.0135s/iter; left time: 57.6457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.2809569 Vali Loss: 0.1987457 Test Loss: 0.2058825\n",
      "Validation loss decreased (inf --> 0.198746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483184\n",
      "\tspeed: 0.0318s/iter; left time: 132.2362s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265880\n",
      "\tspeed: 0.0119s/iter; left time: 48.3405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.1574582 Vali Loss: 0.1070819 Test Loss: 0.1139697\n",
      "Validation loss decreased (0.198746 --> 0.107082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1128726\n",
      "\tspeed: 0.0343s/iter; left time: 134.7188s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028662\n",
      "\tspeed: 0.0173s/iter; left time: 66.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1120445 Vali Loss: 0.0964425 Test Loss: 0.1007512\n",
      "Validation loss decreased (0.107082 --> 0.096443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1027101\n",
      "\tspeed: 0.0353s/iter; left time: 130.9028s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968808\n",
      "\tspeed: 0.0162s/iter; left time: 58.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.1009265 Vali Loss: 0.0918865 Test Loss: 0.0962443\n",
      "Validation loss decreased (0.096443 --> 0.091887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948459\n",
      "\tspeed: 0.0351s/iter; left time: 122.1523s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935852\n",
      "\tspeed: 0.0182s/iter; left time: 61.5547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0945565 Vali Loss: 0.0876052 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.091887 --> 0.087605).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0925825\n",
      "\tspeed: 0.0330s/iter; left time: 107.5714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906551\n",
      "\tspeed: 0.0159s/iter; left time: 50.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0908851 Vali Loss: 0.0874503 Test Loss: 0.0924078\n",
      "Validation loss decreased (0.087605 --> 0.087450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869377\n",
      "\tspeed: 0.0364s/iter; left time: 110.4730s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865689\n",
      "\tspeed: 0.0168s/iter; left time: 49.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0887364 Vali Loss: 0.0828174 Test Loss: 0.0874810\n",
      "Validation loss decreased (0.087450 --> 0.082817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0885890\n",
      "\tspeed: 0.0372s/iter; left time: 104.7506s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889565\n",
      "\tspeed: 0.0188s/iter; left time: 51.0357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0870928 Vali Loss: 0.0816418 Test Loss: 0.0867913\n",
      "Validation loss decreased (0.082817 --> 0.081642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821148\n",
      "\tspeed: 0.0362s/iter; left time: 93.7808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840469\n",
      "\tspeed: 0.0188s/iter; left time: 46.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0858144 Vali Loss: 0.0818335 Test Loss: 0.0865875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0872634\n",
      "\tspeed: 0.0318s/iter; left time: 75.1964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0836935\n",
      "\tspeed: 0.0102s/iter; left time: 23.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0849410 Vali Loss: 0.0806118 Test Loss: 0.0851354\n",
      "Validation loss decreased (0.081642 --> 0.080612).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830239\n",
      "\tspeed: 0.0338s/iter; left time: 72.2765s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826347\n",
      "\tspeed: 0.0166s/iter; left time: 33.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0840906 Vali Loss: 0.0802821 Test Loss: 0.0848690\n",
      "Validation loss decreased (0.080612 --> 0.080282).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836394\n",
      "\tspeed: 0.0392s/iter; left time: 75.2042s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815957\n",
      "\tspeed: 0.0207s/iter; left time: 37.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0835918 Vali Loss: 0.0812157 Test Loss: 0.0862934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850312\n",
      "\tspeed: 0.0393s/iter; left time: 66.4763s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830976\n",
      "\tspeed: 0.0206s/iter; left time: 32.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0829835 Vali Loss: 0.0798016 Test Loss: 0.0845023\n",
      "Validation loss decreased (0.080282 --> 0.079802).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0774787\n",
      "\tspeed: 0.0409s/iter; left time: 60.1194s\n",
      "\titers: 200, epoch: 14 | loss: 0.0843273\n",
      "\tspeed: 0.0208s/iter; left time: 28.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0826279 Vali Loss: 0.0793638 Test Loss: 0.0843691\n",
      "Validation loss decreased (0.079802 --> 0.079364).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868259\n",
      "\tspeed: 0.0360s/iter; left time: 44.8682s\n",
      "\titers: 200, epoch: 15 | loss: 0.0784463\n",
      "\tspeed: 0.0216s/iter; left time: 24.7207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0822965 Vali Loss: 0.0796150 Test Loss: 0.0846718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0780062\n",
      "\tspeed: 0.0370s/iter; left time: 37.7275s\n",
      "\titers: 200, epoch: 16 | loss: 0.0858845\n",
      "\tspeed: 0.0203s/iter; left time: 18.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0818971 Vali Loss: 0.0792692 Test Loss: 0.0843721\n",
      "Validation loss decreased (0.079364 --> 0.079269).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798775\n",
      "\tspeed: 0.0377s/iter; left time: 30.0604s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814304\n",
      "\tspeed: 0.0188s/iter; left time: 13.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0816377 Vali Loss: 0.0790040 Test Loss: 0.0839584\n",
      "Validation loss decreased (0.079269 --> 0.079004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839265\n",
      "\tspeed: 0.0395s/iter; left time: 22.6435s\n",
      "\titers: 200, epoch: 18 | loss: 0.0808156\n",
      "\tspeed: 0.0201s/iter; left time: 9.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0816533 Vali Loss: 0.0791150 Test Loss: 0.0840862\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775932\n",
      "\tspeed: 0.0376s/iter; left time: 13.1317s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793722\n",
      "\tspeed: 0.0183s/iter; left time: 4.5534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0812165 Vali Loss: 0.0791734 Test Loss: 0.0845648\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0766307\n",
      "\tspeed: 0.0351s/iter; left time: 4.3879s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812289\n",
      "\tspeed: 0.0174s/iter; left time: 0.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0810414 Vali Loss: 0.0784436 Test Loss: 0.0837516\n",
      "Validation loss decreased (0.079004 --> 0.078444).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018444322049617767, rmse:0.13580986857414246, mae:0.0837516337633133, rse:0.5135117769241333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2798630\n",
      "\tspeed: 0.0234s/iter; left time: 102.6526s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552814\n",
      "\tspeed: 0.0163s/iter; left time: 69.7467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.2785395 Vali Loss: 0.1956593 Test Loss: 0.2025459\n",
      "Validation loss decreased (inf --> 0.195659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1523195\n",
      "\tspeed: 0.0408s/iter; left time: 169.6055s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261142\n",
      "\tspeed: 0.0180s/iter; left time: 73.2253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.1576536 Vali Loss: 0.1078425 Test Loss: 0.1150946\n",
      "Validation loss decreased (0.195659 --> 0.107843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147000\n",
      "\tspeed: 0.0354s/iter; left time: 139.3425s\n",
      "\titers: 200, epoch: 3 | loss: 0.1113540\n",
      "\tspeed: 0.0170s/iter; left time: 65.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1117495 Vali Loss: 0.0957548 Test Loss: 0.1001511\n",
      "Validation loss decreased (0.107843 --> 0.095755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995651\n",
      "\tspeed: 0.0370s/iter; left time: 137.3680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954478\n",
      "\tspeed: 0.0182s/iter; left time: 65.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1004729 Vali Loss: 0.0901986 Test Loss: 0.0926676\n",
      "Validation loss decreased (0.095755 --> 0.090199).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0969215\n",
      "\tspeed: 0.0386s/iter; left time: 134.3633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928631\n",
      "\tspeed: 0.0206s/iter; left time: 69.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0938142 Vali Loss: 0.0860796 Test Loss: 0.0895533\n",
      "Validation loss decreased (0.090199 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0870151\n",
      "\tspeed: 0.0284s/iter; left time: 92.4786s\n",
      "\titers: 200, epoch: 6 | loss: 0.0875229\n",
      "\tspeed: 0.0178s/iter; left time: 56.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0905203 Vali Loss: 0.0847814 Test Loss: 0.0879801\n",
      "Validation loss decreased (0.086080 --> 0.084781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876240\n",
      "\tspeed: 0.0377s/iter; left time: 114.5815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0924451\n",
      "\tspeed: 0.0169s/iter; left time: 49.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0881872 Vali Loss: 0.0827412 Test Loss: 0.0871473\n",
      "Validation loss decreased (0.084781 --> 0.082741).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911712\n",
      "\tspeed: 0.0358s/iter; left time: 100.6126s\n",
      "\titers: 200, epoch: 8 | loss: 0.0860737\n",
      "\tspeed: 0.0178s/iter; left time: 48.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0866387 Vali Loss: 0.0817173 Test Loss: 0.0861746\n",
      "Validation loss decreased (0.082741 --> 0.081717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867940\n",
      "\tspeed: 0.0341s/iter; left time: 88.3317s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838338\n",
      "\tspeed: 0.0168s/iter; left time: 41.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0853725 Vali Loss: 0.0804546 Test Loss: 0.0854482\n",
      "Validation loss decreased (0.081717 --> 0.080455).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0817206\n",
      "\tspeed: 0.0364s/iter; left time: 86.0294s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812260\n",
      "\tspeed: 0.0173s/iter; left time: 39.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0844308 Vali Loss: 0.0804576 Test Loss: 0.0854035\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823050\n",
      "\tspeed: 0.0364s/iter; left time: 78.0030s\n",
      "\titers: 200, epoch: 11 | loss: 0.0891172\n",
      "\tspeed: 0.0171s/iter; left time: 34.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0839546 Vali Loss: 0.0798848 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080455 --> 0.079885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836017\n",
      "\tspeed: 0.0359s/iter; left time: 68.8174s\n",
      "\titers: 200, epoch: 12 | loss: 0.0801083\n",
      "\tspeed: 0.0192s/iter; left time: 34.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0831784 Vali Loss: 0.0796328 Test Loss: 0.0854974\n",
      "Validation loss decreased (0.079885 --> 0.079633).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847356\n",
      "\tspeed: 0.0380s/iter; left time: 64.3992s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833554\n",
      "\tspeed: 0.0169s/iter; left time: 26.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0827545 Vali Loss: 0.0793973 Test Loss: 0.0847967\n",
      "Validation loss decreased (0.079633 --> 0.079397).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791785\n",
      "\tspeed: 0.0349s/iter; left time: 51.2328s\n",
      "\titers: 200, epoch: 14 | loss: 0.0865727\n",
      "\tspeed: 0.0176s/iter; left time: 24.0852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0823615 Vali Loss: 0.0789985 Test Loss: 0.0845724\n",
      "Validation loss decreased (0.079397 --> 0.078999).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0853503\n",
      "\tspeed: 0.0366s/iter; left time: 45.5915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0792778\n",
      "\tspeed: 0.0173s/iter; left time: 19.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0819889 Vali Loss: 0.0791902 Test Loss: 0.0849499\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0856560\n",
      "\tspeed: 0.0403s/iter; left time: 41.1114s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827346\n",
      "\tspeed: 0.0204s/iter; left time: 18.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0816865 Vali Loss: 0.0787904 Test Loss: 0.0842490\n",
      "Validation loss decreased (0.078999 --> 0.078790).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848473\n",
      "\tspeed: 0.0388s/iter; left time: 30.8988s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770277\n",
      "\tspeed: 0.0202s/iter; left time: 14.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0814561 Vali Loss: 0.0784145 Test Loss: 0.0843971\n",
      "Validation loss decreased (0.078790 --> 0.078414).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760338\n",
      "\tspeed: 0.0386s/iter; left time: 22.1347s\n",
      "\titers: 200, epoch: 18 | loss: 0.0781984\n",
      "\tspeed: 0.0184s/iter; left time: 8.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0810920 Vali Loss: 0.0786268 Test Loss: 0.0844016\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800134\n",
      "\tspeed: 0.0384s/iter; left time: 13.4095s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767878\n",
      "\tspeed: 0.0195s/iter; left time: 4.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0810874 Vali Loss: 0.0781209 Test Loss: 0.0842462\n",
      "Validation loss decreased (0.078414 --> 0.078121).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0753115\n",
      "\tspeed: 0.0365s/iter; left time: 4.5596s\n",
      "\titers: 200, epoch: 20 | loss: 0.0850095\n",
      "\tspeed: 0.0186s/iter; left time: 0.4641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0807790 Vali Loss: 0.0781104 Test Loss: 0.0839733\n",
      "Validation loss decreased (0.078121 --> 0.078110).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018509913235902786, rmse:0.13605114817619324, mae:0.08397328108549118, rse:0.5144240260124207\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:48.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2806670\n",
      "\tspeed: 0.0419s/iter; left time: 182.6315s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536687\n",
      "\tspeed: 0.0170s/iter; left time: 72.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.2809382 Vali Loss: 0.2007670 Test Loss: 0.2071321\n",
      "Validation loss decreased (inf --> 0.200767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1456783\n",
      "\tspeed: 0.0368s/iter; left time: 152.4655s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235611\n",
      "\tspeed: 0.0183s/iter; left time: 73.7435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.1555662 Vali Loss: 0.1090099 Test Loss: 0.1161211\n",
      "Validation loss decreased (0.200767 --> 0.109010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146813\n",
      "\tspeed: 0.0418s/iter; left time: 163.6557s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096148\n",
      "\tspeed: 0.0187s/iter; left time: 71.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1136691 Vali Loss: 0.0990993 Test Loss: 0.1021370\n",
      "Validation loss decreased (0.109010 --> 0.099099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1061195\n",
      "\tspeed: 0.0369s/iter; left time: 136.1239s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028804\n",
      "\tspeed: 0.0183s/iter; left time: 65.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1029431 Vali Loss: 0.0935908 Test Loss: 0.0958491\n",
      "Validation loss decreased (0.099099 --> 0.093591).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986858\n",
      "\tspeed: 0.0386s/iter; left time: 133.8685s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012404\n",
      "\tspeed: 0.0191s/iter; left time: 64.5082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0969436 Vali Loss: 0.0903867 Test Loss: 0.0929090\n",
      "Validation loss decreased (0.093591 --> 0.090387).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0951721\n",
      "\tspeed: 0.0382s/iter; left time: 123.8349s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931958\n",
      "\tspeed: 0.0161s/iter; left time: 50.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0941113 Vali Loss: 0.0882187 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.090387 --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919470\n",
      "\tspeed: 0.0422s/iter; left time: 127.5245s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882975\n",
      "\tspeed: 0.0225s/iter; left time: 65.6778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0915717 Vali Loss: 0.0868411 Test Loss: 0.0904239\n",
      "Validation loss decreased (0.088219 --> 0.086841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931816\n",
      "\tspeed: 0.0380s/iter; left time: 106.3493s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920436\n",
      "\tspeed: 0.0168s/iter; left time: 45.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0904402 Vali Loss: 0.0861517 Test Loss: 0.0897113\n",
      "Validation loss decreased (0.086841 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0897104\n",
      "\tspeed: 0.0355s/iter; left time: 91.5564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0893104\n",
      "\tspeed: 0.0181s/iter; left time: 44.7516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0891757 Vali Loss: 0.0858148 Test Loss: 0.0905518\n",
      "Validation loss decreased (0.086152 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0859979\n",
      "\tspeed: 0.0381s/iter; left time: 89.7250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0946045\n",
      "\tspeed: 0.0176s/iter; left time: 39.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0883377 Vali Loss: 0.0847727 Test Loss: 0.0895214\n",
      "Validation loss decreased (0.085815 --> 0.084773).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891667\n",
      "\tspeed: 0.0398s/iter; left time: 84.7522s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880123\n",
      "\tspeed: 0.0197s/iter; left time: 40.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0874938 Vali Loss: 0.0841198 Test Loss: 0.0892585\n",
      "Validation loss decreased (0.084773 --> 0.084120).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883936\n",
      "\tspeed: 0.0395s/iter; left time: 75.3079s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843179\n",
      "\tspeed: 0.0194s/iter; left time: 35.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0868613 Vali Loss: 0.0843133 Test Loss: 0.0890422\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877362\n",
      "\tspeed: 0.0363s/iter; left time: 61.1904s\n",
      "\titers: 200, epoch: 13 | loss: 0.0853775\n",
      "\tspeed: 0.0177s/iter; left time: 28.1020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0864612 Vali Loss: 0.0844159 Test Loss: 0.0896111\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878787\n",
      "\tspeed: 0.0387s/iter; left time: 56.5955s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860630\n",
      "\tspeed: 0.0200s/iter; left time: 27.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0861412 Vali Loss: 0.0840332 Test Loss: 0.0888304\n",
      "Validation loss decreased (0.084120 --> 0.084033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0870090\n",
      "\tspeed: 0.0397s/iter; left time: 49.2184s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814019\n",
      "\tspeed: 0.0201s/iter; left time: 22.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0857522 Vali Loss: 0.0836039 Test Loss: 0.0888983\n",
      "Validation loss decreased (0.084033 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891866\n",
      "\tspeed: 0.0391s/iter; left time: 39.7543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0816880\n",
      "\tspeed: 0.0187s/iter; left time: 17.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0854146 Vali Loss: 0.0835101 Test Loss: 0.0891035\n",
      "Validation loss decreased (0.083604 --> 0.083510).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0854014\n",
      "\tspeed: 0.0375s/iter; left time: 29.7350s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870032\n",
      "\tspeed: 0.0188s/iter; left time: 13.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0852643 Vali Loss: 0.0841342 Test Loss: 0.0901400\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833913\n",
      "\tspeed: 0.0376s/iter; left time: 21.4124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842014\n",
      "\tspeed: 0.0194s/iter; left time: 9.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0848912 Vali Loss: 0.0829792 Test Loss: 0.0887053\n",
      "Validation loss decreased (0.083510 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869769\n",
      "\tspeed: 0.0394s/iter; left time: 13.6689s\n",
      "\titers: 200, epoch: 19 | loss: 0.0855556\n",
      "\tspeed: 0.0199s/iter; left time: 4.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0848935 Vali Loss: 0.0831412 Test Loss: 0.0886999\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856051\n",
      "\tspeed: 0.0386s/iter; left time: 4.7844s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830579\n",
      "\tspeed: 0.0194s/iter; left time: 0.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0846303 Vali Loss: 0.0840227 Test Loss: 0.0897492\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020099075511097908, rmse:0.14177121222019196, mae:0.08870533108711243, rse:0.5365503430366516\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2813044\n",
      "\tspeed: 0.0229s/iter; left time: 99.9398s\n",
      "\titers: 200, epoch: 1 | loss: 0.2537842\n",
      "\tspeed: 0.0202s/iter; left time: 85.9223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.2827695 Vali Loss: 0.1986171 Test Loss: 0.2049647\n",
      "Validation loss decreased (inf --> 0.198617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426644\n",
      "\tspeed: 0.0405s/iter; left time: 167.7063s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291617\n",
      "\tspeed: 0.0202s/iter; left time: 81.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1570104 Vali Loss: 0.1081954 Test Loss: 0.1133942\n",
      "Validation loss decreased (0.198617 --> 0.108195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168254\n",
      "\tspeed: 0.0404s/iter; left time: 158.3028s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129910\n",
      "\tspeed: 0.0199s/iter; left time: 75.8324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1136678 Vali Loss: 0.0983627 Test Loss: 0.1008437\n",
      "Validation loss decreased (0.108195 --> 0.098363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040641\n",
      "\tspeed: 0.0435s/iter; left time: 160.6158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984779\n",
      "\tspeed: 0.0178s/iter; left time: 63.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1031041 Vali Loss: 0.0935392 Test Loss: 0.0961893\n",
      "Validation loss decreased (0.098363 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0936531\n",
      "\tspeed: 0.0389s/iter; left time: 135.0783s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950231\n",
      "\tspeed: 0.0201s/iter; left time: 67.7309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0967202 Vali Loss: 0.0893786 Test Loss: 0.0926177\n",
      "Validation loss decreased (0.093539 --> 0.089379).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0924721\n",
      "\tspeed: 0.0402s/iter; left time: 130.4695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0913443\n",
      "\tspeed: 0.0209s/iter; left time: 65.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0941212 Vali Loss: 0.0876763 Test Loss: 0.0913170\n",
      "Validation loss decreased (0.089379 --> 0.087676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0951016\n",
      "\tspeed: 0.0399s/iter; left time: 120.5680s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915995\n",
      "\tspeed: 0.0198s/iter; left time: 57.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0915591 Vali Loss: 0.0875427 Test Loss: 0.0913138\n",
      "Validation loss decreased (0.087676 --> 0.087543).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0927571\n",
      "\tspeed: 0.0410s/iter; left time: 114.6984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0894333\n",
      "\tspeed: 0.0198s/iter; left time: 53.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0900401 Vali Loss: 0.0854019 Test Loss: 0.0900058\n",
      "Validation loss decreased (0.087543 --> 0.085402).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0886705\n",
      "\tspeed: 0.0409s/iter; left time: 105.4171s\n",
      "\titers: 200, epoch: 9 | loss: 0.0879912\n",
      "\tspeed: 0.0203s/iter; left time: 50.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0889541 Vali Loss: 0.0849612 Test Loss: 0.0891515\n",
      "Validation loss decreased (0.085402 --> 0.084961).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0877168\n",
      "\tspeed: 0.0404s/iter; left time: 95.0838s\n",
      "\titers: 200, epoch: 10 | loss: 0.0875674\n",
      "\tspeed: 0.0205s/iter; left time: 46.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0881908 Vali Loss: 0.0846811 Test Loss: 0.0888525\n",
      "Validation loss decreased (0.084961 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0898153\n",
      "\tspeed: 0.0399s/iter; left time: 85.0774s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906977\n",
      "\tspeed: 0.0192s/iter; left time: 39.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0876222 Vali Loss: 0.0841912 Test Loss: 0.0885119\n",
      "Validation loss decreased (0.084681 --> 0.084191).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0854267\n",
      "\tspeed: 0.0400s/iter; left time: 76.3177s\n",
      "\titers: 200, epoch: 12 | loss: 0.0921324\n",
      "\tspeed: 0.0194s/iter; left time: 35.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0870224 Vali Loss: 0.0838905 Test Loss: 0.0882123\n",
      "Validation loss decreased (0.084191 --> 0.083890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908491\n",
      "\tspeed: 0.0402s/iter; left time: 67.7130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0868078\n",
      "\tspeed: 0.0194s/iter; left time: 30.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0865049 Vali Loss: 0.0839069 Test Loss: 0.0883935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0854094\n",
      "\tspeed: 0.0398s/iter; left time: 58.2553s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844667\n",
      "\tspeed: 0.0197s/iter; left time: 26.7745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0861975 Vali Loss: 0.0840705 Test Loss: 0.0888260\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889031\n",
      "\tspeed: 0.0397s/iter; left time: 49.1403s\n",
      "\titers: 200, epoch: 15 | loss: 0.0843957\n",
      "\tspeed: 0.0202s/iter; left time: 23.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0855418 Vali Loss: 0.0836140 Test Loss: 0.0885775\n",
      "Validation loss decreased (0.083890 --> 0.083614).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0875921\n",
      "\tspeed: 0.0408s/iter; left time: 41.4238s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831733\n",
      "\tspeed: 0.0207s/iter; left time: 18.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0853479 Vali Loss: 0.0839115 Test Loss: 0.0888283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0873199\n",
      "\tspeed: 0.0402s/iter; left time: 31.8651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0876978\n",
      "\tspeed: 0.0189s/iter; left time: 13.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0852551 Vali Loss: 0.0832509 Test Loss: 0.0884188\n",
      "Validation loss decreased (0.083614 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0823902\n",
      "\tspeed: 0.0398s/iter; left time: 22.6634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818335\n",
      "\tspeed: 0.0207s/iter; left time: 9.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0849353 Vali Loss: 0.0838093 Test Loss: 0.0887195\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851609\n",
      "\tspeed: 0.0322s/iter; left time: 11.1699s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858866\n",
      "\tspeed: 0.0101s/iter; left time: 2.5044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 223 | Train Loss: 0.0846712 Vali Loss: 0.0832612 Test Loss: 0.0881233\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0836230\n",
      "\tspeed: 0.0398s/iter; left time: 4.9385s\n",
      "\titers: 200, epoch: 20 | loss: 0.0846320\n",
      "\tspeed: 0.0215s/iter; left time: 0.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0845549 Vali Loss: 0.0833086 Test Loss: 0.0881949\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019747594371438026, rmse:0.14052613079547882, mae:0.0884188562631607, rse:0.5318382382392883\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:05.17s\n",
      "Intermediate time for IT: 00h:11m:36.77s\n",
      "Total time: 00h:58m:25.34s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1657</td>\n",
       "      <td>0.1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0217  0.1473  0.0911\n",
       "        96             0.0401  0.2002  0.1317\n",
       "        168            0.0432  0.2077  0.1391\n",
       "ES      24             0.0168  0.1281  0.0760\n",
       "        96             0.0263  0.1609  0.1041\n",
       "        168            0.0266  0.1624  0.1084\n",
       "FR      24             0.0108  0.1041  0.0597\n",
       "        96             0.0203  0.1423  0.0836\n",
       "        168            0.0230  0.1516  0.0899\n",
       "GB      24             0.0275  0.1657  0.1054\n",
       "        96             0.0497  0.2226  0.1490\n",
       "        168            0.0518  0.2274  0.1545\n",
       "IT      24             0.0108  0.1039  0.0611\n",
       "        96             0.0185  0.1360  0.0829\n",
       "        168            0.0202  0.1421  0.0882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1567678\n",
      "\tspeed: 0.0526s/iter; left time: 230.4653s\n",
      "\titers: 200, epoch: 1 | loss: 0.1433145\n",
      "\tspeed: 0.0295s/iter; left time: 126.2014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.1576000 Vali Loss: 0.1551504 Test Loss: 0.1667591\n",
      "Validation loss decreased (inf --> 0.155150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031226\n",
      "\tspeed: 0.0561s/iter; left time: 233.3046s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875558\n",
      "\tspeed: 0.0295s/iter; left time: 119.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1013773 Vali Loss: 0.0982898 Test Loss: 0.0989775\n",
      "Validation loss decreased (0.155150 --> 0.098290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0797586\n",
      "\tspeed: 0.0566s/iter; left time: 222.5262s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794722\n",
      "\tspeed: 0.0308s/iter; left time: 118.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0823492 Vali Loss: 0.0925360 Test Loss: 0.0942594\n",
      "Validation loss decreased (0.098290 --> 0.092536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760267\n",
      "\tspeed: 0.0572s/iter; left time: 212.2079s\n",
      "\titers: 200, epoch: 4 | loss: 0.0783228\n",
      "\tspeed: 0.0291s/iter; left time: 105.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0784050 Vali Loss: 0.0904746 Test Loss: 0.0920334\n",
      "Validation loss decreased (0.092536 --> 0.090475).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0719172\n",
      "\tspeed: 0.0570s/iter; left time: 198.6682s\n",
      "\titers: 200, epoch: 5 | loss: 0.0714680\n",
      "\tspeed: 0.0291s/iter; left time: 98.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0762039 Vali Loss: 0.0893666 Test Loss: 0.0909590\n",
      "Validation loss decreased (0.090475 --> 0.089367).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0756994\n",
      "\tspeed: 0.0592s/iter; left time: 192.9706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0780923\n",
      "\tspeed: 0.0383s/iter; left time: 121.0480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0748772 Vali Loss: 0.0882359 Test Loss: 0.0903265\n",
      "Validation loss decreased (0.089367 --> 0.088236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0710799\n",
      "\tspeed: 0.0572s/iter; left time: 173.6389s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715732\n",
      "\tspeed: 0.0300s/iter; left time: 88.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0740736 Vali Loss: 0.0880114 Test Loss: 0.0901419\n",
      "Validation loss decreased (0.088236 --> 0.088011).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694230\n",
      "\tspeed: 0.0574s/iter; left time: 161.4618s\n",
      "\titers: 200, epoch: 8 | loss: 0.0746452\n",
      "\tspeed: 0.0295s/iter; left time: 79.9652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0733045 Vali Loss: 0.0874589 Test Loss: 0.0899554\n",
      "Validation loss decreased (0.088011 --> 0.087459).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742549\n",
      "\tspeed: 0.0560s/iter; left time: 145.0346s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728040\n",
      "\tspeed: 0.0300s/iter; left time: 74.6476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0727485 Vali Loss: 0.0871458 Test Loss: 0.0898097\n",
      "Validation loss decreased (0.087459 --> 0.087146).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769949\n",
      "\tspeed: 0.0567s/iter; left time: 134.0706s\n",
      "\titers: 200, epoch: 10 | loss: 0.0757486\n",
      "\tspeed: 0.0292s/iter; left time: 66.0353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0723941 Vali Loss: 0.0869690 Test Loss: 0.0893965\n",
      "Validation loss decreased (0.087146 --> 0.086969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0711140\n",
      "\tspeed: 0.0572s/iter; left time: 122.4488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0674053\n",
      "\tspeed: 0.0300s/iter; left time: 61.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.0719007 Vali Loss: 0.0871842 Test Loss: 0.0897539\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0718379\n",
      "\tspeed: 0.0604s/iter; left time: 115.7306s\n",
      "\titers: 200, epoch: 12 | loss: 0.0715494\n",
      "\tspeed: 0.0315s/iter; left time: 57.2251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0716341 Vali Loss: 0.0869635 Test Loss: 0.0896744\n",
      "Validation loss decreased (0.086969 --> 0.086963).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637034\n",
      "\tspeed: 0.0558s/iter; left time: 94.4345s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712081\n",
      "\tspeed: 0.0289s/iter; left time: 46.0194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0713736 Vali Loss: 0.0869584 Test Loss: 0.0896179\n",
      "Validation loss decreased (0.086963 --> 0.086958).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0750033\n",
      "\tspeed: 0.0548s/iter; left time: 80.5025s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712781\n",
      "\tspeed: 0.0292s/iter; left time: 39.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0711929 Vali Loss: 0.0867721 Test Loss: 0.0895204\n",
      "Validation loss decreased (0.086958 --> 0.086772).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734930\n",
      "\tspeed: 0.0556s/iter; left time: 69.2534s\n",
      "\titers: 200, epoch: 15 | loss: 0.0692435\n",
      "\tspeed: 0.0294s/iter; left time: 33.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0709822 Vali Loss: 0.0867286 Test Loss: 0.0896428\n",
      "Validation loss decreased (0.086772 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0722989\n",
      "\tspeed: 0.0554s/iter; left time: 56.6061s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687896\n",
      "\tspeed: 0.0291s/iter; left time: 26.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0707381 Vali Loss: 0.0868145 Test Loss: 0.0894336\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0716818\n",
      "\tspeed: 0.0561s/iter; left time: 44.7074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0709396\n",
      "\tspeed: 0.0301s/iter; left time: 20.9981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0706003 Vali Loss: 0.0866975 Test Loss: 0.0896750\n",
      "Validation loss decreased (0.086729 --> 0.086697).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0790525\n",
      "\tspeed: 0.0599s/iter; left time: 34.3310s\n",
      "\titers: 200, epoch: 18 | loss: 0.0712589\n",
      "\tspeed: 0.0296s/iter; left time: 14.0126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0704566 Vali Loss: 0.0867676 Test Loss: 0.0897200\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0673314\n",
      "\tspeed: 0.0550s/iter; left time: 19.2075s\n",
      "\titers: 200, epoch: 19 | loss: 0.0730108\n",
      "\tspeed: 0.0301s/iter; left time: 7.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0703885 Vali Loss: 0.0866267 Test Loss: 0.0896360\n",
      "Validation loss decreased (0.086697 --> 0.086627).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0742142\n",
      "\tspeed: 0.0576s/iter; left time: 7.1990s\n",
      "\titers: 200, epoch: 20 | loss: 0.0673859\n",
      "\tspeed: 0.0292s/iter; left time: 0.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0702162 Vali Loss: 0.0865770 Test Loss: 0.0894810\n",
      "Validation loss decreased (0.086627 --> 0.086577).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021502211689949036, rmse:0.14663632214069366, mae:0.08948095887899399, rse:0.5174998641014099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1495929\n",
      "\tspeed: 0.0313s/iter; left time: 137.2827s\n",
      "\titers: 200, epoch: 1 | loss: 0.1463803\n",
      "\tspeed: 0.0290s/iter; left time: 124.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1526839 Vali Loss: 0.1514840 Test Loss: 0.1624655\n",
      "Validation loss decreased (inf --> 0.151484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1021311\n",
      "\tspeed: 0.0566s/iter; left time: 235.3639s\n",
      "\titers: 200, epoch: 2 | loss: 0.0848635\n",
      "\tspeed: 0.0304s/iter; left time: 123.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.1027181 Vali Loss: 0.1005402 Test Loss: 0.1007976\n",
      "Validation loss decreased (0.151484 --> 0.100540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795188\n",
      "\tspeed: 0.0582s/iter; left time: 229.0344s\n",
      "\titers: 200, epoch: 3 | loss: 0.0751623\n",
      "\tspeed: 0.0298s/iter; left time: 114.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0833608 Vali Loss: 0.0931789 Test Loss: 0.0944922\n",
      "Validation loss decreased (0.100540 --> 0.093179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771583\n",
      "\tspeed: 0.0577s/iter; left time: 213.9901s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792882\n",
      "\tspeed: 0.0319s/iter; left time: 114.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0788445 Vali Loss: 0.0906632 Test Loss: 0.0922750\n",
      "Validation loss decreased (0.093179 --> 0.090663).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749987\n",
      "\tspeed: 0.0590s/iter; left time: 205.4676s\n",
      "\titers: 200, epoch: 5 | loss: 0.0770526\n",
      "\tspeed: 0.0295s/iter; left time: 99.8559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0765704 Vali Loss: 0.0890175 Test Loss: 0.0910768\n",
      "Validation loss decreased (0.090663 --> 0.089018).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711239\n",
      "\tspeed: 0.0579s/iter; left time: 188.8633s\n",
      "\titers: 200, epoch: 6 | loss: 0.0737886\n",
      "\tspeed: 0.0296s/iter; left time: 93.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0751682 Vali Loss: 0.0882793 Test Loss: 0.0906633\n",
      "Validation loss decreased (0.089018 --> 0.088279).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0720635\n",
      "\tspeed: 0.0572s/iter; left time: 173.7315s\n",
      "\titers: 200, epoch: 7 | loss: 0.0716138\n",
      "\tspeed: 0.0291s/iter; left time: 85.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0741472 Vali Loss: 0.0878513 Test Loss: 0.0899362\n",
      "Validation loss decreased (0.088279 --> 0.087851).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0790010\n",
      "\tspeed: 0.0569s/iter; left time: 160.1218s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732888\n",
      "\tspeed: 0.0290s/iter; left time: 78.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0734326 Vali Loss: 0.0876877 Test Loss: 0.0901576\n",
      "Validation loss decreased (0.087851 --> 0.087688).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745864\n",
      "\tspeed: 0.0559s/iter; left time: 144.8465s\n",
      "\titers: 200, epoch: 9 | loss: 0.0714607\n",
      "\tspeed: 0.0290s/iter; left time: 72.0725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0728461 Vali Loss: 0.0876252 Test Loss: 0.0900793\n",
      "Validation loss decreased (0.087688 --> 0.087625).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710246\n",
      "\tspeed: 0.0567s/iter; left time: 134.1321s\n",
      "\titers: 200, epoch: 10 | loss: 0.0737277\n",
      "\tspeed: 0.0301s/iter; left time: 68.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0724467 Vali Loss: 0.0874645 Test Loss: 0.0899862\n",
      "Validation loss decreased (0.087625 --> 0.087465).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0824003\n",
      "\tspeed: 0.0560s/iter; left time: 119.9479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0767711\n",
      "\tspeed: 0.0289s/iter; left time: 58.9626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0721063 Vali Loss: 0.0873299 Test Loss: 0.0897865\n",
      "Validation loss decreased (0.087465 --> 0.087330).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0684023\n",
      "\tspeed: 0.0561s/iter; left time: 107.5268s\n",
      "\titers: 200, epoch: 12 | loss: 0.0673439\n",
      "\tspeed: 0.0298s/iter; left time: 54.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0716876 Vali Loss: 0.0869440 Test Loss: 0.0897215\n",
      "Validation loss decreased (0.087330 --> 0.086944).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0723820\n",
      "\tspeed: 0.0572s/iter; left time: 96.7987s\n",
      "\titers: 200, epoch: 13 | loss: 0.0820618\n",
      "\tspeed: 0.0293s/iter; left time: 46.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0714127 Vali Loss: 0.0869791 Test Loss: 0.0897072\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0728505\n",
      "\tspeed: 0.0564s/iter; left time: 82.8270s\n",
      "\titers: 200, epoch: 14 | loss: 0.0703271\n",
      "\tspeed: 0.0299s/iter; left time: 40.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0711567 Vali Loss: 0.0867776 Test Loss: 0.0895040\n",
      "Validation loss decreased (0.086944 --> 0.086778).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0760713\n",
      "\tspeed: 0.0558s/iter; left time: 69.5205s\n",
      "\titers: 200, epoch: 15 | loss: 0.0742841\n",
      "\tspeed: 0.0291s/iter; left time: 33.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0710318 Vali Loss: 0.0868737 Test Loss: 0.0898782\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0706063\n",
      "\tspeed: 0.0570s/iter; left time: 58.2470s\n",
      "\titers: 200, epoch: 16 | loss: 0.0680393\n",
      "\tspeed: 0.0295s/iter; left time: 27.1706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0708270 Vali Loss: 0.0867780 Test Loss: 0.0894497\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0699022\n",
      "\tspeed: 0.0562s/iter; left time: 44.7841s\n",
      "\titers: 200, epoch: 17 | loss: 0.0742621\n",
      "\tspeed: 0.0291s/iter; left time: 20.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0705761 Vali Loss: 0.0866692 Test Loss: 0.0895365\n",
      "Validation loss decreased (0.086778 --> 0.086669).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760129\n",
      "\tspeed: 0.0584s/iter; left time: 33.4761s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760739\n",
      "\tspeed: 0.0327s/iter; left time: 15.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0704689 Vali Loss: 0.0866643 Test Loss: 0.0895565\n",
      "Validation loss decreased (0.086669 --> 0.086664).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0719868\n",
      "\tspeed: 0.0588s/iter; left time: 20.5357s\n",
      "\titers: 200, epoch: 19 | loss: 0.0686807\n",
      "\tspeed: 0.0290s/iter; left time: 7.2293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0703805 Vali Loss: 0.0865281 Test Loss: 0.0897488\n",
      "Validation loss decreased (0.086664 --> 0.086528).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727066\n",
      "\tspeed: 0.0556s/iter; left time: 6.9445s\n",
      "\titers: 200, epoch: 20 | loss: 0.0750364\n",
      "\tspeed: 0.0293s/iter; left time: 0.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0701832 Vali Loss: 0.0867045 Test Loss: 0.0895885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021511759608983994, rmse:0.14666888117790222, mae:0.08974876254796982, rse:0.5176147222518921\n",
      "Intermediate time for DE and pred_len 24: 00h:05m:57.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1715337\n",
      "\tspeed: 0.0527s/iter; left time: 230.8474s\n",
      "\titers: 200, epoch: 1 | loss: 0.1585579\n",
      "\tspeed: 0.0294s/iter; left time: 126.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.1652060 Vali Loss: 0.1660529 Test Loss: 0.1809062\n",
      "Validation loss decreased (inf --> 0.166053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205626\n",
      "\tspeed: 0.0572s/iter; left time: 237.8563s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186947\n",
      "\tspeed: 0.0294s/iter; left time: 119.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1246657 Vali Loss: 0.1251731 Test Loss: 0.1321551\n",
      "Validation loss decreased (0.166053 --> 0.125173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1044892\n",
      "\tspeed: 0.0580s/iter; left time: 228.1895s\n",
      "\titers: 200, epoch: 3 | loss: 0.1051909\n",
      "\tspeed: 0.0294s/iter; left time: 112.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.1088846 Vali Loss: 0.1206153 Test Loss: 0.1288252\n",
      "Validation loss decreased (0.125173 --> 0.120615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1050393\n",
      "\tspeed: 0.0571s/iter; left time: 211.6377s\n",
      "\titers: 200, epoch: 4 | loss: 0.1002400\n",
      "\tspeed: 0.0295s/iter; left time: 106.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.1050778 Vali Loss: 0.1188297 Test Loss: 0.1277407\n",
      "Validation loss decreased (0.120615 --> 0.118830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1064784\n",
      "\tspeed: 0.0583s/iter; left time: 203.0252s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052308\n",
      "\tspeed: 0.0294s/iter; left time: 99.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1030869 Vali Loss: 0.1183381 Test Loss: 0.1272658\n",
      "Validation loss decreased (0.118830 --> 0.118338).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961202\n",
      "\tspeed: 0.0581s/iter; left time: 189.3808s\n",
      "\titers: 200, epoch: 6 | loss: 0.1015194\n",
      "\tspeed: 0.0297s/iter; left time: 94.0018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1016476 Vali Loss: 0.1183048 Test Loss: 0.1270003\n",
      "Validation loss decreased (0.118338 --> 0.118305).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025156\n",
      "\tspeed: 0.0612s/iter; left time: 185.7932s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025395\n",
      "\tspeed: 0.0312s/iter; left time: 91.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.1005917 Vali Loss: 0.1185534 Test Loss: 0.1271381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1011636\n",
      "\tspeed: 0.0581s/iter; left time: 163.5451s\n",
      "\titers: 200, epoch: 8 | loss: 0.1008992\n",
      "\tspeed: 0.0304s/iter; left time: 82.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0996272 Vali Loss: 0.1187628 Test Loss: 0.1273232\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012495\n",
      "\tspeed: 0.0581s/iter; left time: 150.3892s\n",
      "\titers: 200, epoch: 9 | loss: 0.0997166\n",
      "\tspeed: 0.0303s/iter; left time: 75.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0987985 Vali Loss: 0.1189673 Test Loss: 0.1284143\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0935672\n",
      "\tspeed: 0.0585s/iter; left time: 138.4348s\n",
      "\titers: 200, epoch: 10 | loss: 0.0895828\n",
      "\tspeed: 0.0292s/iter; left time: 66.1003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0979273 Vali Loss: 0.1193244 Test Loss: 0.1281973\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0980667\n",
      "\tspeed: 0.0584s/iter; left time: 125.1255s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946719\n",
      "\tspeed: 0.0293s/iter; left time: 59.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0972261 Vali Loss: 0.1196312 Test Loss: 0.1285315\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03652429208159447, rmse:0.19111329317092896, mae:0.12700024247169495, rse:0.6767708659172058\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1707475\n",
      "\tspeed: 0.0319s/iter; left time: 139.7210s\n",
      "\titers: 200, epoch: 1 | loss: 0.1572355\n",
      "\tspeed: 0.0318s/iter; left time: 136.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1646986 Vali Loss: 0.1664857 Test Loss: 0.1810335\n",
      "Validation loss decreased (inf --> 0.166486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1249209\n",
      "\tspeed: 0.0586s/iter; left time: 243.7430s\n",
      "\titers: 200, epoch: 2 | loss: 0.1092523\n",
      "\tspeed: 0.0316s/iter; left time: 128.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.1259303 Vali Loss: 0.1252617 Test Loss: 0.1327774\n",
      "Validation loss decreased (0.166486 --> 0.125262).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1103554\n",
      "\tspeed: 0.0592s/iter; left time: 232.7197s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098578\n",
      "\tspeed: 0.0299s/iter; left time: 114.5617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.1090203 Vali Loss: 0.1205140 Test Loss: 0.1289042\n",
      "Validation loss decreased (0.125262 --> 0.120514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1024322\n",
      "\tspeed: 0.0589s/iter; left time: 218.4656s\n",
      "\titers: 200, epoch: 4 | loss: 0.0968125\n",
      "\tspeed: 0.0291s/iter; left time: 104.8738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1048213 Vali Loss: 0.1189481 Test Loss: 0.1279226\n",
      "Validation loss decreased (0.120514 --> 0.118948).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023740\n",
      "\tspeed: 0.0591s/iter; left time: 205.8925s\n",
      "\titers: 200, epoch: 5 | loss: 0.1045832\n",
      "\tspeed: 0.0300s/iter; left time: 101.4533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1025675 Vali Loss: 0.1190735 Test Loss: 0.1273407\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1015776\n",
      "\tspeed: 0.0615s/iter; left time: 200.6118s\n",
      "\titers: 200, epoch: 6 | loss: 0.0969167\n",
      "\tspeed: 0.0301s/iter; left time: 95.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.1010989 Vali Loss: 0.1192106 Test Loss: 0.1277003\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1016324\n",
      "\tspeed: 0.0606s/iter; left time: 184.0986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0961842\n",
      "\tspeed: 0.0314s/iter; left time: 92.0903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1000090 Vali Loss: 0.1189345 Test Loss: 0.1278622\n",
      "Validation loss decreased (0.118948 --> 0.118934).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0966568\n",
      "\tspeed: 0.0589s/iter; left time: 165.7244s\n",
      "\titers: 200, epoch: 8 | loss: 0.1004526\n",
      "\tspeed: 0.0299s/iter; left time: 81.1677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0989549 Vali Loss: 0.1192892 Test Loss: 0.1279659\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0971342\n",
      "\tspeed: 0.0583s/iter; left time: 151.0583s\n",
      "\titers: 200, epoch: 9 | loss: 0.1002588\n",
      "\tspeed: 0.0295s/iter; left time: 73.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0980472 Vali Loss: 0.1194566 Test Loss: 0.1285430\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1007213\n",
      "\tspeed: 0.0590s/iter; left time: 139.4621s\n",
      "\titers: 200, epoch: 10 | loss: 0.0992056\n",
      "\tspeed: 0.0296s/iter; left time: 66.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.0972348 Vali Loss: 0.1195670 Test Loss: 0.1284383\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1030212\n",
      "\tspeed: 0.0577s/iter; left time: 123.5502s\n",
      "\titers: 200, epoch: 11 | loss: 0.0922267\n",
      "\tspeed: 0.0299s/iter; left time: 60.9550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0964738 Vali Loss: 0.1196612 Test Loss: 0.1292171\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0946532\n",
      "\tspeed: 0.0590s/iter; left time: 113.0544s\n",
      "\titers: 200, epoch: 12 | loss: 0.0945020\n",
      "\tspeed: 0.0310s/iter; left time: 56.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0958266 Vali Loss: 0.1199754 Test Loss: 0.1294843\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036961257457733154, rmse:0.19225311279296875, mae:0.12786221504211426, rse:0.6808071732521057\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:36.09s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1689817\n",
      "\tspeed: 0.0535s/iter; left time: 233.4927s\n",
      "\titers: 200, epoch: 1 | loss: 0.1642684\n",
      "\tspeed: 0.0298s/iter; left time: 127.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 223 | Train Loss: 0.1665411 Vali Loss: 0.1681140 Test Loss: 0.1834208\n",
      "Validation loss decreased (inf --> 0.168114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1266156\n",
      "\tspeed: 0.0623s/iter; left time: 257.6126s\n",
      "\titers: 200, epoch: 2 | loss: 0.1200108\n",
      "\tspeed: 0.0313s/iter; left time: 126.2210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 223 | Train Loss: 0.1296155 Vali Loss: 0.1291023 Test Loss: 0.1378668\n",
      "Validation loss decreased (0.168114 --> 0.129102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1214094\n",
      "\tspeed: 0.0609s/iter; left time: 238.3725s\n",
      "\titers: 200, epoch: 3 | loss: 0.1149558\n",
      "\tspeed: 0.0303s/iter; left time: 115.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.1144919 Vali Loss: 0.1243992 Test Loss: 0.1346566\n",
      "Validation loss decreased (0.129102 --> 0.124399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1130121\n",
      "\tspeed: 0.0595s/iter; left time: 219.7274s\n",
      "\titers: 200, epoch: 4 | loss: 0.1080625\n",
      "\tspeed: 0.0304s/iter; left time: 109.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1109701 Vali Loss: 0.1235877 Test Loss: 0.1350279\n",
      "Validation loss decreased (0.124399 --> 0.123588).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1092762\n",
      "\tspeed: 0.0597s/iter; left time: 207.0465s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114840\n",
      "\tspeed: 0.0297s/iter; left time: 99.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1091429 Vali Loss: 0.1233613 Test Loss: 0.1347366\n",
      "Validation loss decreased (0.123588 --> 0.123361).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1129082\n",
      "\tspeed: 0.0596s/iter; left time: 193.5171s\n",
      "\titers: 200, epoch: 6 | loss: 0.1027416\n",
      "\tspeed: 0.0309s/iter; left time: 97.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.1077531 Vali Loss: 0.1237961 Test Loss: 0.1352117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056892\n",
      "\tspeed: 0.0598s/iter; left time: 180.7616s\n",
      "\titers: 200, epoch: 7 | loss: 0.1095061\n",
      "\tspeed: 0.0301s/iter; left time: 87.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1066067 Vali Loss: 0.1236090 Test Loss: 0.1354179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0993296\n",
      "\tspeed: 0.0579s/iter; left time: 162.1528s\n",
      "\titers: 200, epoch: 8 | loss: 0.1133994\n",
      "\tspeed: 0.0297s/iter; left time: 80.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1054562 Vali Loss: 0.1237645 Test Loss: 0.1360048\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1035121\n",
      "\tspeed: 0.0590s/iter; left time: 152.0124s\n",
      "\titers: 200, epoch: 9 | loss: 0.0996546\n",
      "\tspeed: 0.0318s/iter; left time: 78.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.1044893 Vali Loss: 0.1240688 Test Loss: 0.1365043\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1052005\n",
      "\tspeed: 0.0591s/iter; left time: 139.0198s\n",
      "\titers: 200, epoch: 10 | loss: 0.1107367\n",
      "\tspeed: 0.0299s/iter; left time: 67.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.1034715 Vali Loss: 0.1245504 Test Loss: 0.1374091\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039026908576488495, rmse:0.19755229353904724, mae:0.13473661243915558, rse:0.6997461318969727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1647042\n",
      "\tspeed: 0.0322s/iter; left time: 140.5425s\n",
      "\titers: 200, epoch: 1 | loss: 0.1576401\n",
      "\tspeed: 0.0298s/iter; left time: 127.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.1669393 Vali Loss: 0.1686858 Test Loss: 0.1837087\n",
      "Validation loss decreased (inf --> 0.168686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1288892\n",
      "\tspeed: 0.0600s/iter; left time: 248.4589s\n",
      "\titers: 200, epoch: 2 | loss: 0.1215590\n",
      "\tspeed: 0.0297s/iter; left time: 120.0702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1297781 Vali Loss: 0.1294112 Test Loss: 0.1387461\n",
      "Validation loss decreased (0.168686 --> 0.129411).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145444\n",
      "\tspeed: 0.0600s/iter; left time: 235.0454s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084206\n",
      "\tspeed: 0.0299s/iter; left time: 113.8906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.1147885 Vali Loss: 0.1250967 Test Loss: 0.1359649\n",
      "Validation loss decreased (0.129411 --> 0.125097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1122477\n",
      "\tspeed: 0.0627s/iter; left time: 231.4991s\n",
      "\titers: 200, epoch: 4 | loss: 0.1090828\n",
      "\tspeed: 0.0302s/iter; left time: 108.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.1109871 Vali Loss: 0.1237649 Test Loss: 0.1352141\n",
      "Validation loss decreased (0.125097 --> 0.123765).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1040569\n",
      "\tspeed: 0.0619s/iter; left time: 214.7305s\n",
      "\titers: 200, epoch: 5 | loss: 0.1037638\n",
      "\tspeed: 0.0307s/iter; left time: 103.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.1088394 Vali Loss: 0.1239514 Test Loss: 0.1354574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1014345\n",
      "\tspeed: 0.0607s/iter; left time: 197.1594s\n",
      "\titers: 200, epoch: 6 | loss: 0.1059505\n",
      "\tspeed: 0.0302s/iter; left time: 95.0764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 223 | Train Loss: 0.1072900 Vali Loss: 0.1241839 Test Loss: 0.1355870\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1154614\n",
      "\tspeed: 0.0601s/iter; left time: 181.6841s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025606\n",
      "\tspeed: 0.0300s/iter; left time: 87.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 223 | Train Loss: 0.1059765 Vali Loss: 0.1244203 Test Loss: 0.1356905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1050515\n",
      "\tspeed: 0.0614s/iter; left time: 172.0208s\n",
      "\titers: 200, epoch: 8 | loss: 0.1034834\n",
      "\tspeed: 0.0302s/iter; left time: 81.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 223 | Train Loss: 0.1048230 Vali Loss: 0.1244611 Test Loss: 0.1359269\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1014910\n",
      "\tspeed: 0.0611s/iter; left time: 157.5654s\n",
      "\titers: 200, epoch: 9 | loss: 0.1047624\n",
      "\tspeed: 0.0300s/iter; left time: 74.4332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 223 | Train Loss: 0.1036161 Vali Loss: 0.1247070 Test Loss: 0.1366667\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03935402259230614, rmse:0.19837848842144012, mae:0.1352141946554184, rse:0.70267254114151\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:04.34s\n",
      "Intermediate time for DE: 00h:12m:38.35s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1416442\n",
      "\tspeed: 0.0530s/iter; left time: 232.3901s\n",
      "\titers: 200, epoch: 1 | loss: 0.1359674\n",
      "\tspeed: 0.0292s/iter; left time: 125.0933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.1428490 Vali Loss: 0.1416124 Test Loss: 0.1641944\n",
      "Validation loss decreased (inf --> 0.141612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982989\n",
      "\tspeed: 0.0607s/iter; left time: 252.3749s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841241\n",
      "\tspeed: 0.0287s/iter; left time: 116.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0967408 Vali Loss: 0.0950226 Test Loss: 0.1060177\n",
      "Validation loss decreased (0.141612 --> 0.095023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0755521\n",
      "\tspeed: 0.0569s/iter; left time: 223.9049s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794114\n",
      "\tspeed: 0.0295s/iter; left time: 113.1279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0807715 Vali Loss: 0.0917419 Test Loss: 0.1033771\n",
      "Validation loss decreased (0.095023 --> 0.091742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820476\n",
      "\tspeed: 0.0576s/iter; left time: 213.8150s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825884\n",
      "\tspeed: 0.0303s/iter; left time: 109.1732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0781855 Vali Loss: 0.0911295 Test Loss: 0.1026525\n",
      "Validation loss decreased (0.091742 --> 0.091129).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0787778\n",
      "\tspeed: 0.0602s/iter; left time: 209.6792s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802914\n",
      "\tspeed: 0.0309s/iter; left time: 104.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.0769637 Vali Loss: 0.0900058 Test Loss: 0.1023378\n",
      "Validation loss decreased (0.091129 --> 0.090006).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0744972\n",
      "\tspeed: 0.0574s/iter; left time: 187.2892s\n",
      "\titers: 200, epoch: 6 | loss: 0.0772638\n",
      "\tspeed: 0.0293s/iter; left time: 92.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0760804 Vali Loss: 0.0900013 Test Loss: 0.1019079\n",
      "Validation loss decreased (0.090006 --> 0.090001).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0762442\n",
      "\tspeed: 0.0568s/iter; left time: 172.5659s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727803\n",
      "\tspeed: 0.0291s/iter; left time: 85.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0754529 Vali Loss: 0.0896282 Test Loss: 0.1022905\n",
      "Validation loss decreased (0.090001 --> 0.089628).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801298\n",
      "\tspeed: 0.0596s/iter; left time: 167.7904s\n",
      "\titers: 200, epoch: 8 | loss: 0.0791657\n",
      "\tspeed: 0.0316s/iter; left time: 85.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0749296 Vali Loss: 0.0892004 Test Loss: 0.1020514\n",
      "Validation loss decreased (0.089628 --> 0.089200).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734463\n",
      "\tspeed: 0.0622s/iter; left time: 160.9160s\n",
      "\titers: 200, epoch: 9 | loss: 0.0723017\n",
      "\tspeed: 0.0304s/iter; left time: 75.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.0745067 Vali Loss: 0.0891742 Test Loss: 0.1021916\n",
      "Validation loss decreased (0.089200 --> 0.089174).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0807116\n",
      "\tspeed: 0.0582s/iter; left time: 137.5747s\n",
      "\titers: 200, epoch: 10 | loss: 0.0744405\n",
      "\tspeed: 0.0299s/iter; left time: 67.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.0741352 Vali Loss: 0.0890640 Test Loss: 0.1017153\n",
      "Validation loss decreased (0.089174 --> 0.089064).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733814\n",
      "\tspeed: 0.0587s/iter; left time: 125.7721s\n",
      "\titers: 200, epoch: 11 | loss: 0.0779751\n",
      "\tspeed: 0.0293s/iter; left time: 59.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0738129 Vali Loss: 0.0889336 Test Loss: 0.1020456\n",
      "Validation loss decreased (0.089064 --> 0.088934).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787763\n",
      "\tspeed: 0.0584s/iter; left time: 111.9926s\n",
      "\titers: 200, epoch: 12 | loss: 0.0728098\n",
      "\tspeed: 0.0290s/iter; left time: 52.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0735505 Vali Loss: 0.0888196 Test Loss: 0.1024022\n",
      "Validation loss decreased (0.088934 --> 0.088820).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0715337\n",
      "\tspeed: 0.0578s/iter; left time: 97.9230s\n",
      "\titers: 200, epoch: 13 | loss: 0.0715669\n",
      "\tspeed: 0.0335s/iter; left time: 53.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0733221 Vali Loss: 0.0886738 Test Loss: 0.1021919\n",
      "Validation loss decreased (0.088820 --> 0.088674).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712817\n",
      "\tspeed: 0.0585s/iter; left time: 85.9060s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718854\n",
      "\tspeed: 0.0302s/iter; left time: 41.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0731035 Vali Loss: 0.0889941 Test Loss: 0.1024620\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0701052\n",
      "\tspeed: 0.0572s/iter; left time: 71.2236s\n",
      "\titers: 200, epoch: 15 | loss: 0.0703838\n",
      "\tspeed: 0.0294s/iter; left time: 33.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0728872 Vali Loss: 0.0887056 Test Loss: 0.1023624\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703939\n",
      "\tspeed: 0.0605s/iter; left time: 61.8026s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741787\n",
      "\tspeed: 0.0305s/iter; left time: 28.1005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0727279 Vali Loss: 0.0886003 Test Loss: 0.1021663\n",
      "Validation loss decreased (0.088674 --> 0.088600).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0698442\n",
      "\tspeed: 0.0582s/iter; left time: 46.3757s\n",
      "\titers: 200, epoch: 17 | loss: 0.0758607\n",
      "\tspeed: 0.0298s/iter; left time: 20.7367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0725987 Vali Loss: 0.0886171 Test Loss: 0.1021710\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662590\n",
      "\tspeed: 0.0613s/iter; left time: 35.1394s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706528\n",
      "\tspeed: 0.0296s/iter; left time: 14.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 224 | Train Loss: 0.0724800 Vali Loss: 0.0888152 Test Loss: 0.1024421\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0742896\n",
      "\tspeed: 0.0576s/iter; left time: 20.1128s\n",
      "\titers: 200, epoch: 19 | loss: 0.0735393\n",
      "\tspeed: 0.0293s/iter; left time: 7.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0723689 Vali Loss: 0.0887323 Test Loss: 0.1025851\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0666809\n",
      "\tspeed: 0.0564s/iter; left time: 7.0511s\n",
      "\titers: 200, epoch: 20 | loss: 0.0699753\n",
      "\tspeed: 0.0292s/iter; left time: 0.7303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0886836 Test Loss: 0.1025293\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025964142754673958, rmse:0.16113393008708954, mae:0.1021663025021553, rse:0.5558663606643677\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1354569\n",
      "\tspeed: 0.0316s/iter; left time: 138.3078s\n",
      "\titers: 200, epoch: 1 | loss: 0.1332909\n",
      "\tspeed: 0.0291s/iter; left time: 124.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.1393385 Vali Loss: 0.1384809 Test Loss: 0.1598563\n",
      "Validation loss decreased (inf --> 0.138481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0976845\n",
      "\tspeed: 0.0578s/iter; left time: 240.3468s\n",
      "\titers: 200, epoch: 2 | loss: 0.0826960\n",
      "\tspeed: 0.0291s/iter; left time: 118.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0982992 Vali Loss: 0.0959441 Test Loss: 0.1075740\n",
      "Validation loss decreased (0.138481 --> 0.095944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0828190\n",
      "\tspeed: 0.0582s/iter; left time: 228.7219s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774016\n",
      "\tspeed: 0.0307s/iter; left time: 117.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0814919 Vali Loss: 0.0920538 Test Loss: 0.1037733\n",
      "Validation loss decreased (0.095944 --> 0.092054).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0768839\n",
      "\tspeed: 0.0594s/iter; left time: 220.1914s\n",
      "\titers: 200, epoch: 4 | loss: 0.0783832\n",
      "\tspeed: 0.0306s/iter; left time: 110.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0785152 Vali Loss: 0.0909251 Test Loss: 0.1024362\n",
      "Validation loss decreased (0.092054 --> 0.090925).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776981\n",
      "\tspeed: 0.0582s/iter; left time: 202.9563s\n",
      "\titers: 200, epoch: 5 | loss: 0.0770190\n",
      "\tspeed: 0.0293s/iter; left time: 99.1732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0770842 Vali Loss: 0.0903363 Test Loss: 0.1027377\n",
      "Validation loss decreased (0.090925 --> 0.090336).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0758352\n",
      "\tspeed: 0.0580s/iter; left time: 189.2236s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810753\n",
      "\tspeed: 0.0304s/iter; left time: 96.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0761209 Vali Loss: 0.0898761 Test Loss: 0.1023513\n",
      "Validation loss decreased (0.090336 --> 0.089876).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0719840\n",
      "\tspeed: 0.0580s/iter; left time: 176.2209s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753599\n",
      "\tspeed: 0.0291s/iter; left time: 85.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.0754588 Vali Loss: 0.0895967 Test Loss: 0.1024055\n",
      "Validation loss decreased (0.089876 --> 0.089597).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792034\n",
      "\tspeed: 0.0599s/iter; left time: 168.3665s\n",
      "\titers: 200, epoch: 8 | loss: 0.0735539\n",
      "\tspeed: 0.0297s/iter; left time: 80.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0750365 Vali Loss: 0.0894292 Test Loss: 0.1019174\n",
      "Validation loss decreased (0.089597 --> 0.089429).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0768409\n",
      "\tspeed: 0.0611s/iter; left time: 158.1644s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745305\n",
      "\tspeed: 0.0305s/iter; left time: 76.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0745266 Vali Loss: 0.0895942 Test Loss: 0.1023652\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0718862\n",
      "\tspeed: 0.0565s/iter; left time: 133.6978s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749407\n",
      "\tspeed: 0.0301s/iter; left time: 68.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0742332 Vali Loss: 0.0892495 Test Loss: 0.1022792\n",
      "Validation loss decreased (0.089429 --> 0.089249).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0750564\n",
      "\tspeed: 0.0589s/iter; left time: 126.0899s\n",
      "\titers: 200, epoch: 11 | loss: 0.0812153\n",
      "\tspeed: 0.0308s/iter; left time: 62.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 224 | Train Loss: 0.0739060 Vali Loss: 0.0890175 Test Loss: 0.1028246\n",
      "Validation loss decreased (0.089249 --> 0.089018).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728291\n",
      "\tspeed: 0.0580s/iter; left time: 111.2395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719949\n",
      "\tspeed: 0.0298s/iter; left time: 54.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0736938 Vali Loss: 0.0886921 Test Loss: 0.1024665\n",
      "Validation loss decreased (0.089018 --> 0.088692).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0771927\n",
      "\tspeed: 0.0584s/iter; left time: 98.7965s\n",
      "\titers: 200, epoch: 13 | loss: 0.0795360\n",
      "\tspeed: 0.0319s/iter; left time: 50.8758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0734331 Vali Loss: 0.0889147 Test Loss: 0.1024984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0728168\n",
      "\tspeed: 0.0577s/iter; left time: 84.7429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726639\n",
      "\tspeed: 0.0314s/iter; left time: 43.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0731269 Vali Loss: 0.0887128 Test Loss: 0.1024059\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0786317\n",
      "\tspeed: 0.0583s/iter; left time: 72.5469s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763230\n",
      "\tspeed: 0.0311s/iter; left time: 35.5748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0730170 Vali Loss: 0.0888302 Test Loss: 0.1023854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0728925\n",
      "\tspeed: 0.0633s/iter; left time: 64.5849s\n",
      "\titers: 200, epoch: 16 | loss: 0.0766838\n",
      "\tspeed: 0.0293s/iter; left time: 27.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0728502 Vali Loss: 0.0886681 Test Loss: 0.1021706\n",
      "Validation loss decreased (0.088692 --> 0.088668).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0690544\n",
      "\tspeed: 0.0589s/iter; left time: 46.9251s\n",
      "\titers: 200, epoch: 17 | loss: 0.0709749\n",
      "\tspeed: 0.0307s/iter; left time: 21.3870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0726627 Vali Loss: 0.0886784 Test Loss: 0.1022870\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765421\n",
      "\tspeed: 0.0583s/iter; left time: 33.4036s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764679\n",
      "\tspeed: 0.0303s/iter; left time: 14.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.0724841 Vali Loss: 0.0885779 Test Loss: 0.1023734\n",
      "Validation loss decreased (0.088668 --> 0.088578).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733659\n",
      "\tspeed: 0.0575s/iter; left time: 20.0534s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709908\n",
      "\tspeed: 0.0295s/iter; left time: 7.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0724357 Vali Loss: 0.0886666 Test Loss: 0.1023417\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0777882\n",
      "\tspeed: 0.0588s/iter; left time: 7.3470s\n",
      "\titers: 200, epoch: 20 | loss: 0.0725895\n",
      "\tspeed: 0.0305s/iter; left time: 0.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0723057 Vali Loss: 0.0885511 Test Loss: 0.1022906\n",
      "Validation loss decreased (0.088578 --> 0.088551).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025928454473614693, rmse:0.16102315485477448, mae:0.102290578186512, rse:0.5554842352867126\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:06.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1509436\n",
      "\tspeed: 0.0538s/iter; left time: 235.6260s\n",
      "\titers: 200, epoch: 1 | loss: 0.1384306\n",
      "\tspeed: 0.0296s/iter; left time: 126.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1494617 Vali Loss: 0.1517594 Test Loss: 0.1784826\n",
      "Validation loss decreased (inf --> 0.151759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1140732\n",
      "\tspeed: 0.0579s/iter; left time: 240.5169s\n",
      "\titers: 200, epoch: 2 | loss: 0.1110358\n",
      "\tspeed: 0.0302s/iter; left time: 122.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.1177922 Vali Loss: 0.1202108 Test Loss: 0.1407618\n",
      "Validation loss decreased (0.151759 --> 0.120211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1010459\n",
      "\tspeed: 0.0581s/iter; left time: 228.4508s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007194\n",
      "\tspeed: 0.0293s/iter; left time: 112.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1048377 Vali Loss: 0.1183033 Test Loss: 0.1404727\n",
      "Validation loss decreased (0.120211 --> 0.118303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993064\n",
      "\tspeed: 0.0590s/iter; left time: 218.6588s\n",
      "\titers: 200, epoch: 4 | loss: 0.0927820\n",
      "\tspeed: 0.0293s/iter; left time: 105.6643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1025748 Vali Loss: 0.1174855 Test Loss: 0.1413985\n",
      "Validation loss decreased (0.118303 --> 0.117486).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074209\n",
      "\tspeed: 0.0590s/iter; left time: 205.7213s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001854\n",
      "\tspeed: 0.0297s/iter; left time: 100.6690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1010666 Vali Loss: 0.1169583 Test Loss: 0.1422356\n",
      "Validation loss decreased (0.117486 --> 0.116958).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989520\n",
      "\tspeed: 0.0596s/iter; left time: 194.2305s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977094\n",
      "\tspeed: 0.0303s/iter; left time: 95.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0997825 Vali Loss: 0.1166532 Test Loss: 0.1427568\n",
      "Validation loss decreased (0.116958 --> 0.116653).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0942127\n",
      "\tspeed: 0.0591s/iter; left time: 179.4103s\n",
      "\titers: 200, epoch: 7 | loss: 0.0975899\n",
      "\tspeed: 0.0292s/iter; left time: 85.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0985532 Vali Loss: 0.1167040 Test Loss: 0.1430438\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0976923\n",
      "\tspeed: 0.0580s/iter; left time: 163.2372s\n",
      "\titers: 200, epoch: 8 | loss: 0.0960573\n",
      "\tspeed: 0.0293s/iter; left time: 79.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0973627 Vali Loss: 0.1159907 Test Loss: 0.1423306\n",
      "Validation loss decreased (0.116653 --> 0.115991).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0953182\n",
      "\tspeed: 0.0584s/iter; left time: 151.2799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0952382\n",
      "\tspeed: 0.0294s/iter; left time: 73.2102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0962679 Vali Loss: 0.1164612 Test Loss: 0.1433991\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0937599\n",
      "\tspeed: 0.0570s/iter; left time: 134.7254s\n",
      "\titers: 200, epoch: 10 | loss: 0.0933965\n",
      "\tspeed: 0.0291s/iter; left time: 65.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0953636 Vali Loss: 0.1165707 Test Loss: 0.1438840\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0931610\n",
      "\tspeed: 0.0573s/iter; left time: 122.7653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0885064\n",
      "\tspeed: 0.0293s/iter; left time: 59.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0946030 Vali Loss: 0.1159253 Test Loss: 0.1434017\n",
      "Validation loss decreased (0.115991 --> 0.115925).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0895501\n",
      "\tspeed: 0.0593s/iter; left time: 113.6431s\n",
      "\titers: 200, epoch: 12 | loss: 0.0912748\n",
      "\tspeed: 0.0295s/iter; left time: 53.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0939016 Vali Loss: 0.1166419 Test Loss: 0.1436138\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0973094\n",
      "\tspeed: 0.0585s/iter; left time: 98.9625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0974050\n",
      "\tspeed: 0.0301s/iter; left time: 47.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0932893 Vali Loss: 0.1173202 Test Loss: 0.1447276\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0905818\n",
      "\tspeed: 0.0593s/iter; left time: 87.1410s\n",
      "\titers: 200, epoch: 14 | loss: 0.0921348\n",
      "\tspeed: 0.0306s/iter; left time: 41.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0928849 Vali Loss: 0.1163865 Test Loss: 0.1436901\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0909728\n",
      "\tspeed: 0.0613s/iter; left time: 76.3760s\n",
      "\titers: 200, epoch: 15 | loss: 0.0944395\n",
      "\tspeed: 0.0351s/iter; left time: 40.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0923803 Vali Loss: 0.1168629 Test Loss: 0.1441083\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0966858\n",
      "\tspeed: 0.0608s/iter; left time: 62.0848s\n",
      "\titers: 200, epoch: 16 | loss: 0.0883803\n",
      "\tspeed: 0.0339s/iter; left time: 31.2369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0919351 Vali Loss: 0.1172677 Test Loss: 0.1449067\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04481872543692589, rmse:0.2117043286561966, mae:0.14340177178382874, rse:0.7321031093597412\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1461980\n",
      "\tspeed: 0.0332s/iter; left time: 145.6107s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341958\n",
      "\tspeed: 0.0308s/iter; left time: 131.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.1492552 Vali Loss: 0.1518430 Test Loss: 0.1783923\n",
      "Validation loss decreased (inf --> 0.151843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1161822\n",
      "\tspeed: 0.0591s/iter; left time: 245.7346s\n",
      "\titers: 200, epoch: 2 | loss: 0.1058718\n",
      "\tspeed: 0.0304s/iter; left time: 123.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.1174654 Vali Loss: 0.1204625 Test Loss: 0.1418096\n",
      "Validation loss decreased (0.151843 --> 0.120463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1101666\n",
      "\tspeed: 0.0597s/iter; left time: 234.7721s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059080\n",
      "\tspeed: 0.0292s/iter; left time: 111.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.1048325 Vali Loss: 0.1180718 Test Loss: 0.1405513\n",
      "Validation loss decreased (0.120463 --> 0.118072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0998193\n",
      "\tspeed: 0.0615s/iter; left time: 227.9245s\n",
      "\titers: 200, epoch: 4 | loss: 0.1022913\n",
      "\tspeed: 0.0299s/iter; left time: 107.8305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.1025756 Vali Loss: 0.1173136 Test Loss: 0.1412795\n",
      "Validation loss decreased (0.118072 --> 0.117314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1037625\n",
      "\tspeed: 0.0611s/iter; left time: 213.0388s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001566\n",
      "\tspeed: 0.0297s/iter; left time: 100.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.1010131 Vali Loss: 0.1169841 Test Loss: 0.1424543\n",
      "Validation loss decreased (0.117314 --> 0.116984).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1029929\n",
      "\tspeed: 0.0595s/iter; left time: 194.1226s\n",
      "\titers: 200, epoch: 6 | loss: 0.1008184\n",
      "\tspeed: 0.0302s/iter; left time: 95.4803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0996978 Vali Loss: 0.1170137 Test Loss: 0.1434475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1009895\n",
      "\tspeed: 0.0599s/iter; left time: 181.9358s\n",
      "\titers: 200, epoch: 7 | loss: 0.0975019\n",
      "\tspeed: 0.0293s/iter; left time: 86.0629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0984956 Vali Loss: 0.1169074 Test Loss: 0.1428533\n",
      "Validation loss decreased (0.116984 --> 0.116907).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0954991\n",
      "\tspeed: 0.0593s/iter; left time: 166.6874s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941261\n",
      "\tspeed: 0.0292s/iter; left time: 79.3340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0973538 Vali Loss: 0.1172971 Test Loss: 0.1431828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0952091\n",
      "\tspeed: 0.0588s/iter; left time: 152.1226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0931841\n",
      "\tspeed: 0.0307s/iter; left time: 76.3161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0963928 Vali Loss: 0.1174340 Test Loss: 0.1422643\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1013168\n",
      "\tspeed: 0.0598s/iter; left time: 141.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934406\n",
      "\tspeed: 0.0323s/iter; left time: 73.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0955075 Vali Loss: 0.1177513 Test Loss: 0.1434349\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0917407\n",
      "\tspeed: 0.0593s/iter; left time: 127.0599s\n",
      "\titers: 200, epoch: 11 | loss: 0.0943487\n",
      "\tspeed: 0.0298s/iter; left time: 60.8763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0947423 Vali Loss: 0.1187260 Test Loss: 0.1445843\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0922019\n",
      "\tspeed: 0.0582s/iter; left time: 111.4814s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971775\n",
      "\tspeed: 0.0295s/iter; left time: 53.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0941181 Vali Loss: 0.1188033 Test Loss: 0.1440543\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04385209456086159, rmse:0.2094089239835739, mae:0.1428532749414444, rse:0.7241652011871338\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:22.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1510125\n",
      "\tspeed: 0.0534s/iter; left time: 232.9331s\n",
      "\titers: 200, epoch: 1 | loss: 0.1460141\n",
      "\tspeed: 0.0299s/iter; left time: 127.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 223 | Train Loss: 0.1503453 Vali Loss: 0.1539050 Test Loss: 0.1814873\n",
      "Validation loss decreased (inf --> 0.153905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1220895\n",
      "\tspeed: 0.0593s/iter; left time: 245.5397s\n",
      "\titers: 200, epoch: 2 | loss: 0.1078975\n",
      "\tspeed: 0.0340s/iter; left time: 137.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 223 | Train Loss: 0.1217292 Vali Loss: 0.1243885 Test Loss: 0.1467298\n",
      "Validation loss decreased (0.153905 --> 0.124388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1145073\n",
      "\tspeed: 0.0649s/iter; left time: 254.1509s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081278\n",
      "\tspeed: 0.0341s/iter; left time: 130.1032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.1094722 Vali Loss: 0.1223220 Test Loss: 0.1469709\n",
      "Validation loss decreased (0.124388 --> 0.122322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053047\n",
      "\tspeed: 0.0621s/iter; left time: 229.3814s\n",
      "\titers: 200, epoch: 4 | loss: 0.1045539\n",
      "\tspeed: 0.0298s/iter; left time: 106.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 223 | Train Loss: 0.1068624 Vali Loss: 0.1214676 Test Loss: 0.1486108\n",
      "Validation loss decreased (0.122322 --> 0.121468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1042434\n",
      "\tspeed: 0.0613s/iter; left time: 212.6899s\n",
      "\titers: 200, epoch: 5 | loss: 0.1094913\n",
      "\tspeed: 0.0312s/iter; left time: 104.9619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.1051321 Vali Loss: 0.1207100 Test Loss: 0.1481413\n",
      "Validation loss decreased (0.121468 --> 0.120710).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052476\n",
      "\tspeed: 0.0653s/iter; left time: 212.0141s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002916\n",
      "\tspeed: 0.0317s/iter; left time: 99.6505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 223 | Train Loss: 0.1036120 Vali Loss: 0.1213116 Test Loss: 0.1490655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003036\n",
      "\tspeed: 0.0644s/iter; left time: 194.8136s\n",
      "\titers: 200, epoch: 7 | loss: 0.1022745\n",
      "\tspeed: 0.0355s/iter; left time: 103.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1022487 Vali Loss: 0.1211078 Test Loss: 0.1485610\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0986450\n",
      "\tspeed: 0.0603s/iter; left time: 168.8967s\n",
      "\titers: 200, epoch: 8 | loss: 0.1077900\n",
      "\tspeed: 0.0330s/iter; left time: 89.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 223 | Train Loss: 0.1008363 Vali Loss: 0.1215522 Test Loss: 0.1486728\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0967671\n",
      "\tspeed: 0.0619s/iter; left time: 159.5206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0943255\n",
      "\tspeed: 0.0328s/iter; left time: 81.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 223 | Train Loss: 0.0996088 Vali Loss: 0.1225537 Test Loss: 0.1496329\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975155\n",
      "\tspeed: 0.0605s/iter; left time: 142.3044s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030245\n",
      "\tspeed: 0.0315s/iter; left time: 71.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 223 | Train Loss: 0.0985247 Vali Loss: 0.1229634 Test Loss: 0.1504967\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04586709663271904, rmse:0.2141660451889038, mae:0.1481413096189499, rse:0.7425444722175598\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1485536\n",
      "\tspeed: 0.0380s/iter; left time: 165.8778s\n",
      "\titers: 200, epoch: 1 | loss: 0.1414048\n",
      "\tspeed: 0.0305s/iter; left time: 129.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.1507393 Vali Loss: 0.1542606 Test Loss: 0.1818024\n",
      "Validation loss decreased (inf --> 0.154261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219954\n",
      "\tspeed: 0.0662s/iter; left time: 273.8677s\n",
      "\titers: 200, epoch: 2 | loss: 0.1118876\n",
      "\tspeed: 0.0349s/iter; left time: 140.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1219783 Vali Loss: 0.1245134 Test Loss: 0.1471873\n",
      "Validation loss decreased (0.154261 --> 0.124513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1097370\n",
      "\tspeed: 0.0658s/iter; left time: 257.5462s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050628\n",
      "\tspeed: 0.0339s/iter; left time: 129.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.1094273 Vali Loss: 0.1224969 Test Loss: 0.1482502\n",
      "Validation loss decreased (0.124513 --> 0.122497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1110828\n",
      "\tspeed: 0.0628s/iter; left time: 231.7800s\n",
      "\titers: 200, epoch: 4 | loss: 0.1024591\n",
      "\tspeed: 0.0295s/iter; left time: 106.0394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.1068961 Vali Loss: 0.1210321 Test Loss: 0.1482490\n",
      "Validation loss decreased (0.122497 --> 0.121032).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032787\n",
      "\tspeed: 0.0620s/iter; left time: 214.9381s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020764\n",
      "\tspeed: 0.0302s/iter; left time: 101.7230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.1049933 Vali Loss: 0.1214267 Test Loss: 0.1499755\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994527\n",
      "\tspeed: 0.0612s/iter; left time: 198.7637s\n",
      "\titers: 200, epoch: 6 | loss: 0.1018772\n",
      "\tspeed: 0.0302s/iter; left time: 95.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.1032620 Vali Loss: 0.1213790 Test Loss: 0.1485605\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056867\n",
      "\tspeed: 0.0617s/iter; left time: 186.4334s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025994\n",
      "\tspeed: 0.0307s/iter; left time: 89.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 223 | Train Loss: 0.1017742 Vali Loss: 0.1215589 Test Loss: 0.1493624\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0987241\n",
      "\tspeed: 0.0598s/iter; left time: 167.3432s\n",
      "\titers: 200, epoch: 8 | loss: 0.1000190\n",
      "\tspeed: 0.0305s/iter; left time: 82.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1004642 Vali Loss: 0.1226435 Test Loss: 0.1507201\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008038\n",
      "\tspeed: 0.0594s/iter; left time: 152.9557s\n",
      "\titers: 200, epoch: 9 | loss: 0.1012690\n",
      "\tspeed: 0.0301s/iter; left time: 74.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0993725 Vali Loss: 0.1224250 Test Loss: 0.1501770\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0455046072602272, rmse:0.2133180946111679, mae:0.1482490599155426, rse:0.7396044135093689\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:11.57s\n",
      "Intermediate time for GB: 00h:13m:39.84s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1721672\n",
      "\tspeed: 0.0482s/iter; left time: 211.0295s\n",
      "\titers: 200, epoch: 1 | loss: 0.1541415\n",
      "\tspeed: 0.0237s/iter; left time: 101.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.1675985 Vali Loss: 0.1512479 Test Loss: 0.1809724\n",
      "Validation loss decreased (inf --> 0.151248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780379\n",
      "\tspeed: 0.0477s/iter; left time: 198.4731s\n",
      "\titers: 200, epoch: 2 | loss: 0.0692572\n",
      "\tspeed: 0.0235s/iter; left time: 95.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0879753 Vali Loss: 0.0655792 Test Loss: 0.0731002\n",
      "Validation loss decreased (0.151248 --> 0.065579).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0671448\n",
      "\tspeed: 0.0443s/iter; left time: 174.1113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669683\n",
      "\tspeed: 0.0234s/iter; left time: 89.5858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0660800 Vali Loss: 0.0612512 Test Loss: 0.0685301\n",
      "Validation loss decreased (0.065579 --> 0.061251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627315\n",
      "\tspeed: 0.0441s/iter; left time: 163.6560s\n",
      "\titers: 200, epoch: 4 | loss: 0.0589354\n",
      "\tspeed: 0.0275s/iter; left time: 99.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0623051 Vali Loss: 0.0593758 Test Loss: 0.0663927\n",
      "Validation loss decreased (0.061251 --> 0.059376).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630472\n",
      "\tspeed: 0.0479s/iter; left time: 166.8209s\n",
      "\titers: 200, epoch: 5 | loss: 0.0602869\n",
      "\tspeed: 0.0269s/iter; left time: 91.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0600424 Vali Loss: 0.0578820 Test Loss: 0.0648575\n",
      "Validation loss decreased (0.059376 --> 0.057882).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594011\n",
      "\tspeed: 0.0533s/iter; left time: 173.8753s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568600\n",
      "\tspeed: 0.0298s/iter; left time: 94.0829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.0585781 Vali Loss: 0.0568827 Test Loss: 0.0638525\n",
      "Validation loss decreased (0.057882 --> 0.056883).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0563148\n",
      "\tspeed: 0.0579s/iter; left time: 175.8525s\n",
      "\titers: 200, epoch: 7 | loss: 0.0567453\n",
      "\tspeed: 0.0281s/iter; left time: 82.6583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0575676 Vali Loss: 0.0562464 Test Loss: 0.0631524\n",
      "Validation loss decreased (0.056883 --> 0.056246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0558760\n",
      "\tspeed: 0.0430s/iter; left time: 121.0684s\n",
      "\titers: 200, epoch: 8 | loss: 0.0579761\n",
      "\tspeed: 0.0236s/iter; left time: 63.9464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0568867 Vali Loss: 0.0558712 Test Loss: 0.0627775\n",
      "Validation loss decreased (0.056246 --> 0.055871).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550179\n",
      "\tspeed: 0.0481s/iter; left time: 124.6547s\n",
      "\titers: 200, epoch: 9 | loss: 0.0563627\n",
      "\tspeed: 0.0244s/iter; left time: 60.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0563171 Vali Loss: 0.0555385 Test Loss: 0.0625146\n",
      "Validation loss decreased (0.055871 --> 0.055538).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541733\n",
      "\tspeed: 0.0537s/iter; left time: 126.9873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585516\n",
      "\tspeed: 0.0303s/iter; left time: 68.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0558124 Vali Loss: 0.0551824 Test Loss: 0.0620765\n",
      "Validation loss decreased (0.055538 --> 0.055182).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569852\n",
      "\tspeed: 0.0571s/iter; left time: 122.1636s\n",
      "\titers: 200, epoch: 11 | loss: 0.0544668\n",
      "\tspeed: 0.0350s/iter; left time: 71.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0554116 Vali Loss: 0.0549211 Test Loss: 0.0618197\n",
      "Validation loss decreased (0.055182 --> 0.054921).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540032\n",
      "\tspeed: 0.0514s/iter; left time: 98.4402s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546257\n",
      "\tspeed: 0.0332s/iter; left time: 60.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0550291 Vali Loss: 0.0545743 Test Loss: 0.0615266\n",
      "Validation loss decreased (0.054921 --> 0.054574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0511341\n",
      "\tspeed: 0.0557s/iter; left time: 94.2888s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562718\n",
      "\tspeed: 0.0297s/iter; left time: 47.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0547906 Vali Loss: 0.0546620 Test Loss: 0.0614961\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0558587\n",
      "\tspeed: 0.0534s/iter; left time: 78.5128s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546150\n",
      "\tspeed: 0.0314s/iter; left time: 42.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0545490 Vali Loss: 0.0545183 Test Loss: 0.0613927\n",
      "Validation loss decreased (0.054574 --> 0.054518).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518050\n",
      "\tspeed: 0.0611s/iter; left time: 76.0589s\n",
      "\titers: 200, epoch: 15 | loss: 0.0536502\n",
      "\tspeed: 0.0286s/iter; left time: 32.7595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0542878 Vali Loss: 0.0543094 Test Loss: 0.0612394\n",
      "Validation loss decreased (0.054518 --> 0.054309).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0536641\n",
      "\tspeed: 0.0547s/iter; left time: 55.8139s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557155\n",
      "\tspeed: 0.0237s/iter; left time: 21.8350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0541524 Vali Loss: 0.0542523 Test Loss: 0.0609261\n",
      "Validation loss decreased (0.054309 --> 0.054252).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0548307\n",
      "\tspeed: 0.0449s/iter; left time: 35.8044s\n",
      "\titers: 200, epoch: 17 | loss: 0.0553817\n",
      "\tspeed: 0.0253s/iter; left time: 17.6333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0540486 Vali Loss: 0.0543452 Test Loss: 0.0611064\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0527278\n",
      "\tspeed: 0.0537s/iter; left time: 30.7484s\n",
      "\titers: 200, epoch: 18 | loss: 0.0522661\n",
      "\tspeed: 0.0289s/iter; left time: 13.6667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0537799 Vali Loss: 0.0541636 Test Loss: 0.0608962\n",
      "Validation loss decreased (0.054252 --> 0.054164).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0565891\n",
      "\tspeed: 0.0520s/iter; left time: 18.1348s\n",
      "\titers: 200, epoch: 19 | loss: 0.0534971\n",
      "\tspeed: 0.0239s/iter; left time: 5.9495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0536614 Vali Loss: 0.0540985 Test Loss: 0.0608358\n",
      "Validation loss decreased (0.054164 --> 0.054098).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522145\n",
      "\tspeed: 0.0445s/iter; left time: 5.5684s\n",
      "\titers: 200, epoch: 20 | loss: 0.0552006\n",
      "\tspeed: 0.0218s/iter; left time: 0.5441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0535905 Vali Loss: 0.0539736 Test Loss: 0.0607711\n",
      "Validation loss decreased (0.054098 --> 0.053974).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010008933022618294, rmse:0.10004465281963348, mae:0.0607711523771286, rse:0.2944193184375763\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1596532\n",
      "\tspeed: 0.0292s/iter; left time: 128.0733s\n",
      "\titers: 200, epoch: 1 | loss: 0.1511044\n",
      "\tspeed: 0.0281s/iter; left time: 120.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.1618877 Vali Loss: 0.1474657 Test Loss: 0.1776175\n",
      "Validation loss decreased (inf --> 0.147466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0835509\n",
      "\tspeed: 0.0478s/iter; left time: 198.5603s\n",
      "\titers: 200, epoch: 2 | loss: 0.0762760\n",
      "\tspeed: 0.0296s/iter; left time: 119.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0891758 Vali Loss: 0.0672824 Test Loss: 0.0747560\n",
      "Validation loss decreased (0.147466 --> 0.067282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0639110\n",
      "\tspeed: 0.0524s/iter; left time: 205.9805s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644747\n",
      "\tspeed: 0.0329s/iter; left time: 126.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.0668662 Vali Loss: 0.0616086 Test Loss: 0.0688085\n",
      "Validation loss decreased (0.067282 --> 0.061609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611796\n",
      "\tspeed: 0.0423s/iter; left time: 156.9516s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618229\n",
      "\tspeed: 0.0186s/iter; left time: 67.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0627781 Vali Loss: 0.0593571 Test Loss: 0.0664236\n",
      "Validation loss decreased (0.061609 --> 0.059357).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597486\n",
      "\tspeed: 0.0405s/iter; left time: 141.2781s\n",
      "\titers: 200, epoch: 5 | loss: 0.0587326\n",
      "\tspeed: 0.0201s/iter; left time: 68.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0602809 Vali Loss: 0.0579410 Test Loss: 0.0649095\n",
      "Validation loss decreased (0.059357 --> 0.057941).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0611355\n",
      "\tspeed: 0.0581s/iter; left time: 189.4448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0561308\n",
      "\tspeed: 0.0320s/iter; left time: 101.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0587318 Vali Loss: 0.0569767 Test Loss: 0.0641535\n",
      "Validation loss decreased (0.057941 --> 0.056977).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0576968\n",
      "\tspeed: 0.0503s/iter; left time: 152.8757s\n",
      "\titers: 200, epoch: 7 | loss: 0.0565405\n",
      "\tspeed: 0.0327s/iter; left time: 96.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0576639 Vali Loss: 0.0563742 Test Loss: 0.0633033\n",
      "Validation loss decreased (0.056977 --> 0.056374).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0594950\n",
      "\tspeed: 0.0506s/iter; left time: 142.3918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0555147\n",
      "\tspeed: 0.0301s/iter; left time: 81.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0568690 Vali Loss: 0.0558792 Test Loss: 0.0627439\n",
      "Validation loss decreased (0.056374 --> 0.055879).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539621\n",
      "\tspeed: 0.0525s/iter; left time: 135.9322s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581579\n",
      "\tspeed: 0.0290s/iter; left time: 72.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0563084 Vali Loss: 0.0554888 Test Loss: 0.0624231\n",
      "Validation loss decreased (0.055879 --> 0.055489).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0527902\n",
      "\tspeed: 0.0530s/iter; left time: 125.4042s\n",
      "\titers: 200, epoch: 10 | loss: 0.0541985\n",
      "\tspeed: 0.0293s/iter; left time: 66.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0558122 Vali Loss: 0.0552245 Test Loss: 0.0619763\n",
      "Validation loss decreased (0.055489 --> 0.055224).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0638917\n",
      "\tspeed: 0.0570s/iter; left time: 121.9441s\n",
      "\titers: 200, epoch: 11 | loss: 0.0540700\n",
      "\tspeed: 0.0307s/iter; left time: 62.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0553275 Vali Loss: 0.0549091 Test Loss: 0.0617257\n",
      "Validation loss decreased (0.055224 --> 0.054909).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549082\n",
      "\tspeed: 0.0529s/iter; left time: 101.4455s\n",
      "\titers: 200, epoch: 12 | loss: 0.0537651\n",
      "\tspeed: 0.0272s/iter; left time: 49.3598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0550657 Vali Loss: 0.0547247 Test Loss: 0.0615050\n",
      "Validation loss decreased (0.054909 --> 0.054725).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530530\n",
      "\tspeed: 0.0546s/iter; left time: 92.5221s\n",
      "\titers: 200, epoch: 13 | loss: 0.0534420\n",
      "\tspeed: 0.0320s/iter; left time: 51.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0547626 Vali Loss: 0.0544340 Test Loss: 0.0614279\n",
      "Validation loss decreased (0.054725 --> 0.054434).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559322\n",
      "\tspeed: 0.0550s/iter; left time: 80.7642s\n",
      "\titers: 200, epoch: 14 | loss: 0.0536417\n",
      "\tspeed: 0.0329s/iter; left time: 45.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0545341 Vali Loss: 0.0543583 Test Loss: 0.0611642\n",
      "Validation loss decreased (0.054434 --> 0.054358).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531458\n",
      "\tspeed: 0.0548s/iter; left time: 68.2640s\n",
      "\titers: 200, epoch: 15 | loss: 0.0525758\n",
      "\tspeed: 0.0282s/iter; left time: 32.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0543144 Vali Loss: 0.0542424 Test Loss: 0.0610617\n",
      "Validation loss decreased (0.054358 --> 0.054242).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566691\n",
      "\tspeed: 0.0524s/iter; left time: 53.4819s\n",
      "\titers: 200, epoch: 16 | loss: 0.0541308\n",
      "\tspeed: 0.0276s/iter; left time: 25.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0540456 Vali Loss: 0.0542631 Test Loss: 0.0610142\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0526512\n",
      "\tspeed: 0.0577s/iter; left time: 45.9562s\n",
      "\titers: 200, epoch: 17 | loss: 0.0552824\n",
      "\tspeed: 0.0307s/iter; left time: 21.3949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0539070 Vali Loss: 0.0541401 Test Loss: 0.0609468\n",
      "Validation loss decreased (0.054242 --> 0.054140).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0565813\n",
      "\tspeed: 0.0576s/iter; left time: 33.0305s\n",
      "\titers: 200, epoch: 18 | loss: 0.0520637\n",
      "\tspeed: 0.0312s/iter; left time: 14.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0538013 Vali Loss: 0.0541952 Test Loss: 0.0610134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529261\n",
      "\tspeed: 0.0540s/iter; left time: 18.8317s\n",
      "\titers: 200, epoch: 19 | loss: 0.0513931\n",
      "\tspeed: 0.0299s/iter; left time: 7.4489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0537718 Vali Loss: 0.0540280 Test Loss: 0.0606972\n",
      "Validation loss decreased (0.054140 --> 0.054028).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0558502\n",
      "\tspeed: 0.0488s/iter; left time: 6.1015s\n",
      "\titers: 200, epoch: 20 | loss: 0.0569763\n",
      "\tspeed: 0.0250s/iter; left time: 0.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0535420 Vali Loss: 0.0540532 Test Loss: 0.0608387\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010019290260970592, rmse:0.10009640455245972, mae:0.06069719046354294, rse:0.2945716083049774\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:29.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1725521\n",
      "\tspeed: 0.0467s/iter; left time: 204.3969s\n",
      "\titers: 200, epoch: 1 | loss: 0.1565479\n",
      "\tspeed: 0.0241s/iter; left time: 103.2692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.1733191 Vali Loss: 0.1604159 Test Loss: 0.1920301\n",
      "Validation loss decreased (inf --> 0.160416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0971588\n",
      "\tspeed: 0.0513s/iter; left time: 213.1956s\n",
      "\titers: 200, epoch: 2 | loss: 0.0904106\n",
      "\tspeed: 0.0252s/iter; left time: 102.2149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.1049145 Vali Loss: 0.0852466 Test Loss: 0.0970004\n",
      "Validation loss decreased (0.160416 --> 0.085247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0837260\n",
      "\tspeed: 0.0559s/iter; left time: 219.6750s\n",
      "\titers: 200, epoch: 3 | loss: 0.0843056\n",
      "\tspeed: 0.0280s/iter; left time: 107.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0858868 Vali Loss: 0.0812536 Test Loss: 0.0927678\n",
      "Validation loss decreased (0.085247 --> 0.081254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0847470\n",
      "\tspeed: 0.0536s/iter; left time: 198.9055s\n",
      "\titers: 200, epoch: 4 | loss: 0.0795012\n",
      "\tspeed: 0.0280s/iter; left time: 101.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0821978 Vali Loss: 0.0792219 Test Loss: 0.0906864\n",
      "Validation loss decreased (0.081254 --> 0.079222).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797794\n",
      "\tspeed: 0.0528s/iter; left time: 184.1136s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782854\n",
      "\tspeed: 0.0290s/iter; left time: 98.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0800650 Vali Loss: 0.0781124 Test Loss: 0.0899344\n",
      "Validation loss decreased (0.079222 --> 0.078112).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791900\n",
      "\tspeed: 0.0600s/iter; left time: 195.5888s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792341\n",
      "\tspeed: 0.0317s/iter; left time: 100.1234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0788165 Vali Loss: 0.0774148 Test Loss: 0.0892412\n",
      "Validation loss decreased (0.078112 --> 0.077415).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756104\n",
      "\tspeed: 0.0498s/iter; left time: 151.1711s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788164\n",
      "\tspeed: 0.0226s/iter; left time: 66.4754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0779038 Vali Loss: 0.0771728 Test Loss: 0.0889014\n",
      "Validation loss decreased (0.077415 --> 0.077173).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746468\n",
      "\tspeed: 0.0479s/iter; left time: 134.8191s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767286\n",
      "\tspeed: 0.0229s/iter; left time: 62.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0773065 Vali Loss: 0.0771795 Test Loss: 0.0888543\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0737905\n",
      "\tspeed: 0.0596s/iter; left time: 154.2708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749887\n",
      "\tspeed: 0.0369s/iter; left time: 91.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0766889 Vali Loss: 0.0768313 Test Loss: 0.0886019\n",
      "Validation loss decreased (0.077173 --> 0.076831).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0796218\n",
      "\tspeed: 0.0539s/iter; left time: 127.5319s\n",
      "\titers: 200, epoch: 10 | loss: 0.0761664\n",
      "\tspeed: 0.0280s/iter; left time: 63.3465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0761690 Vali Loss: 0.0766745 Test Loss: 0.0885171\n",
      "Validation loss decreased (0.076831 --> 0.076674).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744708\n",
      "\tspeed: 0.0553s/iter; left time: 118.3026s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737956\n",
      "\tspeed: 0.0288s/iter; left time: 58.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0757698 Vali Loss: 0.0763696 Test Loss: 0.0880664\n",
      "Validation loss decreased (0.076674 --> 0.076370).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777045\n",
      "\tspeed: 0.0597s/iter; left time: 114.5291s\n",
      "\titers: 200, epoch: 12 | loss: 0.0758489\n",
      "\tspeed: 0.0259s/iter; left time: 47.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0754678 Vali Loss: 0.0762871 Test Loss: 0.0880422\n",
      "Validation loss decreased (0.076370 --> 0.076287).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761366\n",
      "\tspeed: 0.0522s/iter; left time: 88.3423s\n",
      "\titers: 200, epoch: 13 | loss: 0.0749714\n",
      "\tspeed: 0.0302s/iter; left time: 48.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0750555 Vali Loss: 0.0764202 Test Loss: 0.0880241\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738863\n",
      "\tspeed: 0.0461s/iter; left time: 67.6757s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734386\n",
      "\tspeed: 0.0256s/iter; left time: 35.0789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0747718 Vali Loss: 0.0765696 Test Loss: 0.0884194\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0754326\n",
      "\tspeed: 0.0520s/iter; left time: 64.7425s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753600\n",
      "\tspeed: 0.0220s/iter; left time: 25.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0745057 Vali Loss: 0.0765277 Test Loss: 0.0880612\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789264\n",
      "\tspeed: 0.0527s/iter; left time: 53.7621s\n",
      "\titers: 200, epoch: 16 | loss: 0.0727971\n",
      "\tspeed: 0.0291s/iter; left time: 26.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0743405 Vali Loss: 0.0766495 Test Loss: 0.0883471\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705721\n",
      "\tspeed: 0.0574s/iter; left time: 45.7406s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726235\n",
      "\tspeed: 0.0247s/iter; left time: 17.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.0740760 Vali Loss: 0.0764771 Test Loss: 0.0879456\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018859263509511948, rmse:0.13732902705669403, mae:0.0880422294139862, rse:0.40343135595321655\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1698379\n",
      "\tspeed: 0.0303s/iter; left time: 132.6421s\n",
      "\titers: 200, epoch: 1 | loss: 0.1551609\n",
      "\tspeed: 0.0309s/iter; left time: 132.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1712080 Vali Loss: 0.1599785 Test Loss: 0.1912402\n",
      "Validation loss decreased (inf --> 0.159978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0994957\n",
      "\tspeed: 0.0609s/iter; left time: 253.2226s\n",
      "\titers: 200, epoch: 2 | loss: 0.0872781\n",
      "\tspeed: 0.0241s/iter; left time: 97.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1052443 Vali Loss: 0.0858486 Test Loss: 0.0975516\n",
      "Validation loss decreased (0.159978 --> 0.085849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0863583\n",
      "\tspeed: 0.0579s/iter; left time: 227.5402s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788953\n",
      "\tspeed: 0.0275s/iter; left time: 105.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0860598 Vali Loss: 0.0819055 Test Loss: 0.0936085\n",
      "Validation loss decreased (0.085849 --> 0.081906).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0829154\n",
      "\tspeed: 0.0545s/iter; left time: 202.0343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851816\n",
      "\tspeed: 0.0287s/iter; left time: 103.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0824357 Vali Loss: 0.0797307 Test Loss: 0.0914204\n",
      "Validation loss decreased (0.081906 --> 0.079731).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805445\n",
      "\tspeed: 0.0566s/iter; left time: 197.2479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823711\n",
      "\tspeed: 0.0287s/iter; left time: 97.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0802209 Vali Loss: 0.0785390 Test Loss: 0.0900773\n",
      "Validation loss decreased (0.079731 --> 0.078539).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774995\n",
      "\tspeed: 0.0558s/iter; left time: 181.8183s\n",
      "\titers: 200, epoch: 6 | loss: 0.0801018\n",
      "\tspeed: 0.0292s/iter; left time: 92.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0789004 Vali Loss: 0.0779210 Test Loss: 0.0895773\n",
      "Validation loss decreased (0.078539 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772473\n",
      "\tspeed: 0.0510s/iter; left time: 154.8437s\n",
      "\titers: 200, epoch: 7 | loss: 0.0745187\n",
      "\tspeed: 0.0341s/iter; left time: 100.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0780322 Vali Loss: 0.0775394 Test Loss: 0.0888620\n",
      "Validation loss decreased (0.077921 --> 0.077539).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767846\n",
      "\tspeed: 0.0625s/iter; left time: 175.8554s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762060\n",
      "\tspeed: 0.0298s/iter; left time: 80.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0773130 Vali Loss: 0.0773337 Test Loss: 0.0889454\n",
      "Validation loss decreased (0.077539 --> 0.077334).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0799662\n",
      "\tspeed: 0.0614s/iter; left time: 158.8582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0755567\n",
      "\tspeed: 0.0304s/iter; left time: 75.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.0767137 Vali Loss: 0.0773684 Test Loss: 0.0886134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779764\n",
      "\tspeed: 0.0498s/iter; left time: 117.6977s\n",
      "\titers: 200, epoch: 10 | loss: 0.0724026\n",
      "\tspeed: 0.0311s/iter; left time: 70.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.0762154 Vali Loss: 0.0771214 Test Loss: 0.0885725\n",
      "Validation loss decreased (0.077334 --> 0.077121).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0718195\n",
      "\tspeed: 0.0544s/iter; left time: 116.5583s\n",
      "\titers: 200, epoch: 11 | loss: 0.0712211\n",
      "\tspeed: 0.0273s/iter; left time: 55.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0758795 Vali Loss: 0.0772411 Test Loss: 0.0884136\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752166\n",
      "\tspeed: 0.0550s/iter; left time: 105.4956s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782087\n",
      "\tspeed: 0.0311s/iter; left time: 56.5082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0755200 Vali Loss: 0.0769878 Test Loss: 0.0881455\n",
      "Validation loss decreased (0.077121 --> 0.076988).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0730099\n",
      "\tspeed: 0.0608s/iter; left time: 102.9406s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741637\n",
      "\tspeed: 0.0347s/iter; left time: 55.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0752080 Vali Loss: 0.0770076 Test Loss: 0.0882863\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752712\n",
      "\tspeed: 0.0598s/iter; left time: 87.7783s\n",
      "\titers: 200, epoch: 14 | loss: 0.0748860\n",
      "\tspeed: 0.0335s/iter; left time: 45.9268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0748604 Vali Loss: 0.0769626 Test Loss: 0.0879683\n",
      "Validation loss decreased (0.076988 --> 0.076963).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0728656\n",
      "\tspeed: 0.0597s/iter; left time: 74.3318s\n",
      "\titers: 200, epoch: 15 | loss: 0.0721450\n",
      "\tspeed: 0.0310s/iter; left time: 35.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0746116 Vali Loss: 0.0770035 Test Loss: 0.0879916\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0743508\n",
      "\tspeed: 0.0541s/iter; left time: 55.2559s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751298\n",
      "\tspeed: 0.0302s/iter; left time: 27.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0744169 Vali Loss: 0.0770240 Test Loss: 0.0881299\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0765967\n",
      "\tspeed: 0.0623s/iter; left time: 49.6789s\n",
      "\titers: 200, epoch: 17 | loss: 0.0723585\n",
      "\tspeed: 0.0344s/iter; left time: 23.9923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0741332 Vali Loss: 0.0772078 Test Loss: 0.0881946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0753285\n",
      "\tspeed: 0.0596s/iter; left time: 34.1679s\n",
      "\titers: 200, epoch: 18 | loss: 0.0715521\n",
      "\tspeed: 0.0252s/iter; left time: 11.9057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0740344 Vali Loss: 0.0769602 Test Loss: 0.0879356\n",
      "Validation loss decreased (0.076963 --> 0.076960).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725593\n",
      "\tspeed: 0.0529s/iter; left time: 18.4490s\n",
      "\titers: 200, epoch: 19 | loss: 0.0743347\n",
      "\tspeed: 0.0269s/iter; left time: 6.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 224 | Train Loss: 0.0738742 Vali Loss: 0.0769454 Test Loss: 0.0878929\n",
      "Validation loss decreased (0.076960 --> 0.076945).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0705099\n",
      "\tspeed: 0.0594s/iter; left time: 7.4261s\n",
      "\titers: 200, epoch: 20 | loss: 0.0758584\n",
      "\tspeed: 0.0233s/iter; left time: 0.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0737104 Vali Loss: 0.0769447 Test Loss: 0.0878037\n",
      "Validation loss decreased (0.076945 --> 0.076945).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018894238397479057, rmse:0.13745631277561188, mae:0.08780369907617569, rse:0.40380528569221497\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:21.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1724428\n",
      "\tspeed: 0.0494s/iter; left time: 215.2616s\n",
      "\titers: 200, epoch: 1 | loss: 0.1588923\n",
      "\tspeed: 0.0225s/iter; left time: 96.0574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.1736329 Vali Loss: 0.1629829 Test Loss: 0.1935919\n",
      "Validation loss decreased (inf --> 0.162983).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031059\n",
      "\tspeed: 0.0483s/iter; left time: 199.9668s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941303\n",
      "\tspeed: 0.0239s/iter; left time: 96.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.1083642 Vali Loss: 0.0904125 Test Loss: 0.1030170\n",
      "Validation loss decreased (0.162983 --> 0.090412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933322\n",
      "\tspeed: 0.0460s/iter; left time: 180.1691s\n",
      "\titers: 200, epoch: 3 | loss: 0.0876527\n",
      "\tspeed: 0.0202s/iter; left time: 77.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0905381 Vali Loss: 0.0867086 Test Loss: 0.0988521\n",
      "Validation loss decreased (0.090412 --> 0.086709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839370\n",
      "\tspeed: 0.0480s/iter; left time: 177.0924s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888987\n",
      "\tspeed: 0.0242s/iter; left time: 86.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0871525 Vali Loss: 0.0848498 Test Loss: 0.0969069\n",
      "Validation loss decreased (0.086709 --> 0.084850).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852654\n",
      "\tspeed: 0.0496s/iter; left time: 172.0758s\n",
      "\titers: 200, epoch: 5 | loss: 0.0876925\n",
      "\tspeed: 0.0255s/iter; left time: 86.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0851081 Vali Loss: 0.0839559 Test Loss: 0.0959918\n",
      "Validation loss decreased (0.084850 --> 0.083956).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864237\n",
      "\tspeed: 0.0500s/iter; left time: 162.3804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834747\n",
      "\tspeed: 0.0262s/iter; left time: 82.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0839395 Vali Loss: 0.0839342 Test Loss: 0.0956602\n",
      "Validation loss decreased (0.083956 --> 0.083934).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0808936\n",
      "\tspeed: 0.0533s/iter; left time: 161.0165s\n",
      "\titers: 200, epoch: 7 | loss: 0.0824597\n",
      "\tspeed: 0.0240s/iter; left time: 70.0918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0830664 Vali Loss: 0.0834632 Test Loss: 0.0948906\n",
      "Validation loss decreased (0.083934 --> 0.083463).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823163\n",
      "\tspeed: 0.0485s/iter; left time: 135.8576s\n",
      "\titers: 200, epoch: 8 | loss: 0.0843908\n",
      "\tspeed: 0.0257s/iter; left time: 69.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0823626 Vali Loss: 0.0832727 Test Loss: 0.0947872\n",
      "Validation loss decreased (0.083463 --> 0.083273).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0813698\n",
      "\tspeed: 0.0524s/iter; left time: 134.9189s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757824\n",
      "\tspeed: 0.0286s/iter; left time: 70.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0817842 Vali Loss: 0.0832338 Test Loss: 0.0946435\n",
      "Validation loss decreased (0.083273 --> 0.083234).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778607\n",
      "\tspeed: 0.0530s/iter; left time: 124.8782s\n",
      "\titers: 200, epoch: 10 | loss: 0.0814881\n",
      "\tspeed: 0.0341s/iter; left time: 76.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 223 | Train Loss: 0.0812702 Vali Loss: 0.0833407 Test Loss: 0.0946731\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0789123\n",
      "\tspeed: 0.0524s/iter; left time: 111.6055s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789626\n",
      "\tspeed: 0.0302s/iter; left time: 61.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0808463 Vali Loss: 0.0833778 Test Loss: 0.0943542\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781472\n",
      "\tspeed: 0.0552s/iter; left time: 105.2810s\n",
      "\titers: 200, epoch: 12 | loss: 0.0828225\n",
      "\tspeed: 0.0291s/iter; left time: 52.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.0803191 Vali Loss: 0.0832993 Test Loss: 0.0946182\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0797154\n",
      "\tspeed: 0.0505s/iter; left time: 85.0859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817254\n",
      "\tspeed: 0.0231s/iter; left time: 36.6633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0800107 Vali Loss: 0.0832920 Test Loss: 0.0947295\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0831568\n",
      "\tspeed: 0.0461s/iter; left time: 67.4657s\n",
      "\titers: 200, epoch: 14 | loss: 0.0769861\n",
      "\tspeed: 0.0214s/iter; left time: 29.1911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0795818 Vali Loss: 0.0831941 Test Loss: 0.0945907\n",
      "Validation loss decreased (0.083234 --> 0.083194).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776958\n",
      "\tspeed: 0.0469s/iter; left time: 58.0574s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804305\n",
      "\tspeed: 0.0239s/iter; left time: 27.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0793109 Vali Loss: 0.0831197 Test Loss: 0.0947189\n",
      "Validation loss decreased (0.083194 --> 0.083120).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0773943\n",
      "\tspeed: 0.0608s/iter; left time: 61.7349s\n",
      "\titers: 200, epoch: 16 | loss: 0.0784585\n",
      "\tspeed: 0.0299s/iter; left time: 27.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0790696 Vali Loss: 0.0831180 Test Loss: 0.0951498\n",
      "Validation loss decreased (0.083120 --> 0.083118).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0790858\n",
      "\tspeed: 0.0528s/iter; left time: 41.8953s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786156\n",
      "\tspeed: 0.0317s/iter; left time: 21.9710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0788158 Vali Loss: 0.0832317 Test Loss: 0.0950733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0775901\n",
      "\tspeed: 0.0554s/iter; left time: 31.5807s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769227\n",
      "\tspeed: 0.0275s/iter; left time: 12.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.0785558 Vali Loss: 0.0831419 Test Loss: 0.0955544\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0774844\n",
      "\tspeed: 0.0511s/iter; left time: 17.7383s\n",
      "\titers: 200, epoch: 19 | loss: 0.0780503\n",
      "\tspeed: 0.0284s/iter; left time: 7.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0783748 Vali Loss: 0.0832605 Test Loss: 0.0955217\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0776535\n",
      "\tspeed: 0.0471s/iter; left time: 5.8374s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809101\n",
      "\tspeed: 0.0217s/iter; left time: 0.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0782038 Vali Loss: 0.0833181 Test Loss: 0.0958952\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021193236112594604, rmse:0.14557896554470062, mae:0.09514977037906647, rse:0.42769792675971985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1731604\n",
      "\tspeed: 0.0326s/iter; left time: 141.9851s\n",
      "\titers: 200, epoch: 1 | loss: 0.1555609\n",
      "\tspeed: 0.0301s/iter; left time: 128.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.1734870 Vali Loss: 0.1622746 Test Loss: 0.1926449\n",
      "Validation loss decreased (inf --> 0.162275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1074086\n",
      "\tspeed: 0.0604s/iter; left time: 250.1104s\n",
      "\titers: 200, epoch: 2 | loss: 0.0952417\n",
      "\tspeed: 0.0233s/iter; left time: 93.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.1087056 Vali Loss: 0.0912250 Test Loss: 0.1036784\n",
      "Validation loss decreased (0.162275 --> 0.091225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0896540\n",
      "\tspeed: 0.0458s/iter; left time: 179.2799s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888033\n",
      "\tspeed: 0.0345s/iter; left time: 131.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0905796 Vali Loss: 0.0868622 Test Loss: 0.0986554\n",
      "Validation loss decreased (0.091225 --> 0.086862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0896549\n",
      "\tspeed: 0.0608s/iter; left time: 224.4141s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831606\n",
      "\tspeed: 0.0311s/iter; left time: 111.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0871482 Vali Loss: 0.0852566 Test Loss: 0.0967489\n",
      "Validation loss decreased (0.086862 --> 0.085257).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867048\n",
      "\tspeed: 0.0555s/iter; left time: 192.4907s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822510\n",
      "\tspeed: 0.0293s/iter; left time: 98.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0852015 Vali Loss: 0.0842187 Test Loss: 0.0956000\n",
      "Validation loss decreased (0.085257 --> 0.084219).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821767\n",
      "\tspeed: 0.0570s/iter; left time: 184.9672s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812441\n",
      "\tspeed: 0.0331s/iter; left time: 104.1651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 223 | Train Loss: 0.0840424 Vali Loss: 0.0838111 Test Loss: 0.0949707\n",
      "Validation loss decreased (0.084219 --> 0.083811).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0849632\n",
      "\tspeed: 0.0585s/iter; left time: 176.9790s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865966\n",
      "\tspeed: 0.0319s/iter; left time: 93.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.0831739 Vali Loss: 0.0836109 Test Loss: 0.0946763\n",
      "Validation loss decreased (0.083811 --> 0.083611).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826017\n",
      "\tspeed: 0.0452s/iter; left time: 126.5638s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872086\n",
      "\tspeed: 0.0229s/iter; left time: 61.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0824814 Vali Loss: 0.0836222 Test Loss: 0.0943728\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0819883\n",
      "\tspeed: 0.0472s/iter; left time: 121.5943s\n",
      "\titers: 200, epoch: 9 | loss: 0.0810876\n",
      "\tspeed: 0.0251s/iter; left time: 62.2676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0819490 Vali Loss: 0.0836817 Test Loss: 0.0945390\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0797654\n",
      "\tspeed: 0.0514s/iter; left time: 121.1090s\n",
      "\titers: 200, epoch: 10 | loss: 0.0800230\n",
      "\tspeed: 0.0262s/iter; left time: 58.9670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0814641 Vali Loss: 0.0834043 Test Loss: 0.0946467\n",
      "Validation loss decreased (0.083611 --> 0.083404).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0814106\n",
      "\tspeed: 0.0443s/iter; left time: 94.4772s\n",
      "\titers: 200, epoch: 11 | loss: 0.0814041\n",
      "\tspeed: 0.0209s/iter; left time: 42.5318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0811022 Vali Loss: 0.0832592 Test Loss: 0.0942038\n",
      "Validation loss decreased (0.083404 --> 0.083259).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0816876\n",
      "\tspeed: 0.0556s/iter; left time: 106.1225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0792565\n",
      "\tspeed: 0.0244s/iter; left time: 44.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0806484 Vali Loss: 0.0833714 Test Loss: 0.0942682\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0848594\n",
      "\tspeed: 0.0447s/iter; left time: 75.3346s\n",
      "\titers: 200, epoch: 13 | loss: 0.0822343\n",
      "\tspeed: 0.0294s/iter; left time: 46.5477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.0803014 Vali Loss: 0.0835582 Test Loss: 0.0945760\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0798232\n",
      "\tspeed: 0.0512s/iter; left time: 74.7839s\n",
      "\titers: 200, epoch: 14 | loss: 0.0771208\n",
      "\tspeed: 0.0234s/iter; left time: 31.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0799772 Vali Loss: 0.0834042 Test Loss: 0.0945561\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0788781\n",
      "\tspeed: 0.0431s/iter; left time: 53.4422s\n",
      "\titers: 200, epoch: 15 | loss: 0.0812524\n",
      "\tspeed: 0.0256s/iter; left time: 29.1773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0796701 Vali Loss: 0.0835115 Test Loss: 0.0951602\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0758907\n",
      "\tspeed: 0.0444s/iter; left time: 45.1199s\n",
      "\titers: 200, epoch: 16 | loss: 0.0802064\n",
      "\tspeed: 0.0216s/iter; left time: 19.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0794595 Vali Loss: 0.0834023 Test Loss: 0.0946738\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020750947296619415, rmse:0.14405189454555511, mae:0.09420380741357803, rse:0.4232114851474762\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:50.96s\n",
      "Intermediate time for ES: 00h:15m:41.67s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1294495\n",
      "\tspeed: 0.0452s/iter; left time: 197.8852s\n",
      "\titers: 200, epoch: 1 | loss: 0.1062147\n",
      "\tspeed: 0.0197s/iter; left time: 84.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.1220942 Vali Loss: 0.1216610 Test Loss: 0.1354970\n",
      "Validation loss decreased (inf --> 0.121661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0639767\n",
      "\tspeed: 0.0435s/iter; left time: 180.7170s\n",
      "\titers: 200, epoch: 2 | loss: 0.0543063\n",
      "\tspeed: 0.0228s/iter; left time: 92.6324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0668089 Vali Loss: 0.0613634 Test Loss: 0.0647360\n",
      "Validation loss decreased (0.121661 --> 0.061363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0503427\n",
      "\tspeed: 0.0483s/iter; left time: 189.8594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0490987\n",
      "\tspeed: 0.0260s/iter; left time: 99.6892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0503591 Vali Loss: 0.0579463 Test Loss: 0.0608869\n",
      "Validation loss decreased (0.061363 --> 0.057946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0471422\n",
      "\tspeed: 0.0513s/iter; left time: 190.2402s\n",
      "\titers: 200, epoch: 4 | loss: 0.0454242\n",
      "\tspeed: 0.0312s/iter; left time: 112.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0475197 Vali Loss: 0.0563043 Test Loss: 0.0594963\n",
      "Validation loss decreased (0.057946 --> 0.056304).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0465195\n",
      "\tspeed: 0.0463s/iter; left time: 161.4687s\n",
      "\titers: 200, epoch: 5 | loss: 0.0459883\n",
      "\tspeed: 0.0265s/iter; left time: 89.7260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0459609 Vali Loss: 0.0547188 Test Loss: 0.0583823\n",
      "Validation loss decreased (0.056304 --> 0.054719).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0444707\n",
      "\tspeed: 0.0510s/iter; left time: 166.4315s\n",
      "\titers: 200, epoch: 6 | loss: 0.0458128\n",
      "\tspeed: 0.0302s/iter; left time: 95.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0449418 Vali Loss: 0.0539698 Test Loss: 0.0577845\n",
      "Validation loss decreased (0.054719 --> 0.053970).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0439692\n",
      "\tspeed: 0.0514s/iter; left time: 156.1797s\n",
      "\titers: 200, epoch: 7 | loss: 0.0433992\n",
      "\tspeed: 0.0274s/iter; left time: 80.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0442236 Vali Loss: 0.0535927 Test Loss: 0.0574142\n",
      "Validation loss decreased (0.053970 --> 0.053593).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0466260\n",
      "\tspeed: 0.0509s/iter; left time: 143.0782s\n",
      "\titers: 200, epoch: 8 | loss: 0.0438989\n",
      "\tspeed: 0.0313s/iter; left time: 84.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0436074 Vali Loss: 0.0532091 Test Loss: 0.0570019\n",
      "Validation loss decreased (0.053593 --> 0.053209).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0432463\n",
      "\tspeed: 0.0455s/iter; left time: 117.7713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0419723\n",
      "\tspeed: 0.0212s/iter; left time: 52.6460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0431866 Vali Loss: 0.0528547 Test Loss: 0.0567240\n",
      "Validation loss decreased (0.053209 --> 0.052855).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0422297\n",
      "\tspeed: 0.0408s/iter; left time: 96.5818s\n",
      "\titers: 200, epoch: 10 | loss: 0.0441075\n",
      "\tspeed: 0.0204s/iter; left time: 46.2142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0428570 Vali Loss: 0.0527033 Test Loss: 0.0564517\n",
      "Validation loss decreased (0.052855 --> 0.052703).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0464948\n",
      "\tspeed: 0.0433s/iter; left time: 92.5983s\n",
      "\titers: 200, epoch: 11 | loss: 0.0453811\n",
      "\tspeed: 0.0230s/iter; left time: 47.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0425816 Vali Loss: 0.0526440 Test Loss: 0.0565030\n",
      "Validation loss decreased (0.052703 --> 0.052644).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0401720\n",
      "\tspeed: 0.0498s/iter; left time: 95.4452s\n",
      "\titers: 200, epoch: 12 | loss: 0.0404212\n",
      "\tspeed: 0.0214s/iter; left time: 38.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0422643 Vali Loss: 0.0522506 Test Loss: 0.0560284\n",
      "Validation loss decreased (0.052644 --> 0.052251).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0415695\n",
      "\tspeed: 0.0457s/iter; left time: 77.4424s\n",
      "\titers: 200, epoch: 13 | loss: 0.0443146\n",
      "\tspeed: 0.0228s/iter; left time: 36.3582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0420859 Vali Loss: 0.0521906 Test Loss: 0.0561989\n",
      "Validation loss decreased (0.052251 --> 0.052191).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0405096\n",
      "\tspeed: 0.0525s/iter; left time: 77.0641s\n",
      "\titers: 200, epoch: 14 | loss: 0.0428962\n",
      "\tspeed: 0.0220s/iter; left time: 30.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0419528 Vali Loss: 0.0521557 Test Loss: 0.0560080\n",
      "Validation loss decreased (0.052191 --> 0.052156).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0439769\n",
      "\tspeed: 0.0453s/iter; left time: 56.4136s\n",
      "\titers: 200, epoch: 15 | loss: 0.0409417\n",
      "\tspeed: 0.0228s/iter; left time: 26.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.0417630 Vali Loss: 0.0522371 Test Loss: 0.0561968\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0415810\n",
      "\tspeed: 0.0468s/iter; left time: 47.8059s\n",
      "\titers: 200, epoch: 16 | loss: 0.0439729\n",
      "\tspeed: 0.0290s/iter; left time: 26.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0416330 Vali Loss: 0.0520897 Test Loss: 0.0559218\n",
      "Validation loss decreased (0.052156 --> 0.052090).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0412142\n",
      "\tspeed: 0.0481s/iter; left time: 38.3743s\n",
      "\titers: 200, epoch: 17 | loss: 0.0391558\n",
      "\tspeed: 0.0253s/iter; left time: 17.6568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0414791 Vali Loss: 0.0520750 Test Loss: 0.0559001\n",
      "Validation loss decreased (0.052090 --> 0.052075).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435842\n",
      "\tspeed: 0.0440s/iter; left time: 25.2178s\n",
      "\titers: 200, epoch: 18 | loss: 0.0409682\n",
      "\tspeed: 0.0329s/iter; left time: 15.5495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0413539 Vali Loss: 0.0520137 Test Loss: 0.0558166\n",
      "Validation loss decreased (0.052075 --> 0.052014).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426775\n",
      "\tspeed: 0.0523s/iter; left time: 18.2624s\n",
      "\titers: 200, epoch: 19 | loss: 0.0413912\n",
      "\tspeed: 0.0297s/iter; left time: 7.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0412634 Vali Loss: 0.0518539 Test Loss: 0.0556660\n",
      "Validation loss decreased (0.052014 --> 0.051854).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0423297\n",
      "\tspeed: 0.0480s/iter; left time: 6.0041s\n",
      "\titers: 200, epoch: 20 | loss: 0.0426290\n",
      "\tspeed: 0.0296s/iter; left time: 0.7401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0411589 Vali Loss: 0.0518800 Test Loss: 0.0556026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010140854865312576, rmse:0.10070180892944336, mae:0.0556659996509552, rse:0.3885048031806946\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1156989\n",
      "\tspeed: 0.0277s/iter; left time: 121.3517s\n",
      "\titers: 200, epoch: 1 | loss: 0.1126049\n",
      "\tspeed: 0.0301s/iter; left time: 129.0326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.1177636 Vali Loss: 0.1186768 Test Loss: 0.1322489\n",
      "Validation loss decreased (inf --> 0.118677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0665713\n",
      "\tspeed: 0.0538s/iter; left time: 223.7167s\n",
      "\titers: 200, epoch: 2 | loss: 0.0572921\n",
      "\tspeed: 0.0291s/iter; left time: 118.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0673499 Vali Loss: 0.0626244 Test Loss: 0.0658060\n",
      "Validation loss decreased (0.118677 --> 0.062624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513267\n",
      "\tspeed: 0.0426s/iter; left time: 167.6615s\n",
      "\titers: 200, epoch: 3 | loss: 0.0495483\n",
      "\tspeed: 0.0202s/iter; left time: 77.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0510713 Vali Loss: 0.0580691 Test Loss: 0.0611644\n",
      "Validation loss decreased (0.062624 --> 0.058069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0493779\n",
      "\tspeed: 0.0542s/iter; left time: 201.1526s\n",
      "\titers: 200, epoch: 4 | loss: 0.0480314\n",
      "\tspeed: 0.0272s/iter; left time: 98.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0478354 Vali Loss: 0.0566307 Test Loss: 0.0597713\n",
      "Validation loss decreased (0.058069 --> 0.056631).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0456753\n",
      "\tspeed: 0.0458s/iter; left time: 159.7061s\n",
      "\titers: 200, epoch: 5 | loss: 0.0481579\n",
      "\tspeed: 0.0202s/iter; left time: 68.5067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0461125 Vali Loss: 0.0552079 Test Loss: 0.0586774\n",
      "Validation loss decreased (0.056631 --> 0.055208).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0433432\n",
      "\tspeed: 0.0507s/iter; left time: 165.4386s\n",
      "\titers: 200, epoch: 6 | loss: 0.0438934\n",
      "\tspeed: 0.0237s/iter; left time: 74.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0449733 Vali Loss: 0.0546046 Test Loss: 0.0581054\n",
      "Validation loss decreased (0.055208 --> 0.054605).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0433763\n",
      "\tspeed: 0.0433s/iter; left time: 131.5622s\n",
      "\titers: 200, epoch: 7 | loss: 0.0434338\n",
      "\tspeed: 0.0203s/iter; left time: 59.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0442060 Vali Loss: 0.0540793 Test Loss: 0.0575524\n",
      "Validation loss decreased (0.054605 --> 0.054079).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0499130\n",
      "\tspeed: 0.0417s/iter; left time: 117.3025s\n",
      "\titers: 200, epoch: 8 | loss: 0.0430701\n",
      "\tspeed: 0.0203s/iter; left time: 54.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0435767 Vali Loss: 0.0535739 Test Loss: 0.0571675\n",
      "Validation loss decreased (0.054079 --> 0.053574).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0390219\n",
      "\tspeed: 0.0494s/iter; left time: 128.0139s\n",
      "\titers: 200, epoch: 9 | loss: 0.0444570\n",
      "\tspeed: 0.0264s/iter; left time: 65.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0432303 Vali Loss: 0.0533335 Test Loss: 0.0570714\n",
      "Validation loss decreased (0.053574 --> 0.053334).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0411982\n",
      "\tspeed: 0.0435s/iter; left time: 102.8776s\n",
      "\titers: 200, epoch: 10 | loss: 0.0398775\n",
      "\tspeed: 0.0215s/iter; left time: 48.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0427857 Vali Loss: 0.0529757 Test Loss: 0.0566004\n",
      "Validation loss decreased (0.053334 --> 0.052976).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0413758\n",
      "\tspeed: 0.0498s/iter; left time: 106.7205s\n",
      "\titers: 200, epoch: 11 | loss: 0.0414854\n",
      "\tspeed: 0.0216s/iter; left time: 44.0622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0424803 Vali Loss: 0.0529616 Test Loss: 0.0566401\n",
      "Validation loss decreased (0.052976 --> 0.052962).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0417593\n",
      "\tspeed: 0.0427s/iter; left time: 81.8265s\n",
      "\titers: 200, epoch: 12 | loss: 0.0413798\n",
      "\tspeed: 0.0203s/iter; left time: 36.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 224 | Train Loss: 0.0422089 Vali Loss: 0.0528429 Test Loss: 0.0567950\n",
      "Validation loss decreased (0.052962 --> 0.052843).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0455193\n",
      "\tspeed: 0.0427s/iter; left time: 72.2999s\n",
      "\titers: 200, epoch: 13 | loss: 0.0427652\n",
      "\tspeed: 0.0209s/iter; left time: 33.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0420843 Vali Loss: 0.0525807 Test Loss: 0.0563995\n",
      "Validation loss decreased (0.052843 --> 0.052581).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0405789\n",
      "\tspeed: 0.0427s/iter; left time: 62.6907s\n",
      "\titers: 200, epoch: 14 | loss: 0.0434480\n",
      "\tspeed: 0.0203s/iter; left time: 27.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0418399 Vali Loss: 0.0524618 Test Loss: 0.0562129\n",
      "Validation loss decreased (0.052581 --> 0.052462).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0381983\n",
      "\tspeed: 0.0424s/iter; left time: 52.8141s\n",
      "\titers: 200, epoch: 15 | loss: 0.0441614\n",
      "\tspeed: 0.0218s/iter; left time: 25.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0416632 Vali Loss: 0.0523744 Test Loss: 0.0561107\n",
      "Validation loss decreased (0.052462 --> 0.052374).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0423018\n",
      "\tspeed: 0.0442s/iter; left time: 45.1116s\n",
      "\titers: 200, epoch: 16 | loss: 0.0433236\n",
      "\tspeed: 0.0294s/iter; left time: 27.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0415048 Vali Loss: 0.0524557 Test Loss: 0.0561790\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0401473\n",
      "\tspeed: 0.0508s/iter; left time: 40.4776s\n",
      "\titers: 200, epoch: 17 | loss: 0.0428792\n",
      "\tspeed: 0.0300s/iter; left time: 20.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0413593 Vali Loss: 0.0523922 Test Loss: 0.0561023\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0436991\n",
      "\tspeed: 0.0453s/iter; left time: 25.9352s\n",
      "\titers: 200, epoch: 18 | loss: 0.0433974\n",
      "\tspeed: 0.0219s/iter; left time: 10.3655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0413004 Vali Loss: 0.0523634 Test Loss: 0.0559128\n",
      "Validation loss decreased (0.052374 --> 0.052363).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0421766\n",
      "\tspeed: 0.0443s/iter; left time: 15.4594s\n",
      "\titers: 200, epoch: 19 | loss: 0.0394853\n",
      "\tspeed: 0.0206s/iter; left time: 5.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0412342 Vali Loss: 0.0522778 Test Loss: 0.0559841\n",
      "Validation loss decreased (0.052363 --> 0.052278).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0417428\n",
      "\tspeed: 0.0467s/iter; left time: 5.8326s\n",
      "\titers: 200, epoch: 20 | loss: 0.0415096\n",
      "\tspeed: 0.0237s/iter; left time: 0.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0410669 Vali Loss: 0.0522418 Test Loss: 0.0558019\n",
      "Validation loss decreased (0.052278 --> 0.052242).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010225116275250912, rmse:0.10111931711435318, mae:0.055801935493946075, rse:0.39011552929878235\n",
      "Intermediate time for FR and pred_len 24: 00h:04m:57.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265848\n",
      "\tspeed: 0.0457s/iter; left time: 200.0147s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160576\n",
      "\tspeed: 0.0233s/iter; left time: 99.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 224 | Train Loss: 0.1267992 Vali Loss: 0.1287320 Test Loss: 0.1445993\n",
      "Validation loss decreased (inf --> 0.128732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707921\n",
      "\tspeed: 0.0549s/iter; left time: 228.1993s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724738\n",
      "\tspeed: 0.0245s/iter; left time: 99.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0796952 Vali Loss: 0.0779081 Test Loss: 0.0857513\n",
      "Validation loss decreased (0.128732 --> 0.077908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656895\n",
      "\tspeed: 0.0518s/iter; left time: 203.7536s\n",
      "\titers: 200, epoch: 3 | loss: 0.0630336\n",
      "\tspeed: 0.0295s/iter; left time: 113.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0653353 Vali Loss: 0.0747998 Test Loss: 0.0834583\n",
      "Validation loss decreased (0.077908 --> 0.074800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0618594\n",
      "\tspeed: 0.0503s/iter; left time: 186.7428s\n",
      "\titers: 200, epoch: 4 | loss: 0.0613811\n",
      "\tspeed: 0.0225s/iter; left time: 81.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0626020 Vali Loss: 0.0735094 Test Loss: 0.0832137\n",
      "Validation loss decreased (0.074800 --> 0.073509).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0624905\n",
      "\tspeed: 0.0508s/iter; left time: 177.0091s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597809\n",
      "\tspeed: 0.0250s/iter; left time: 84.5772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0610879 Vali Loss: 0.0732011 Test Loss: 0.0830770\n",
      "Validation loss decreased (0.073509 --> 0.073201).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602219\n",
      "\tspeed: 0.0536s/iter; left time: 174.9522s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599985\n",
      "\tspeed: 0.0293s/iter; left time: 92.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0601473 Vali Loss: 0.0730911 Test Loss: 0.0830713\n",
      "Validation loss decreased (0.073201 --> 0.073091).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556722\n",
      "\tspeed: 0.0587s/iter; left time: 178.1920s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570081\n",
      "\tspeed: 0.0293s/iter; left time: 86.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0593975 Vali Loss: 0.0728413 Test Loss: 0.0826903\n",
      "Validation loss decreased (0.073091 --> 0.072841).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0607334\n",
      "\tspeed: 0.0622s/iter; left time: 175.0551s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572102\n",
      "\tspeed: 0.0353s/iter; left time: 95.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 224 | Train Loss: 0.0587627 Vali Loss: 0.0727445 Test Loss: 0.0826892\n",
      "Validation loss decreased (0.072841 --> 0.072745).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0568982\n",
      "\tspeed: 0.0554s/iter; left time: 143.4948s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577328\n",
      "\tspeed: 0.0280s/iter; left time: 69.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 224 | Train Loss: 0.0582831 Vali Loss: 0.0729152 Test Loss: 0.0829045\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0607955\n",
      "\tspeed: 0.0571s/iter; left time: 135.0433s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549816\n",
      "\tspeed: 0.0364s/iter; left time: 82.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0578358 Vali Loss: 0.0725348 Test Loss: 0.0823290\n",
      "Validation loss decreased (0.072745 --> 0.072535).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0588676\n",
      "\tspeed: 0.0509s/iter; left time: 109.0688s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556585\n",
      "\tspeed: 0.0292s/iter; left time: 59.6131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0574854 Vali Loss: 0.0724202 Test Loss: 0.0824947\n",
      "Validation loss decreased (0.072535 --> 0.072420).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0541983\n",
      "\tspeed: 0.0549s/iter; left time: 105.2841s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565055\n",
      "\tspeed: 0.0347s/iter; left time: 63.1020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0571298 Vali Loss: 0.0725223 Test Loss: 0.0825608\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571905\n",
      "\tspeed: 0.0630s/iter; left time: 106.6174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0566736\n",
      "\tspeed: 0.0283s/iter; left time: 45.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0568127 Vali Loss: 0.0725568 Test Loss: 0.0825895\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0557126\n",
      "\tspeed: 0.0572s/iter; left time: 84.0172s\n",
      "\titers: 200, epoch: 14 | loss: 0.0527579\n",
      "\tspeed: 0.0337s/iter; left time: 46.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0565760 Vali Loss: 0.0725397 Test Loss: 0.0825762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571562\n",
      "\tspeed: 0.0581s/iter; left time: 72.3470s\n",
      "\titers: 200, epoch: 15 | loss: 0.0557211\n",
      "\tspeed: 0.0326s/iter; left time: 37.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0563037 Vali Loss: 0.0724232 Test Loss: 0.0825011\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0610621\n",
      "\tspeed: 0.0599s/iter; left time: 61.1747s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567887\n",
      "\tspeed: 0.0405s/iter; left time: 37.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 224 | Train Loss: 0.0561308 Vali Loss: 0.0722441 Test Loss: 0.0822556\n",
      "Validation loss decreased (0.072420 --> 0.072244).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0526743\n",
      "\tspeed: 0.0584s/iter; left time: 46.5844s\n",
      "\titers: 200, epoch: 17 | loss: 0.0538024\n",
      "\tspeed: 0.0307s/iter; left time: 21.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 224 | Train Loss: 0.0559952 Vali Loss: 0.0724563 Test Loss: 0.0822722\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0554455\n",
      "\tspeed: 0.0539s/iter; left time: 30.8859s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562438\n",
      "\tspeed: 0.0286s/iter; left time: 13.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0557950 Vali Loss: 0.0726438 Test Loss: 0.0824924\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546079\n",
      "\tspeed: 0.0593s/iter; left time: 20.6804s\n",
      "\titers: 200, epoch: 19 | loss: 0.0550639\n",
      "\tspeed: 0.0348s/iter; left time: 8.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 224 | Train Loss: 0.0556395 Vali Loss: 0.0725970 Test Loss: 0.0822686\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546348\n",
      "\tspeed: 0.0555s/iter; left time: 6.9389s\n",
      "\titers: 200, epoch: 20 | loss: 0.0527595\n",
      "\tspeed: 0.0303s/iter; left time: 0.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0554853 Vali Loss: 0.0723826 Test Loss: 0.0823606\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01943235844373703, rmse:0.13939999043941498, mae:0.08225554972887039, rse:0.5392362475395203\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252755\n",
      "\tspeed: 0.0370s/iter; left time: 162.2644s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177421\n",
      "\tspeed: 0.0297s/iter; left time: 127.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.1265747 Vali Loss: 0.1291795 Test Loss: 0.1450781\n",
      "Validation loss decreased (inf --> 0.129180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0777028\n",
      "\tspeed: 0.0549s/iter; left time: 228.1753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0700571\n",
      "\tspeed: 0.0303s/iter; left time: 122.9208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0804924 Vali Loss: 0.0789985 Test Loss: 0.0866145\n",
      "Validation loss decreased (0.129180 --> 0.078999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0652047\n",
      "\tspeed: 0.0509s/iter; left time: 200.0048s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671842\n",
      "\tspeed: 0.0226s/iter; left time: 86.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0659453 Vali Loss: 0.0751095 Test Loss: 0.0839890\n",
      "Validation loss decreased (0.078999 --> 0.075110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0618653\n",
      "\tspeed: 0.0510s/iter; left time: 189.1001s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625589\n",
      "\tspeed: 0.0315s/iter; left time: 113.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0629832 Vali Loss: 0.0738920 Test Loss: 0.0833610\n",
      "Validation loss decreased (0.075110 --> 0.073892).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602557\n",
      "\tspeed: 0.0618s/iter; left time: 215.3067s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606426\n",
      "\tspeed: 0.0311s/iter; left time: 105.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0612738 Vali Loss: 0.0732520 Test Loss: 0.0831448\n",
      "Validation loss decreased (0.073892 --> 0.073252).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0643058\n",
      "\tspeed: 0.0562s/iter; left time: 183.4094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0566837\n",
      "\tspeed: 0.0369s/iter; left time: 116.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0602414 Vali Loss: 0.0729771 Test Loss: 0.0830028\n",
      "Validation loss decreased (0.073252 --> 0.072977).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0627280\n",
      "\tspeed: 0.0683s/iter; left time: 207.5704s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607288\n",
      "\tspeed: 0.0374s/iter; left time: 109.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 224 | Train Loss: 0.0594454 Vali Loss: 0.0729301 Test Loss: 0.0829592\n",
      "Validation loss decreased (0.072977 --> 0.072930).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563310\n",
      "\tspeed: 0.0572s/iter; left time: 161.0267s\n",
      "\titers: 200, epoch: 8 | loss: 0.0614869\n",
      "\tspeed: 0.0319s/iter; left time: 86.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.0588495 Vali Loss: 0.0727265 Test Loss: 0.0825064\n",
      "Validation loss decreased (0.072930 --> 0.072726).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562903\n",
      "\tspeed: 0.0489s/iter; left time: 126.4999s\n",
      "\titers: 200, epoch: 9 | loss: 0.0605214\n",
      "\tspeed: 0.0263s/iter; left time: 65.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0582757 Vali Loss: 0.0729441 Test Loss: 0.0828436\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0526544\n",
      "\tspeed: 0.0580s/iter; left time: 137.0808s\n",
      "\titers: 200, epoch: 10 | loss: 0.0563431\n",
      "\tspeed: 0.0253s/iter; left time: 57.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.0578484 Vali Loss: 0.0726505 Test Loss: 0.0824824\n",
      "Validation loss decreased (0.072726 --> 0.072651).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0554575\n",
      "\tspeed: 0.0542s/iter; left time: 116.0273s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553810\n",
      "\tspeed: 0.0300s/iter; left time: 61.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0574268 Vali Loss: 0.0728950 Test Loss: 0.0827484\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0610510\n",
      "\tspeed: 0.0578s/iter; left time: 110.8609s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550776\n",
      "\tspeed: 0.0293s/iter; left time: 53.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0570823 Vali Loss: 0.0727692 Test Loss: 0.0823997\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0557465\n",
      "\tspeed: 0.0574s/iter; left time: 97.1006s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579109\n",
      "\tspeed: 0.0253s/iter; left time: 40.2291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 224 | Train Loss: 0.0567732 Vali Loss: 0.0727386 Test Loss: 0.0828238\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575899\n",
      "\tspeed: 0.0577s/iter; left time: 84.7980s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560710\n",
      "\tspeed: 0.0323s/iter; left time: 44.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0564817 Vali Loss: 0.0724824 Test Loss: 0.0824522\n",
      "Validation loss decreased (0.072651 --> 0.072482).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0565562\n",
      "\tspeed: 0.0505s/iter; left time: 62.8627s\n",
      "\titers: 200, epoch: 15 | loss: 0.0549395\n",
      "\tspeed: 0.0329s/iter; left time: 37.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0562620 Vali Loss: 0.0726615 Test Loss: 0.0823244\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550967\n",
      "\tspeed: 0.0595s/iter; left time: 60.7113s\n",
      "\titers: 200, epoch: 16 | loss: 0.0593819\n",
      "\tspeed: 0.0284s/iter; left time: 26.1941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.0560185 Vali Loss: 0.0728865 Test Loss: 0.0830823\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0542303\n",
      "\tspeed: 0.0600s/iter; left time: 47.8429s\n",
      "\titers: 200, epoch: 17 | loss: 0.0569359\n",
      "\tspeed: 0.0345s/iter; left time: 24.0326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0558007 Vali Loss: 0.0726378 Test Loss: 0.0820559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0530904\n",
      "\tspeed: 0.0571s/iter; left time: 32.7015s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574775\n",
      "\tspeed: 0.0325s/iter; left time: 15.3846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0556729 Vali Loss: 0.0727650 Test Loss: 0.0827113\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572736\n",
      "\tspeed: 0.0608s/iter; left time: 21.2225s\n",
      "\titers: 200, epoch: 19 | loss: 0.0519176\n",
      "\tspeed: 0.0417s/iter; left time: 10.3775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0555104 Vali Loss: 0.0728376 Test Loss: 0.0823948\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019553449004888535, rmse:0.13983364403247833, mae:0.08245225250720978, rse:0.5409137010574341\n",
      "Intermediate time for FR and pred_len 96: 00h:05m:50.61s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1297625\n",
      "\tspeed: 0.0500s/iter; left time: 218.1337s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218552\n",
      "\tspeed: 0.0253s/iter; left time: 107.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1276988 Vali Loss: 0.1311957 Test Loss: 0.1463019\n",
      "Validation loss decreased (inf --> 0.131196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0779558\n",
      "\tspeed: 0.0495s/iter; left time: 204.9871s\n",
      "\titers: 200, epoch: 2 | loss: 0.0755704\n",
      "\tspeed: 0.0275s/iter; left time: 111.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0829580 Vali Loss: 0.0812419 Test Loss: 0.0898472\n",
      "Validation loss decreased (0.131196 --> 0.081242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0740079\n",
      "\tspeed: 0.0464s/iter; left time: 181.5831s\n",
      "\titers: 200, epoch: 3 | loss: 0.0690034\n",
      "\tspeed: 0.0221s/iter; left time: 84.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0693732 Vali Loss: 0.0784192 Test Loss: 0.0880657\n",
      "Validation loss decreased (0.081242 --> 0.078419).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0661538\n",
      "\tspeed: 0.0489s/iter; left time: 180.7173s\n",
      "\titers: 200, epoch: 4 | loss: 0.0661210\n",
      "\tspeed: 0.0301s/iter; left time: 108.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0667746 Vali Loss: 0.0778472 Test Loss: 0.0885173\n",
      "Validation loss decreased (0.078419 --> 0.077847).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0631964\n",
      "\tspeed: 0.0618s/iter; left time: 214.3853s\n",
      "\titers: 200, epoch: 5 | loss: 0.0674683\n",
      "\tspeed: 0.0306s/iter; left time: 103.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 223 | Train Loss: 0.0651882 Vali Loss: 0.0775052 Test Loss: 0.0884320\n",
      "Validation loss decreased (0.077847 --> 0.077505).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0702235\n",
      "\tspeed: 0.0471s/iter; left time: 152.8595s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608694\n",
      "\tspeed: 0.0249s/iter; left time: 78.4094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0642429 Vali Loss: 0.0770239 Test Loss: 0.0879949\n",
      "Validation loss decreased (0.077505 --> 0.077024).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0622515\n",
      "\tspeed: 0.0514s/iter; left time: 155.4124s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645545\n",
      "\tspeed: 0.0305s/iter; left time: 89.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0635172 Vali Loss: 0.0770736 Test Loss: 0.0880356\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0612265\n",
      "\tspeed: 0.0522s/iter; left time: 146.2861s\n",
      "\titers: 200, epoch: 8 | loss: 0.0644453\n",
      "\tspeed: 0.0300s/iter; left time: 80.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.0628146 Vali Loss: 0.0768640 Test Loss: 0.0881845\n",
      "Validation loss decreased (0.077024 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604829\n",
      "\tspeed: 0.0520s/iter; left time: 134.1322s\n",
      "\titers: 200, epoch: 9 | loss: 0.0574445\n",
      "\tspeed: 0.0260s/iter; left time: 64.4218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0622101 Vali Loss: 0.0768721 Test Loss: 0.0883375\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0619563\n",
      "\tspeed: 0.0515s/iter; left time: 121.1925s\n",
      "\titers: 200, epoch: 10 | loss: 0.0663133\n",
      "\tspeed: 0.0300s/iter; left time: 67.6341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 223 | Train Loss: 0.0617265 Vali Loss: 0.0767716 Test Loss: 0.0876879\n",
      "Validation loss decreased (0.076864 --> 0.076772).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0590609\n",
      "\tspeed: 0.0551s/iter; left time: 117.3545s\n",
      "\titers: 200, epoch: 11 | loss: 0.0637394\n",
      "\tspeed: 0.0307s/iter; left time: 62.4447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 223 | Train Loss: 0.0612641 Vali Loss: 0.0764794 Test Loss: 0.0883729\n",
      "Validation loss decreased (0.076772 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0604968\n",
      "\tspeed: 0.0576s/iter; left time: 109.9796s\n",
      "\titers: 200, epoch: 12 | loss: 0.0636662\n",
      "\tspeed: 0.0300s/iter; left time: 54.1807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.0608765 Vali Loss: 0.0765738 Test Loss: 0.0885806\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580173\n",
      "\tspeed: 0.0559s/iter; left time: 94.1139s\n",
      "\titers: 200, epoch: 13 | loss: 0.0592753\n",
      "\tspeed: 0.0324s/iter; left time: 51.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 223 | Train Loss: 0.0605181 Vali Loss: 0.0766301 Test Loss: 0.0885519\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0642119\n",
      "\tspeed: 0.0540s/iter; left time: 79.0088s\n",
      "\titers: 200, epoch: 14 | loss: 0.0596652\n",
      "\tspeed: 0.0295s/iter; left time: 40.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0601345 Vali Loss: 0.0768824 Test Loss: 0.0885637\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0595802\n",
      "\tspeed: 0.0542s/iter; left time: 67.2072s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610297\n",
      "\tspeed: 0.0320s/iter; left time: 36.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0599008 Vali Loss: 0.0767296 Test Loss: 0.0886496\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0564703\n",
      "\tspeed: 0.0528s/iter; left time: 53.6243s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578421\n",
      "\tspeed: 0.0335s/iter; left time: 30.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.0596375 Vali Loss: 0.0764678 Test Loss: 0.0891664\n",
      "Validation loss decreased (0.076479 --> 0.076468).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0584689\n",
      "\tspeed: 0.0484s/iter; left time: 38.3835s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588286\n",
      "\tspeed: 0.0247s/iter; left time: 17.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 223 | Train Loss: 0.0594019 Vali Loss: 0.0767071 Test Loss: 0.0888374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0585432\n",
      "\tspeed: 0.0490s/iter; left time: 27.9348s\n",
      "\titers: 200, epoch: 18 | loss: 0.0562324\n",
      "\tspeed: 0.0256s/iter; left time: 12.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0592314 Vali Loss: 0.0767916 Test Loss: 0.0893060\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0569657\n",
      "\tspeed: 0.0524s/iter; left time: 18.1782s\n",
      "\titers: 200, epoch: 19 | loss: 0.0583235\n",
      "\tspeed: 0.0273s/iter; left time: 6.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 223 | Train Loss: 0.0590660 Vali Loss: 0.0766518 Test Loss: 0.0891056\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0585008\n",
      "\tspeed: 0.0572s/iter; left time: 7.0944s\n",
      "\titers: 200, epoch: 20 | loss: 0.0610277\n",
      "\tspeed: 0.0301s/iter; left time: 0.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.0588792 Vali Loss: 0.0769340 Test Loss: 0.0892387\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021859269589185715, rmse:0.14784879982471466, mae:0.08916646987199783, rse:0.5726324319839478\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1307294\n",
      "\tspeed: 0.0259s/iter; left time: 112.9240s\n",
      "\titers: 200, epoch: 1 | loss: 0.1180498\n",
      "\tspeed: 0.0252s/iter; left time: 107.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.1277571 Vali Loss: 0.1306019 Test Loss: 0.1459391\n",
      "Validation loss decreased (inf --> 0.130602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0785018\n",
      "\tspeed: 0.0557s/iter; left time: 230.4090s\n",
      "\titers: 200, epoch: 2 | loss: 0.0721335\n",
      "\tspeed: 0.0295s/iter; left time: 119.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.0832413 Vali Loss: 0.0819843 Test Loss: 0.0902141\n",
      "Validation loss decreased (0.130602 --> 0.081984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0651473\n",
      "\tspeed: 0.0568s/iter; left time: 222.4959s\n",
      "\titers: 200, epoch: 3 | loss: 0.0697175\n",
      "\tspeed: 0.0306s/iter; left time: 116.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 223 | Train Loss: 0.0697501 Vali Loss: 0.0783455 Test Loss: 0.0882071\n",
      "Validation loss decreased (0.081984 --> 0.078345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0683868\n",
      "\tspeed: 0.0582s/iter; left time: 215.0482s\n",
      "\titers: 200, epoch: 4 | loss: 0.0692430\n",
      "\tspeed: 0.0306s/iter; left time: 110.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.0669555 Vali Loss: 0.0775143 Test Loss: 0.0879903\n",
      "Validation loss decreased (0.078345 --> 0.077514).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0681198\n",
      "\tspeed: 0.0540s/iter; left time: 187.2240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626949\n",
      "\tspeed: 0.0256s/iter; left time: 86.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 223 | Train Loss: 0.0653237 Vali Loss: 0.0772944 Test Loss: 0.0877824\n",
      "Validation loss decreased (0.077514 --> 0.077294).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0662500\n",
      "\tspeed: 0.0546s/iter; left time: 177.1976s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653271\n",
      "\tspeed: 0.0303s/iter; left time: 95.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.0643880 Vali Loss: 0.0770352 Test Loss: 0.0877884\n",
      "Validation loss decreased (0.077294 --> 0.077035).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656545\n",
      "\tspeed: 0.0523s/iter; left time: 158.1255s\n",
      "\titers: 200, epoch: 7 | loss: 0.0654096\n",
      "\tspeed: 0.0229s/iter; left time: 66.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.0636389 Vali Loss: 0.0766515 Test Loss: 0.0875135\n",
      "Validation loss decreased (0.077035 --> 0.076651).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0643423\n",
      "\tspeed: 0.0497s/iter; left time: 139.2030s\n",
      "\titers: 200, epoch: 8 | loss: 0.0631188\n",
      "\tspeed: 0.0326s/iter; left time: 88.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0630707 Vali Loss: 0.0767798 Test Loss: 0.0875747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0595275\n",
      "\tspeed: 0.0508s/iter; left time: 130.8310s\n",
      "\titers: 200, epoch: 9 | loss: 0.0649888\n",
      "\tspeed: 0.0250s/iter; left time: 61.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0625001 Vali Loss: 0.0767266 Test Loss: 0.0877923\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0623606\n",
      "\tspeed: 0.0526s/iter; left time: 123.8412s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623257\n",
      "\tspeed: 0.0262s/iter; left time: 58.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0620366 Vali Loss: 0.0763871 Test Loss: 0.0875149\n",
      "Validation loss decreased (0.076651 --> 0.076387).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0651598\n",
      "\tspeed: 0.0582s/iter; left time: 123.9556s\n",
      "\titers: 200, epoch: 11 | loss: 0.0623889\n",
      "\tspeed: 0.0302s/iter; left time: 61.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 223 | Train Loss: 0.0615982 Vali Loss: 0.0767498 Test Loss: 0.0876656\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0589358\n",
      "\tspeed: 0.0563s/iter; left time: 107.3756s\n",
      "\titers: 200, epoch: 12 | loss: 0.0586929\n",
      "\tspeed: 0.0308s/iter; left time: 55.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.0612120 Vali Loss: 0.0763009 Test Loss: 0.0879019\n",
      "Validation loss decreased (0.076387 --> 0.076301).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637620\n",
      "\tspeed: 0.0516s/iter; left time: 86.9097s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602572\n",
      "\tspeed: 0.0308s/iter; left time: 48.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.0608595 Vali Loss: 0.0765384 Test Loss: 0.0877782\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605162\n",
      "\tspeed: 0.0598s/iter; left time: 87.3572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0601249\n",
      "\tspeed: 0.0300s/iter; left time: 40.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 223 | Train Loss: 0.0605626 Vali Loss: 0.0765698 Test Loss: 0.0878827\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0623439\n",
      "\tspeed: 0.0471s/iter; left time: 58.3435s\n",
      "\titers: 200, epoch: 15 | loss: 0.0620373\n",
      "\tspeed: 0.0298s/iter; left time: 33.8998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0602744 Vali Loss: 0.0766484 Test Loss: 0.0876817\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0576993\n",
      "\tspeed: 0.0551s/iter; left time: 56.0005s\n",
      "\titers: 200, epoch: 16 | loss: 0.0606477\n",
      "\tspeed: 0.0239s/iter; left time: 21.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0600479 Vali Loss: 0.0765530 Test Loss: 0.0876996\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0592523\n",
      "\tspeed: 0.0473s/iter; left time: 37.4906s\n",
      "\titers: 200, epoch: 17 | loss: 0.0636494\n",
      "\tspeed: 0.0236s/iter; left time: 16.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0598044 Vali Loss: 0.0766756 Test Loss: 0.0878995\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021330418065190315, rmse:0.146049365401268, mae:0.08790186047554016, rse:0.5656630396842957\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:12.60s\n",
      "Intermediate time for FR: 00h:16m:00.57s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1803285\n",
      "\tspeed: 0.0541s/iter; left time: 236.9474s\n",
      "\titers: 200, epoch: 1 | loss: 0.1561516\n",
      "\tspeed: 0.0323s/iter; left time: 138.4313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.1787327 Vali Loss: 0.1493044 Test Loss: 0.1571240\n",
      "Validation loss decreased (inf --> 0.149304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0884989\n",
      "\tspeed: 0.0536s/iter; left time: 222.7884s\n",
      "\titers: 200, epoch: 2 | loss: 0.0718555\n",
      "\tspeed: 0.0285s/iter; left time: 115.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0935900 Vali Loss: 0.0657520 Test Loss: 0.0689282\n",
      "Validation loss decreased (0.149304 --> 0.065752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0687594\n",
      "\tspeed: 0.0458s/iter; left time: 180.3185s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634412\n",
      "\tspeed: 0.0267s/iter; left time: 102.2886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0670692 Vali Loss: 0.0613089 Test Loss: 0.0642823\n",
      "Validation loss decreased (0.065752 --> 0.061309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647866\n",
      "\tspeed: 0.0455s/iter; left time: 168.5788s\n",
      "\titers: 200, epoch: 4 | loss: 0.0620681\n",
      "\tspeed: 0.0248s/iter; left time: 89.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0628625 Vali Loss: 0.0592713 Test Loss: 0.0624793\n",
      "Validation loss decreased (0.061309 --> 0.059271).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0634824\n",
      "\tspeed: 0.0492s/iter; left time: 171.4466s\n",
      "\titers: 200, epoch: 5 | loss: 0.0559167\n",
      "\tspeed: 0.0267s/iter; left time: 90.2829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0606811 Vali Loss: 0.0583014 Test Loss: 0.0612789\n",
      "Validation loss decreased (0.059271 --> 0.058301).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0618689\n",
      "\tspeed: 0.0512s/iter; left time: 167.0199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0632138\n",
      "\tspeed: 0.0278s/iter; left time: 87.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.0593727 Vali Loss: 0.0572041 Test Loss: 0.0602464\n",
      "Validation loss decreased (0.058301 --> 0.057204).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0580892\n",
      "\tspeed: 0.0563s/iter; left time: 170.9124s\n",
      "\titers: 200, epoch: 7 | loss: 0.0551325\n",
      "\tspeed: 0.0351s/iter; left time: 102.9599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0584159 Vali Loss: 0.0566405 Test Loss: 0.0599954\n",
      "Validation loss decreased (0.057204 --> 0.056640).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596450\n",
      "\tspeed: 0.0434s/iter; left time: 122.1791s\n",
      "\titers: 200, epoch: 8 | loss: 0.0521865\n",
      "\tspeed: 0.0209s/iter; left time: 56.7987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0576568 Vali Loss: 0.0563623 Test Loss: 0.0592458\n",
      "Validation loss decreased (0.056640 --> 0.056362).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0588039\n",
      "\tspeed: 0.0493s/iter; left time: 127.7156s\n",
      "\titers: 200, epoch: 9 | loss: 0.0572356\n",
      "\tspeed: 0.0297s/iter; left time: 73.8034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0571365 Vali Loss: 0.0558992 Test Loss: 0.0588940\n",
      "Validation loss decreased (0.056362 --> 0.055899).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591912\n",
      "\tspeed: 0.0501s/iter; left time: 118.5395s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584814\n",
      "\tspeed: 0.0309s/iter; left time: 69.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0566877 Vali Loss: 0.0556870 Test Loss: 0.0587829\n",
      "Validation loss decreased (0.055899 --> 0.055687).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596775\n",
      "\tspeed: 0.0425s/iter; left time: 90.8950s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567011\n",
      "\tspeed: 0.0202s/iter; left time: 41.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0563323 Vali Loss: 0.0555266 Test Loss: 0.0586415\n",
      "Validation loss decreased (0.055687 --> 0.055527).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561975\n",
      "\tspeed: 0.0449s/iter; left time: 85.9925s\n",
      "\titers: 200, epoch: 12 | loss: 0.0497049\n",
      "\tspeed: 0.0238s/iter; left time: 43.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0560005 Vali Loss: 0.0553365 Test Loss: 0.0585531\n",
      "Validation loss decreased (0.055527 --> 0.055336).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533420\n",
      "\tspeed: 0.0464s/iter; left time: 78.5389s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536150\n",
      "\tspeed: 0.0235s/iter; left time: 37.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0556909 Vali Loss: 0.0552049 Test Loss: 0.0582373\n",
      "Validation loss decreased (0.055336 --> 0.055205).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0551642\n",
      "\tspeed: 0.0540s/iter; left time: 79.3076s\n",
      "\titers: 200, epoch: 14 | loss: 0.0565335\n",
      "\tspeed: 0.0292s/iter; left time: 39.9384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0555313 Vali Loss: 0.0551372 Test Loss: 0.0581639\n",
      "Validation loss decreased (0.055205 --> 0.055137).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0547692\n",
      "\tspeed: 0.0574s/iter; left time: 71.4258s\n",
      "\titers: 200, epoch: 15 | loss: 0.0579177\n",
      "\tspeed: 0.0338s/iter; left time: 38.6950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0554094 Vali Loss: 0.0549491 Test Loss: 0.0580422\n",
      "Validation loss decreased (0.055137 --> 0.054949).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574420\n",
      "\tspeed: 0.0498s/iter; left time: 50.8569s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558785\n",
      "\tspeed: 0.0266s/iter; left time: 24.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0552002 Vali Loss: 0.0549935 Test Loss: 0.0580523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0573268\n",
      "\tspeed: 0.0592s/iter; left time: 47.1883s\n",
      "\titers: 200, epoch: 17 | loss: 0.0564547\n",
      "\tspeed: 0.0302s/iter; left time: 21.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0549727 Vali Loss: 0.0550069 Test Loss: 0.0578836\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0557826\n",
      "\tspeed: 0.0506s/iter; left time: 28.9885s\n",
      "\titers: 200, epoch: 18 | loss: 0.0533563\n",
      "\tspeed: 0.0302s/iter; left time: 14.2691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.0548400 Vali Loss: 0.0548707 Test Loss: 0.0577691\n",
      "Validation loss decreased (0.054949 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0552048\n",
      "\tspeed: 0.0468s/iter; left time: 16.3162s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570209\n",
      "\tspeed: 0.0254s/iter; left time: 6.3295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0547510 Vali Loss: 0.0548125 Test Loss: 0.0577676\n",
      "Validation loss decreased (0.054871 --> 0.054812).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546754\n",
      "\tspeed: 0.0537s/iter; left time: 6.7063s\n",
      "\titers: 200, epoch: 20 | loss: 0.0541841\n",
      "\tspeed: 0.0299s/iter; left time: 0.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0547040 Vali Loss: 0.0546349 Test Loss: 0.0576870\n",
      "Validation loss decreased (0.054812 --> 0.054635).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010263843461871147, rmse:0.1013106256723404, mae:0.057687003165483475, rse:0.3828029930591583\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1748176\n",
      "\tspeed: 0.0256s/iter; left time: 112.2929s\n",
      "\titers: 200, epoch: 1 | loss: 0.1604554\n",
      "\tspeed: 0.0263s/iter; left time: 112.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.1724834 Vali Loss: 0.1453608 Test Loss: 0.1526962\n",
      "Validation loss decreased (inf --> 0.145361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907714\n",
      "\tspeed: 0.0578s/iter; left time: 240.4169s\n",
      "\titers: 200, epoch: 2 | loss: 0.0750888\n",
      "\tspeed: 0.0247s/iter; left time: 100.1384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0943206 Vali Loss: 0.0673051 Test Loss: 0.0703402\n",
      "Validation loss decreased (0.145361 --> 0.067305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0645738\n",
      "\tspeed: 0.0532s/iter; left time: 209.2469s\n",
      "\titers: 200, epoch: 3 | loss: 0.0629438\n",
      "\tspeed: 0.0230s/iter; left time: 87.9942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0683002 Vali Loss: 0.0617943 Test Loss: 0.0650749\n",
      "Validation loss decreased (0.067305 --> 0.061794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0578337\n",
      "\tspeed: 0.0519s/iter; left time: 192.4436s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635780\n",
      "\tspeed: 0.0303s/iter; left time: 109.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0636387 Vali Loss: 0.0593566 Test Loss: 0.0627842\n",
      "Validation loss decreased (0.061794 --> 0.059357).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600169\n",
      "\tspeed: 0.0445s/iter; left time: 154.9405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0594396\n",
      "\tspeed: 0.0188s/iter; left time: 63.6084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0611824 Vali Loss: 0.0580568 Test Loss: 0.0613618\n",
      "Validation loss decreased (0.059357 --> 0.058057).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569750\n",
      "\tspeed: 0.0566s/iter; left time: 184.7134s\n",
      "\titers: 200, epoch: 6 | loss: 0.0581864\n",
      "\tspeed: 0.0280s/iter; left time: 88.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0597106 Vali Loss: 0.0572314 Test Loss: 0.0604894\n",
      "Validation loss decreased (0.058057 --> 0.057231).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562898\n",
      "\tspeed: 0.0517s/iter; left time: 157.0327s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583714\n",
      "\tspeed: 0.0333s/iter; left time: 97.8519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.0586403 Vali Loss: 0.0567161 Test Loss: 0.0599390\n",
      "Validation loss decreased (0.057231 --> 0.056716).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0587929\n",
      "\tspeed: 0.0498s/iter; left time: 140.1559s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572564\n",
      "\tspeed: 0.0298s/iter; left time: 80.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.0579431 Vali Loss: 0.0562614 Test Loss: 0.0595006\n",
      "Validation loss decreased (0.056716 --> 0.056261).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571081\n",
      "\tspeed: 0.0505s/iter; left time: 130.8685s\n",
      "\titers: 200, epoch: 9 | loss: 0.0570041\n",
      "\tspeed: 0.0262s/iter; left time: 65.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0573265 Vali Loss: 0.0559593 Test Loss: 0.0591668\n",
      "Validation loss decreased (0.056261 --> 0.055959).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576447\n",
      "\tspeed: 0.0515s/iter; left time: 121.8524s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589789\n",
      "\tspeed: 0.0324s/iter; left time: 73.3892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0568582 Vali Loss: 0.0556057 Test Loss: 0.0590149\n",
      "Validation loss decreased (0.055959 --> 0.055606).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585090\n",
      "\tspeed: 0.0541s/iter; left time: 115.8209s\n",
      "\titers: 200, epoch: 11 | loss: 0.0582005\n",
      "\tspeed: 0.0265s/iter; left time: 54.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0565893 Vali Loss: 0.0553864 Test Loss: 0.0585763\n",
      "Validation loss decreased (0.055606 --> 0.055386).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0534899\n",
      "\tspeed: 0.0466s/iter; left time: 89.3860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0588524\n",
      "\tspeed: 0.0303s/iter; left time: 55.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0561565 Vali Loss: 0.0552892 Test Loss: 0.0583881\n",
      "Validation loss decreased (0.055386 --> 0.055289).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552472\n",
      "\tspeed: 0.0584s/iter; left time: 98.8064s\n",
      "\titers: 200, epoch: 13 | loss: 0.0548960\n",
      "\tspeed: 0.0278s/iter; left time: 44.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0559186 Vali Loss: 0.0552087 Test Loss: 0.0583677\n",
      "Validation loss decreased (0.055289 --> 0.055209).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0573418\n",
      "\tspeed: 0.0486s/iter; left time: 71.4656s\n",
      "\titers: 200, epoch: 14 | loss: 0.0608316\n",
      "\tspeed: 0.0247s/iter; left time: 33.7609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0556653 Vali Loss: 0.0550338 Test Loss: 0.0582229\n",
      "Validation loss decreased (0.055209 --> 0.055034).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0565656\n",
      "\tspeed: 0.0523s/iter; left time: 65.1309s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532348\n",
      "\tspeed: 0.0305s/iter; left time: 34.9454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0554400 Vali Loss: 0.0547852 Test Loss: 0.0580902\n",
      "Validation loss decreased (0.055034 --> 0.054785).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0576807\n",
      "\tspeed: 0.0480s/iter; left time: 48.9692s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561692\n",
      "\tspeed: 0.0236s/iter; left time: 21.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0551736 Vali Loss: 0.0547484 Test Loss: 0.0579829\n",
      "Validation loss decreased (0.054785 --> 0.054748).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0523255\n",
      "\tspeed: 0.0464s/iter; left time: 36.9972s\n",
      "\titers: 200, epoch: 17 | loss: 0.0570813\n",
      "\tspeed: 0.0275s/iter; left time: 19.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0550855 Vali Loss: 0.0547416 Test Loss: 0.0579592\n",
      "Validation loss decreased (0.054748 --> 0.054742).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0594292\n",
      "\tspeed: 0.0487s/iter; left time: 27.9068s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543789\n",
      "\tspeed: 0.0236s/iter; left time: 11.1415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0549851 Vali Loss: 0.0545977 Test Loss: 0.0579616\n",
      "Validation loss decreased (0.054742 --> 0.054598).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0561446\n",
      "\tspeed: 0.0605s/iter; left time: 21.1225s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542956\n",
      "\tspeed: 0.0334s/iter; left time: 8.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0548294 Vali Loss: 0.0546343 Test Loss: 0.0578962\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542588\n",
      "\tspeed: 0.0593s/iter; left time: 7.4071s\n",
      "\titers: 200, epoch: 20 | loss: 0.0597184\n",
      "\tspeed: 0.0304s/iter; left time: 0.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 224 | Train Loss: 0.0546439 Vali Loss: 0.0545661 Test Loss: 0.0578418\n",
      "Validation loss decreased (0.054598 --> 0.054566).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010255648754537106, rmse:0.1012701764702797, mae:0.05784180760383606, rse:0.3826501667499542\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:25.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1897424\n",
      "\tspeed: 0.0489s/iter; left time: 214.1836s\n",
      "\titers: 200, epoch: 1 | loss: 0.1660296\n",
      "\tspeed: 0.0290s/iter; left time: 124.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.1848700 Vali Loss: 0.1568288 Test Loss: 0.1659999\n",
      "Validation loss decreased (inf --> 0.156829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024169\n",
      "\tspeed: 0.0463s/iter; left time: 192.3558s\n",
      "\titers: 200, epoch: 2 | loss: 0.0910956\n",
      "\tspeed: 0.0202s/iter; left time: 82.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.1107622 Vali Loss: 0.0839978 Test Loss: 0.0893387\n",
      "Validation loss decreased (0.156829 --> 0.083998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0877967\n",
      "\tspeed: 0.0491s/iter; left time: 192.9831s\n",
      "\titers: 200, epoch: 3 | loss: 0.0845751\n",
      "\tspeed: 0.0307s/iter; left time: 117.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0868382 Vali Loss: 0.0797890 Test Loss: 0.0855101\n",
      "Validation loss decreased (0.083998 --> 0.079789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0832801\n",
      "\tspeed: 0.0536s/iter; left time: 198.9739s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838606\n",
      "\tspeed: 0.0287s/iter; left time: 103.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0830027 Vali Loss: 0.0779550 Test Loss: 0.0838770\n",
      "Validation loss decreased (0.079789 --> 0.077955).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836165\n",
      "\tspeed: 0.0560s/iter; left time: 194.9925s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807150\n",
      "\tspeed: 0.0286s/iter; left time: 96.9442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0807142 Vali Loss: 0.0771537 Test Loss: 0.0831487\n",
      "Validation loss decreased (0.077955 --> 0.077154).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791843\n",
      "\tspeed: 0.0465s/iter; left time: 151.5870s\n",
      "\titers: 200, epoch: 6 | loss: 0.0823486\n",
      "\tspeed: 0.0229s/iter; left time: 72.3507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0791624 Vali Loss: 0.0759724 Test Loss: 0.0820996\n",
      "Validation loss decreased (0.077154 --> 0.075972).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0760478\n",
      "\tspeed: 0.0513s/iter; left time: 155.7254s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799497\n",
      "\tspeed: 0.0242s/iter; left time: 71.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0779178 Vali Loss: 0.0754273 Test Loss: 0.0814582\n",
      "Validation loss decreased (0.075972 --> 0.075427).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771076\n",
      "\tspeed: 0.0553s/iter; left time: 155.5531s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778728\n",
      "\tspeed: 0.0332s/iter; left time: 90.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0770985 Vali Loss: 0.0752305 Test Loss: 0.0811528\n",
      "Validation loss decreased (0.075427 --> 0.075231).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780314\n",
      "\tspeed: 0.0599s/iter; left time: 155.1486s\n",
      "\titers: 200, epoch: 9 | loss: 0.0764838\n",
      "\tspeed: 0.0338s/iter; left time: 84.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0764028 Vali Loss: 0.0753533 Test Loss: 0.0808745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0785056\n",
      "\tspeed: 0.0518s/iter; left time: 122.5596s\n",
      "\titers: 200, epoch: 10 | loss: 0.0828919\n",
      "\tspeed: 0.0272s/iter; left time: 61.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0759053 Vali Loss: 0.0748969 Test Loss: 0.0806462\n",
      "Validation loss decreased (0.075231 --> 0.074897).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739013\n",
      "\tspeed: 0.0505s/iter; left time: 108.2238s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738992\n",
      "\tspeed: 0.0280s/iter; left time: 57.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0754611 Vali Loss: 0.0747856 Test Loss: 0.0804091\n",
      "Validation loss decreased (0.074897 --> 0.074786).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0753315\n",
      "\tspeed: 0.0449s/iter; left time: 86.0923s\n",
      "\titers: 200, epoch: 12 | loss: 0.0744555\n",
      "\tspeed: 0.0280s/iter; left time: 50.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0751179 Vali Loss: 0.0747633 Test Loss: 0.0803175\n",
      "Validation loss decreased (0.074786 --> 0.074763).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0761819\n",
      "\tspeed: 0.0441s/iter; left time: 74.7003s\n",
      "\titers: 200, epoch: 13 | loss: 0.0746646\n",
      "\tspeed: 0.0267s/iter; left time: 42.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0746043 Vali Loss: 0.0748485 Test Loss: 0.0802644\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0739487\n",
      "\tspeed: 0.0558s/iter; left time: 81.9199s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754596\n",
      "\tspeed: 0.0285s/iter; left time: 39.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0742950 Vali Loss: 0.0747813 Test Loss: 0.0801432\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745794\n",
      "\tspeed: 0.0470s/iter; left time: 58.5206s\n",
      "\titers: 200, epoch: 15 | loss: 0.0730356\n",
      "\tspeed: 0.0321s/iter; left time: 36.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0740151 Vali Loss: 0.0747088 Test Loss: 0.0800761\n",
      "Validation loss decreased (0.074763 --> 0.074709).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0738461\n",
      "\tspeed: 0.0536s/iter; left time: 54.7089s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740163\n",
      "\tspeed: 0.0264s/iter; left time: 24.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0737508 Vali Loss: 0.0748973 Test Loss: 0.0801656\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0755595\n",
      "\tspeed: 0.0569s/iter; left time: 45.3532s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715953\n",
      "\tspeed: 0.0263s/iter; left time: 18.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0735619 Vali Loss: 0.0748916 Test Loss: 0.0801487\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721768\n",
      "\tspeed: 0.0483s/iter; left time: 27.6621s\n",
      "\titers: 200, epoch: 18 | loss: 0.0739127\n",
      "\tspeed: 0.0236s/iter; left time: 11.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0732374 Vali Loss: 0.0749033 Test Loss: 0.0800379\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716102\n",
      "\tspeed: 0.0433s/iter; left time: 15.0971s\n",
      "\titers: 200, epoch: 19 | loss: 0.0738876\n",
      "\tspeed: 0.0205s/iter; left time: 5.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0731215 Vali Loss: 0.0749334 Test Loss: 0.0801609\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0754706\n",
      "\tspeed: 0.0463s/iter; left time: 5.7848s\n",
      "\titers: 200, epoch: 20 | loss: 0.0715530\n",
      "\tspeed: 0.0287s/iter; left time: 0.7187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0729291 Vali Loss: 0.0750122 Test Loss: 0.0800666\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018337104469537735, rmse:0.13541457056999207, mae:0.08007606863975525, rse:0.5120170712471008\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1848896\n",
      "\tspeed: 0.0322s/iter; left time: 141.0848s\n",
      "\titers: 200, epoch: 1 | loss: 0.1702881\n",
      "\tspeed: 0.0246s/iter; left time: 105.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.1839626 Vali Loss: 0.1566620 Test Loss: 0.1656541\n",
      "Validation loss decreased (inf --> 0.156662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052182\n",
      "\tspeed: 0.0486s/iter; left time: 201.8253s\n",
      "\titers: 200, epoch: 2 | loss: 0.0916617\n",
      "\tspeed: 0.0283s/iter; left time: 114.7787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1117930 Vali Loss: 0.0850417 Test Loss: 0.0903111\n",
      "Validation loss decreased (0.156662 --> 0.085042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0841488\n",
      "\tspeed: 0.0499s/iter; left time: 196.2220s\n",
      "\titers: 200, epoch: 3 | loss: 0.0864988\n",
      "\tspeed: 0.0260s/iter; left time: 99.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0872875 Vali Loss: 0.0798249 Test Loss: 0.0858153\n",
      "Validation loss decreased (0.085042 --> 0.079825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820333\n",
      "\tspeed: 0.0501s/iter; left time: 185.9735s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806281\n",
      "\tspeed: 0.0321s/iter; left time: 115.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0831388 Vali Loss: 0.0777901 Test Loss: 0.0841360\n",
      "Validation loss decreased (0.079825 --> 0.077790).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0814946\n",
      "\tspeed: 0.0491s/iter; left time: 171.1271s\n",
      "\titers: 200, epoch: 5 | loss: 0.0829391\n",
      "\tspeed: 0.0277s/iter; left time: 93.9171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0807499 Vali Loss: 0.0768962 Test Loss: 0.0834245\n",
      "Validation loss decreased (0.077790 --> 0.076896).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0780942\n",
      "\tspeed: 0.0540s/iter; left time: 176.0817s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756233\n",
      "\tspeed: 0.0205s/iter; left time: 64.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0792229 Vali Loss: 0.0761550 Test Loss: 0.0826469\n",
      "Validation loss decreased (0.076896 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815455\n",
      "\tspeed: 0.0580s/iter; left time: 176.2833s\n",
      "\titers: 200, epoch: 7 | loss: 0.0749220\n",
      "\tspeed: 0.0268s/iter; left time: 78.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0781923 Vali Loss: 0.0757254 Test Loss: 0.0822483\n",
      "Validation loss decreased (0.076155 --> 0.075725).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725536\n",
      "\tspeed: 0.0454s/iter; left time: 127.6649s\n",
      "\titers: 200, epoch: 8 | loss: 0.0816789\n",
      "\tspeed: 0.0284s/iter; left time: 77.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0773640 Vali Loss: 0.0755222 Test Loss: 0.0820925\n",
      "Validation loss decreased (0.075725 --> 0.075522).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729998\n",
      "\tspeed: 0.0548s/iter; left time: 141.9775s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779591\n",
      "\tspeed: 0.0262s/iter; left time: 65.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0767070 Vali Loss: 0.0751880 Test Loss: 0.0818229\n",
      "Validation loss decreased (0.075522 --> 0.075188).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747287\n",
      "\tspeed: 0.0536s/iter; left time: 126.7644s\n",
      "\titers: 200, epoch: 10 | loss: 0.0773368\n",
      "\tspeed: 0.0297s/iter; left time: 67.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0761678 Vali Loss: 0.0748941 Test Loss: 0.0814742\n",
      "Validation loss decreased (0.075188 --> 0.074894).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0752597\n",
      "\tspeed: 0.0595s/iter; left time: 127.4540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774656\n",
      "\tspeed: 0.0302s/iter; left time: 61.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0756531 Vali Loss: 0.0746970 Test Loss: 0.0814151\n",
      "Validation loss decreased (0.074894 --> 0.074697).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0753434\n",
      "\tspeed: 0.0600s/iter; left time: 114.9880s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704508\n",
      "\tspeed: 0.0300s/iter; left time: 54.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 224 | Train Loss: 0.0752868 Vali Loss: 0.0746100 Test Loss: 0.0811851\n",
      "Validation loss decreased (0.074697 --> 0.074610).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0756183\n",
      "\tspeed: 0.0520s/iter; left time: 88.0355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0807456\n",
      "\tspeed: 0.0207s/iter; left time: 32.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0748513 Vali Loss: 0.0744771 Test Loss: 0.0812228\n",
      "Validation loss decreased (0.074610 --> 0.074477).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773405\n",
      "\tspeed: 0.0525s/iter; left time: 77.1740s\n",
      "\titers: 200, epoch: 14 | loss: 0.0720738\n",
      "\tspeed: 0.0260s/iter; left time: 35.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0744754 Vali Loss: 0.0746097 Test Loss: 0.0814365\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0762251\n",
      "\tspeed: 0.0492s/iter; left time: 61.3008s\n",
      "\titers: 200, epoch: 15 | loss: 0.0699799\n",
      "\tspeed: 0.0250s/iter; left time: 28.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0741833 Vali Loss: 0.0745790 Test Loss: 0.0813912\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703396\n",
      "\tspeed: 0.0466s/iter; left time: 47.5663s\n",
      "\titers: 200, epoch: 16 | loss: 0.0742892\n",
      "\tspeed: 0.0273s/iter; left time: 25.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 224 | Train Loss: 0.0738830 Vali Loss: 0.0745625 Test Loss: 0.0813043\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0726125\n",
      "\tspeed: 0.0457s/iter; left time: 36.4209s\n",
      "\titers: 200, epoch: 17 | loss: 0.0737094\n",
      "\tspeed: 0.0208s/iter; left time: 14.4794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0735999 Vali Loss: 0.0745103 Test Loss: 0.0813766\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0757006\n",
      "\tspeed: 0.0588s/iter; left time: 33.6897s\n",
      "\titers: 200, epoch: 18 | loss: 0.0697500\n",
      "\tspeed: 0.0264s/iter; left time: 12.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 224 | Train Loss: 0.0733262 Vali Loss: 0.0744833 Test Loss: 0.0813951\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018741896376013756, rmse:0.13690105080604553, mae:0.08122283220291138, rse:0.5176376104354858\n",
      "Intermediate time for IT and pred_len 96: 00h:05m:08.73s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1871080\n",
      "\tspeed: 0.0507s/iter; left time: 221.0081s\n",
      "\titers: 200, epoch: 1 | loss: 0.1701941\n",
      "\tspeed: 0.0283s/iter; left time: 120.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.1848148 Vali Loss: 0.1584008 Test Loss: 0.1668562\n",
      "Validation loss decreased (inf --> 0.158401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1082211\n",
      "\tspeed: 0.0479s/iter; left time: 198.1291s\n",
      "\titers: 200, epoch: 2 | loss: 0.0961469\n",
      "\tspeed: 0.0218s/iter; left time: 87.9943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.1135394 Vali Loss: 0.0881948 Test Loss: 0.0930001\n",
      "Validation loss decreased (0.158401 --> 0.088195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899713\n",
      "\tspeed: 0.0483s/iter; left time: 189.0131s\n",
      "\titers: 200, epoch: 3 | loss: 0.0872674\n",
      "\tspeed: 0.0265s/iter; left time: 101.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0908954 Vali Loss: 0.0842529 Test Loss: 0.0897564\n",
      "Validation loss decreased (0.088195 --> 0.084253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878746\n",
      "\tspeed: 0.0512s/iter; left time: 189.1105s\n",
      "\titers: 200, epoch: 4 | loss: 0.0890932\n",
      "\tspeed: 0.0217s/iter; left time: 77.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0872191 Vali Loss: 0.0827244 Test Loss: 0.0881889\n",
      "Validation loss decreased (0.084253 --> 0.082724).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0804994\n",
      "\tspeed: 0.0507s/iter; left time: 175.7300s\n",
      "\titers: 200, epoch: 5 | loss: 0.0868201\n",
      "\tspeed: 0.0192s/iter; left time: 64.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0849675 Vali Loss: 0.0816579 Test Loss: 0.0870870\n",
      "Validation loss decreased (0.082724 --> 0.081658).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0877921\n",
      "\tspeed: 0.0498s/iter; left time: 161.7249s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802644\n",
      "\tspeed: 0.0191s/iter; left time: 60.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0834004 Vali Loss: 0.0816223 Test Loss: 0.0867260\n",
      "Validation loss decreased (0.081658 --> 0.081622).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0802745\n",
      "\tspeed: 0.0521s/iter; left time: 157.5878s\n",
      "\titers: 200, epoch: 7 | loss: 0.0880157\n",
      "\tspeed: 0.0288s/iter; left time: 84.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0822841 Vali Loss: 0.0809245 Test Loss: 0.0860589\n",
      "Validation loss decreased (0.081622 --> 0.080924).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823588\n",
      "\tspeed: 0.0474s/iter; left time: 132.7456s\n",
      "\titers: 200, epoch: 8 | loss: 0.0811449\n",
      "\tspeed: 0.0205s/iter; left time: 55.4086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0813769 Vali Loss: 0.0811670 Test Loss: 0.0860912\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778788\n",
      "\tspeed: 0.0438s/iter; left time: 112.8295s\n",
      "\titers: 200, epoch: 9 | loss: 0.0804173\n",
      "\tspeed: 0.0253s/iter; left time: 62.6242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0806823 Vali Loss: 0.0805403 Test Loss: 0.0857278\n",
      "Validation loss decreased (0.080924 --> 0.080540).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0770819\n",
      "\tspeed: 0.0465s/iter; left time: 109.4804s\n",
      "\titers: 200, epoch: 10 | loss: 0.0826294\n",
      "\tspeed: 0.0224s/iter; left time: 50.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0801259 Vali Loss: 0.0807335 Test Loss: 0.0857788\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796840\n",
      "\tspeed: 0.0504s/iter; left time: 107.3052s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764318\n",
      "\tspeed: 0.0287s/iter; left time: 58.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0794757 Vali Loss: 0.0806652 Test Loss: 0.0857937\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0779649\n",
      "\tspeed: 0.0457s/iter; left time: 87.2256s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754844\n",
      "\tspeed: 0.0252s/iter; left time: 45.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0789886 Vali Loss: 0.0805692 Test Loss: 0.0857285\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0795467\n",
      "\tspeed: 0.0548s/iter; left time: 92.2921s\n",
      "\titers: 200, epoch: 13 | loss: 0.0763251\n",
      "\tspeed: 0.0308s/iter; left time: 48.7701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 223 | Train Loss: 0.0785508 Vali Loss: 0.0807191 Test Loss: 0.0858291\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0554s/iter; left time: 80.9855s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791975\n",
      "\tspeed: 0.0302s/iter; left time: 41.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.0781226 Vali Loss: 0.0805922 Test Loss: 0.0856806\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019921839237213135, rmse:0.1411447525024414, mae:0.08572778850793839, rse:0.5341794490814209\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1849068\n",
      "\tspeed: 0.0405s/iter; left time: 176.7605s\n",
      "\titers: 200, epoch: 1 | loss: 0.1685807\n",
      "\tspeed: 0.0361s/iter; left time: 153.9972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 223 | Train Loss: 0.1846713 Vali Loss: 0.1577873 Test Loss: 0.1660891\n",
      "Validation loss decreased (inf --> 0.157787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1045911\n",
      "\tspeed: 0.0572s/iter; left time: 236.5925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949796\n",
      "\tspeed: 0.0279s/iter; left time: 112.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 223 | Train Loss: 0.1138509 Vali Loss: 0.0886006 Test Loss: 0.0937042\n",
      "Validation loss decreased (0.157787 --> 0.088601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0948578\n",
      "\tspeed: 0.0569s/iter; left time: 222.9296s\n",
      "\titers: 200, epoch: 3 | loss: 0.0875881\n",
      "\tspeed: 0.0302s/iter; left time: 115.2123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.0914499 Vali Loss: 0.0846576 Test Loss: 0.0900654\n",
      "Validation loss decreased (0.088601 --> 0.084658).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856811\n",
      "\tspeed: 0.0595s/iter; left time: 219.7368s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876901\n",
      "\tspeed: 0.0320s/iter; left time: 114.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 223 | Train Loss: 0.0877011 Vali Loss: 0.0831210 Test Loss: 0.0885521\n",
      "Validation loss decreased (0.084658 --> 0.083121).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0841582\n",
      "\tspeed: 0.0594s/iter; left time: 206.0744s\n",
      "\titers: 200, epoch: 5 | loss: 0.0856197\n",
      "\tspeed: 0.0297s/iter; left time: 99.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0850402 Vali Loss: 0.0818794 Test Loss: 0.0873512\n",
      "Validation loss decreased (0.083121 --> 0.081879).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0818212\n",
      "\tspeed: 0.0612s/iter; left time: 198.6696s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813358\n",
      "\tspeed: 0.0317s/iter; left time: 99.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.0834159 Vali Loss: 0.0816959 Test Loss: 0.0868120\n",
      "Validation loss decreased (0.081879 --> 0.081696).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801502\n",
      "\tspeed: 0.0618s/iter; left time: 186.8518s\n",
      "\titers: 200, epoch: 7 | loss: 0.0789587\n",
      "\tspeed: 0.0337s/iter; left time: 98.3678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 223 | Train Loss: 0.0822746 Vali Loss: 0.0814660 Test Loss: 0.0865260\n",
      "Validation loss decreased (0.081696 --> 0.081466).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0817945\n",
      "\tspeed: 0.0573s/iter; left time: 160.3820s\n",
      "\titers: 200, epoch: 8 | loss: 0.0821537\n",
      "\tspeed: 0.0284s/iter; left time: 76.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 223 | Train Loss: 0.0812834 Vali Loss: 0.0814090 Test Loss: 0.0864545\n",
      "Validation loss decreased (0.081466 --> 0.081409).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0799169\n",
      "\tspeed: 0.0564s/iter; left time: 145.2267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813630\n",
      "\tspeed: 0.0274s/iter; left time: 67.7528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0804551 Vali Loss: 0.0810828 Test Loss: 0.0860351\n",
      "Validation loss decreased (0.081409 --> 0.081083).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793515\n",
      "\tspeed: 0.0489s/iter; left time: 115.0307s\n",
      "\titers: 200, epoch: 10 | loss: 0.0807153\n",
      "\tspeed: 0.0223s/iter; left time: 50.2003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0797932 Vali Loss: 0.0814308 Test Loss: 0.0862978\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0776108\n",
      "\tspeed: 0.0555s/iter; left time: 118.2987s\n",
      "\titers: 200, epoch: 11 | loss: 0.0790648\n",
      "\tspeed: 0.0306s/iter; left time: 62.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 223 | Train Loss: 0.0791857 Vali Loss: 0.0812311 Test Loss: 0.0861865\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794773\n",
      "\tspeed: 0.0589s/iter; left time: 112.3290s\n",
      "\titers: 200, epoch: 12 | loss: 0.0744852\n",
      "\tspeed: 0.0328s/iter; left time: 59.2418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 223 | Train Loss: 0.0785311 Vali Loss: 0.0815119 Test Loss: 0.0864249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0771206\n",
      "\tspeed: 0.0596s/iter; left time: 100.3813s\n",
      "\titers: 200, epoch: 13 | loss: 0.0765637\n",
      "\tspeed: 0.0305s/iter; left time: 48.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 223 | Train Loss: 0.0780971 Vali Loss: 0.0814536 Test Loss: 0.0862876\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770525\n",
      "\tspeed: 0.0542s/iter; left time: 79.2229s\n",
      "\titers: 200, epoch: 14 | loss: 0.0785253\n",
      "\tspeed: 0.0254s/iter; left time: 34.6018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0776683 Vali Loss: 0.0815699 Test Loss: 0.0864037\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020061098039150238, rmse:0.14163720607757568, mae:0.08603502810001373, rse:0.5360432267189026\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:59.44s\n",
      "Intermediate time for IT: 00h:14m:33.95s\n",
      "Total time: 01h:12m:34.37s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.0824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0215  0.1467  0.0896\n",
       "        96              0.0367  0.1917  0.1274\n",
       "        168             0.0392  0.1980  0.1350\n",
       "ES      24              0.0100  0.1001  0.0607\n",
       "        96              0.0189  0.1374  0.0879\n",
       "        168             0.0210  0.1448  0.0947\n",
       "FR      24              0.0102  0.1009  0.0557\n",
       "        96              0.0195  0.1396  0.0824\n",
       "        168             0.0216  0.1469  0.0885\n",
       "GB      24              0.0259  0.1611  0.1022\n",
       "        96              0.0443  0.2106  0.1431\n",
       "        168             0.0457  0.2137  0.1482\n",
       "IT      24              0.0103  0.1013  0.0578\n",
       "        96              0.0185  0.1362  0.0806\n",
       "        168             0.0200  0.1414  0.0859"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TS Decomposition + No RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3197058\n",
      "\tspeed: 0.0524s/iter; left time: 229.6893s\n",
      "\titers: 200, epoch: 1 | loss: 0.2848803\n",
      "\tspeed: 0.0290s/iter; left time: 123.9998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.3224996 Vali Loss: 0.2445201 Test Loss: 0.2496311\n",
      "Validation loss decreased (inf --> 0.244520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1632958\n",
      "\tspeed: 0.0594s/iter; left time: 247.0352s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435396\n",
      "\tspeed: 0.0293s/iter; left time: 118.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1791550 Vali Loss: 0.1517329 Test Loss: 0.1590105\n",
      "Validation loss decreased (0.244520 --> 0.151733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1282190\n",
      "\tspeed: 0.0632s/iter; left time: 248.4655s\n",
      "\titers: 200, epoch: 3 | loss: 0.1236127\n",
      "\tspeed: 0.0300s/iter; left time: 115.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.1314856 Vali Loss: 0.1271769 Test Loss: 0.1298694\n",
      "Validation loss decreased (0.151733 --> 0.127177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1127182\n",
      "\tspeed: 0.0584s/iter; left time: 216.5464s\n",
      "\titers: 200, epoch: 4 | loss: 0.1083485\n",
      "\tspeed: 0.0294s/iter; left time: 105.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1104953 Vali Loss: 0.1135581 Test Loss: 0.1164518\n",
      "Validation loss decreased (0.127177 --> 0.113558).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994385\n",
      "\tspeed: 0.0582s/iter; left time: 202.7633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0961599\n",
      "\tspeed: 0.0296s/iter; left time: 100.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1026559 Vali Loss: 0.1095314 Test Loss: 0.1127537\n",
      "Validation loss decreased (0.113558 --> 0.109531).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0999587\n",
      "\tspeed: 0.0653s/iter; left time: 212.9782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0995596\n",
      "\tspeed: 0.0309s/iter; left time: 97.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 224 | Train Loss: 0.0984441 Vali Loss: 0.1057713 Test Loss: 0.1084825\n",
      "Validation loss decreased (0.109531 --> 0.105771).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0907515\n",
      "\tspeed: 0.0588s/iter; left time: 178.6023s\n",
      "\titers: 200, epoch: 7 | loss: 0.0917593\n",
      "\tspeed: 0.0308s/iter; left time: 90.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0954027 Vali Loss: 0.1031872 Test Loss: 0.1064405\n",
      "Validation loss decreased (0.105771 --> 0.103187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0886695\n",
      "\tspeed: 0.0597s/iter; left time: 167.8961s\n",
      "\titers: 200, epoch: 8 | loss: 0.0955137\n",
      "\tspeed: 0.0333s/iter; left time: 90.4527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0931543 Vali Loss: 0.1008810 Test Loss: 0.1040170\n",
      "Validation loss decreased (0.103187 --> 0.100881).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0916593\n",
      "\tspeed: 0.0610s/iter; left time: 157.9673s\n",
      "\titers: 200, epoch: 9 | loss: 0.0895172\n",
      "\tspeed: 0.0314s/iter; left time: 78.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0904668 Vali Loss: 0.1005310 Test Loss: 0.1034304\n",
      "Validation loss decreased (0.100881 --> 0.100531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0934890\n",
      "\tspeed: 0.0604s/iter; left time: 142.9588s\n",
      "\titers: 200, epoch: 10 | loss: 0.0902340\n",
      "\tspeed: 0.0338s/iter; left time: 76.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0886777 Vali Loss: 0.0990515 Test Loss: 0.1017572\n",
      "Validation loss decreased (0.100531 --> 0.099052).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0879926\n",
      "\tspeed: 0.0573s/iter; left time: 122.7334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0838314\n",
      "\tspeed: 0.0286s/iter; left time: 58.3234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.0874012 Vali Loss: 0.0971403 Test Loss: 0.0998325\n",
      "Validation loss decreased (0.099052 --> 0.097140).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0874995\n",
      "\tspeed: 0.0603s/iter; left time: 115.6242s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851341\n",
      "\tspeed: 0.0320s/iter; left time: 58.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0861278 Vali Loss: 0.0964099 Test Loss: 0.0993579\n",
      "Validation loss decreased (0.097140 --> 0.096410).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0777159\n",
      "\tspeed: 0.0626s/iter; left time: 106.0138s\n",
      "\titers: 200, epoch: 13 | loss: 0.0838768\n",
      "\tspeed: 0.0312s/iter; left time: 49.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0850737 Vali Loss: 0.0961637 Test Loss: 0.0989631\n",
      "Validation loss decreased (0.096410 --> 0.096164).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0880001\n",
      "\tspeed: 0.0626s/iter; left time: 91.9588s\n",
      "\titers: 200, epoch: 14 | loss: 0.0836521\n",
      "\tspeed: 0.0351s/iter; left time: 48.0654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0842551 Vali Loss: 0.0952583 Test Loss: 0.0980118\n",
      "Validation loss decreased (0.096164 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869703\n",
      "\tspeed: 0.0625s/iter; left time: 77.8040s\n",
      "\titers: 200, epoch: 15 | loss: 0.0802809\n",
      "\tspeed: 0.0303s/iter; left time: 34.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0836535 Vali Loss: 0.0945245 Test Loss: 0.0974304\n",
      "Validation loss decreased (0.095258 --> 0.094524).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831622\n",
      "\tspeed: 0.0572s/iter; left time: 58.3876s\n",
      "\titers: 200, epoch: 16 | loss: 0.0802412\n",
      "\tspeed: 0.0323s/iter; left time: 29.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0830385 Vali Loss: 0.0941433 Test Loss: 0.0969761\n",
      "Validation loss decreased (0.094524 --> 0.094143).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0828111\n",
      "\tspeed: 0.0628s/iter; left time: 50.0771s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813980\n",
      "\tspeed: 0.0309s/iter; left time: 21.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0826371 Vali Loss: 0.0938573 Test Loss: 0.0968296\n",
      "Validation loss decreased (0.094143 --> 0.093857).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0882007\n",
      "\tspeed: 0.0657s/iter; left time: 37.6542s\n",
      "\titers: 200, epoch: 18 | loss: 0.0830444\n",
      "\tspeed: 0.0329s/iter; left time: 15.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0820137 Vali Loss: 0.0932900 Test Loss: 0.0962584\n",
      "Validation loss decreased (0.093857 --> 0.093290).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0787852\n",
      "\tspeed: 0.0630s/iter; left time: 22.0035s\n",
      "\titers: 200, epoch: 19 | loss: 0.0860242\n",
      "\tspeed: 0.0302s/iter; left time: 7.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0818549 Vali Loss: 0.0935120 Test Loss: 0.0964473\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0869714\n",
      "\tspeed: 0.0572s/iter; left time: 7.1523s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774314\n",
      "\tspeed: 0.0289s/iter; left time: 0.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0814949 Vali Loss: 0.0931582 Test Loss: 0.0962105\n",
      "Validation loss decreased (0.093290 --> 0.093158).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022892432287335396, rmse:0.15130245685577393, mae:0.0962105318903923, rse:0.5339672565460205\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3120975\n",
      "\tspeed: 0.0339s/iter; left time: 148.5472s\n",
      "\titers: 200, epoch: 1 | loss: 0.2910876\n",
      "\tspeed: 0.0304s/iter; left time: 130.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 224 | Train Loss: 0.3183213 Vali Loss: 0.2360670 Test Loss: 0.2400601\n",
      "Validation loss decreased (inf --> 0.236067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1708847\n",
      "\tspeed: 0.0623s/iter; left time: 258.9866s\n",
      "\titers: 200, epoch: 2 | loss: 0.1423552\n",
      "\tspeed: 0.0331s/iter; left time: 134.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.1805347 Vali Loss: 0.1529165 Test Loss: 0.1606148\n",
      "Validation loss decreased (0.236067 --> 0.152916).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1302526\n",
      "\tspeed: 0.0589s/iter; left time: 231.6927s\n",
      "\titers: 200, epoch: 3 | loss: 0.1299180\n",
      "\tspeed: 0.0291s/iter; left time: 111.6346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1349752 Vali Loss: 0.1363092 Test Loss: 0.1442030\n",
      "Validation loss decreased (0.152916 --> 0.136309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1193460\n",
      "\tspeed: 0.0575s/iter; left time: 213.4330s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128909\n",
      "\tspeed: 0.0308s/iter; left time: 111.1721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.1195715 Vali Loss: 0.1198629 Test Loss: 0.1233520\n",
      "Validation loss decreased (0.136309 --> 0.119863).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1051826\n",
      "\tspeed: 0.0646s/iter; left time: 225.2401s\n",
      "\titers: 200, epoch: 5 | loss: 0.1037136\n",
      "\tspeed: 0.0312s/iter; left time: 105.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.1050998 Vali Loss: 0.1105362 Test Loss: 0.1132714\n",
      "Validation loss decreased (0.119863 --> 0.110536).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982642\n",
      "\tspeed: 0.0640s/iter; left time: 208.5927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0981104\n",
      "\tspeed: 0.0322s/iter; left time: 101.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0982943 Vali Loss: 0.1054796 Test Loss: 0.1073494\n",
      "Validation loss decreased (0.110536 --> 0.105480).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0920649\n",
      "\tspeed: 0.0601s/iter; left time: 182.5511s\n",
      "\titers: 200, epoch: 7 | loss: 0.0908038\n",
      "\tspeed: 0.0287s/iter; left time: 84.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.0944413 Vali Loss: 0.1012434 Test Loss: 0.1036118\n",
      "Validation loss decreased (0.105480 --> 0.101243).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0989663\n",
      "\tspeed: 0.0592s/iter; left time: 166.6439s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905332\n",
      "\tspeed: 0.0324s/iter; left time: 87.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0910230 Vali Loss: 0.0990399 Test Loss: 0.1018160\n",
      "Validation loss decreased (0.101243 --> 0.099040).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0934790\n",
      "\tspeed: 0.0605s/iter; left time: 156.7448s\n",
      "\titers: 200, epoch: 9 | loss: 0.0859272\n",
      "\tspeed: 0.0299s/iter; left time: 74.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0891101 Vali Loss: 0.0979165 Test Loss: 0.1009639\n",
      "Validation loss decreased (0.099040 --> 0.097917).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0868982\n",
      "\tspeed: 0.0617s/iter; left time: 145.9926s\n",
      "\titers: 200, epoch: 10 | loss: 0.0882804\n",
      "\tspeed: 0.0312s/iter; left time: 70.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0874651 Vali Loss: 0.0993109 Test Loss: 0.1013410\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0955282\n",
      "\tspeed: 0.0655s/iter; left time: 140.2108s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906513\n",
      "\tspeed: 0.0332s/iter; left time: 67.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 224 | Train Loss: 0.0863330 Vali Loss: 0.0966949 Test Loss: 0.0994753\n",
      "Validation loss decreased (0.097917 --> 0.096695).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0803810\n",
      "\tspeed: 0.0614s/iter; left time: 117.7618s\n",
      "\titers: 200, epoch: 12 | loss: 0.0817595\n",
      "\tspeed: 0.0308s/iter; left time: 56.0428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0851068 Vali Loss: 0.0951778 Test Loss: 0.0981684\n",
      "Validation loss decreased (0.096695 --> 0.095178).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0846884\n",
      "\tspeed: 0.0620s/iter; left time: 105.0326s\n",
      "\titers: 200, epoch: 13 | loss: 0.0968739\n",
      "\tspeed: 0.0305s/iter; left time: 48.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0844143 Vali Loss: 0.0948840 Test Loss: 0.0980664\n",
      "Validation loss decreased (0.095178 --> 0.094884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0862818\n",
      "\tspeed: 0.0606s/iter; left time: 89.0299s\n",
      "\titers: 200, epoch: 14 | loss: 0.0832956\n",
      "\tspeed: 0.0307s/iter; left time: 42.0967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0837264 Vali Loss: 0.0941368 Test Loss: 0.0973042\n",
      "Validation loss decreased (0.094884 --> 0.094137).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842593\n",
      "\tspeed: 0.0611s/iter; left time: 76.0140s\n",
      "\titers: 200, epoch: 15 | loss: 0.0869031\n",
      "\tspeed: 0.0309s/iter; left time: 35.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0830546 Vali Loss: 0.0947447 Test Loss: 0.0975902\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0812184\n",
      "\tspeed: 0.0597s/iter; left time: 60.9138s\n",
      "\titers: 200, epoch: 16 | loss: 0.0804541\n",
      "\tspeed: 0.0288s/iter; left time: 26.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0826449 Vali Loss: 0.0942419 Test Loss: 0.0972068\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0811960\n",
      "\tspeed: 0.0581s/iter; left time: 46.3359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0870397\n",
      "\tspeed: 0.0307s/iter; left time: 21.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0822812 Vali Loss: 0.0933710 Test Loss: 0.0968070\n",
      "Validation loss decreased (0.094137 --> 0.093371).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0871290\n",
      "\tspeed: 0.0577s/iter; left time: 33.0456s\n",
      "\titers: 200, epoch: 18 | loss: 0.0847259\n",
      "\tspeed: 0.0291s/iter; left time: 13.7761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 224 | Train Loss: 0.0817981 Vali Loss: 0.0932530 Test Loss: 0.0965270\n",
      "Validation loss decreased (0.093371 --> 0.093253).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0822029\n",
      "\tspeed: 0.0615s/iter; left time: 21.4657s\n",
      "\titers: 200, epoch: 19 | loss: 0.0823385\n",
      "\tspeed: 0.0336s/iter; left time: 8.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0814749 Vali Loss: 0.0927413 Test Loss: 0.0962034\n",
      "Validation loss decreased (0.093253 --> 0.092741).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0860762\n",
      "\tspeed: 0.0638s/iter; left time: 7.9797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0863629\n",
      "\tspeed: 0.0287s/iter; left time: 0.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 224 | Train Loss: 0.0811540 Vali Loss: 0.0934738 Test Loss: 0.0970979\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02291129343211651, rmse:0.1513647735118866, mae:0.09620340168476105, rse:0.5341871976852417\n",
      "Intermediate time for DE and pred_len 24: 00h:06m:18.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3305949\n",
      "\tspeed: 0.0550s/iter; left time: 240.9204s\n",
      "\titers: 200, epoch: 1 | loss: 0.2956578\n",
      "\tspeed: 0.0293s/iter; left time: 125.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.3304898 Vali Loss: 0.2460313 Test Loss: 0.2522872\n",
      "Validation loss decreased (inf --> 0.246031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1738605\n",
      "\tspeed: 0.0587s/iter; left time: 243.9369s\n",
      "\titers: 200, epoch: 2 | loss: 0.1676649\n",
      "\tspeed: 0.0295s/iter; left time: 119.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1863481 Vali Loss: 0.1649268 Test Loss: 0.1775943\n",
      "Validation loss decreased (0.246031 --> 0.164927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1428607\n",
      "\tspeed: 0.0601s/iter; left time: 236.4361s\n",
      "\titers: 200, epoch: 3 | loss: 0.1391043\n",
      "\tspeed: 0.0306s/iter; left time: 117.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.1467414 Vali Loss: 0.1448588 Test Loss: 0.1559910\n",
      "Validation loss decreased (0.164927 --> 0.144859).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1298204\n",
      "\tspeed: 0.0620s/iter; left time: 230.0170s\n",
      "\titers: 200, epoch: 4 | loss: 0.1236297\n",
      "\tspeed: 0.0293s/iter; left time: 105.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.1299367 Vali Loss: 0.1388450 Test Loss: 0.1505615\n",
      "Validation loss decreased (0.144859 --> 0.138845).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1246714\n",
      "\tspeed: 0.0585s/iter; left time: 203.8526s\n",
      "\titers: 200, epoch: 5 | loss: 0.1221234\n",
      "\tspeed: 0.0291s/iter; left time: 98.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1215292 Vali Loss: 0.1347570 Test Loss: 0.1447935\n",
      "Validation loss decreased (0.138845 --> 0.134757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116392\n",
      "\tspeed: 0.0587s/iter; left time: 191.4891s\n",
      "\titers: 200, epoch: 6 | loss: 0.1164589\n",
      "\tspeed: 0.0304s/iter; left time: 96.1349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.1170554 Vali Loss: 0.1323325 Test Loss: 0.1419576\n",
      "Validation loss decreased (0.134757 --> 0.132332).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1179960\n",
      "\tspeed: 0.0604s/iter; left time: 183.5005s\n",
      "\titers: 200, epoch: 7 | loss: 0.1148745\n",
      "\tspeed: 0.0294s/iter; left time: 86.3446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.1143025 Vali Loss: 0.1329686 Test Loss: 0.1423291\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1147837\n",
      "\tspeed: 0.0584s/iter; left time: 164.3228s\n",
      "\titers: 200, epoch: 8 | loss: 0.1144873\n",
      "\tspeed: 0.0306s/iter; left time: 83.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 224 | Train Loss: 0.1126514 Vali Loss: 0.1288230 Test Loss: 0.1395905\n",
      "Validation loss decreased (0.132332 --> 0.128823).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1133409\n",
      "\tspeed: 0.0577s/iter; left time: 149.3675s\n",
      "\titers: 200, epoch: 9 | loss: 0.1105448\n",
      "\tspeed: 0.0291s/iter; left time: 72.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1108414 Vali Loss: 0.1291419 Test Loss: 0.1410021\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033083\n",
      "\tspeed: 0.0572s/iter; left time: 135.3929s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998180\n",
      "\tspeed: 0.0294s/iter; left time: 66.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1096718 Vali Loss: 0.1295754 Test Loss: 0.1407565\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1091216\n",
      "\tspeed: 0.0582s/iter; left time: 124.5251s\n",
      "\titers: 200, epoch: 11 | loss: 0.1039226\n",
      "\tspeed: 0.0303s/iter; left time: 61.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 224 | Train Loss: 0.1088921 Vali Loss: 0.1282423 Test Loss: 0.1401506\n",
      "Validation loss decreased (0.128823 --> 0.128242).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034938\n",
      "\tspeed: 0.0584s/iter; left time: 111.9340s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064432\n",
      "\tspeed: 0.0290s/iter; left time: 52.7487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1083104 Vali Loss: 0.1277135 Test Loss: 0.1397114\n",
      "Validation loss decreased (0.128242 --> 0.127714).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1134645\n",
      "\tspeed: 0.0577s/iter; left time: 97.6218s\n",
      "\titers: 200, epoch: 13 | loss: 0.1068219\n",
      "\tspeed: 0.0305s/iter; left time: 48.5075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.1076771 Vali Loss: 0.1271697 Test Loss: 0.1411984\n",
      "Validation loss decreased (0.127714 --> 0.127170).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1027745\n",
      "\tspeed: 0.0575s/iter; left time: 84.4615s\n",
      "\titers: 200, epoch: 14 | loss: 0.1024124\n",
      "\tspeed: 0.0293s/iter; left time: 40.1282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1070298 Vali Loss: 0.1266795 Test Loss: 0.1409364\n",
      "Validation loss decreased (0.127170 --> 0.126680).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1063156\n",
      "\tspeed: 0.0582s/iter; left time: 72.5165s\n",
      "\titers: 200, epoch: 15 | loss: 0.1051071\n",
      "\tspeed: 0.0291s/iter; left time: 33.2971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1065328 Vali Loss: 0.1270111 Test Loss: 0.1420114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1201266\n",
      "\tspeed: 0.0576s/iter; left time: 58.8555s\n",
      "\titers: 200, epoch: 16 | loss: 0.1075292\n",
      "\tspeed: 0.0290s/iter; left time: 26.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1063653 Vali Loss: 0.1267055 Test Loss: 0.1414126\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013357\n",
      "\tspeed: 0.0574s/iter; left time: 45.7314s\n",
      "\titers: 200, epoch: 17 | loss: 0.1006848\n",
      "\tspeed: 0.0291s/iter; left time: 20.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1056272 Vali Loss: 0.1262707 Test Loss: 0.1414120\n",
      "Validation loss decreased (0.126680 --> 0.126271).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1043863\n",
      "\tspeed: 0.0582s/iter; left time: 33.3543s\n",
      "\titers: 200, epoch: 18 | loss: 0.1103412\n",
      "\tspeed: 0.0290s/iter; left time: 13.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 224 | Train Loss: 0.1053320 Vali Loss: 0.1252308 Test Loss: 0.1395144\n",
      "Validation loss decreased (0.126271 --> 0.125231).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1047481\n",
      "\tspeed: 0.0582s/iter; left time: 20.3164s\n",
      "\titers: 200, epoch: 19 | loss: 0.1057975\n",
      "\tspeed: 0.0292s/iter; left time: 7.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1050644 Vali Loss: 0.1265537 Test Loss: 0.1420747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0998083\n",
      "\tspeed: 0.0591s/iter; left time: 7.3847s\n",
      "\titers: 200, epoch: 20 | loss: 0.1027103\n",
      "\tspeed: 0.0290s/iter; left time: 0.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1048490 Vali Loss: 0.1264704 Test Loss: 0.1424879\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04499721899628639, rmse:0.2121254801750183, mae:0.13951440155506134, rse:0.7511792182922363\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3297660\n",
      "\tspeed: 0.0313s/iter; left time: 137.1780s\n",
      "\titers: 200, epoch: 1 | loss: 0.2990467\n",
      "\tspeed: 0.0295s/iter; left time: 126.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.3308888 Vali Loss: 0.2447320 Test Loss: 0.2501129\n",
      "Validation loss decreased (inf --> 0.244732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1811734\n",
      "\tspeed: 0.0589s/iter; left time: 244.8859s\n",
      "\titers: 200, epoch: 2 | loss: 0.1558454\n",
      "\tspeed: 0.0291s/iter; left time: 117.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.1866350 Vali Loss: 0.1652548 Test Loss: 0.1801539\n",
      "Validation loss decreased (0.244732 --> 0.165255).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1498525\n",
      "\tspeed: 0.0583s/iter; left time: 229.2331s\n",
      "\titers: 200, epoch: 3 | loss: 0.1406645\n",
      "\tspeed: 0.0290s/iter; left time: 111.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.1483932 Vali Loss: 0.1459946 Test Loss: 0.1576371\n",
      "Validation loss decreased (0.165255 --> 0.145995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1305772\n",
      "\tspeed: 0.0587s/iter; left time: 217.8759s\n",
      "\titers: 200, epoch: 4 | loss: 0.1242648\n",
      "\tspeed: 0.0290s/iter; left time: 104.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1299763 Vali Loss: 0.1385265 Test Loss: 0.1505447\n",
      "Validation loss decreased (0.145995 --> 0.138526).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1206663\n",
      "\tspeed: 0.0587s/iter; left time: 204.6901s\n",
      "\titers: 200, epoch: 5 | loss: 0.1142883\n",
      "\tspeed: 0.0297s/iter; left time: 100.6769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 224 | Train Loss: 0.1216098 Vali Loss: 0.1332125 Test Loss: 0.1441918\n",
      "Validation loss decreased (0.138526 --> 0.133212).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1173400\n",
      "\tspeed: 0.0627s/iter; left time: 204.5584s\n",
      "\titers: 200, epoch: 6 | loss: 0.1111144\n",
      "\tspeed: 0.0296s/iter; left time: 93.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.1176333 Vali Loss: 0.1301108 Test Loss: 0.1427203\n",
      "Validation loss decreased (0.133212 --> 0.130111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1232475\n",
      "\tspeed: 0.0617s/iter; left time: 187.4552s\n",
      "\titers: 200, epoch: 7 | loss: 0.1187314\n",
      "\tspeed: 0.0290s/iter; left time: 85.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1153080 Vali Loss: 0.1285257 Test Loss: 0.1416099\n",
      "Validation loss decreased (0.130111 --> 0.128526).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1126224\n",
      "\tspeed: 0.0585s/iter; left time: 164.5758s\n",
      "\titers: 200, epoch: 8 | loss: 0.1116168\n",
      "\tspeed: 0.0290s/iter; left time: 78.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.1135190 Vali Loss: 0.1282783 Test Loss: 0.1424074\n",
      "Validation loss decreased (0.128526 --> 0.128278).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1077939\n",
      "\tspeed: 0.0615s/iter; left time: 159.2937s\n",
      "\titers: 200, epoch: 9 | loss: 0.1161721\n",
      "\tspeed: 0.0290s/iter; left time: 72.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1119330 Vali Loss: 0.1249939 Test Loss: 0.1399854\n",
      "Validation loss decreased (0.128278 --> 0.124994).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1078152\n",
      "\tspeed: 0.0585s/iter; left time: 138.3506s\n",
      "\titers: 200, epoch: 10 | loss: 0.1069120\n",
      "\tspeed: 0.0289s/iter; left time: 65.4275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1110137 Vali Loss: 0.1244445 Test Loss: 0.1391180\n",
      "Validation loss decreased (0.124994 --> 0.124445).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1042973\n",
      "\tspeed: 0.0589s/iter; left time: 126.1828s\n",
      "\titers: 200, epoch: 11 | loss: 0.1053502\n",
      "\tspeed: 0.0290s/iter; left time: 59.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1099827 Vali Loss: 0.1239039 Test Loss: 0.1384027\n",
      "Validation loss decreased (0.124445 --> 0.123904).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1130868\n",
      "\tspeed: 0.0587s/iter; left time: 112.5022s\n",
      "\titers: 200, epoch: 12 | loss: 0.1062623\n",
      "\tspeed: 0.0320s/iter; left time: 58.1655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.1093764 Vali Loss: 0.1239002 Test Loss: 0.1377378\n",
      "Validation loss decreased (0.123904 --> 0.123900).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1084605\n",
      "\tspeed: 0.0598s/iter; left time: 101.2504s\n",
      "\titers: 200, epoch: 13 | loss: 0.1060402\n",
      "\tspeed: 0.0299s/iter; left time: 47.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1089919 Vali Loss: 0.1245300 Test Loss: 0.1390902\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1090453\n",
      "\tspeed: 0.0588s/iter; left time: 86.3276s\n",
      "\titers: 200, epoch: 14 | loss: 0.1050313\n",
      "\tspeed: 0.0292s/iter; left time: 39.9813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1083116 Vali Loss: 0.1249334 Test Loss: 0.1386261\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1094635\n",
      "\tspeed: 0.0584s/iter; left time: 72.7596s\n",
      "\titers: 200, epoch: 15 | loss: 0.1102435\n",
      "\tspeed: 0.0291s/iter; left time: 33.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1075992 Vali Loss: 0.1235160 Test Loss: 0.1370709\n",
      "Validation loss decreased (0.123900 --> 0.123516).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1109557\n",
      "\tspeed: 0.0591s/iter; left time: 60.3178s\n",
      "\titers: 200, epoch: 16 | loss: 0.1085943\n",
      "\tspeed: 0.0291s/iter; left time: 26.8192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.1072603 Vali Loss: 0.1240432 Test Loss: 0.1376296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0991273\n",
      "\tspeed: 0.0584s/iter; left time: 46.5096s\n",
      "\titers: 200, epoch: 17 | loss: 0.1073230\n",
      "\tspeed: 0.0293s/iter; left time: 20.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1071549 Vali Loss: 0.1243623 Test Loss: 0.1374125\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1026045\n",
      "\tspeed: 0.0586s/iter; left time: 33.5757s\n",
      "\titers: 200, epoch: 18 | loss: 0.1057652\n",
      "\tspeed: 0.0294s/iter; left time: 13.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1066896 Vali Loss: 0.1235560 Test Loss: 0.1374642\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1053776\n",
      "\tspeed: 0.0600s/iter; left time: 20.9235s\n",
      "\titers: 200, epoch: 19 | loss: 0.1043892\n",
      "\tspeed: 0.0290s/iter; left time: 7.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1064574 Vali Loss: 0.1240025 Test Loss: 0.1374955\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1015059\n",
      "\tspeed: 0.0608s/iter; left time: 7.5970s\n",
      "\titers: 200, epoch: 20 | loss: 0.1014527\n",
      "\tspeed: 0.0292s/iter; left time: 0.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.1060711 Vali Loss: 0.1241181 Test Loss: 0.1371680\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04204053431749344, rmse:0.2050378918647766, mae:0.13707080483436584, rse:0.726080596446991\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:05.28s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3286587\n",
      "\tspeed: 0.0527s/iter; left time: 229.8659s\n",
      "\titers: 200, epoch: 1 | loss: 0.3013372\n",
      "\tspeed: 0.0299s/iter; left time: 127.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 223 | Train Loss: 0.3286599 Vali Loss: 0.2467528 Test Loss: 0.2530674\n",
      "Validation loss decreased (inf --> 0.246753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1765077\n",
      "\tspeed: 0.0592s/iter; left time: 245.0321s\n",
      "\titers: 200, epoch: 2 | loss: 0.1638675\n",
      "\tspeed: 0.0299s/iter; left time: 120.5609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.1864189 Vali Loss: 0.1629359 Test Loss: 0.1780014\n",
      "Validation loss decreased (0.246753 --> 0.162936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1551177\n",
      "\tspeed: 0.0594s/iter; left time: 232.6972s\n",
      "\titers: 200, epoch: 3 | loss: 0.1425488\n",
      "\tspeed: 0.0310s/iter; left time: 118.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1476279 Vali Loss: 0.1472359 Test Loss: 0.1596510\n",
      "Validation loss decreased (0.162936 --> 0.147236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1331133\n",
      "\tspeed: 0.0590s/iter; left time: 217.7383s\n",
      "\titers: 200, epoch: 4 | loss: 0.1265453\n",
      "\tspeed: 0.0296s/iter; left time: 106.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1320004 Vali Loss: 0.1415179 Test Loss: 0.1524611\n",
      "Validation loss decreased (0.147236 --> 0.141518).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1259447\n",
      "\tspeed: 0.0573s/iter; left time: 198.6943s\n",
      "\titers: 200, epoch: 5 | loss: 0.1273993\n",
      "\tspeed: 0.0293s/iter; left time: 98.6951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1262169 Vali Loss: 0.1371331 Test Loss: 0.1511706\n",
      "Validation loss decreased (0.141518 --> 0.137133).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1267060\n",
      "\tspeed: 0.0600s/iter; left time: 194.8408s\n",
      "\titers: 200, epoch: 6 | loss: 0.1168640\n",
      "\tspeed: 0.0304s/iter; left time: 95.5369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.1231220 Vali Loss: 0.1367026 Test Loss: 0.1504243\n",
      "Validation loss decreased (0.137133 --> 0.136703).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1181977\n",
      "\tspeed: 0.0596s/iter; left time: 180.2783s\n",
      "\titers: 200, epoch: 7 | loss: 0.1217122\n",
      "\tspeed: 0.0298s/iter; left time: 87.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1201023 Vali Loss: 0.1350890 Test Loss: 0.1480702\n",
      "Validation loss decreased (0.136703 --> 0.135089).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1119177\n",
      "\tspeed: 0.0590s/iter; left time: 165.1693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1277463\n",
      "\tspeed: 0.0293s/iter; left time: 79.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1180846 Vali Loss: 0.1334483 Test Loss: 0.1455045\n",
      "Validation loss decreased (0.135089 --> 0.133448).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1158057\n",
      "\tspeed: 0.0565s/iter; left time: 145.7265s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110080\n",
      "\tspeed: 0.0293s/iter; left time: 72.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.1168650 Vali Loss: 0.1351943 Test Loss: 0.1486059\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1218441\n",
      "\tspeed: 0.0583s/iter; left time: 137.1833s\n",
      "\titers: 200, epoch: 10 | loss: 0.1218923\n",
      "\tspeed: 0.0295s/iter; left time: 66.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 223 | Train Loss: 0.1157089 Vali Loss: 0.1341855 Test Loss: 0.1481222\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1136349\n",
      "\tspeed: 0.0583s/iter; left time: 124.2362s\n",
      "\titers: 200, epoch: 11 | loss: 0.1178679\n",
      "\tspeed: 0.0317s/iter; left time: 64.4508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 223 | Train Loss: 0.1147224 Vali Loss: 0.1333909 Test Loss: 0.1478128\n",
      "Validation loss decreased (0.133448 --> 0.133391).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1089779\n",
      "\tspeed: 0.0599s/iter; left time: 114.3094s\n",
      "\titers: 200, epoch: 12 | loss: 0.1130720\n",
      "\tspeed: 0.0305s/iter; left time: 55.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 223 | Train Loss: 0.1141470 Vali Loss: 0.1320217 Test Loss: 0.1457483\n",
      "Validation loss decreased (0.133391 --> 0.132022).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1091995\n",
      "\tspeed: 0.0621s/iter; left time: 104.7007s\n",
      "\titers: 200, epoch: 13 | loss: 0.1105160\n",
      "\tspeed: 0.0297s/iter; left time: 47.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.1132571 Vali Loss: 0.1329884 Test Loss: 0.1476688\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1213825\n",
      "\tspeed: 0.0588s/iter; left time: 85.9919s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086435\n",
      "\tspeed: 0.0293s/iter; left time: 39.9285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1129378 Vali Loss: 0.1322988 Test Loss: 0.1477441\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1101832\n",
      "\tspeed: 0.0574s/iter; left time: 71.1470s\n",
      "\titers: 200, epoch: 15 | loss: 0.1128385\n",
      "\tspeed: 0.0293s/iter; left time: 33.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1123634 Vali Loss: 0.1319943 Test Loss: 0.1473603\n",
      "Validation loss decreased (0.132022 --> 0.131994).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1071931\n",
      "\tspeed: 0.0571s/iter; left time: 58.0365s\n",
      "\titers: 200, epoch: 16 | loss: 0.1116006\n",
      "\tspeed: 0.0295s/iter; left time: 27.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.1118787 Vali Loss: 0.1312458 Test Loss: 0.1476277\n",
      "Validation loss decreased (0.131994 --> 0.131246).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1146794\n",
      "\tspeed: 0.0579s/iter; left time: 45.9433s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118371\n",
      "\tspeed: 0.0293s/iter; left time: 20.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1114189 Vali Loss: 0.1309584 Test Loss: 0.1475634\n",
      "Validation loss decreased (0.131246 --> 0.130958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1184363\n",
      "\tspeed: 0.0573s/iter; left time: 32.6461s\n",
      "\titers: 200, epoch: 18 | loss: 0.1055574\n",
      "\tspeed: 0.0296s/iter; left time: 13.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.1112526 Vali Loss: 0.1306421 Test Loss: 0.1476581\n",
      "Validation loss decreased (0.130958 --> 0.130642).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1138625\n",
      "\tspeed: 0.0614s/iter; left time: 21.3049s\n",
      "\titers: 200, epoch: 19 | loss: 0.1111660\n",
      "\tspeed: 0.0304s/iter; left time: 7.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 223 | Train Loss: 0.1107028 Vali Loss: 0.1304632 Test Loss: 0.1480525\n",
      "Validation loss decreased (0.130642 --> 0.130463).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1142451\n",
      "\tspeed: 0.0576s/iter; left time: 7.1415s\n",
      "\titers: 200, epoch: 20 | loss: 0.1087447\n",
      "\tspeed: 0.0300s/iter; left time: 0.7199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1103219 Vali Loss: 0.1294829 Test Loss: 0.1470253\n",
      "Validation loss decreased (0.130463 --> 0.129483).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048888467252254486, rmse:0.2211073637008667, mae:0.14702542126178741, rse:0.7831800580024719\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3337743\n",
      "\tspeed: 0.0314s/iter; left time: 136.8176s\n",
      "\titers: 200, epoch: 1 | loss: 0.2935378\n",
      "\tspeed: 0.0293s/iter; left time: 124.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.3319396 Vali Loss: 0.2452022 Test Loss: 0.2508689\n",
      "Validation loss decreased (inf --> 0.245202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1742424\n",
      "\tspeed: 0.0584s/iter; left time: 241.6211s\n",
      "\titers: 200, epoch: 2 | loss: 0.1611502\n",
      "\tspeed: 0.0296s/iter; left time: 119.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1884793 Vali Loss: 0.1657862 Test Loss: 0.1822352\n",
      "Validation loss decreased (0.245202 --> 0.165786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1460810\n",
      "\tspeed: 0.0606s/iter; left time: 237.3066s\n",
      "\titers: 200, epoch: 3 | loss: 0.1393744\n",
      "\tspeed: 0.0294s/iter; left time: 112.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.1494653 Vali Loss: 0.1479477 Test Loss: 0.1607709\n",
      "Validation loss decreased (0.165786 --> 0.147948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1351952\n",
      "\tspeed: 0.0602s/iter; left time: 222.3546s\n",
      "\titers: 200, epoch: 4 | loss: 0.1265540\n",
      "\tspeed: 0.0294s/iter; left time: 105.5775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1320048 Vali Loss: 0.1404832 Test Loss: 0.1536703\n",
      "Validation loss decreased (0.147948 --> 0.140483).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1281559\n",
      "\tspeed: 0.0587s/iter; left time: 203.6846s\n",
      "\titers: 200, epoch: 5 | loss: 0.1284090\n",
      "\tspeed: 0.0303s/iter; left time: 102.1773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1258329 Vali Loss: 0.1355311 Test Loss: 0.1502418\n",
      "Validation loss decreased (0.140483 --> 0.135531).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1293960\n",
      "\tspeed: 0.0589s/iter; left time: 191.0950s\n",
      "\titers: 200, epoch: 6 | loss: 0.1262868\n",
      "\tspeed: 0.0298s/iter; left time: 93.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.1220864 Vali Loss: 0.1322428 Test Loss: 0.1480273\n",
      "Validation loss decreased (0.135531 --> 0.132243).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1230115\n",
      "\tspeed: 0.0597s/iter; left time: 180.3305s\n",
      "\titers: 200, epoch: 7 | loss: 0.1253694\n",
      "\tspeed: 0.0293s/iter; left time: 85.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1200187 Vali Loss: 0.1303286 Test Loss: 0.1472878\n",
      "Validation loss decreased (0.132243 --> 0.130329).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1207607\n",
      "\tspeed: 0.0590s/iter; left time: 165.1346s\n",
      "\titers: 200, epoch: 8 | loss: 0.1200787\n",
      "\tspeed: 0.0296s/iter; left time: 79.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1181405 Vali Loss: 0.1295161 Test Loss: 0.1449011\n",
      "Validation loss decreased (0.130329 --> 0.129516).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1134350\n",
      "\tspeed: 0.0601s/iter; left time: 154.8634s\n",
      "\titers: 200, epoch: 9 | loss: 0.1178156\n",
      "\tspeed: 0.0292s/iter; left time: 72.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1171303 Vali Loss: 0.1303412 Test Loss: 0.1487283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1167257\n",
      "\tspeed: 0.0593s/iter; left time: 139.5594s\n",
      "\titers: 200, epoch: 10 | loss: 0.1140056\n",
      "\tspeed: 0.0294s/iter; left time: 66.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 223 | Train Loss: 0.1159781 Vali Loss: 0.1294428 Test Loss: 0.1465944\n",
      "Validation loss decreased (0.129516 --> 0.129443).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1160517\n",
      "\tspeed: 0.0600s/iter; left time: 127.8672s\n",
      "\titers: 200, epoch: 11 | loss: 0.1189535\n",
      "\tspeed: 0.0292s/iter; left time: 59.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.1147170 Vali Loss: 0.1292408 Test Loss: 0.1446240\n",
      "Validation loss decreased (0.129443 --> 0.129241).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1133090\n",
      "\tspeed: 0.0592s/iter; left time: 112.9847s\n",
      "\titers: 200, epoch: 12 | loss: 0.1096749\n",
      "\tspeed: 0.0293s/iter; left time: 52.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.1138976 Vali Loss: 0.1296563 Test Loss: 0.1455196\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1180899\n",
      "\tspeed: 0.0627s/iter; left time: 105.6263s\n",
      "\titers: 200, epoch: 13 | loss: 0.1130622\n",
      "\tspeed: 0.0293s/iter; left time: 46.5112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.1134599 Vali Loss: 0.1311366 Test Loss: 0.1463708\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1152554\n",
      "\tspeed: 0.0588s/iter; left time: 85.9040s\n",
      "\titers: 200, epoch: 14 | loss: 0.1137584\n",
      "\tspeed: 0.0294s/iter; left time: 40.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.1130660 Vali Loss: 0.1304459 Test Loss: 0.1450407\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1126037\n",
      "\tspeed: 0.0590s/iter; left time: 73.0569s\n",
      "\titers: 200, epoch: 15 | loss: 0.1157417\n",
      "\tspeed: 0.0295s/iter; left time: 33.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1122536 Vali Loss: 0.1299901 Test Loss: 0.1450334\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1138715\n",
      "\tspeed: 0.0587s/iter; left time: 59.6632s\n",
      "\titers: 200, epoch: 16 | loss: 0.1129028\n",
      "\tspeed: 0.0297s/iter; left time: 27.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.1119111 Vali Loss: 0.1291578 Test Loss: 0.1441945\n",
      "Validation loss decreased (0.129241 --> 0.129158).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1113938\n",
      "\tspeed: 0.0591s/iter; left time: 46.8835s\n",
      "\titers: 200, epoch: 17 | loss: 0.1152524\n",
      "\tspeed: 0.0294s/iter; left time: 20.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1116043 Vali Loss: 0.1299192 Test Loss: 0.1443742\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1154647\n",
      "\tspeed: 0.0584s/iter; left time: 33.2784s\n",
      "\titers: 200, epoch: 18 | loss: 0.1141288\n",
      "\tspeed: 0.0293s/iter; left time: 13.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.1111130 Vali Loss: 0.1297319 Test Loss: 0.1449329\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1109985\n",
      "\tspeed: 0.0589s/iter; left time: 20.4404s\n",
      "\titers: 200, epoch: 19 | loss: 0.1100777\n",
      "\tspeed: 0.0298s/iter; left time: 7.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1111366 Vali Loss: 0.1301898 Test Loss: 0.1459167\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1112318\n",
      "\tspeed: 0.0589s/iter; left time: 7.2985s\n",
      "\titers: 200, epoch: 20 | loss: 0.1081951\n",
      "\tspeed: 0.0294s/iter; left time: 0.7053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1105430 Vali Loss: 0.1303462 Test Loss: 0.1455693\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046200282871723175, rmse:0.21494251489639282, mae:0.14419451355934143, rse:0.7613436579704285\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:06.94s\n",
      "Intermediate time for DE: 00h:18m:30.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3239528\n",
      "\tspeed: 0.0539s/iter; left time: 236.1368s\n",
      "\titers: 200, epoch: 1 | loss: 0.3033940\n",
      "\tspeed: 0.0294s/iter; left time: 125.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.3316580 Vali Loss: 0.2575737 Test Loss: 0.2757833\n",
      "Validation loss decreased (inf --> 0.257574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1560647\n",
      "\tspeed: 0.0619s/iter; left time: 257.1798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1330305\n",
      "\tspeed: 0.0296s/iter; left time: 120.1204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.1746304 Vali Loss: 0.1365823 Test Loss: 0.1545957\n",
      "Validation loss decreased (0.257574 --> 0.136582).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217884\n",
      "\tspeed: 0.0605s/iter; left time: 238.0649s\n",
      "\titers: 200, epoch: 3 | loss: 0.1226198\n",
      "\tspeed: 0.0312s/iter; left time: 119.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 224 | Train Loss: 0.1249406 Vali Loss: 0.1276880 Test Loss: 0.1422693\n",
      "Validation loss decreased (0.136582 --> 0.127688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1207634\n",
      "\tspeed: 0.0651s/iter; left time: 241.6190s\n",
      "\titers: 200, epoch: 4 | loss: 0.1144840\n",
      "\tspeed: 0.0307s/iter; left time: 110.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.1158130 Vali Loss: 0.1153170 Test Loss: 0.1286238\n",
      "Validation loss decreased (0.127688 --> 0.115317).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1052632\n",
      "\tspeed: 0.0586s/iter; left time: 204.1607s\n",
      "\titers: 200, epoch: 5 | loss: 0.1034931\n",
      "\tspeed: 0.0297s/iter; left time: 100.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.1032673 Vali Loss: 0.1062338 Test Loss: 0.1240031\n",
      "Validation loss decreased (0.115317 --> 0.106234).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0983069\n",
      "\tspeed: 0.0596s/iter; left time: 194.3492s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024979\n",
      "\tspeed: 0.0317s/iter; left time: 100.3318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.0980320 Vali Loss: 0.1041580 Test Loss: 0.1207242\n",
      "Validation loss decreased (0.106234 --> 0.104158).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0965420\n",
      "\tspeed: 0.0606s/iter; left time: 184.0178s\n",
      "\titers: 200, epoch: 7 | loss: 0.0939151\n",
      "\tspeed: 0.0310s/iter; left time: 90.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0953881 Vali Loss: 0.1014206 Test Loss: 0.1178902\n",
      "Validation loss decreased (0.104158 --> 0.101421).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0975644\n",
      "\tspeed: 0.0631s/iter; left time: 177.4521s\n",
      "\titers: 200, epoch: 8 | loss: 0.1016343\n",
      "\tspeed: 0.0355s/iter; left time: 96.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0935245 Vali Loss: 0.1007923 Test Loss: 0.1176121\n",
      "Validation loss decreased (0.101421 --> 0.100792).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0902932\n",
      "\tspeed: 0.0648s/iter; left time: 167.6392s\n",
      "\titers: 200, epoch: 9 | loss: 0.0904424\n",
      "\tspeed: 0.0359s/iter; left time: 89.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0924001 Vali Loss: 0.1006797 Test Loss: 0.1164299\n",
      "Validation loss decreased (0.100792 --> 0.100680).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0965946\n",
      "\tspeed: 0.0669s/iter; left time: 158.1252s\n",
      "\titers: 200, epoch: 10 | loss: 0.0888032\n",
      "\tspeed: 0.0362s/iter; left time: 81.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 224 | Train Loss: 0.0911065 Vali Loss: 0.0995127 Test Loss: 0.1151111\n",
      "Validation loss decreased (0.100680 --> 0.099513).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0901263\n",
      "\tspeed: 0.0644s/iter; left time: 137.8627s\n",
      "\titers: 200, epoch: 11 | loss: 0.0959461\n",
      "\tspeed: 0.0304s/iter; left time: 62.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0899971 Vali Loss: 0.0993530 Test Loss: 0.1157064\n",
      "Validation loss decreased (0.099513 --> 0.099353).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0930362\n",
      "\tspeed: 0.0589s/iter; left time: 112.8455s\n",
      "\titers: 200, epoch: 12 | loss: 0.0857455\n",
      "\tspeed: 0.0295s/iter; left time: 53.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0890770 Vali Loss: 0.0977133 Test Loss: 0.1146280\n",
      "Validation loss decreased (0.099353 --> 0.097713).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858697\n",
      "\tspeed: 0.0608s/iter; left time: 102.8702s\n",
      "\titers: 200, epoch: 13 | loss: 0.0877948\n",
      "\tspeed: 0.0308s/iter; left time: 49.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0881250 Vali Loss: 0.0980751 Test Loss: 0.1147111\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0851261\n",
      "\tspeed: 0.0579s/iter; left time: 85.0402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0844360\n",
      "\tspeed: 0.0302s/iter; left time: 41.3520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0869829 Vali Loss: 0.0969597 Test Loss: 0.1132574\n",
      "Validation loss decreased (0.097713 --> 0.096960).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831320\n",
      "\tspeed: 0.0612s/iter; left time: 76.2107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0848908\n",
      "\tspeed: 0.0326s/iter; left time: 37.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0860614 Vali Loss: 0.0959674 Test Loss: 0.1132786\n",
      "Validation loss decreased (0.096960 --> 0.095967).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0827185\n",
      "\tspeed: 0.0634s/iter; left time: 64.7174s\n",
      "\titers: 200, epoch: 16 | loss: 0.0866139\n",
      "\tspeed: 0.0293s/iter; left time: 26.9515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 224 | Train Loss: 0.0854626 Vali Loss: 0.0950077 Test Loss: 0.1113449\n",
      "Validation loss decreased (0.095967 --> 0.095008).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0817979\n",
      "\tspeed: 0.0568s/iter; left time: 45.2320s\n",
      "\titers: 200, epoch: 17 | loss: 0.0858268\n",
      "\tspeed: 0.0300s/iter; left time: 20.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0846109 Vali Loss: 0.0947485 Test Loss: 0.1113595\n",
      "Validation loss decreased (0.095008 --> 0.094749).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0800059\n",
      "\tspeed: 0.0565s/iter; left time: 32.3674s\n",
      "\titers: 200, epoch: 18 | loss: 0.0814329\n",
      "\tspeed: 0.0292s/iter; left time: 13.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0837961 Vali Loss: 0.0942703 Test Loss: 0.1104814\n",
      "Validation loss decreased (0.094749 --> 0.094270).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0824048\n",
      "\tspeed: 0.0600s/iter; left time: 20.9355s\n",
      "\titers: 200, epoch: 19 | loss: 0.0877841\n",
      "\tspeed: 0.0319s/iter; left time: 7.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0834405 Vali Loss: 0.0939164 Test Loss: 0.1100721\n",
      "Validation loss decreased (0.094270 --> 0.093916).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0759753\n",
      "\tspeed: 0.0603s/iter; left time: 7.5340s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791688\n",
      "\tspeed: 0.0303s/iter; left time: 0.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0830391 Vali Loss: 0.0946813 Test Loss: 0.1106669\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028247060254216194, rmse:0.16806861758232117, mae:0.1100720539689064, rse:0.5797891020774841\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3250797\n",
      "\tspeed: 0.0391s/iter; left time: 171.2037s\n",
      "\titers: 200, epoch: 1 | loss: 0.3051234\n",
      "\tspeed: 0.0325s/iter; left time: 139.1514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.3280506 Vali Loss: 0.2509711 Test Loss: 0.2657584\n",
      "Validation loss decreased (inf --> 0.250971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1608512\n",
      "\tspeed: 0.0607s/iter; left time: 252.4223s\n",
      "\titers: 200, epoch: 2 | loss: 0.1361629\n",
      "\tspeed: 0.0290s/iter; left time: 117.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.1757303 Vali Loss: 0.1375118 Test Loss: 0.1559557\n",
      "Validation loss decreased (0.250971 --> 0.137512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1274329\n",
      "\tspeed: 0.0648s/iter; left time: 255.0078s\n",
      "\titers: 200, epoch: 3 | loss: 0.1178589\n",
      "\tspeed: 0.0376s/iter; left time: 144.1115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 224 | Train Loss: 0.1247714 Vali Loss: 0.1283534 Test Loss: 0.1437468\n",
      "Validation loss decreased (0.137512 --> 0.128353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1128319\n",
      "\tspeed: 0.0636s/iter; left time: 236.0019s\n",
      "\titers: 200, epoch: 4 | loss: 0.1142801\n",
      "\tspeed: 0.0299s/iter; left time: 107.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.1175590 Vali Loss: 0.1236853 Test Loss: 0.1395646\n",
      "Validation loss decreased (0.128353 --> 0.123685).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1122211\n",
      "\tspeed: 0.0637s/iter; left time: 221.9224s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047428\n",
      "\tspeed: 0.0339s/iter; left time: 114.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.1114656 Vali Loss: 0.1150442 Test Loss: 0.1301543\n",
      "Validation loss decreased (0.123685 --> 0.115044).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1043425\n",
      "\tspeed: 0.0587s/iter; left time: 191.3612s\n",
      "\titers: 200, epoch: 6 | loss: 0.1058902\n",
      "\tspeed: 0.0295s/iter; left time: 93.4028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1012323 Vali Loss: 0.1053452 Test Loss: 0.1231468\n",
      "Validation loss decreased (0.115044 --> 0.105345).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0944449\n",
      "\tspeed: 0.0590s/iter; left time: 179.0925s\n",
      "\titers: 200, epoch: 7 | loss: 0.0947269\n",
      "\tspeed: 0.0340s/iter; left time: 99.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0966659 Vali Loss: 0.1018385 Test Loss: 0.1175386\n",
      "Validation loss decreased (0.105345 --> 0.101839).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1005144\n",
      "\tspeed: 0.0622s/iter; left time: 174.9334s\n",
      "\titers: 200, epoch: 8 | loss: 0.0914212\n",
      "\tspeed: 0.0325s/iter; left time: 88.0581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0943060 Vali Loss: 0.1010736 Test Loss: 0.1169308\n",
      "Validation loss decreased (0.101839 --> 0.101074).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0927854\n",
      "\tspeed: 0.0634s/iter; left time: 164.2491s\n",
      "\titers: 200, epoch: 9 | loss: 0.0920297\n",
      "\tspeed: 0.0336s/iter; left time: 83.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0926017 Vali Loss: 0.1001840 Test Loss: 0.1151641\n",
      "Validation loss decreased (0.101074 --> 0.100184).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0898557\n",
      "\tspeed: 0.0630s/iter; left time: 148.9707s\n",
      "\titers: 200, epoch: 10 | loss: 0.0914794\n",
      "\tspeed: 0.0348s/iter; left time: 78.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0912905 Vali Loss: 0.0996700 Test Loss: 0.1157632\n",
      "Validation loss decreased (0.100184 --> 0.099670).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0900160\n",
      "\tspeed: 0.0652s/iter; left time: 139.5116s\n",
      "\titers: 200, epoch: 11 | loss: 0.0981012\n",
      "\tspeed: 0.0340s/iter; left time: 69.4376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0900536 Vali Loss: 0.0984564 Test Loss: 0.1143827\n",
      "Validation loss decreased (0.099670 --> 0.098456).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0888562\n",
      "\tspeed: 0.0625s/iter; left time: 119.8305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0894168\n",
      "\tspeed: 0.0335s/iter; left time: 60.7916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0891110 Vali Loss: 0.0975752 Test Loss: 0.1130308\n",
      "Validation loss decreased (0.098456 --> 0.097575).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0918563\n",
      "\tspeed: 0.0589s/iter; left time: 99.7321s\n",
      "\titers: 200, epoch: 13 | loss: 0.0919589\n",
      "\tspeed: 0.0348s/iter; left time: 55.3947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0882034 Vali Loss: 0.0973145 Test Loss: 0.1123101\n",
      "Validation loss decreased (0.097575 --> 0.097315).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0852174\n",
      "\tspeed: 0.0599s/iter; left time: 87.9919s\n",
      "\titers: 200, epoch: 14 | loss: 0.0852957\n",
      "\tspeed: 0.0286s/iter; left time: 39.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0871614 Vali Loss: 0.0964670 Test Loss: 0.1118558\n",
      "Validation loss decreased (0.097315 --> 0.096467).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0894147\n",
      "\tspeed: 0.0571s/iter; left time: 71.1230s\n",
      "\titers: 200, epoch: 15 | loss: 0.0901312\n",
      "\tspeed: 0.0351s/iter; left time: 40.2388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0865445 Vali Loss: 0.0962386 Test Loss: 0.1110527\n",
      "Validation loss decreased (0.096467 --> 0.096239).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0856697\n",
      "\tspeed: 0.0620s/iter; left time: 63.2661s\n",
      "\titers: 200, epoch: 16 | loss: 0.0871343\n",
      "\tspeed: 0.0344s/iter; left time: 31.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0857234 Vali Loss: 0.0957917 Test Loss: 0.1103710\n",
      "Validation loss decreased (0.096239 --> 0.095792).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0860123\n",
      "\tspeed: 0.0679s/iter; left time: 54.1487s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850986\n",
      "\tspeed: 0.0357s/iter; left time: 24.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 224 | Train Loss: 0.0849745 Vali Loss: 0.0947832 Test Loss: 0.1095936\n",
      "Validation loss decreased (0.095792 --> 0.094783).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878262\n",
      "\tspeed: 0.0700s/iter; left time: 40.0884s\n",
      "\titers: 200, epoch: 18 | loss: 0.0900078\n",
      "\tspeed: 0.0432s/iter; left time: 20.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 224 | Train Loss: 0.0842663 Vali Loss: 0.0946132 Test Loss: 0.1089559\n",
      "Validation loss decreased (0.094783 --> 0.094613).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0826841\n",
      "\tspeed: 0.0618s/iter; left time: 21.5719s\n",
      "\titers: 200, epoch: 19 | loss: 0.0813321\n",
      "\tspeed: 0.0300s/iter; left time: 7.4688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0836174 Vali Loss: 0.0942607 Test Loss: 0.1088751\n",
      "Validation loss decreased (0.094613 --> 0.094261).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0898202\n",
      "\tspeed: 0.0572s/iter; left time: 7.1454s\n",
      "\titers: 200, epoch: 20 | loss: 0.0839985\n",
      "\tspeed: 0.0318s/iter; left time: 0.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0832184 Vali Loss: 0.0940505 Test Loss: 0.1086721\n",
      "Validation loss decreased (0.094261 --> 0.094051).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027067717164754868, rmse:0.1645226925611496, mae:0.10867207497358322, rse:0.567556619644165\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:27.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3359300\n",
      "\tspeed: 0.0542s/iter; left time: 237.6443s\n",
      "\titers: 200, epoch: 1 | loss: 0.3055382\n",
      "\tspeed: 0.0299s/iter; left time: 128.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.3383009 Vali Loss: 0.2619191 Test Loss: 0.2823846\n",
      "Validation loss decreased (inf --> 0.261919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645241\n",
      "\tspeed: 0.0593s/iter; left time: 246.3316s\n",
      "\titers: 200, epoch: 2 | loss: 0.1518169\n",
      "\tspeed: 0.0299s/iter; left time: 121.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.1798169 Vali Loss: 0.1554538 Test Loss: 0.1792535\n",
      "Validation loss decreased (0.261919 --> 0.155454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1382080\n",
      "\tspeed: 0.0600s/iter; left time: 235.9428s\n",
      "\titers: 200, epoch: 3 | loss: 0.1341432\n",
      "\tspeed: 0.0303s/iter; left time: 116.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.1412312 Vali Loss: 0.1473401 Test Loss: 0.1714565\n",
      "Validation loss decreased (0.155454 --> 0.147340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1285816\n",
      "\tspeed: 0.0632s/iter; left time: 234.2440s\n",
      "\titers: 200, epoch: 4 | loss: 0.1210611\n",
      "\tspeed: 0.0305s/iter; left time: 110.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.1327344 Vali Loss: 0.1408065 Test Loss: 0.1661706\n",
      "Validation loss decreased (0.147340 --> 0.140806).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1270812\n",
      "\tspeed: 0.0587s/iter; left time: 204.7188s\n",
      "\titers: 200, epoch: 5 | loss: 0.1171009\n",
      "\tspeed: 0.0295s/iter; left time: 99.8739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.1209899 Vali Loss: 0.1331111 Test Loss: 0.1586780\n",
      "Validation loss decreased (0.140806 --> 0.133111).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1146407\n",
      "\tspeed: 0.0594s/iter; left time: 193.6957s\n",
      "\titers: 200, epoch: 6 | loss: 0.1110103\n",
      "\tspeed: 0.0299s/iter; left time: 94.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.1145377 Vali Loss: 0.1320503 Test Loss: 0.1594520\n",
      "Validation loss decreased (0.133111 --> 0.132050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1034329\n",
      "\tspeed: 0.0589s/iter; left time: 179.0214s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117046\n",
      "\tspeed: 0.0296s/iter; left time: 87.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.1119251 Vali Loss: 0.1324430 Test Loss: 0.1580923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1104701\n",
      "\tspeed: 0.0592s/iter; left time: 166.5728s\n",
      "\titers: 200, epoch: 8 | loss: 0.1084470\n",
      "\tspeed: 0.0308s/iter; left time: 83.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.1101401 Vali Loss: 0.1287862 Test Loss: 0.1565470\n",
      "Validation loss decreased (0.132050 --> 0.128786).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1070692\n",
      "\tspeed: 0.0615s/iter; left time: 159.1498s\n",
      "\titers: 200, epoch: 9 | loss: 0.1071072\n",
      "\tspeed: 0.0304s/iter; left time: 75.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.1090582 Vali Loss: 0.1291053 Test Loss: 0.1570928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1071760\n",
      "\tspeed: 0.0620s/iter; left time: 146.6603s\n",
      "\titers: 200, epoch: 10 | loss: 0.1052107\n",
      "\tspeed: 0.0377s/iter; left time: 85.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.1077298 Vali Loss: 0.1280605 Test Loss: 0.1562621\n",
      "Validation loss decreased (0.128786 --> 0.128060).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1072934\n",
      "\tspeed: 0.0679s/iter; left time: 145.2970s\n",
      "\titers: 200, epoch: 11 | loss: 0.1008391\n",
      "\tspeed: 0.0381s/iter; left time: 77.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 224 | Train Loss: 0.1075322 Vali Loss: 0.1267957 Test Loss: 0.1560000\n",
      "Validation loss decreased (0.128060 --> 0.126796).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1015190\n",
      "\tspeed: 0.0621s/iter; left time: 119.1118s\n",
      "\titers: 200, epoch: 12 | loss: 0.1038616\n",
      "\tspeed: 0.0319s/iter; left time: 57.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.1065964 Vali Loss: 0.1269001 Test Loss: 0.1561267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1077410\n",
      "\tspeed: 0.0685s/iter; left time: 115.8987s\n",
      "\titers: 200, epoch: 13 | loss: 0.1095136\n",
      "\tspeed: 0.0373s/iter; left time: 59.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 224 | Train Loss: 0.1061064 Vali Loss: 0.1263930 Test Loss: 0.1561556\n",
      "Validation loss decreased (0.126796 --> 0.126393).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1006579\n",
      "\tspeed: 0.0605s/iter; left time: 88.9184s\n",
      "\titers: 200, epoch: 14 | loss: 0.1050430\n",
      "\tspeed: 0.0288s/iter; left time: 39.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.1056615 Vali Loss: 0.1263432 Test Loss: 0.1562384\n",
      "Validation loss decreased (0.126393 --> 0.126343).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1036151\n",
      "\tspeed: 0.0583s/iter; left time: 72.5662s\n",
      "\titers: 200, epoch: 15 | loss: 0.1043281\n",
      "\tspeed: 0.0304s/iter; left time: 34.7520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.1053216 Vali Loss: 0.1269479 Test Loss: 0.1575384\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1070781\n",
      "\tspeed: 0.0579s/iter; left time: 59.0973s\n",
      "\titers: 200, epoch: 16 | loss: 0.1034022\n",
      "\tspeed: 0.0288s/iter; left time: 26.5629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.1048783 Vali Loss: 0.1277726 Test Loss: 0.1580403\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003585\n",
      "\tspeed: 0.0590s/iter; left time: 47.0080s\n",
      "\titers: 200, epoch: 17 | loss: 0.1001033\n",
      "\tspeed: 0.0299s/iter; left time: 20.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.1045216 Vali Loss: 0.1268236 Test Loss: 0.1577196\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1009254\n",
      "\tspeed: 0.0576s/iter; left time: 32.9887s\n",
      "\titers: 200, epoch: 18 | loss: 0.1098270\n",
      "\tspeed: 0.0323s/iter; left time: 15.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1045029 Vali Loss: 0.1274844 Test Loss: 0.1583436\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1014802\n",
      "\tspeed: 0.0577s/iter; left time: 20.1321s\n",
      "\titers: 200, epoch: 19 | loss: 0.1074477\n",
      "\tspeed: 0.0292s/iter; left time: 7.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.1041605 Vali Loss: 0.1276784 Test Loss: 0.1590157\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05218035355210304, rmse:0.22843019664287567, mae:0.15623831748962402, rse:0.7899434566497803\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3300635\n",
      "\tspeed: 0.0309s/iter; left time: 135.5898s\n",
      "\titers: 200, epoch: 1 | loss: 0.3069834\n",
      "\tspeed: 0.0337s/iter; left time: 144.2476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.3345827 Vali Loss: 0.2615018 Test Loss: 0.2799031\n",
      "Validation loss decreased (inf --> 0.261502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626710\n",
      "\tspeed: 0.0749s/iter; left time: 311.4098s\n",
      "\titers: 200, epoch: 2 | loss: 0.1453529\n",
      "\tspeed: 0.0394s/iter; left time: 159.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 224 | Train Loss: 0.1782290 Vali Loss: 0.1532511 Test Loss: 0.1771102\n",
      "Validation loss decreased (0.261502 --> 0.153251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1456772\n",
      "\tspeed: 0.0628s/iter; left time: 246.9967s\n",
      "\titers: 200, epoch: 3 | loss: 0.1369624\n",
      "\tspeed: 0.0360s/iter; left time: 138.1518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 224 | Train Loss: 0.1406521 Vali Loss: 0.1460541 Test Loss: 0.1696936\n",
      "Validation loss decreased (0.153251 --> 0.146054).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1349763\n",
      "\tspeed: 0.0627s/iter; left time: 232.5751s\n",
      "\titers: 200, epoch: 4 | loss: 0.1190720\n",
      "\tspeed: 0.0320s/iter; left time: 115.5334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.1291489 Vali Loss: 0.1353938 Test Loss: 0.1603968\n",
      "Validation loss decreased (0.146054 --> 0.135394).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1174923\n",
      "\tspeed: 0.0630s/iter; left time: 219.4629s\n",
      "\titers: 200, epoch: 5 | loss: 0.1112894\n",
      "\tspeed: 0.0294s/iter; left time: 99.4007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 224 | Train Loss: 0.1166360 Vali Loss: 0.1304969 Test Loss: 0.1555896\n",
      "Validation loss decreased (0.135394 --> 0.130497).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1105183\n",
      "\tspeed: 0.0646s/iter; left time: 210.6752s\n",
      "\titers: 200, epoch: 6 | loss: 0.1094140\n",
      "\tspeed: 0.0323s/iter; left time: 102.2409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.1125421 Vali Loss: 0.1280145 Test Loss: 0.1537448\n",
      "Validation loss decreased (0.130497 --> 0.128015).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1119591\n",
      "\tspeed: 0.0690s/iter; left time: 209.7042s\n",
      "\titers: 200, epoch: 7 | loss: 0.1081779\n",
      "\tspeed: 0.0384s/iter; left time: 112.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 224 | Train Loss: 0.1108190 Vali Loss: 0.1268316 Test Loss: 0.1527903\n",
      "Validation loss decreased (0.128015 --> 0.126832).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1059798\n",
      "\tspeed: 0.0668s/iter; left time: 187.7766s\n",
      "\titers: 200, epoch: 8 | loss: 0.1082918\n",
      "\tspeed: 0.0288s/iter; left time: 78.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.1093996 Vali Loss: 0.1266075 Test Loss: 0.1539616\n",
      "Validation loss decreased (0.126832 --> 0.126608).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1064540\n",
      "\tspeed: 0.0607s/iter; left time: 157.0302s\n",
      "\titers: 200, epoch: 9 | loss: 0.1133547\n",
      "\tspeed: 0.0332s/iter; left time: 82.5622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.1080566 Vali Loss: 0.1265789 Test Loss: 0.1556840\n",
      "Validation loss decreased (0.126608 --> 0.126579).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1029432\n",
      "\tspeed: 0.0621s/iter; left time: 146.8844s\n",
      "\titers: 200, epoch: 10 | loss: 0.1088319\n",
      "\tspeed: 0.0289s/iter; left time: 65.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.1074244 Vali Loss: 0.1258261 Test Loss: 0.1551538\n",
      "Validation loss decreased (0.126579 --> 0.125826).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1049707\n",
      "\tspeed: 0.0617s/iter; left time: 132.0337s\n",
      "\titers: 200, epoch: 11 | loss: 0.1057446\n",
      "\tspeed: 0.0296s/iter; left time: 60.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.1064734 Vali Loss: 0.1268403 Test Loss: 0.1558869\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1005699\n",
      "\tspeed: 0.0586s/iter; left time: 112.3401s\n",
      "\titers: 200, epoch: 12 | loss: 0.1022382\n",
      "\tspeed: 0.0287s/iter; left time: 52.2294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.1063154 Vali Loss: 0.1260629 Test Loss: 0.1554382\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1023861\n",
      "\tspeed: 0.0617s/iter; left time: 104.4271s\n",
      "\titers: 200, epoch: 13 | loss: 0.1041378\n",
      "\tspeed: 0.0377s/iter; left time: 59.9957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.1061238 Vali Loss: 0.1259569 Test Loss: 0.1549777\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1060393\n",
      "\tspeed: 0.0689s/iter; left time: 101.2662s\n",
      "\titers: 200, epoch: 14 | loss: 0.1075132\n",
      "\tspeed: 0.0382s/iter; left time: 52.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 224 | Train Loss: 0.1054816 Vali Loss: 0.1252780 Test Loss: 0.1558774\n",
      "Validation loss decreased (0.125826 --> 0.125278).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1085446\n",
      "\tspeed: 0.0678s/iter; left time: 84.4009s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065541\n",
      "\tspeed: 0.0362s/iter; left time: 41.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 224 | Train Loss: 0.1048591 Vali Loss: 0.1264124 Test Loss: 0.1563790\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1046837\n",
      "\tspeed: 0.0701s/iter; left time: 71.5390s\n",
      "\titers: 200, epoch: 16 | loss: 0.1055512\n",
      "\tspeed: 0.0341s/iter; left time: 31.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 224 | Train Loss: 0.1045654 Vali Loss: 0.1258728 Test Loss: 0.1556855\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013528\n",
      "\tspeed: 0.0624s/iter; left time: 49.7114s\n",
      "\titers: 200, epoch: 17 | loss: 0.1063012\n",
      "\tspeed: 0.0338s/iter; left time: 23.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.1042688 Vali Loss: 0.1258008 Test Loss: 0.1565767\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1035561\n",
      "\tspeed: 0.0636s/iter; left time: 36.4209s\n",
      "\titers: 200, epoch: 18 | loss: 0.1051094\n",
      "\tspeed: 0.0295s/iter; left time: 13.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.1039990 Vali Loss: 0.1257299 Test Loss: 0.1565168\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1031777\n",
      "\tspeed: 0.0621s/iter; left time: 21.6697s\n",
      "\titers: 200, epoch: 19 | loss: 0.1055896\n",
      "\tspeed: 0.0292s/iter; left time: 7.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 224 | Train Loss: 0.1038695 Vali Loss: 0.1257164 Test Loss: 0.1569353\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05129655823111534, rmse:0.2264874279499054, mae:0.15587741136550903, rse:0.7832251191139221\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:11.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3366266\n",
      "\tspeed: 0.0511s/iter; left time: 222.7563s\n",
      "\titers: 200, epoch: 1 | loss: 0.3121953\n",
      "\tspeed: 0.0300s/iter; left time: 127.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.3369664 Vali Loss: 0.2647370 Test Loss: 0.2830009\n",
      "Validation loss decreased (inf --> 0.264737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651093\n",
      "\tspeed: 0.0585s/iter; left time: 242.0307s\n",
      "\titers: 200, epoch: 2 | loss: 0.1446099\n",
      "\tspeed: 0.0307s/iter; left time: 123.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.1787822 Vali Loss: 0.1586284 Test Loss: 0.1842767\n",
      "Validation loss decreased (0.264737 --> 0.158628).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1485163\n",
      "\tspeed: 0.0590s/iter; left time: 231.0618s\n",
      "\titers: 200, epoch: 3 | loss: 0.1400858\n",
      "\tspeed: 0.0298s/iter; left time: 113.8308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.1445244 Vali Loss: 0.1465050 Test Loss: 0.1715189\n",
      "Validation loss decreased (0.158628 --> 0.146505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1308593\n",
      "\tspeed: 0.0606s/iter; left time: 223.5961s\n",
      "\titers: 200, epoch: 4 | loss: 0.1231993\n",
      "\tspeed: 0.0313s/iter; left time: 112.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 223 | Train Loss: 0.1302476 Vali Loss: 0.1380062 Test Loss: 0.1644330\n",
      "Validation loss decreased (0.146505 --> 0.138006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1219988\n",
      "\tspeed: 0.0597s/iter; left time: 207.1436s\n",
      "\titers: 200, epoch: 5 | loss: 0.1241196\n",
      "\tspeed: 0.0296s/iter; left time: 99.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.1196544 Vali Loss: 0.1335753 Test Loss: 0.1605477\n",
      "Validation loss decreased (0.138006 --> 0.133575).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1183338\n",
      "\tspeed: 0.0582s/iter; left time: 189.0581s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119973\n",
      "\tspeed: 0.0295s/iter; left time: 92.9384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1171256 Vali Loss: 0.1322436 Test Loss: 0.1586682\n",
      "Validation loss decreased (0.133575 --> 0.132244).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1133875\n",
      "\tspeed: 0.0606s/iter; left time: 183.2475s\n",
      "\titers: 200, epoch: 7 | loss: 0.1137060\n",
      "\tspeed: 0.0295s/iter; left time: 86.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.1146362 Vali Loss: 0.1312758 Test Loss: 0.1601958\n",
      "Validation loss decreased (0.132244 --> 0.131276).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1116588\n",
      "\tspeed: 0.0587s/iter; left time: 164.3720s\n",
      "\titers: 200, epoch: 8 | loss: 0.1241252\n",
      "\tspeed: 0.0295s/iter; left time: 79.5488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1129455 Vali Loss: 0.1309668 Test Loss: 0.1592294\n",
      "Validation loss decreased (0.131276 --> 0.130967).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1091937\n",
      "\tspeed: 0.0578s/iter; left time: 148.9205s\n",
      "\titers: 200, epoch: 9 | loss: 0.1055460\n",
      "\tspeed: 0.0293s/iter; left time: 72.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1121144 Vali Loss: 0.1297192 Test Loss: 0.1594340\n",
      "Validation loss decreased (0.130967 --> 0.129719).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1107557\n",
      "\tspeed: 0.0589s/iter; left time: 138.6516s\n",
      "\titers: 200, epoch: 10 | loss: 0.1175592\n",
      "\tspeed: 0.0303s/iter; left time: 68.2081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 223 | Train Loss: 0.1112239 Vali Loss: 0.1295732 Test Loss: 0.1591213\n",
      "Validation loss decreased (0.129719 --> 0.129573).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1079672\n",
      "\tspeed: 0.0582s/iter; left time: 123.9272s\n",
      "\titers: 200, epoch: 11 | loss: 0.1083318\n",
      "\tspeed: 0.0295s/iter; left time: 59.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1106468 Vali Loss: 0.1309009 Test Loss: 0.1610821\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1072241\n",
      "\tspeed: 0.0571s/iter; left time: 108.9562s\n",
      "\titers: 200, epoch: 12 | loss: 0.1056165\n",
      "\tspeed: 0.0329s/iter; left time: 59.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.1101225 Vali Loss: 0.1297053 Test Loss: 0.1603713\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1043832\n",
      "\tspeed: 0.0581s/iter; left time: 97.9220s\n",
      "\titers: 200, epoch: 13 | loss: 0.1069444\n",
      "\tspeed: 0.0294s/iter; left time: 46.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1096867 Vali Loss: 0.1322169 Test Loss: 0.1629731\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1110399\n",
      "\tspeed: 0.0601s/iter; left time: 87.8830s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076464\n",
      "\tspeed: 0.0293s/iter; left time: 39.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.1092416 Vali Loss: 0.1294154 Test Loss: 0.1616850\n",
      "Validation loss decreased (0.129573 --> 0.129415).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1066780\n",
      "\tspeed: 0.0586s/iter; left time: 72.6210s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097973\n",
      "\tspeed: 0.0294s/iter; left time: 33.4401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1091256 Vali Loss: 0.1305313 Test Loss: 0.1634465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1044781\n",
      "\tspeed: 0.0577s/iter; left time: 58.6681s\n",
      "\titers: 200, epoch: 16 | loss: 0.1063152\n",
      "\tspeed: 0.0294s/iter; left time: 26.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.1086627 Vali Loss: 0.1311994 Test Loss: 0.1641488\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1121321\n",
      "\tspeed: 0.0593s/iter; left time: 47.0061s\n",
      "\titers: 200, epoch: 17 | loss: 0.1099676\n",
      "\tspeed: 0.0299s/iter; left time: 20.7135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.1086403 Vali Loss: 0.1308852 Test Loss: 0.1652794\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1089587\n",
      "\tspeed: 0.0611s/iter; left time: 34.8520s\n",
      "\titers: 200, epoch: 18 | loss: 0.1039194\n",
      "\tspeed: 0.0296s/iter; left time: 13.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.1083525 Vali Loss: 0.1308944 Test Loss: 0.1648135\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1075632\n",
      "\tspeed: 0.0583s/iter; left time: 20.2440s\n",
      "\titers: 200, epoch: 19 | loss: 0.1068872\n",
      "\tspeed: 0.0293s/iter; left time: 7.2432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1078722 Vali Loss: 0.1303356 Test Loss: 0.1646044\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05683257430791855, rmse:0.2383958399295807, mae:0.16168498992919922, rse:0.8265526294708252\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3448404\n",
      "\tspeed: 0.0312s/iter; left time: 136.2776s\n",
      "\titers: 200, epoch: 1 | loss: 0.3114725\n",
      "\tspeed: 0.0292s/iter; left time: 124.3874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.3431663 Vali Loss: 0.2624171 Test Loss: 0.2813881\n",
      "Validation loss decreased (inf --> 0.262417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1681919\n",
      "\tspeed: 0.0591s/iter; left time: 244.5712s\n",
      "\titers: 200, epoch: 2 | loss: 0.1522436\n",
      "\tspeed: 0.0298s/iter; left time: 120.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 223 | Train Loss: 0.1822425 Vali Loss: 0.1558322 Test Loss: 0.1810907\n",
      "Validation loss decreased (0.262417 --> 0.155832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1434462\n",
      "\tspeed: 0.0605s/iter; left time: 236.6851s\n",
      "\titers: 200, epoch: 3 | loss: 0.1360027\n",
      "\tspeed: 0.0296s/iter; left time: 113.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.1424184 Vali Loss: 0.1481556 Test Loss: 0.1781064\n",
      "Validation loss decreased (0.155832 --> 0.148156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1272199\n",
      "\tspeed: 0.0601s/iter; left time: 221.8680s\n",
      "\titers: 200, epoch: 4 | loss: 0.1219373\n",
      "\tspeed: 0.0294s/iter; left time: 105.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.1293516 Vali Loss: 0.1383934 Test Loss: 0.1681931\n",
      "Validation loss decreased (0.148156 --> 0.138393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1190115\n",
      "\tspeed: 0.0615s/iter; left time: 213.2216s\n",
      "\titers: 200, epoch: 5 | loss: 0.1149337\n",
      "\tspeed: 0.0296s/iter; left time: 99.7307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.1186070 Vali Loss: 0.1361909 Test Loss: 0.1622809\n",
      "Validation loss decreased (0.138393 --> 0.136191).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1221291\n",
      "\tspeed: 0.0598s/iter; left time: 194.2456s\n",
      "\titers: 200, epoch: 6 | loss: 0.1157978\n",
      "\tspeed: 0.0293s/iter; left time: 92.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.1156672 Vali Loss: 0.1317579 Test Loss: 0.1599577\n",
      "Validation loss decreased (0.136191 --> 0.131758).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1127864\n",
      "\tspeed: 0.0594s/iter; left time: 179.5127s\n",
      "\titers: 200, epoch: 7 | loss: 0.1200389\n",
      "\tspeed: 0.0293s/iter; left time: 85.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1138024 Vali Loss: 0.1312542 Test Loss: 0.1603573\n",
      "Validation loss decreased (0.131758 --> 0.131254).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114607\n",
      "\tspeed: 0.0600s/iter; left time: 168.1036s\n",
      "\titers: 200, epoch: 8 | loss: 0.1170066\n",
      "\tspeed: 0.0302s/iter; left time: 81.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.1124662 Vali Loss: 0.1304371 Test Loss: 0.1605133\n",
      "Validation loss decreased (0.131254 --> 0.130437).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1116766\n",
      "\tspeed: 0.0602s/iter; left time: 155.0131s\n",
      "\titers: 200, epoch: 9 | loss: 0.1159248\n",
      "\tspeed: 0.0294s/iter; left time: 72.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.1115361 Vali Loss: 0.1305044 Test Loss: 0.1607228\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1081617\n",
      "\tspeed: 0.0584s/iter; left time: 137.4055s\n",
      "\titers: 200, epoch: 10 | loss: 0.1107629\n",
      "\tspeed: 0.0294s/iter; left time: 66.1651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1108348 Vali Loss: 0.1290053 Test Loss: 0.1587574\n",
      "Validation loss decreased (0.130437 --> 0.129005).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088022\n",
      "\tspeed: 0.0589s/iter; left time: 125.5169s\n",
      "\titers: 200, epoch: 11 | loss: 0.1097917\n",
      "\tspeed: 0.0296s/iter; left time: 60.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.1103654 Vali Loss: 0.1302083 Test Loss: 0.1607575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1111057\n",
      "\tspeed: 0.0591s/iter; left time: 112.8120s\n",
      "\titers: 200, epoch: 12 | loss: 0.1093946\n",
      "\tspeed: 0.0366s/iter; left time: 66.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.1097317 Vali Loss: 0.1285337 Test Loss: 0.1594696\n",
      "Validation loss decreased (0.129005 --> 0.128534).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1035095\n",
      "\tspeed: 0.0617s/iter; left time: 103.9324s\n",
      "\titers: 200, epoch: 13 | loss: 0.1072009\n",
      "\tspeed: 0.0292s/iter; left time: 46.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1094330 Vali Loss: 0.1300576 Test Loss: 0.1604318\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1161422\n",
      "\tspeed: 0.0587s/iter; left time: 85.7874s\n",
      "\titers: 200, epoch: 14 | loss: 0.1110904\n",
      "\tspeed: 0.0303s/iter; left time: 41.2882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1088140 Vali Loss: 0.1291556 Test Loss: 0.1608481\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1106052\n",
      "\tspeed: 0.0586s/iter; left time: 72.5491s\n",
      "\titers: 200, epoch: 15 | loss: 0.1103900\n",
      "\tspeed: 0.0293s/iter; left time: 33.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1084292 Vali Loss: 0.1281835 Test Loss: 0.1598357\n",
      "Validation loss decreased (0.128534 --> 0.128183).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1077371\n",
      "\tspeed: 0.0596s/iter; left time: 60.5494s\n",
      "\titers: 200, epoch: 16 | loss: 0.1105075\n",
      "\tspeed: 0.0293s/iter; left time: 26.8491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1082942 Vali Loss: 0.1281097 Test Loss: 0.1601676\n",
      "Validation loss decreased (0.128183 --> 0.128110).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1077863\n",
      "\tspeed: 0.0611s/iter; left time: 48.4470s\n",
      "\titers: 200, epoch: 17 | loss: 0.1065453\n",
      "\tspeed: 0.0306s/iter; left time: 21.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 223 | Train Loss: 0.1079001 Vali Loss: 0.1282784 Test Loss: 0.1608187\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1139839\n",
      "\tspeed: 0.0587s/iter; left time: 33.4457s\n",
      "\titers: 200, epoch: 18 | loss: 0.1077382\n",
      "\tspeed: 0.0293s/iter; left time: 13.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1076214 Vali Loss: 0.1287324 Test Loss: 0.1604823\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1091504\n",
      "\tspeed: 0.0629s/iter; left time: 21.8115s\n",
      "\titers: 200, epoch: 19 | loss: 0.1087892\n",
      "\tspeed: 0.0312s/iter; left time: 7.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 223 | Train Loss: 0.1073880 Vali Loss: 0.1278804 Test Loss: 0.1602757\n",
      "Validation loss decreased (0.128110 --> 0.127880).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1067593\n",
      "\tspeed: 0.0613s/iter; left time: 7.5964s\n",
      "\titers: 200, epoch: 20 | loss: 0.1033180\n",
      "\tspeed: 0.0294s/iter; left time: 0.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.1074320 Vali Loss: 0.1289045 Test Loss: 0.1616881\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.055159423500299454, rmse:0.23486043512821198, mae:0.16027556359767914, rse:0.8142948150634766\n",
      "Intermediate time for GB and pred_len 168: 00h:06m:00.73s\n",
      "Intermediate time for GB: 00h:18m:40.02s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3280331\n",
      "\tspeed: 0.0449s/iter; left time: 196.7138s\n",
      "\titers: 200, epoch: 1 | loss: 0.3062457\n",
      "\tspeed: 0.0262s/iter; left time: 112.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.3322086 Vali Loss: 0.2327209 Test Loss: 0.2490792\n",
      "Validation loss decreased (inf --> 0.232721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1790698\n",
      "\tspeed: 0.0433s/iter; left time: 179.9870s\n",
      "\titers: 200, epoch: 2 | loss: 0.1240088\n",
      "\tspeed: 0.0226s/iter; left time: 91.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.1817373 Vali Loss: 0.0993574 Test Loss: 0.1297020\n",
      "Validation loss decreased (0.232721 --> 0.099357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1098694\n",
      "\tspeed: 0.0457s/iter; left time: 179.6809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0996033\n",
      "\tspeed: 0.0218s/iter; left time: 83.6459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.1085433 Vali Loss: 0.0891265 Test Loss: 0.1197414\n",
      "Validation loss decreased (0.099357 --> 0.089126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0921610\n",
      "\tspeed: 0.0503s/iter; left time: 186.4538s\n",
      "\titers: 200, epoch: 4 | loss: 0.0895967\n",
      "\tspeed: 0.0264s/iter; left time: 95.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0948460 Vali Loss: 0.0861677 Test Loss: 0.1175608\n",
      "Validation loss decreased (0.089126 --> 0.086168).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0900297\n",
      "\tspeed: 0.0525s/iter; left time: 183.0169s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834872\n",
      "\tspeed: 0.0294s/iter; left time: 99.6371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.0862508 Vali Loss: 0.0829640 Test Loss: 0.1167970\n",
      "Validation loss decreased (0.086168 --> 0.082964).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831936\n",
      "\tspeed: 0.0428s/iter; left time: 139.6535s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793548\n",
      "\tspeed: 0.0187s/iter; left time: 59.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0819093 Vali Loss: 0.0773864 Test Loss: 0.1101628\n",
      "Validation loss decreased (0.082964 --> 0.077386).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0755749\n",
      "\tspeed: 0.0473s/iter; left time: 143.7521s\n",
      "\titers: 200, epoch: 7 | loss: 0.0745635\n",
      "\tspeed: 0.0276s/iter; left time: 81.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0778414 Vali Loss: 0.0777628 Test Loss: 0.1100845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761717\n",
      "\tspeed: 0.0548s/iter; left time: 154.1631s\n",
      "\titers: 200, epoch: 8 | loss: 0.0765059\n",
      "\tspeed: 0.0338s/iter; left time: 91.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0762376 Vali Loss: 0.0787192 Test Loss: 0.1120105\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749097\n",
      "\tspeed: 0.0448s/iter; left time: 116.1109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0730209\n",
      "\tspeed: 0.0233s/iter; left time: 57.9664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0743153 Vali Loss: 0.0744291 Test Loss: 0.1079679\n",
      "Validation loss decreased (0.077386 --> 0.074429).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0723649\n",
      "\tspeed: 0.0436s/iter; left time: 103.1862s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749586\n",
      "\tspeed: 0.0281s/iter; left time: 63.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0725542 Vali Loss: 0.0720653 Test Loss: 0.1045647\n",
      "Validation loss decreased (0.074429 --> 0.072065).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0698954\n",
      "\tspeed: 0.0451s/iter; left time: 96.6623s\n",
      "\titers: 200, epoch: 11 | loss: 0.0665099\n",
      "\tspeed: 0.0197s/iter; left time: 40.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0712120 Vali Loss: 0.0733315 Test Loss: 0.1072205\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0686331\n",
      "\tspeed: 0.0395s/iter; left time: 75.7594s\n",
      "\titers: 200, epoch: 12 | loss: 0.0743411\n",
      "\tspeed: 0.0294s/iter; left time: 53.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0706372 Vali Loss: 0.0697939 Test Loss: 0.1047984\n",
      "Validation loss decreased (0.072065 --> 0.069794).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659835\n",
      "\tspeed: 0.0555s/iter; left time: 93.9194s\n",
      "\titers: 200, epoch: 13 | loss: 0.0677568\n",
      "\tspeed: 0.0308s/iter; left time: 48.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.0696442 Vali Loss: 0.0698661 Test Loss: 0.1043272\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0699686\n",
      "\tspeed: 0.0433s/iter; left time: 63.6218s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682936\n",
      "\tspeed: 0.0213s/iter; left time: 29.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0691257 Vali Loss: 0.0687277 Test Loss: 0.1038685\n",
      "Validation loss decreased (0.069794 --> 0.068728).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0669770\n",
      "\tspeed: 0.0503s/iter; left time: 62.5976s\n",
      "\titers: 200, epoch: 15 | loss: 0.0678553\n",
      "\tspeed: 0.0300s/iter; left time: 34.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0684012 Vali Loss: 0.0678756 Test Loss: 0.1020736\n",
      "Validation loss decreased (0.068728 --> 0.067876).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683907\n",
      "\tspeed: 0.0474s/iter; left time: 48.4280s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732732\n",
      "\tspeed: 0.0276s/iter; left time: 25.3988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0679654 Vali Loss: 0.0691879 Test Loss: 0.1037720\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676069\n",
      "\tspeed: 0.0478s/iter; left time: 38.0997s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683437\n",
      "\tspeed: 0.0252s/iter; left time: 17.5487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 224 | Train Loss: 0.0671994 Vali Loss: 0.0691082 Test Loss: 0.1038079\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0656383\n",
      "\tspeed: 0.0425s/iter; left time: 24.3277s\n",
      "\titers: 200, epoch: 18 | loss: 0.0635727\n",
      "\tspeed: 0.0195s/iter; left time: 9.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0668719 Vali Loss: 0.0675755 Test Loss: 0.1024245\n",
      "Validation loss decreased (0.067876 --> 0.067575).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0701581\n",
      "\tspeed: 0.0472s/iter; left time: 16.4562s\n",
      "\titers: 200, epoch: 19 | loss: 0.0651758\n",
      "\tspeed: 0.0261s/iter; left time: 6.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0665310 Vali Loss: 0.0670448 Test Loss: 0.1016155\n",
      "Validation loss decreased (0.067575 --> 0.067045).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650204\n",
      "\tspeed: 0.0509s/iter; left time: 6.3586s\n",
      "\titers: 200, epoch: 20 | loss: 0.0690049\n",
      "\tspeed: 0.0266s/iter; left time: 0.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0662901 Vali Loss: 0.0665436 Test Loss: 0.1012922\n",
      "Validation loss decreased (0.067045 --> 0.066544).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03169455751776695, rmse:0.17802965641021729, mae:0.1012922003865242, rse:0.5239197611808777\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3240063\n",
      "\tspeed: 0.0348s/iter; left time: 152.5854s\n",
      "\titers: 200, epoch: 1 | loss: 0.3011152\n",
      "\tspeed: 0.0308s/iter; left time: 132.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.3235901 Vali Loss: 0.2252735 Test Loss: 0.2429013\n",
      "Validation loss decreased (inf --> 0.225273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1841610\n",
      "\tspeed: 0.0457s/iter; left time: 190.0378s\n",
      "\titers: 200, epoch: 2 | loss: 0.1259237\n",
      "\tspeed: 0.0247s/iter; left time: 100.0793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.1811181 Vali Loss: 0.0986894 Test Loss: 0.1299421\n",
      "Validation loss decreased (0.225273 --> 0.098689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1087460\n",
      "\tspeed: 0.0487s/iter; left time: 191.5664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1016842\n",
      "\tspeed: 0.0258s/iter; left time: 98.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.1088129 Vali Loss: 0.0907269 Test Loss: 0.1233280\n",
      "Validation loss decreased (0.098689 --> 0.090727).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0951770\n",
      "\tspeed: 0.0446s/iter; left time: 165.5741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0900192\n",
      "\tspeed: 0.0276s/iter; left time: 99.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0954793 Vali Loss: 0.0849838 Test Loss: 0.1162852\n",
      "Validation loss decreased (0.090727 --> 0.084984).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862284\n",
      "\tspeed: 0.0483s/iter; left time: 168.4167s\n",
      "\titers: 200, epoch: 5 | loss: 0.0845530\n",
      "\tspeed: 0.0207s/iter; left time: 69.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0868355 Vali Loss: 0.0824368 Test Loss: 0.1174904\n",
      "Validation loss decreased (0.084984 --> 0.082437).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821444\n",
      "\tspeed: 0.0496s/iter; left time: 161.8480s\n",
      "\titers: 200, epoch: 6 | loss: 0.0785076\n",
      "\tspeed: 0.0298s/iter; left time: 94.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.0805803 Vali Loss: 0.0795069 Test Loss: 0.1151268\n",
      "Validation loss decreased (0.082437 --> 0.079507).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770724\n",
      "\tspeed: 0.0447s/iter; left time: 135.8707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0726599\n",
      "\tspeed: 0.0233s/iter; left time: 68.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0771316 Vali Loss: 0.0752714 Test Loss: 0.1105221\n",
      "Validation loss decreased (0.079507 --> 0.075271).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758897\n",
      "\tspeed: 0.0489s/iter; left time: 137.5237s\n",
      "\titers: 200, epoch: 8 | loss: 0.0700810\n",
      "\tspeed: 0.0229s/iter; left time: 62.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0749105 Vali Loss: 0.0749520 Test Loss: 0.1096441\n",
      "Validation loss decreased (0.075271 --> 0.074952).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0720540\n",
      "\tspeed: 0.0479s/iter; left time: 124.0353s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773025\n",
      "\tspeed: 0.0260s/iter; left time: 64.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0743595 Vali Loss: 0.0713165 Test Loss: 0.1069118\n",
      "Validation loss decreased (0.074952 --> 0.071316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0705967\n",
      "\tspeed: 0.0437s/iter; left time: 103.3369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688695\n",
      "\tspeed: 0.0257s/iter; left time: 58.1120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0717123 Vali Loss: 0.0725047 Test Loss: 0.1082819\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0786993\n",
      "\tspeed: 0.0412s/iter; left time: 88.1078s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676706\n",
      "\tspeed: 0.0205s/iter; left time: 41.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0705034 Vali Loss: 0.0719281 Test Loss: 0.1085368\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716621\n",
      "\tspeed: 0.0402s/iter; left time: 77.0094s\n",
      "\titers: 200, epoch: 12 | loss: 0.0679636\n",
      "\tspeed: 0.0184s/iter; left time: 33.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0694761 Vali Loss: 0.0707490 Test Loss: 0.1057574\n",
      "Validation loss decreased (0.071316 --> 0.070749).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0692822\n",
      "\tspeed: 0.0432s/iter; left time: 73.0963s\n",
      "\titers: 200, epoch: 13 | loss: 0.0670487\n",
      "\tspeed: 0.0197s/iter; left time: 31.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0691506 Vali Loss: 0.0691561 Test Loss: 0.1026278\n",
      "Validation loss decreased (0.070749 --> 0.069156).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0667814\n",
      "\tspeed: 0.0515s/iter; left time: 75.6873s\n",
      "\titers: 200, epoch: 14 | loss: 0.0683141\n",
      "\tspeed: 0.0285s/iter; left time: 39.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0676780 Vali Loss: 0.0675079 Test Loss: 0.0992190\n",
      "Validation loss decreased (0.069156 --> 0.067508).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0711147\n",
      "\tspeed: 0.0537s/iter; left time: 66.8149s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673262\n",
      "\tspeed: 0.0279s/iter; left time: 31.9285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0678792 Vali Loss: 0.0703952 Test Loss: 0.1050050\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0676657\n",
      "\tspeed: 0.0500s/iter; left time: 51.0445s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665897\n",
      "\tspeed: 0.0307s/iter; left time: 28.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0668736 Vali Loss: 0.0674849 Test Loss: 0.0993137\n",
      "Validation loss decreased (0.067508 --> 0.067485).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0697541\n",
      "\tspeed: 0.0525s/iter; left time: 41.8505s\n",
      "\titers: 200, epoch: 17 | loss: 0.0689287\n",
      "\tspeed: 0.0294s/iter; left time: 20.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0669281 Vali Loss: 0.0677050 Test Loss: 0.1021641\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0695552\n",
      "\tspeed: 0.0534s/iter; left time: 30.5829s\n",
      "\titers: 200, epoch: 18 | loss: 0.0664041\n",
      "\tspeed: 0.0201s/iter; left time: 9.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0661559 Vali Loss: 0.0677006 Test Loss: 0.1009095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0698143\n",
      "\tspeed: 0.0413s/iter; left time: 14.4109s\n",
      "\titers: 200, epoch: 19 | loss: 0.0618790\n",
      "\tspeed: 0.0199s/iter; left time: 4.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0660811 Vali Loss: 0.0664031 Test Loss: 0.0998656\n",
      "Validation loss decreased (0.067485 --> 0.066403).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0708033\n",
      "\tspeed: 0.0410s/iter; left time: 5.1291s\n",
      "\titers: 200, epoch: 20 | loss: 0.0661031\n",
      "\tspeed: 0.0199s/iter; left time: 0.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0655636 Vali Loss: 0.0670016 Test Loss: 0.1006286\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03145262226462364, rmse:0.17734886705875397, mae:0.09986557066440582, rse:0.5219162702560425\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:59.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3315652\n",
      "\tspeed: 0.0546s/iter; left time: 239.4161s\n",
      "\titers: 200, epoch: 1 | loss: 0.3048264\n",
      "\tspeed: 0.0229s/iter; left time: 97.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.3371278 Vali Loss: 0.2310152 Test Loss: 0.2483150\n",
      "Validation loss decreased (inf --> 0.231015).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1515196\n",
      "\tspeed: 0.0593s/iter; left time: 246.6218s\n",
      "\titers: 200, epoch: 2 | loss: 0.1261632\n",
      "\tspeed: 0.0292s/iter; left time: 118.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.1680064 Vali Loss: 0.1113563 Test Loss: 0.1466127\n",
      "Validation loss decreased (0.231015 --> 0.111356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156678\n",
      "\tspeed: 0.0571s/iter; left time: 224.4623s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112574\n",
      "\tspeed: 0.0344s/iter; left time: 131.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.1180376 Vali Loss: 0.1046258 Test Loss: 0.1426476\n",
      "Validation loss decreased (0.111356 --> 0.104626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1120634\n",
      "\tspeed: 0.0573s/iter; left time: 212.5470s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007832\n",
      "\tspeed: 0.0279s/iter; left time: 100.8709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 224 | Train Loss: 0.1083790 Vali Loss: 0.1060640 Test Loss: 0.1551398\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0995809\n",
      "\tspeed: 0.0498s/iter; left time: 173.6846s\n",
      "\titers: 200, epoch: 5 | loss: 0.0972068\n",
      "\tspeed: 0.0295s/iter; left time: 99.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 224 | Train Loss: 0.1011719 Vali Loss: 0.1020747 Test Loss: 0.1501847\n",
      "Validation loss decreased (0.104626 --> 0.102075).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1011587\n",
      "\tspeed: 0.0468s/iter; left time: 152.6189s\n",
      "\titers: 200, epoch: 6 | loss: 0.0956222\n",
      "\tspeed: 0.0255s/iter; left time: 80.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0965476 Vali Loss: 0.0971423 Test Loss: 0.1451695\n",
      "Validation loss decreased (0.102075 --> 0.097142).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0902083\n",
      "\tspeed: 0.0447s/iter; left time: 135.6473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0930668\n",
      "\tspeed: 0.0211s/iter; left time: 62.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0940820 Vali Loss: 0.0942421 Test Loss: 0.1400523\n",
      "Validation loss decreased (0.097142 --> 0.094242).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0921565\n",
      "\tspeed: 0.0533s/iter; left time: 149.8406s\n",
      "\titers: 200, epoch: 8 | loss: 0.0899937\n",
      "\tspeed: 0.0238s/iter; left time: 64.6791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0912714 Vali Loss: 0.0915773 Test Loss: 0.1377201\n",
      "Validation loss decreased (0.094242 --> 0.091577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0887518\n",
      "\tspeed: 0.0567s/iter; left time: 146.8364s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869254\n",
      "\tspeed: 0.0302s/iter; left time: 75.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0903758 Vali Loss: 0.0894141 Test Loss: 0.1365595\n",
      "Validation loss decreased (0.091577 --> 0.089414).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0930247\n",
      "\tspeed: 0.0549s/iter; left time: 129.9307s\n",
      "\titers: 200, epoch: 10 | loss: 0.0881074\n",
      "\tspeed: 0.0301s/iter; left time: 68.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0888782 Vali Loss: 0.0888946 Test Loss: 0.1372542\n",
      "Validation loss decreased (0.089414 --> 0.088895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0862355\n",
      "\tspeed: 0.0482s/iter; left time: 103.1900s\n",
      "\titers: 200, epoch: 11 | loss: 0.0870282\n",
      "\tspeed: 0.0293s/iter; left time: 59.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0880042 Vali Loss: 0.0889236 Test Loss: 0.1354891\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0872819\n",
      "\tspeed: 0.0445s/iter; left time: 85.3862s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861812\n",
      "\tspeed: 0.0233s/iter; left time: 42.3075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0872007 Vali Loss: 0.0884258 Test Loss: 0.1340075\n",
      "Validation loss decreased (0.088895 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0887255\n",
      "\tspeed: 0.0461s/iter; left time: 78.0086s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851904\n",
      "\tspeed: 0.0233s/iter; left time: 37.0498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0865768 Vali Loss: 0.0902111 Test Loss: 0.1376934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0846166\n",
      "\tspeed: 0.0445s/iter; left time: 65.3719s\n",
      "\titers: 200, epoch: 14 | loss: 0.0883543\n",
      "\tspeed: 0.0294s/iter; left time: 40.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0861572 Vali Loss: 0.0874945 Test Loss: 0.1347178\n",
      "Validation loss decreased (0.088426 --> 0.087494).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0862527\n",
      "\tspeed: 0.0454s/iter; left time: 56.5294s\n",
      "\titers: 200, epoch: 15 | loss: 0.0848772\n",
      "\tspeed: 0.0186s/iter; left time: 21.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0854270 Vali Loss: 0.0870578 Test Loss: 0.1343060\n",
      "Validation loss decreased (0.087494 --> 0.087058).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0869423\n",
      "\tspeed: 0.0412s/iter; left time: 42.0909s\n",
      "\titers: 200, epoch: 16 | loss: 0.0879444\n",
      "\tspeed: 0.0186s/iter; left time: 17.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0852942 Vali Loss: 0.0859861 Test Loss: 0.1327333\n",
      "Validation loss decreased (0.087058 --> 0.085986).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0842726\n",
      "\tspeed: 0.0548s/iter; left time: 43.6868s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838040\n",
      "\tspeed: 0.0307s/iter; left time: 21.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0847827 Vali Loss: 0.0873697 Test Loss: 0.1350182\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0835783\n",
      "\tspeed: 0.0531s/iter; left time: 30.4370s\n",
      "\titers: 200, epoch: 18 | loss: 0.0864455\n",
      "\tspeed: 0.0304s/iter; left time: 14.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0846126 Vali Loss: 0.0863356 Test Loss: 0.1339827\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0833691\n",
      "\tspeed: 0.0555s/iter; left time: 19.3555s\n",
      "\titers: 200, epoch: 19 | loss: 0.0822876\n",
      "\tspeed: 0.0255s/iter; left time: 6.3381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.0843596 Vali Loss: 0.0859072 Test Loss: 0.1321979\n",
      "Validation loss decreased (0.085986 --> 0.085907).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0847429\n",
      "\tspeed: 0.0433s/iter; left time: 5.4106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0797493\n",
      "\tspeed: 0.0222s/iter; left time: 0.5552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0841035 Vali Loss: 0.0872152 Test Loss: 0.1352517\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05022406578063965, rmse:0.2241072654724121, mae:0.13219796121120453, rse:0.658359706401825\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3352188\n",
      "\tspeed: 0.0319s/iter; left time: 139.7958s\n",
      "\titers: 200, epoch: 1 | loss: 0.3025524\n",
      "\tspeed: 0.0245s/iter; left time: 104.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.3364650 Vali Loss: 0.2322810 Test Loss: 0.2508384\n",
      "Validation loss decreased (inf --> 0.232281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1519292\n",
      "\tspeed: 0.0554s/iter; left time: 230.3388s\n",
      "\titers: 200, epoch: 2 | loss: 0.1306179\n",
      "\tspeed: 0.0305s/iter; left time: 123.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1691885 Vali Loss: 0.1128382 Test Loss: 0.1485094\n",
      "Validation loss decreased (0.232281 --> 0.112838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1176780\n",
      "\tspeed: 0.0569s/iter; left time: 223.5993s\n",
      "\titers: 200, epoch: 3 | loss: 0.1161417\n",
      "\tspeed: 0.0317s/iter; left time: 121.4818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.1177882 Vali Loss: 0.1091252 Test Loss: 0.1525652\n",
      "Validation loss decreased (0.112838 --> 0.109125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1079238\n",
      "\tspeed: 0.0501s/iter; left time: 185.6999s\n",
      "\titers: 200, epoch: 4 | loss: 0.1016733\n",
      "\tspeed: 0.0306s/iter; left time: 110.5790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.1058076 Vali Loss: 0.1017132 Test Loss: 0.1436944\n",
      "Validation loss decreased (0.109125 --> 0.101713).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1006734\n",
      "\tspeed: 0.0509s/iter; left time: 177.5497s\n",
      "\titers: 200, epoch: 5 | loss: 0.0961927\n",
      "\tspeed: 0.0289s/iter; left time: 97.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0991864 Vali Loss: 0.0994525 Test Loss: 0.1395824\n",
      "Validation loss decreased (0.101713 --> 0.099453).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026271\n",
      "\tspeed: 0.0444s/iter; left time: 144.9442s\n",
      "\titers: 200, epoch: 6 | loss: 0.0901057\n",
      "\tspeed: 0.0219s/iter; left time: 69.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0952561 Vali Loss: 0.0934377 Test Loss: 0.1342140\n",
      "Validation loss decreased (0.099453 --> 0.093438).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0931007\n",
      "\tspeed: 0.0479s/iter; left time: 145.5719s\n",
      "\titers: 200, epoch: 7 | loss: 0.0870902\n",
      "\tspeed: 0.0255s/iter; left time: 74.8115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0924912 Vali Loss: 0.0921764 Test Loss: 0.1331230\n",
      "Validation loss decreased (0.093438 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0872020\n",
      "\tspeed: 0.0550s/iter; left time: 154.8175s\n",
      "\titers: 200, epoch: 8 | loss: 0.0854113\n",
      "\tspeed: 0.0304s/iter; left time: 82.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 224 | Train Loss: 0.0911417 Vali Loss: 0.0893332 Test Loss: 0.1317367\n",
      "Validation loss decreased (0.092176 --> 0.089333).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0893634\n",
      "\tspeed: 0.0533s/iter; left time: 138.0018s\n",
      "\titers: 200, epoch: 9 | loss: 0.0943796\n",
      "\tspeed: 0.0290s/iter; left time: 72.2228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 224 | Train Loss: 0.0893636 Vali Loss: 0.0897438 Test Loss: 0.1309265\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850024\n",
      "\tspeed: 0.0519s/iter; left time: 122.6709s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844018\n",
      "\tspeed: 0.0264s/iter; left time: 59.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0881412 Vali Loss: 0.0873415 Test Loss: 0.1271393\n",
      "Validation loss decreased (0.089333 --> 0.087342).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0928675\n",
      "\tspeed: 0.0495s/iter; left time: 105.9405s\n",
      "\titers: 200, epoch: 11 | loss: 0.0848214\n",
      "\tspeed: 0.0208s/iter; left time: 42.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0881503 Vali Loss: 0.0879250 Test Loss: 0.1270414\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0861826\n",
      "\tspeed: 0.0445s/iter; left time: 85.3292s\n",
      "\titers: 200, epoch: 12 | loss: 0.0823760\n",
      "\tspeed: 0.0214s/iter; left time: 38.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0868916 Vali Loss: 0.0868427 Test Loss: 0.1267310\n",
      "Validation loss decreased (0.087342 --> 0.086843).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0828384\n",
      "\tspeed: 0.0469s/iter; left time: 79.3818s\n",
      "\titers: 200, epoch: 13 | loss: 0.0869917\n",
      "\tspeed: 0.0274s/iter; left time: 43.5981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0858966 Vali Loss: 0.0871766 Test Loss: 0.1276436\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0863992\n",
      "\tspeed: 0.0512s/iter; left time: 75.2184s\n",
      "\titers: 200, epoch: 14 | loss: 0.0853098\n",
      "\tspeed: 0.0235s/iter; left time: 32.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0851917 Vali Loss: 0.0843905 Test Loss: 0.1251583\n",
      "Validation loss decreased (0.086843 --> 0.084391).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0881202\n",
      "\tspeed: 0.0514s/iter; left time: 64.0203s\n",
      "\titers: 200, epoch: 15 | loss: 0.0820398\n",
      "\tspeed: 0.0302s/iter; left time: 34.5784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0845152 Vali Loss: 0.0841971 Test Loss: 0.1257131\n",
      "Validation loss decreased (0.084391 --> 0.084197).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0846898\n",
      "\tspeed: 0.0506s/iter; left time: 51.6720s\n",
      "\titers: 200, epoch: 16 | loss: 0.0868959\n",
      "\tspeed: 0.0306s/iter; left time: 28.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0859426 Vali Loss: 0.0851005 Test Loss: 0.1263184\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0823267\n",
      "\tspeed: 0.0605s/iter; left time: 48.2132s\n",
      "\titers: 200, epoch: 17 | loss: 0.0851173\n",
      "\tspeed: 0.0257s/iter; left time: 17.9334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0843479 Vali Loss: 0.0840246 Test Loss: 0.1252312\n",
      "Validation loss decreased (0.084197 --> 0.084025).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812925\n",
      "\tspeed: 0.0550s/iter; left time: 31.4888s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866565\n",
      "\tspeed: 0.0275s/iter; left time: 12.9988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0838354 Vali Loss: 0.0845851 Test Loss: 0.1263972\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0839691\n",
      "\tspeed: 0.0471s/iter; left time: 16.4260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0793351\n",
      "\tspeed: 0.0208s/iter; left time: 5.1761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0839386 Vali Loss: 0.0876493 Test Loss: 0.1280711\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0826305\n",
      "\tspeed: 0.0493s/iter; left time: 6.1639s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824421\n",
      "\tspeed: 0.0307s/iter; left time: 0.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0835652 Vali Loss: 0.0849726 Test Loss: 0.1262683\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04244036599993706, rmse:0.2060105949640274, mae:0.12523116171360016, rse:0.6051971316337585\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:20.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3272073\n",
      "\tspeed: 0.0494s/iter; left time: 215.5407s\n",
      "\titers: 200, epoch: 1 | loss: 0.3026049\n",
      "\tspeed: 0.0219s/iter; left time: 93.4339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.3342721 Vali Loss: 0.2337924 Test Loss: 0.2506682\n",
      "Validation loss decreased (inf --> 0.233792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470250\n",
      "\tspeed: 0.0564s/iter; left time: 233.4766s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291535\n",
      "\tspeed: 0.0258s/iter; left time: 104.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.1645171 Vali Loss: 0.1163712 Test Loss: 0.1542404\n",
      "Validation loss decreased (0.233792 --> 0.116371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1219507\n",
      "\tspeed: 0.0653s/iter; left time: 255.4579s\n",
      "\titers: 200, epoch: 3 | loss: 0.1154138\n",
      "\tspeed: 0.0400s/iter; left time: 152.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 223 | Train Loss: 0.1199075 Vali Loss: 0.1112828 Test Loss: 0.1557654\n",
      "Validation loss decreased (0.116371 --> 0.111283).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1098431\n",
      "\tspeed: 0.0556s/iter; left time: 205.2191s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072883\n",
      "\tspeed: 0.0289s/iter; left time: 103.8325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 223 | Train Loss: 0.1098577 Vali Loss: 0.1073227 Test Loss: 0.1554891\n",
      "Validation loss decreased (0.111283 --> 0.107323).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1021843\n",
      "\tspeed: 0.0586s/iter; left time: 203.1348s\n",
      "\titers: 200, epoch: 5 | loss: 0.1037903\n",
      "\tspeed: 0.0313s/iter; left time: 105.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 223 | Train Loss: 0.1026884 Vali Loss: 0.1045218 Test Loss: 0.1500455\n",
      "Validation loss decreased (0.107323 --> 0.104522).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1068423\n",
      "\tspeed: 0.0509s/iter; left time: 165.1171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0974413\n",
      "\tspeed: 0.0256s/iter; left time: 80.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0986868 Vali Loss: 0.1024585 Test Loss: 0.1526809\n",
      "Validation loss decreased (0.104522 --> 0.102459).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0941754\n",
      "\tspeed: 0.0493s/iter; left time: 148.9453s\n",
      "\titers: 200, epoch: 7 | loss: 0.0970213\n",
      "\tspeed: 0.0248s/iter; left time: 72.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.0964046 Vali Loss: 0.0974908 Test Loss: 0.1487274\n",
      "Validation loss decreased (0.102459 --> 0.097491).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0978848\n",
      "\tspeed: 0.0605s/iter; left time: 169.4850s\n",
      "\titers: 200, epoch: 8 | loss: 0.1064261\n",
      "\tspeed: 0.0322s/iter; left time: 86.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 223 | Train Loss: 0.0954354 Vali Loss: 0.0973079 Test Loss: 0.1464562\n",
      "Validation loss decreased (0.097491 --> 0.097308).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0910053\n",
      "\tspeed: 0.0535s/iter; left time: 137.9375s\n",
      "\titers: 200, epoch: 9 | loss: 0.0877116\n",
      "\tspeed: 0.0326s/iter; left time: 80.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.0934517 Vali Loss: 0.0933162 Test Loss: 0.1411466\n",
      "Validation loss decreased (0.097308 --> 0.093316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0917288\n",
      "\tspeed: 0.0555s/iter; left time: 130.6530s\n",
      "\titers: 200, epoch: 10 | loss: 0.0891469\n",
      "\tspeed: 0.0249s/iter; left time: 56.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0928747 Vali Loss: 0.0937422 Test Loss: 0.1440561\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0894130\n",
      "\tspeed: 0.0531s/iter; left time: 113.0766s\n",
      "\titers: 200, epoch: 11 | loss: 0.0897102\n",
      "\tspeed: 0.0293s/iter; left time: 59.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0916440 Vali Loss: 0.0934271 Test Loss: 0.1425395\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0876455\n",
      "\tspeed: 0.0551s/iter; left time: 105.0648s\n",
      "\titers: 200, epoch: 12 | loss: 0.0936328\n",
      "\tspeed: 0.0260s/iter; left time: 46.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0904704 Vali Loss: 0.0943040 Test Loss: 0.1463207\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893361\n",
      "\tspeed: 0.0499s/iter; left time: 84.0235s\n",
      "\titers: 200, epoch: 13 | loss: 0.0908853\n",
      "\tspeed: 0.0259s/iter; left time: 41.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0904523 Vali Loss: 0.0927199 Test Loss: 0.1441108\n",
      "Validation loss decreased (0.093316 --> 0.092720).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967873\n",
      "\tspeed: 0.0624s/iter; left time: 91.1900s\n",
      "\titers: 200, epoch: 14 | loss: 0.0869694\n",
      "\tspeed: 0.0357s/iter; left time: 48.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 223 | Train Loss: 0.0897502 Vali Loss: 0.0960521 Test Loss: 0.1475645\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0868967\n",
      "\tspeed: 0.0516s/iter; left time: 63.9883s\n",
      "\titers: 200, epoch: 15 | loss: 0.0878250\n",
      "\tspeed: 0.0215s/iter; left time: 24.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0895878 Vali Loss: 0.0941561 Test Loss: 0.1457388\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865125\n",
      "\tspeed: 0.0532s/iter; left time: 54.0563s\n",
      "\titers: 200, epoch: 16 | loss: 0.0896552\n",
      "\tspeed: 0.0288s/iter; left time: 26.3536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 223 | Train Loss: 0.0891077 Vali Loss: 0.0912570 Test Loss: 0.1434957\n",
      "Validation loss decreased (0.092720 --> 0.091257).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0917246\n",
      "\tspeed: 0.0537s/iter; left time: 42.6115s\n",
      "\titers: 200, epoch: 17 | loss: 0.0901025\n",
      "\tspeed: 0.0286s/iter; left time: 19.8536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0885562 Vali Loss: 0.0902318 Test Loss: 0.1420662\n",
      "Validation loss decreased (0.091257 --> 0.090232).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863970\n",
      "\tspeed: 0.0582s/iter; left time: 33.1871s\n",
      "\titers: 200, epoch: 18 | loss: 0.0868525\n",
      "\tspeed: 0.0329s/iter; left time: 15.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 223 | Train Loss: 0.0880472 Vali Loss: 0.0911535 Test Loss: 0.1439678\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0932073\n",
      "\tspeed: 0.0530s/iter; left time: 18.4039s\n",
      "\titers: 200, epoch: 19 | loss: 0.0869107\n",
      "\tspeed: 0.0191s/iter; left time: 4.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0879256 Vali Loss: 0.0903262 Test Loss: 0.1419569\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0866946\n",
      "\tspeed: 0.0566s/iter; left time: 7.0178s\n",
      "\titers: 200, epoch: 20 | loss: 0.0920869\n",
      "\tspeed: 0.0248s/iter; left time: 0.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0874827 Vali Loss: 0.0898795 Test Loss: 0.1401584\n",
      "Validation loss decreased (0.090232 --> 0.089879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.053760867565870285, rmse:0.23186390101909637, mae:0.14015838503837585, rse:0.6811953186988831\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3325249\n",
      "\tspeed: 0.0352s/iter; left time: 153.5546s\n",
      "\titers: 200, epoch: 1 | loss: 0.3036836\n",
      "\tspeed: 0.0300s/iter; left time: 128.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 223 | Train Loss: 0.3378976 Vali Loss: 0.2335328 Test Loss: 0.2497145\n",
      "Validation loss decreased (inf --> 0.233533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1525073\n",
      "\tspeed: 0.0549s/iter; left time: 227.2574s\n",
      "\titers: 200, epoch: 2 | loss: 0.1282728\n",
      "\tspeed: 0.0303s/iter; left time: 122.1836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.1679677 Vali Loss: 0.1156138 Test Loss: 0.1517599\n",
      "Validation loss decreased (0.233533 --> 0.115614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1186406\n",
      "\tspeed: 0.0653s/iter; left time: 255.4727s\n",
      "\titers: 200, epoch: 3 | loss: 0.1109349\n",
      "\tspeed: 0.0282s/iter; left time: 107.4377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 223 | Train Loss: 0.1170518 Vali Loss: 0.1114620 Test Loss: 0.1601326\n",
      "Validation loss decreased (0.115614 --> 0.111462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1049514\n",
      "\tspeed: 0.0525s/iter; left time: 193.8241s\n",
      "\titers: 200, epoch: 4 | loss: 0.0991601\n",
      "\tspeed: 0.0299s/iter; left time: 107.5643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 223 | Train Loss: 0.1064693 Vali Loss: 0.1070964 Test Loss: 0.1576497\n",
      "Validation loss decreased (0.111462 --> 0.107096).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1014234\n",
      "\tspeed: 0.0558s/iter; left time: 193.7136s\n",
      "\titers: 200, epoch: 5 | loss: 0.1015412\n",
      "\tspeed: 0.0310s/iter; left time: 104.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.1009228 Vali Loss: 0.1018978 Test Loss: 0.1531383\n",
      "Validation loss decreased (0.107096 --> 0.101898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1002377\n",
      "\tspeed: 0.0552s/iter; left time: 179.0827s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926220\n",
      "\tspeed: 0.0306s/iter; left time: 96.2198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 223 | Train Loss: 0.0982974 Vali Loss: 0.0982990 Test Loss: 0.1478771\n",
      "Validation loss decreased (0.101898 --> 0.098299).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0965383\n",
      "\tspeed: 0.0533s/iter; left time: 161.0717s\n",
      "\titers: 200, epoch: 7 | loss: 0.1073857\n",
      "\tspeed: 0.0285s/iter; left time: 83.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0958014 Vali Loss: 0.0945488 Test Loss: 0.1454805\n",
      "Validation loss decreased (0.098299 --> 0.094549).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0944051\n",
      "\tspeed: 0.0558s/iter; left time: 156.2520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0996613\n",
      "\tspeed: 0.0279s/iter; left time: 75.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.0938202 Vali Loss: 0.0941311 Test Loss: 0.1459381\n",
      "Validation loss decreased (0.094549 --> 0.094131).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0952720\n",
      "\tspeed: 0.0514s/iter; left time: 132.3772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0914937\n",
      "\tspeed: 0.0295s/iter; left time: 73.1769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0926462 Vali Loss: 0.0945315 Test Loss: 0.1443452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0909936\n",
      "\tspeed: 0.0540s/iter; left time: 127.1146s\n",
      "\titers: 200, epoch: 10 | loss: 0.0907522\n",
      "\tspeed: 0.0313s/iter; left time: 70.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.0921186 Vali Loss: 0.0945845 Test Loss: 0.1444769\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0909183\n",
      "\tspeed: 0.0474s/iter; left time: 101.0698s\n",
      "\titers: 200, epoch: 11 | loss: 0.0895526\n",
      "\tspeed: 0.0213s/iter; left time: 43.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0907187 Vali Loss: 0.0965888 Test Loss: 0.1492195\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0886578\n",
      "\tspeed: 0.0510s/iter; left time: 97.3094s\n",
      "\titers: 200, epoch: 12 | loss: 0.0874450\n",
      "\tspeed: 0.0325s/iter; left time: 58.7652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0901906 Vali Loss: 0.0916381 Test Loss: 0.1448544\n",
      "Validation loss decreased (0.094131 --> 0.091638).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0925940\n",
      "\tspeed: 0.0585s/iter; left time: 98.5902s\n",
      "\titers: 200, epoch: 13 | loss: 0.0912999\n",
      "\tspeed: 0.0341s/iter; left time: 54.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 223 | Train Loss: 0.0902250 Vali Loss: 0.0937931 Test Loss: 0.1462685\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0874789\n",
      "\tspeed: 0.0550s/iter; left time: 80.4210s\n",
      "\titers: 200, epoch: 14 | loss: 0.0931408\n",
      "\tspeed: 0.0345s/iter; left time: 47.0257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.0890070 Vali Loss: 0.0912268 Test Loss: 0.1426358\n",
      "Validation loss decreased (0.091638 --> 0.091227).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0887858\n",
      "\tspeed: 0.0526s/iter; left time: 65.1612s\n",
      "\titers: 200, epoch: 15 | loss: 0.0890698\n",
      "\tspeed: 0.0300s/iter; left time: 34.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0884342 Vali Loss: 0.0914985 Test Loss: 0.1442550\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0847876\n",
      "\tspeed: 0.0460s/iter; left time: 46.7410s\n",
      "\titers: 200, epoch: 16 | loss: 0.0888722\n",
      "\tspeed: 0.0290s/iter; left time: 26.5489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0884534 Vali Loss: 0.0916927 Test Loss: 0.1442598\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0877180\n",
      "\tspeed: 0.0660s/iter; left time: 52.3759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0862027\n",
      "\tspeed: 0.0329s/iter; left time: 22.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0882375 Vali Loss: 0.0930869 Test Loss: 0.1462336\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0875793\n",
      "\tspeed: 0.0536s/iter; left time: 30.5495s\n",
      "\titers: 200, epoch: 18 | loss: 0.0881898\n",
      "\tspeed: 0.0293s/iter; left time: 13.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0877962 Vali Loss: 0.0920132 Test Loss: 0.1456427\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0872039\n",
      "\tspeed: 0.0462s/iter; left time: 16.0155s\n",
      "\titers: 200, epoch: 19 | loss: 0.0868675\n",
      "\tspeed: 0.0202s/iter; left time: 4.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0875302 Vali Loss: 0.0901017 Test Loss: 0.1424918\n",
      "Validation loss decreased (0.091227 --> 0.090102).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0860389\n",
      "\tspeed: 0.0438s/iter; left time: 5.4321s\n",
      "\titers: 200, epoch: 20 | loss: 0.0879648\n",
      "\tspeed: 0.0205s/iter; left time: 0.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0871673 Vali Loss: 0.0901394 Test Loss: 0.1426537\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05572858825325966, rmse:0.23606903851032257, mae:0.14249183237552643, rse:0.6935495734214783\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:43.02s\n",
      "Intermediate time for ES: 00h:16m:03.45s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3031570\n",
      "\tspeed: 0.0523s/iter; left time: 229.3035s\n",
      "\titers: 200, epoch: 1 | loss: 0.2661880\n",
      "\tspeed: 0.0268s/iter; left time: 114.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.3031129 Vali Loss: 0.1975509 Test Loss: 0.2047458\n",
      "Validation loss decreased (inf --> 0.197551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1700511\n",
      "\tspeed: 0.0475s/iter; left time: 197.6218s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234627\n",
      "\tspeed: 0.0293s/iter; left time: 118.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.1677709 Vali Loss: 0.1246342 Test Loss: 0.1452387\n",
      "Validation loss decreased (0.197551 --> 0.124634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046241\n",
      "\tspeed: 0.0516s/iter; left time: 203.0255s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946132\n",
      "\tspeed: 0.0277s/iter; left time: 106.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.1051751 Vali Loss: 0.0900916 Test Loss: 0.1030797\n",
      "Validation loss decreased (0.124634 --> 0.090092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0793020\n",
      "\tspeed: 0.0471s/iter; left time: 174.5758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741578\n",
      "\tspeed: 0.0212s/iter; left time: 76.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0806216 Vali Loss: 0.0840992 Test Loss: 0.0945809\n",
      "Validation loss decreased (0.090092 --> 0.084099).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0724940\n",
      "\tspeed: 0.0471s/iter; left time: 164.2871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0706007\n",
      "\tspeed: 0.0310s/iter; left time: 104.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0701725 Vali Loss: 0.0739391 Test Loss: 0.0835122\n",
      "Validation loss decreased (0.084099 --> 0.073939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637366\n",
      "\tspeed: 0.0466s/iter; left time: 151.8785s\n",
      "\titers: 200, epoch: 6 | loss: 0.0639374\n",
      "\tspeed: 0.0280s/iter; left time: 88.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0646443 Vali Loss: 0.0753255 Test Loss: 0.0834676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0603915\n",
      "\tspeed: 0.0524s/iter; left time: 159.2035s\n",
      "\titers: 200, epoch: 7 | loss: 0.0617729\n",
      "\tspeed: 0.0302s/iter; left time: 88.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0620678 Vali Loss: 0.0677964 Test Loss: 0.0761279\n",
      "Validation loss decreased (0.073939 --> 0.067796).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0613004\n",
      "\tspeed: 0.0506s/iter; left time: 142.2780s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569501\n",
      "\tspeed: 0.0269s/iter; left time: 73.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0598886 Vali Loss: 0.0665350 Test Loss: 0.0746689\n",
      "Validation loss decreased (0.067796 --> 0.066535).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581849\n",
      "\tspeed: 0.0451s/iter; left time: 116.6636s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587629\n",
      "\tspeed: 0.0259s/iter; left time: 64.4234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0589584 Vali Loss: 0.0676015 Test Loss: 0.0748784\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0584715\n",
      "\tspeed: 0.0493s/iter; left time: 116.6426s\n",
      "\titers: 200, epoch: 10 | loss: 0.0570730\n",
      "\tspeed: 0.0266s/iter; left time: 60.2790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0572760 Vali Loss: 0.0641024 Test Loss: 0.0710237\n",
      "Validation loss decreased (0.066535 --> 0.064102).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0610658\n",
      "\tspeed: 0.0542s/iter; left time: 115.9994s\n",
      "\titers: 200, epoch: 11 | loss: 0.0637527\n",
      "\tspeed: 0.0287s/iter; left time: 58.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0571127 Vali Loss: 0.0646065 Test Loss: 0.0718394\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540640\n",
      "\tspeed: 0.0476s/iter; left time: 91.1562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0507963\n",
      "\tspeed: 0.0287s/iter; left time: 52.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0559361 Vali Loss: 0.0630240 Test Loss: 0.0695875\n",
      "Validation loss decreased (0.064102 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536563\n",
      "\tspeed: 0.0516s/iter; left time: 87.2751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0561524\n",
      "\tspeed: 0.0212s/iter; left time: 33.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0555018 Vali Loss: 0.0629439 Test Loss: 0.0697007\n",
      "Validation loss decreased (0.063024 --> 0.062944).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0564091\n",
      "\tspeed: 0.0498s/iter; left time: 73.0925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555801\n",
      "\tspeed: 0.0215s/iter; left time: 29.3731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0547870 Vali Loss: 0.0621768 Test Loss: 0.0686022\n",
      "Validation loss decreased (0.062944 --> 0.062177).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0559220\n",
      "\tspeed: 0.0559s/iter; left time: 69.6403s\n",
      "\titers: 200, epoch: 15 | loss: 0.0500105\n",
      "\tspeed: 0.0318s/iter; left time: 36.4613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0544496 Vali Loss: 0.0620015 Test Loss: 0.0682016\n",
      "Validation loss decreased (0.062177 --> 0.062002).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0538385\n",
      "\tspeed: 0.0603s/iter; left time: 61.5185s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594354\n",
      "\tspeed: 0.0313s/iter; left time: 28.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0542660 Vali Loss: 0.0612766 Test Loss: 0.0677436\n",
      "Validation loss decreased (0.062002 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0541625\n",
      "\tspeed: 0.0529s/iter; left time: 42.1516s\n",
      "\titers: 200, epoch: 17 | loss: 0.0515244\n",
      "\tspeed: 0.0294s/iter; left time: 20.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.0538572 Vali Loss: 0.0615994 Test Loss: 0.0680216\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578847\n",
      "\tspeed: 0.0522s/iter; left time: 29.9304s\n",
      "\titers: 200, epoch: 18 | loss: 0.0544322\n",
      "\tspeed: 0.0300s/iter; left time: 14.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0532655 Vali Loss: 0.0612200 Test Loss: 0.0676835\n",
      "Validation loss decreased (0.061277 --> 0.061220).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0533487\n",
      "\tspeed: 0.0480s/iter; left time: 16.7506s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539787\n",
      "\tspeed: 0.0229s/iter; left time: 5.7131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0531338 Vali Loss: 0.0608750 Test Loss: 0.0672109\n",
      "Validation loss decreased (0.061220 --> 0.060875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0544674\n",
      "\tspeed: 0.0519s/iter; left time: 6.4822s\n",
      "\titers: 200, epoch: 20 | loss: 0.0542753\n",
      "\tspeed: 0.0282s/iter; left time: 0.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0529647 Vali Loss: 0.0616055 Test Loss: 0.0680856\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01296120136976242, rmse:0.1138472706079483, mae:0.06721087545156479, rse:0.43921959400177\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3036491\n",
      "\tspeed: 0.0294s/iter; left time: 128.6211s\n",
      "\titers: 200, epoch: 1 | loss: 0.2713493\n",
      "\tspeed: 0.0294s/iter; left time: 125.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 224 | Train Loss: 0.3010282 Vali Loss: 0.1930760 Test Loss: 0.1990146\n",
      "Validation loss decreased (inf --> 0.193076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1711202\n",
      "\tspeed: 0.0459s/iter; left time: 190.7589s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364843\n",
      "\tspeed: 0.0200s/iter; left time: 81.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.1702044 Vali Loss: 0.1243302 Test Loss: 0.1475148\n",
      "Validation loss decreased (0.193076 --> 0.124330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053015\n",
      "\tspeed: 0.0471s/iter; left time: 185.3740s\n",
      "\titers: 200, epoch: 3 | loss: 0.0951417\n",
      "\tspeed: 0.0251s/iter; left time: 96.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.1048861 Vali Loss: 0.0900227 Test Loss: 0.1013165\n",
      "Validation loss decreased (0.124330 --> 0.090023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0833160\n",
      "\tspeed: 0.0425s/iter; left time: 157.5103s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780369\n",
      "\tspeed: 0.0209s/iter; left time: 75.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0830910 Vali Loss: 0.0845501 Test Loss: 0.0971023\n",
      "Validation loss decreased (0.090023 --> 0.084550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0720565\n",
      "\tspeed: 0.0436s/iter; left time: 151.9407s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721459\n",
      "\tspeed: 0.0212s/iter; left time: 71.6099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0735491 Vali Loss: 0.0801926 Test Loss: 0.0912523\n",
      "Validation loss decreased (0.084550 --> 0.080193).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0662238\n",
      "\tspeed: 0.0440s/iter; left time: 143.4327s\n",
      "\titers: 200, epoch: 6 | loss: 0.0631883\n",
      "\tspeed: 0.0208s/iter; left time: 65.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0670113 Vali Loss: 0.0739509 Test Loss: 0.0836558\n",
      "Validation loss decreased (0.080193 --> 0.073951).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0638612\n",
      "\tspeed: 0.0480s/iter; left time: 145.8053s\n",
      "\titers: 200, epoch: 7 | loss: 0.0600191\n",
      "\tspeed: 0.0259s/iter; left time: 76.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0645225 Vali Loss: 0.0720683 Test Loss: 0.0820645\n",
      "Validation loss decreased (0.073951 --> 0.072068).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0673516\n",
      "\tspeed: 0.0460s/iter; left time: 129.2620s\n",
      "\titers: 200, epoch: 8 | loss: 0.0605210\n",
      "\tspeed: 0.0243s/iter; left time: 65.8846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0608083 Vali Loss: 0.0698977 Test Loss: 0.0797139\n",
      "Validation loss decreased (0.072068 --> 0.069898).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0560809\n",
      "\tspeed: 0.0496s/iter; left time: 128.4727s\n",
      "\titers: 200, epoch: 9 | loss: 0.0593896\n",
      "\tspeed: 0.0302s/iter; left time: 75.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0590829 Vali Loss: 0.0688912 Test Loss: 0.0779572\n",
      "Validation loss decreased (0.069898 --> 0.068891).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0566290\n",
      "\tspeed: 0.0469s/iter; left time: 110.8481s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559409\n",
      "\tspeed: 0.0303s/iter; left time: 68.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0577284 Vali Loss: 0.0685555 Test Loss: 0.0780135\n",
      "Validation loss decreased (0.068891 --> 0.068555).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0566271\n",
      "\tspeed: 0.0516s/iter; left time: 110.4843s\n",
      "\titers: 200, epoch: 11 | loss: 0.0555120\n",
      "\tspeed: 0.0292s/iter; left time: 59.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 224 | Train Loss: 0.0565948 Vali Loss: 0.0661794 Test Loss: 0.0750803\n",
      "Validation loss decreased (0.068555 --> 0.066179).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0559720\n",
      "\tspeed: 0.0486s/iter; left time: 93.1670s\n",
      "\titers: 200, epoch: 12 | loss: 0.0543331\n",
      "\tspeed: 0.0215s/iter; left time: 39.1461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0561935 Vali Loss: 0.0662163 Test Loss: 0.0754619\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0613785\n",
      "\tspeed: 0.0506s/iter; left time: 85.6732s\n",
      "\titers: 200, epoch: 13 | loss: 0.0580092\n",
      "\tspeed: 0.0294s/iter; left time: 46.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 224 | Train Loss: 0.0551322 Vali Loss: 0.0654463 Test Loss: 0.0744327\n",
      "Validation loss decreased (0.066179 --> 0.065446).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0513290\n",
      "\tspeed: 0.0480s/iter; left time: 70.4625s\n",
      "\titers: 200, epoch: 14 | loss: 0.0554245\n",
      "\tspeed: 0.0313s/iter; left time: 42.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0545807 Vali Loss: 0.0644772 Test Loss: 0.0730760\n",
      "Validation loss decreased (0.065446 --> 0.064477).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0504967\n",
      "\tspeed: 0.0435s/iter; left time: 54.2173s\n",
      "\titers: 200, epoch: 15 | loss: 0.0576769\n",
      "\tspeed: 0.0238s/iter; left time: 27.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0541460 Vali Loss: 0.0646239 Test Loss: 0.0727789\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545350\n",
      "\tspeed: 0.0518s/iter; left time: 52.9124s\n",
      "\titers: 200, epoch: 16 | loss: 0.0539467\n",
      "\tspeed: 0.0292s/iter; left time: 26.8619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0537262 Vali Loss: 0.0640684 Test Loss: 0.0727816\n",
      "Validation loss decreased (0.064477 --> 0.064068).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0564130\n",
      "\tspeed: 0.0421s/iter; left time: 33.5431s\n",
      "\titers: 200, epoch: 17 | loss: 0.0536563\n",
      "\tspeed: 0.0185s/iter; left time: 12.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0535623 Vali Loss: 0.0634081 Test Loss: 0.0715995\n",
      "Validation loss decreased (0.064068 --> 0.063408).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0550766\n",
      "\tspeed: 0.0441s/iter; left time: 25.2661s\n",
      "\titers: 200, epoch: 18 | loss: 0.0532972\n",
      "\tspeed: 0.0270s/iter; left time: 12.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0528366 Vali Loss: 0.0634656 Test Loss: 0.0714108\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0559715\n",
      "\tspeed: 0.0467s/iter; left time: 16.2939s\n",
      "\titers: 200, epoch: 19 | loss: 0.0530445\n",
      "\tspeed: 0.0246s/iter; left time: 6.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0527167 Vali Loss: 0.0632446 Test Loss: 0.0715925\n",
      "Validation loss decreased (0.063408 --> 0.063245).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535196\n",
      "\tspeed: 0.0527s/iter; left time: 6.5908s\n",
      "\titers: 200, epoch: 20 | loss: 0.0511422\n",
      "\tspeed: 0.0299s/iter; left time: 0.7467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0526694 Vali Loss: 0.0633634 Test Loss: 0.0716642\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.015266279689967632, rmse:0.12355678528547287, mae:0.07159248739480972, rse:0.47667863965034485\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:12.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3053247\n",
      "\tspeed: 0.0474s/iter; left time: 207.8680s\n",
      "\titers: 200, epoch: 1 | loss: 0.2671898\n",
      "\tspeed: 0.0209s/iter; left time: 89.4803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.3101927 Vali Loss: 0.1949117 Test Loss: 0.2026870\n",
      "Validation loss decreased (inf --> 0.194912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1464543\n",
      "\tspeed: 0.0453s/iter; left time: 188.3611s\n",
      "\titers: 200, epoch: 2 | loss: 0.1145843\n",
      "\tspeed: 0.0218s/iter; left time: 88.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.1510744 Vali Loss: 0.1107624 Test Loss: 0.1299908\n",
      "Validation loss decreased (0.194912 --> 0.110762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012661\n",
      "\tspeed: 0.0453s/iter; left time: 178.2363s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927679\n",
      "\tspeed: 0.0200s/iter; left time: 76.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.1001072 Vali Loss: 0.1042898 Test Loss: 0.1226965\n",
      "Validation loss decreased (0.110762 --> 0.104290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856560\n",
      "\tspeed: 0.0437s/iter; left time: 161.9259s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805916\n",
      "\tspeed: 0.0188s/iter; left time: 67.7921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0878769 Vali Loss: 0.0966204 Test Loss: 0.1124682\n",
      "Validation loss decreased (0.104290 --> 0.096620).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0807854\n",
      "\tspeed: 0.0536s/iter; left time: 186.8678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774228\n",
      "\tspeed: 0.0304s/iter; left time: 102.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0789022 Vali Loss: 0.0915065 Test Loss: 0.1068967\n",
      "Validation loss decreased (0.096620 --> 0.091506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809742\n",
      "\tspeed: 0.0527s/iter; left time: 171.9311s\n",
      "\titers: 200, epoch: 6 | loss: 0.0763631\n",
      "\tspeed: 0.0322s/iter; left time: 101.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0754589 Vali Loss: 0.0883207 Test Loss: 0.1032911\n",
      "Validation loss decreased (0.091506 --> 0.088321).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695377\n",
      "\tspeed: 0.0453s/iter; left time: 137.5390s\n",
      "\titers: 200, epoch: 7 | loss: 0.0713625\n",
      "\tspeed: 0.0203s/iter; left time: 59.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0731320 Vali Loss: 0.0885737 Test Loss: 0.1044392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743736\n",
      "\tspeed: 0.0471s/iter; left time: 132.5327s\n",
      "\titers: 200, epoch: 8 | loss: 0.0707687\n",
      "\tspeed: 0.0219s/iter; left time: 59.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0720725 Vali Loss: 0.0876094 Test Loss: 0.1025418\n",
      "Validation loss decreased (0.088321 --> 0.087609).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704825\n",
      "\tspeed: 0.0494s/iter; left time: 127.9278s\n",
      "\titers: 200, epoch: 9 | loss: 0.0673042\n",
      "\tspeed: 0.0297s/iter; left time: 73.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 224 | Train Loss: 0.0707117 Vali Loss: 0.0850467 Test Loss: 0.1002401\n",
      "Validation loss decreased (0.087609 --> 0.085047).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0740139\n",
      "\tspeed: 0.0595s/iter; left time: 140.7188s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683985\n",
      "\tspeed: 0.0314s/iter; left time: 71.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0697940 Vali Loss: 0.0856127 Test Loss: 0.1010424\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0701245\n",
      "\tspeed: 0.0523s/iter; left time: 112.0333s\n",
      "\titers: 200, epoch: 11 | loss: 0.0665256\n",
      "\tspeed: 0.0209s/iter; left time: 42.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0688453 Vali Loss: 0.0830623 Test Loss: 0.0977509\n",
      "Validation loss decreased (0.085047 --> 0.083062).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0666852\n",
      "\tspeed: 0.0437s/iter; left time: 83.7731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0662511\n",
      "\tspeed: 0.0225s/iter; left time: 40.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0682378 Vali Loss: 0.0838902 Test Loss: 0.0993334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0674334\n",
      "\tspeed: 0.0475s/iter; left time: 80.4027s\n",
      "\titers: 200, epoch: 13 | loss: 0.0669474\n",
      "\tspeed: 0.0262s/iter; left time: 41.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0680135 Vali Loss: 0.0823024 Test Loss: 0.0965227\n",
      "Validation loss decreased (0.083062 --> 0.082302).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0662640\n",
      "\tspeed: 0.0534s/iter; left time: 78.4962s\n",
      "\titers: 200, epoch: 14 | loss: 0.0642669\n",
      "\tspeed: 0.0302s/iter; left time: 41.3758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 224 | Train Loss: 0.0673367 Vali Loss: 0.0825047 Test Loss: 0.0972182\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0680349\n",
      "\tspeed: 0.0512s/iter; left time: 63.7049s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660250\n",
      "\tspeed: 0.0305s/iter; left time: 34.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 224 | Train Loss: 0.0673574 Vali Loss: 0.0823004 Test Loss: 0.0961922\n",
      "Validation loss decreased (0.082302 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0733240\n",
      "\tspeed: 0.0556s/iter; left time: 56.7861s\n",
      "\titers: 200, epoch: 16 | loss: 0.0649534\n",
      "\tspeed: 0.0244s/iter; left time: 22.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0667445 Vali Loss: 0.0818571 Test Loss: 0.0957230\n",
      "Validation loss decreased (0.082300 --> 0.081857).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0613340\n",
      "\tspeed: 0.0468s/iter; left time: 37.3144s\n",
      "\titers: 200, epoch: 17 | loss: 0.0651078\n",
      "\tspeed: 0.0313s/iter; left time: 21.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0668929 Vali Loss: 0.0817282 Test Loss: 0.0960675\n",
      "Validation loss decreased (0.081857 --> 0.081728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0673034\n",
      "\tspeed: 0.0471s/iter; left time: 26.9815s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666244\n",
      "\tspeed: 0.0223s/iter; left time: 10.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0662236 Vali Loss: 0.0816988 Test Loss: 0.0955875\n",
      "Validation loss decreased (0.081728 --> 0.081699).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643109\n",
      "\tspeed: 0.0423s/iter; left time: 14.7782s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676606\n",
      "\tspeed: 0.0259s/iter; left time: 6.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.0664485 Vali Loss: 0.0816755 Test Loss: 0.0961933\n",
      "Validation loss decreased (0.081699 --> 0.081676).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0637590\n",
      "\tspeed: 0.0576s/iter; left time: 7.1971s\n",
      "\titers: 200, epoch: 20 | loss: 0.0621488\n",
      "\tspeed: 0.0276s/iter; left time: 0.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0657882 Vali Loss: 0.0817215 Test Loss: 0.0960275\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02705598995089531, rmse:0.1644870489835739, mae:0.09619328379631042, rse:0.6362796425819397\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3108837\n",
      "\tspeed: 0.0302s/iter; left time: 132.4481s\n",
      "\titers: 200, epoch: 1 | loss: 0.2715177\n",
      "\tspeed: 0.0291s/iter; left time: 124.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.3108451 Vali Loss: 0.1967746 Test Loss: 0.2040621\n",
      "Validation loss decreased (inf --> 0.196775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1549554\n",
      "\tspeed: 0.0521s/iter; left time: 216.5178s\n",
      "\titers: 200, epoch: 2 | loss: 0.1135907\n",
      "\tspeed: 0.0282s/iter; left time: 114.5947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.1532687 Vali Loss: 0.1133522 Test Loss: 0.1331124\n",
      "Validation loss decreased (0.196775 --> 0.113352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1013032\n",
      "\tspeed: 0.0551s/iter; left time: 216.6074s\n",
      "\titers: 200, epoch: 3 | loss: 0.0954395\n",
      "\tspeed: 0.0294s/iter; left time: 112.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 224 | Train Loss: 0.1004433 Vali Loss: 0.1051643 Test Loss: 0.1238942\n",
      "Validation loss decreased (0.113352 --> 0.105164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878634\n",
      "\tspeed: 0.0532s/iter; left time: 197.4504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836997\n",
      "\tspeed: 0.0315s/iter; left time: 113.6113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0866122 Vali Loss: 0.1025585 Test Loss: 0.1213774\n",
      "Validation loss decreased (0.105164 --> 0.102559).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0768709\n",
      "\tspeed: 0.0546s/iter; left time: 190.1427s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765896\n",
      "\tspeed: 0.0276s/iter; left time: 93.3119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0797510 Vali Loss: 0.0968424 Test Loss: 0.1145583\n",
      "Validation loss decreased (0.102559 --> 0.096842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0786579\n",
      "\tspeed: 0.0464s/iter; left time: 151.1765s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760415\n",
      "\tspeed: 0.0241s/iter; left time: 76.3288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0762392 Vali Loss: 0.0950832 Test Loss: 0.1129819\n",
      "Validation loss decreased (0.096842 --> 0.095083).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792768\n",
      "\tspeed: 0.0522s/iter; left time: 158.6789s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737199\n",
      "\tspeed: 0.0308s/iter; left time: 90.4150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0742570 Vali Loss: 0.0923439 Test Loss: 0.1103651\n",
      "Validation loss decreased (0.095083 --> 0.092344).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0706322\n",
      "\tspeed: 0.0513s/iter; left time: 144.3110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0771114\n",
      "\tspeed: 0.0211s/iter; left time: 57.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0723770 Vali Loss: 0.0898313 Test Loss: 0.1068650\n",
      "Validation loss decreased (0.092344 --> 0.089831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0676159\n",
      "\tspeed: 0.0473s/iter; left time: 122.5653s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745942\n",
      "\tspeed: 0.0290s/iter; left time: 72.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0725249 Vali Loss: 0.0906453 Test Loss: 0.1079092\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0654886\n",
      "\tspeed: 0.0551s/iter; left time: 130.2269s\n",
      "\titers: 200, epoch: 10 | loss: 0.0678367\n",
      "\tspeed: 0.0264s/iter; left time: 59.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0702825 Vali Loss: 0.0883766 Test Loss: 0.1045693\n",
      "Validation loss decreased (0.089831 --> 0.088377).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0687106\n",
      "\tspeed: 0.0475s/iter; left time: 101.6445s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669637\n",
      "\tspeed: 0.0284s/iter; left time: 58.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0693803 Vali Loss: 0.0876922 Test Loss: 0.1039979\n",
      "Validation loss decreased (0.088377 --> 0.087692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0727920\n",
      "\tspeed: 0.0566s/iter; left time: 108.5453s\n",
      "\titers: 200, epoch: 12 | loss: 0.0665965\n",
      "\tspeed: 0.0267s/iter; left time: 48.6018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0690061 Vali Loss: 0.0862251 Test Loss: 0.1019772\n",
      "Validation loss decreased (0.087692 --> 0.086225).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0665514\n",
      "\tspeed: 0.0551s/iter; left time: 93.2968s\n",
      "\titers: 200, epoch: 13 | loss: 0.0682258\n",
      "\tspeed: 0.0304s/iter; left time: 48.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0683277 Vali Loss: 0.0860226 Test Loss: 0.1017762\n",
      "Validation loss decreased (0.086225 --> 0.086023).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677535\n",
      "\tspeed: 0.0560s/iter; left time: 82.2429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669046\n",
      "\tspeed: 0.0263s/iter; left time: 36.0432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0677444 Vali Loss: 0.0857449 Test Loss: 0.1009125\n",
      "Validation loss decreased (0.086023 --> 0.085745).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0670836\n",
      "\tspeed: 0.0527s/iter; left time: 65.6707s\n",
      "\titers: 200, epoch: 15 | loss: 0.0662252\n",
      "\tspeed: 0.0299s/iter; left time: 34.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 224 | Train Loss: 0.0675300 Vali Loss: 0.0837215 Test Loss: 0.0993854\n",
      "Validation loss decreased (0.085745 --> 0.083722).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0678067\n",
      "\tspeed: 0.0464s/iter; left time: 47.3320s\n",
      "\titers: 200, epoch: 16 | loss: 0.0706666\n",
      "\tspeed: 0.0203s/iter; left time: 18.6532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0674310 Vali Loss: 0.0841451 Test Loss: 0.0996885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0636066\n",
      "\tspeed: 0.0432s/iter; left time: 34.4392s\n",
      "\titers: 200, epoch: 17 | loss: 0.0694183\n",
      "\tspeed: 0.0293s/iter; left time: 20.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0666583 Vali Loss: 0.0845393 Test Loss: 0.1000306\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631247\n",
      "\tspeed: 0.0549s/iter; left time: 31.4533s\n",
      "\titers: 200, epoch: 18 | loss: 0.0673969\n",
      "\tspeed: 0.0300s/iter; left time: 14.2086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 224 | Train Loss: 0.0663918 Vali Loss: 0.0844233 Test Loss: 0.0997957\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0673384\n",
      "\tspeed: 0.0495s/iter; left time: 17.2744s\n",
      "\titers: 200, epoch: 19 | loss: 0.0619630\n",
      "\tspeed: 0.0253s/iter; left time: 6.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0662497 Vali Loss: 0.0847994 Test Loss: 0.1004529\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0651463\n",
      "\tspeed: 0.0444s/iter; left time: 5.5477s\n",
      "\titers: 200, epoch: 20 | loss: 0.0591125\n",
      "\tspeed: 0.0200s/iter; left time: 0.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0660254 Vali Loss: 0.0845398 Test Loss: 0.1001053\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.028783556073904037, rmse:0.1696571707725525, mae:0.0993853285908699, rse:0.6562790274620056\n",
      "Intermediate time for FR and pred_len 96: 00h:05m:17.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3056463\n",
      "\tspeed: 0.0480s/iter; left time: 209.2284s\n",
      "\titers: 200, epoch: 1 | loss: 0.2750270\n",
      "\tspeed: 0.0261s/iter; left time: 111.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.3081200 Vali Loss: 0.1966147 Test Loss: 0.2026496\n",
      "Validation loss decreased (inf --> 0.196615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406024\n",
      "\tspeed: 0.0551s/iter; left time: 227.8277s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148641\n",
      "\tspeed: 0.0291s/iter; left time: 117.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.1478834 Vali Loss: 0.1124123 Test Loss: 0.1319528\n",
      "Validation loss decreased (0.196615 --> 0.112412).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1052083\n",
      "\tspeed: 0.0549s/iter; left time: 214.8064s\n",
      "\titers: 200, epoch: 3 | loss: 0.0980960\n",
      "\tspeed: 0.0270s/iter; left time: 102.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.1014490 Vali Loss: 0.1101401 Test Loss: 0.1290472\n",
      "Validation loss decreased (0.112412 --> 0.110140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891950\n",
      "\tspeed: 0.0432s/iter; left time: 159.4362s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838128\n",
      "\tspeed: 0.0254s/iter; left time: 91.1194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0888782 Vali Loss: 0.1001368 Test Loss: 0.1178571\n",
      "Validation loss decreased (0.110140 --> 0.100137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785809\n",
      "\tspeed: 0.0582s/iter; left time: 201.9641s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798440\n",
      "\tspeed: 0.0308s/iter; left time: 103.6161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0801975 Vali Loss: 0.0948170 Test Loss: 0.1117502\n",
      "Validation loss decreased (0.100137 --> 0.094817).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862667\n",
      "\tspeed: 0.0494s/iter; left time: 160.3114s\n",
      "\titers: 200, epoch: 6 | loss: 0.0743461\n",
      "\tspeed: 0.0245s/iter; left time: 77.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0784861 Vali Loss: 0.0913564 Test Loss: 0.1107985\n",
      "Validation loss decreased (0.094817 --> 0.091356).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756594\n",
      "\tspeed: 0.0427s/iter; left time: 129.2244s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737419\n",
      "\tspeed: 0.0296s/iter; left time: 86.6615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0754298 Vali Loss: 0.0909558 Test Loss: 0.1092427\n",
      "Validation loss decreased (0.091356 --> 0.090956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0721901\n",
      "\tspeed: 0.0462s/iter; left time: 129.4476s\n",
      "\titers: 200, epoch: 8 | loss: 0.0744981\n",
      "\tspeed: 0.0233s/iter; left time: 62.8601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0740356 Vali Loss: 0.0898430 Test Loss: 0.1084145\n",
      "Validation loss decreased (0.090956 --> 0.089843).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0712783\n",
      "\tspeed: 0.0451s/iter; left time: 116.2279s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681567\n",
      "\tspeed: 0.0253s/iter; left time: 62.7377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 223 | Train Loss: 0.0729723 Vali Loss: 0.0880685 Test Loss: 0.1060141\n",
      "Validation loss decreased (0.089843 --> 0.088068).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0713213\n",
      "\tspeed: 0.0440s/iter; left time: 103.6184s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768684\n",
      "\tspeed: 0.0227s/iter; left time: 51.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0722284 Vali Loss: 0.0871236 Test Loss: 0.1050940\n",
      "Validation loss decreased (0.088068 --> 0.087124).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0704259\n",
      "\tspeed: 0.0467s/iter; left time: 99.4799s\n",
      "\titers: 200, epoch: 11 | loss: 0.0723021\n",
      "\tspeed: 0.0217s/iter; left time: 44.1079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0715449 Vali Loss: 0.0877762 Test Loss: 0.1076831\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0695812\n",
      "\tspeed: 0.0517s/iter; left time: 98.5954s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746474\n",
      "\tspeed: 0.0299s/iter; left time: 54.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0711022 Vali Loss: 0.0866286 Test Loss: 0.1063094\n",
      "Validation loss decreased (0.087124 --> 0.086629).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0669145\n",
      "\tspeed: 0.0556s/iter; left time: 93.6043s\n",
      "\titers: 200, epoch: 13 | loss: 0.0660579\n",
      "\tspeed: 0.0297s/iter; left time: 47.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.0705118 Vali Loss: 0.0863909 Test Loss: 0.1063076\n",
      "Validation loss decreased (0.086629 --> 0.086391).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0747703\n",
      "\tspeed: 0.0538s/iter; left time: 78.6679s\n",
      "\titers: 200, epoch: 14 | loss: 0.0690772\n",
      "\tspeed: 0.0283s/iter; left time: 38.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0705380 Vali Loss: 0.0877921 Test Loss: 0.1085731\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0695677\n",
      "\tspeed: 0.0523s/iter; left time: 64.8029s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720575\n",
      "\tspeed: 0.0320s/iter; left time: 36.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0704207 Vali Loss: 0.0875006 Test Loss: 0.1082015\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0641172\n",
      "\tspeed: 0.0458s/iter; left time: 46.5049s\n",
      "\titers: 200, epoch: 16 | loss: 0.0675112\n",
      "\tspeed: 0.0289s/iter; left time: 26.4766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0697628 Vali Loss: 0.0860266 Test Loss: 0.1058902\n",
      "Validation loss decreased (0.086391 --> 0.086027).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685382\n",
      "\tspeed: 0.0504s/iter; left time: 40.0030s\n",
      "\titers: 200, epoch: 17 | loss: 0.0676206\n",
      "\tspeed: 0.0303s/iter; left time: 21.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0694674 Vali Loss: 0.0891481 Test Loss: 0.1103076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680806\n",
      "\tspeed: 0.0446s/iter; left time: 25.3975s\n",
      "\titers: 200, epoch: 18 | loss: 0.0670943\n",
      "\tspeed: 0.0244s/iter; left time: 11.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.0694200 Vali Loss: 0.0871083 Test Loss: 0.1089652\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0665102\n",
      "\tspeed: 0.0513s/iter; left time: 17.8135s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682023\n",
      "\tspeed: 0.0330s/iter; left time: 8.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 223 | Train Loss: 0.0689093 Vali Loss: 0.0853713 Test Loss: 0.1053322\n",
      "Validation loss decreased (0.086027 --> 0.085371).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0679075\n",
      "\tspeed: 0.0536s/iter; left time: 6.6511s\n",
      "\titers: 200, epoch: 20 | loss: 0.0668783\n",
      "\tspeed: 0.0293s/iter; left time: 0.7029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0687146 Vali Loss: 0.0857996 Test Loss: 0.1070610\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03186313062906265, rmse:0.17850247025489807, mae:0.10533218085765839, rse:0.6913569569587708\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3110895\n",
      "\tspeed: 0.0269s/iter; left time: 117.1096s\n",
      "\titers: 200, epoch: 1 | loss: 0.2733461\n",
      "\tspeed: 0.0271s/iter; left time: 115.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.3127744 Vali Loss: 0.1956528 Test Loss: 0.2024440\n",
      "Validation loss decreased (inf --> 0.195653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471542\n",
      "\tspeed: 0.0565s/iter; left time: 233.6218s\n",
      "\titers: 200, epoch: 2 | loss: 0.1100252\n",
      "\tspeed: 0.0290s/iter; left time: 117.0689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.1514860 Vali Loss: 0.1148716 Test Loss: 0.1340131\n",
      "Validation loss decreased (0.195653 --> 0.114872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007249\n",
      "\tspeed: 0.0612s/iter; left time: 239.5755s\n",
      "\titers: 200, epoch: 3 | loss: 0.0940878\n",
      "\tspeed: 0.0327s/iter; left time: 124.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.1011317 Vali Loss: 0.1099761 Test Loss: 0.1258833\n",
      "Validation loss decreased (0.114872 --> 0.109976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0898426\n",
      "\tspeed: 0.0586s/iter; left time: 216.2358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866002\n",
      "\tspeed: 0.0325s/iter; left time: 116.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 223 | Train Loss: 0.0888675 Vali Loss: 0.1049041 Test Loss: 0.1241062\n",
      "Validation loss decreased (0.109976 --> 0.104904).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0828300\n",
      "\tspeed: 0.0573s/iter; left time: 198.8695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785435\n",
      "\tspeed: 0.0245s/iter; left time: 82.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0821998 Vali Loss: 0.0974495 Test Loss: 0.1159489\n",
      "Validation loss decreased (0.104904 --> 0.097449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808651\n",
      "\tspeed: 0.0570s/iter; left time: 185.0843s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779448\n",
      "\tspeed: 0.0310s/iter; left time: 97.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0782434 Vali Loss: 0.0961614 Test Loss: 0.1156868\n",
      "Validation loss decreased (0.097449 --> 0.096161).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792456\n",
      "\tspeed: 0.0544s/iter; left time: 164.4935s\n",
      "\titers: 200, epoch: 7 | loss: 0.0795758\n",
      "\tspeed: 0.0213s/iter; left time: 62.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0769779 Vali Loss: 0.0948468 Test Loss: 0.1160244\n",
      "Validation loss decreased (0.096161 --> 0.094847).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0759630\n",
      "\tspeed: 0.0577s/iter; left time: 161.6104s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734885\n",
      "\tspeed: 0.0309s/iter; left time: 83.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 223 | Train Loss: 0.0748855 Vali Loss: 0.0934625 Test Loss: 0.1131503\n",
      "Validation loss decreased (0.094847 --> 0.093462).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718829\n",
      "\tspeed: 0.0636s/iter; left time: 163.9752s\n",
      "\titers: 200, epoch: 9 | loss: 0.0750023\n",
      "\tspeed: 0.0333s/iter; left time: 82.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 223 | Train Loss: 0.0739508 Vali Loss: 0.0917955 Test Loss: 0.1099190\n",
      "Validation loss decreased (0.093462 --> 0.091796).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0739155\n",
      "\tspeed: 0.0618s/iter; left time: 145.4176s\n",
      "\titers: 200, epoch: 10 | loss: 0.0726909\n",
      "\tspeed: 0.0328s/iter; left time: 73.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 223 | Train Loss: 0.0731741 Vali Loss: 0.0906850 Test Loss: 0.1085306\n",
      "Validation loss decreased (0.091796 --> 0.090685).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762428\n",
      "\tspeed: 0.0546s/iter; left time: 116.4046s\n",
      "\titers: 200, epoch: 11 | loss: 0.0733840\n",
      "\tspeed: 0.0292s/iter; left time: 59.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0722653 Vali Loss: 0.0907135 Test Loss: 0.1080224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0699719\n",
      "\tspeed: 0.0635s/iter; left time: 121.1140s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696745\n",
      "\tspeed: 0.0378s/iter; left time: 68.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 223 | Train Loss: 0.0717581 Vali Loss: 0.0898042 Test Loss: 0.1076233\n",
      "Validation loss decreased (0.090685 --> 0.089804).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751506\n",
      "\tspeed: 0.0668s/iter; left time: 112.6022s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705956\n",
      "\tspeed: 0.0399s/iter; left time: 63.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0712911 Vali Loss: 0.0898546 Test Loss: 0.1076015\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0743975\n",
      "\tspeed: 0.0589s/iter; left time: 86.0758s\n",
      "\titers: 200, epoch: 14 | loss: 0.0698327\n",
      "\tspeed: 0.0211s/iter; left time: 28.7812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0708174 Vali Loss: 0.0894737 Test Loss: 0.1074752\n",
      "Validation loss decreased (0.089804 --> 0.089474).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717648\n",
      "\tspeed: 0.0518s/iter; left time: 64.1467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728368\n",
      "\tspeed: 0.0411s/iter; left time: 46.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 223 | Train Loss: 0.0702746 Vali Loss: 0.0885001 Test Loss: 0.1072534\n",
      "Validation loss decreased (0.089474 --> 0.088500).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0670100\n",
      "\tspeed: 0.0587s/iter; left time: 59.6616s\n",
      "\titers: 200, epoch: 16 | loss: 0.0725973\n",
      "\tspeed: 0.0273s/iter; left time: 24.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0705790 Vali Loss: 0.0885262 Test Loss: 0.1070511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0700781\n",
      "\tspeed: 0.0571s/iter; left time: 45.3092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727089\n",
      "\tspeed: 0.0328s/iter; left time: 22.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 223 | Train Loss: 0.0698155 Vali Loss: 0.0879518 Test Loss: 0.1063838\n",
      "Validation loss decreased (0.088500 --> 0.087952).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0724899\n",
      "\tspeed: 0.0560s/iter; left time: 31.9221s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700032\n",
      "\tspeed: 0.0278s/iter; left time: 13.0428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 223 | Train Loss: 0.0696845 Vali Loss: 0.0879740 Test Loss: 0.1068064\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675094\n",
      "\tspeed: 0.0534s/iter; left time: 18.5369s\n",
      "\titers: 200, epoch: 19 | loss: 0.0672282\n",
      "\tspeed: 0.0383s/iter; left time: 9.4508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0696365 Vali Loss: 0.0898802 Test Loss: 0.1088626\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0672357\n",
      "\tspeed: 0.0563s/iter; left time: 6.9758s\n",
      "\titers: 200, epoch: 20 | loss: 0.0703758\n",
      "\tspeed: 0.0321s/iter; left time: 0.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 223 | Train Loss: 0.0698509 Vali Loss: 0.0894553 Test Loss: 0.1081365\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03193802013993263, rmse:0.17871211469173431, mae:0.1063838005065918, rse:0.6921689510345459\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:43.53s\n",
      "Intermediate time for FR: 00h:16m:13.23s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3241130\n",
      "\tspeed: 0.0420s/iter; left time: 184.0574s\n",
      "\titers: 200, epoch: 1 | loss: 0.2924705\n",
      "\tspeed: 0.0198s/iter; left time: 84.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.3293812 Vali Loss: 0.2032730 Test Loss: 0.2058396\n",
      "Validation loss decreased (inf --> 0.203273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1823538\n",
      "\tspeed: 0.0478s/iter; left time: 198.5364s\n",
      "\titers: 200, epoch: 2 | loss: 0.1272631\n",
      "\tspeed: 0.0305s/iter; left time: 123.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 224 | Train Loss: 0.1802252 Vali Loss: 0.0967880 Test Loss: 0.1039044\n",
      "Validation loss decreased (0.203273 --> 0.096788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1102813\n",
      "\tspeed: 0.0541s/iter; left time: 212.5999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1015408\n",
      "\tspeed: 0.0281s/iter; left time: 107.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.1101142 Vali Loss: 0.0867770 Test Loss: 0.0935860\n",
      "Validation loss decreased (0.096788 --> 0.086777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0987595\n",
      "\tspeed: 0.0478s/iter; left time: 177.1086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0914146\n",
      "\tspeed: 0.0240s/iter; left time: 86.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0953743 Vali Loss: 0.0836503 Test Loss: 0.0907633\n",
      "Validation loss decreased (0.086777 --> 0.083650).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0914880\n",
      "\tspeed: 0.0477s/iter; left time: 166.1274s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797405\n",
      "\tspeed: 0.0268s/iter; left time: 90.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.0867192 Vali Loss: 0.0805143 Test Loss: 0.0885993\n",
      "Validation loss decreased (0.083650 --> 0.080514).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831972\n",
      "\tspeed: 0.0528s/iter; left time: 172.0713s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841526\n",
      "\tspeed: 0.0272s/iter; left time: 86.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0815772 Vali Loss: 0.0758380 Test Loss: 0.0836374\n",
      "Validation loss decreased (0.080514 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0780363\n",
      "\tspeed: 0.0491s/iter; left time: 149.2396s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747870\n",
      "\tspeed: 0.0300s/iter; left time: 88.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 224 | Train Loss: 0.0782017 Vali Loss: 0.0735970 Test Loss: 0.0810491\n",
      "Validation loss decreased (0.075838 --> 0.073597).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777398\n",
      "\tspeed: 0.0547s/iter; left time: 153.7952s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721127\n",
      "\tspeed: 0.0215s/iter; left time: 58.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0758689 Vali Loss: 0.0717367 Test Loss: 0.0790521\n",
      "Validation loss decreased (0.073597 --> 0.071737).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745881\n",
      "\tspeed: 0.0492s/iter; left time: 127.3377s\n",
      "\titers: 200, epoch: 9 | loss: 0.0750067\n",
      "\tspeed: 0.0238s/iter; left time: 59.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0736036 Vali Loss: 0.0696429 Test Loss: 0.0766724\n",
      "Validation loss decreased (0.071737 --> 0.069643).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727063\n",
      "\tspeed: 0.0487s/iter; left time: 115.1374s\n",
      "\titers: 200, epoch: 10 | loss: 0.0740233\n",
      "\tspeed: 0.0233s/iter; left time: 52.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0722619 Vali Loss: 0.0725336 Test Loss: 0.0788293\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0735900\n",
      "\tspeed: 0.0432s/iter; left time: 92.5136s\n",
      "\titers: 200, epoch: 11 | loss: 0.0679127\n",
      "\tspeed: 0.0229s/iter; left time: 46.8191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0710921 Vali Loss: 0.0678468 Test Loss: 0.0742797\n",
      "Validation loss decreased (0.069643 --> 0.067847).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0689806\n",
      "\tspeed: 0.0487s/iter; left time: 93.4038s\n",
      "\titers: 200, epoch: 12 | loss: 0.0633102\n",
      "\tspeed: 0.0291s/iter; left time: 52.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0697913 Vali Loss: 0.0665521 Test Loss: 0.0731295\n",
      "Validation loss decreased (0.067847 --> 0.066552).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659795\n",
      "\tspeed: 0.0457s/iter; left time: 77.3884s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675767\n",
      "\tspeed: 0.0230s/iter; left time: 36.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0691679 Vali Loss: 0.0673855 Test Loss: 0.0735560\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0673730\n",
      "\tspeed: 0.0425s/iter; left time: 62.3727s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723676\n",
      "\tspeed: 0.0225s/iter; left time: 30.8313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0686567 Vali Loss: 0.0658610 Test Loss: 0.0721688\n",
      "Validation loss decreased (0.066552 --> 0.065861).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665028\n",
      "\tspeed: 0.0447s/iter; left time: 55.6499s\n",
      "\titers: 200, epoch: 15 | loss: 0.0716088\n",
      "\tspeed: 0.0230s/iter; left time: 26.2907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0676216 Vali Loss: 0.0652331 Test Loss: 0.0712755\n",
      "Validation loss decreased (0.065861 --> 0.065233).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0716273\n",
      "\tspeed: 0.0470s/iter; left time: 48.0272s\n",
      "\titers: 200, epoch: 16 | loss: 0.0693894\n",
      "\tspeed: 0.0293s/iter; left time: 27.0215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0673985 Vali Loss: 0.0654312 Test Loss: 0.0713966\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0693793\n",
      "\tspeed: 0.0488s/iter; left time: 38.9217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0694804\n",
      "\tspeed: 0.0269s/iter; left time: 18.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0664789 Vali Loss: 0.0646361 Test Loss: 0.0706474\n",
      "Validation loss decreased (0.065233 --> 0.064636).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657475\n",
      "\tspeed: 0.0536s/iter; left time: 30.7216s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641076\n",
      "\tspeed: 0.0304s/iter; left time: 14.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0663919 Vali Loss: 0.0642198 Test Loss: 0.0705100\n",
      "Validation loss decreased (0.064636 --> 0.064220).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0665292\n",
      "\tspeed: 0.0530s/iter; left time: 18.4989s\n",
      "\titers: 200, epoch: 19 | loss: 0.0665402\n",
      "\tspeed: 0.0241s/iter; left time: 5.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0659680 Vali Loss: 0.0642783 Test Loss: 0.0698895\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0663938\n",
      "\tspeed: 0.0483s/iter; left time: 6.0340s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653906\n",
      "\tspeed: 0.0315s/iter; left time: 0.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0654910 Vali Loss: 0.0632012 Test Loss: 0.0692569\n",
      "Validation loss decreased (0.064220 --> 0.063201).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012533404864370823, rmse:0.11195269227027893, mae:0.06925688683986664, rse:0.4230141043663025\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3260766\n",
      "\tspeed: 0.0292s/iter; left time: 127.9332s\n",
      "\titers: 200, epoch: 1 | loss: 0.2884215\n",
      "\tspeed: 0.0265s/iter; left time: 113.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.3203309 Vali Loss: 0.1930694 Test Loss: 0.1963564\n",
      "Validation loss decreased (inf --> 0.193069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1852431\n",
      "\tspeed: 0.0433s/iter; left time: 180.0874s\n",
      "\titers: 200, epoch: 2 | loss: 0.1311365\n",
      "\tspeed: 0.0209s/iter; left time: 84.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.1803587 Vali Loss: 0.0980424 Test Loss: 0.1045948\n",
      "Validation loss decreased (0.193069 --> 0.098042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1087056\n",
      "\tspeed: 0.0517s/iter; left time: 203.4614s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013638\n",
      "\tspeed: 0.0284s/iter; left time: 108.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.1105208 Vali Loss: 0.0899404 Test Loss: 0.0959410\n",
      "Validation loss decreased (0.098042 --> 0.089940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961066\n",
      "\tspeed: 0.0480s/iter; left time: 178.0176s\n",
      "\titers: 200, epoch: 4 | loss: 0.0961643\n",
      "\tspeed: 0.0277s/iter; left time: 100.1300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0976806 Vali Loss: 0.0867286 Test Loss: 0.0945126\n",
      "Validation loss decreased (0.089940 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0896491\n",
      "\tspeed: 0.0512s/iter; left time: 178.3701s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853310\n",
      "\tspeed: 0.0230s/iter; left time: 77.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0887996 Vali Loss: 0.0804609 Test Loss: 0.0880719\n",
      "Validation loss decreased (0.086729 --> 0.080461).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0824584\n",
      "\tspeed: 0.0429s/iter; left time: 139.7618s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798026\n",
      "\tspeed: 0.0186s/iter; left time: 58.7042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0825577 Vali Loss: 0.0776103 Test Loss: 0.0849037\n",
      "Validation loss decreased (0.080461 --> 0.077610).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0751694\n",
      "\tspeed: 0.0441s/iter; left time: 134.0747s\n",
      "\titers: 200, epoch: 7 | loss: 0.0751700\n",
      "\tspeed: 0.0213s/iter; left time: 62.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0782513 Vali Loss: 0.0735455 Test Loss: 0.0811478\n",
      "Validation loss decreased (0.077610 --> 0.073545).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754821\n",
      "\tspeed: 0.0466s/iter; left time: 131.1935s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745687\n",
      "\tspeed: 0.0227s/iter; left time: 61.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0756319 Vali Loss: 0.0719685 Test Loss: 0.0787906\n",
      "Validation loss decreased (0.073545 --> 0.071968).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0755634\n",
      "\tspeed: 0.0457s/iter; left time: 118.2462s\n",
      "\titers: 200, epoch: 9 | loss: 0.0703089\n",
      "\tspeed: 0.0242s/iter; left time: 60.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0736844 Vali Loss: 0.0697589 Test Loss: 0.0768646\n",
      "Validation loss decreased (0.071968 --> 0.069759).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0734000\n",
      "\tspeed: 0.0444s/iter; left time: 104.9004s\n",
      "\titers: 200, epoch: 10 | loss: 0.0729146\n",
      "\tspeed: 0.0295s/iter; left time: 66.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 224 | Train Loss: 0.0717080 Vali Loss: 0.0689828 Test Loss: 0.0761895\n",
      "Validation loss decreased (0.069759 --> 0.068983).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0725044\n",
      "\tspeed: 0.0466s/iter; left time: 99.8091s\n",
      "\titers: 200, epoch: 11 | loss: 0.0721925\n",
      "\tspeed: 0.0274s/iter; left time: 55.8661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0700212 Vali Loss: 0.0670274 Test Loss: 0.0736000\n",
      "Validation loss decreased (0.068983 --> 0.067027).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0667297\n",
      "\tspeed: 0.0543s/iter; left time: 104.1666s\n",
      "\titers: 200, epoch: 12 | loss: 0.0720936\n",
      "\tspeed: 0.0286s/iter; left time: 51.9624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0692349 Vali Loss: 0.0665584 Test Loss: 0.0733864\n",
      "Validation loss decreased (0.067027 --> 0.066558).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0686679\n",
      "\tspeed: 0.0519s/iter; left time: 87.8388s\n",
      "\titers: 200, epoch: 13 | loss: 0.0660093\n",
      "\tspeed: 0.0267s/iter; left time: 42.5684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 224 | Train Loss: 0.0687345 Vali Loss: 0.0657200 Test Loss: 0.0719715\n",
      "Validation loss decreased (0.066558 --> 0.065720).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0677135\n",
      "\tspeed: 0.0497s/iter; left time: 72.9753s\n",
      "\titers: 200, epoch: 14 | loss: 0.0714047\n",
      "\tspeed: 0.0261s/iter; left time: 35.7285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0679324 Vali Loss: 0.0674945 Test Loss: 0.0741059\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0683160\n",
      "\tspeed: 0.0508s/iter; left time: 63.2257s\n",
      "\titers: 200, epoch: 15 | loss: 0.0621956\n",
      "\tspeed: 0.0319s/iter; left time: 36.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0674553 Vali Loss: 0.0645062 Test Loss: 0.0705446\n",
      "Validation loss decreased (0.065720 --> 0.064506).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0684832\n",
      "\tspeed: 0.0589s/iter; left time: 60.1512s\n",
      "\titers: 200, epoch: 16 | loss: 0.0681714\n",
      "\tspeed: 0.0306s/iter; left time: 28.2121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 224 | Train Loss: 0.0667683 Vali Loss: 0.0639489 Test Loss: 0.0701983\n",
      "Validation loss decreased (0.064506 --> 0.063949).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653762\n",
      "\tspeed: 0.0482s/iter; left time: 38.4204s\n",
      "\titers: 200, epoch: 17 | loss: 0.0679813\n",
      "\tspeed: 0.0234s/iter; left time: 16.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0665032 Vali Loss: 0.0644687 Test Loss: 0.0700730\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0683108\n",
      "\tspeed: 0.0498s/iter; left time: 28.5279s\n",
      "\titers: 200, epoch: 18 | loss: 0.0642735\n",
      "\tspeed: 0.0323s/iter; left time: 15.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 224 | Train Loss: 0.0656873 Vali Loss: 0.0633490 Test Loss: 0.0688658\n",
      "Validation loss decreased (0.063949 --> 0.063349).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0667158\n",
      "\tspeed: 0.0545s/iter; left time: 19.0213s\n",
      "\titers: 200, epoch: 19 | loss: 0.0644505\n",
      "\tspeed: 0.0185s/iter; left time: 4.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0657448 Vali Loss: 0.0648937 Test Loss: 0.0707799\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0652613\n",
      "\tspeed: 0.0445s/iter; left time: 5.5615s\n",
      "\titers: 200, epoch: 20 | loss: 0.0697343\n",
      "\tspeed: 0.0255s/iter; left time: 0.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0652526 Vali Loss: 0.0630473 Test Loss: 0.0683114\n",
      "Validation loss decreased (0.063349 --> 0.063047).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012373764999210835, rmse:0.11123742908239365, mae:0.0683114230632782, rse:0.42031145095825195\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:07.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3342477\n",
      "\tspeed: 0.0447s/iter; left time: 196.0483s\n",
      "\titers: 200, epoch: 1 | loss: 0.2966344\n",
      "\tspeed: 0.0202s/iter; left time: 86.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.3351949 Vali Loss: 0.2028280 Test Loss: 0.2053291\n",
      "Validation loss decreased (inf --> 0.202828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1558569\n",
      "\tspeed: 0.0484s/iter; left time: 201.3748s\n",
      "\titers: 200, epoch: 2 | loss: 0.1292385\n",
      "\tspeed: 0.0236s/iter; left time: 95.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.1685702 Vali Loss: 0.1075267 Test Loss: 0.1149655\n",
      "Validation loss decreased (0.202828 --> 0.107527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1244688\n",
      "\tspeed: 0.0509s/iter; left time: 200.3723s\n",
      "\titers: 200, epoch: 3 | loss: 0.1151195\n",
      "\tspeed: 0.0261s/iter; left time: 100.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1208200 Vali Loss: 0.1044624 Test Loss: 0.1127941\n",
      "Validation loss decreased (0.107527 --> 0.104462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077869\n",
      "\tspeed: 0.0478s/iter; left time: 177.2938s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054402\n",
      "\tspeed: 0.0218s/iter; left time: 78.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1087310 Vali Loss: 0.0986950 Test Loss: 0.1069118\n",
      "Validation loss decreased (0.104462 --> 0.098695).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027654\n",
      "\tspeed: 0.0541s/iter; left time: 188.4992s\n",
      "\titers: 200, epoch: 5 | loss: 0.1014348\n",
      "\tspeed: 0.0261s/iter; left time: 88.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.1021137 Vali Loss: 0.0965420 Test Loss: 0.1046490\n",
      "Validation loss decreased (0.098695 --> 0.096542).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989471\n",
      "\tspeed: 0.0566s/iter; left time: 184.5101s\n",
      "\titers: 200, epoch: 6 | loss: 0.1000381\n",
      "\tspeed: 0.0296s/iter; left time: 93.4089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 224 | Train Loss: 0.0976498 Vali Loss: 0.0944560 Test Loss: 0.1027542\n",
      "Validation loss decreased (0.096542 --> 0.094456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0930226\n",
      "\tspeed: 0.0557s/iter; left time: 169.2020s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953423\n",
      "\tspeed: 0.0297s/iter; left time: 87.0829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0950571 Vali Loss: 0.0902779 Test Loss: 0.0984376\n",
      "Validation loss decreased (0.094456 --> 0.090278).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901980\n",
      "\tspeed: 0.0531s/iter; left time: 149.4826s\n",
      "\titers: 200, epoch: 8 | loss: 0.0943654\n",
      "\tspeed: 0.0259s/iter; left time: 70.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0927207 Vali Loss: 0.0893505 Test Loss: 0.0980295\n",
      "Validation loss decreased (0.090278 --> 0.089350).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0900329\n",
      "\tspeed: 0.0474s/iter; left time: 122.7232s\n",
      "\titers: 200, epoch: 9 | loss: 0.0930791\n",
      "\tspeed: 0.0202s/iter; left time: 50.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0912607 Vali Loss: 0.0872020 Test Loss: 0.0947072\n",
      "Validation loss decreased (0.089350 --> 0.087202).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0901265\n",
      "\tspeed: 0.0469s/iter; left time: 110.9332s\n",
      "\titers: 200, epoch: 10 | loss: 0.0961293\n",
      "\tspeed: 0.0234s/iter; left time: 52.9210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0897692 Vali Loss: 0.0858830 Test Loss: 0.0944918\n",
      "Validation loss decreased (0.087202 --> 0.085883).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0864411\n",
      "\tspeed: 0.0500s/iter; left time: 107.0692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0874748\n",
      "\tspeed: 0.0233s/iter; left time: 47.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 224 | Train Loss: 0.0889523 Vali Loss: 0.0859419 Test Loss: 0.0931551\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0856065\n",
      "\tspeed: 0.0508s/iter; left time: 97.4177s\n",
      "\titers: 200, epoch: 12 | loss: 0.0859468\n",
      "\tspeed: 0.0239s/iter; left time: 43.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 224 | Train Loss: 0.0877325 Vali Loss: 0.0861587 Test Loss: 0.0935987\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0896335\n",
      "\tspeed: 0.0444s/iter; left time: 75.1470s\n",
      "\titers: 200, epoch: 13 | loss: 0.0880722\n",
      "\tspeed: 0.0246s/iter; left time: 39.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0873248 Vali Loss: 0.0875621 Test Loss: 0.0946284\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1004308\n",
      "\tspeed: 0.0543s/iter; left time: 79.8255s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864576\n",
      "\tspeed: 0.0323s/iter; left time: 44.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0864875 Vali Loss: 0.0835620 Test Loss: 0.0915664\n",
      "Validation loss decreased (0.085883 --> 0.083562).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0837932\n",
      "\tspeed: 0.0553s/iter; left time: 68.8204s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837968\n",
      "\tspeed: 0.0303s/iter; left time: 34.6377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0858382 Vali Loss: 0.0836731 Test Loss: 0.0909717\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0854254\n",
      "\tspeed: 0.0442s/iter; left time: 45.0866s\n",
      "\titers: 200, epoch: 16 | loss: 0.0880396\n",
      "\tspeed: 0.0227s/iter; left time: 20.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0854107 Vali Loss: 0.0838805 Test Loss: 0.0915355\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0853538\n",
      "\tspeed: 0.0528s/iter; left time: 42.1163s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814950\n",
      "\tspeed: 0.0292s/iter; left time: 20.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0850889 Vali Loss: 0.0828494 Test Loss: 0.0902955\n",
      "Validation loss decreased (0.083562 --> 0.082849).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0848045\n",
      "\tspeed: 0.0571s/iter; left time: 32.7139s\n",
      "\titers: 200, epoch: 18 | loss: 0.0846333\n",
      "\tspeed: 0.0327s/iter; left time: 15.4777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0845887 Vali Loss: 0.0831546 Test Loss: 0.0906458\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0851608\n",
      "\tspeed: 0.0547s/iter; left time: 19.1050s\n",
      "\titers: 200, epoch: 19 | loss: 0.0858944\n",
      "\tspeed: 0.0294s/iter; left time: 7.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0841915 Vali Loss: 0.0828417 Test Loss: 0.0905262\n",
      "Validation loss decreased (0.082849 --> 0.082842).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0963844\n",
      "\tspeed: 0.0491s/iter; left time: 6.1356s\n",
      "\titers: 200, epoch: 20 | loss: 0.0828180\n",
      "\tspeed: 0.0241s/iter; left time: 0.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0840370 Vali Loss: 0.0831964 Test Loss: 0.0906983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021317047998309135, rmse:0.1460035890340805, mae:0.09052624553442001, rse:0.552055299282074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3315488\n",
      "\tspeed: 0.0328s/iter; left time: 143.7473s\n",
      "\titers: 200, epoch: 1 | loss: 0.2964730\n",
      "\tspeed: 0.0326s/iter; left time: 139.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 224 | Train Loss: 0.3347829 Vali Loss: 0.2020670 Test Loss: 0.2055457\n",
      "Validation loss decreased (inf --> 0.202067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566910\n",
      "\tspeed: 0.0586s/iter; left time: 243.5282s\n",
      "\titers: 200, epoch: 2 | loss: 0.1318579\n",
      "\tspeed: 0.0240s/iter; left time: 97.1983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 224 | Train Loss: 0.1701297 Vali Loss: 0.1086547 Test Loss: 0.1151527\n",
      "Validation loss decreased (0.202067 --> 0.108655).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1186601\n",
      "\tspeed: 0.0545s/iter; left time: 214.2070s\n",
      "\titers: 200, epoch: 3 | loss: 0.1164838\n",
      "\tspeed: 0.0288s/iter; left time: 110.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 224 | Train Loss: 0.1210322 Vali Loss: 0.1048554 Test Loss: 0.1130993\n",
      "Validation loss decreased (0.108655 --> 0.104855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1093321\n",
      "\tspeed: 0.0557s/iter; left time: 206.5679s\n",
      "\titers: 200, epoch: 4 | loss: 0.1035023\n",
      "\tspeed: 0.0300s/iter; left time: 108.1823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 224 | Train Loss: 0.1079807 Vali Loss: 0.1005572 Test Loss: 0.1096718\n",
      "Validation loss decreased (0.104855 --> 0.100557).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027339\n",
      "\tspeed: 0.0581s/iter; left time: 202.5618s\n",
      "\titers: 200, epoch: 5 | loss: 0.0988467\n",
      "\tspeed: 0.0305s/iter; left time: 103.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 224 | Train Loss: 0.1002171 Vali Loss: 0.0943754 Test Loss: 0.1030717\n",
      "Validation loss decreased (0.100557 --> 0.094375).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947172\n",
      "\tspeed: 0.0501s/iter; left time: 163.4469s\n",
      "\titers: 200, epoch: 6 | loss: 0.0907952\n",
      "\tspeed: 0.0289s/iter; left time: 91.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0964468 Vali Loss: 0.0922971 Test Loss: 0.1008487\n",
      "Validation loss decreased (0.094375 --> 0.092297).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0970036\n",
      "\tspeed: 0.0603s/iter; left time: 183.1907s\n",
      "\titers: 200, epoch: 7 | loss: 0.0926471\n",
      "\tspeed: 0.0334s/iter; left time: 98.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0931144 Vali Loss: 0.0879728 Test Loss: 0.0971996\n",
      "Validation loss decreased (0.092297 --> 0.087973).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911590\n",
      "\tspeed: 0.0578s/iter; left time: 162.5461s\n",
      "\titers: 200, epoch: 8 | loss: 0.0975477\n",
      "\tspeed: 0.0313s/iter; left time: 84.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 224 | Train Loss: 0.0920921 Vali Loss: 0.0888528 Test Loss: 0.0970901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0887272\n",
      "\tspeed: 0.0592s/iter; left time: 153.2671s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956185\n",
      "\tspeed: 0.0329s/iter; left time: 81.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0897549 Vali Loss: 0.0890942 Test Loss: 0.0979138\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865468\n",
      "\tspeed: 0.0634s/iter; left time: 149.8778s\n",
      "\titers: 200, epoch: 10 | loss: 0.0878873\n",
      "\tspeed: 0.0348s/iter; left time: 78.7720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0885026 Vali Loss: 0.0873071 Test Loss: 0.0959127\n",
      "Validation loss decreased (0.087973 --> 0.087307).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0860743\n",
      "\tspeed: 0.0580s/iter; left time: 124.1057s\n",
      "\titers: 200, epoch: 11 | loss: 0.0877034\n",
      "\tspeed: 0.0325s/iter; left time: 66.4156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 224 | Train Loss: 0.0875241 Vali Loss: 0.0858103 Test Loss: 0.0951497\n",
      "Validation loss decreased (0.087307 --> 0.085810).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0864757\n",
      "\tspeed: 0.0532s/iter; left time: 101.9849s\n",
      "\titers: 200, epoch: 12 | loss: 0.0795697\n",
      "\tspeed: 0.0368s/iter; left time: 66.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0867332 Vali Loss: 0.0840776 Test Loss: 0.0916556\n",
      "Validation loss decreased (0.085810 --> 0.084078).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0869969\n",
      "\tspeed: 0.0572s/iter; left time: 96.7709s\n",
      "\titers: 200, epoch: 13 | loss: 0.0890389\n",
      "\tspeed: 0.0306s/iter; left time: 48.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 224 | Train Loss: 0.0857792 Vali Loss: 0.0827870 Test Loss: 0.0903907\n",
      "Validation loss decreased (0.084078 --> 0.082787).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0889446\n",
      "\tspeed: 0.0538s/iter; left time: 79.0307s\n",
      "\titers: 200, epoch: 14 | loss: 0.0828328\n",
      "\tspeed: 0.0272s/iter; left time: 37.1789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0851548 Vali Loss: 0.0833536 Test Loss: 0.0917344\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0846801\n",
      "\tspeed: 0.0519s/iter; left time: 64.5707s\n",
      "\titers: 200, epoch: 15 | loss: 0.0800037\n",
      "\tspeed: 0.0331s/iter; left time: 37.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.0847556 Vali Loss: 0.0835403 Test Loss: 0.0912179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0808663\n",
      "\tspeed: 0.0638s/iter; left time: 65.1807s\n",
      "\titers: 200, epoch: 16 | loss: 0.0865189\n",
      "\tspeed: 0.0349s/iter; left time: 32.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0843541 Vali Loss: 0.0828337 Test Loss: 0.0903978\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0834759\n",
      "\tspeed: 0.0546s/iter; left time: 43.5345s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843606\n",
      "\tspeed: 0.0300s/iter; left time: 20.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.0836238 Vali Loss: 0.0822698 Test Loss: 0.0891294\n",
      "Validation loss decreased (0.082787 --> 0.082270).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0869973\n",
      "\tspeed: 0.0558s/iter; left time: 31.9499s\n",
      "\titers: 200, epoch: 18 | loss: 0.0802380\n",
      "\tspeed: 0.0294s/iter; left time: 13.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 224 | Train Loss: 0.0838429 Vali Loss: 0.0838681 Test Loss: 0.0918710\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0906087\n",
      "\tspeed: 0.0595s/iter; left time: 20.7612s\n",
      "\titers: 200, epoch: 19 | loss: 0.0778156\n",
      "\tspeed: 0.0305s/iter; left time: 7.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0832003 Vali Loss: 0.0827956 Test Loss: 0.0905706\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0843093\n",
      "\tspeed: 0.0458s/iter; left time: 5.7291s\n",
      "\titers: 200, epoch: 20 | loss: 0.0784432\n",
      "\tspeed: 0.0295s/iter; left time: 0.7368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0834071 Vali Loss: 0.0828429 Test Loss: 0.0905480\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020632119849324226, rmse:0.14363884925842285, mae:0.08912941813468933, rse:0.5431139469146729\n",
      "Intermediate time for IT and pred_len 96: 00h:05m:39.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3299916\n",
      "\tspeed: 0.0458s/iter; left time: 199.6074s\n",
      "\titers: 200, epoch: 1 | loss: 0.3000069\n",
      "\tspeed: 0.0246s/iter; left time: 104.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.3321474 Vali Loss: 0.2036837 Test Loss: 0.2054069\n",
      "Validation loss decreased (inf --> 0.203684).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1536698\n",
      "\tspeed: 0.0451s/iter; left time: 186.4386s\n",
      "\titers: 200, epoch: 2 | loss: 0.1333364\n",
      "\tspeed: 0.0242s/iter; left time: 97.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.1655924 Vali Loss: 0.1104899 Test Loss: 0.1182266\n",
      "Validation loss decreased (0.203684 --> 0.110490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1203284\n",
      "\tspeed: 0.0447s/iter; left time: 175.0920s\n",
      "\titers: 200, epoch: 3 | loss: 0.1173807\n",
      "\tspeed: 0.0206s/iter; left time: 78.6256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.1221578 Vali Loss: 0.1053292 Test Loss: 0.1129497\n",
      "Validation loss decreased (0.110490 --> 0.105329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1070902\n",
      "\tspeed: 0.0442s/iter; left time: 163.2177s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064659\n",
      "\tspeed: 0.0203s/iter; left time: 72.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.1101036 Vali Loss: 0.1003444 Test Loss: 0.1065617\n",
      "Validation loss decreased (0.105329 --> 0.100344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0988737\n",
      "\tspeed: 0.0495s/iter; left time: 171.7834s\n",
      "\titers: 200, epoch: 5 | loss: 0.1036142\n",
      "\tspeed: 0.0288s/iter; left time: 97.0160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1026914 Vali Loss: 0.0987232 Test Loss: 0.1058409\n",
      "Validation loss decreased (0.100344 --> 0.098723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1027035\n",
      "\tspeed: 0.0496s/iter; left time: 161.1492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0965298\n",
      "\tspeed: 0.0286s/iter; left time: 89.9426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0990277 Vali Loss: 0.0968072 Test Loss: 0.1045042\n",
      "Validation loss decreased (0.098723 --> 0.096807).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958492\n",
      "\tspeed: 0.0540s/iter; left time: 163.0926s\n",
      "\titers: 200, epoch: 7 | loss: 0.1004818\n",
      "\tspeed: 0.0286s/iter; left time: 83.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0961664 Vali Loss: 0.0936732 Test Loss: 0.0995967\n",
      "Validation loss decreased (0.096807 --> 0.093673).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0938658\n",
      "\tspeed: 0.0500s/iter; left time: 140.0598s\n",
      "\titers: 200, epoch: 8 | loss: 0.0944194\n",
      "\tspeed: 0.0242s/iter; left time: 65.3467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0952811 Vali Loss: 0.0935394 Test Loss: 0.1003524\n",
      "Validation loss decreased (0.093673 --> 0.093539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0896352\n",
      "\tspeed: 0.0436s/iter; left time: 112.2954s\n",
      "\titers: 200, epoch: 9 | loss: 0.0914407\n",
      "\tspeed: 0.0239s/iter; left time: 59.1221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0927135 Vali Loss: 0.0923371 Test Loss: 0.0988408\n",
      "Validation loss decreased (0.093539 --> 0.092337).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0901856\n",
      "\tspeed: 0.0520s/iter; left time: 122.4319s\n",
      "\titers: 200, epoch: 10 | loss: 0.0936390\n",
      "\tspeed: 0.0269s/iter; left time: 60.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0917986 Vali Loss: 0.0901431 Test Loss: 0.0960062\n",
      "Validation loss decreased (0.092337 --> 0.090143).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0899440\n",
      "\tspeed: 0.0504s/iter; left time: 107.3716s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883214\n",
      "\tspeed: 0.0276s/iter; left time: 56.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0911774 Vali Loss: 0.0913543 Test Loss: 0.0972036\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0899939\n",
      "\tspeed: 0.0536s/iter; left time: 102.2899s\n",
      "\titers: 200, epoch: 12 | loss: 0.0857778\n",
      "\tspeed: 0.0301s/iter; left time: 54.4454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0901367 Vali Loss: 0.0889537 Test Loss: 0.0949218\n",
      "Validation loss decreased (0.090143 --> 0.088954).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893306\n",
      "\tspeed: 0.0562s/iter; left time: 94.7175s\n",
      "\titers: 200, epoch: 13 | loss: 0.0863610\n",
      "\tspeed: 0.0295s/iter; left time: 46.6968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.0891761 Vali Loss: 0.0884308 Test Loss: 0.0943324\n",
      "Validation loss decreased (0.088954 --> 0.088431).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0908454\n",
      "\tspeed: 0.0493s/iter; left time: 72.0826s\n",
      "\titers: 200, epoch: 14 | loss: 0.0903270\n",
      "\tspeed: 0.0272s/iter; left time: 37.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0885082 Vali Loss: 0.0893701 Test Loss: 0.0943574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0879544\n",
      "\tspeed: 0.0544s/iter; left time: 67.4009s\n",
      "\titers: 200, epoch: 15 | loss: 0.0859830\n",
      "\tspeed: 0.0296s/iter; left time: 33.6650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0881688 Vali Loss: 0.0887465 Test Loss: 0.0948149\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0832802\n",
      "\tspeed: 0.0441s/iter; left time: 44.7560s\n",
      "\titers: 200, epoch: 16 | loss: 0.0854839\n",
      "\tspeed: 0.0202s/iter; left time: 18.5202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0878722 Vali Loss: 0.0877291 Test Loss: 0.0933230\n",
      "Validation loss decreased (0.088431 --> 0.087729).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0858911\n",
      "\tspeed: 0.0475s/iter; left time: 37.6802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0860742\n",
      "\tspeed: 0.0279s/iter; left time: 19.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0874662 Vali Loss: 0.0889209 Test Loss: 0.0942997\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0854234\n",
      "\tspeed: 0.0465s/iter; left time: 26.5191s\n",
      "\titers: 200, epoch: 18 | loss: 0.0837145\n",
      "\tspeed: 0.0232s/iter; left time: 10.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0870829 Vali Loss: 0.0906566 Test Loss: 0.0963612\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0852829\n",
      "\tspeed: 0.0511s/iter; left time: 17.7281s\n",
      "\titers: 200, epoch: 19 | loss: 0.0859199\n",
      "\tspeed: 0.0292s/iter; left time: 7.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0867489 Vali Loss: 0.0890158 Test Loss: 0.0946742\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0866870\n",
      "\tspeed: 0.0500s/iter; left time: 6.2017s\n",
      "\titers: 200, epoch: 20 | loss: 0.0881107\n",
      "\tspeed: 0.0222s/iter; left time: 0.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 223 | Train Loss: 0.0864305 Vali Loss: 0.0892794 Test Loss: 0.0948846\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02238144911825657, rmse:0.14960430562496185, mae:0.09332302957773209, rse:0.5661956667900085\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3329466\n",
      "\tspeed: 0.0308s/iter; left time: 134.1500s\n",
      "\titers: 200, epoch: 1 | loss: 0.3001673\n",
      "\tspeed: 0.0237s/iter; left time: 101.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.3362979 Vali Loss: 0.2034186 Test Loss: 0.2055462\n",
      "Validation loss decreased (inf --> 0.203419).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1564364\n",
      "\tspeed: 0.0536s/iter; left time: 221.6289s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302675\n",
      "\tspeed: 0.0244s/iter; left time: 98.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.1689114 Vali Loss: 0.1121811 Test Loss: 0.1193566\n",
      "Validation loss decreased (0.203419 --> 0.112181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1191837\n",
      "\tspeed: 0.0552s/iter; left time: 215.9162s\n",
      "\titers: 200, epoch: 3 | loss: 0.1136332\n",
      "\tspeed: 0.0292s/iter; left time: 111.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.1195872 Vali Loss: 0.1070493 Test Loss: 0.1161330\n",
      "Validation loss decreased (0.112181 --> 0.107049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1171367\n",
      "\tspeed: 0.0543s/iter; left time: 200.3545s\n",
      "\titers: 200, epoch: 4 | loss: 0.1040029\n",
      "\tspeed: 0.0297s/iter; left time: 106.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.1087133 Vali Loss: 0.1072877 Test Loss: 0.1167374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026915\n",
      "\tspeed: 0.0447s/iter; left time: 154.9020s\n",
      "\titers: 200, epoch: 5 | loss: 0.1027551\n",
      "\tspeed: 0.0215s/iter; left time: 72.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.1024551 Vali Loss: 0.1004836 Test Loss: 0.1088075\n",
      "Validation loss decreased (0.107049 --> 0.100484).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1014442\n",
      "\tspeed: 0.0476s/iter; left time: 154.4224s\n",
      "\titers: 200, epoch: 6 | loss: 0.0935985\n",
      "\tspeed: 0.0205s/iter; left time: 64.5011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0992469 Vali Loss: 0.0981301 Test Loss: 0.1050202\n",
      "Validation loss decreased (0.100484 --> 0.098130).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028433\n",
      "\tspeed: 0.0441s/iter; left time: 133.2190s\n",
      "\titers: 200, epoch: 7 | loss: 0.0974711\n",
      "\tspeed: 0.0206s/iter; left time: 60.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0971664 Vali Loss: 0.0950341 Test Loss: 0.1026516\n",
      "Validation loss decreased (0.098130 --> 0.095034).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0932003\n",
      "\tspeed: 0.0490s/iter; left time: 137.1829s\n",
      "\titers: 200, epoch: 8 | loss: 0.0951514\n",
      "\tspeed: 0.0263s/iter; left time: 70.8812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0946685 Vali Loss: 0.0910811 Test Loss: 0.0989792\n",
      "Validation loss decreased (0.095034 --> 0.091081).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0916397\n",
      "\tspeed: 0.0567s/iter; left time: 146.0020s\n",
      "\titers: 200, epoch: 9 | loss: 0.0932798\n",
      "\tspeed: 0.0333s/iter; left time: 82.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 223 | Train Loss: 0.0939221 Vali Loss: 0.0949594 Test Loss: 0.1033267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0929595\n",
      "\tspeed: 0.0538s/iter; left time: 126.6222s\n",
      "\titers: 200, epoch: 10 | loss: 0.0917582\n",
      "\tspeed: 0.0309s/iter; left time: 69.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0921100 Vali Loss: 0.0958197 Test Loss: 0.1038818\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0930068\n",
      "\tspeed: 0.0429s/iter; left time: 91.4216s\n",
      "\titers: 200, epoch: 11 | loss: 0.0886110\n",
      "\tspeed: 0.0208s/iter; left time: 42.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0916677 Vali Loss: 0.0919321 Test Loss: 0.0984919\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0920270\n",
      "\tspeed: 0.0496s/iter; left time: 94.5557s\n",
      "\titers: 200, epoch: 12 | loss: 0.0926006\n",
      "\tspeed: 0.0277s/iter; left time: 50.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0904331 Vali Loss: 0.0902387 Test Loss: 0.0982403\n",
      "Validation loss decreased (0.091081 --> 0.090239).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0928006\n",
      "\tspeed: 0.0445s/iter; left time: 75.0234s\n",
      "\titers: 200, epoch: 13 | loss: 0.0901859\n",
      "\tspeed: 0.0207s/iter; left time: 32.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0903667 Vali Loss: 0.0920868 Test Loss: 0.1006144\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0870517\n",
      "\tspeed: 0.0440s/iter; left time: 64.3389s\n",
      "\titers: 200, epoch: 14 | loss: 0.0903576\n",
      "\tspeed: 0.0226s/iter; left time: 30.7210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0893385 Vali Loss: 0.0881971 Test Loss: 0.0958530\n",
      "Validation loss decreased (0.090239 --> 0.088197).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0900526\n",
      "\tspeed: 0.0511s/iter; left time: 63.2589s\n",
      "\titers: 200, epoch: 15 | loss: 0.0907226\n",
      "\tspeed: 0.0278s/iter; left time: 31.7171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0890614 Vali Loss: 0.0887460 Test Loss: 0.0959489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865015\n",
      "\tspeed: 0.0578s/iter; left time: 58.7362s\n",
      "\titers: 200, epoch: 16 | loss: 0.0892532\n",
      "\tspeed: 0.0257s/iter; left time: 23.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0883051 Vali Loss: 0.0894168 Test Loss: 0.0971686\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0881911\n",
      "\tspeed: 0.0503s/iter; left time: 39.9124s\n",
      "\titers: 200, epoch: 17 | loss: 0.0895243\n",
      "\tspeed: 0.0287s/iter; left time: 19.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0879117 Vali Loss: 0.0884444 Test Loss: 0.0956225\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0895580\n",
      "\tspeed: 0.0481s/iter; left time: 27.4042s\n",
      "\titers: 200, epoch: 18 | loss: 0.0856539\n",
      "\tspeed: 0.0205s/iter; left time: 9.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0873532 Vali Loss: 0.0885280 Test Loss: 0.0955959\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0862491\n",
      "\tspeed: 0.0550s/iter; left time: 19.0958s\n",
      "\titers: 200, epoch: 19 | loss: 0.0867470\n",
      "\tspeed: 0.0275s/iter; left time: 6.7988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0869722 Vali Loss: 0.0893798 Test Loss: 0.0964291\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02392091415822506, rmse:0.15466387569904327, mae:0.09585300087928772, rse:0.5853442549705505\n",
      "Intermediate time for IT and pred_len 168: 00h:05m:04.56s\n",
      "Intermediate time for IT: 00h:15m:52.49s\n",
      "Total time: 01h:25m:20.18s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN + Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.0972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.0852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            -RevIN + Decomposition                 \n",
       "Metrics                              MSE    RMSE     MAE\n",
       "Country Pred_len                                        \n",
       "DE      24                        0.0222  0.1490  0.0929\n",
       "        96                        0.0401  0.2001  0.1329\n",
       "        168                       0.0434  0.2080  0.1403\n",
       "ES      24                        0.0208  0.1389  0.0807\n",
       "        96                        0.0326  0.1762  0.1083\n",
       "        168                       0.0379  0.1894  0.1180\n",
       "FR      24                        0.0121  0.1098  0.0626\n",
       "        96                        0.0237  0.1533  0.0901\n",
       "        168                       0.0267  0.1628  0.0972\n",
       "GB      24                        0.0268  0.1637  0.1058\n",
       "        96                        0.0480  0.2190  0.1496\n",
       "        168                       0.0508  0.2252  0.1546\n",
       "IT      24                        0.0114  0.1064  0.0633\n",
       "        96                        0.0198  0.1405  0.0852\n",
       "        168                       0.0216  0.1468  0.0902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN + Decomposition '], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
