{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2551474\n",
      "\tspeed: 0.2279s/iter; left time: 5059.3152s\n",
      "\titers: 200, epoch: 1 | loss: 0.2432507\n",
      "\tspeed: 0.0204s/iter; left time: 449.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 223 | Train Loss: 0.2668637 Vali Loss: 0.2238720 Test Loss: 0.2261513\n",
      "Validation loss decreased (inf --> 0.223872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1460399\n",
      "\tspeed: 0.0410s/iter; left time: 902.1688s\n",
      "\titers: 200, epoch: 2 | loss: 0.1216822\n",
      "\tspeed: 0.0200s/iter; left time: 437.5177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.1540140 Vali Loss: 0.1182901 Test Loss: 0.1211827\n",
      "Validation loss decreased (0.223872 --> 0.118290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1031451\n",
      "\tspeed: 0.0410s/iter; left time: 892.2053s\n",
      "\titers: 200, epoch: 3 | loss: 0.0994028\n",
      "\tspeed: 0.0203s/iter; left time: 438.5858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.1050465 Vali Loss: 0.1039644 Test Loss: 0.1058513\n",
      "Validation loss decreased (0.118290 --> 0.103964).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0926209\n",
      "\tspeed: 0.0412s/iter; left time: 887.4343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939199\n",
      "\tspeed: 0.0203s/iter; left time: 434.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0937571 Vali Loss: 0.1005288 Test Loss: 0.1036960\n",
      "Validation loss decreased (0.103964 --> 0.100529).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850811\n",
      "\tspeed: 0.0415s/iter; left time: 884.4378s\n",
      "\titers: 200, epoch: 5 | loss: 0.0833859\n",
      "\tspeed: 0.0201s/iter; left time: 425.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0885040 Vali Loss: 0.0979386 Test Loss: 0.1008237\n",
      "Validation loss decreased (0.100529 --> 0.097939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0871982\n",
      "\tspeed: 0.0428s/iter; left time: 902.2839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802622\n",
      "\tspeed: 0.0207s/iter; left time: 434.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0855585 Vali Loss: 0.0960701 Test Loss: 0.0991458\n",
      "Validation loss decreased (0.097939 --> 0.096070).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0858348\n",
      "\tspeed: 0.0423s/iter; left time: 882.2415s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834494\n",
      "\tspeed: 0.0202s/iter; left time: 420.3030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0836893 Vali Loss: 0.0947459 Test Loss: 0.0976809\n",
      "Validation loss decreased (0.096070 --> 0.094746).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0848817\n",
      "\tspeed: 0.0415s/iter; left time: 856.4181s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845404\n",
      "\tspeed: 0.0202s/iter; left time: 414.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0825642 Vali Loss: 0.0944185 Test Loss: 0.0969981\n",
      "Validation loss decreased (0.094746 --> 0.094418).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0807175\n",
      "\tspeed: 0.0413s/iter; left time: 842.4548s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817962\n",
      "\tspeed: 0.0201s/iter; left time: 407.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0816720 Vali Loss: 0.0936054 Test Loss: 0.0966767\n",
      "Validation loss decreased (0.094418 --> 0.093605).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0784829\n",
      "\tspeed: 0.0410s/iter; left time: 828.5696s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803997\n",
      "\tspeed: 0.0206s/iter; left time: 414.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0807184 Vali Loss: 0.0934066 Test Loss: 0.0967435\n",
      "Validation loss decreased (0.093605 --> 0.093407).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819594\n",
      "\tspeed: 0.0403s/iter; left time: 805.1945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865497\n",
      "\tspeed: 0.0205s/iter; left time: 406.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0801734 Vali Loss: 0.0931065 Test Loss: 0.0961571\n",
      "Validation loss decreased (0.093407 --> 0.093107).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0791169\n",
      "\tspeed: 0.0434s/iter; left time: 856.9073s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787896\n",
      "\tspeed: 0.0201s/iter; left time: 394.6917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0795977 Vali Loss: 0.0921469 Test Loss: 0.0951979\n",
      "Validation loss decreased (0.093107 --> 0.092147).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847492\n",
      "\tspeed: 0.0409s/iter; left time: 798.6956s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785450\n",
      "\tspeed: 0.0200s/iter; left time: 389.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0789553 Vali Loss: 0.0926504 Test Loss: 0.0946430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0829063\n",
      "\tspeed: 0.0429s/iter; left time: 827.5193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0806567\n",
      "\tspeed: 0.0210s/iter; left time: 402.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0787015 Vali Loss: 0.0915155 Test Loss: 0.0943696\n",
      "Validation loss decreased (0.092147 --> 0.091516).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0762333\n",
      "\tspeed: 0.0418s/iter; left time: 797.0623s\n",
      "\titers: 200, epoch: 15 | loss: 0.0717894\n",
      "\tspeed: 0.0203s/iter; left time: 384.9363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0784450 Vali Loss: 0.0928697 Test Loss: 0.0947774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0849216\n",
      "\tspeed: 0.0406s/iter; left time: 765.5098s\n",
      "\titers: 200, epoch: 16 | loss: 0.0702852\n",
      "\tspeed: 0.0201s/iter; left time: 377.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0778535 Vali Loss: 0.0908958 Test Loss: 0.0936488\n",
      "Validation loss decreased (0.091516 --> 0.090896).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0746360\n",
      "\tspeed: 0.0417s/iter; left time: 777.2252s\n",
      "\titers: 200, epoch: 17 | loss: 0.0754247\n",
      "\tspeed: 0.0201s/iter; left time: 372.6304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0778101 Vali Loss: 0.0920660 Test Loss: 0.0938107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0796930\n",
      "\tspeed: 0.0405s/iter; left time: 746.4698s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769788\n",
      "\tspeed: 0.0202s/iter; left time: 370.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0775739 Vali Loss: 0.0911418 Test Loss: 0.0939341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0831764\n",
      "\tspeed: 0.0409s/iter; left time: 743.3748s\n",
      "\titers: 200, epoch: 19 | loss: 0.0808170\n",
      "\tspeed: 0.0201s/iter; left time: 363.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0774244 Vali Loss: 0.0907504 Test Loss: 0.0931982\n",
      "Validation loss decreased (0.090896 --> 0.090750).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0716149\n",
      "\tspeed: 0.0422s/iter; left time: 757.5547s\n",
      "\titers: 200, epoch: 20 | loss: 0.0760816\n",
      "\tspeed: 0.0203s/iter; left time: 362.3681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0772027 Vali Loss: 0.0906361 Test Loss: 0.0929811\n",
      "Validation loss decreased (0.090750 --> 0.090636).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749635\n",
      "\tspeed: 0.0422s/iter; left time: 748.6606s\n",
      "\titers: 200, epoch: 21 | loss: 0.0808887\n",
      "\tspeed: 0.0201s/iter; left time: 354.2490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0770270 Vali Loss: 0.0912815 Test Loss: 0.0931846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0787776\n",
      "\tspeed: 0.0405s/iter; left time: 708.8265s\n",
      "\titers: 200, epoch: 22 | loss: 0.0730315\n",
      "\tspeed: 0.0201s/iter; left time: 349.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0768111 Vali Loss: 0.0906218 Test Loss: 0.0928346\n",
      "Validation loss decreased (0.090636 --> 0.090622).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767148\n",
      "\tspeed: 0.0413s/iter; left time: 714.0402s\n",
      "\titers: 200, epoch: 23 | loss: 0.0704466\n",
      "\tspeed: 0.0200s/iter; left time: 344.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0768343 Vali Loss: 0.0902418 Test Loss: 0.0928105\n",
      "Validation loss decreased (0.090622 --> 0.090242).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0786109\n",
      "\tspeed: 0.0407s/iter; left time: 694.0425s\n",
      "\titers: 200, epoch: 24 | loss: 0.0816796\n",
      "\tspeed: 0.0202s/iter; left time: 342.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0768173 Vali Loss: 0.0915265 Test Loss: 0.0935371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0799610\n",
      "\tspeed: 0.0404s/iter; left time: 681.1417s\n",
      "\titers: 200, epoch: 25 | loss: 0.0757982\n",
      "\tspeed: 0.0202s/iter; left time: 338.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0765245 Vali Loss: 0.0903133 Test Loss: 0.0926046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0829906\n",
      "\tspeed: 0.0421s/iter; left time: 700.0881s\n",
      "\titers: 200, epoch: 26 | loss: 0.0752078\n",
      "\tspeed: 0.0206s/iter; left time: 340.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0767063 Vali Loss: 0.0907616 Test Loss: 0.0928094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0766492\n",
      "\tspeed: 0.0408s/iter; left time: 669.2238s\n",
      "\titers: 200, epoch: 27 | loss: 0.0786701\n",
      "\tspeed: 0.0203s/iter; left time: 330.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0764181 Vali Loss: 0.0901262 Test Loss: 0.0925877\n",
      "Validation loss decreased (0.090242 --> 0.090126).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0784914\n",
      "\tspeed: 0.0428s/iter; left time: 692.6582s\n",
      "\titers: 200, epoch: 28 | loss: 0.0745633\n",
      "\tspeed: 0.0202s/iter; left time: 325.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0764216 Vali Loss: 0.0901526 Test Loss: 0.0923966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0747117\n",
      "\tspeed: 0.0419s/iter; left time: 668.8001s\n",
      "\titers: 200, epoch: 29 | loss: 0.0750493\n",
      "\tspeed: 0.0203s/iter; left time: 321.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0762765 Vali Loss: 0.0906515 Test Loss: 0.0927716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733853\n",
      "\tspeed: 0.0404s/iter; left time: 635.5100s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688315\n",
      "\tspeed: 0.0204s/iter; left time: 318.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0762149 Vali Loss: 0.0904111 Test Loss: 0.0925728\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0777000\n",
      "\tspeed: 0.0412s/iter; left time: 638.8738s\n",
      "\titers: 200, epoch: 31 | loss: 0.0803295\n",
      "\tspeed: 0.0203s/iter; left time: 312.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0762395 Vali Loss: 0.0902504 Test Loss: 0.0925031\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0813218\n",
      "\tspeed: 0.0420s/iter; left time: 642.5064s\n",
      "\titers: 200, epoch: 32 | loss: 0.0807492\n",
      "\tspeed: 0.0209s/iter; left time: 317.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0762469 Vali Loss: 0.0904030 Test Loss: 0.0924835\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0759100\n",
      "\tspeed: 0.0426s/iter; left time: 641.1219s\n",
      "\titers: 200, epoch: 33 | loss: 0.0789927\n",
      "\tspeed: 0.0203s/iter; left time: 303.1174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0760764 Vali Loss: 0.0904389 Test Loss: 0.0925347\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0766042\n",
      "\tspeed: 0.0410s/iter; left time: 608.7992s\n",
      "\titers: 200, epoch: 34 | loss: 0.0764266\n",
      "\tspeed: 0.0201s/iter; left time: 295.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0760347 Vali Loss: 0.0900640 Test Loss: 0.0923488\n",
      "Validation loss decreased (0.090126 --> 0.090064).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0786287\n",
      "\tspeed: 0.0414s/iter; left time: 604.8152s\n",
      "\titers: 200, epoch: 35 | loss: 0.0746180\n",
      "\tspeed: 0.0202s/iter; left time: 293.7808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0761513 Vali Loss: 0.0902407 Test Loss: 0.0924330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0749169\n",
      "\tspeed: 0.0406s/iter; left time: 584.7912s\n",
      "\titers: 200, epoch: 36 | loss: 0.0796616\n",
      "\tspeed: 0.0202s/iter; left time: 288.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0759159 Vali Loss: 0.0899827 Test Loss: 0.0923898\n",
      "Validation loss decreased (0.090064 --> 0.089983).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0782966\n",
      "\tspeed: 0.0452s/iter; left time: 641.2365s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751562\n",
      "\tspeed: 0.0233s/iter; left time: 327.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0760409 Vali Loss: 0.0900562 Test Loss: 0.0924457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0712603\n",
      "\tspeed: 0.0437s/iter; left time: 609.7384s\n",
      "\titers: 200, epoch: 38 | loss: 0.0760157\n",
      "\tspeed: 0.0210s/iter; left time: 290.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0759507 Vali Loss: 0.0900844 Test Loss: 0.0923730\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0731397\n",
      "\tspeed: 0.0410s/iter; left time: 562.6470s\n",
      "\titers: 200, epoch: 39 | loss: 0.0794201\n",
      "\tspeed: 0.0202s/iter; left time: 275.8190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0759710 Vali Loss: 0.0901734 Test Loss: 0.0923374\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0817736\n",
      "\tspeed: 0.0407s/iter; left time: 549.6592s\n",
      "\titers: 200, epoch: 40 | loss: 0.0793654\n",
      "\tspeed: 0.0202s/iter; left time: 271.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0758759 Vali Loss: 0.0899806 Test Loss: 0.0922941\n",
      "Validation loss decreased (0.089983 --> 0.089981).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0760485\n",
      "\tspeed: 0.0422s/iter; left time: 560.3692s\n",
      "\titers: 200, epoch: 41 | loss: 0.0804850\n",
      "\tspeed: 0.0200s/iter; left time: 264.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0759402 Vali Loss: 0.0901777 Test Loss: 0.0923692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0706304\n",
      "\tspeed: 0.0429s/iter; left time: 559.8487s\n",
      "\titers: 200, epoch: 42 | loss: 0.0729233\n",
      "\tspeed: 0.0203s/iter; left time: 262.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0759457 Vali Loss: 0.0904252 Test Loss: 0.0925111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0790886\n",
      "\tspeed: 0.0418s/iter; left time: 536.2689s\n",
      "\titers: 200, epoch: 43 | loss: 0.0814318\n",
      "\tspeed: 0.0205s/iter; left time: 261.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0759084 Vali Loss: 0.0899477 Test Loss: 0.0922394\n",
      "Validation loss decreased (0.089981 --> 0.089948).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0786488\n",
      "\tspeed: 0.0441s/iter; left time: 556.7565s\n",
      "\titers: 200, epoch: 44 | loss: 0.0755523\n",
      "\tspeed: 0.0225s/iter; left time: 281.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0757828 Vali Loss: 0.0901779 Test Loss: 0.0923653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0733363\n",
      "\tspeed: 0.0410s/iter; left time: 508.1361s\n",
      "\titers: 200, epoch: 45 | loss: 0.0768012\n",
      "\tspeed: 0.0207s/iter; left time: 254.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0758640 Vali Loss: 0.0898905 Test Loss: 0.0922444\n",
      "Validation loss decreased (0.089948 --> 0.089891).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0751334\n",
      "\tspeed: 0.0417s/iter; left time: 507.0996s\n",
      "\titers: 200, epoch: 46 | loss: 0.0761013\n",
      "\tspeed: 0.0202s/iter; left time: 243.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0758378 Vali Loss: 0.0901122 Test Loss: 0.0922677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0758792\n",
      "\tspeed: 0.0405s/iter; left time: 483.7107s\n",
      "\titers: 200, epoch: 47 | loss: 0.0769830\n",
      "\tspeed: 0.0200s/iter; left time: 237.3521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0758577 Vali Loss: 0.0898865 Test Loss: 0.0922733\n",
      "Validation loss decreased (0.089891 --> 0.089886).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0755687\n",
      "\tspeed: 0.0411s/iter; left time: 481.2738s\n",
      "\titers: 200, epoch: 48 | loss: 0.0684738\n",
      "\tspeed: 0.0203s/iter; left time: 235.6721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0758337 Vali Loss: 0.0901259 Test Loss: 0.0923032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0780505\n",
      "\tspeed: 0.0406s/iter; left time: 466.6713s\n",
      "\titers: 200, epoch: 49 | loss: 0.0805702\n",
      "\tspeed: 0.0203s/iter; left time: 230.8592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0757781 Vali Loss: 0.0902890 Test Loss: 0.0924151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0776887\n",
      "\tspeed: 0.0408s/iter; left time: 460.2357s\n",
      "\titers: 200, epoch: 50 | loss: 0.0776037\n",
      "\tspeed: 0.0203s/iter; left time: 226.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0758782 Vali Loss: 0.0899573 Test Loss: 0.0922979\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0753882\n",
      "\tspeed: 0.0425s/iter; left time: 469.8451s\n",
      "\titers: 200, epoch: 51 | loss: 0.0724134\n",
      "\tspeed: 0.0201s/iter; left time: 220.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0757393 Vali Loss: 0.0902660 Test Loss: 0.0922951\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0755895\n",
      "\tspeed: 0.0412s/iter; left time: 445.8406s\n",
      "\titers: 200, epoch: 52 | loss: 0.0731984\n",
      "\tspeed: 0.0208s/iter; left time: 223.2291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0757159 Vali Loss: 0.0901273 Test Loss: 0.0922962\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0751628\n",
      "\tspeed: 0.0423s/iter; left time: 448.7024s\n",
      "\titers: 200, epoch: 53 | loss: 0.0780671\n",
      "\tspeed: 0.0202s/iter; left time: 212.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0758241 Vali Loss: 0.0900409 Test Loss: 0.0922524\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0734993\n",
      "\tspeed: 0.0406s/iter; left time: 421.5472s\n",
      "\titers: 200, epoch: 54 | loss: 0.0789594\n",
      "\tspeed: 0.0202s/iter; left time: 207.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0758112 Vali Loss: 0.0901230 Test Loss: 0.0922837\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0770739\n",
      "\tspeed: 0.0409s/iter; left time: 415.0096s\n",
      "\titers: 200, epoch: 55 | loss: 0.0766134\n",
      "\tspeed: 0.0202s/iter; left time: 203.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0756895 Vali Loss: 0.0897605 Test Loss: 0.0921850\n",
      "Validation loss decreased (0.089886 --> 0.089760).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0714346\n",
      "\tspeed: 0.0408s/iter; left time: 405.1607s\n",
      "\titers: 200, epoch: 56 | loss: 0.0775620\n",
      "\tspeed: 0.0200s/iter; left time: 197.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0757827 Vali Loss: 0.0898352 Test Loss: 0.0922000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0780214\n",
      "\tspeed: 0.0427s/iter; left time: 414.4624s\n",
      "\titers: 200, epoch: 57 | loss: 0.0744787\n",
      "\tspeed: 0.0221s/iter; left time: 212.5403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0758389 Vali Loss: 0.0899776 Test Loss: 0.0922067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0730577\n",
      "\tspeed: 0.0414s/iter; left time: 392.9608s\n",
      "\titers: 200, epoch: 58 | loss: 0.0724419\n",
      "\tspeed: 0.0202s/iter; left time: 190.1005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0758324 Vali Loss: 0.0902179 Test Loss: 0.0923441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0772266\n",
      "\tspeed: 0.0406s/iter; left time: 376.5729s\n",
      "\titers: 200, epoch: 59 | loss: 0.0724157\n",
      "\tspeed: 0.0200s/iter; left time: 183.4466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0758184 Vali Loss: 0.0899658 Test Loss: 0.0922477\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0779026\n",
      "\tspeed: 0.0408s/iter; left time: 369.3891s\n",
      "\titers: 200, epoch: 60 | loss: 0.0778434\n",
      "\tspeed: 0.0203s/iter; left time: 181.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0757282 Vali Loss: 0.0900866 Test Loss: 0.0923297\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0761693\n",
      "\tspeed: 0.0412s/iter; left time: 363.3962s\n",
      "\titers: 200, epoch: 61 | loss: 0.0769647\n",
      "\tspeed: 0.0203s/iter; left time: 176.6532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0757709 Vali Loss: 0.0900442 Test Loss: 0.0923081\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0724088\n",
      "\tspeed: 0.0408s/iter; left time: 350.6407s\n",
      "\titers: 200, epoch: 62 | loss: 0.0770181\n",
      "\tspeed: 0.0205s/iter; left time: 173.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0757130 Vali Loss: 0.0899358 Test Loss: 0.0922996\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0824577\n",
      "\tspeed: 0.0406s/iter; left time: 339.9735s\n",
      "\titers: 200, epoch: 63 | loss: 0.0750519\n",
      "\tspeed: 0.0201s/iter; left time: 166.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0757345 Vali Loss: 0.0898351 Test Loss: 0.0921792\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0733577\n",
      "\tspeed: 0.0418s/iter; left time: 340.4529s\n",
      "\titers: 200, epoch: 64 | loss: 0.0708779\n",
      "\tspeed: 0.0202s/iter; left time: 162.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0757627 Vali Loss: 0.0899927 Test Loss: 0.0922466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0763176\n",
      "\tspeed: 0.0416s/iter; left time: 329.6832s\n",
      "\titers: 200, epoch: 65 | loss: 0.0740640\n",
      "\tspeed: 0.0201s/iter; left time: 157.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0756659 Vali Loss: 0.0900139 Test Loss: 0.0922281\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021770920604467392, rmse:0.14754971861839294, mae:0.09218499064445496, rse:0.5207234025001526\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2690482\n",
      "\tspeed: 0.0235s/iter; left time: 522.8060s\n",
      "\titers: 200, epoch: 1 | loss: 0.2657327\n",
      "\tspeed: 0.0226s/iter; left time: 498.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.2704633 Vali Loss: 0.2223115 Test Loss: 0.2248250\n",
      "Validation loss decreased (inf --> 0.222311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482837\n",
      "\tspeed: 0.0435s/iter; left time: 956.1774s\n",
      "\titers: 200, epoch: 2 | loss: 0.1158016\n",
      "\tspeed: 0.0213s/iter; left time: 466.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.1525808 Vali Loss: 0.1137699 Test Loss: 0.1151182\n",
      "Validation loss decreased (0.222311 --> 0.113770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056265\n",
      "\tspeed: 0.0428s/iter; left time: 930.9929s\n",
      "\titers: 200, epoch: 3 | loss: 0.1027019\n",
      "\tspeed: 0.0202s/iter; left time: 438.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.1028301 Vali Loss: 0.1022478 Test Loss: 0.1034218\n",
      "Validation loss decreased (0.113770 --> 0.102248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0959680\n",
      "\tspeed: 0.0416s/iter; left time: 895.6674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0917668\n",
      "\tspeed: 0.0207s/iter; left time: 442.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0926323 Vali Loss: 0.1012006 Test Loss: 0.1035642\n",
      "Validation loss decreased (0.102248 --> 0.101201).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895127\n",
      "\tspeed: 0.0416s/iter; left time: 886.8723s\n",
      "\titers: 200, epoch: 5 | loss: 0.0910337\n",
      "\tspeed: 0.0200s/iter; left time: 424.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0879356 Vali Loss: 0.1026857 Test Loss: 0.1047157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0865112\n",
      "\tspeed: 0.0412s/iter; left time: 869.4109s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826559\n",
      "\tspeed: 0.0202s/iter; left time: 424.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0855119 Vali Loss: 0.0961093 Test Loss: 0.0984576\n",
      "Validation loss decreased (0.101201 --> 0.096109).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855684\n",
      "\tspeed: 0.0422s/iter; left time: 881.2471s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826875\n",
      "\tspeed: 0.0200s/iter; left time: 415.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0836208 Vali Loss: 0.0949075 Test Loss: 0.0979425\n",
      "Validation loss decreased (0.096109 --> 0.094907).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0855871\n",
      "\tspeed: 0.0437s/iter; left time: 901.0950s\n",
      "\titers: 200, epoch: 8 | loss: 0.0835874\n",
      "\tspeed: 0.0201s/iter; left time: 412.1041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0826147 Vali Loss: 0.0944877 Test Loss: 0.0977451\n",
      "Validation loss decreased (0.094907 --> 0.094488).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804175\n",
      "\tspeed: 0.0418s/iter; left time: 853.9394s\n",
      "\titers: 200, epoch: 9 | loss: 0.0806948\n",
      "\tspeed: 0.0200s/iter; left time: 407.3030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0813928 Vali Loss: 0.0938870 Test Loss: 0.0963996\n",
      "Validation loss decreased (0.094488 --> 0.093887).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0782151\n",
      "\tspeed: 0.0421s/iter; left time: 851.1456s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771089\n",
      "\tspeed: 0.0201s/iter; left time: 402.8916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0809815 Vali Loss: 0.0933232 Test Loss: 0.0965916\n",
      "Validation loss decreased (0.093887 --> 0.093323).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0837242\n",
      "\tspeed: 0.0426s/iter; left time: 851.0427s\n",
      "\titers: 200, epoch: 11 | loss: 0.0726382\n",
      "\tspeed: 0.0203s/iter; left time: 402.5506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0801455 Vali Loss: 0.0934604 Test Loss: 0.0958622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754714\n",
      "\tspeed: 0.0414s/iter; left time: 818.3948s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837562\n",
      "\tspeed: 0.0201s/iter; left time: 394.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0796965 Vali Loss: 0.0922704 Test Loss: 0.0946606\n",
      "Validation loss decreased (0.093323 --> 0.092270).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872200\n",
      "\tspeed: 0.0467s/iter; left time: 911.3299s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782231\n",
      "\tspeed: 0.0227s/iter; left time: 441.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0793188 Vali Loss: 0.0918262 Test Loss: 0.0947884\n",
      "Validation loss decreased (0.092270 --> 0.091826).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766850\n",
      "\tspeed: 0.0432s/iter; left time: 834.7820s\n",
      "\titers: 200, epoch: 14 | loss: 0.0802228\n",
      "\tspeed: 0.0202s/iter; left time: 388.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0787686 Vali Loss: 0.0916737 Test Loss: 0.0941335\n",
      "Validation loss decreased (0.091826 --> 0.091674).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0821675\n",
      "\tspeed: 0.0431s/iter; left time: 822.5197s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822299\n",
      "\tspeed: 0.0201s/iter; left time: 382.3223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0783110 Vali Loss: 0.0927818 Test Loss: 0.0945928\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0768079\n",
      "\tspeed: 0.0423s/iter; left time: 798.4825s\n",
      "\titers: 200, epoch: 16 | loss: 0.0720540\n",
      "\tspeed: 0.0204s/iter; left time: 382.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0780134 Vali Loss: 0.0911310 Test Loss: 0.0939451\n",
      "Validation loss decreased (0.091674 --> 0.091131).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0797201\n",
      "\tspeed: 0.0419s/iter; left time: 781.2086s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744011\n",
      "\tspeed: 0.0202s/iter; left time: 374.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0779091 Vali Loss: 0.0909791 Test Loss: 0.0935009\n",
      "Validation loss decreased (0.091131 --> 0.090979).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765691\n",
      "\tspeed: 0.0423s/iter; left time: 778.0983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0816458\n",
      "\tspeed: 0.0200s/iter; left time: 366.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0776151 Vali Loss: 0.0909137 Test Loss: 0.0934092\n",
      "Validation loss decreased (0.090979 --> 0.090914).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730380\n",
      "\tspeed: 0.0429s/iter; left time: 779.4260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760622\n",
      "\tspeed: 0.0203s/iter; left time: 366.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0774823 Vali Loss: 0.0913616 Test Loss: 0.0933854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717250\n",
      "\tspeed: 0.0418s/iter; left time: 751.0693s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820573\n",
      "\tspeed: 0.0225s/iter; left time: 401.5140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0773356 Vali Loss: 0.0905771 Test Loss: 0.0930068\n",
      "Validation loss decreased (0.090914 --> 0.090577).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0793903\n",
      "\tspeed: 0.0472s/iter; left time: 837.9029s\n",
      "\titers: 200, epoch: 21 | loss: 0.0780636\n",
      "\tspeed: 0.0203s/iter; left time: 357.4075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0771456 Vali Loss: 0.0904109 Test Loss: 0.0928583\n",
      "Validation loss decreased (0.090577 --> 0.090411).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0777267\n",
      "\tspeed: 0.0422s/iter; left time: 739.6105s\n",
      "\titers: 200, epoch: 22 | loss: 0.0722126\n",
      "\tspeed: 0.0203s/iter; left time: 352.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0770543 Vali Loss: 0.0915218 Test Loss: 0.0934001\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0766328\n",
      "\tspeed: 0.0423s/iter; left time: 731.7848s\n",
      "\titers: 200, epoch: 23 | loss: 0.0684822\n",
      "\tspeed: 0.0204s/iter; left time: 350.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0768432 Vali Loss: 0.0903650 Test Loss: 0.0926346\n",
      "Validation loss decreased (0.090411 --> 0.090365).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0784689\n",
      "\tspeed: 0.0420s/iter; left time: 717.5366s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759460\n",
      "\tspeed: 0.0202s/iter; left time: 343.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0766120 Vali Loss: 0.0904842 Test Loss: 0.0925846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0746728\n",
      "\tspeed: 0.0422s/iter; left time: 711.3838s\n",
      "\titers: 200, epoch: 25 | loss: 0.0797455\n",
      "\tspeed: 0.0203s/iter; left time: 339.7796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0766469 Vali Loss: 0.0902146 Test Loss: 0.0926205\n",
      "Validation loss decreased (0.090365 --> 0.090215).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0747347\n",
      "\tspeed: 0.0448s/iter; left time: 744.7433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0790192\n",
      "\tspeed: 0.0200s/iter; left time: 330.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0765807 Vali Loss: 0.0901931 Test Loss: 0.0924875\n",
      "Validation loss decreased (0.090215 --> 0.090193).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789229\n",
      "\tspeed: 0.0428s/iter; left time: 702.3090s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742214\n",
      "\tspeed: 0.0200s/iter; left time: 326.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0765636 Vali Loss: 0.0903746 Test Loss: 0.0923825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0839163\n",
      "\tspeed: 0.0449s/iter; left time: 727.0543s\n",
      "\titers: 200, epoch: 28 | loss: 0.0786108\n",
      "\tspeed: 0.0219s/iter; left time: 351.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0764924 Vali Loss: 0.0900318 Test Loss: 0.0922259\n",
      "Validation loss decreased (0.090193 --> 0.090032).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0794161\n",
      "\tspeed: 0.0424s/iter; left time: 676.6532s\n",
      "\titers: 200, epoch: 29 | loss: 0.0799167\n",
      "\tspeed: 0.0207s/iter; left time: 328.8010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0764207 Vali Loss: 0.0903167 Test Loss: 0.0924859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792144\n",
      "\tspeed: 0.0424s/iter; left time: 666.4452s\n",
      "\titers: 200, epoch: 30 | loss: 0.0792654\n",
      "\tspeed: 0.0201s/iter; left time: 314.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0763410 Vali Loss: 0.0900657 Test Loss: 0.0922183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0734143\n",
      "\tspeed: 0.0416s/iter; left time: 645.3637s\n",
      "\titers: 200, epoch: 31 | loss: 0.0754072\n",
      "\tspeed: 0.0200s/iter; left time: 307.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0761650 Vali Loss: 0.0901884 Test Loss: 0.0921875\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0739676\n",
      "\tspeed: 0.0434s/iter; left time: 663.9147s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764657\n",
      "\tspeed: 0.0212s/iter; left time: 322.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0762222 Vali Loss: 0.0902136 Test Loss: 0.0922444\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0711847\n",
      "\tspeed: 0.0423s/iter; left time: 637.6489s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719252\n",
      "\tspeed: 0.0200s/iter; left time: 299.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0761187 Vali Loss: 0.0902977 Test Loss: 0.0922513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0733805\n",
      "\tspeed: 0.0420s/iter; left time: 622.6329s\n",
      "\titers: 200, epoch: 34 | loss: 0.0727109\n",
      "\tspeed: 0.0206s/iter; left time: 304.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0761814 Vali Loss: 0.0900516 Test Loss: 0.0922492\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732718\n",
      "\tspeed: 0.0434s/iter; left time: 634.2841s\n",
      "\titers: 200, epoch: 35 | loss: 0.0749703\n",
      "\tspeed: 0.0203s/iter; left time: 294.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0761930 Vali Loss: 0.0900128 Test Loss: 0.0921448\n",
      "Validation loss decreased (0.090032 --> 0.090013).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0766798\n",
      "\tspeed: 0.0419s/iter; left time: 603.3767s\n",
      "\titers: 200, epoch: 36 | loss: 0.0750102\n",
      "\tspeed: 0.0200s/iter; left time: 286.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0760836 Vali Loss: 0.0898830 Test Loss: 0.0920632\n",
      "Validation loss decreased (0.090013 --> 0.089883).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0715126\n",
      "\tspeed: 0.0418s/iter; left time: 592.9737s\n",
      "\titers: 200, epoch: 37 | loss: 0.0778742\n",
      "\tspeed: 0.0202s/iter; left time: 283.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0760820 Vali Loss: 0.0897833 Test Loss: 0.0920799\n",
      "Validation loss decreased (0.089883 --> 0.089783).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829859\n",
      "\tspeed: 0.0423s/iter; left time: 590.6046s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762555\n",
      "\tspeed: 0.0203s/iter; left time: 281.6048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0760130 Vali Loss: 0.0897898 Test Loss: 0.0920178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0805645\n",
      "\tspeed: 0.0444s/iter; left time: 608.9222s\n",
      "\titers: 200, epoch: 39 | loss: 0.0714110\n",
      "\tspeed: 0.0209s/iter; left time: 284.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0760181 Vali Loss: 0.0902636 Test Loss: 0.0921534\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0692887\n",
      "\tspeed: 0.0418s/iter; left time: 563.9564s\n",
      "\titers: 200, epoch: 40 | loss: 0.0778426\n",
      "\tspeed: 0.0201s/iter; left time: 269.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0759935 Vali Loss: 0.0900973 Test Loss: 0.0920592\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0776406\n",
      "\tspeed: 0.0444s/iter; left time: 589.6531s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807740\n",
      "\tspeed: 0.0232s/iter; left time: 306.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0759819 Vali Loss: 0.0901239 Test Loss: 0.0921484\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0771315\n",
      "\tspeed: 0.0429s/iter; left time: 560.3947s\n",
      "\titers: 200, epoch: 42 | loss: 0.0792104\n",
      "\tspeed: 0.0203s/iter; left time: 262.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0759037 Vali Loss: 0.0902524 Test Loss: 0.0922276\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0745168\n",
      "\tspeed: 0.0418s/iter; left time: 536.6257s\n",
      "\titers: 200, epoch: 43 | loss: 0.0744583\n",
      "\tspeed: 0.0201s/iter; left time: 255.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0759841 Vali Loss: 0.0900033 Test Loss: 0.0919992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0741830\n",
      "\tspeed: 0.0415s/iter; left time: 523.2505s\n",
      "\titers: 200, epoch: 44 | loss: 0.0781158\n",
      "\tspeed: 0.0202s/iter; left time: 253.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0760082 Vali Loss: 0.0902275 Test Loss: 0.0920613\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0744472\n",
      "\tspeed: 0.0415s/iter; left time: 513.8190s\n",
      "\titers: 200, epoch: 45 | loss: 0.0767980\n",
      "\tspeed: 0.0200s/iter; left time: 245.8168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0758981 Vali Loss: 0.0899390 Test Loss: 0.0919780\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0772938\n",
      "\tspeed: 0.0415s/iter; left time: 504.9122s\n",
      "\titers: 200, epoch: 46 | loss: 0.0725428\n",
      "\tspeed: 0.0203s/iter; left time: 244.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0759235 Vali Loss: 0.0900554 Test Loss: 0.0920169\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0756535\n",
      "\tspeed: 0.0423s/iter; left time: 504.9368s\n",
      "\titers: 200, epoch: 47 | loss: 0.0725707\n",
      "\tspeed: 0.0202s/iter; left time: 239.3397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0758647 Vali Loss: 0.0901466 Test Loss: 0.0921033\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02188282459974289, rmse:0.14792844653129578, mae:0.09207988530397415, rse:0.522059977054596\n",
      "Intermediate time for DE and pred_len 24: 00h:12m:46.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2746008\n",
      "\tspeed: 0.0468s/iter; left time: 1033.6303s\n",
      "\titers: 200, epoch: 1 | loss: 0.2514527\n",
      "\tspeed: 0.0203s/iter; left time: 446.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.2698757 Vali Loss: 0.2293017 Test Loss: 0.2318186\n",
      "Validation loss decreased (inf --> 0.229302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492694\n",
      "\tspeed: 0.0431s/iter; left time: 942.2505s\n",
      "\titers: 200, epoch: 2 | loss: 0.1347827\n",
      "\tspeed: 0.0203s/iter; left time: 441.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1624832 Vali Loss: 0.1391781 Test Loss: 0.1439656\n",
      "Validation loss decreased (0.229302 --> 0.139178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1229763\n",
      "\tspeed: 0.0439s/iter; left time: 950.8258s\n",
      "\titers: 200, epoch: 3 | loss: 0.1150210\n",
      "\tspeed: 0.0203s/iter; left time: 438.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1233960 Vali Loss: 0.1294220 Test Loss: 0.1383118\n",
      "Validation loss decreased (0.139178 --> 0.129422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1141142\n",
      "\tspeed: 0.0470s/iter; left time: 1008.5028s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133401\n",
      "\tspeed: 0.0203s/iter; left time: 432.7118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1151363 Vali Loss: 0.1264710 Test Loss: 0.1364030\n",
      "Validation loss decreased (0.129422 --> 0.126471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1109501\n",
      "\tspeed: 0.0447s/iter; left time: 948.3396s\n",
      "\titers: 200, epoch: 5 | loss: 0.1127798\n",
      "\tspeed: 0.0205s/iter; left time: 433.8193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1110755 Vali Loss: 0.1256932 Test Loss: 0.1349780\n",
      "Validation loss decreased (0.126471 --> 0.125693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1092230\n",
      "\tspeed: 0.0450s/iter; left time: 944.1938s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076659\n",
      "\tspeed: 0.0211s/iter; left time: 440.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.1088447 Vali Loss: 0.1248127 Test Loss: 0.1327785\n",
      "Validation loss decreased (0.125693 --> 0.124813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1058396\n",
      "\tspeed: 0.0440s/iter; left time: 914.3585s\n",
      "\titers: 200, epoch: 7 | loss: 0.1048053\n",
      "\tspeed: 0.0207s/iter; left time: 427.1157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1074621 Vali Loss: 0.1242875 Test Loss: 0.1321853\n",
      "Validation loss decreased (0.124813 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1044636\n",
      "\tspeed: 0.0438s/iter; left time: 899.3121s\n",
      "\titers: 200, epoch: 8 | loss: 0.1106110\n",
      "\tspeed: 0.0206s/iter; left time: 421.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1064293 Vali Loss: 0.1245186 Test Loss: 0.1325380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1028444\n",
      "\tspeed: 0.0437s/iter; left time: 888.6251s\n",
      "\titers: 200, epoch: 9 | loss: 0.1033391\n",
      "\tspeed: 0.0203s/iter; left time: 409.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1060250 Vali Loss: 0.1257819 Test Loss: 0.1342924\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1019384\n",
      "\tspeed: 0.0436s/iter; left time: 875.5088s\n",
      "\titers: 200, epoch: 10 | loss: 0.1127677\n",
      "\tspeed: 0.0206s/iter; left time: 412.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1051250 Vali Loss: 0.1261847 Test Loss: 0.1348590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1105345\n",
      "\tspeed: 0.0454s/iter; left time: 902.3258s\n",
      "\titers: 200, epoch: 11 | loss: 0.0960624\n",
      "\tspeed: 0.0206s/iter; left time: 406.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1045347 Vali Loss: 0.1262054 Test Loss: 0.1351160\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1078019\n",
      "\tspeed: 0.0439s/iter; left time: 863.7430s\n",
      "\titers: 200, epoch: 12 | loss: 0.1036723\n",
      "\tspeed: 0.0205s/iter; left time: 401.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1040074 Vali Loss: 0.1268728 Test Loss: 0.1366953\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0956001\n",
      "\tspeed: 0.0471s/iter; left time: 915.5366s\n",
      "\titers: 200, epoch: 13 | loss: 0.1090278\n",
      "\tspeed: 0.0240s/iter; left time: 464.7826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 222 | Train Loss: 0.1036443 Vali Loss: 0.1239581 Test Loss: 0.1338916\n",
      "Validation loss decreased (0.124288 --> 0.123958).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1035504\n",
      "\tspeed: 0.0465s/iter; left time: 892.6390s\n",
      "\titers: 200, epoch: 14 | loss: 0.1060487\n",
      "\tspeed: 0.0201s/iter; left time: 385.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1032384 Vali Loss: 0.1256748 Test Loss: 0.1361385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1129628\n",
      "\tspeed: 0.0449s/iter; left time: 853.4368s\n",
      "\titers: 200, epoch: 15 | loss: 0.1020180\n",
      "\tspeed: 0.0205s/iter; left time: 386.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.1028863 Vali Loss: 0.1249194 Test Loss: 0.1358103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1013643\n",
      "\tspeed: 0.0451s/iter; left time: 845.7937s\n",
      "\titers: 200, epoch: 16 | loss: 0.1023591\n",
      "\tspeed: 0.0204s/iter; left time: 380.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1027078 Vali Loss: 0.1254926 Test Loss: 0.1374308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1028595\n",
      "\tspeed: 0.0437s/iter; left time: 810.3983s\n",
      "\titers: 200, epoch: 17 | loss: 0.1062037\n",
      "\tspeed: 0.0214s/iter; left time: 394.1270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1023961 Vali Loss: 0.1247974 Test Loss: 0.1360857\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051540\n",
      "\tspeed: 0.0441s/iter; left time: 807.8478s\n",
      "\titers: 200, epoch: 18 | loss: 0.1016844\n",
      "\tspeed: 0.0205s/iter; left time: 372.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1021692 Vali Loss: 0.1236309 Test Loss: 0.1358653\n",
      "Validation loss decreased (0.123958 --> 0.123631).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0980886\n",
      "\tspeed: 0.0452s/iter; left time: 818.7251s\n",
      "\titers: 200, epoch: 19 | loss: 0.0989304\n",
      "\tspeed: 0.0215s/iter; left time: 386.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.1020997 Vali Loss: 0.1242423 Test Loss: 0.1365159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0994082\n",
      "\tspeed: 0.0460s/iter; left time: 823.1998s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025019\n",
      "\tspeed: 0.0202s/iter; left time: 359.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1017810 Vali Loss: 0.1236135 Test Loss: 0.1353629\n",
      "Validation loss decreased (0.123631 --> 0.123613).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1010832\n",
      "\tspeed: 0.0445s/iter; left time: 786.0739s\n",
      "\titers: 200, epoch: 21 | loss: 0.1020031\n",
      "\tspeed: 0.0201s/iter; left time: 352.7888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1016102 Vali Loss: 0.1237748 Test Loss: 0.1351325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1072670\n",
      "\tspeed: 0.0433s/iter; left time: 755.5870s\n",
      "\titers: 200, epoch: 22 | loss: 0.0955645\n",
      "\tspeed: 0.0203s/iter; left time: 352.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1015021 Vali Loss: 0.1242287 Test Loss: 0.1366241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1039758\n",
      "\tspeed: 0.0442s/iter; left time: 760.6483s\n",
      "\titers: 200, epoch: 23 | loss: 0.1001585\n",
      "\tspeed: 0.0202s/iter; left time: 346.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1012979 Vali Loss: 0.1236947 Test Loss: 0.1362057\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1015419\n",
      "\tspeed: 0.0457s/iter; left time: 776.6440s\n",
      "\titers: 200, epoch: 24 | loss: 0.1029821\n",
      "\tspeed: 0.0208s/iter; left time: 351.9294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1012101 Vali Loss: 0.1228898 Test Loss: 0.1353223\n",
      "Validation loss decreased (0.123613 --> 0.122890).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1006997\n",
      "\tspeed: 0.0459s/iter; left time: 769.7573s\n",
      "\titers: 200, epoch: 25 | loss: 0.1036851\n",
      "\tspeed: 0.0202s/iter; left time: 337.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1011557 Vali Loss: 0.1235861 Test Loss: 0.1363387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1022189\n",
      "\tspeed: 0.0430s/iter; left time: 712.4349s\n",
      "\titers: 200, epoch: 26 | loss: 0.1006631\n",
      "\tspeed: 0.0202s/iter; left time: 333.1137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1010096 Vali Loss: 0.1235806 Test Loss: 0.1365928\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0983847\n",
      "\tspeed: 0.0433s/iter; left time: 707.7387s\n",
      "\titers: 200, epoch: 27 | loss: 0.1016240\n",
      "\tspeed: 0.0202s/iter; left time: 328.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1009450 Vali Loss: 0.1230507 Test Loss: 0.1359318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1026335\n",
      "\tspeed: 0.0429s/iter; left time: 691.7887s\n",
      "\titers: 200, epoch: 28 | loss: 0.1020207\n",
      "\tspeed: 0.0201s/iter; left time: 321.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.1007601 Vali Loss: 0.1238459 Test Loss: 0.1372463\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1021552\n",
      "\tspeed: 0.0444s/iter; left time: 704.7739s\n",
      "\titers: 200, epoch: 29 | loss: 0.1018350\n",
      "\tspeed: 0.0201s/iter; left time: 317.7285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1007110 Vali Loss: 0.1231984 Test Loss: 0.1362782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1000956\n",
      "\tspeed: 0.0441s/iter; left time: 690.1297s\n",
      "\titers: 200, epoch: 30 | loss: 0.0969561\n",
      "\tspeed: 0.0217s/iter; left time: 337.0369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.1007576 Vali Loss: 0.1226942 Test Loss: 0.1350585\n",
      "Validation loss decreased (0.122890 --> 0.122694).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1027024\n",
      "\tspeed: 0.0471s/iter; left time: 727.5944s\n",
      "\titers: 200, epoch: 31 | loss: 0.1042811\n",
      "\tspeed: 0.0206s/iter; left time: 315.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.1006005 Vali Loss: 0.1229716 Test Loss: 0.1359890\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0981697\n",
      "\tspeed: 0.0433s/iter; left time: 659.0667s\n",
      "\titers: 200, epoch: 32 | loss: 0.0995496\n",
      "\tspeed: 0.0203s/iter; left time: 307.3423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1005524 Vali Loss: 0.1228913 Test Loss: 0.1353133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1058541\n",
      "\tspeed: 0.0443s/iter; left time: 663.7183s\n",
      "\titers: 200, epoch: 33 | loss: 0.0986717\n",
      "\tspeed: 0.0202s/iter; left time: 301.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1005826 Vali Loss: 0.1226582 Test Loss: 0.1358778\n",
      "Validation loss decreased (0.122694 --> 0.122658).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1002448\n",
      "\tspeed: 0.0442s/iter; left time: 652.3602s\n",
      "\titers: 200, epoch: 34 | loss: 0.1039753\n",
      "\tspeed: 0.0201s/iter; left time: 294.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1004527 Vali Loss: 0.1232586 Test Loss: 0.1365952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0940850\n",
      "\tspeed: 0.0428s/iter; left time: 622.4574s\n",
      "\titers: 200, epoch: 35 | loss: 0.1029950\n",
      "\tspeed: 0.0202s/iter; left time: 292.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1004678 Vali Loss: 0.1227602 Test Loss: 0.1357923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1029373\n",
      "\tspeed: 0.0442s/iter; left time: 633.6179s\n",
      "\titers: 200, epoch: 36 | loss: 0.1054347\n",
      "\tspeed: 0.0219s/iter; left time: 311.0179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1004078 Vali Loss: 0.1227727 Test Loss: 0.1358065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1081109\n",
      "\tspeed: 0.0438s/iter; left time: 617.3410s\n",
      "\titers: 200, epoch: 37 | loss: 0.0991923\n",
      "\tspeed: 0.0202s/iter; left time: 282.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1003935 Vali Loss: 0.1230432 Test Loss: 0.1360274\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1074517\n",
      "\tspeed: 0.0434s/iter; left time: 603.1094s\n",
      "\titers: 200, epoch: 38 | loss: 0.1009870\n",
      "\tspeed: 0.0202s/iter; left time: 278.0370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.1003523 Vali Loss: 0.1227690 Test Loss: 0.1360568\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0948013\n",
      "\tspeed: 0.0439s/iter; left time: 599.7974s\n",
      "\titers: 200, epoch: 39 | loss: 0.0981326\n",
      "\tspeed: 0.0202s/iter; left time: 274.0078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1004339 Vali Loss: 0.1229201 Test Loss: 0.1361592\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0993517\n",
      "\tspeed: 0.0451s/iter; left time: 606.8329s\n",
      "\titers: 200, epoch: 40 | loss: 0.1014140\n",
      "\tspeed: 0.0204s/iter; left time: 271.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1002876 Vali Loss: 0.1227761 Test Loss: 0.1359072\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0989447\n",
      "\tspeed: 0.0461s/iter; left time: 608.9805s\n",
      "\titers: 200, epoch: 41 | loss: 0.1099960\n",
      "\tspeed: 0.0218s/iter; left time: 286.1910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.1002325 Vali Loss: 0.1226757 Test Loss: 0.1358664\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1030385\n",
      "\tspeed: 0.0464s/iter; left time: 602.8755s\n",
      "\titers: 200, epoch: 42 | loss: 0.0987012\n",
      "\tspeed: 0.0207s/iter; left time: 267.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.1002886 Vali Loss: 0.1227850 Test Loss: 0.1359752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0982130\n",
      "\tspeed: 0.0432s/iter; left time: 552.1654s\n",
      "\titers: 200, epoch: 43 | loss: 0.0974052\n",
      "\tspeed: 0.0203s/iter; left time: 257.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1003444 Vali Loss: 0.1222139 Test Loss: 0.1353274\n",
      "Validation loss decreased (0.122658 --> 0.122214).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0966651\n",
      "\tspeed: 0.0443s/iter; left time: 556.3549s\n",
      "\titers: 200, epoch: 44 | loss: 0.1020363\n",
      "\tspeed: 0.0202s/iter; left time: 251.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1002789 Vali Loss: 0.1226460 Test Loss: 0.1358935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0998923\n",
      "\tspeed: 0.0432s/iter; left time: 532.7968s\n",
      "\titers: 200, epoch: 45 | loss: 0.1030129\n",
      "\tspeed: 0.0203s/iter; left time: 248.4085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1002502 Vali Loss: 0.1225560 Test Loss: 0.1356725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1024632\n",
      "\tspeed: 0.0436s/iter; left time: 527.9337s\n",
      "\titers: 200, epoch: 46 | loss: 0.0993016\n",
      "\tspeed: 0.0201s/iter; left time: 241.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1002555 Vali Loss: 0.1223647 Test Loss: 0.1355448\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1035789\n",
      "\tspeed: 0.0461s/iter; left time: 548.2739s\n",
      "\titers: 200, epoch: 47 | loss: 0.0957147\n",
      "\tspeed: 0.0203s/iter; left time: 238.8915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1001944 Vali Loss: 0.1229249 Test Loss: 0.1360979\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0991891\n",
      "\tspeed: 0.0445s/iter; left time: 518.9435s\n",
      "\titers: 200, epoch: 48 | loss: 0.0935006\n",
      "\tspeed: 0.0206s/iter; left time: 237.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1002300 Vali Loss: 0.1223428 Test Loss: 0.1355022\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0980361\n",
      "\tspeed: 0.0466s/iter; left time: 533.5844s\n",
      "\titers: 200, epoch: 49 | loss: 0.0991728\n",
      "\tspeed: 0.0204s/iter; left time: 231.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.1001759 Vali Loss: 0.1224179 Test Loss: 0.1355893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0994642\n",
      "\tspeed: 0.0437s/iter; left time: 490.9086s\n",
      "\titers: 200, epoch: 50 | loss: 0.1009895\n",
      "\tspeed: 0.0201s/iter; left time: 223.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1001639 Vali Loss: 0.1221785 Test Loss: 0.1352349\n",
      "Validation loss decreased (0.122214 --> 0.122179).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0987073\n",
      "\tspeed: 0.0441s/iter; left time: 485.0629s\n",
      "\titers: 200, epoch: 51 | loss: 0.0991311\n",
      "\tspeed: 0.0203s/iter; left time: 221.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1002218 Vali Loss: 0.1223758 Test Loss: 0.1355910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1037601\n",
      "\tspeed: 0.0443s/iter; left time: 477.3635s\n",
      "\titers: 200, epoch: 52 | loss: 0.0984696\n",
      "\tspeed: 0.0206s/iter; left time: 220.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1001934 Vali Loss: 0.1226441 Test Loss: 0.1358739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1021746\n",
      "\tspeed: 0.0438s/iter; left time: 462.8144s\n",
      "\titers: 200, epoch: 53 | loss: 0.1018147\n",
      "\tspeed: 0.0201s/iter; left time: 210.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1001650 Vali Loss: 0.1227890 Test Loss: 0.1359922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1007738\n",
      "\tspeed: 0.0440s/iter; left time: 454.5417s\n",
      "\titers: 200, epoch: 54 | loss: 0.1033273\n",
      "\tspeed: 0.0205s/iter; left time: 210.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1001679 Vali Loss: 0.1231412 Test Loss: 0.1365046\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1000785\n",
      "\tspeed: 0.0449s/iter; left time: 453.6208s\n",
      "\titers: 200, epoch: 55 | loss: 0.1052800\n",
      "\tspeed: 0.0219s/iter; left time: 219.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 222 | Train Loss: 0.1001285 Vali Loss: 0.1222991 Test Loss: 0.1355074\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1022447\n",
      "\tspeed: 0.0477s/iter; left time: 471.3087s\n",
      "\titers: 200, epoch: 56 | loss: 0.1039488\n",
      "\tspeed: 0.0203s/iter; left time: 199.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.1000040 Vali Loss: 0.1224804 Test Loss: 0.1359329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1056654\n",
      "\tspeed: 0.0442s/iter; left time: 427.3898s\n",
      "\titers: 200, epoch: 57 | loss: 0.1034027\n",
      "\tspeed: 0.0201s/iter; left time: 192.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1001704 Vali Loss: 0.1227876 Test Loss: 0.1363264\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1005686\n",
      "\tspeed: 0.0434s/iter; left time: 409.7021s\n",
      "\titers: 200, epoch: 58 | loss: 0.0983072\n",
      "\tspeed: 0.0204s/iter; left time: 190.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1001412 Vali Loss: 0.1227559 Test Loss: 0.1361562\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1005821\n",
      "\tspeed: 0.0429s/iter; left time: 396.1528s\n",
      "\titers: 200, epoch: 59 | loss: 0.0988197\n",
      "\tspeed: 0.0201s/iter; left time: 183.6366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1001613 Vali Loss: 0.1223188 Test Loss: 0.1354785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.1040010\n",
      "\tspeed: 0.0439s/iter; left time: 395.2345s\n",
      "\titers: 200, epoch: 60 | loss: 0.0978208\n",
      "\tspeed: 0.0203s/iter; left time: 180.3882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1001361 Vali Loss: 0.1230012 Test Loss: 0.1364686\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04340914264321327, rmse:0.2083486020565033, mae:0.13523496687412262, rse:0.7378045320510864\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2644310\n",
      "\tspeed: 0.0230s/iter; left time: 507.2347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2517203\n",
      "\tspeed: 0.0218s/iter; left time: 480.0413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.2714728 Vali Loss: 0.2290613 Test Loss: 0.2317390\n",
      "Validation loss decreased (inf --> 0.229061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1558459\n",
      "\tspeed: 0.0439s/iter; left time: 961.5692s\n",
      "\titers: 200, epoch: 2 | loss: 0.1308161\n",
      "\tspeed: 0.0203s/iter; left time: 441.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1623632 Vali Loss: 0.1391634 Test Loss: 0.1442310\n",
      "Validation loss decreased (0.229061 --> 0.139163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1262097\n",
      "\tspeed: 0.0470s/iter; left time: 1017.6321s\n",
      "\titers: 200, epoch: 3 | loss: 0.1221988\n",
      "\tspeed: 0.0212s/iter; left time: 456.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 222 | Train Loss: 0.1247924 Vali Loss: 0.1285259 Test Loss: 0.1363316\n",
      "Validation loss decreased (0.139163 --> 0.128526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1116177\n",
      "\tspeed: 0.0473s/iter; left time: 1013.2629s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129111\n",
      "\tspeed: 0.0228s/iter; left time: 487.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 222 | Train Loss: 0.1145915 Vali Loss: 0.1257595 Test Loss: 0.1340147\n",
      "Validation loss decreased (0.128526 --> 0.125759).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1033075\n",
      "\tspeed: 0.0438s/iter; left time: 928.5915s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064940\n",
      "\tspeed: 0.0201s/iter; left time: 424.9210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1106250 Vali Loss: 0.1245823 Test Loss: 0.1331115\n",
      "Validation loss decreased (0.125759 --> 0.124582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1061657\n",
      "\tspeed: 0.0488s/iter; left time: 1025.0091s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098838\n",
      "\tspeed: 0.0207s/iter; left time: 433.4690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.1087908 Vali Loss: 0.1249903 Test Loss: 0.1338880\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1084789\n",
      "\tspeed: 0.0471s/iter; left time: 978.5360s\n",
      "\titers: 200, epoch: 7 | loss: 0.1140483\n",
      "\tspeed: 0.0202s/iter; left time: 418.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1072994 Vali Loss: 0.1264852 Test Loss: 0.1340602\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098727\n",
      "\tspeed: 0.0438s/iter; left time: 900.6806s\n",
      "\titers: 200, epoch: 8 | loss: 0.1146306\n",
      "\tspeed: 0.0202s/iter; left time: 413.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1063628 Vali Loss: 0.1240705 Test Loss: 0.1315209\n",
      "Validation loss decreased (0.124582 --> 0.124070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1115242\n",
      "\tspeed: 0.0437s/iter; left time: 887.3923s\n",
      "\titers: 200, epoch: 9 | loss: 0.1031145\n",
      "\tspeed: 0.0201s/iter; left time: 407.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1056624 Vali Loss: 0.1263402 Test Loss: 0.1336622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067512\n",
      "\tspeed: 0.0437s/iter; left time: 879.3856s\n",
      "\titers: 200, epoch: 10 | loss: 0.1040183\n",
      "\tspeed: 0.0201s/iter; left time: 402.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1050005 Vali Loss: 0.1251166 Test Loss: 0.1326799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1089376\n",
      "\tspeed: 0.0429s/iter; left time: 853.7762s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986640\n",
      "\tspeed: 0.0203s/iter; left time: 400.6855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1045842 Vali Loss: 0.1240261 Test Loss: 0.1322822\n",
      "Validation loss decreased (0.124070 --> 0.124026).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066567\n",
      "\tspeed: 0.0440s/iter; left time: 865.5651s\n",
      "\titers: 200, epoch: 12 | loss: 0.1005452\n",
      "\tspeed: 0.0203s/iter; left time: 397.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1040709 Vali Loss: 0.1257275 Test Loss: 0.1339570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1006553\n",
      "\tspeed: 0.0447s/iter; left time: 868.0454s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049977\n",
      "\tspeed: 0.0202s/iter; left time: 391.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1036637 Vali Loss: 0.1257253 Test Loss: 0.1338510\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0959458\n",
      "\tspeed: 0.0439s/iter; left time: 844.4609s\n",
      "\titers: 200, epoch: 14 | loss: 0.1034217\n",
      "\tspeed: 0.0202s/iter; left time: 387.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1034468 Vali Loss: 0.1255327 Test Loss: 0.1356756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1008628\n",
      "\tspeed: 0.0437s/iter; left time: 829.0623s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011707\n",
      "\tspeed: 0.0201s/iter; left time: 379.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1029629 Vali Loss: 0.1264527 Test Loss: 0.1365733\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1021052\n",
      "\tspeed: 0.0445s/iter; left time: 834.5961s\n",
      "\titers: 200, epoch: 16 | loss: 0.1040429\n",
      "\tspeed: 0.0202s/iter; left time: 377.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1027325 Vali Loss: 0.1243456 Test Loss: 0.1328561\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1048103\n",
      "\tspeed: 0.0432s/iter; left time: 800.9917s\n",
      "\titers: 200, epoch: 17 | loss: 0.1021821\n",
      "\tspeed: 0.0210s/iter; left time: 387.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1024323 Vali Loss: 0.1234998 Test Loss: 0.1329888\n",
      "Validation loss decreased (0.124026 --> 0.123500).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1026683\n",
      "\tspeed: 0.0438s/iter; left time: 803.4176s\n",
      "\titers: 200, epoch: 18 | loss: 0.0989553\n",
      "\tspeed: 0.0201s/iter; left time: 366.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1022891 Vali Loss: 0.1259734 Test Loss: 0.1368130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1009428\n",
      "\tspeed: 0.0465s/iter; left time: 841.9709s\n",
      "\titers: 200, epoch: 19 | loss: 0.1040189\n",
      "\tspeed: 0.0210s/iter; left time: 378.2188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 222 | Train Loss: 0.1022190 Vali Loss: 0.1257375 Test Loss: 0.1346503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1026354\n",
      "\tspeed: 0.0475s/iter; left time: 849.1692s\n",
      "\titers: 200, epoch: 20 | loss: 0.1002588\n",
      "\tspeed: 0.0228s/iter; left time: 405.0483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 222 | Train Loss: 0.1018585 Vali Loss: 0.1253074 Test Loss: 0.1350731\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1005532\n",
      "\tspeed: 0.0446s/iter; left time: 786.9355s\n",
      "\titers: 200, epoch: 21 | loss: 0.0934714\n",
      "\tspeed: 0.0203s/iter; left time: 356.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1017166 Vali Loss: 0.1254313 Test Loss: 0.1365214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1041646\n",
      "\tspeed: 0.0454s/iter; left time: 791.5812s\n",
      "\titers: 200, epoch: 22 | loss: 0.1001442\n",
      "\tspeed: 0.0207s/iter; left time: 359.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1017033 Vali Loss: 0.1260002 Test Loss: 0.1364065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1053329\n",
      "\tspeed: 0.0446s/iter; left time: 768.0766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0997870\n",
      "\tspeed: 0.0204s/iter; left time: 349.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1014405 Vali Loss: 0.1269710 Test Loss: 0.1371964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1001726\n",
      "\tspeed: 0.0440s/iter; left time: 748.0403s\n",
      "\titers: 200, epoch: 24 | loss: 0.0986712\n",
      "\tspeed: 0.0202s/iter; left time: 340.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1014841 Vali Loss: 0.1259731 Test Loss: 0.1364085\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0971417\n",
      "\tspeed: 0.0434s/iter; left time: 727.1293s\n",
      "\titers: 200, epoch: 25 | loss: 0.0972540\n",
      "\tspeed: 0.0202s/iter; left time: 337.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1012330 Vali Loss: 0.1254518 Test Loss: 0.1343188\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0966127\n",
      "\tspeed: 0.0436s/iter; left time: 720.8721s\n",
      "\titers: 200, epoch: 26 | loss: 0.1000932\n",
      "\tspeed: 0.0203s/iter; left time: 333.2512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1012501 Vali Loss: 0.1263892 Test Loss: 0.1373893\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1027568\n",
      "\tspeed: 0.0445s/iter; left time: 726.2366s\n",
      "\titers: 200, epoch: 27 | loss: 0.1002008\n",
      "\tspeed: 0.0207s/iter; left time: 336.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1010386 Vali Loss: 0.1256889 Test Loss: 0.1365835\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04084043577313423, rmse:0.20209017395973206, mae:0.1329888105392456, rse:0.7156420946121216\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:40.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2635712\n",
      "\tspeed: 0.0463s/iter; left time: 1022.7045s\n",
      "\titers: 200, epoch: 1 | loss: 0.2505818\n",
      "\tspeed: 0.0205s/iter; left time: 451.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.2714522 Vali Loss: 0.2291701 Test Loss: 0.2326015\n",
      "Validation loss decreased (inf --> 0.229170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1508654\n",
      "\tspeed: 0.0460s/iter; left time: 1006.9796s\n",
      "\titers: 200, epoch: 2 | loss: 0.1371257\n",
      "\tspeed: 0.0207s/iter; left time: 451.8616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1640857 Vali Loss: 0.1416273 Test Loss: 0.1485835\n",
      "Validation loss decreased (0.229170 --> 0.141627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1233250\n",
      "\tspeed: 0.0436s/iter; left time: 944.5375s\n",
      "\titers: 200, epoch: 3 | loss: 0.1236663\n",
      "\tspeed: 0.0229s/iter; left time: 494.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.1269506 Vali Loss: 0.1366062 Test Loss: 0.1493749\n",
      "Validation loss decreased (0.141627 --> 0.136606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1219652\n",
      "\tspeed: 0.0448s/iter; left time: 959.5298s\n",
      "\titers: 200, epoch: 4 | loss: 0.1137599\n",
      "\tspeed: 0.0206s/iter; left time: 440.2518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1188799 Vali Loss: 0.1308372 Test Loss: 0.1418802\n",
      "Validation loss decreased (0.136606 --> 0.130837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1190454\n",
      "\tspeed: 0.0446s/iter; left time: 946.4585s\n",
      "\titers: 200, epoch: 5 | loss: 0.1164137\n",
      "\tspeed: 0.0208s/iter; left time: 439.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.1155872 Vali Loss: 0.1299212 Test Loss: 0.1408072\n",
      "Validation loss decreased (0.130837 --> 0.129921).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1164058\n",
      "\tspeed: 0.0454s/iter; left time: 953.5725s\n",
      "\titers: 200, epoch: 6 | loss: 0.1132132\n",
      "\tspeed: 0.0245s/iter; left time: 512.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 222 | Train Loss: 0.1134714 Vali Loss: 0.1308232 Test Loss: 0.1423041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104720\n",
      "\tspeed: 0.0479s/iter; left time: 994.8967s\n",
      "\titers: 200, epoch: 7 | loss: 0.1137908\n",
      "\tspeed: 0.0241s/iter; left time: 498.8305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 222 | Train Loss: 0.1122399 Vali Loss: 0.1317047 Test Loss: 0.1434711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1121600\n",
      "\tspeed: 0.0435s/iter; left time: 893.3539s\n",
      "\titers: 200, epoch: 8 | loss: 0.1126190\n",
      "\tspeed: 0.0204s/iter; left time: 416.7355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1111663 Vali Loss: 0.1357587 Test Loss: 0.1516875\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1132699\n",
      "\tspeed: 0.0437s/iter; left time: 887.3972s\n",
      "\titers: 200, epoch: 9 | loss: 0.1096397\n",
      "\tspeed: 0.0208s/iter; left time: 421.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1106153 Vali Loss: 0.1315435 Test Loss: 0.1457874\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1088877\n",
      "\tspeed: 0.0434s/iter; left time: 871.6284s\n",
      "\titers: 200, epoch: 10 | loss: 0.1072207\n",
      "\tspeed: 0.0216s/iter; left time: 431.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.1096746 Vali Loss: 0.1307920 Test Loss: 0.1449525\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129742\n",
      "\tspeed: 0.0434s/iter; left time: 863.3778s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104764\n",
      "\tspeed: 0.0224s/iter; left time: 443.3776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1092887 Vali Loss: 0.1300609 Test Loss: 0.1449732\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1130502\n",
      "\tspeed: 0.0438s/iter; left time: 860.4834s\n",
      "\titers: 200, epoch: 12 | loss: 0.1096532\n",
      "\tspeed: 0.0234s/iter; left time: 458.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 222 | Train Loss: 0.1086675 Vali Loss: 0.1291688 Test Loss: 0.1437897\n",
      "Validation loss decreased (0.129921 --> 0.129169).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032140\n",
      "\tspeed: 0.0468s/iter; left time: 909.3248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990243\n",
      "\tspeed: 0.0206s/iter; left time: 398.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1080841 Vali Loss: 0.1294795 Test Loss: 0.1436269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1076146\n",
      "\tspeed: 0.0442s/iter; left time: 850.2597s\n",
      "\titers: 200, epoch: 14 | loss: 0.1087734\n",
      "\tspeed: 0.0207s/iter; left time: 395.7543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.1079351 Vali Loss: 0.1275356 Test Loss: 0.1418951\n",
      "Validation loss decreased (0.129169 --> 0.127536).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1076952\n",
      "\tspeed: 0.0451s/iter; left time: 856.3837s\n",
      "\titers: 200, epoch: 15 | loss: 0.1095065\n",
      "\tspeed: 0.0208s/iter; left time: 392.1937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1076429 Vali Loss: 0.1281830 Test Loss: 0.1446722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1086038\n",
      "\tspeed: 0.0457s/iter; left time: 857.1397s\n",
      "\titers: 200, epoch: 16 | loss: 0.1030773\n",
      "\tspeed: 0.0230s/iter; left time: 429.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 222 | Train Loss: 0.1071818 Vali Loss: 0.1278302 Test Loss: 0.1433857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1056638\n",
      "\tspeed: 0.0432s/iter; left time: 801.7546s\n",
      "\titers: 200, epoch: 17 | loss: 0.1042433\n",
      "\tspeed: 0.0205s/iter; left time: 377.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1071794 Vali Loss: 0.1285924 Test Loss: 0.1446194\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1053060\n",
      "\tspeed: 0.0434s/iter; left time: 794.4787s\n",
      "\titers: 200, epoch: 18 | loss: 0.1094116\n",
      "\tspeed: 0.0211s/iter; left time: 384.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1068149 Vali Loss: 0.1272435 Test Loss: 0.1427091\n",
      "Validation loss decreased (0.127536 --> 0.127243).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1108867\n",
      "\tspeed: 0.0427s/iter; left time: 772.7683s\n",
      "\titers: 200, epoch: 19 | loss: 0.1097524\n",
      "\tspeed: 0.0204s/iter; left time: 368.1566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1064583 Vali Loss: 0.1268616 Test Loss: 0.1427672\n",
      "Validation loss decreased (0.127243 --> 0.126862).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1038617\n",
      "\tspeed: 0.0467s/iter; left time: 834.5036s\n",
      "\titers: 200, epoch: 20 | loss: 0.1059494\n",
      "\tspeed: 0.0206s/iter; left time: 365.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.1062101 Vali Loss: 0.1266779 Test Loss: 0.1428877\n",
      "Validation loss decreased (0.126862 --> 0.126678).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033215\n",
      "\tspeed: 0.0453s/iter; left time: 799.6570s\n",
      "\titers: 200, epoch: 21 | loss: 0.1048715\n",
      "\tspeed: 0.0216s/iter; left time: 378.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.1062270 Vali Loss: 0.1276238 Test Loss: 0.1445345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1037091\n",
      "\tspeed: 0.0453s/iter; left time: 790.2485s\n",
      "\titers: 200, epoch: 22 | loss: 0.1078178\n",
      "\tspeed: 0.0209s/iter; left time: 362.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1059321 Vali Loss: 0.1267027 Test Loss: 0.1432244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1041584\n",
      "\tspeed: 0.0440s/iter; left time: 757.9136s\n",
      "\titers: 200, epoch: 23 | loss: 0.1000154\n",
      "\tspeed: 0.0208s/iter; left time: 356.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.1058848 Vali Loss: 0.1268779 Test Loss: 0.1424203\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1026665\n",
      "\tspeed: 0.0460s/iter; left time: 782.3851s\n",
      "\titers: 200, epoch: 24 | loss: 0.1068058\n",
      "\tspeed: 0.0206s/iter; left time: 347.8888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1058591 Vali Loss: 0.1262804 Test Loss: 0.1424438\n",
      "Validation loss decreased (0.126678 --> 0.126280).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1042366\n",
      "\tspeed: 0.0462s/iter; left time: 774.8191s\n",
      "\titers: 200, epoch: 25 | loss: 0.1067096\n",
      "\tspeed: 0.0206s/iter; left time: 343.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.1056078 Vali Loss: 0.1267104 Test Loss: 0.1430844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1093422\n",
      "\tspeed: 0.0431s/iter; left time: 713.1939s\n",
      "\titers: 200, epoch: 26 | loss: 0.1035668\n",
      "\tspeed: 0.0204s/iter; left time: 334.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1055133 Vali Loss: 0.1270550 Test Loss: 0.1438429\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1037734\n",
      "\tspeed: 0.0424s/iter; left time: 691.7114s\n",
      "\titers: 200, epoch: 27 | loss: 0.1029718\n",
      "\tspeed: 0.0210s/iter; left time: 340.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1054176 Vali Loss: 0.1262701 Test Loss: 0.1428297\n",
      "Validation loss decreased (0.126280 --> 0.126270).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1046086\n",
      "\tspeed: 0.0434s/iter; left time: 699.7760s\n",
      "\titers: 200, epoch: 28 | loss: 0.1028433\n",
      "\tspeed: 0.0205s/iter; left time: 328.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1053458 Vali Loss: 0.1264106 Test Loss: 0.1432624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1039153\n",
      "\tspeed: 0.0425s/iter; left time: 674.6228s\n",
      "\titers: 200, epoch: 29 | loss: 0.1044010\n",
      "\tspeed: 0.0207s/iter; left time: 327.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1052193 Vali Loss: 0.1259411 Test Loss: 0.1422317\n",
      "Validation loss decreased (0.126270 --> 0.125941).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1020727\n",
      "\tspeed: 0.0429s/iter; left time: 672.7025s\n",
      "\titers: 200, epoch: 30 | loss: 0.1071113\n",
      "\tspeed: 0.0206s/iter; left time: 320.4939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1052012 Vali Loss: 0.1258453 Test Loss: 0.1425649\n",
      "Validation loss decreased (0.125941 --> 0.125845).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1079093\n",
      "\tspeed: 0.0439s/iter; left time: 678.1173s\n",
      "\titers: 200, epoch: 31 | loss: 0.1101111\n",
      "\tspeed: 0.0204s/iter; left time: 312.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1050924 Vali Loss: 0.1261823 Test Loss: 0.1432493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1044770\n",
      "\tspeed: 0.0428s/iter; left time: 651.1859s\n",
      "\titers: 200, epoch: 32 | loss: 0.1037062\n",
      "\tspeed: 0.0207s/iter; left time: 312.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1050540 Vali Loss: 0.1260934 Test Loss: 0.1428397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1051383\n",
      "\tspeed: 0.0429s/iter; left time: 642.6469s\n",
      "\titers: 200, epoch: 33 | loss: 0.1025543\n",
      "\tspeed: 0.0207s/iter; left time: 308.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1050585 Vali Loss: 0.1261664 Test Loss: 0.1434357\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1060019\n",
      "\tspeed: 0.0422s/iter; left time: 623.6637s\n",
      "\titers: 200, epoch: 34 | loss: 0.1090982\n",
      "\tspeed: 0.0203s/iter; left time: 298.5977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1049983 Vali Loss: 0.1263918 Test Loss: 0.1437126\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1018900\n",
      "\tspeed: 0.0429s/iter; left time: 623.8303s\n",
      "\titers: 200, epoch: 35 | loss: 0.1032309\n",
      "\tspeed: 0.0224s/iter; left time: 323.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1050053 Vali Loss: 0.1262742 Test Loss: 0.1440051\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1098305\n",
      "\tspeed: 0.0475s/iter; left time: 680.6013s\n",
      "\titers: 200, epoch: 36 | loss: 0.1090532\n",
      "\tspeed: 0.0215s/iter; left time: 306.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.1049113 Vali Loss: 0.1259437 Test Loss: 0.1433206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1012445\n",
      "\tspeed: 0.0446s/iter; left time: 628.8339s\n",
      "\titers: 200, epoch: 37 | loss: 0.1029525\n",
      "\tspeed: 0.0214s/iter; left time: 300.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.1048600 Vali Loss: 0.1261355 Test Loss: 0.1437023\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1011759\n",
      "\tspeed: 0.0437s/iter; left time: 607.2890s\n",
      "\titers: 200, epoch: 38 | loss: 0.1020085\n",
      "\tspeed: 0.0204s/iter; left time: 280.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1048106 Vali Loss: 0.1260846 Test Loss: 0.1427205\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1081446\n",
      "\tspeed: 0.0428s/iter; left time: 584.2930s\n",
      "\titers: 200, epoch: 39 | loss: 0.1047102\n",
      "\tspeed: 0.0219s/iter; left time: 296.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.1049029 Vali Loss: 0.1261722 Test Loss: 0.1429999\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1027207\n",
      "\tspeed: 0.0433s/iter; left time: 582.6551s\n",
      "\titers: 200, epoch: 40 | loss: 0.1031509\n",
      "\tspeed: 0.0205s/iter; left time: 273.1358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1048176 Vali Loss: 0.1258087 Test Loss: 0.1429110\n",
      "Validation loss decreased (0.125845 --> 0.125809).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1084505\n",
      "\tspeed: 0.0437s/iter; left time: 577.7253s\n",
      "\titers: 200, epoch: 41 | loss: 0.1063763\n",
      "\tspeed: 0.0204s/iter; left time: 267.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1048004 Vali Loss: 0.1260300 Test Loss: 0.1431440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1037070\n",
      "\tspeed: 0.0426s/iter; left time: 553.4370s\n",
      "\titers: 200, epoch: 42 | loss: 0.0985596\n",
      "\tspeed: 0.0204s/iter; left time: 262.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1047334 Vali Loss: 0.1259820 Test Loss: 0.1429048\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1047863\n",
      "\tspeed: 0.0446s/iter; left time: 569.6503s\n",
      "\titers: 200, epoch: 43 | loss: 0.1066994\n",
      "\tspeed: 0.0230s/iter; left time: 291.4190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 222 | Train Loss: 0.1048005 Vali Loss: 0.1257820 Test Loss: 0.1428812\n",
      "Validation loss decreased (0.125809 --> 0.125782).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1029892\n",
      "\tspeed: 0.0447s/iter; left time: 560.6365s\n",
      "\titers: 200, epoch: 44 | loss: 0.1043477\n",
      "\tspeed: 0.0205s/iter; left time: 255.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1047804 Vali Loss: 0.1262902 Test Loss: 0.1438335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1020061\n",
      "\tspeed: 0.0429s/iter; left time: 529.0244s\n",
      "\titers: 200, epoch: 45 | loss: 0.1090222\n",
      "\tspeed: 0.0205s/iter; left time: 251.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1047420 Vali Loss: 0.1259686 Test Loss: 0.1430282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1056381\n",
      "\tspeed: 0.0436s/iter; left time: 528.2960s\n",
      "\titers: 200, epoch: 46 | loss: 0.1050418\n",
      "\tspeed: 0.0213s/iter; left time: 255.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.1046810 Vali Loss: 0.1261729 Test Loss: 0.1438249\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1090499\n",
      "\tspeed: 0.0468s/iter; left time: 556.4086s\n",
      "\titers: 200, epoch: 47 | loss: 0.1054865\n",
      "\tspeed: 0.0224s/iter; left time: 263.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 222 | Train Loss: 0.1047337 Vali Loss: 0.1261556 Test Loss: 0.1435580\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1041568\n",
      "\tspeed: 0.0427s/iter; left time: 498.0700s\n",
      "\titers: 200, epoch: 48 | loss: 0.1082203\n",
      "\tspeed: 0.0204s/iter; left time: 235.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1047066 Vali Loss: 0.1259478 Test Loss: 0.1431990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1073269\n",
      "\tspeed: 0.0428s/iter; left time: 489.9038s\n",
      "\titers: 200, epoch: 49 | loss: 0.1065548\n",
      "\tspeed: 0.0209s/iter; left time: 237.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1047069 Vali Loss: 0.1259166 Test Loss: 0.1426549\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1035100\n",
      "\tspeed: 0.0439s/iter; left time: 492.3951s\n",
      "\titers: 200, epoch: 50 | loss: 0.1045742\n",
      "\tspeed: 0.0210s/iter; left time: 233.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1045960 Vali Loss: 0.1257866 Test Loss: 0.1427472\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1047946\n",
      "\tspeed: 0.0424s/iter; left time: 466.4244s\n",
      "\titers: 200, epoch: 51 | loss: 0.1056989\n",
      "\tspeed: 0.0204s/iter; left time: 222.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1046224 Vali Loss: 0.1262049 Test Loss: 0.1436868\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1077790\n",
      "\tspeed: 0.0445s/iter; left time: 479.3058s\n",
      "\titers: 200, epoch: 52 | loss: 0.1084152\n",
      "\tspeed: 0.0211s/iter; left time: 225.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.1046219 Vali Loss: 0.1257649 Test Loss: 0.1430751\n",
      "Validation loss decreased (0.125782 --> 0.125765).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1022902\n",
      "\tspeed: 0.0429s/iter; left time: 453.2472s\n",
      "\titers: 200, epoch: 53 | loss: 0.0999769\n",
      "\tspeed: 0.0203s/iter; left time: 212.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1046869 Vali Loss: 0.1258842 Test Loss: 0.1429341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1066160\n",
      "\tspeed: 0.0428s/iter; left time: 442.2756s\n",
      "\titers: 200, epoch: 54 | loss: 0.1075375\n",
      "\tspeed: 0.0206s/iter; left time: 210.9638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1046579 Vali Loss: 0.1260206 Test Loss: 0.1434988\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0984180\n",
      "\tspeed: 0.0427s/iter; left time: 432.2236s\n",
      "\titers: 200, epoch: 55 | loss: 0.1051654\n",
      "\tspeed: 0.0206s/iter; left time: 205.8743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1046924 Vali Loss: 0.1261065 Test Loss: 0.1433332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1052093\n",
      "\tspeed: 0.0448s/iter; left time: 442.7669s\n",
      "\titers: 200, epoch: 56 | loss: 0.1066872\n",
      "\tspeed: 0.0227s/iter; left time: 222.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 222 | Train Loss: 0.1046459 Vali Loss: 0.1258322 Test Loss: 0.1427461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1064580\n",
      "\tspeed: 0.0447s/iter; left time: 432.2270s\n",
      "\titers: 200, epoch: 57 | loss: 0.1035502\n",
      "\tspeed: 0.0217s/iter; left time: 207.3127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1046452 Vali Loss: 0.1260563 Test Loss: 0.1435452\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1044552\n",
      "\tspeed: 0.0433s/iter; left time: 408.9134s\n",
      "\titers: 200, epoch: 58 | loss: 0.1059206\n",
      "\tspeed: 0.0205s/iter; left time: 191.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1046005 Vali Loss: 0.1258516 Test Loss: 0.1427021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1065851\n",
      "\tspeed: 0.0422s/iter; left time: 389.2438s\n",
      "\titers: 200, epoch: 59 | loss: 0.1070579\n",
      "\tspeed: 0.0204s/iter; left time: 186.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1046313 Vali Loss: 0.1259600 Test Loss: 0.1434012\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.1046154\n",
      "\tspeed: 0.0426s/iter; left time: 383.1501s\n",
      "\titers: 200, epoch: 60 | loss: 0.1000190\n",
      "\tspeed: 0.0204s/iter; left time: 181.5473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1045699 Vali Loss: 0.1260350 Test Loss: 0.1433356\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.1069357\n",
      "\tspeed: 0.0457s/iter; left time: 401.6045s\n",
      "\titers: 200, epoch: 61 | loss: 0.1066801\n",
      "\tspeed: 0.0220s/iter; left time: 191.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 222 | Train Loss: 0.1046159 Vali Loss: 0.1262933 Test Loss: 0.1439901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1067538\n",
      "\tspeed: 0.0448s/iter; left time: 383.7765s\n",
      "\titers: 200, epoch: 62 | loss: 0.1066487\n",
      "\tspeed: 0.0211s/iter; left time: 178.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.1045509 Vali Loss: 0.1259451 Test Loss: 0.1432046\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048424143344163895, rmse:0.22005486488342285, mae:0.14307503402233124, rse:0.7794520258903503\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2733041\n",
      "\tspeed: 0.0261s/iter; left time: 577.5948s\n",
      "\titers: 200, epoch: 1 | loss: 0.2486118\n",
      "\tspeed: 0.0223s/iter; left time: 491.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 222 | Train Loss: 0.2720052 Vali Loss: 0.2292754 Test Loss: 0.2321390\n",
      "Validation loss decreased (inf --> 0.229275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501245\n",
      "\tspeed: 0.0473s/iter; left time: 1033.8036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1419022\n",
      "\tspeed: 0.0230s/iter; left time: 501.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 222 | Train Loss: 0.1636119 Vali Loss: 0.1440349 Test Loss: 0.1509175\n",
      "Validation loss decreased (0.229275 --> 0.144035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1302628\n",
      "\tspeed: 0.0456s/iter; left time: 987.2898s\n",
      "\titers: 200, epoch: 3 | loss: 0.1214185\n",
      "\tspeed: 0.0220s/iter; left time: 473.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.1282141 Vali Loss: 0.1328316 Test Loss: 0.1453151\n",
      "Validation loss decreased (0.144035 --> 0.132832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1173071\n",
      "\tspeed: 0.0463s/iter; left time: 993.1155s\n",
      "\titers: 200, epoch: 4 | loss: 0.1165423\n",
      "\tspeed: 0.0204s/iter; left time: 434.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1197912 Vali Loss: 0.1308119 Test Loss: 0.1437014\n",
      "Validation loss decreased (0.132832 --> 0.130812).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1130587\n",
      "\tspeed: 0.0450s/iter; left time: 954.2235s\n",
      "\titers: 200, epoch: 5 | loss: 0.1200719\n",
      "\tspeed: 0.0203s/iter; left time: 428.9243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1163651 Vali Loss: 0.1289939 Test Loss: 0.1387951\n",
      "Validation loss decreased (0.130812 --> 0.128994).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1133281\n",
      "\tspeed: 0.0449s/iter; left time: 942.9878s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126720\n",
      "\tspeed: 0.0204s/iter; left time: 426.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1143900 Vali Loss: 0.1289839 Test Loss: 0.1393874\n",
      "Validation loss decreased (0.128994 --> 0.128984).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1136062\n",
      "\tspeed: 0.0450s/iter; left time: 935.3147s\n",
      "\titers: 200, epoch: 7 | loss: 0.1068207\n",
      "\tspeed: 0.0205s/iter; left time: 424.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1129568 Vali Loss: 0.1288813 Test Loss: 0.1396884\n",
      "Validation loss decreased (0.128984 --> 0.128881).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1109090\n",
      "\tspeed: 0.0465s/iter; left time: 955.2320s\n",
      "\titers: 200, epoch: 8 | loss: 0.1150609\n",
      "\tspeed: 0.0212s/iter; left time: 433.9958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.1119167 Vali Loss: 0.1274864 Test Loss: 0.1367660\n",
      "Validation loss decreased (0.128881 --> 0.127486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1099020\n",
      "\tspeed: 0.0476s/iter; left time: 967.5466s\n",
      "\titers: 200, epoch: 9 | loss: 0.1079431\n",
      "\tspeed: 0.0209s/iter; left time: 421.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1112272 Vali Loss: 0.1272544 Test Loss: 0.1383725\n",
      "Validation loss decreased (0.127486 --> 0.127254).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1099395\n",
      "\tspeed: 0.0445s/iter; left time: 895.5479s\n",
      "\titers: 200, epoch: 10 | loss: 0.1108703\n",
      "\tspeed: 0.0204s/iter; left time: 408.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1104818 Vali Loss: 0.1289230 Test Loss: 0.1409940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1105483\n",
      "\tspeed: 0.0449s/iter; left time: 891.9914s\n",
      "\titers: 200, epoch: 11 | loss: 0.1057599\n",
      "\tspeed: 0.0205s/iter; left time: 405.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1096762 Vali Loss: 0.1277673 Test Loss: 0.1389453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1108596\n",
      "\tspeed: 0.0446s/iter; left time: 876.7293s\n",
      "\titers: 200, epoch: 12 | loss: 0.1118881\n",
      "\tspeed: 0.0206s/iter; left time: 403.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1091056 Vali Loss: 0.1276943 Test Loss: 0.1410744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1093146\n",
      "\tspeed: 0.0439s/iter; left time: 853.7754s\n",
      "\titers: 200, epoch: 13 | loss: 0.1094457\n",
      "\tspeed: 0.0203s/iter; left time: 392.2997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1088402 Vali Loss: 0.1278117 Test Loss: 0.1405839\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1091221\n",
      "\tspeed: 0.0442s/iter; left time: 848.8190s\n",
      "\titers: 200, epoch: 14 | loss: 0.1050427\n",
      "\tspeed: 0.0205s/iter; left time: 392.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1081201 Vali Loss: 0.1274476 Test Loss: 0.1421491\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1038304\n",
      "\tspeed: 0.0442s/iter; left time: 839.5400s\n",
      "\titers: 200, epoch: 15 | loss: 0.1066700\n",
      "\tspeed: 0.0205s/iter; left time: 386.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1076028 Vali Loss: 0.1285415 Test Loss: 0.1428325\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1085553\n",
      "\tspeed: 0.0446s/iter; left time: 836.3540s\n",
      "\titers: 200, epoch: 16 | loss: 0.1015527\n",
      "\tspeed: 0.0204s/iter; left time: 381.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1071608 Vali Loss: 0.1279540 Test Loss: 0.1432049\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1035085\n",
      "\tspeed: 0.0435s/iter; left time: 806.9387s\n",
      "\titers: 200, epoch: 17 | loss: 0.1029408\n",
      "\tspeed: 0.0205s/iter; left time: 378.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1068667 Vali Loss: 0.1280768 Test Loss: 0.1425950\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1006354\n",
      "\tspeed: 0.0436s/iter; left time: 799.9275s\n",
      "\titers: 200, epoch: 18 | loss: 0.1092632\n",
      "\tspeed: 0.0204s/iter; left time: 371.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1065844 Vali Loss: 0.1277221 Test Loss: 0.1425489\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1035319\n",
      "\tspeed: 0.0450s/iter; left time: 815.3620s\n",
      "\titers: 200, epoch: 19 | loss: 0.1085452\n",
      "\tspeed: 0.0204s/iter; left time: 367.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1063101 Vali Loss: 0.1279139 Test Loss: 0.1433686\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04185667261481285, rmse:0.20458903908729553, mae:0.13837240636348724, rse:0.7246708273887634\n",
      "Intermediate time for DE and pred_len 168: 00h:09m:05.04s\n",
      "Intermediate time for DE: 00h:31m:31.41s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2762307\n",
      "\tspeed: 0.0486s/iter; left time: 1079.8196s\n",
      "\titers: 200, epoch: 1 | loss: 0.2635011\n",
      "\tspeed: 0.0201s/iter; left time: 445.1202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.2846532 Vali Loss: 0.2345314 Test Loss: 0.2545903\n",
      "Validation loss decreased (inf --> 0.234531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462703\n",
      "\tspeed: 0.0431s/iter; left time: 947.8180s\n",
      "\titers: 200, epoch: 2 | loss: 0.1180813\n",
      "\tspeed: 0.0200s/iter; left time: 438.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.1548678 Vali Loss: 0.1075235 Test Loss: 0.1276649\n",
      "Validation loss decreased (0.234531 --> 0.107523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056325\n",
      "\tspeed: 0.0424s/iter; left time: 921.5323s\n",
      "\titers: 200, epoch: 3 | loss: 0.0978099\n",
      "\tspeed: 0.0200s/iter; left time: 433.8361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.1021520 Vali Loss: 0.1020983 Test Loss: 0.1142755\n",
      "Validation loss decreased (0.107523 --> 0.102098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859044\n",
      "\tspeed: 0.0429s/iter; left time: 924.7683s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863699\n",
      "\tspeed: 0.0204s/iter; left time: 436.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0910893 Vali Loss: 0.0958324 Test Loss: 0.1089872\n",
      "Validation loss decreased (0.102098 --> 0.095832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870712\n",
      "\tspeed: 0.0420s/iter; left time: 894.3137s\n",
      "\titers: 200, epoch: 5 | loss: 0.0877185\n",
      "\tspeed: 0.0202s/iter; left time: 427.6438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0873805 Vali Loss: 0.0958049 Test Loss: 0.1089031\n",
      "Validation loss decreased (0.095832 --> 0.095805).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0865226\n",
      "\tspeed: 0.0425s/iter; left time: 895.3277s\n",
      "\titers: 200, epoch: 6 | loss: 0.0773692\n",
      "\tspeed: 0.0202s/iter; left time: 423.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0851459 Vali Loss: 0.0935297 Test Loss: 0.1068609\n",
      "Validation loss decreased (0.095805 --> 0.093530).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0910266\n",
      "\tspeed: 0.0422s/iter; left time: 880.2031s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836363\n",
      "\tspeed: 0.0202s/iter; left time: 419.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0837980 Vali Loss: 0.0958510 Test Loss: 0.1085853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0929813\n",
      "\tspeed: 0.0417s/iter; left time: 860.9380s\n",
      "\titers: 200, epoch: 8 | loss: 0.0798118\n",
      "\tspeed: 0.0202s/iter; left time: 415.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0825603 Vali Loss: 0.0935541 Test Loss: 0.1069116\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0834011\n",
      "\tspeed: 0.0425s/iter; left time: 868.4110s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846200\n",
      "\tspeed: 0.0203s/iter; left time: 411.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0822000 Vali Loss: 0.0931175 Test Loss: 0.1068537\n",
      "Validation loss decreased (0.093530 --> 0.093118).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833874\n",
      "\tspeed: 0.0413s/iter; left time: 834.8350s\n",
      "\titers: 200, epoch: 10 | loss: 0.0764196\n",
      "\tspeed: 0.0200s/iter; left time: 402.0615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0813710 Vali Loss: 0.0927926 Test Loss: 0.1075682\n",
      "Validation loss decreased (0.093118 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779778\n",
      "\tspeed: 0.0442s/iter; left time: 883.6099s\n",
      "\titers: 200, epoch: 11 | loss: 0.0850850\n",
      "\tspeed: 0.0212s/iter; left time: 422.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0807591 Vali Loss: 0.0936243 Test Loss: 0.1078661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0772677\n",
      "\tspeed: 0.0411s/iter; left time: 812.4208s\n",
      "\titers: 200, epoch: 12 | loss: 0.0849133\n",
      "\tspeed: 0.0200s/iter; left time: 392.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0806203 Vali Loss: 0.0925910 Test Loss: 0.1069170\n",
      "Validation loss decreased (0.092793 --> 0.092591).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850292\n",
      "\tspeed: 0.0430s/iter; left time: 839.4115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785023\n",
      "\tspeed: 0.0201s/iter; left time: 391.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0802062 Vali Loss: 0.0925909 Test Loss: 0.1061884\n",
      "Validation loss decreased (0.092591 --> 0.092591).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785980\n",
      "\tspeed: 0.0473s/iter; left time: 912.4832s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815690\n",
      "\tspeed: 0.0214s/iter; left time: 411.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0797629 Vali Loss: 0.0924830 Test Loss: 0.1066159\n",
      "Validation loss decreased (0.092591 --> 0.092483).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0841059\n",
      "\tspeed: 0.0464s/iter; left time: 885.4181s\n",
      "\titers: 200, epoch: 15 | loss: 0.0772365\n",
      "\tspeed: 0.0203s/iter; left time: 385.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0795653 Vali Loss: 0.0932157 Test Loss: 0.1072776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0795897\n",
      "\tspeed: 0.0477s/iter; left time: 898.5717s\n",
      "\titers: 200, epoch: 16 | loss: 0.0753777\n",
      "\tspeed: 0.0223s/iter; left time: 418.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0794256 Vali Loss: 0.0920563 Test Loss: 0.1061548\n",
      "Validation loss decreased (0.092483 --> 0.092056).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0772193\n",
      "\tspeed: 0.0427s/iter; left time: 795.5770s\n",
      "\titers: 200, epoch: 17 | loss: 0.0747934\n",
      "\tspeed: 0.0200s/iter; left time: 370.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0793213 Vali Loss: 0.0931103 Test Loss: 0.1067440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747713\n",
      "\tspeed: 0.0444s/iter; left time: 817.6195s\n",
      "\titers: 200, epoch: 18 | loss: 0.0862258\n",
      "\tspeed: 0.0201s/iter; left time: 367.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0791298 Vali Loss: 0.0921512 Test Loss: 0.1064603\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0825629\n",
      "\tspeed: 0.0416s/iter; left time: 756.7801s\n",
      "\titers: 200, epoch: 19 | loss: 0.0780634\n",
      "\tspeed: 0.0201s/iter; left time: 362.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0787885 Vali Loss: 0.0922389 Test Loss: 0.1064509\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0749995\n",
      "\tspeed: 0.0482s/iter; left time: 865.2657s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809347\n",
      "\tspeed: 0.0242s/iter; left time: 432.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0787338 Vali Loss: 0.0917851 Test Loss: 0.1061701\n",
      "Validation loss decreased (0.092056 --> 0.091785).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0832797\n",
      "\tspeed: 0.0463s/iter; left time: 820.5247s\n",
      "\titers: 200, epoch: 21 | loss: 0.0727622\n",
      "\tspeed: 0.0202s/iter; left time: 357.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0786904 Vali Loss: 0.0932141 Test Loss: 0.1068489\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0788772\n",
      "\tspeed: 0.0438s/iter; left time: 767.6033s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747757\n",
      "\tspeed: 0.0201s/iter; left time: 350.5766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0784753 Vali Loss: 0.0922331 Test Loss: 0.1063197\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0788626\n",
      "\tspeed: 0.0424s/iter; left time: 733.2957s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793575\n",
      "\tspeed: 0.0202s/iter; left time: 347.1004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0784267 Vali Loss: 0.0918397 Test Loss: 0.1061428\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0749169\n",
      "\tspeed: 0.0428s/iter; left time: 730.4919s\n",
      "\titers: 200, epoch: 24 | loss: 0.0753831\n",
      "\tspeed: 0.0201s/iter; left time: 340.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0783742 Vali Loss: 0.0922403 Test Loss: 0.1065024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0784230\n",
      "\tspeed: 0.0428s/iter; left time: 721.5282s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784471\n",
      "\tspeed: 0.0202s/iter; left time: 338.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0782461 Vali Loss: 0.0925442 Test Loss: 0.1068081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763853\n",
      "\tspeed: 0.0442s/iter; left time: 734.8093s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793958\n",
      "\tspeed: 0.0202s/iter; left time: 334.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0782700 Vali Loss: 0.0923135 Test Loss: 0.1068690\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747001\n",
      "\tspeed: 0.0413s/iter; left time: 677.8769s\n",
      "\titers: 200, epoch: 27 | loss: 0.0807642\n",
      "\tspeed: 0.0201s/iter; left time: 328.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0781686 Vali Loss: 0.0923405 Test Loss: 0.1064812\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0738155\n",
      "\tspeed: 0.0419s/iter; left time: 677.7745s\n",
      "\titers: 200, epoch: 28 | loss: 0.0812550\n",
      "\tspeed: 0.0202s/iter; left time: 324.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0780317 Vali Loss: 0.0921537 Test Loss: 0.1063893\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0752697\n",
      "\tspeed: 0.0415s/iter; left time: 662.7057s\n",
      "\titers: 200, epoch: 29 | loss: 0.0774270\n",
      "\tspeed: 0.0204s/iter; left time: 323.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0779177 Vali Loss: 0.0927803 Test Loss: 0.1068341\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0787583\n",
      "\tspeed: 0.0412s/iter; left time: 648.6949s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751580\n",
      "\tspeed: 0.0200s/iter; left time: 312.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0778590 Vali Loss: 0.0923661 Test Loss: 0.1068291\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026821088045835495, rmse:0.16377145051956177, mae:0.10617007315158844, rse:0.5649650692939758\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2793686\n",
      "\tspeed: 0.0227s/iter; left time: 503.0000s\n",
      "\titers: 200, epoch: 1 | loss: 0.2693298\n",
      "\tspeed: 0.0200s/iter; left time: 442.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.2860429 Vali Loss: 0.2387114 Test Loss: 0.2581464\n",
      "Validation loss decreased (inf --> 0.238711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410758\n",
      "\tspeed: 0.0459s/iter; left time: 1009.8152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1199975\n",
      "\tspeed: 0.0201s/iter; left time: 438.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.1571827 Vali Loss: 0.1098685 Test Loss: 0.1288528\n",
      "Validation loss decreased (0.238711 --> 0.109869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1047048\n",
      "\tspeed: 0.0452s/iter; left time: 982.9029s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938154\n",
      "\tspeed: 0.0202s/iter; left time: 437.9363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.1013627 Vali Loss: 0.0964666 Test Loss: 0.1093780\n",
      "Validation loss decreased (0.109869 --> 0.096467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0908748\n",
      "\tspeed: 0.0439s/iter; left time: 944.8328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0965955\n",
      "\tspeed: 0.0202s/iter; left time: 433.7016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0905734 Vali Loss: 0.0966123 Test Loss: 0.1098793\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856086\n",
      "\tspeed: 0.0439s/iter; left time: 936.1312s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853570\n",
      "\tspeed: 0.0200s/iter; left time: 424.6745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0865073 Vali Loss: 0.0934426 Test Loss: 0.1061646\n",
      "Validation loss decreased (0.096467 --> 0.093443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0795323\n",
      "\tspeed: 0.0435s/iter; left time: 918.0179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0903210\n",
      "\tspeed: 0.0201s/iter; left time: 421.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0844781 Vali Loss: 0.0934596 Test Loss: 0.1064623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811414\n",
      "\tspeed: 0.0423s/iter; left time: 881.6132s\n",
      "\titers: 200, epoch: 7 | loss: 0.0801971\n",
      "\tspeed: 0.0230s/iter; left time: 477.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0836599 Vali Loss: 0.0939470 Test Loss: 0.1066778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0799184\n",
      "\tspeed: 0.0418s/iter; left time: 863.4843s\n",
      "\titers: 200, epoch: 8 | loss: 0.0786862\n",
      "\tspeed: 0.0200s/iter; left time: 410.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0826515 Vali Loss: 0.0929084 Test Loss: 0.1069776\n",
      "Validation loss decreased (0.093443 --> 0.092908).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797641\n",
      "\tspeed: 0.0438s/iter; left time: 893.8245s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805009\n",
      "\tspeed: 0.0202s/iter; left time: 411.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0819511 Vali Loss: 0.0927792 Test Loss: 0.1072595\n",
      "Validation loss decreased (0.092908 --> 0.092779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793059\n",
      "\tspeed: 0.0434s/iter; left time: 876.2095s\n",
      "\titers: 200, epoch: 10 | loss: 0.0776059\n",
      "\tspeed: 0.0202s/iter; left time: 405.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0813555 Vali Loss: 0.0931993 Test Loss: 0.1069561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0812942\n",
      "\tspeed: 0.0428s/iter; left time: 855.6571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0773368\n",
      "\tspeed: 0.0202s/iter; left time: 402.1161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0807996 Vali Loss: 0.0935010 Test Loss: 0.1081753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819042\n",
      "\tspeed: 0.0443s/iter; left time: 874.6247s\n",
      "\titers: 200, epoch: 12 | loss: 0.0891401\n",
      "\tspeed: 0.0202s/iter; left time: 397.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0802689 Vali Loss: 0.0921093 Test Loss: 0.1080482\n",
      "Validation loss decreased (0.092779 --> 0.092109).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825793\n",
      "\tspeed: 0.0439s/iter; left time: 857.5473s\n",
      "\titers: 200, epoch: 13 | loss: 0.0778091\n",
      "\tspeed: 0.0203s/iter; left time: 395.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0802096 Vali Loss: 0.0923726 Test Loss: 0.1076031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0799974\n",
      "\tspeed: 0.0435s/iter; left time: 840.0255s\n",
      "\titers: 200, epoch: 14 | loss: 0.0840938\n",
      "\tspeed: 0.0203s/iter; left time: 389.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0799977 Vali Loss: 0.0940052 Test Loss: 0.1118738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0742097\n",
      "\tspeed: 0.0454s/iter; left time: 866.0489s\n",
      "\titers: 200, epoch: 15 | loss: 0.0788889\n",
      "\tspeed: 0.0204s/iter; left time: 386.3508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0796003 Vali Loss: 0.0926683 Test Loss: 0.1094749\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0827809\n",
      "\tspeed: 0.0420s/iter; left time: 792.7826s\n",
      "\titers: 200, epoch: 16 | loss: 0.0761974\n",
      "\tspeed: 0.0200s/iter; left time: 374.2520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0792026 Vali Loss: 0.0926945 Test Loss: 0.1080312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776870\n",
      "\tspeed: 0.0433s/iter; left time: 807.6105s\n",
      "\titers: 200, epoch: 17 | loss: 0.0801408\n",
      "\tspeed: 0.0203s/iter; left time: 375.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0792390 Vali Loss: 0.0917448 Test Loss: 0.1088138\n",
      "Validation loss decreased (0.092109 --> 0.091745).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0825436\n",
      "\tspeed: 0.0459s/iter; left time: 844.3683s\n",
      "\titers: 200, epoch: 18 | loss: 0.0730348\n",
      "\tspeed: 0.0201s/iter; left time: 368.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0791526 Vali Loss: 0.0928045 Test Loss: 0.1083731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0804147\n",
      "\tspeed: 0.0435s/iter; left time: 790.5618s\n",
      "\titers: 200, epoch: 19 | loss: 0.0762362\n",
      "\tspeed: 0.0201s/iter; left time: 364.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0788301 Vali Loss: 0.0921725 Test Loss: 0.1092025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814857\n",
      "\tspeed: 0.0436s/iter; left time: 783.3200s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812849\n",
      "\tspeed: 0.0205s/iter; left time: 365.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0786442 Vali Loss: 0.0929008 Test Loss: 0.1094604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0769161\n",
      "\tspeed: 0.0452s/iter; left time: 801.8889s\n",
      "\titers: 200, epoch: 21 | loss: 0.0792939\n",
      "\tspeed: 0.0205s/iter; left time: 361.1183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0784565 Vali Loss: 0.0921167 Test Loss: 0.1095856\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779309\n",
      "\tspeed: 0.0434s/iter; left time: 760.5653s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750891\n",
      "\tspeed: 0.0203s/iter; left time: 352.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0784182 Vali Loss: 0.0918832 Test Loss: 0.1091213\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780503\n",
      "\tspeed: 0.0442s/iter; left time: 763.6470s\n",
      "\titers: 200, epoch: 23 | loss: 0.0786653\n",
      "\tspeed: 0.0201s/iter; left time: 346.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0784081 Vali Loss: 0.0925678 Test Loss: 0.1100193\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0802660\n",
      "\tspeed: 0.0421s/iter; left time: 718.2740s\n",
      "\titers: 200, epoch: 24 | loss: 0.0779760\n",
      "\tspeed: 0.0200s/iter; left time: 339.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0922913 Test Loss: 0.1099897\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0787994\n",
      "\tspeed: 0.0453s/iter; left time: 763.1095s\n",
      "\titers: 200, epoch: 25 | loss: 0.0808907\n",
      "\tspeed: 0.0205s/iter; left time: 342.9270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0781578 Vali Loss: 0.0923322 Test Loss: 0.1098471\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821575\n",
      "\tspeed: 0.0459s/iter; left time: 763.3554s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739094\n",
      "\tspeed: 0.0205s/iter; left time: 338.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0780644 Vali Loss: 0.0924523 Test Loss: 0.1103858\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0761999\n",
      "\tspeed: 0.0455s/iter; left time: 745.5856s\n",
      "\titers: 200, epoch: 27 | loss: 0.0786215\n",
      "\tspeed: 0.0233s/iter; left time: 379.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0780216 Vali Loss: 0.0919582 Test Loss: 0.1091315\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028750205412507057, rmse:0.16955885291099548, mae:0.10881377011537552, rse:0.5849299430847168\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:17.37s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2830859\n",
      "\tspeed: 0.0461s/iter; left time: 1018.0651s\n",
      "\titers: 200, epoch: 1 | loss: 0.2743740\n",
      "\tspeed: 0.0202s/iter; left time: 445.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.2865906 Vali Loss: 0.2415922 Test Loss: 0.2616447\n",
      "Validation loss decreased (inf --> 0.241592).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1478237\n",
      "\tspeed: 0.0427s/iter; left time: 935.1634s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268669\n",
      "\tspeed: 0.0204s/iter; left time: 443.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1614316 Vali Loss: 0.1285596 Test Loss: 0.1510565\n",
      "Validation loss decreased (0.241592 --> 0.128560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1189906\n",
      "\tspeed: 0.0427s/iter; left time: 924.6408s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098326\n",
      "\tspeed: 0.0204s/iter; left time: 439.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1174459 Vali Loss: 0.1205229 Test Loss: 0.1438784\n",
      "Validation loss decreased (0.128560 --> 0.120523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124115\n",
      "\tspeed: 0.0421s/iter; left time: 901.6909s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102599\n",
      "\tspeed: 0.0204s/iter; left time: 434.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.1116619 Vali Loss: 0.1212728 Test Loss: 0.1459699\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1115558\n",
      "\tspeed: 0.0415s/iter; left time: 880.4326s\n",
      "\titers: 200, epoch: 5 | loss: 0.1066562\n",
      "\tspeed: 0.0216s/iter; left time: 455.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1089256 Vali Loss: 0.1229624 Test Loss: 0.1504071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1053467\n",
      "\tspeed: 0.0420s/iter; left time: 881.3352s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036319\n",
      "\tspeed: 0.0204s/iter; left time: 426.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1072726 Vali Loss: 0.1256787 Test Loss: 0.1525851\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1046161\n",
      "\tspeed: 0.0415s/iter; left time: 862.0817s\n",
      "\titers: 200, epoch: 7 | loss: 0.1032366\n",
      "\tspeed: 0.0204s/iter; left time: 421.0916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1060321 Vali Loss: 0.1266989 Test Loss: 0.1591470\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1062903\n",
      "\tspeed: 0.0426s/iter; left time: 875.8304s\n",
      "\titers: 200, epoch: 8 | loss: 0.1077296\n",
      "\tspeed: 0.0204s/iter; left time: 416.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1051435 Vali Loss: 0.1254328 Test Loss: 0.1550419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043956\n",
      "\tspeed: 0.0414s/iter; left time: 842.1368s\n",
      "\titers: 200, epoch: 9 | loss: 0.1047444\n",
      "\tspeed: 0.0205s/iter; left time: 415.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1047975 Vali Loss: 0.1283385 Test Loss: 0.1620889\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1064517\n",
      "\tspeed: 0.0434s/iter; left time: 872.1729s\n",
      "\titers: 200, epoch: 10 | loss: 0.1051306\n",
      "\tspeed: 0.0229s/iter; left time: 458.4921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.1040109 Vali Loss: 0.1263400 Test Loss: 0.1575660\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1020149\n",
      "\tspeed: 0.0427s/iter; left time: 849.7358s\n",
      "\titers: 200, epoch: 11 | loss: 0.0961309\n",
      "\tspeed: 0.0204s/iter; left time: 402.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1033939 Vali Loss: 0.1245517 Test Loss: 0.1525567\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011116\n",
      "\tspeed: 0.0413s/iter; left time: 811.3142s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045583\n",
      "\tspeed: 0.0203s/iter; left time: 397.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1028317 Vali Loss: 0.1266475 Test Loss: 0.1584357\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0991534\n",
      "\tspeed: 0.0427s/iter; left time: 829.3094s\n",
      "\titers: 200, epoch: 13 | loss: 0.1028156\n",
      "\tspeed: 0.0210s/iter; left time: 406.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1026982 Vali Loss: 0.1249986 Test Loss: 0.1543648\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04194752871990204, rmse:0.2048109620809555, mae:0.14387835562229156, rse:0.7082648277282715\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2857521\n",
      "\tspeed: 0.0237s/iter; left time: 524.7916s\n",
      "\titers: 200, epoch: 1 | loss: 0.2757615\n",
      "\tspeed: 0.0203s/iter; left time: 447.6650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.2916806 Vali Loss: 0.2445744 Test Loss: 0.2660964\n",
      "Validation loss decreased (inf --> 0.244574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426474\n",
      "\tspeed: 0.0445s/iter; left time: 974.5089s\n",
      "\titers: 200, epoch: 2 | loss: 0.1280049\n",
      "\tspeed: 0.0228s/iter; left time: 496.6771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.1630443 Vali Loss: 0.1273275 Test Loss: 0.1519118\n",
      "Validation loss decreased (0.244574 --> 0.127328).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1187076\n",
      "\tspeed: 0.0499s/iter; left time: 1081.3853s\n",
      "\titers: 200, epoch: 3 | loss: 0.1128903\n",
      "\tspeed: 0.0224s/iter; left time: 483.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1179070 Vali Loss: 0.1216799 Test Loss: 0.1441890\n",
      "Validation loss decreased (0.127328 --> 0.121680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1176371\n",
      "\tspeed: 0.0435s/iter; left time: 932.4660s\n",
      "\titers: 200, epoch: 4 | loss: 0.1096063\n",
      "\tspeed: 0.0203s/iter; left time: 433.0545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1111886 Vali Loss: 0.1207477 Test Loss: 0.1466962\n",
      "Validation loss decreased (0.121680 --> 0.120748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166723\n",
      "\tspeed: 0.0448s/iter; left time: 949.6646s\n",
      "\titers: 200, epoch: 5 | loss: 0.1139806\n",
      "\tspeed: 0.0231s/iter; left time: 488.6616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.1086714 Vali Loss: 0.1235578 Test Loss: 0.1564359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026459\n",
      "\tspeed: 0.0436s/iter; left time: 916.1302s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138240\n",
      "\tspeed: 0.0205s/iter; left time: 428.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1069735 Vali Loss: 0.1237044 Test Loss: 0.1564380\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1069064\n",
      "\tspeed: 0.0432s/iter; left time: 897.7734s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059684\n",
      "\tspeed: 0.0205s/iter; left time: 424.1536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1059816 Vali Loss: 0.1225111 Test Loss: 0.1536749\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1027634\n",
      "\tspeed: 0.0435s/iter; left time: 893.6748s\n",
      "\titers: 200, epoch: 8 | loss: 0.1018030\n",
      "\tspeed: 0.0204s/iter; left time: 416.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1056321 Vali Loss: 0.1218389 Test Loss: 0.1519313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063525\n",
      "\tspeed: 0.0456s/iter; left time: 927.6932s\n",
      "\titers: 200, epoch: 9 | loss: 0.1072328\n",
      "\tspeed: 0.0205s/iter; left time: 413.7059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.1047135 Vali Loss: 0.1208165 Test Loss: 0.1489650\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0998539\n",
      "\tspeed: 0.0445s/iter; left time: 894.6796s\n",
      "\titers: 200, epoch: 10 | loss: 0.1041441\n",
      "\tspeed: 0.0236s/iter; left time: 471.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.1039581 Vali Loss: 0.1213863 Test Loss: 0.1500021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1029014\n",
      "\tspeed: 0.0450s/iter; left time: 894.5403s\n",
      "\titers: 200, epoch: 11 | loss: 0.1065745\n",
      "\tspeed: 0.0204s/iter; left time: 403.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1035431 Vali Loss: 0.1209281 Test Loss: 0.1487738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1033012\n",
      "\tspeed: 0.0436s/iter; left time: 856.1577s\n",
      "\titers: 200, epoch: 12 | loss: 0.1080546\n",
      "\tspeed: 0.0225s/iter; left time: 440.7402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1033090 Vali Loss: 0.1216931 Test Loss: 0.1507952\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1062972\n",
      "\tspeed: 0.0433s/iter; left time: 841.9308s\n",
      "\titers: 200, epoch: 13 | loss: 0.1032194\n",
      "\tspeed: 0.0204s/iter; left time: 395.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1027705 Vali Loss: 0.1215444 Test Loss: 0.1481337\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1045286\n",
      "\tspeed: 0.0426s/iter; left time: 819.2387s\n",
      "\titers: 200, epoch: 14 | loss: 0.1021893\n",
      "\tspeed: 0.0204s/iter; left time: 389.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1025529 Vali Loss: 0.1212421 Test Loss: 0.1494780\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04693262279033661, rmse:0.21663938462734222, mae:0.14669613540172577, rse:0.7491691708564758\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:07.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2847386\n",
      "\tspeed: 0.0495s/iter; left time: 1093.3159s\n",
      "\titers: 200, epoch: 1 | loss: 0.2732988\n",
      "\tspeed: 0.0208s/iter; left time: 457.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.2875838 Vali Loss: 0.2422487 Test Loss: 0.2623464\n",
      "Validation loss decreased (inf --> 0.242249).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1490528\n",
      "\tspeed: 0.0459s/iter; left time: 1004.9024s\n",
      "\titers: 200, epoch: 2 | loss: 0.1271268\n",
      "\tspeed: 0.0209s/iter; left time: 456.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1616939 Vali Loss: 0.1300322 Test Loss: 0.1555596\n",
      "Validation loss decreased (0.242249 --> 0.130032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1159026\n",
      "\tspeed: 0.0456s/iter; left time: 988.0824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142748\n",
      "\tspeed: 0.0206s/iter; left time: 444.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1201043 Vali Loss: 0.1246263 Test Loss: 0.1511487\n",
      "Validation loss decreased (0.130032 --> 0.124626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1161936\n",
      "\tspeed: 0.0473s/iter; left time: 1012.9549s\n",
      "\titers: 200, epoch: 4 | loss: 0.1142678\n",
      "\tspeed: 0.0215s/iter; left time: 459.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 222 | Train Loss: 0.1146955 Vali Loss: 0.1259331 Test Loss: 0.1559995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156335\n",
      "\tspeed: 0.0449s/iter; left time: 951.6998s\n",
      "\titers: 200, epoch: 5 | loss: 0.1136656\n",
      "\tspeed: 0.0205s/iter; left time: 433.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1125922 Vali Loss: 0.1289697 Test Loss: 0.1656465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1125581\n",
      "\tspeed: 0.0443s/iter; left time: 930.1783s\n",
      "\titers: 200, epoch: 6 | loss: 0.1118595\n",
      "\tspeed: 0.0206s/iter; left time: 430.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1109664 Vali Loss: 0.1305788 Test Loss: 0.1679211\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1114427\n",
      "\tspeed: 0.0441s/iter; left time: 916.2295s\n",
      "\titers: 200, epoch: 7 | loss: 0.1108004\n",
      "\tspeed: 0.0218s/iter; left time: 451.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.1101296 Vali Loss: 0.1268001 Test Loss: 0.1582920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1117834\n",
      "\tspeed: 0.0433s/iter; left time: 889.4084s\n",
      "\titers: 200, epoch: 8 | loss: 0.1109027\n",
      "\tspeed: 0.0207s/iter; left time: 423.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1092303 Vali Loss: 0.1320953 Test Loss: 0.1703052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1069235\n",
      "\tspeed: 0.0432s/iter; left time: 878.4281s\n",
      "\titers: 200, epoch: 9 | loss: 0.1065887\n",
      "\tspeed: 0.0210s/iter; left time: 425.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1085968 Vali Loss: 0.1300069 Test Loss: 0.1626084\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1086212\n",
      "\tspeed: 0.0438s/iter; left time: 879.5187s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030650\n",
      "\tspeed: 0.0206s/iter; left time: 411.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1079234 Vali Loss: 0.1297312 Test Loss: 0.1594644\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1081972\n",
      "\tspeed: 0.0439s/iter; left time: 871.9717s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104306\n",
      "\tspeed: 0.0206s/iter; left time: 406.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1075208 Vali Loss: 0.1284075 Test Loss: 0.1579085\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1100941\n",
      "\tspeed: 0.0457s/iter; left time: 899.1604s\n",
      "\titers: 200, epoch: 12 | loss: 0.1078582\n",
      "\tspeed: 0.0207s/iter; left time: 405.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1069388 Vali Loss: 0.1275865 Test Loss: 0.1551821\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1002419\n",
      "\tspeed: 0.0439s/iter; left time: 853.1455s\n",
      "\titers: 200, epoch: 13 | loss: 0.1029617\n",
      "\tspeed: 0.0216s/iter; left time: 418.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.1065173 Vali Loss: 0.1302151 Test Loss: 0.1581639\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04640279710292816, rmse:0.21541307866573334, mae:0.15114876627922058, rse:0.7468680739402771\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2827889\n",
      "\tspeed: 0.0233s/iter; left time: 515.2525s\n",
      "\titers: 200, epoch: 1 | loss: 0.2717319\n",
      "\tspeed: 0.0206s/iter; left time: 453.0439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.2875044 Vali Loss: 0.2468908 Test Loss: 0.2667910\n",
      "Validation loss decreased (inf --> 0.246891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483081\n",
      "\tspeed: 0.0484s/iter; left time: 1059.4323s\n",
      "\titers: 200, epoch: 2 | loss: 0.1301151\n",
      "\tspeed: 0.0225s/iter; left time: 490.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 222 | Train Loss: 0.1614167 Vali Loss: 0.1320312 Test Loss: 0.1557729\n",
      "Validation loss decreased (0.246891 --> 0.132031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1208680\n",
      "\tspeed: 0.0511s/iter; left time: 1105.9588s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123617\n",
      "\tspeed: 0.0209s/iter; left time: 449.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.1204286 Vali Loss: 0.1251208 Test Loss: 0.1511288\n",
      "Validation loss decreased (0.132031 --> 0.125121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124564\n",
      "\tspeed: 0.0467s/iter; left time: 1000.4376s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097842\n",
      "\tspeed: 0.0205s/iter; left time: 436.9314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1146207 Vali Loss: 0.1287144 Test Loss: 0.1621836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1086292\n",
      "\tspeed: 0.0454s/iter; left time: 963.6879s\n",
      "\titers: 200, epoch: 5 | loss: 0.1128315\n",
      "\tspeed: 0.0205s/iter; left time: 433.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1123435 Vali Loss: 0.1277754 Test Loss: 0.1615553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128400\n",
      "\tspeed: 0.0453s/iter; left time: 951.5354s\n",
      "\titers: 200, epoch: 6 | loss: 0.1101898\n",
      "\tspeed: 0.0206s/iter; left time: 430.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1108323 Vali Loss: 0.1293614 Test Loss: 0.1619483\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1088920\n",
      "\tspeed: 0.0444s/iter; left time: 922.0280s\n",
      "\titers: 200, epoch: 7 | loss: 0.1099801\n",
      "\tspeed: 0.0205s/iter; left time: 423.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1101685 Vali Loss: 0.1274933 Test Loss: 0.1573811\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1096876\n",
      "\tspeed: 0.0447s/iter; left time: 918.2042s\n",
      "\titers: 200, epoch: 8 | loss: 0.1091753\n",
      "\tspeed: 0.0246s/iter; left time: 503.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.1093744 Vali Loss: 0.1286852 Test Loss: 0.1589296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1071864\n",
      "\tspeed: 0.0471s/iter; left time: 957.2928s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103567\n",
      "\tspeed: 0.0216s/iter; left time: 437.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 222 | Train Loss: 0.1089083 Vali Loss: 0.1305566 Test Loss: 0.1642011\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1032997\n",
      "\tspeed: 0.0459s/iter; left time: 923.6998s\n",
      "\titers: 200, epoch: 10 | loss: 0.1062638\n",
      "\tspeed: 0.0204s/iter; left time: 408.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1078734 Vali Loss: 0.1292104 Test Loss: 0.1591856\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1080145\n",
      "\tspeed: 0.0476s/iter; left time: 946.9651s\n",
      "\titers: 200, epoch: 11 | loss: 0.1034257\n",
      "\tspeed: 0.0207s/iter; left time: 410.0584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.1075698 Vali Loss: 0.1302238 Test Loss: 0.1593552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1071013\n",
      "\tspeed: 0.0485s/iter; left time: 952.6406s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045469\n",
      "\tspeed: 0.0220s/iter; left time: 429.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 222 | Train Loss: 0.1070806 Vali Loss: 0.1295131 Test Loss: 0.1613695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1073833\n",
      "\tspeed: 0.0504s/iter; left time: 980.1201s\n",
      "\titers: 200, epoch: 13 | loss: 0.1102557\n",
      "\tspeed: 0.0209s/iter; left time: 403.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.1067905 Vali Loss: 0.1295707 Test Loss: 0.1595024\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04654495418071747, rmse:0.2157427966594696, mae:0.15112879872322083, rse:0.7480112910270691\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:09.89s\n",
      "Intermediate time for GB: 00h:12m:34.37s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2734229\n",
      "\tspeed: 0.0412s/iter; left time: 915.1822s\n",
      "\titers: 200, epoch: 1 | loss: 0.2591398\n",
      "\tspeed: 0.0135s/iter; left time: 297.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.2797764 Vali Loss: 0.2077011 Test Loss: 0.2316831\n",
      "Validation loss decreased (inf --> 0.207701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501102\n",
      "\tspeed: 0.0360s/iter; left time: 791.6209s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156371\n",
      "\tspeed: 0.0177s/iter; left time: 386.7437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.1579866 Vali Loss: 0.0862343 Test Loss: 0.0958197\n",
      "Validation loss decreased (0.207701 --> 0.086234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1001764\n",
      "\tspeed: 0.0358s/iter; left time: 777.9672s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914646\n",
      "\tspeed: 0.0163s/iter; left time: 353.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0996259 Vali Loss: 0.0773804 Test Loss: 0.0889997\n",
      "Validation loss decreased (0.086234 --> 0.077380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0825320\n",
      "\tspeed: 0.0353s/iter; left time: 759.1844s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785926\n",
      "\tspeed: 0.0158s/iter; left time: 338.0004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0848808 Vali Loss: 0.0700407 Test Loss: 0.0814023\n",
      "Validation loss decreased (0.077380 --> 0.070041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759574\n",
      "\tspeed: 0.0346s/iter; left time: 737.1928s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730125\n",
      "\tspeed: 0.0182s/iter; left time: 386.5762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0764828 Vali Loss: 0.0672355 Test Loss: 0.0818017\n",
      "Validation loss decreased (0.070041 --> 0.067236).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0721011\n",
      "\tspeed: 0.0355s/iter; left time: 748.5467s\n",
      "\titers: 200, epoch: 6 | loss: 0.0727575\n",
      "\tspeed: 0.0175s/iter; left time: 366.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0723590 Vali Loss: 0.0652889 Test Loss: 0.0797523\n",
      "Validation loss decreased (0.067236 --> 0.065289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0692551\n",
      "\tspeed: 0.0380s/iter; left time: 792.7467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711924\n",
      "\tspeed: 0.0189s/iter; left time: 392.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0708371 Vali Loss: 0.0639640 Test Loss: 0.0786748\n",
      "Validation loss decreased (0.065289 --> 0.063964).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0698496\n",
      "\tspeed: 0.0374s/iter; left time: 771.7648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680445\n",
      "\tspeed: 0.0156s/iter; left time: 320.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0689431 Vali Loss: 0.0626610 Test Loss: 0.0816812\n",
      "Validation loss decreased (0.063964 --> 0.062661).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672548\n",
      "\tspeed: 0.0355s/iter; left time: 724.3456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681350\n",
      "\tspeed: 0.0188s/iter; left time: 382.0022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0672450 Vali Loss: 0.0624299 Test Loss: 0.0814141\n",
      "Validation loss decreased (0.062661 --> 0.062430).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0663894\n",
      "\tspeed: 0.0404s/iter; left time: 816.3157s\n",
      "\titers: 200, epoch: 10 | loss: 0.0668906\n",
      "\tspeed: 0.0233s/iter; left time: 467.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0666955 Vali Loss: 0.0616107 Test Loss: 0.0823262\n",
      "Validation loss decreased (0.062430 --> 0.061611).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0638787\n",
      "\tspeed: 0.0404s/iter; left time: 807.6937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0628497\n",
      "\tspeed: 0.0201s/iter; left time: 400.2705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0660342 Vali Loss: 0.0623551 Test Loss: 0.0771238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0637039\n",
      "\tspeed: 0.0376s/iter; left time: 742.5367s\n",
      "\titers: 200, epoch: 12 | loss: 0.0641958\n",
      "\tspeed: 0.0177s/iter; left time: 346.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0653721 Vali Loss: 0.0610190 Test Loss: 0.0782874\n",
      "Validation loss decreased (0.061611 --> 0.061019).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646565\n",
      "\tspeed: 0.0364s/iter; left time: 711.3248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586972\n",
      "\tspeed: 0.0186s/iter; left time: 361.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0643298 Vali Loss: 0.0609863 Test Loss: 0.0768389\n",
      "Validation loss decreased (0.061019 --> 0.060986).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0663159\n",
      "\tspeed: 0.0392s/iter; left time: 755.6923s\n",
      "\titers: 200, epoch: 14 | loss: 0.0670872\n",
      "\tspeed: 0.0183s/iter; left time: 350.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0644528 Vali Loss: 0.0608356 Test Loss: 0.0754247\n",
      "Validation loss decreased (0.060986 --> 0.060836).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638315\n",
      "\tspeed: 0.0332s/iter; left time: 632.5133s\n",
      "\titers: 200, epoch: 15 | loss: 0.0577864\n",
      "\tspeed: 0.0135s/iter; left time: 256.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 223 | Train Loss: 0.0638601 Vali Loss: 0.0599702 Test Loss: 0.0777668\n",
      "Validation loss decreased (0.060836 --> 0.059970).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0630899\n",
      "\tspeed: 0.0343s/iter; left time: 646.0438s\n",
      "\titers: 200, epoch: 16 | loss: 0.0636763\n",
      "\tspeed: 0.0178s/iter; left time: 334.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0635268 Vali Loss: 0.0602922 Test Loss: 0.0782625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0641218\n",
      "\tspeed: 0.0379s/iter; left time: 706.4753s\n",
      "\titers: 200, epoch: 17 | loss: 0.0639976\n",
      "\tspeed: 0.0185s/iter; left time: 342.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0630966 Vali Loss: 0.0598330 Test Loss: 0.0770544\n",
      "Validation loss decreased (0.059970 --> 0.059833).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0695380\n",
      "\tspeed: 0.0372s/iter; left time: 684.8273s\n",
      "\titers: 200, epoch: 18 | loss: 0.0604190\n",
      "\tspeed: 0.0165s/iter; left time: 302.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0627721 Vali Loss: 0.0599829 Test Loss: 0.0771877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676237\n",
      "\tspeed: 0.0352s/iter; left time: 640.9198s\n",
      "\titers: 200, epoch: 19 | loss: 0.0617841\n",
      "\tspeed: 0.0151s/iter; left time: 272.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0624605 Vali Loss: 0.0592976 Test Loss: 0.0751091\n",
      "Validation loss decreased (0.059833 --> 0.059298).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0599678\n",
      "\tspeed: 0.0357s/iter; left time: 640.4573s\n",
      "\titers: 200, epoch: 20 | loss: 0.0608872\n",
      "\tspeed: 0.0174s/iter; left time: 310.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0624633 Vali Loss: 0.0594797 Test Loss: 0.0742862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0636331\n",
      "\tspeed: 0.0360s/iter; left time: 638.2627s\n",
      "\titers: 200, epoch: 21 | loss: 0.0605511\n",
      "\tspeed: 0.0175s/iter; left time: 308.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0621196 Vali Loss: 0.0590982 Test Loss: 0.0735378\n",
      "Validation loss decreased (0.059298 --> 0.059098).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0681865\n",
      "\tspeed: 0.0343s/iter; left time: 601.1297s\n",
      "\titers: 200, epoch: 22 | loss: 0.0630321\n",
      "\tspeed: 0.0178s/iter; left time: 310.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0619806 Vali Loss: 0.0591053 Test Loss: 0.0748091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618666\n",
      "\tspeed: 0.0402s/iter; left time: 694.7574s\n",
      "\titers: 200, epoch: 23 | loss: 0.0637027\n",
      "\tspeed: 0.0232s/iter; left time: 398.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0616507 Vali Loss: 0.0588343 Test Loss: 0.0745264\n",
      "Validation loss decreased (0.059098 --> 0.058834).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621395\n",
      "\tspeed: 0.0392s/iter; left time: 669.7631s\n",
      "\titers: 200, epoch: 24 | loss: 0.0605529\n",
      "\tspeed: 0.0176s/iter; left time: 297.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0617294 Vali Loss: 0.0591653 Test Loss: 0.0739306\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0642471\n",
      "\tspeed: 0.0352s/iter; left time: 593.3458s\n",
      "\titers: 200, epoch: 25 | loss: 0.0604569\n",
      "\tspeed: 0.0198s/iter; left time: 331.9531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0615576 Vali Loss: 0.0589806 Test Loss: 0.0727910\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0616106\n",
      "\tspeed: 0.0415s/iter; left time: 689.2845s\n",
      "\titers: 200, epoch: 26 | loss: 0.0597703\n",
      "\tspeed: 0.0231s/iter; left time: 380.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0620085 Vali Loss: 0.0588338 Test Loss: 0.0719916\n",
      "Validation loss decreased (0.058834 --> 0.058834).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0596189\n",
      "\tspeed: 0.0401s/iter; left time: 657.5962s\n",
      "\titers: 200, epoch: 27 | loss: 0.0635520\n",
      "\tspeed: 0.0214s/iter; left time: 348.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0612380 Vali Loss: 0.0586246 Test Loss: 0.0727618\n",
      "Validation loss decreased (0.058834 --> 0.058625).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0588917\n",
      "\tspeed: 0.0348s/iter; left time: 563.6073s\n",
      "\titers: 200, epoch: 28 | loss: 0.0635731\n",
      "\tspeed: 0.0191s/iter; left time: 306.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0611303 Vali Loss: 0.0587932 Test Loss: 0.0731516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625889\n",
      "\tspeed: 0.0382s/iter; left time: 608.8753s\n",
      "\titers: 200, epoch: 29 | loss: 0.0612762\n",
      "\tspeed: 0.0186s/iter; left time: 294.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0612841 Vali Loss: 0.0586699 Test Loss: 0.0720458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0627371\n",
      "\tspeed: 0.0365s/iter; left time: 574.2597s\n",
      "\titers: 200, epoch: 30 | loss: 0.0609327\n",
      "\tspeed: 0.0172s/iter; left time: 268.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0611244 Vali Loss: 0.0587655 Test Loss: 0.0722661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0626832\n",
      "\tspeed: 0.0373s/iter; left time: 577.8201s\n",
      "\titers: 200, epoch: 31 | loss: 0.0611782\n",
      "\tspeed: 0.0205s/iter; left time: 316.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0608637 Vali Loss: 0.0585725 Test Loss: 0.0721224\n",
      "Validation loss decreased (0.058625 --> 0.058573).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0591056\n",
      "\tspeed: 0.0420s/iter; left time: 642.3836s\n",
      "\titers: 200, epoch: 32 | loss: 0.0608703\n",
      "\tspeed: 0.0189s/iter; left time: 287.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0611035 Vali Loss: 0.0585316 Test Loss: 0.0720294\n",
      "Validation loss decreased (0.058573 --> 0.058532).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0627462\n",
      "\tspeed: 0.0351s/iter; left time: 529.1923s\n",
      "\titers: 200, epoch: 33 | loss: 0.0638220\n",
      "\tspeed: 0.0168s/iter; left time: 251.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0609369 Vali Loss: 0.0589222 Test Loss: 0.0714391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0611427\n",
      "\tspeed: 0.0357s/iter; left time: 530.0501s\n",
      "\titers: 200, epoch: 34 | loss: 0.0592877\n",
      "\tspeed: 0.0178s/iter; left time: 261.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0609008 Vali Loss: 0.0587073 Test Loss: 0.0718306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0647226\n",
      "\tspeed: 0.0358s/iter; left time: 523.1411s\n",
      "\titers: 200, epoch: 35 | loss: 0.0613430\n",
      "\tspeed: 0.0172s/iter; left time: 249.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0610456 Vali Loss: 0.0587233 Test Loss: 0.0709572\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610038\n",
      "\tspeed: 0.0347s/iter; left time: 499.1304s\n",
      "\titers: 200, epoch: 36 | loss: 0.0639765\n",
      "\tspeed: 0.0179s/iter; left time: 255.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0608291 Vali Loss: 0.0585552 Test Loss: 0.0723657\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628329\n",
      "\tspeed: 0.0353s/iter; left time: 500.9689s\n",
      "\titers: 200, epoch: 37 | loss: 0.0624324\n",
      "\tspeed: 0.0186s/iter; left time: 262.1521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0609406 Vali Loss: 0.0585783 Test Loss: 0.0719445\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0570951\n",
      "\tspeed: 0.0382s/iter; left time: 533.2406s\n",
      "\titers: 200, epoch: 38 | loss: 0.0635981\n",
      "\tspeed: 0.0194s/iter; left time: 268.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0608932 Vali Loss: 0.0582021 Test Loss: 0.0709829\n",
      "Validation loss decreased (0.058532 --> 0.058202).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0648834\n",
      "\tspeed: 0.0363s/iter; left time: 498.8376s\n",
      "\titers: 200, epoch: 39 | loss: 0.0634245\n",
      "\tspeed: 0.0177s/iter; left time: 241.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0607717 Vali Loss: 0.0584518 Test Loss: 0.0719673\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0667321\n",
      "\tspeed: 0.0357s/iter; left time: 481.7794s\n",
      "\titers: 200, epoch: 40 | loss: 0.0605432\n",
      "\tspeed: 0.0175s/iter; left time: 233.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0606790 Vali Loss: 0.0582629 Test Loss: 0.0711489\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0607338\n",
      "\tspeed: 0.0309s/iter; left time: 410.1472s\n",
      "\titers: 200, epoch: 41 | loss: 0.0625932\n",
      "\tspeed: 0.0133s/iter; left time: 174.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 223 | Train Loss: 0.0607329 Vali Loss: 0.0583876 Test Loss: 0.0709399\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0610299\n",
      "\tspeed: 0.0408s/iter; left time: 533.0227s\n",
      "\titers: 200, epoch: 42 | loss: 0.0592471\n",
      "\tspeed: 0.0194s/iter; left time: 250.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0605536 Vali Loss: 0.0584407 Test Loss: 0.0717083\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0613073\n",
      "\tspeed: 0.0406s/iter; left time: 520.8543s\n",
      "\titers: 200, epoch: 43 | loss: 0.0620735\n",
      "\tspeed: 0.0203s/iter; left time: 258.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0605541 Vali Loss: 0.0583683 Test Loss: 0.0715528\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0572556\n",
      "\tspeed: 0.0395s/iter; left time: 497.9866s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614139\n",
      "\tspeed: 0.0204s/iter; left time: 255.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0606213 Vali Loss: 0.0583518 Test Loss: 0.0715966\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0610600\n",
      "\tspeed: 0.0355s/iter; left time: 439.2695s\n",
      "\titers: 200, epoch: 45 | loss: 0.0638830\n",
      "\tspeed: 0.0232s/iter; left time: 284.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0606214 Vali Loss: 0.0583446 Test Loss: 0.0709620\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0632091\n",
      "\tspeed: 0.0359s/iter; left time: 436.2607s\n",
      "\titers: 200, epoch: 46 | loss: 0.0578360\n",
      "\tspeed: 0.0164s/iter; left time: 198.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0606273 Vali Loss: 0.0582291 Test Loss: 0.0716396\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0647540\n",
      "\tspeed: 0.0370s/iter; left time: 441.9253s\n",
      "\titers: 200, epoch: 47 | loss: 0.0604675\n",
      "\tspeed: 0.0178s/iter; left time: 210.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0607377 Vali Loss: 0.0581766 Test Loss: 0.0712587\n",
      "Validation loss decreased (0.058202 --> 0.058177).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0603332\n",
      "\tspeed: 0.0421s/iter; left time: 493.4049s\n",
      "\titers: 200, epoch: 48 | loss: 0.0626702\n",
      "\tspeed: 0.0161s/iter; left time: 186.7659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0606299 Vali Loss: 0.0583450 Test Loss: 0.0713740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0630806\n",
      "\tspeed: 0.0362s/iter; left time: 415.7025s\n",
      "\titers: 200, epoch: 49 | loss: 0.0596555\n",
      "\tspeed: 0.0185s/iter; left time: 210.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0604360 Vali Loss: 0.0584677 Test Loss: 0.0718548\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0638820\n",
      "\tspeed: 0.0363s/iter; left time: 409.0885s\n",
      "\titers: 200, epoch: 50 | loss: 0.0623280\n",
      "\tspeed: 0.0171s/iter; left time: 191.5678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0607593 Vali Loss: 0.0585534 Test Loss: 0.0712420\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0583699\n",
      "\tspeed: 0.0358s/iter; left time: 395.7284s\n",
      "\titers: 200, epoch: 51 | loss: 0.0574530\n",
      "\tspeed: 0.0170s/iter; left time: 186.7099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0605747 Vali Loss: 0.0583292 Test Loss: 0.0713487\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0591375\n",
      "\tspeed: 0.0387s/iter; left time: 419.1905s\n",
      "\titers: 200, epoch: 52 | loss: 0.0602642\n",
      "\tspeed: 0.0172s/iter; left time: 184.3612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0605271 Vali Loss: 0.0583008 Test Loss: 0.0709413\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0602914\n",
      "\tspeed: 0.0338s/iter; left time: 358.4478s\n",
      "\titers: 200, epoch: 53 | loss: 0.0605704\n",
      "\tspeed: 0.0132s/iter; left time: 138.6052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 223 | Train Loss: 0.0605934 Vali Loss: 0.0583363 Test Loss: 0.0710621\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0597997\n",
      "\tspeed: 0.0345s/iter; left time: 358.4977s\n",
      "\titers: 200, epoch: 54 | loss: 0.0601996\n",
      "\tspeed: 0.0134s/iter; left time: 137.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0604698 Vali Loss: 0.0581101 Test Loss: 0.0708624\n",
      "Validation loss decreased (0.058177 --> 0.058110).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0588478\n",
      "\tspeed: 0.0370s/iter; left time: 375.8495s\n",
      "\titers: 200, epoch: 55 | loss: 0.0611312\n",
      "\tspeed: 0.0181s/iter; left time: 182.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0606346 Vali Loss: 0.0584171 Test Loss: 0.0711248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0626345\n",
      "\tspeed: 0.0390s/iter; left time: 387.7881s\n",
      "\titers: 200, epoch: 56 | loss: 0.0593741\n",
      "\tspeed: 0.0204s/iter; left time: 200.5963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0606858 Vali Loss: 0.0582332 Test Loss: 0.0709630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0606673\n",
      "\tspeed: 0.0393s/iter; left time: 381.5303s\n",
      "\titers: 200, epoch: 57 | loss: 0.0603442\n",
      "\tspeed: 0.0212s/iter; left time: 203.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0604547 Vali Loss: 0.0585694 Test Loss: 0.0713051\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0621592\n",
      "\tspeed: 0.0389s/iter; left time: 369.4547s\n",
      "\titers: 200, epoch: 58 | loss: 0.0647210\n",
      "\tspeed: 0.0174s/iter; left time: 163.6315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0605014 Vali Loss: 0.0583662 Test Loss: 0.0710849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0604595\n",
      "\tspeed: 0.0354s/iter; left time: 327.6770s\n",
      "\titers: 200, epoch: 59 | loss: 0.0580812\n",
      "\tspeed: 0.0168s/iter; left time: 154.3800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0605654 Vali Loss: 0.0582231 Test Loss: 0.0715041\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0636667\n",
      "\tspeed: 0.0355s/iter; left time: 320.7019s\n",
      "\titers: 200, epoch: 60 | loss: 0.0592665\n",
      "\tspeed: 0.0173s/iter; left time: 154.5496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0604897 Vali Loss: 0.0582843 Test Loss: 0.0711999\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0601453\n",
      "\tspeed: 0.0382s/iter; left time: 336.8420s\n",
      "\titers: 200, epoch: 61 | loss: 0.0581520\n",
      "\tspeed: 0.0201s/iter; left time: 175.2035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0605203 Vali Loss: 0.0583585 Test Loss: 0.0720579\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0599685\n",
      "\tspeed: 0.0379s/iter; left time: 325.9290s\n",
      "\titers: 200, epoch: 62 | loss: 0.0612502\n",
      "\tspeed: 0.0178s/iter; left time: 151.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0604107 Vali Loss: 0.0580978 Test Loss: 0.0713375\n",
      "Validation loss decreased (0.058110 --> 0.058098).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0600454\n",
      "\tspeed: 0.0385s/iter; left time: 322.4052s\n",
      "\titers: 200, epoch: 63 | loss: 0.0610860\n",
      "\tspeed: 0.0222s/iter; left time: 183.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0603876 Vali Loss: 0.0581605 Test Loss: 0.0709788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0585512\n",
      "\tspeed: 0.0369s/iter; left time: 300.5606s\n",
      "\titers: 200, epoch: 64 | loss: 0.0573843\n",
      "\tspeed: 0.0175s/iter; left time: 140.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0606150 Vali Loss: 0.0581815 Test Loss: 0.0715361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0555013\n",
      "\tspeed: 0.0427s/iter; left time: 338.7843s\n",
      "\titers: 200, epoch: 65 | loss: 0.0608431\n",
      "\tspeed: 0.0193s/iter; left time: 150.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0603913 Vali Loss: 0.0581201 Test Loss: 0.0710223\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0624073\n",
      "\tspeed: 0.0410s/iter; left time: 315.7987s\n",
      "\titers: 200, epoch: 66 | loss: 0.0613218\n",
      "\tspeed: 0.0189s/iter; left time: 143.9260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0604806 Vali Loss: 0.0582048 Test Loss: 0.0712893\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0566933\n",
      "\tspeed: 0.0332s/iter; left time: 248.2611s\n",
      "\titers: 200, epoch: 67 | loss: 0.0575886\n",
      "\tspeed: 0.0197s/iter; left time: 145.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0604509 Vali Loss: 0.0582309 Test Loss: 0.0714317\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0561184\n",
      "\tspeed: 0.0386s/iter; left time: 280.1489s\n",
      "\titers: 200, epoch: 68 | loss: 0.0544464\n",
      "\tspeed: 0.0175s/iter; left time: 125.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0604748 Vali Loss: 0.0583191 Test Loss: 0.0714386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0618815\n",
      "\tspeed: 0.0363s/iter; left time: 255.6443s\n",
      "\titers: 200, epoch: 69 | loss: 0.0603830\n",
      "\tspeed: 0.0170s/iter; left time: 118.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0604967 Vali Loss: 0.0584250 Test Loss: 0.0712096\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0605376\n",
      "\tspeed: 0.0375s/iter; left time: 255.4280s\n",
      "\titers: 200, epoch: 70 | loss: 0.0598305\n",
      "\tspeed: 0.0174s/iter; left time: 116.7765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0603894 Vali Loss: 0.0581378 Test Loss: 0.0708586\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0592535\n",
      "\tspeed: 0.0411s/iter; left time: 270.9040s\n",
      "\titers: 200, epoch: 71 | loss: 0.0590382\n",
      "\tspeed: 0.0200s/iter; left time: 129.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0604078 Vali Loss: 0.0583088 Test Loss: 0.0717112\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0595916\n",
      "\tspeed: 0.0368s/iter; left time: 234.4311s\n",
      "\titers: 200, epoch: 72 | loss: 0.0579982\n",
      "\tspeed: 0.0203s/iter; left time: 127.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0604241 Vali Loss: 0.0583643 Test Loss: 0.0725297\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012035089544951916, rmse:0.10970455408096313, mae:0.07133753597736359, rse:0.32284724712371826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2803350\n",
      "\tspeed: 0.0219s/iter; left time: 486.8568s\n",
      "\titers: 200, epoch: 1 | loss: 0.2575611\n",
      "\tspeed: 0.0201s/iter; left time: 444.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.2803172 Vali Loss: 0.2082613 Test Loss: 0.2316559\n",
      "Validation loss decreased (inf --> 0.208261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483288\n",
      "\tspeed: 0.0411s/iter; left time: 902.3950s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121401\n",
      "\tspeed: 0.0206s/iter; left time: 451.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.1565978 Vali Loss: 0.0902821 Test Loss: 0.0989393\n",
      "Validation loss decreased (0.208261 --> 0.090282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1000984\n",
      "\tspeed: 0.0380s/iter; left time: 827.6431s\n",
      "\titers: 200, epoch: 3 | loss: 0.0889085\n",
      "\tspeed: 0.0199s/iter; left time: 431.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0975246 Vali Loss: 0.0740844 Test Loss: 0.0832097\n",
      "Validation loss decreased (0.090282 --> 0.074084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866115\n",
      "\tspeed: 0.0414s/iter; left time: 892.1376s\n",
      "\titers: 200, epoch: 4 | loss: 0.0850188\n",
      "\tspeed: 0.0221s/iter; left time: 472.6048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0862536 Vali Loss: 0.0705641 Test Loss: 0.0806000\n",
      "Validation loss decreased (0.074084 --> 0.070564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772351\n",
      "\tspeed: 0.0442s/iter; left time: 941.3216s\n",
      "\titers: 200, epoch: 5 | loss: 0.0778000\n",
      "\tspeed: 0.0209s/iter; left time: 443.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0779588 Vali Loss: 0.0672013 Test Loss: 0.0807283\n",
      "Validation loss decreased (0.070564 --> 0.067201).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711917\n",
      "\tspeed: 0.0403s/iter; left time: 849.4317s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722112\n",
      "\tspeed: 0.0158s/iter; left time: 331.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0744477 Vali Loss: 0.0661554 Test Loss: 0.0860211\n",
      "Validation loss decreased (0.067201 --> 0.066155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739123\n",
      "\tspeed: 0.0423s/iter; left time: 881.9343s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742147\n",
      "\tspeed: 0.0252s/iter; left time: 523.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0716308 Vali Loss: 0.0647305 Test Loss: 0.0859744\n",
      "Validation loss decreased (0.066155 --> 0.064730).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0713335\n",
      "\tspeed: 0.0428s/iter; left time: 884.2053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682481\n",
      "\tspeed: 0.0201s/iter; left time: 413.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0695360 Vali Loss: 0.0645455 Test Loss: 0.0859980\n",
      "Validation loss decreased (0.064730 --> 0.064546).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0687030\n",
      "\tspeed: 0.0381s/iter; left time: 777.0498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697583\n",
      "\tspeed: 0.0213s/iter; left time: 432.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0686131 Vali Loss: 0.0629123 Test Loss: 0.0801577\n",
      "Validation loss decreased (0.064546 --> 0.062912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684517\n",
      "\tspeed: 0.0428s/iter; left time: 863.3470s\n",
      "\titers: 200, epoch: 10 | loss: 0.0667424\n",
      "\tspeed: 0.0200s/iter; left time: 401.7817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0671330 Vali Loss: 0.0622508 Test Loss: 0.0774219\n",
      "Validation loss decreased (0.062912 --> 0.062251).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619685\n",
      "\tspeed: 0.0417s/iter; left time: 832.1462s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625683\n",
      "\tspeed: 0.0195s/iter; left time: 388.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0660573 Vali Loss: 0.0615198 Test Loss: 0.0774656\n",
      "Validation loss decreased (0.062251 --> 0.061520).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726550\n",
      "\tspeed: 0.0495s/iter; left time: 976.8611s\n",
      "\titers: 200, epoch: 12 | loss: 0.0644123\n",
      "\tspeed: 0.0260s/iter; left time: 511.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0657273 Vali Loss: 0.0620292 Test Loss: 0.0781812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650582\n",
      "\tspeed: 0.0428s/iter; left time: 836.4521s\n",
      "\titers: 200, epoch: 13 | loss: 0.0631247\n",
      "\tspeed: 0.0226s/iter; left time: 439.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0647720 Vali Loss: 0.0607914 Test Loss: 0.0755807\n",
      "Validation loss decreased (0.061520 --> 0.060791).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641611\n",
      "\tspeed: 0.0399s/iter; left time: 770.2098s\n",
      "\titers: 200, epoch: 14 | loss: 0.0662648\n",
      "\tspeed: 0.0202s/iter; left time: 388.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0643654 Vali Loss: 0.0608688 Test Loss: 0.0753162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0639788\n",
      "\tspeed: 0.0384s/iter; left time: 733.5842s\n",
      "\titers: 200, epoch: 15 | loss: 0.0637772\n",
      "\tspeed: 0.0213s/iter; left time: 403.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0637493 Vali Loss: 0.0603454 Test Loss: 0.0746442\n",
      "Validation loss decreased (0.060791 --> 0.060345).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0646336\n",
      "\tspeed: 0.0431s/iter; left time: 812.6171s\n",
      "\titers: 200, epoch: 16 | loss: 0.0639375\n",
      "\tspeed: 0.0210s/iter; left time: 393.0999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0635661 Vali Loss: 0.0603865 Test Loss: 0.0745695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624194\n",
      "\tspeed: 0.0407s/iter; left time: 757.5899s\n",
      "\titers: 200, epoch: 17 | loss: 0.0644356\n",
      "\tspeed: 0.0193s/iter; left time: 358.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0632484 Vali Loss: 0.0601870 Test Loss: 0.0742894\n",
      "Validation loss decreased (0.060345 --> 0.060187).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0630162\n",
      "\tspeed: 0.0416s/iter; left time: 766.6431s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598314\n",
      "\tspeed: 0.0206s/iter; left time: 376.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0629594 Vali Loss: 0.0595147 Test Loss: 0.0732608\n",
      "Validation loss decreased (0.060187 --> 0.059515).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643004\n",
      "\tspeed: 0.0405s/iter; left time: 737.1713s\n",
      "\titers: 200, epoch: 19 | loss: 0.0667522\n",
      "\tspeed: 0.0192s/iter; left time: 347.6795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0626891 Vali Loss: 0.0593911 Test Loss: 0.0726724\n",
      "Validation loss decreased (0.059515 --> 0.059391).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621276\n",
      "\tspeed: 0.0393s/iter; left time: 705.9623s\n",
      "\titers: 200, epoch: 20 | loss: 0.0597470\n",
      "\tspeed: 0.0178s/iter; left time: 317.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0624875 Vali Loss: 0.0595826 Test Loss: 0.0720896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0612602\n",
      "\tspeed: 0.0412s/iter; left time: 730.5395s\n",
      "\titers: 200, epoch: 21 | loss: 0.0627079\n",
      "\tspeed: 0.0156s/iter; left time: 275.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0622138 Vali Loss: 0.0592976 Test Loss: 0.0722283\n",
      "Validation loss decreased (0.059391 --> 0.059298).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0617739\n",
      "\tspeed: 0.0319s/iter; left time: 559.5380s\n",
      "\titers: 200, epoch: 22 | loss: 0.0627653\n",
      "\tspeed: 0.0134s/iter; left time: 233.6281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 223 | Train Loss: 0.0619760 Vali Loss: 0.0589683 Test Loss: 0.0714743\n",
      "Validation loss decreased (0.059298 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0598896\n",
      "\tspeed: 0.0416s/iter; left time: 719.0129s\n",
      "\titers: 200, epoch: 23 | loss: 0.0631920\n",
      "\tspeed: 0.0254s/iter; left time: 436.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 223 | Train Loss: 0.0618875 Vali Loss: 0.0587703 Test Loss: 0.0712057\n",
      "Validation loss decreased (0.058968 --> 0.058770).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583961\n",
      "\tspeed: 0.0452s/iter; left time: 772.0838s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610948\n",
      "\tspeed: 0.0190s/iter; left time: 322.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0617510 Vali Loss: 0.0593059 Test Loss: 0.0719591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0580491\n",
      "\tspeed: 0.0333s/iter; left time: 561.8974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0652222\n",
      "\tspeed: 0.0175s/iter; left time: 293.1519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0616693 Vali Loss: 0.0590747 Test Loss: 0.0716805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0642503\n",
      "\tspeed: 0.0369s/iter; left time: 613.9415s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594688\n",
      "\tspeed: 0.0170s/iter; left time: 280.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0615083 Vali Loss: 0.0594680 Test Loss: 0.0719661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0635411\n",
      "\tspeed: 0.0431s/iter; left time: 706.9856s\n",
      "\titers: 200, epoch: 27 | loss: 0.0603641\n",
      "\tspeed: 0.0214s/iter; left time: 349.2069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0613732 Vali Loss: 0.0590979 Test Loss: 0.0716480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0590103\n",
      "\tspeed: 0.0411s/iter; left time: 665.8038s\n",
      "\titers: 200, epoch: 28 | loss: 0.0609089\n",
      "\tspeed: 0.0218s/iter; left time: 351.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0612358 Vali Loss: 0.0587728 Test Loss: 0.0712729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596771\n",
      "\tspeed: 0.0409s/iter; left time: 652.8578s\n",
      "\titers: 200, epoch: 29 | loss: 0.0595601\n",
      "\tspeed: 0.0203s/iter; left time: 322.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0610402 Vali Loss: 0.0587477 Test Loss: 0.0714170\n",
      "Validation loss decreased (0.058770 --> 0.058748).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0619347\n",
      "\tspeed: 0.0378s/iter; left time: 595.2806s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606348\n",
      "\tspeed: 0.0164s/iter; left time: 256.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0611645 Vali Loss: 0.0587530 Test Loss: 0.0711717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0613811\n",
      "\tspeed: 0.0357s/iter; left time: 554.1205s\n",
      "\titers: 200, epoch: 31 | loss: 0.0604562\n",
      "\tspeed: 0.0182s/iter; left time: 280.2641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0611316 Vali Loss: 0.0584519 Test Loss: 0.0709715\n",
      "Validation loss decreased (0.058748 --> 0.058452).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0605088\n",
      "\tspeed: 0.0415s/iter; left time: 634.2541s\n",
      "\titers: 200, epoch: 32 | loss: 0.0672119\n",
      "\tspeed: 0.0202s/iter; left time: 307.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0610969 Vali Loss: 0.0583849 Test Loss: 0.0707176\n",
      "Validation loss decreased (0.058452 --> 0.058385).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0572636\n",
      "\tspeed: 0.0416s/iter; left time: 626.1339s\n",
      "\titers: 200, epoch: 33 | loss: 0.0620738\n",
      "\tspeed: 0.0200s/iter; left time: 299.6786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0610526 Vali Loss: 0.0584173 Test Loss: 0.0707011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0663672\n",
      "\tspeed: 0.0411s/iter; left time: 609.9933s\n",
      "\titers: 200, epoch: 34 | loss: 0.0620922\n",
      "\tspeed: 0.0199s/iter; left time: 293.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0608810 Vali Loss: 0.0588598 Test Loss: 0.0714231\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0639941\n",
      "\tspeed: 0.0400s/iter; left time: 584.1779s\n",
      "\titers: 200, epoch: 35 | loss: 0.0623683\n",
      "\tspeed: 0.0204s/iter; left time: 296.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0607366 Vali Loss: 0.0589204 Test Loss: 0.0713703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0612918\n",
      "\tspeed: 0.0393s/iter; left time: 566.1825s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612551\n",
      "\tspeed: 0.0189s/iter; left time: 269.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0609784 Vali Loss: 0.0585926 Test Loss: 0.0710650\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0589662\n",
      "\tspeed: 0.0394s/iter; left time: 557.8564s\n",
      "\titers: 200, epoch: 37 | loss: 0.0611438\n",
      "\tspeed: 0.0190s/iter; left time: 266.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0607585 Vali Loss: 0.0585449 Test Loss: 0.0707495\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0599900\n",
      "\tspeed: 0.0385s/iter; left time: 537.5345s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618140\n",
      "\tspeed: 0.0173s/iter; left time: 238.9617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0607697 Vali Loss: 0.0584142 Test Loss: 0.0706665\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0616662\n",
      "\tspeed: 0.0384s/iter; left time: 526.8247s\n",
      "\titers: 200, epoch: 39 | loss: 0.0635473\n",
      "\tspeed: 0.0216s/iter; left time: 294.8922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0605788 Vali Loss: 0.0585327 Test Loss: 0.0709554\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0612657\n",
      "\tspeed: 0.0401s/iter; left time: 541.7049s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608891\n",
      "\tspeed: 0.0202s/iter; left time: 270.9334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0607439 Vali Loss: 0.0587597 Test Loss: 0.0710037\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0582456\n",
      "\tspeed: 0.0395s/iter; left time: 524.9009s\n",
      "\titers: 200, epoch: 41 | loss: 0.0610829\n",
      "\tspeed: 0.0130s/iter; left time: 171.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0606736 Vali Loss: 0.0584041 Test Loss: 0.0705513\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0610278\n",
      "\tspeed: 0.0398s/iter; left time: 519.1021s\n",
      "\titers: 200, epoch: 42 | loss: 0.0608318\n",
      "\tspeed: 0.0203s/iter; left time: 263.3606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0606727 Vali Loss: 0.0586551 Test Loss: 0.0710897\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011825245805084705, rmse:0.10874394327402115, mae:0.07071761041879654, rse:0.32002028822898865\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:02.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736052\n",
      "\tspeed: 0.0428s/iter; left time: 945.3248s\n",
      "\titers: 200, epoch: 1 | loss: 0.2632492\n",
      "\tspeed: 0.0138s/iter; left time: 304.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 222 | Train Loss: 0.2820088 Vali Loss: 0.2145321 Test Loss: 0.2392163\n",
      "Validation loss decreased (inf --> 0.214532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443035\n",
      "\tspeed: 0.0371s/iter; left time: 812.4408s\n",
      "\titers: 200, epoch: 2 | loss: 0.1171579\n",
      "\tspeed: 0.0178s/iter; left time: 388.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.1566103 Vali Loss: 0.1021497 Test Loss: 0.1147590\n",
      "Validation loss decreased (0.214532 --> 0.102150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029422\n",
      "\tspeed: 0.0417s/iter; left time: 903.9865s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004539\n",
      "\tspeed: 0.0226s/iter; left time: 486.8202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.1075946 Vali Loss: 0.0927374 Test Loss: 0.1105644\n",
      "Validation loss decreased (0.102150 --> 0.092737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0945588\n",
      "\tspeed: 0.0361s/iter; left time: 773.6963s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923368\n",
      "\tspeed: 0.0135s/iter; left time: 288.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 222 | Train Loss: 0.0960586 Vali Loss: 0.0868538 Test Loss: 0.1093112\n",
      "Validation loss decreased (0.092737 --> 0.086854).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870314\n",
      "\tspeed: 0.0344s/iter; left time: 729.3418s\n",
      "\titers: 200, epoch: 5 | loss: 0.0919901\n",
      "\tspeed: 0.0168s/iter; left time: 354.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0906975 Vali Loss: 0.0841453 Test Loss: 0.1088696\n",
      "Validation loss decreased (0.086854 --> 0.084145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0899552\n",
      "\tspeed: 0.0391s/iter; left time: 820.3539s\n",
      "\titers: 200, epoch: 6 | loss: 0.0853597\n",
      "\tspeed: 0.0189s/iter; left time: 394.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0879212 Vali Loss: 0.0829789 Test Loss: 0.1075587\n",
      "Validation loss decreased (0.084145 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0906571\n",
      "\tspeed: 0.0421s/iter; left time: 874.2868s\n",
      "\titers: 200, epoch: 7 | loss: 0.0847237\n",
      "\tspeed: 0.0190s/iter; left time: 392.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0863495 Vali Loss: 0.0817976 Test Loss: 0.1075792\n",
      "Validation loss decreased (0.082979 --> 0.081798).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0875130\n",
      "\tspeed: 0.0409s/iter; left time: 840.8521s\n",
      "\titers: 200, epoch: 8 | loss: 0.0924293\n",
      "\tspeed: 0.0185s/iter; left time: 377.7500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0849309 Vali Loss: 0.0810084 Test Loss: 0.1117717\n",
      "Validation loss decreased (0.081798 --> 0.081008).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0818318\n",
      "\tspeed: 0.0337s/iter; left time: 684.9659s\n",
      "\titers: 200, epoch: 9 | loss: 0.0829084\n",
      "\tspeed: 0.0198s/iter; left time: 400.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0841765 Vali Loss: 0.0805167 Test Loss: 0.1112050\n",
      "Validation loss decreased (0.081008 --> 0.080517).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0829857\n",
      "\tspeed: 0.0367s/iter; left time: 737.8455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0831658\n",
      "\tspeed: 0.0170s/iter; left time: 340.6905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0832553 Vali Loss: 0.0805455 Test Loss: 0.1122987\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0824473\n",
      "\tspeed: 0.0369s/iter; left time: 734.0875s\n",
      "\titers: 200, epoch: 11 | loss: 0.0810061\n",
      "\tspeed: 0.0178s/iter; left time: 352.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0827405 Vali Loss: 0.0800260 Test Loss: 0.1080277\n",
      "Validation loss decreased (0.080517 --> 0.080026).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0822582\n",
      "\tspeed: 0.0370s/iter; left time: 726.5029s\n",
      "\titers: 200, epoch: 12 | loss: 0.0819651\n",
      "\tspeed: 0.0174s/iter; left time: 341.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0823618 Vali Loss: 0.0809900 Test Loss: 0.1009054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825042\n",
      "\tspeed: 0.0398s/iter; left time: 773.1183s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784602\n",
      "\tspeed: 0.0170s/iter; left time: 328.2063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0822133 Vali Loss: 0.0801974 Test Loss: 0.1046171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0790386\n",
      "\tspeed: 0.0391s/iter; left time: 751.5961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0854282\n",
      "\tspeed: 0.0244s/iter; left time: 467.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.0814955 Vali Loss: 0.0800733 Test Loss: 0.1055419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843044\n",
      "\tspeed: 0.0346s/iter; left time: 656.9880s\n",
      "\titers: 200, epoch: 15 | loss: 0.0819646\n",
      "\tspeed: 0.0199s/iter; left time: 376.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0814477 Vali Loss: 0.0800168 Test Loss: 0.1067444\n",
      "Validation loss decreased (0.080026 --> 0.080017).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0788339\n",
      "\tspeed: 0.0384s/iter; left time: 721.2076s\n",
      "\titers: 200, epoch: 16 | loss: 0.0818524\n",
      "\tspeed: 0.0191s/iter; left time: 356.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0808672 Vali Loss: 0.0796301 Test Loss: 0.1091263\n",
      "Validation loss decreased (0.080017 --> 0.079630).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810963\n",
      "\tspeed: 0.0415s/iter; left time: 769.2538s\n",
      "\titers: 200, epoch: 17 | loss: 0.0811919\n",
      "\tspeed: 0.0193s/iter; left time: 355.6003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0805257 Vali Loss: 0.0796749 Test Loss: 0.1080271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0794173\n",
      "\tspeed: 0.0360s/iter; left time: 659.5197s\n",
      "\titers: 200, epoch: 18 | loss: 0.0789100\n",
      "\tspeed: 0.0183s/iter; left time: 334.1224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0805847 Vali Loss: 0.0798890 Test Loss: 0.1028857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0782742\n",
      "\tspeed: 0.0400s/iter; left time: 724.7694s\n",
      "\titers: 200, epoch: 19 | loss: 0.0784676\n",
      "\tspeed: 0.0176s/iter; left time: 317.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0803351 Vali Loss: 0.0796942 Test Loss: 0.1051105\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0789921\n",
      "\tspeed: 0.0364s/iter; left time: 650.6245s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792069\n",
      "\tspeed: 0.0176s/iter; left time: 313.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0799567 Vali Loss: 0.0794589 Test Loss: 0.1085698\n",
      "Validation loss decreased (0.079630 --> 0.079459).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0794683\n",
      "\tspeed: 0.0374s/iter; left time: 659.8898s\n",
      "\titers: 200, epoch: 21 | loss: 0.0818249\n",
      "\tspeed: 0.0226s/iter; left time: 397.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0800978 Vali Loss: 0.0798695 Test Loss: 0.1047418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0790459\n",
      "\tspeed: 0.0379s/iter; left time: 661.3822s\n",
      "\titers: 200, epoch: 22 | loss: 0.0759462\n",
      "\tspeed: 0.0193s/iter; left time: 334.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0799170 Vali Loss: 0.0802823 Test Loss: 0.1047563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0786337\n",
      "\tspeed: 0.0325s/iter; left time: 559.7323s\n",
      "\titers: 200, epoch: 23 | loss: 0.0806328\n",
      "\tspeed: 0.0135s/iter; left time: 231.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 222 | Train Loss: 0.0798040 Vali Loss: 0.0794180 Test Loss: 0.1073540\n",
      "Validation loss decreased (0.079459 --> 0.079418).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0760322\n",
      "\tspeed: 0.0355s/iter; left time: 602.9466s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821401\n",
      "\tspeed: 0.0175s/iter; left time: 295.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0797892 Vali Loss: 0.0796151 Test Loss: 0.1060932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0772340\n",
      "\tspeed: 0.0405s/iter; left time: 678.7995s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787995\n",
      "\tspeed: 0.0196s/iter; left time: 326.4710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0794597 Vali Loss: 0.0794219 Test Loss: 0.1073216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0778118\n",
      "\tspeed: 0.0381s/iter; left time: 630.2582s\n",
      "\titers: 200, epoch: 26 | loss: 0.0779257\n",
      "\tspeed: 0.0192s/iter; left time: 316.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0807394 Vali Loss: 0.0795315 Test Loss: 0.1035431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0823847\n",
      "\tspeed: 0.0341s/iter; left time: 557.5098s\n",
      "\titers: 200, epoch: 27 | loss: 0.0796326\n",
      "\tspeed: 0.0138s/iter; left time: 224.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 222 | Train Loss: 0.0800514 Vali Loss: 0.0796474 Test Loss: 0.1041704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0773318\n",
      "\tspeed: 0.0405s/iter; left time: 651.7941s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778298\n",
      "\tspeed: 0.0224s/iter; left time: 358.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0793746 Vali Loss: 0.0794691 Test Loss: 0.1060363\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796701\n",
      "\tspeed: 0.0368s/iter; left time: 584.9133s\n",
      "\titers: 200, epoch: 29 | loss: 0.0800269\n",
      "\tspeed: 0.0171s/iter; left time: 269.6129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0794556 Vali Loss: 0.0795925 Test Loss: 0.1068346\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0770347\n",
      "\tspeed: 0.0402s/iter; left time: 628.9837s\n",
      "\titers: 200, epoch: 30 | loss: 0.0802456\n",
      "\tspeed: 0.0201s/iter; left time: 313.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0794860 Vali Loss: 0.0793846 Test Loss: 0.1058029\n",
      "Validation loss decreased (0.079418 --> 0.079385).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0806104\n",
      "\tspeed: 0.0409s/iter; left time: 632.1020s\n",
      "\titers: 200, epoch: 31 | loss: 0.0805081\n",
      "\tspeed: 0.0179s/iter; left time: 274.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0793361 Vali Loss: 0.0794412 Test Loss: 0.1057922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776382\n",
      "\tspeed: 0.0385s/iter; left time: 586.1146s\n",
      "\titers: 200, epoch: 32 | loss: 0.0759733\n",
      "\tspeed: 0.0209s/iter; left time: 315.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0791413 Vali Loss: 0.0793291 Test Loss: 0.1056899\n",
      "Validation loss decreased (0.079385 --> 0.079329).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822738\n",
      "\tspeed: 0.0473s/iter; left time: 709.0383s\n",
      "\titers: 200, epoch: 33 | loss: 0.0759665\n",
      "\tspeed: 0.0231s/iter; left time: 344.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 222 | Train Loss: 0.0792071 Vali Loss: 0.0793188 Test Loss: 0.1060055\n",
      "Validation loss decreased (0.079329 --> 0.079319).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0833341\n",
      "\tspeed: 0.0397s/iter; left time: 586.8228s\n",
      "\titers: 200, epoch: 34 | loss: 0.0800838\n",
      "\tspeed: 0.0202s/iter; left time: 296.6790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0795997 Vali Loss: 0.0795705 Test Loss: 0.1056227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0800573\n",
      "\tspeed: 0.0440s/iter; left time: 641.0209s\n",
      "\titers: 200, epoch: 35 | loss: 0.0797740\n",
      "\tspeed: 0.0250s/iter; left time: 361.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.0790790 Vali Loss: 0.0794705 Test Loss: 0.1075593\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0796889\n",
      "\tspeed: 0.0439s/iter; left time: 629.3514s\n",
      "\titers: 200, epoch: 36 | loss: 0.0789199\n",
      "\tspeed: 0.0192s/iter; left time: 273.3409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0790394 Vali Loss: 0.0793967 Test Loss: 0.1054460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0809594\n",
      "\tspeed: 0.0364s/iter; left time: 514.0844s\n",
      "\titers: 200, epoch: 37 | loss: 0.0761129\n",
      "\tspeed: 0.0249s/iter; left time: 349.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.0797229 Vali Loss: 0.0795006 Test Loss: 0.1052754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0801391\n",
      "\tspeed: 0.0433s/iter; left time: 600.9338s\n",
      "\titers: 200, epoch: 38 | loss: 0.0799272\n",
      "\tspeed: 0.0202s/iter; left time: 277.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0793253 Vali Loss: 0.0793680 Test Loss: 0.1042482\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0731748\n",
      "\tspeed: 0.0376s/iter; left time: 513.9178s\n",
      "\titers: 200, epoch: 39 | loss: 0.0759681\n",
      "\tspeed: 0.0181s/iter; left time: 245.5942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0791599 Vali Loss: 0.0794062 Test Loss: 0.1052876\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0807964\n",
      "\tspeed: 0.0424s/iter; left time: 569.8575s\n",
      "\titers: 200, epoch: 40 | loss: 0.0771302\n",
      "\tspeed: 0.0199s/iter; left time: 265.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0790388 Vali Loss: 0.0794293 Test Loss: 0.1057975\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0836560\n",
      "\tspeed: 0.0372s/iter; left time: 492.4023s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785259\n",
      "\tspeed: 0.0185s/iter; left time: 243.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0790498 Vali Loss: 0.0792747 Test Loss: 0.1050334\n",
      "Validation loss decreased (0.079319 --> 0.079275).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0776172\n",
      "\tspeed: 0.0384s/iter; left time: 499.2674s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767821\n",
      "\tspeed: 0.0204s/iter; left time: 263.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0789913 Vali Loss: 0.0794345 Test Loss: 0.1060006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0781929\n",
      "\tspeed: 0.0400s/iter; left time: 511.3625s\n",
      "\titers: 200, epoch: 43 | loss: 0.0808915\n",
      "\tspeed: 0.0248s/iter; left time: 314.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 222 | Train Loss: 0.0789933 Vali Loss: 0.0792438 Test Loss: 0.1065399\n",
      "Validation loss decreased (0.079275 --> 0.079244).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0794440\n",
      "\tspeed: 0.0436s/iter; left time: 547.2190s\n",
      "\titers: 200, epoch: 44 | loss: 0.0768947\n",
      "\tspeed: 0.0201s/iter; left time: 250.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0789396 Vali Loss: 0.0792829 Test Loss: 0.1052665\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0767747\n",
      "\tspeed: 0.0434s/iter; left time: 535.0829s\n",
      "\titers: 200, epoch: 45 | loss: 0.0813656\n",
      "\tspeed: 0.0228s/iter; left time: 278.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 222 | Train Loss: 0.0788868 Vali Loss: 0.0792649 Test Loss: 0.1054403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0801876\n",
      "\tspeed: 0.0405s/iter; left time: 490.2599s\n",
      "\titers: 200, epoch: 46 | loss: 0.0818402\n",
      "\tspeed: 0.0234s/iter; left time: 280.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.0790246 Vali Loss: 0.0795171 Test Loss: 0.1061524\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0776780\n",
      "\tspeed: 0.0395s/iter; left time: 469.1328s\n",
      "\titers: 200, epoch: 47 | loss: 0.0776617\n",
      "\tspeed: 0.0189s/iter; left time: 223.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0790503 Vali Loss: 0.0793589 Test Loss: 0.1065618\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0787293\n",
      "\tspeed: 0.0402s/iter; left time: 469.5481s\n",
      "\titers: 200, epoch: 48 | loss: 0.0779946\n",
      "\tspeed: 0.0230s/iter; left time: 265.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0788890 Vali Loss: 0.0794486 Test Loss: 0.1072019\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0784116\n",
      "\tspeed: 0.0396s/iter; left time: 452.7702s\n",
      "\titers: 200, epoch: 49 | loss: 0.0840174\n",
      "\tspeed: 0.0196s/iter; left time: 222.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0790734 Vali Loss: 0.0795275 Test Loss: 0.1060289\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0797258\n",
      "\tspeed: 0.0369s/iter; left time: 413.8712s\n",
      "\titers: 200, epoch: 50 | loss: 0.0782866\n",
      "\tspeed: 0.0198s/iter; left time: 220.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0788809 Vali Loss: 0.0792069 Test Loss: 0.1061280\n",
      "Validation loss decreased (0.079244 --> 0.079207).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0792235\n",
      "\tspeed: 0.0393s/iter; left time: 432.8322s\n",
      "\titers: 200, epoch: 51 | loss: 0.0801942\n",
      "\tspeed: 0.0193s/iter; left time: 210.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0789939 Vali Loss: 0.0792910 Test Loss: 0.1068094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0792178\n",
      "\tspeed: 0.0407s/iter; left time: 438.6843s\n",
      "\titers: 200, epoch: 52 | loss: 0.0770822\n",
      "\tspeed: 0.0152s/iter; left time: 162.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0790832 Vali Loss: 0.0792130 Test Loss: 0.1049754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0768336\n",
      "\tspeed: 0.0381s/iter; left time: 401.8601s\n",
      "\titers: 200, epoch: 53 | loss: 0.0789928\n",
      "\tspeed: 0.0161s/iter; left time: 168.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0791616 Vali Loss: 0.0794049 Test Loss: 0.1072447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0766972\n",
      "\tspeed: 0.0367s/iter; left time: 379.3799s\n",
      "\titers: 200, epoch: 54 | loss: 0.0793522\n",
      "\tspeed: 0.0171s/iter; left time: 175.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0789057 Vali Loss: 0.0794337 Test Loss: 0.1055728\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0789461\n",
      "\tspeed: 0.0419s/iter; left time: 423.4118s\n",
      "\titers: 200, epoch: 55 | loss: 0.0785880\n",
      "\tspeed: 0.0193s/iter; left time: 193.3897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0789052 Vali Loss: 0.0791764 Test Loss: 0.1050162\n",
      "Validation loss decreased (0.079207 --> 0.079176).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0805046\n",
      "\tspeed: 0.0382s/iter; left time: 377.4146s\n",
      "\titers: 200, epoch: 56 | loss: 0.0815311\n",
      "\tspeed: 0.0175s/iter; left time: 171.5381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0791163 Vali Loss: 0.0792601 Test Loss: 0.1053911\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0772773\n",
      "\tspeed: 0.0375s/iter; left time: 362.7796s\n",
      "\titers: 200, epoch: 57 | loss: 0.0802374\n",
      "\tspeed: 0.0192s/iter; left time: 183.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0789890 Vali Loss: 0.0792851 Test Loss: 0.1053438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0784494\n",
      "\tspeed: 0.0359s/iter; left time: 339.0564s\n",
      "\titers: 200, epoch: 58 | loss: 0.0803647\n",
      "\tspeed: 0.0132s/iter; left time: 123.5900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 222 | Train Loss: 0.0788573 Vali Loss: 0.0793364 Test Loss: 0.1058882\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0762803\n",
      "\tspeed: 0.0390s/iter; left time: 359.7969s\n",
      "\titers: 200, epoch: 59 | loss: 0.0783992\n",
      "\tspeed: 0.0194s/iter; left time: 176.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0788758 Vali Loss: 0.0791969 Test Loss: 0.1057142\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0825018\n",
      "\tspeed: 0.0395s/iter; left time: 355.7064s\n",
      "\titers: 200, epoch: 60 | loss: 0.0767532\n",
      "\tspeed: 0.0194s/iter; left time: 172.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0789938 Vali Loss: 0.0794343 Test Loss: 0.1060912\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0837195\n",
      "\tspeed: 0.0392s/iter; left time: 344.0122s\n",
      "\titers: 200, epoch: 61 | loss: 0.0781572\n",
      "\tspeed: 0.0191s/iter; left time: 165.5171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0788658 Vali Loss: 0.0793094 Test Loss: 0.1054503\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0807465\n",
      "\tspeed: 0.0379s/iter; left time: 324.7601s\n",
      "\titers: 200, epoch: 62 | loss: 0.0786767\n",
      "\tspeed: 0.0194s/iter; left time: 163.7630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0788907 Vali Loss: 0.0794156 Test Loss: 0.1059766\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0781662\n",
      "\tspeed: 0.0386s/iter; left time: 321.8443s\n",
      "\titers: 200, epoch: 63 | loss: 0.0798408\n",
      "\tspeed: 0.0203s/iter; left time: 167.2580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0791201 Vali Loss: 0.0793008 Test Loss: 0.1065161\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0772898\n",
      "\tspeed: 0.0398s/iter; left time: 322.6937s\n",
      "\titers: 200, epoch: 64 | loss: 0.0802854\n",
      "\tspeed: 0.0228s/iter; left time: 182.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0788891 Vali Loss: 0.0797067 Test Loss: 0.1072320\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0743827\n",
      "\tspeed: 0.0401s/iter; left time: 316.1353s\n",
      "\titers: 200, epoch: 65 | loss: 0.0831507\n",
      "\tspeed: 0.0190s/iter; left time: 148.1383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0788639 Vali Loss: 0.0792007 Test Loss: 0.1048479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02376987598836422, rmse:0.1541748195886612, mae:0.10501614212989807, rse:0.45291921496391296\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2810470\n",
      "\tspeed: 0.0207s/iter; left time: 457.1764s\n",
      "\titers: 200, epoch: 1 | loss: 0.2589971\n",
      "\tspeed: 0.0196s/iter; left time: 431.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.2842580 Vali Loss: 0.2176934 Test Loss: 0.2430637\n",
      "Validation loss decreased (inf --> 0.217693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1428849\n",
      "\tspeed: 0.0388s/iter; left time: 849.1580s\n",
      "\titers: 200, epoch: 2 | loss: 0.1177629\n",
      "\tspeed: 0.0181s/iter; left time: 393.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.1566190 Vali Loss: 0.1053681 Test Loss: 0.1198546\n",
      "Validation loss decreased (0.217693 --> 0.105368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089350\n",
      "\tspeed: 0.0386s/iter; left time: 835.4087s\n",
      "\titers: 200, epoch: 3 | loss: 0.1000227\n",
      "\tspeed: 0.0184s/iter; left time: 396.1822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.1072686 Vali Loss: 0.0916175 Test Loss: 0.1095698\n",
      "Validation loss decreased (0.105368 --> 0.091617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0956034\n",
      "\tspeed: 0.0400s/iter; left time: 857.3030s\n",
      "\titers: 200, epoch: 4 | loss: 0.0941442\n",
      "\tspeed: 0.0195s/iter; left time: 416.8059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0948761 Vali Loss: 0.0862199 Test Loss: 0.1078077\n",
      "Validation loss decreased (0.091617 --> 0.086220).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0916500\n",
      "\tspeed: 0.0395s/iter; left time: 837.2804s\n",
      "\titers: 200, epoch: 5 | loss: 0.0919713\n",
      "\tspeed: 0.0194s/iter; left time: 409.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 222 | Train Loss: 0.0908284 Vali Loss: 0.0855985 Test Loss: 0.1063819\n",
      "Validation loss decreased (0.086220 --> 0.085599).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0832181\n",
      "\tspeed: 0.0445s/iter; left time: 933.9045s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862229\n",
      "\tspeed: 0.0200s/iter; left time: 418.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.0884109 Vali Loss: 0.0834829 Test Loss: 0.1045711\n",
      "Validation loss decreased (0.085599 --> 0.083483).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0872452\n",
      "\tspeed: 0.0421s/iter; left time: 873.6491s\n",
      "\titers: 200, epoch: 7 | loss: 0.0880526\n",
      "\tspeed: 0.0197s/iter; left time: 406.4527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0868561 Vali Loss: 0.0827404 Test Loss: 0.1038241\n",
      "Validation loss decreased (0.083483 --> 0.082740).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873086\n",
      "\tspeed: 0.0396s/iter; left time: 814.4985s\n",
      "\titers: 200, epoch: 8 | loss: 0.0818132\n",
      "\tspeed: 0.0216s/iter; left time: 441.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0854578 Vali Loss: 0.0854367 Test Loss: 0.1063910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821413\n",
      "\tspeed: 0.0400s/iter; left time: 812.8920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866865\n",
      "\tspeed: 0.0215s/iter; left time: 434.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0848729 Vali Loss: 0.0824220 Test Loss: 0.1041098\n",
      "Validation loss decreased (0.082740 --> 0.082422).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799296\n",
      "\tspeed: 0.0471s/iter; left time: 946.8067s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849174\n",
      "\tspeed: 0.0215s/iter; left time: 430.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.0840741 Vali Loss: 0.0813358 Test Loss: 0.1034212\n",
      "Validation loss decreased (0.082422 --> 0.081336).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811578\n",
      "\tspeed: 0.0400s/iter; left time: 796.1080s\n",
      "\titers: 200, epoch: 11 | loss: 0.0790042\n",
      "\tspeed: 0.0201s/iter; left time: 397.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0830483 Vali Loss: 0.0805814 Test Loss: 0.1018861\n",
      "Validation loss decreased (0.081336 --> 0.080581).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0865190\n",
      "\tspeed: 0.0413s/iter; left time: 811.6023s\n",
      "\titers: 200, epoch: 12 | loss: 0.0824904\n",
      "\tspeed: 0.0222s/iter; left time: 434.5857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 222 | Train Loss: 0.0829455 Vali Loss: 0.0818581 Test Loss: 0.1040239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0845788\n",
      "\tspeed: 0.0367s/iter; left time: 714.2909s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808019\n",
      "\tspeed: 0.0217s/iter; left time: 418.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0825119 Vali Loss: 0.0802521 Test Loss: 0.1025698\n",
      "Validation loss decreased (0.080581 --> 0.080252).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800021\n",
      "\tspeed: 0.0410s/iter; left time: 787.0546s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800325\n",
      "\tspeed: 0.0139s/iter; left time: 266.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0818480 Vali Loss: 0.0801559 Test Loss: 0.1029230\n",
      "Validation loss decreased (0.080252 --> 0.080156).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0839747\n",
      "\tspeed: 0.0419s/iter; left time: 795.6957s\n",
      "\titers: 200, epoch: 15 | loss: 0.0872229\n",
      "\tspeed: 0.0210s/iter; left time: 396.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.0818756 Vali Loss: 0.0803459 Test Loss: 0.1029744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0794405\n",
      "\tspeed: 0.0412s/iter; left time: 772.9624s\n",
      "\titers: 200, epoch: 16 | loss: 0.0777880\n",
      "\tspeed: 0.0198s/iter; left time: 369.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0812288 Vali Loss: 0.0796655 Test Loss: 0.1032664\n",
      "Validation loss decreased (0.080156 --> 0.079665).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801393\n",
      "\tspeed: 0.0399s/iter; left time: 740.6013s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806118\n",
      "\tspeed: 0.0185s/iter; left time: 342.1889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0809478 Vali Loss: 0.0795601 Test Loss: 0.1028116\n",
      "Validation loss decreased (0.079665 --> 0.079560).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812949\n",
      "\tspeed: 0.0414s/iter; left time: 758.0088s\n",
      "\titers: 200, epoch: 18 | loss: 0.0829192\n",
      "\tspeed: 0.0197s/iter; left time: 358.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0809617 Vali Loss: 0.0797312 Test Loss: 0.1021368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0776868\n",
      "\tspeed: 0.0398s/iter; left time: 720.0746s\n",
      "\titers: 200, epoch: 19 | loss: 0.0802930\n",
      "\tspeed: 0.0195s/iter; left time: 350.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0806394 Vali Loss: 0.0795797 Test Loss: 0.1032248\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0839570\n",
      "\tspeed: 0.0412s/iter; left time: 736.6568s\n",
      "\titers: 200, epoch: 20 | loss: 0.0903985\n",
      "\tspeed: 0.0216s/iter; left time: 383.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0805856 Vali Loss: 0.0797428 Test Loss: 0.1031292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0777669\n",
      "\tspeed: 0.0430s/iter; left time: 760.0149s\n",
      "\titers: 200, epoch: 21 | loss: 0.0817776\n",
      "\tspeed: 0.0199s/iter; left time: 350.2997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0802346 Vali Loss: 0.0792237 Test Loss: 0.1023476\n",
      "Validation loss decreased (0.079560 --> 0.079224).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0790358\n",
      "\tspeed: 0.0401s/iter; left time: 698.5715s\n",
      "\titers: 200, epoch: 22 | loss: 0.0821888\n",
      "\tspeed: 0.0181s/iter; left time: 314.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0802168 Vali Loss: 0.0791976 Test Loss: 0.1022222\n",
      "Validation loss decreased (0.079224 --> 0.079198).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802167\n",
      "\tspeed: 0.0437s/iter; left time: 752.7711s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791469\n",
      "\tspeed: 0.0190s/iter; left time: 325.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0800416 Vali Loss: 0.0792813 Test Loss: 0.1030126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0794432\n",
      "\tspeed: 0.0406s/iter; left time: 689.2078s\n",
      "\titers: 200, epoch: 24 | loss: 0.0804316\n",
      "\tspeed: 0.0192s/iter; left time: 324.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0798016 Vali Loss: 0.0791978 Test Loss: 0.1020456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0815211\n",
      "\tspeed: 0.0391s/iter; left time: 656.4393s\n",
      "\titers: 200, epoch: 25 | loss: 0.0761523\n",
      "\tspeed: 0.0214s/iter; left time: 356.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0797133 Vali Loss: 0.0792341 Test Loss: 0.1035025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0782770\n",
      "\tspeed: 0.0441s/iter; left time: 729.5756s\n",
      "\titers: 200, epoch: 26 | loss: 0.0795551\n",
      "\tspeed: 0.0210s/iter; left time: 345.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0796777 Vali Loss: 0.0791404 Test Loss: 0.1027319\n",
      "Validation loss decreased (0.079198 --> 0.079140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0820096\n",
      "\tspeed: 0.0408s/iter; left time: 667.0003s\n",
      "\titers: 200, epoch: 27 | loss: 0.0759461\n",
      "\tspeed: 0.0195s/iter; left time: 315.6728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0794938 Vali Loss: 0.0791340 Test Loss: 0.1030964\n",
      "Validation loss decreased (0.079140 --> 0.079134).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0820050\n",
      "\tspeed: 0.0420s/iter; left time: 675.8103s\n",
      "\titers: 200, epoch: 28 | loss: 0.0995732\n",
      "\tspeed: 0.0194s/iter; left time: 311.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0803654 Vali Loss: 0.0793823 Test Loss: 0.1027825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0787976\n",
      "\tspeed: 0.0407s/iter; left time: 647.2600s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788985\n",
      "\tspeed: 0.0184s/iter; left time: 290.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0795554 Vali Loss: 0.0791490 Test Loss: 0.1026566\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0781396\n",
      "\tspeed: 0.0410s/iter; left time: 641.8839s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771283\n",
      "\tspeed: 0.0203s/iter; left time: 316.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0795234 Vali Loss: 0.0792159 Test Loss: 0.1034529\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0786963\n",
      "\tspeed: 0.0419s/iter; left time: 647.1760s\n",
      "\titers: 200, epoch: 31 | loss: 0.0803929\n",
      "\tspeed: 0.0204s/iter; left time: 313.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0793471 Vali Loss: 0.0791961 Test Loss: 0.1027451\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0819115\n",
      "\tspeed: 0.0386s/iter; left time: 586.8495s\n",
      "\titers: 200, epoch: 32 | loss: 0.0808079\n",
      "\tspeed: 0.0167s/iter; left time: 251.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0794470 Vali Loss: 0.0791438 Test Loss: 0.1026879\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0762618\n",
      "\tspeed: 0.0376s/iter; left time: 564.0535s\n",
      "\titers: 200, epoch: 33 | loss: 0.0815164\n",
      "\tspeed: 0.0190s/iter; left time: 283.2116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0794177 Vali Loss: 0.0792071 Test Loss: 0.1027365\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0749935\n",
      "\tspeed: 0.0428s/iter; left time: 632.0449s\n",
      "\titers: 200, epoch: 34 | loss: 0.0780543\n",
      "\tspeed: 0.0194s/iter; left time: 284.2457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0792908 Vali Loss: 0.0789458 Test Loss: 0.1024397\n",
      "Validation loss decreased (0.079134 --> 0.078946).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0782235\n",
      "\tspeed: 0.0404s/iter; left time: 587.8104s\n",
      "\titers: 200, epoch: 35 | loss: 0.0795221\n",
      "\tspeed: 0.0193s/iter; left time: 279.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0791714 Vali Loss: 0.0791555 Test Loss: 0.1031611\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0820126\n",
      "\tspeed: 0.0386s/iter; left time: 552.6923s\n",
      "\titers: 200, epoch: 36 | loss: 0.0786146\n",
      "\tspeed: 0.0197s/iter; left time: 280.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0796702 Vali Loss: 0.0791106 Test Loss: 0.1022685\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803640\n",
      "\tspeed: 0.0384s/iter; left time: 542.3539s\n",
      "\titers: 200, epoch: 37 | loss: 0.0808174\n",
      "\tspeed: 0.0193s/iter; left time: 270.7213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0792411 Vali Loss: 0.0790062 Test Loss: 0.1028497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0790733\n",
      "\tspeed: 0.0388s/iter; left time: 538.6376s\n",
      "\titers: 200, epoch: 38 | loss: 0.0804619\n",
      "\tspeed: 0.0174s/iter; left time: 239.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0792892 Vali Loss: 0.0790832 Test Loss: 0.1028110\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0762917\n",
      "\tspeed: 0.0389s/iter; left time: 531.4142s\n",
      "\titers: 200, epoch: 39 | loss: 0.0776001\n",
      "\tspeed: 0.0176s/iter; left time: 238.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0791708 Vali Loss: 0.0790128 Test Loss: 0.1030692\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0814784\n",
      "\tspeed: 0.0434s/iter; left time: 583.3151s\n",
      "\titers: 200, epoch: 40 | loss: 0.0833261\n",
      "\tspeed: 0.0237s/iter; left time: 315.6315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 222 | Train Loss: 0.0791577 Vali Loss: 0.0788823 Test Loss: 0.1023154\n",
      "Validation loss decreased (0.078946 --> 0.078882).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0781104\n",
      "\tspeed: 0.0463s/iter; left time: 612.5403s\n",
      "\titers: 200, epoch: 41 | loss: 0.0804314\n",
      "\tspeed: 0.0241s/iter; left time: 316.2983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 222 | Train Loss: 0.0791517 Vali Loss: 0.0789537 Test Loss: 0.1029243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0816227\n",
      "\tspeed: 0.0388s/iter; left time: 503.8707s\n",
      "\titers: 200, epoch: 42 | loss: 0.0790452\n",
      "\tspeed: 0.0240s/iter; left time: 310.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0791252 Vali Loss: 0.0789561 Test Loss: 0.1028040\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0790205\n",
      "\tspeed: 0.0438s/iter; left time: 559.2371s\n",
      "\titers: 200, epoch: 43 | loss: 0.0782743\n",
      "\tspeed: 0.0180s/iter; left time: 228.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0790588 Vali Loss: 0.0788983 Test Loss: 0.1029840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0739642\n",
      "\tspeed: 0.0379s/iter; left time: 475.3153s\n",
      "\titers: 200, epoch: 44 | loss: 0.0761449\n",
      "\tspeed: 0.0200s/iter; left time: 249.6112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0790975 Vali Loss: 0.0791018 Test Loss: 0.1036198\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0774458\n",
      "\tspeed: 0.0384s/iter; left time: 473.8516s\n",
      "\titers: 200, epoch: 45 | loss: 0.0799462\n",
      "\tspeed: 0.0174s/iter; left time: 212.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0794921 Vali Loss: 0.0788967 Test Loss: 0.1025624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0784422\n",
      "\tspeed: 0.0435s/iter; left time: 527.3603s\n",
      "\titers: 200, epoch: 46 | loss: 0.0794881\n",
      "\tspeed: 0.0179s/iter; left time: 215.4544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0793124 Vali Loss: 0.0790206 Test Loss: 0.1033023\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0794085\n",
      "\tspeed: 0.0387s/iter; left time: 459.5798s\n",
      "\titers: 200, epoch: 47 | loss: 0.0817144\n",
      "\tspeed: 0.0176s/iter; left time: 207.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0790663 Vali Loss: 0.0790133 Test Loss: 0.1029455\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0763003\n",
      "\tspeed: 0.0426s/iter; left time: 496.7901s\n",
      "\titers: 200, epoch: 48 | loss: 0.0763451\n",
      "\tspeed: 0.0171s/iter; left time: 197.6930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0789351 Vali Loss: 0.0787943 Test Loss: 0.1024749\n",
      "Validation loss decreased (0.078882 --> 0.078794).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0795730\n",
      "\tspeed: 0.0401s/iter; left time: 458.5868s\n",
      "\titers: 200, epoch: 49 | loss: 0.0759086\n",
      "\tspeed: 0.0194s/iter; left time: 219.5469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0790111 Vali Loss: 0.0789350 Test Loss: 0.1026037\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0815081\n",
      "\tspeed: 0.0416s/iter; left time: 467.0580s\n",
      "\titers: 200, epoch: 50 | loss: 0.0753445\n",
      "\tspeed: 0.0222s/iter; left time: 246.5248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0789808 Vali Loss: 0.0789486 Test Loss: 0.1029010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0784314\n",
      "\tspeed: 0.0416s/iter; left time: 458.0392s\n",
      "\titers: 200, epoch: 51 | loss: 0.0786514\n",
      "\tspeed: 0.0186s/iter; left time: 202.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0794860 Vali Loss: 0.0789050 Test Loss: 0.1026498\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0763737\n",
      "\tspeed: 0.0362s/iter; left time: 390.1381s\n",
      "\titers: 200, epoch: 52 | loss: 0.0796035\n",
      "\tspeed: 0.0201s/iter; left time: 215.0945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0789189 Vali Loss: 0.0789363 Test Loss: 0.1030508\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0794703\n",
      "\tspeed: 0.0338s/iter; left time: 356.8066s\n",
      "\titers: 200, epoch: 53 | loss: 0.0759548\n",
      "\tspeed: 0.0135s/iter; left time: 140.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 222 | Train Loss: 0.0789999 Vali Loss: 0.0789349 Test Loss: 0.1028371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802278\n",
      "\tspeed: 0.0338s/iter; left time: 348.9989s\n",
      "\titers: 200, epoch: 54 | loss: 0.0752189\n",
      "\tspeed: 0.0196s/iter; left time: 200.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0792957 Vali Loss: 0.0788629 Test Loss: 0.1025980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0809674\n",
      "\tspeed: 0.0386s/iter; left time: 390.4257s\n",
      "\titers: 200, epoch: 55 | loss: 0.0801318\n",
      "\tspeed: 0.0221s/iter; left time: 221.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0790151 Vali Loss: 0.0788676 Test Loss: 0.1026907\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0795336\n",
      "\tspeed: 0.0412s/iter; left time: 407.1784s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784315\n",
      "\tspeed: 0.0188s/iter; left time: 183.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0790342 Vali Loss: 0.0788297 Test Loss: 0.1026216\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0769611\n",
      "\tspeed: 0.0421s/iter; left time: 406.9476s\n",
      "\titers: 200, epoch: 57 | loss: 0.0787185\n",
      "\tspeed: 0.0220s/iter; left time: 210.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0789022 Vali Loss: 0.0788922 Test Loss: 0.1029108\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0799873\n",
      "\tspeed: 0.0435s/iter; left time: 411.3040s\n",
      "\titers: 200, epoch: 58 | loss: 0.0774429\n",
      "\tspeed: 0.0181s/iter; left time: 169.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0797733 Vali Loss: 0.0790526 Test Loss: 0.1029665\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022674940526485443, rmse:0.15058200061321259, mae:0.1024748831987381, rse:0.4423646032810211\n",
      "Intermediate time for ES and pred_len 96: 00h:12m:18.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2752975\n",
      "\tspeed: 0.0504s/iter; left time: 1113.1489s\n",
      "\titers: 200, epoch: 1 | loss: 0.2628833\n",
      "\tspeed: 0.0245s/iter; left time: 540.0316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.2844597 Vali Loss: 0.2161710 Test Loss: 0.2390840\n",
      "Validation loss decreased (inf --> 0.216171).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1424186\n",
      "\tspeed: 0.0414s/iter; left time: 905.0575s\n",
      "\titers: 200, epoch: 2 | loss: 0.1192986\n",
      "\tspeed: 0.0231s/iter; left time: 503.0483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1557773 Vali Loss: 0.1054073 Test Loss: 0.1212500\n",
      "Validation loss decreased (0.216171 --> 0.105407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1097088\n",
      "\tspeed: 0.0362s/iter; left time: 784.2747s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013827\n",
      "\tspeed: 0.0134s/iter; left time: 288.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 222 | Train Loss: 0.1089300 Vali Loss: 0.0947460 Test Loss: 0.1189555\n",
      "Validation loss decreased (0.105407 --> 0.094746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0972929\n",
      "\tspeed: 0.0376s/iter; left time: 805.1637s\n",
      "\titers: 200, epoch: 4 | loss: 0.0936165\n",
      "\tspeed: 0.0181s/iter; left time: 387.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0985258 Vali Loss: 0.0916113 Test Loss: 0.1213326\n",
      "Validation loss decreased (0.094746 --> 0.091611).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0950370\n",
      "\tspeed: 0.0377s/iter; left time: 800.5678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0936327\n",
      "\tspeed: 0.0171s/iter; left time: 361.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0938632 Vali Loss: 0.0910431 Test Loss: 0.1281624\n",
      "Validation loss decreased (0.091611 --> 0.091043).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913503\n",
      "\tspeed: 0.0417s/iter; left time: 874.9500s\n",
      "\titers: 200, epoch: 6 | loss: 0.0894877\n",
      "\tspeed: 0.0216s/iter; left time: 451.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0910923 Vali Loss: 0.0887452 Test Loss: 0.1254068\n",
      "Validation loss decreased (0.091043 --> 0.088745).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927720\n",
      "\tspeed: 0.0336s/iter; left time: 698.4304s\n",
      "\titers: 200, epoch: 7 | loss: 0.0898243\n",
      "\tspeed: 0.0135s/iter; left time: 278.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 222 | Train Loss: 0.0894418 Vali Loss: 0.0876978 Test Loss: 0.1303841\n",
      "Validation loss decreased (0.088745 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0880019\n",
      "\tspeed: 0.0393s/iter; left time: 807.7157s\n",
      "\titers: 200, epoch: 8 | loss: 0.0857032\n",
      "\tspeed: 0.0223s/iter; left time: 456.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0886992 Vali Loss: 0.0885285 Test Loss: 0.1267102\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0909302\n",
      "\tspeed: 0.0407s/iter; left time: 827.6605s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866868\n",
      "\tspeed: 0.0196s/iter; left time: 396.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0884096 Vali Loss: 0.0879896 Test Loss: 0.1284705\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849414\n",
      "\tspeed: 0.0382s/iter; left time: 767.3014s\n",
      "\titers: 200, epoch: 10 | loss: 0.0871493\n",
      "\tspeed: 0.0243s/iter; left time: 485.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0869966 Vali Loss: 0.0876488 Test Loss: 0.1233509\n",
      "Validation loss decreased (0.087698 --> 0.087649).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0851709\n",
      "\tspeed: 0.0380s/iter; left time: 755.3783s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827767\n",
      "\tspeed: 0.0183s/iter; left time: 361.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0866055 Vali Loss: 0.0874294 Test Loss: 0.1247353\n",
      "Validation loss decreased (0.087649 --> 0.087429).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0890604\n",
      "\tspeed: 0.0390s/iter; left time: 767.4315s\n",
      "\titers: 200, epoch: 12 | loss: 0.0885759\n",
      "\tspeed: 0.0168s/iter; left time: 328.9863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0861026 Vali Loss: 0.0872539 Test Loss: 0.1288937\n",
      "Validation loss decreased (0.087429 --> 0.087254).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843443\n",
      "\tspeed: 0.0395s/iter; left time: 767.5971s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830567\n",
      "\tspeed: 0.0196s/iter; left time: 379.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0856770 Vali Loss: 0.0878993 Test Loss: 0.1245098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884936\n",
      "\tspeed: 0.0367s/iter; left time: 706.0566s\n",
      "\titers: 200, epoch: 14 | loss: 0.0858436\n",
      "\tspeed: 0.0176s/iter; left time: 335.5529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0857994 Vali Loss: 0.0867274 Test Loss: 0.1248544\n",
      "Validation loss decreased (0.087254 --> 0.086727).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0850908\n",
      "\tspeed: 0.0389s/iter; left time: 738.1524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837386\n",
      "\tspeed: 0.0171s/iter; left time: 323.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0852563 Vali Loss: 0.0865545 Test Loss: 0.1218124\n",
      "Validation loss decreased (0.086727 --> 0.086554).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865563\n",
      "\tspeed: 0.0440s/iter; left time: 825.7637s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827111\n",
      "\tspeed: 0.0189s/iter; left time: 352.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0849347 Vali Loss: 0.0868268 Test Loss: 0.1255154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0817033\n",
      "\tspeed: 0.0367s/iter; left time: 681.6594s\n",
      "\titers: 200, epoch: 17 | loss: 0.0859018\n",
      "\tspeed: 0.0176s/iter; left time: 325.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0846658 Vali Loss: 0.0860702 Test Loss: 0.1188532\n",
      "Validation loss decreased (0.086554 --> 0.086070).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0847445\n",
      "\tspeed: 0.0421s/iter; left time: 770.9378s\n",
      "\titers: 200, epoch: 18 | loss: 0.0858658\n",
      "\tspeed: 0.0182s/iter; left time: 331.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0844824 Vali Loss: 0.0862537 Test Loss: 0.1194086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0864146\n",
      "\tspeed: 0.0319s/iter; left time: 577.8085s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836390\n",
      "\tspeed: 0.0135s/iter; left time: 242.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 222 | Train Loss: 0.0845590 Vali Loss: 0.0858532 Test Loss: 0.1201577\n",
      "Validation loss decreased (0.086070 --> 0.085853).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0812541\n",
      "\tspeed: 0.0393s/iter; left time: 702.4562s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817963\n",
      "\tspeed: 0.0186s/iter; left time: 331.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0840212 Vali Loss: 0.0860785 Test Loss: 0.1225875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0852292\n",
      "\tspeed: 0.0390s/iter; left time: 689.4436s\n",
      "\titers: 200, epoch: 21 | loss: 0.0850305\n",
      "\tspeed: 0.0186s/iter; left time: 326.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0843181 Vali Loss: 0.0860471 Test Loss: 0.1155687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0892569\n",
      "\tspeed: 0.0372s/iter; left time: 649.4592s\n",
      "\titers: 200, epoch: 22 | loss: 0.0872808\n",
      "\tspeed: 0.0202s/iter; left time: 349.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0839909 Vali Loss: 0.0864659 Test Loss: 0.1188963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0801457\n",
      "\tspeed: 0.0357s/iter; left time: 613.8155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0822681\n",
      "\tspeed: 0.0167s/iter; left time: 285.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.0839554 Vali Loss: 0.0859948 Test Loss: 0.1183260\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0808729\n",
      "\tspeed: 0.0385s/iter; left time: 653.6121s\n",
      "\titers: 200, epoch: 24 | loss: 0.0849282\n",
      "\tspeed: 0.0205s/iter; left time: 345.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0837325 Vali Loss: 0.0857487 Test Loss: 0.1177279\n",
      "Validation loss decreased (0.085853 --> 0.085749).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0826968\n",
      "\tspeed: 0.0408s/iter; left time: 683.9449s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812131\n",
      "\tspeed: 0.0193s/iter; left time: 322.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0836089 Vali Loss: 0.0858979 Test Loss: 0.1185065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0807150\n",
      "\tspeed: 0.0391s/iter; left time: 647.5773s\n",
      "\titers: 200, epoch: 26 | loss: 0.0824572\n",
      "\tspeed: 0.0208s/iter; left time: 342.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0836004 Vali Loss: 0.0858044 Test Loss: 0.1179804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0878729\n",
      "\tspeed: 0.0370s/iter; left time: 603.6878s\n",
      "\titers: 200, epoch: 27 | loss: 0.0849801\n",
      "\tspeed: 0.0180s/iter; left time: 291.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0834172 Vali Loss: 0.0857046 Test Loss: 0.1182020\n",
      "Validation loss decreased (0.085749 --> 0.085705).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0838583\n",
      "\tspeed: 0.0385s/iter; left time: 620.5516s\n",
      "\titers: 200, epoch: 28 | loss: 0.0813059\n",
      "\tspeed: 0.0207s/iter; left time: 330.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0834919 Vali Loss: 0.0855824 Test Loss: 0.1166778\n",
      "Validation loss decreased (0.085705 --> 0.085582).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0836871\n",
      "\tspeed: 0.0398s/iter; left time: 632.6084s\n",
      "\titers: 200, epoch: 29 | loss: 0.0847755\n",
      "\tspeed: 0.0197s/iter; left time: 311.0812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0832610 Vali Loss: 0.0857332 Test Loss: 0.1181185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0813245\n",
      "\tspeed: 0.0357s/iter; left time: 559.4185s\n",
      "\titers: 200, epoch: 30 | loss: 0.0840964\n",
      "\tspeed: 0.0188s/iter; left time: 292.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0832914 Vali Loss: 0.0856515 Test Loss: 0.1181112\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0852700\n",
      "\tspeed: 0.0367s/iter; left time: 566.9244s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829485\n",
      "\tspeed: 0.0163s/iter; left time: 250.0498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0832763 Vali Loss: 0.0856775 Test Loss: 0.1183331\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0829257\n",
      "\tspeed: 0.0352s/iter; left time: 535.2760s\n",
      "\titers: 200, epoch: 32 | loss: 0.0838159\n",
      "\tspeed: 0.0203s/iter; left time: 306.4361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0831706 Vali Loss: 0.0858367 Test Loss: 0.1190393\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0832361\n",
      "\tspeed: 0.0393s/iter; left time: 589.7008s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795788\n",
      "\tspeed: 0.0191s/iter; left time: 283.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0831138 Vali Loss: 0.0857219 Test Loss: 0.1188055\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0816920\n",
      "\tspeed: 0.0409s/iter; left time: 603.8807s\n",
      "\titers: 200, epoch: 34 | loss: 0.0846989\n",
      "\tspeed: 0.0193s/iter; left time: 282.6024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0832282 Vali Loss: 0.0860768 Test Loss: 0.1201008\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0790423\n",
      "\tspeed: 0.0394s/iter; left time: 572.6743s\n",
      "\titers: 200, epoch: 35 | loss: 0.0868318\n",
      "\tspeed: 0.0172s/iter; left time: 248.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0831745 Vali Loss: 0.0857664 Test Loss: 0.1191104\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0847716\n",
      "\tspeed: 0.0364s/iter; left time: 521.2218s\n",
      "\titers: 200, epoch: 36 | loss: 0.0838767\n",
      "\tspeed: 0.0183s/iter; left time: 260.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0830319 Vali Loss: 0.0855974 Test Loss: 0.1190438\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0833445\n",
      "\tspeed: 0.0367s/iter; left time: 517.1635s\n",
      "\titers: 200, epoch: 37 | loss: 0.0856886\n",
      "\tspeed: 0.0222s/iter; left time: 310.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0831598 Vali Loss: 0.0855662 Test Loss: 0.1180077\n",
      "Validation loss decreased (0.085582 --> 0.085566).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0799515\n",
      "\tspeed: 0.0381s/iter; left time: 529.7804s\n",
      "\titers: 200, epoch: 38 | loss: 0.0826600\n",
      "\tspeed: 0.0184s/iter; left time: 253.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0829920 Vali Loss: 0.0855045 Test Loss: 0.1182730\n",
      "Validation loss decreased (0.085566 --> 0.085504).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0807335\n",
      "\tspeed: 0.0385s/iter; left time: 526.6604s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850193\n",
      "\tspeed: 0.0184s/iter; left time: 249.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0833037 Vali Loss: 0.0853972 Test Loss: 0.1170263\n",
      "Validation loss decreased (0.085504 --> 0.085397).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0820276\n",
      "\tspeed: 0.0411s/iter; left time: 552.1650s\n",
      "\titers: 200, epoch: 40 | loss: 0.0826481\n",
      "\tspeed: 0.0194s/iter; left time: 259.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0829577 Vali Loss: 0.0856202 Test Loss: 0.1181016\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0816047\n",
      "\tspeed: 0.0407s/iter; left time: 538.3335s\n",
      "\titers: 200, epoch: 41 | loss: 0.0825021\n",
      "\tspeed: 0.0204s/iter; left time: 268.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0829118 Vali Loss: 0.0856374 Test Loss: 0.1184959\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0808047\n",
      "\tspeed: 0.0374s/iter; left time: 486.6674s\n",
      "\titers: 200, epoch: 42 | loss: 0.0821543\n",
      "\tspeed: 0.0213s/iter; left time: 274.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0829277 Vali Loss: 0.0857129 Test Loss: 0.1180947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0831353\n",
      "\tspeed: 0.0330s/iter; left time: 421.3682s\n",
      "\titers: 200, epoch: 43 | loss: 0.0829241\n",
      "\tspeed: 0.0134s/iter; left time: 169.5534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 222 | Train Loss: 0.0830579 Vali Loss: 0.0854294 Test Loss: 0.1168746\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0778174\n",
      "\tspeed: 0.0375s/iter; left time: 471.4292s\n",
      "\titers: 200, epoch: 44 | loss: 0.0832195\n",
      "\tspeed: 0.0182s/iter; left time: 226.2397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0828615 Vali Loss: 0.0857532 Test Loss: 0.1190419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0844192\n",
      "\tspeed: 0.0390s/iter; left time: 480.4837s\n",
      "\titers: 200, epoch: 45 | loss: 0.0852992\n",
      "\tspeed: 0.0204s/iter; left time: 249.9692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0829083 Vali Loss: 0.0855670 Test Loss: 0.1176639\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0820408\n",
      "\tspeed: 0.0420s/iter; left time: 508.8963s\n",
      "\titers: 200, epoch: 46 | loss: 0.0804324\n",
      "\tspeed: 0.0189s/iter; left time: 227.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0830802 Vali Loss: 0.0856216 Test Loss: 0.1181498\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0838422\n",
      "\tspeed: 0.0362s/iter; left time: 430.2937s\n",
      "\titers: 200, epoch: 47 | loss: 0.0814822\n",
      "\tspeed: 0.0170s/iter; left time: 199.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0829183 Vali Loss: 0.0857322 Test Loss: 0.1184879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0838435\n",
      "\tspeed: 0.0346s/iter; left time: 403.9152s\n",
      "\titers: 200, epoch: 48 | loss: 0.0887901\n",
      "\tspeed: 0.0201s/iter; left time: 232.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0828074 Vali Loss: 0.0855418 Test Loss: 0.1179537\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0827551\n",
      "\tspeed: 0.0388s/iter; left time: 444.1623s\n",
      "\titers: 200, epoch: 49 | loss: 0.0847443\n",
      "\tspeed: 0.0200s/iter; left time: 226.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0830245 Vali Loss: 0.0855867 Test Loss: 0.1178466\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02988913655281067, rmse:0.1728847473859787, mae:0.11702635884284973, rse:0.5079198479652405\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2821897\n",
      "\tspeed: 0.0194s/iter; left time: 429.1733s\n",
      "\titers: 200, epoch: 1 | loss: 0.2662972\n",
      "\tspeed: 0.0216s/iter; left time: 475.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.2869222 Vali Loss: 0.2178283 Test Loss: 0.2410417\n",
      "Validation loss decreased (inf --> 0.217828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1402749\n",
      "\tspeed: 0.0345s/iter; left time: 754.4960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1170134\n",
      "\tspeed: 0.0134s/iter; left time: 292.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 222 | Train Loss: 0.1546210 Vali Loss: 0.1089054 Test Loss: 0.1258108\n",
      "Validation loss decreased (0.217828 --> 0.108905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089977\n",
      "\tspeed: 0.0420s/iter; left time: 910.1401s\n",
      "\titers: 200, epoch: 3 | loss: 0.1009634\n",
      "\tspeed: 0.0191s/iter; left time: 412.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1089586 Vali Loss: 0.0951688 Test Loss: 0.1160846\n",
      "Validation loss decreased (0.108905 --> 0.095169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0948937\n",
      "\tspeed: 0.0395s/iter; left time: 846.3265s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920056\n",
      "\tspeed: 0.0184s/iter; left time: 392.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0974960 Vali Loss: 0.0899071 Test Loss: 0.1197113\n",
      "Validation loss decreased (0.095169 --> 0.089907).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0886399\n",
      "\tspeed: 0.0385s/iter; left time: 816.6614s\n",
      "\titers: 200, epoch: 5 | loss: 0.0907884\n",
      "\tspeed: 0.0185s/iter; left time: 390.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0925229 Vali Loss: 0.0882349 Test Loss: 0.1198818\n",
      "Validation loss decreased (0.089907 --> 0.088235).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0976840\n",
      "\tspeed: 0.0409s/iter; left time: 858.3447s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848660\n",
      "\tspeed: 0.0187s/iter; left time: 390.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0902449 Vali Loss: 0.0874264 Test Loss: 0.1217533\n",
      "Validation loss decreased (0.088235 --> 0.087426).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0865841\n",
      "\tspeed: 0.0379s/iter; left time: 787.7721s\n",
      "\titers: 200, epoch: 7 | loss: 0.0873563\n",
      "\tspeed: 0.0176s/iter; left time: 363.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0897471 Vali Loss: 0.0867669 Test Loss: 0.1248483\n",
      "Validation loss decreased (0.087426 --> 0.086767).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843920\n",
      "\tspeed: 0.0445s/iter; left time: 913.9404s\n",
      "\titers: 200, epoch: 8 | loss: 0.0859653\n",
      "\tspeed: 0.0194s/iter; left time: 397.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0878318 Vali Loss: 0.0865790 Test Loss: 0.1223411\n",
      "Validation loss decreased (0.086767 --> 0.086579).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0863907\n",
      "\tspeed: 0.0341s/iter; left time: 692.2333s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878436\n",
      "\tspeed: 0.0135s/iter; left time: 272.5538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 222 | Train Loss: 0.0882253 Vali Loss: 0.0873237 Test Loss: 0.1209770\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0885530\n",
      "\tspeed: 0.0367s/iter; left time: 736.9745s\n",
      "\titers: 200, epoch: 10 | loss: 0.0851510\n",
      "\tspeed: 0.0181s/iter; left time: 362.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0867634 Vali Loss: 0.0861487 Test Loss: 0.1205170\n",
      "Validation loss decreased (0.086579 --> 0.086149).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0874344\n",
      "\tspeed: 0.0404s/iter; left time: 802.9139s\n",
      "\titers: 200, epoch: 11 | loss: 0.0863595\n",
      "\tspeed: 0.0184s/iter; left time: 363.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0872570 Vali Loss: 0.0868843 Test Loss: 0.1093109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830597\n",
      "\tspeed: 0.0393s/iter; left time: 772.1814s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851362\n",
      "\tspeed: 0.0181s/iter; left time: 354.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0860929 Vali Loss: 0.0858989 Test Loss: 0.1195716\n",
      "Validation loss decreased (0.086149 --> 0.085899).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843017\n",
      "\tspeed: 0.0420s/iter; left time: 816.8537s\n",
      "\titers: 200, epoch: 13 | loss: 0.0812857\n",
      "\tspeed: 0.0221s/iter; left time: 426.7235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.0854211 Vali Loss: 0.0858222 Test Loss: 0.1169128\n",
      "Validation loss decreased (0.085899 --> 0.085822).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841619\n",
      "\tspeed: 0.0416s/iter; left time: 800.1104s\n",
      "\titers: 200, epoch: 14 | loss: 0.0850563\n",
      "\tspeed: 0.0216s/iter; left time: 412.1496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0851428 Vali Loss: 0.0859217 Test Loss: 0.1162745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0841240\n",
      "\tspeed: 0.0393s/iter; left time: 747.1920s\n",
      "\titers: 200, epoch: 15 | loss: 0.0833289\n",
      "\tspeed: 0.0203s/iter; left time: 383.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0850074 Vali Loss: 0.0865957 Test Loss: 0.1217066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0830861\n",
      "\tspeed: 0.0416s/iter; left time: 780.5243s\n",
      "\titers: 200, epoch: 16 | loss: 0.0840037\n",
      "\tspeed: 0.0219s/iter; left time: 409.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0851832 Vali Loss: 0.0857930 Test Loss: 0.1104908\n",
      "Validation loss decreased (0.085822 --> 0.085793).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0843337\n",
      "\tspeed: 0.0383s/iter; left time: 709.7465s\n",
      "\titers: 200, epoch: 17 | loss: 0.0852274\n",
      "\tspeed: 0.0173s/iter; left time: 319.2810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0847358 Vali Loss: 0.0859714 Test Loss: 0.1197677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0847530\n",
      "\tspeed: 0.0405s/iter; left time: 741.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827119\n",
      "\tspeed: 0.0189s/iter; left time: 345.2018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0849122 Vali Loss: 0.0861478 Test Loss: 0.1128591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0878472\n",
      "\tspeed: 0.0397s/iter; left time: 718.9452s\n",
      "\titers: 200, epoch: 19 | loss: 0.0837518\n",
      "\tspeed: 0.0205s/iter; left time: 369.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0843614 Vali Loss: 0.0858992 Test Loss: 0.1152965\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0821137\n",
      "\tspeed: 0.0404s/iter; left time: 722.6561s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824019\n",
      "\tspeed: 0.0202s/iter; left time: 358.4489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0840971 Vali Loss: 0.0856594 Test Loss: 0.1176547\n",
      "Validation loss decreased (0.085793 --> 0.085659).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0854850\n",
      "\tspeed: 0.0384s/iter; left time: 679.0228s\n",
      "\titers: 200, epoch: 21 | loss: 0.0865156\n",
      "\tspeed: 0.0179s/iter; left time: 314.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0839960 Vali Loss: 0.0860197 Test Loss: 0.1178863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0861932\n",
      "\tspeed: 0.0375s/iter; left time: 654.2753s\n",
      "\titers: 200, epoch: 22 | loss: 0.0849553\n",
      "\tspeed: 0.0134s/iter; left time: 231.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0839448 Vali Loss: 0.0856153 Test Loss: 0.1129521\n",
      "Validation loss decreased (0.085659 --> 0.085615).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0820616\n",
      "\tspeed: 0.0406s/iter; left time: 698.1552s\n",
      "\titers: 200, epoch: 23 | loss: 0.0854930\n",
      "\tspeed: 0.0185s/iter; left time: 316.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0840585 Vali Loss: 0.0858276 Test Loss: 0.1156647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0851940\n",
      "\tspeed: 0.0391s/iter; left time: 665.0540s\n",
      "\titers: 200, epoch: 24 | loss: 0.0842922\n",
      "\tspeed: 0.0188s/iter; left time: 317.5470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0837446 Vali Loss: 0.0858859 Test Loss: 0.1151031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0862199\n",
      "\tspeed: 0.0372s/iter; left time: 623.4888s\n",
      "\titers: 200, epoch: 25 | loss: 0.0840616\n",
      "\tspeed: 0.0201s/iter; left time: 334.4997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0838487 Vali Loss: 0.0854888 Test Loss: 0.1125921\n",
      "Validation loss decreased (0.085615 --> 0.085489).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0849226\n",
      "\tspeed: 0.0378s/iter; left time: 626.0138s\n",
      "\titers: 200, epoch: 26 | loss: 0.0828406\n",
      "\tspeed: 0.0161s/iter; left time: 265.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0835528 Vali Loss: 0.0856917 Test Loss: 0.1148463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0807310\n",
      "\tspeed: 0.0336s/iter; left time: 548.5956s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837605\n",
      "\tspeed: 0.0134s/iter; left time: 217.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 222 | Train Loss: 0.0835648 Vali Loss: 0.0856213 Test Loss: 0.1142073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0844091\n",
      "\tspeed: 0.0367s/iter; left time: 591.8764s\n",
      "\titers: 200, epoch: 28 | loss: 0.0845645\n",
      "\tspeed: 0.0183s/iter; left time: 292.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0834028 Vali Loss: 0.0856825 Test Loss: 0.1177439\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0843583\n",
      "\tspeed: 0.0379s/iter; left time: 602.6693s\n",
      "\titers: 200, epoch: 29 | loss: 0.0869262\n",
      "\tspeed: 0.0188s/iter; left time: 296.8410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0833694 Vali Loss: 0.0854174 Test Loss: 0.1140677\n",
      "Validation loss decreased (0.085489 --> 0.085417).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0819029\n",
      "\tspeed: 0.0411s/iter; left time: 644.0138s\n",
      "\titers: 200, epoch: 30 | loss: 0.0824094\n",
      "\tspeed: 0.0201s/iter; left time: 312.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0833229 Vali Loss: 0.0855661 Test Loss: 0.1136627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0805220\n",
      "\tspeed: 0.0436s/iter; left time: 673.1444s\n",
      "\titers: 200, epoch: 31 | loss: 0.0854735\n",
      "\tspeed: 0.0237s/iter; left time: 363.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 222 | Train Loss: 0.0834485 Vali Loss: 0.0855906 Test Loss: 0.1148575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0856634\n",
      "\tspeed: 0.0450s/iter; left time: 684.9970s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857480\n",
      "\tspeed: 0.0200s/iter; left time: 302.8922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0831953 Vali Loss: 0.0855765 Test Loss: 0.1134769\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0844713\n",
      "\tspeed: 0.0397s/iter; left time: 595.5817s\n",
      "\titers: 200, epoch: 33 | loss: 0.0828239\n",
      "\tspeed: 0.0202s/iter; left time: 301.6573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0832462 Vali Loss: 0.0855763 Test Loss: 0.1142933\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0818999\n",
      "\tspeed: 0.0399s/iter; left time: 588.8936s\n",
      "\titers: 200, epoch: 34 | loss: 0.0871794\n",
      "\tspeed: 0.0179s/iter; left time: 262.7691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0831211 Vali Loss: 0.0857023 Test Loss: 0.1149117\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0847295\n",
      "\tspeed: 0.0402s/iter; left time: 584.5972s\n",
      "\titers: 200, epoch: 35 | loss: 0.0877135\n",
      "\tspeed: 0.0186s/iter; left time: 269.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0832192 Vali Loss: 0.0856881 Test Loss: 0.1154160\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0835417\n",
      "\tspeed: 0.0397s/iter; left time: 568.5520s\n",
      "\titers: 200, epoch: 36 | loss: 0.0807922\n",
      "\tspeed: 0.0134s/iter; left time: 190.8696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0830666 Vali Loss: 0.0854562 Test Loss: 0.1146717\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815550\n",
      "\tspeed: 0.0367s/iter; left time: 517.6188s\n",
      "\titers: 200, epoch: 37 | loss: 0.0827467\n",
      "\tspeed: 0.0193s/iter; left time: 269.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0830627 Vali Loss: 0.0855188 Test Loss: 0.1143365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0831372\n",
      "\tspeed: 0.0368s/iter; left time: 510.8907s\n",
      "\titers: 200, epoch: 38 | loss: 0.0816436\n",
      "\tspeed: 0.0183s/iter; left time: 252.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0829982 Vali Loss: 0.0853280 Test Loss: 0.1141640\n",
      "Validation loss decreased (0.085417 --> 0.085328).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0828349\n",
      "\tspeed: 0.0396s/iter; left time: 541.6109s\n",
      "\titers: 200, epoch: 39 | loss: 0.0799944\n",
      "\tspeed: 0.0190s/iter; left time: 257.9936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0831050 Vali Loss: 0.0855138 Test Loss: 0.1142776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0838986\n",
      "\tspeed: 0.0371s/iter; left time: 499.2472s\n",
      "\titers: 200, epoch: 40 | loss: 0.0845640\n",
      "\tspeed: 0.0181s/iter; left time: 241.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0830937 Vali Loss: 0.0854541 Test Loss: 0.1141114\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0808545\n",
      "\tspeed: 0.0393s/iter; left time: 519.3387s\n",
      "\titers: 200, epoch: 41 | loss: 0.0814568\n",
      "\tspeed: 0.0180s/iter; left time: 236.3247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0829372 Vali Loss: 0.0854409 Test Loss: 0.1140873\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0817157\n",
      "\tspeed: 0.0388s/iter; left time: 504.2048s\n",
      "\titers: 200, epoch: 42 | loss: 0.0828290\n",
      "\tspeed: 0.0177s/iter; left time: 227.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0831038 Vali Loss: 0.0856674 Test Loss: 0.1147176\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0826415\n",
      "\tspeed: 0.0366s/iter; left time: 467.4840s\n",
      "\titers: 200, epoch: 43 | loss: 0.0856394\n",
      "\tspeed: 0.0182s/iter; left time: 230.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0829656 Vali Loss: 0.0856309 Test Loss: 0.1150501\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0838955\n",
      "\tspeed: 0.0368s/iter; left time: 461.8434s\n",
      "\titers: 200, epoch: 44 | loss: 0.0803811\n",
      "\tspeed: 0.0134s/iter; left time: 167.1044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 222 | Train Loss: 0.0829090 Vali Loss: 0.0854407 Test Loss: 0.1149802\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0877293\n",
      "\tspeed: 0.0390s/iter; left time: 480.7597s\n",
      "\titers: 200, epoch: 45 | loss: 0.0817341\n",
      "\tspeed: 0.0210s/iter; left time: 256.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0830114 Vali Loss: 0.0854746 Test Loss: 0.1146787\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0807717\n",
      "\tspeed: 0.0367s/iter; left time: 444.1405s\n",
      "\titers: 200, epoch: 46 | loss: 0.0828474\n",
      "\tspeed: 0.0165s/iter; left time: 197.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0828582 Vali Loss: 0.0854172 Test Loss: 0.1140642\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0841669\n",
      "\tspeed: 0.0396s/iter; left time: 471.3590s\n",
      "\titers: 200, epoch: 47 | loss: 0.0829546\n",
      "\tspeed: 0.0185s/iter; left time: 217.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0831731 Vali Loss: 0.0854332 Test Loss: 0.1138964\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0812709\n",
      "\tspeed: 0.0376s/iter; left time: 438.8038s\n",
      "\titers: 200, epoch: 48 | loss: 0.0801140\n",
      "\tspeed: 0.0177s/iter; left time: 204.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0836791 Vali Loss: 0.0855523 Test Loss: 0.1143685\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0276211965829134, rmse:0.16619625687599182, mae:0.11416394263505936, rse:0.4882696568965912\n",
      "Intermediate time for ES and pred_len 168: 00h:09m:30.71s\n",
      "Intermediate time for ES: 00h:32m:52.11s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2236021\n",
      "\tspeed: 0.0427s/iter; left time: 947.3003s\n",
      "\titers: 200, epoch: 1 | loss: 0.2074823\n",
      "\tspeed: 0.0168s/iter; left time: 371.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.2296431 Vali Loss: 0.1732810 Test Loss: 0.1809211\n",
      "Validation loss decreased (inf --> 0.173281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1360764\n",
      "\tspeed: 0.0323s/iter; left time: 710.7834s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070553\n",
      "\tspeed: 0.0172s/iter; left time: 376.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.1396844 Vali Loss: 0.0805110 Test Loss: 0.0888648\n",
      "Validation loss decreased (0.173281 --> 0.080511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0867475\n",
      "\tspeed: 0.0341s/iter; left time: 741.4344s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819789\n",
      "\tspeed: 0.0180s/iter; left time: 390.5636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0886421 Vali Loss: 0.0758004 Test Loss: 0.0803676\n",
      "Validation loss decreased (0.080511 --> 0.075800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0735695\n",
      "\tspeed: 0.0354s/iter; left time: 762.9958s\n",
      "\titers: 200, epoch: 4 | loss: 0.0739823\n",
      "\tspeed: 0.0174s/iter; left time: 372.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0747412 Vali Loss: 0.0700433 Test Loss: 0.0733856\n",
      "Validation loss decreased (0.075800 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643737\n",
      "\tspeed: 0.0375s/iter; left time: 798.3683s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621697\n",
      "\tspeed: 0.0167s/iter; left time: 355.1702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0664498 Vali Loss: 0.0659719 Test Loss: 0.0682993\n",
      "Validation loss decreased (0.070043 --> 0.065972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638608\n",
      "\tspeed: 0.0341s/iter; left time: 718.8188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0557668\n",
      "\tspeed: 0.0174s/iter; left time: 364.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0618227 Vali Loss: 0.0629342 Test Loss: 0.0657877\n",
      "Validation loss decreased (0.065972 --> 0.062934).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0578528\n",
      "\tspeed: 0.0372s/iter; left time: 776.9854s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585506\n",
      "\tspeed: 0.0209s/iter; left time: 433.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0590780 Vali Loss: 0.0619209 Test Loss: 0.0649757\n",
      "Validation loss decreased (0.062934 --> 0.061921).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575072\n",
      "\tspeed: 0.0354s/iter; left time: 730.4266s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558983\n",
      "\tspeed: 0.0192s/iter; left time: 394.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0568973 Vali Loss: 0.0624090 Test Loss: 0.0652848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570882\n",
      "\tspeed: 0.0366s/iter; left time: 746.8147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0554337\n",
      "\tspeed: 0.0205s/iter; left time: 417.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0553634 Vali Loss: 0.0605830 Test Loss: 0.0639263\n",
      "Validation loss decreased (0.061921 --> 0.060583).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0517657\n",
      "\tspeed: 0.0327s/iter; left time: 659.9931s\n",
      "\titers: 200, epoch: 10 | loss: 0.0521178\n",
      "\tspeed: 0.0150s/iter; left time: 302.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 223 | Train Loss: 0.0543636 Vali Loss: 0.0603368 Test Loss: 0.0634552\n",
      "Validation loss decreased (0.060583 --> 0.060337).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0519553\n",
      "\tspeed: 0.0386s/iter; left time: 770.1292s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556286\n",
      "\tspeed: 0.0133s/iter; left time: 263.5676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0535645 Vali Loss: 0.0599187 Test Loss: 0.0630554\n",
      "Validation loss decreased (0.060337 --> 0.059919).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0516504\n",
      "\tspeed: 0.0354s/iter; left time: 698.4716s\n",
      "\titers: 200, epoch: 12 | loss: 0.0534213\n",
      "\tspeed: 0.0176s/iter; left time: 345.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0529137 Vali Loss: 0.0594783 Test Loss: 0.0625498\n",
      "Validation loss decreased (0.059919 --> 0.059478).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0555475\n",
      "\tspeed: 0.0378s/iter; left time: 737.6291s\n",
      "\titers: 200, epoch: 13 | loss: 0.0584816\n",
      "\tspeed: 0.0190s/iter; left time: 369.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0524057 Vali Loss: 0.0593581 Test Loss: 0.0624754\n",
      "Validation loss decreased (0.059478 --> 0.059358).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542893\n",
      "\tspeed: 0.0375s/iter; left time: 724.2214s\n",
      "\titers: 200, epoch: 14 | loss: 0.0534149\n",
      "\tspeed: 0.0201s/iter; left time: 386.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0519929 Vali Loss: 0.0595860 Test Loss: 0.0625940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0527701\n",
      "\tspeed: 0.0400s/iter; left time: 762.4159s\n",
      "\titers: 200, epoch: 15 | loss: 0.0493728\n",
      "\tspeed: 0.0223s/iter; left time: 422.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0517307 Vali Loss: 0.0589212 Test Loss: 0.0621964\n",
      "Validation loss decreased (0.059358 --> 0.058921).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0520452\n",
      "\tspeed: 0.0361s/iter; left time: 680.1420s\n",
      "\titers: 200, epoch: 16 | loss: 0.0459705\n",
      "\tspeed: 0.0202s/iter; left time: 379.1528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0514461 Vali Loss: 0.0589452 Test Loss: 0.0618999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0505355\n",
      "\tspeed: 0.0371s/iter; left time: 691.5858s\n",
      "\titers: 200, epoch: 17 | loss: 0.0472499\n",
      "\tspeed: 0.0176s/iter; left time: 327.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0511582 Vali Loss: 0.0588045 Test Loss: 0.0617049\n",
      "Validation loss decreased (0.058921 --> 0.058804).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0510904\n",
      "\tspeed: 0.0362s/iter; left time: 667.2977s\n",
      "\titers: 200, epoch: 18 | loss: 0.0490897\n",
      "\tspeed: 0.0168s/iter; left time: 307.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0509984 Vali Loss: 0.0584419 Test Loss: 0.0615125\n",
      "Validation loss decreased (0.058804 --> 0.058442).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543168\n",
      "\tspeed: 0.0362s/iter; left time: 658.5807s\n",
      "\titers: 200, epoch: 19 | loss: 0.0495084\n",
      "\tspeed: 0.0180s/iter; left time: 325.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0507014 Vali Loss: 0.0585291 Test Loss: 0.0615802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0476689\n",
      "\tspeed: 0.0365s/iter; left time: 656.1062s\n",
      "\titers: 200, epoch: 20 | loss: 0.0483478\n",
      "\tspeed: 0.0180s/iter; left time: 322.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0504669 Vali Loss: 0.0584182 Test Loss: 0.0615142\n",
      "Validation loss decreased (0.058442 --> 0.058418).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0530382\n",
      "\tspeed: 0.0380s/iter; left time: 674.7346s\n",
      "\titers: 200, epoch: 21 | loss: 0.0502974\n",
      "\tspeed: 0.0191s/iter; left time: 337.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0504094 Vali Loss: 0.0584650 Test Loss: 0.0613061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0517241\n",
      "\tspeed: 0.0361s/iter; left time: 631.9328s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502089\n",
      "\tspeed: 0.0172s/iter; left time: 299.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0504444 Vali Loss: 0.0588497 Test Loss: 0.0620846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0514007\n",
      "\tspeed: 0.0406s/iter; left time: 701.6766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0492585\n",
      "\tspeed: 0.0183s/iter; left time: 314.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0500185 Vali Loss: 0.0583586 Test Loss: 0.0614094\n",
      "Validation loss decreased (0.058418 --> 0.058359).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0496051\n",
      "\tspeed: 0.0344s/iter; left time: 587.4658s\n",
      "\titers: 200, epoch: 24 | loss: 0.0515021\n",
      "\tspeed: 0.0180s/iter; left time: 305.7747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0501878 Vali Loss: 0.0579947 Test Loss: 0.0611901\n",
      "Validation loss decreased (0.058359 --> 0.057995).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0468790\n",
      "\tspeed: 0.0363s/iter; left time: 611.7351s\n",
      "\titers: 200, epoch: 25 | loss: 0.0514483\n",
      "\tspeed: 0.0199s/iter; left time: 333.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0498330 Vali Loss: 0.0578034 Test Loss: 0.0610533\n",
      "Validation loss decreased (0.057995 --> 0.057803).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0520252\n",
      "\tspeed: 0.0385s/iter; left time: 639.6575s\n",
      "\titers: 200, epoch: 26 | loss: 0.0486651\n",
      "\tspeed: 0.0188s/iter; left time: 310.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0498788 Vali Loss: 0.0577818 Test Loss: 0.0609126\n",
      "Validation loss decreased (0.057803 --> 0.057782).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0510661\n",
      "\tspeed: 0.0383s/iter; left time: 628.1147s\n",
      "\titers: 200, epoch: 27 | loss: 0.0510372\n",
      "\tspeed: 0.0199s/iter; left time: 323.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0496795 Vali Loss: 0.0577717 Test Loss: 0.0609448\n",
      "Validation loss decreased (0.057782 --> 0.057772).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0492486\n",
      "\tspeed: 0.0387s/iter; left time: 625.8706s\n",
      "\titers: 200, epoch: 28 | loss: 0.0490624\n",
      "\tspeed: 0.0216s/iter; left time: 348.0662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0497134 Vali Loss: 0.0577583 Test Loss: 0.0608637\n",
      "Validation loss decreased (0.057772 --> 0.057758).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0447029\n",
      "\tspeed: 0.0376s/iter; left time: 600.4902s\n",
      "\titers: 200, epoch: 29 | loss: 0.0518960\n",
      "\tspeed: 0.0199s/iter; left time: 315.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0494149 Vali Loss: 0.0578336 Test Loss: 0.0609054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0467443\n",
      "\tspeed: 0.0400s/iter; left time: 628.7197s\n",
      "\titers: 200, epoch: 30 | loss: 0.0528328\n",
      "\tspeed: 0.0198s/iter; left time: 309.4360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0495071 Vali Loss: 0.0576725 Test Loss: 0.0608237\n",
      "Validation loss decreased (0.057758 --> 0.057673).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525649\n",
      "\tspeed: 0.0377s/iter; left time: 584.9170s\n",
      "\titers: 200, epoch: 31 | loss: 0.0509100\n",
      "\tspeed: 0.0178s/iter; left time: 274.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0496710 Vali Loss: 0.0578038 Test Loss: 0.0610071\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0497216\n",
      "\tspeed: 0.0318s/iter; left time: 486.5862s\n",
      "\titers: 200, epoch: 32 | loss: 0.0518590\n",
      "\tspeed: 0.0185s/iter; left time: 280.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0493097 Vali Loss: 0.0579932 Test Loss: 0.0611472\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0471173\n",
      "\tspeed: 0.0348s/iter; left time: 524.7962s\n",
      "\titers: 200, epoch: 33 | loss: 0.0510127\n",
      "\tspeed: 0.0175s/iter; left time: 262.6068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0496982 Vali Loss: 0.0577739 Test Loss: 0.0608639\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0507986\n",
      "\tspeed: 0.0360s/iter; left time: 534.3731s\n",
      "\titers: 200, epoch: 34 | loss: 0.0460285\n",
      "\tspeed: 0.0169s/iter; left time: 249.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0494031 Vali Loss: 0.0576002 Test Loss: 0.0606971\n",
      "Validation loss decreased (0.057673 --> 0.057600).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532590\n",
      "\tspeed: 0.0372s/iter; left time: 543.3926s\n",
      "\titers: 200, epoch: 35 | loss: 0.0478990\n",
      "\tspeed: 0.0174s/iter; left time: 252.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0491909 Vali Loss: 0.0575724 Test Loss: 0.0607575\n",
      "Validation loss decreased (0.057600 --> 0.057572).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536563\n",
      "\tspeed: 0.0353s/iter; left time: 507.4604s\n",
      "\titers: 200, epoch: 36 | loss: 0.0494200\n",
      "\tspeed: 0.0173s/iter; left time: 247.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0493233 Vali Loss: 0.0574575 Test Loss: 0.0607408\n",
      "Validation loss decreased (0.057572 --> 0.057457).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0514181\n",
      "\tspeed: 0.0345s/iter; left time: 489.2100s\n",
      "\titers: 200, epoch: 37 | loss: 0.0520622\n",
      "\tspeed: 0.0164s/iter; left time: 230.7053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0493328 Vali Loss: 0.0575636 Test Loss: 0.0608380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0469239\n",
      "\tspeed: 0.0345s/iter; left time: 481.2345s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513847\n",
      "\tspeed: 0.0165s/iter; left time: 228.2568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0491634 Vali Loss: 0.0575453 Test Loss: 0.0607609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0485902\n",
      "\tspeed: 0.0369s/iter; left time: 507.1305s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522214\n",
      "\tspeed: 0.0213s/iter; left time: 289.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0491197 Vali Loss: 0.0574916 Test Loss: 0.0606667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0508878\n",
      "\tspeed: 0.0400s/iter; left time: 539.8359s\n",
      "\titers: 200, epoch: 40 | loss: 0.0510726\n",
      "\tspeed: 0.0195s/iter; left time: 260.9940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0491322 Vali Loss: 0.0574877 Test Loss: 0.0606639\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0474850\n",
      "\tspeed: 0.0405s/iter; left time: 537.8864s\n",
      "\titers: 200, epoch: 41 | loss: 0.0489669\n",
      "\tspeed: 0.0217s/iter; left time: 286.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0490654 Vali Loss: 0.0574554 Test Loss: 0.0606490\n",
      "Validation loss decreased (0.057457 --> 0.057455).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0482732\n",
      "\tspeed: 0.0386s/iter; left time: 503.9795s\n",
      "\titers: 200, epoch: 42 | loss: 0.0486201\n",
      "\tspeed: 0.0171s/iter; left time: 221.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0491024 Vali Loss: 0.0575753 Test Loss: 0.0607962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0493894\n",
      "\tspeed: 0.0369s/iter; left time: 473.7748s\n",
      "\titers: 200, epoch: 43 | loss: 0.0455434\n",
      "\tspeed: 0.0198s/iter; left time: 252.2896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0491048 Vali Loss: 0.0574100 Test Loss: 0.0606996\n",
      "Validation loss decreased (0.057455 --> 0.057410).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0484123\n",
      "\tspeed: 0.0405s/iter; left time: 511.3028s\n",
      "\titers: 200, epoch: 44 | loss: 0.0515075\n",
      "\tspeed: 0.0227s/iter; left time: 284.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0490080 Vali Loss: 0.0574107 Test Loss: 0.0606340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0502327\n",
      "\tspeed: 0.0369s/iter; left time: 457.2663s\n",
      "\titers: 200, epoch: 45 | loss: 0.0473230\n",
      "\tspeed: 0.0171s/iter; left time: 210.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0489649 Vali Loss: 0.0574543 Test Loss: 0.0607070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0476432\n",
      "\tspeed: 0.0306s/iter; left time: 372.1266s\n",
      "\titers: 200, epoch: 46 | loss: 0.0520346\n",
      "\tspeed: 0.0153s/iter; left time: 184.7466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 223 | Train Loss: 0.0490683 Vali Loss: 0.0573822 Test Loss: 0.0606217\n",
      "Validation loss decreased (0.057410 --> 0.057382).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0490245\n",
      "\tspeed: 0.0367s/iter; left time: 437.8045s\n",
      "\titers: 200, epoch: 47 | loss: 0.0538171\n",
      "\tspeed: 0.0202s/iter; left time: 239.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0489807 Vali Loss: 0.0572679 Test Loss: 0.0605518\n",
      "Validation loss decreased (0.057382 --> 0.057268).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0475258\n",
      "\tspeed: 0.0389s/iter; left time: 455.9066s\n",
      "\titers: 200, epoch: 48 | loss: 0.0465208\n",
      "\tspeed: 0.0186s/iter; left time: 216.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0491117 Vali Loss: 0.0573993 Test Loss: 0.0606615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0471503\n",
      "\tspeed: 0.0345s/iter; left time: 396.8414s\n",
      "\titers: 200, epoch: 49 | loss: 0.0496441\n",
      "\tspeed: 0.0163s/iter; left time: 185.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0489702 Vali Loss: 0.0574515 Test Loss: 0.0606550\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0499291\n",
      "\tspeed: 0.0354s/iter; left time: 398.5626s\n",
      "\titers: 200, epoch: 50 | loss: 0.0515318\n",
      "\tspeed: 0.0191s/iter; left time: 213.5644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0490966 Vali Loss: 0.0574057 Test Loss: 0.0606869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0453082\n",
      "\tspeed: 0.0366s/iter; left time: 404.3097s\n",
      "\titers: 200, epoch: 51 | loss: 0.0507189\n",
      "\tspeed: 0.0191s/iter; left time: 209.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0490981 Vali Loss: 0.0574868 Test Loss: 0.0607159\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0471148\n",
      "\tspeed: 0.0360s/iter; left time: 389.9318s\n",
      "\titers: 200, epoch: 52 | loss: 0.0459591\n",
      "\tspeed: 0.0187s/iter; left time: 200.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0489687 Vali Loss: 0.0573664 Test Loss: 0.0605892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0502054\n",
      "\tspeed: 0.0359s/iter; left time: 380.9478s\n",
      "\titers: 200, epoch: 53 | loss: 0.0481141\n",
      "\tspeed: 0.0195s/iter; left time: 204.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0489371 Vali Loss: 0.0574584 Test Loss: 0.0607231\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0486371\n",
      "\tspeed: 0.0350s/iter; left time: 363.0994s\n",
      "\titers: 200, epoch: 54 | loss: 0.0518243\n",
      "\tspeed: 0.0195s/iter; left time: 200.2718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0490533 Vali Loss: 0.0573801 Test Loss: 0.0607377\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0500921\n",
      "\tspeed: 0.0373s/iter; left time: 379.4357s\n",
      "\titers: 200, epoch: 55 | loss: 0.0491087\n",
      "\tspeed: 0.0197s/iter; left time: 198.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0489493 Vali Loss: 0.0574722 Test Loss: 0.0607315\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0487431\n",
      "\tspeed: 0.0362s/iter; left time: 359.7060s\n",
      "\titers: 200, epoch: 56 | loss: 0.0509029\n",
      "\tspeed: 0.0184s/iter; left time: 181.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0489758 Vali Loss: 0.0574516 Test Loss: 0.0606661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0471308\n",
      "\tspeed: 0.0369s/iter; left time: 358.7243s\n",
      "\titers: 200, epoch: 57 | loss: 0.0509828\n",
      "\tspeed: 0.0169s/iter; left time: 162.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0489801 Vali Loss: 0.0575116 Test Loss: 0.0607592\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011035501956939697, rmse:0.1050499975681305, mae:0.06055183708667755, rse:0.4052799940109253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2229232\n",
      "\tspeed: 0.0235s/iter; left time: 521.7726s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131954\n",
      "\tspeed: 0.0225s/iter; left time: 497.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.2279222 Vali Loss: 0.1772987 Test Loss: 0.1836136\n",
      "Validation loss decreased (inf --> 0.177299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1249637\n",
      "\tspeed: 0.0380s/iter; left time: 835.8641s\n",
      "\titers: 200, epoch: 2 | loss: 0.0974508\n",
      "\tspeed: 0.0175s/iter; left time: 383.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1351827 Vali Loss: 0.0813727 Test Loss: 0.0883006\n",
      "Validation loss decreased (0.177299 --> 0.081373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0826826\n",
      "\tspeed: 0.0360s/iter; left time: 783.9689s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779804\n",
      "\tspeed: 0.0169s/iter; left time: 366.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0842363 Vali Loss: 0.0744897 Test Loss: 0.0781360\n",
      "Validation loss decreased (0.081373 --> 0.074490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733077\n",
      "\tspeed: 0.0374s/iter; left time: 805.0323s\n",
      "\titers: 200, epoch: 4 | loss: 0.0706052\n",
      "\tspeed: 0.0195s/iter; left time: 418.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0731312 Vali Loss: 0.0680141 Test Loss: 0.0700743\n",
      "Validation loss decreased (0.074490 --> 0.068014).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646106\n",
      "\tspeed: 0.0382s/iter; left time: 813.6873s\n",
      "\titers: 200, epoch: 5 | loss: 0.0675028\n",
      "\tspeed: 0.0214s/iter; left time: 452.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0650462 Vali Loss: 0.0643297 Test Loss: 0.0671408\n",
      "Validation loss decreased (0.068014 --> 0.064330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591188\n",
      "\tspeed: 0.0388s/iter; left time: 818.9721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0710175\n",
      "\tspeed: 0.0180s/iter; left time: 376.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0620537 Vali Loss: 0.0625399 Test Loss: 0.0661575\n",
      "Validation loss decreased (0.064330 --> 0.062540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595751\n",
      "\tspeed: 0.0392s/iter; left time: 817.1998s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573575\n",
      "\tspeed: 0.0208s/iter; left time: 432.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0584189 Vali Loss: 0.0616645 Test Loss: 0.0645398\n",
      "Validation loss decreased (0.062540 --> 0.061665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0562228\n",
      "\tspeed: 0.0385s/iter; left time: 795.3514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0559921\n",
      "\tspeed: 0.0180s/iter; left time: 369.2383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0567347 Vali Loss: 0.0625339 Test Loss: 0.0649768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550645\n",
      "\tspeed: 0.0375s/iter; left time: 766.3855s\n",
      "\titers: 200, epoch: 9 | loss: 0.0569895\n",
      "\tspeed: 0.0201s/iter; left time: 409.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0553669 Vali Loss: 0.0608301 Test Loss: 0.0641775\n",
      "Validation loss decreased (0.061665 --> 0.060830).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544550\n",
      "\tspeed: 0.0361s/iter; left time: 728.5037s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551585\n",
      "\tspeed: 0.0209s/iter; left time: 419.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0541188 Vali Loss: 0.0601871 Test Loss: 0.0634924\n",
      "Validation loss decreased (0.060830 --> 0.060187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517126\n",
      "\tspeed: 0.0385s/iter; left time: 769.2133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0560879\n",
      "\tspeed: 0.0189s/iter; left time: 375.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0533662 Vali Loss: 0.0604781 Test Loss: 0.0635637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0528089\n",
      "\tspeed: 0.0356s/iter; left time: 703.7635s\n",
      "\titers: 200, epoch: 12 | loss: 0.0517684\n",
      "\tspeed: 0.0132s/iter; left time: 260.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0528128 Vali Loss: 0.0597733 Test Loss: 0.0627881\n",
      "Validation loss decreased (0.060187 --> 0.059773).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540974\n",
      "\tspeed: 0.0316s/iter; left time: 617.3687s\n",
      "\titers: 200, epoch: 13 | loss: 0.0540248\n",
      "\tspeed: 0.0181s/iter; left time: 351.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0521770 Vali Loss: 0.0591646 Test Loss: 0.0623447\n",
      "Validation loss decreased (0.059773 --> 0.059165).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0499439\n",
      "\tspeed: 0.0334s/iter; left time: 643.8574s\n",
      "\titers: 200, epoch: 14 | loss: 0.0532585\n",
      "\tspeed: 0.0133s/iter; left time: 254.8319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 223 | Train Loss: 0.0519601 Vali Loss: 0.0590841 Test Loss: 0.0623380\n",
      "Validation loss decreased (0.059165 --> 0.059084).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0540655\n",
      "\tspeed: 0.0364s/iter; left time: 695.2376s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485856\n",
      "\tspeed: 0.0199s/iter; left time: 377.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0519877 Vali Loss: 0.0587647 Test Loss: 0.0620551\n",
      "Validation loss decreased (0.059084 --> 0.058765).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0538359\n",
      "\tspeed: 0.0378s/iter; left time: 712.3306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0534890\n",
      "\tspeed: 0.0149s/iter; left time: 279.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0511243 Vali Loss: 0.0587070 Test Loss: 0.0619348\n",
      "Validation loss decreased (0.058765 --> 0.058707).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0491434\n",
      "\tspeed: 0.0375s/iter; left time: 698.3974s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528754\n",
      "\tspeed: 0.0159s/iter; left time: 294.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0509761 Vali Loss: 0.0584687 Test Loss: 0.0615832\n",
      "Validation loss decreased (0.058707 --> 0.058469).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0493292\n",
      "\tspeed: 0.0384s/iter; left time: 706.2232s\n",
      "\titers: 200, epoch: 18 | loss: 0.0531685\n",
      "\tspeed: 0.0132s/iter; left time: 242.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.0506763 Vali Loss: 0.0582606 Test Loss: 0.0614566\n",
      "Validation loss decreased (0.058469 --> 0.058261).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529053\n",
      "\tspeed: 0.0381s/iter; left time: 693.6413s\n",
      "\titers: 200, epoch: 19 | loss: 0.0497256\n",
      "\tspeed: 0.0251s/iter; left time: 453.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0505410 Vali Loss: 0.0581122 Test Loss: 0.0612906\n",
      "Validation loss decreased (0.058261 --> 0.058112).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0491694\n",
      "\tspeed: 0.0396s/iter; left time: 711.6586s\n",
      "\titers: 200, epoch: 20 | loss: 0.0501596\n",
      "\tspeed: 0.0197s/iter; left time: 351.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0503292 Vali Loss: 0.0583369 Test Loss: 0.0614038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0508207\n",
      "\tspeed: 0.0361s/iter; left time: 640.0458s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540633\n",
      "\tspeed: 0.0178s/iter; left time: 314.1338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0503592 Vali Loss: 0.0581978 Test Loss: 0.0612768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0496555\n",
      "\tspeed: 0.0394s/iter; left time: 690.3456s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534243\n",
      "\tspeed: 0.0196s/iter; left time: 341.1761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0501330 Vali Loss: 0.0578809 Test Loss: 0.0610519\n",
      "Validation loss decreased (0.058112 --> 0.057881).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0517100\n",
      "\tspeed: 0.0359s/iter; left time: 621.2116s\n",
      "\titers: 200, epoch: 23 | loss: 0.0478579\n",
      "\tspeed: 0.0167s/iter; left time: 286.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0498769 Vali Loss: 0.0577833 Test Loss: 0.0608692\n",
      "Validation loss decreased (0.057881 --> 0.057783).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0490868\n",
      "\tspeed: 0.0390s/iter; left time: 665.1878s\n",
      "\titers: 200, epoch: 24 | loss: 0.0514370\n",
      "\tspeed: 0.0197s/iter; left time: 333.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0498474 Vali Loss: 0.0577935 Test Loss: 0.0607914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0492130\n",
      "\tspeed: 0.0376s/iter; left time: 633.5509s\n",
      "\titers: 200, epoch: 25 | loss: 0.0489792\n",
      "\tspeed: 0.0180s/iter; left time: 301.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0497373 Vali Loss: 0.0577882 Test Loss: 0.0609075\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0515442\n",
      "\tspeed: 0.0373s/iter; left time: 619.5294s\n",
      "\titers: 200, epoch: 26 | loss: 0.0489699\n",
      "\tspeed: 0.0200s/iter; left time: 331.1352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0495722 Vali Loss: 0.0576558 Test Loss: 0.0608152\n",
      "Validation loss decreased (0.057783 --> 0.057656).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0485971\n",
      "\tspeed: 0.0362s/iter; left time: 594.0867s\n",
      "\titers: 200, epoch: 27 | loss: 0.0478701\n",
      "\tspeed: 0.0194s/iter; left time: 315.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0496339 Vali Loss: 0.0575417 Test Loss: 0.0606223\n",
      "Validation loss decreased (0.057656 --> 0.057542).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0498576\n",
      "\tspeed: 0.0364s/iter; left time: 588.9926s\n",
      "\titers: 200, epoch: 28 | loss: 0.0529318\n",
      "\tspeed: 0.0132s/iter; left time: 212.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0496269 Vali Loss: 0.0576183 Test Loss: 0.0606592\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0478204\n",
      "\tspeed: 0.0356s/iter; left time: 568.7529s\n",
      "\titers: 200, epoch: 29 | loss: 0.0485484\n",
      "\tspeed: 0.0189s/iter; left time: 300.1646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0493664 Vali Loss: 0.0574383 Test Loss: 0.0606688\n",
      "Validation loss decreased (0.057542 --> 0.057438).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0482211\n",
      "\tspeed: 0.0396s/iter; left time: 623.0003s\n",
      "\titers: 200, epoch: 30 | loss: 0.0488848\n",
      "\tspeed: 0.0197s/iter; left time: 308.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0492981 Vali Loss: 0.0575676 Test Loss: 0.0606407\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0501512\n",
      "\tspeed: 0.0393s/iter; left time: 609.2733s\n",
      "\titers: 200, epoch: 31 | loss: 0.0510716\n",
      "\tspeed: 0.0212s/iter; left time: 326.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0492856 Vali Loss: 0.0574316 Test Loss: 0.0604549\n",
      "Validation loss decreased (0.057438 --> 0.057432).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0489707\n",
      "\tspeed: 0.0389s/iter; left time: 594.1041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0501955\n",
      "\tspeed: 0.0188s/iter; left time: 284.8916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0492434 Vali Loss: 0.0574214 Test Loss: 0.0604621\n",
      "Validation loss decreased (0.057432 --> 0.057421).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0473494\n",
      "\tspeed: 0.0417s/iter; left time: 628.2552s\n",
      "\titers: 200, epoch: 33 | loss: 0.0471059\n",
      "\tspeed: 0.0228s/iter; left time: 341.7241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0491912 Vali Loss: 0.0573679 Test Loss: 0.0604532\n",
      "Validation loss decreased (0.057421 --> 0.057368).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0467992\n",
      "\tspeed: 0.0439s/iter; left time: 652.2282s\n",
      "\titers: 200, epoch: 34 | loss: 0.0492968\n",
      "\tspeed: 0.0244s/iter; left time: 360.4034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0491803 Vali Loss: 0.0574905 Test Loss: 0.0606405\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0470877\n",
      "\tspeed: 0.0366s/iter; left time: 534.8477s\n",
      "\titers: 200, epoch: 35 | loss: 0.0462380\n",
      "\tspeed: 0.0204s/iter; left time: 295.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0490107 Vali Loss: 0.0572901 Test Loss: 0.0603345\n",
      "Validation loss decreased (0.057368 --> 0.057290).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0478835\n",
      "\tspeed: 0.0378s/iter; left time: 544.6478s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486398\n",
      "\tspeed: 0.0191s/iter; left time: 273.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0490944 Vali Loss: 0.0572910 Test Loss: 0.0603712\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0479557\n",
      "\tspeed: 0.0382s/iter; left time: 540.9046s\n",
      "\titers: 200, epoch: 37 | loss: 0.0489345\n",
      "\tspeed: 0.0185s/iter; left time: 260.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0494170 Vali Loss: 0.0573440 Test Loss: 0.0604316\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0481758\n",
      "\tspeed: 0.0425s/iter; left time: 592.7678s\n",
      "\titers: 200, epoch: 38 | loss: 0.0517889\n",
      "\tspeed: 0.0198s/iter; left time: 274.0771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0490630 Vali Loss: 0.0571826 Test Loss: 0.0602354\n",
      "Validation loss decreased (0.057290 --> 0.057183).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0457301\n",
      "\tspeed: 0.0404s/iter; left time: 554.7883s\n",
      "\titers: 200, epoch: 39 | loss: 0.0485481\n",
      "\tspeed: 0.0228s/iter; left time: 310.1655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0490053 Vali Loss: 0.0572403 Test Loss: 0.0602771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0452573\n",
      "\tspeed: 0.0376s/iter; left time: 507.4498s\n",
      "\titers: 200, epoch: 40 | loss: 0.0494364\n",
      "\tspeed: 0.0170s/iter; left time: 228.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0489563 Vali Loss: 0.0571800 Test Loss: 0.0602402\n",
      "Validation loss decreased (0.057183 --> 0.057180).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0506086\n",
      "\tspeed: 0.0377s/iter; left time: 500.7817s\n",
      "\titers: 200, epoch: 41 | loss: 0.0454930\n",
      "\tspeed: 0.0184s/iter; left time: 242.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0488437 Vali Loss: 0.0572296 Test Loss: 0.0602630\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0481241\n",
      "\tspeed: 0.0367s/iter; left time: 479.1113s\n",
      "\titers: 200, epoch: 42 | loss: 0.0481783\n",
      "\tspeed: 0.0177s/iter; left time: 229.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0489059 Vali Loss: 0.0572003 Test Loss: 0.0603421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0502890\n",
      "\tspeed: 0.0355s/iter; left time: 455.5281s\n",
      "\titers: 200, epoch: 43 | loss: 0.0449523\n",
      "\tspeed: 0.0177s/iter; left time: 224.7795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0488338 Vali Loss: 0.0572221 Test Loss: 0.0603067\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0488996\n",
      "\tspeed: 0.0371s/iter; left time: 468.3525s\n",
      "\titers: 200, epoch: 44 | loss: 0.0504843\n",
      "\tspeed: 0.0199s/iter; left time: 248.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0487729 Vali Loss: 0.0572168 Test Loss: 0.0602941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495345\n",
      "\tspeed: 0.0381s/iter; left time: 472.0855s\n",
      "\titers: 200, epoch: 45 | loss: 0.0511081\n",
      "\tspeed: 0.0188s/iter; left time: 230.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0488409 Vali Loss: 0.0571053 Test Loss: 0.0602380\n",
      "Validation loss decreased (0.057180 --> 0.057105).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0453051\n",
      "\tspeed: 0.0408s/iter; left time: 495.9841s\n",
      "\titers: 200, epoch: 46 | loss: 0.0496866\n",
      "\tspeed: 0.0232s/iter; left time: 279.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0488729 Vali Loss: 0.0572508 Test Loss: 0.0603855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0495115\n",
      "\tspeed: 0.0342s/iter; left time: 408.6185s\n",
      "\titers: 200, epoch: 47 | loss: 0.0513710\n",
      "\tspeed: 0.0244s/iter; left time: 289.2589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0488442 Vali Loss: 0.0572697 Test Loss: 0.0603364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0499629\n",
      "\tspeed: 0.0413s/iter; left time: 484.0491s\n",
      "\titers: 200, epoch: 48 | loss: 0.0474884\n",
      "\tspeed: 0.0225s/iter; left time: 261.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0487454 Vali Loss: 0.0571224 Test Loss: 0.0602089\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0489947\n",
      "\tspeed: 0.0409s/iter; left time: 470.4935s\n",
      "\titers: 200, epoch: 49 | loss: 0.0513139\n",
      "\tspeed: 0.0225s/iter; left time: 256.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0488029 Vali Loss: 0.0571705 Test Loss: 0.0603408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0507773\n",
      "\tspeed: 0.0402s/iter; left time: 453.4927s\n",
      "\titers: 200, epoch: 50 | loss: 0.0517840\n",
      "\tspeed: 0.0212s/iter; left time: 236.6475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0488013 Vali Loss: 0.0572326 Test Loss: 0.0603317\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0470517\n",
      "\tspeed: 0.0411s/iter; left time: 454.5765s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508473\n",
      "\tspeed: 0.0193s/iter; left time: 211.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0487815 Vali Loss: 0.0571189 Test Loss: 0.0601991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0451237\n",
      "\tspeed: 0.0420s/iter; left time: 454.8672s\n",
      "\titers: 200, epoch: 52 | loss: 0.0477586\n",
      "\tspeed: 0.0212s/iter; left time: 227.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0487631 Vali Loss: 0.0572382 Test Loss: 0.0602812\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0480561\n",
      "\tspeed: 0.0452s/iter; left time: 479.6332s\n",
      "\titers: 200, epoch: 53 | loss: 0.0501801\n",
      "\tspeed: 0.0225s/iter; left time: 235.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.0487478 Vali Loss: 0.0572642 Test Loss: 0.0604258\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0486216\n",
      "\tspeed: 0.0419s/iter; left time: 435.2834s\n",
      "\titers: 200, epoch: 54 | loss: 0.0515684\n",
      "\tspeed: 0.0206s/iter; left time: 212.0627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0488013 Vali Loss: 0.0572423 Test Loss: 0.0603036\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0485251\n",
      "\tspeed: 0.0414s/iter; left time: 420.5371s\n",
      "\titers: 200, epoch: 55 | loss: 0.0512241\n",
      "\tspeed: 0.0226s/iter; left time: 227.6544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0488301 Vali Loss: 0.0571032 Test Loss: 0.0602363\n",
      "Validation loss decreased (0.057105 --> 0.057103).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0494372\n",
      "\tspeed: 0.0419s/iter; left time: 415.8250s\n",
      "\titers: 200, epoch: 56 | loss: 0.0508592\n",
      "\tspeed: 0.0220s/iter; left time: 216.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0486512 Vali Loss: 0.0571337 Test Loss: 0.0602054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0483012\n",
      "\tspeed: 0.0427s/iter; left time: 414.6675s\n",
      "\titers: 200, epoch: 57 | loss: 0.0453609\n",
      "\tspeed: 0.0207s/iter; left time: 199.4654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0487472 Vali Loss: 0.0571260 Test Loss: 0.0602106\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0497502\n",
      "\tspeed: 0.0375s/iter; left time: 355.4554s\n",
      "\titers: 200, epoch: 58 | loss: 0.0494744\n",
      "\tspeed: 0.0198s/iter; left time: 186.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0487636 Vali Loss: 0.0570820 Test Loss: 0.0601979\n",
      "Validation loss decreased (0.057103 --> 0.057082).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0504931\n",
      "\tspeed: 0.0405s/iter; left time: 375.1931s\n",
      "\titers: 200, epoch: 59 | loss: 0.0460840\n",
      "\tspeed: 0.0231s/iter; left time: 211.5079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0486617 Vali Loss: 0.0570963 Test Loss: 0.0601800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0481434\n",
      "\tspeed: 0.0371s/iter; left time: 335.2994s\n",
      "\titers: 200, epoch: 60 | loss: 0.0457142\n",
      "\tspeed: 0.0210s/iter; left time: 187.9454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0487357 Vali Loss: 0.0570586 Test Loss: 0.0601705\n",
      "Validation loss decreased (0.057082 --> 0.057059).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0501712\n",
      "\tspeed: 0.0341s/iter; left time: 301.1750s\n",
      "\titers: 200, epoch: 61 | loss: 0.0504330\n",
      "\tspeed: 0.0169s/iter; left time: 147.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0487754 Vali Loss: 0.0570667 Test Loss: 0.0601745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0477528\n",
      "\tspeed: 0.0387s/iter; left time: 332.9960s\n",
      "\titers: 200, epoch: 62 | loss: 0.0490151\n",
      "\tspeed: 0.0193s/iter; left time: 163.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0486548 Vali Loss: 0.0571455 Test Loss: 0.0601858\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0484906\n",
      "\tspeed: 0.0382s/iter; left time: 320.1490s\n",
      "\titers: 200, epoch: 63 | loss: 0.0544502\n",
      "\tspeed: 0.0217s/iter; left time: 179.7444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0486868 Vali Loss: 0.0573017 Test Loss: 0.0603552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0492642\n",
      "\tspeed: 0.0389s/iter; left time: 316.7180s\n",
      "\titers: 200, epoch: 64 | loss: 0.0498345\n",
      "\tspeed: 0.0200s/iter; left time: 160.8580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0486830 Vali Loss: 0.0572332 Test Loss: 0.0603793\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0486930\n",
      "\tspeed: 0.0362s/iter; left time: 286.8064s\n",
      "\titers: 200, epoch: 65 | loss: 0.0488619\n",
      "\tspeed: 0.0180s/iter; left time: 141.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0487089 Vali Loss: 0.0571097 Test Loss: 0.0601833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0490691\n",
      "\tspeed: 0.0384s/iter; left time: 295.9591s\n",
      "\titers: 200, epoch: 66 | loss: 0.0487439\n",
      "\tspeed: 0.0200s/iter; left time: 152.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0487926 Vali Loss: 0.0570433 Test Loss: 0.0602130\n",
      "Validation loss decreased (0.057059 --> 0.057043).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0451786\n",
      "\tspeed: 0.0388s/iter; left time: 290.1305s\n",
      "\titers: 200, epoch: 67 | loss: 0.0475316\n",
      "\tspeed: 0.0195s/iter; left time: 144.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0486549 Vali Loss: 0.0571768 Test Loss: 0.0602184\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0495597\n",
      "\tspeed: 0.0401s/iter; left time: 291.1757s\n",
      "\titers: 200, epoch: 68 | loss: 0.0467642\n",
      "\tspeed: 0.0241s/iter; left time: 172.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0487434 Vali Loss: 0.0572413 Test Loss: 0.0603635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0515573\n",
      "\tspeed: 0.0390s/iter; left time: 274.4007s\n",
      "\titers: 200, epoch: 69 | loss: 0.0472452\n",
      "\tspeed: 0.0225s/iter; left time: 155.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0486674 Vali Loss: 0.0571629 Test Loss: 0.0602624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0483436\n",
      "\tspeed: 0.0403s/iter; left time: 274.4248s\n",
      "\titers: 200, epoch: 70 | loss: 0.0492028\n",
      "\tspeed: 0.0195s/iter; left time: 131.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0488501 Vali Loss: 0.0573268 Test Loss: 0.0605140\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0507724\n",
      "\tspeed: 0.0442s/iter; left time: 291.0439s\n",
      "\titers: 200, epoch: 71 | loss: 0.0470218\n",
      "\tspeed: 0.0254s/iter; left time: 165.0660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0487067 Vali Loss: 0.0570265 Test Loss: 0.0601782\n",
      "Validation loss decreased (0.057043 --> 0.057027).  Saving model ...\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0502248\n",
      "\tspeed: 0.0363s/iter; left time: 231.2707s\n",
      "\titers: 200, epoch: 72 | loss: 0.0469751\n",
      "\tspeed: 0.0161s/iter; left time: 101.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0486459 Vali Loss: 0.0572870 Test Loss: 0.0604110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0506107\n",
      "\tspeed: 0.0406s/iter; left time: 249.7295s\n",
      "\titers: 200, epoch: 73 | loss: 0.0467111\n",
      "\tspeed: 0.0249s/iter; left time: 150.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0486245 Vali Loss: 0.0572505 Test Loss: 0.0603751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0534502\n",
      "\tspeed: 0.0415s/iter; left time: 245.8057s\n",
      "\titers: 200, epoch: 74 | loss: 0.0468832\n",
      "\tspeed: 0.0224s/iter; left time: 130.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0487680 Vali Loss: 0.0571395 Test Loss: 0.0602298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0481216\n",
      "\tspeed: 0.0443s/iter; left time: 252.1995s\n",
      "\titers: 200, epoch: 75 | loss: 0.0474309\n",
      "\tspeed: 0.0248s/iter; left time: 139.0460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0486899 Vali Loss: 0.0570863 Test Loss: 0.0601322\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0505250\n",
      "\tspeed: 0.0429s/iter; left time: 234.9448s\n",
      "\titers: 200, epoch: 76 | loss: 0.0499156\n",
      "\tspeed: 0.0228s/iter; left time: 122.7590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0486352 Vali Loss: 0.0572839 Test Loss: 0.0603514\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0492026\n",
      "\tspeed: 0.0419s/iter; left time: 220.0852s\n",
      "\titers: 200, epoch: 77 | loss: 0.0488617\n",
      "\tspeed: 0.0176s/iter; left time: 90.4504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0485993 Vali Loss: 0.0571223 Test Loss: 0.0602114\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0487652\n",
      "\tspeed: 0.0394s/iter; left time: 198.2108s\n",
      "\titers: 200, epoch: 78 | loss: 0.0463388\n",
      "\tspeed: 0.0206s/iter; left time: 101.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0486306 Vali Loss: 0.0570852 Test Loss: 0.0602179\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0522110\n",
      "\tspeed: 0.0417s/iter; left time: 200.6131s\n",
      "\titers: 200, epoch: 79 | loss: 0.0446301\n",
      "\tspeed: 0.0246s/iter; left time: 115.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0488554 Vali Loss: 0.0570858 Test Loss: 0.0601446\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0448830\n",
      "\tspeed: 0.0346s/iter; left time: 158.4523s\n",
      "\titers: 200, epoch: 80 | loss: 0.0470769\n",
      "\tspeed: 0.0130s/iter; left time: 58.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 223 | Train Loss: 0.0488327 Vali Loss: 0.0570648 Test Loss: 0.0601736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0455667\n",
      "\tspeed: 0.0308s/iter; left time: 134.3483s\n",
      "\titers: 200, epoch: 81 | loss: 0.0504325\n",
      "\tspeed: 0.0195s/iter; left time: 83.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0487624 Vali Loss: 0.0571202 Test Loss: 0.0602019\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010859417729079723, rmse:0.10420852899551392, mae:0.060178253799676895, rse:0.40203362703323364\n",
      "Intermediate time for FR and pred_len 24: 00h:13m:19.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2267028\n",
      "\tspeed: 0.0430s/iter; left time: 950.1339s\n",
      "\titers: 200, epoch: 1 | loss: 0.2135511\n",
      "\tspeed: 0.0139s/iter; left time: 306.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 222 | Train Loss: 0.2315591 Vali Loss: 0.1772272 Test Loss: 0.1834331\n",
      "Validation loss decreased (inf --> 0.177227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1293374\n",
      "\tspeed: 0.0388s/iter; left time: 847.9954s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015767\n",
      "\tspeed: 0.0167s/iter; left time: 363.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.1325314 Vali Loss: 0.0982890 Test Loss: 0.1072068\n",
      "Validation loss decreased (0.177227 --> 0.098289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0885466\n",
      "\tspeed: 0.0372s/iter; left time: 806.2180s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841450\n",
      "\tspeed: 0.0177s/iter; left time: 380.5072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0886659 Vali Loss: 0.0863668 Test Loss: 0.0925269\n",
      "Validation loss decreased (0.098289 --> 0.086367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0789470\n",
      "\tspeed: 0.0384s/iter; left time: 822.1766s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768474\n",
      "\tspeed: 0.0167s/iter; left time: 356.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0797773 Vali Loss: 0.0806557 Test Loss: 0.0911315\n",
      "Validation loss decreased (0.086367 --> 0.080656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693649\n",
      "\tspeed: 0.0353s/iter; left time: 748.3982s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715431\n",
      "\tspeed: 0.0174s/iter; left time: 367.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0750615 Vali Loss: 0.0792125 Test Loss: 0.0885798\n",
      "Validation loss decreased (0.080656 --> 0.079212).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0718599\n",
      "\tspeed: 0.0378s/iter; left time: 792.7738s\n",
      "\titers: 200, epoch: 6 | loss: 0.0684765\n",
      "\tspeed: 0.0202s/iter; left time: 421.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0718348 Vali Loss: 0.0776187 Test Loss: 0.0871840\n",
      "Validation loss decreased (0.079212 --> 0.077619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0692197\n",
      "\tspeed: 0.0420s/iter; left time: 872.2356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668686\n",
      "\tspeed: 0.0181s/iter; left time: 374.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0699637 Vali Loss: 0.0770199 Test Loss: 0.0862746\n",
      "Validation loss decreased (0.077619 --> 0.077020).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694030\n",
      "\tspeed: 0.0413s/iter; left time: 848.2768s\n",
      "\titers: 200, epoch: 8 | loss: 0.0709295\n",
      "\tspeed: 0.0135s/iter; left time: 276.2751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0685380 Vali Loss: 0.0765425 Test Loss: 0.0860829\n",
      "Validation loss decreased (0.077020 --> 0.076542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0635232\n",
      "\tspeed: 0.0384s/iter; left time: 780.3780s\n",
      "\titers: 200, epoch: 9 | loss: 0.0662752\n",
      "\tspeed: 0.0176s/iter; left time: 355.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0676675 Vali Loss: 0.0762699 Test Loss: 0.0866981\n",
      "Validation loss decreased (0.076542 --> 0.076270).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0636201\n",
      "\tspeed: 0.0367s/iter; left time: 737.3289s\n",
      "\titers: 200, epoch: 10 | loss: 0.0709490\n",
      "\tspeed: 0.0174s/iter; left time: 348.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0667456 Vali Loss: 0.0757279 Test Loss: 0.0858754\n",
      "Validation loss decreased (0.076270 --> 0.075728).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0693292\n",
      "\tspeed: 0.0382s/iter; left time: 759.4231s\n",
      "\titers: 200, epoch: 11 | loss: 0.0601297\n",
      "\tspeed: 0.0206s/iter; left time: 407.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0662411 Vali Loss: 0.0755199 Test Loss: 0.0858755\n",
      "Validation loss decreased (0.075728 --> 0.075520).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652160\n",
      "\tspeed: 0.0440s/iter; left time: 865.8337s\n",
      "\titers: 200, epoch: 12 | loss: 0.0678964\n",
      "\tspeed: 0.0211s/iter; left time: 412.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 222 | Train Loss: 0.0655011 Vali Loss: 0.0760923 Test Loss: 0.0862923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0631842\n",
      "\tspeed: 0.0371s/iter; left time: 720.6682s\n",
      "\titers: 200, epoch: 13 | loss: 0.0668576\n",
      "\tspeed: 0.0168s/iter; left time: 324.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0651463 Vali Loss: 0.0749479 Test Loss: 0.0854728\n",
      "Validation loss decreased (0.075520 --> 0.074948).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689360\n",
      "\tspeed: 0.0403s/iter; left time: 773.7054s\n",
      "\titers: 200, epoch: 14 | loss: 0.0660432\n",
      "\tspeed: 0.0190s/iter; left time: 363.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0648640 Vali Loss: 0.0749733 Test Loss: 0.0859138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0653437\n",
      "\tspeed: 0.0397s/iter; left time: 754.3208s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631717\n",
      "\tspeed: 0.0192s/iter; left time: 362.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0646244 Vali Loss: 0.0749632 Test Loss: 0.0851869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618654\n",
      "\tspeed: 0.0389s/iter; left time: 730.7649s\n",
      "\titers: 200, epoch: 16 | loss: 0.0620756\n",
      "\tspeed: 0.0193s/iter; left time: 361.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0646136 Vali Loss: 0.0756751 Test Loss: 0.0865352\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0663635\n",
      "\tspeed: 0.0399s/iter; left time: 740.6353s\n",
      "\titers: 200, epoch: 17 | loss: 0.0649047\n",
      "\tspeed: 0.0177s/iter; left time: 325.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0643330 Vali Loss: 0.0746861 Test Loss: 0.0858784\n",
      "Validation loss decreased (0.074948 --> 0.074686).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631827\n",
      "\tspeed: 0.0408s/iter; left time: 747.3026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645057\n",
      "\tspeed: 0.0183s/iter; left time: 332.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0638526 Vali Loss: 0.0742696 Test Loss: 0.0852134\n",
      "Validation loss decreased (0.074686 --> 0.074270).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0634702\n",
      "\tspeed: 0.0452s/iter; left time: 817.9499s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629722\n",
      "\tspeed: 0.0239s/iter; left time: 431.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 222 | Train Loss: 0.0638927 Vali Loss: 0.0740166 Test Loss: 0.0853843\n",
      "Validation loss decreased (0.074270 --> 0.074017).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0611127\n",
      "\tspeed: 0.0373s/iter; left time: 667.8859s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653505\n",
      "\tspeed: 0.0174s/iter; left time: 309.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0636053 Vali Loss: 0.0738598 Test Loss: 0.0853267\n",
      "Validation loss decreased (0.074017 --> 0.073860).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0635018\n",
      "\tspeed: 0.0363s/iter; left time: 641.9416s\n",
      "\titers: 200, epoch: 21 | loss: 0.0593666\n",
      "\tspeed: 0.0181s/iter; left time: 318.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0635133 Vali Loss: 0.0739690 Test Loss: 0.0851553\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0633398\n",
      "\tspeed: 0.0412s/iter; left time: 719.0275s\n",
      "\titers: 200, epoch: 22 | loss: 0.0615648\n",
      "\tspeed: 0.0177s/iter; left time: 307.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0632623 Vali Loss: 0.0739025 Test Loss: 0.0853512\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0616216\n",
      "\tspeed: 0.0374s/iter; left time: 644.0342s\n",
      "\titers: 200, epoch: 23 | loss: 0.0620393\n",
      "\tspeed: 0.0171s/iter; left time: 292.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0632685 Vali Loss: 0.0740019 Test Loss: 0.0856074\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0627577\n",
      "\tspeed: 0.0355s/iter; left time: 603.7832s\n",
      "\titers: 200, epoch: 24 | loss: 0.0652485\n",
      "\tspeed: 0.0174s/iter; left time: 293.2848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0630291 Vali Loss: 0.0738503 Test Loss: 0.0852864\n",
      "Validation loss decreased (0.073860 --> 0.073850).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0653873\n",
      "\tspeed: 0.0370s/iter; left time: 620.9667s\n",
      "\titers: 200, epoch: 25 | loss: 0.0658269\n",
      "\tspeed: 0.0175s/iter; left time: 292.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0630961 Vali Loss: 0.0737145 Test Loss: 0.0851739\n",
      "Validation loss decreased (0.073850 --> 0.073715).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0612837\n",
      "\tspeed: 0.0374s/iter; left time: 618.3230s\n",
      "\titers: 200, epoch: 26 | loss: 0.0609538\n",
      "\tspeed: 0.0163s/iter; left time: 267.8602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0629769 Vali Loss: 0.0736573 Test Loss: 0.0851916\n",
      "Validation loss decreased (0.073715 --> 0.073657).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0634126\n",
      "\tspeed: 0.0334s/iter; left time: 545.8212s\n",
      "\titers: 200, epoch: 27 | loss: 0.0625662\n",
      "\tspeed: 0.0186s/iter; left time: 302.0225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0627763 Vali Loss: 0.0736640 Test Loss: 0.0852929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0636804\n",
      "\tspeed: 0.0375s/iter; left time: 604.5586s\n",
      "\titers: 200, epoch: 28 | loss: 0.0618400\n",
      "\tspeed: 0.0189s/iter; left time: 302.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0627862 Vali Loss: 0.0736277 Test Loss: 0.0852906\n",
      "Validation loss decreased (0.073657 --> 0.073628).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602461\n",
      "\tspeed: 0.0387s/iter; left time: 614.9185s\n",
      "\titers: 200, epoch: 29 | loss: 0.0611843\n",
      "\tspeed: 0.0181s/iter; left time: 286.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0626138 Vali Loss: 0.0737159 Test Loss: 0.0853415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0649850\n",
      "\tspeed: 0.0357s/iter; left time: 559.8533s\n",
      "\titers: 200, epoch: 30 | loss: 0.0591837\n",
      "\tspeed: 0.0167s/iter; left time: 259.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0626210 Vali Loss: 0.0734907 Test Loss: 0.0852216\n",
      "Validation loss decreased (0.073628 --> 0.073491).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0608462\n",
      "\tspeed: 0.0424s/iter; left time: 655.0364s\n",
      "\titers: 200, epoch: 31 | loss: 0.0632942\n",
      "\tspeed: 0.0196s/iter; left time: 300.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0625991 Vali Loss: 0.0734548 Test Loss: 0.0850597\n",
      "Validation loss decreased (0.073491 --> 0.073455).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628746\n",
      "\tspeed: 0.0395s/iter; left time: 601.8772s\n",
      "\titers: 200, epoch: 32 | loss: 0.0601225\n",
      "\tspeed: 0.0207s/iter; left time: 313.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0624923 Vali Loss: 0.0735416 Test Loss: 0.0852687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0656446\n",
      "\tspeed: 0.0385s/iter; left time: 577.1724s\n",
      "\titers: 200, epoch: 33 | loss: 0.0621694\n",
      "\tspeed: 0.0198s/iter; left time: 294.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0626026 Vali Loss: 0.0734950 Test Loss: 0.0850879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0622397\n",
      "\tspeed: 0.0361s/iter; left time: 533.9594s\n",
      "\titers: 200, epoch: 34 | loss: 0.0640215\n",
      "\tspeed: 0.0166s/iter; left time: 243.6706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0625493 Vali Loss: 0.0734956 Test Loss: 0.0850923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0603158\n",
      "\tspeed: 0.0370s/iter; left time: 538.5086s\n",
      "\titers: 200, epoch: 35 | loss: 0.0613668\n",
      "\tspeed: 0.0166s/iter; left time: 239.6628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0624190 Vali Loss: 0.0734789 Test Loss: 0.0851558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618927\n",
      "\tspeed: 0.0362s/iter; left time: 519.2258s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608553\n",
      "\tspeed: 0.0184s/iter; left time: 262.2182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0623591 Vali Loss: 0.0735502 Test Loss: 0.0853786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669588\n",
      "\tspeed: 0.0371s/iter; left time: 523.3177s\n",
      "\titers: 200, epoch: 37 | loss: 0.0614287\n",
      "\tspeed: 0.0175s/iter; left time: 245.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0623217 Vali Loss: 0.0734225 Test Loss: 0.0852213\n",
      "Validation loss decreased (0.073455 --> 0.073422).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0647136\n",
      "\tspeed: 0.0383s/iter; left time: 531.5301s\n",
      "\titers: 200, epoch: 38 | loss: 0.0664441\n",
      "\tspeed: 0.0223s/iter; left time: 306.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0623466 Vali Loss: 0.0734045 Test Loss: 0.0851296\n",
      "Validation loss decreased (0.073422 --> 0.073404).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0553426\n",
      "\tspeed: 0.0369s/iter; left time: 503.8072s\n",
      "\titers: 200, epoch: 39 | loss: 0.0591905\n",
      "\tspeed: 0.0181s/iter; left time: 245.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0623191 Vali Loss: 0.0734078 Test Loss: 0.0852216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0611381\n",
      "\tspeed: 0.0371s/iter; left time: 498.8000s\n",
      "\titers: 200, epoch: 40 | loss: 0.0612438\n",
      "\tspeed: 0.0218s/iter; left time: 290.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0622629 Vali Loss: 0.0734093 Test Loss: 0.0852055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0598230\n",
      "\tspeed: 0.0387s/iter; left time: 512.2397s\n",
      "\titers: 200, epoch: 41 | loss: 0.0645696\n",
      "\tspeed: 0.0183s/iter; left time: 240.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0622982 Vali Loss: 0.0733894 Test Loss: 0.0852577\n",
      "Validation loss decreased (0.073404 --> 0.073389).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0657890\n",
      "\tspeed: 0.0371s/iter; left time: 482.4530s\n",
      "\titers: 200, epoch: 42 | loss: 0.0596970\n",
      "\tspeed: 0.0184s/iter; left time: 236.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0622755 Vali Loss: 0.0733945 Test Loss: 0.0852331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0649050\n",
      "\tspeed: 0.0370s/iter; left time: 473.1050s\n",
      "\titers: 200, epoch: 43 | loss: 0.0636251\n",
      "\tspeed: 0.0135s/iter; left time: 170.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 222 | Train Loss: 0.0622306 Vali Loss: 0.0734597 Test Loss: 0.0852875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0583642\n",
      "\tspeed: 0.0339s/iter; left time: 425.3237s\n",
      "\titers: 200, epoch: 44 | loss: 0.0639238\n",
      "\tspeed: 0.0185s/iter; left time: 230.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0622259 Vali Loss: 0.0733659 Test Loss: 0.0851065\n",
      "Validation loss decreased (0.073389 --> 0.073366).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659315\n",
      "\tspeed: 0.0420s/iter; left time: 517.7167s\n",
      "\titers: 200, epoch: 45 | loss: 0.0602623\n",
      "\tspeed: 0.0171s/iter; left time: 209.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0621681 Vali Loss: 0.0735022 Test Loss: 0.0853961\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0611856\n",
      "\tspeed: 0.0400s/iter; left time: 483.9266s\n",
      "\titers: 200, epoch: 46 | loss: 0.0662605\n",
      "\tspeed: 0.0217s/iter; left time: 260.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0622885 Vali Loss: 0.0733904 Test Loss: 0.0852588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0666935\n",
      "\tspeed: 0.0369s/iter; left time: 438.4896s\n",
      "\titers: 200, epoch: 47 | loss: 0.0618797\n",
      "\tspeed: 0.0163s/iter; left time: 192.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0622976 Vali Loss: 0.0733338 Test Loss: 0.0851604\n",
      "Validation loss decreased (0.073366 --> 0.073334).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0614597\n",
      "\tspeed: 0.0362s/iter; left time: 422.0458s\n",
      "\titers: 200, epoch: 48 | loss: 0.0589264\n",
      "\tspeed: 0.0186s/iter; left time: 215.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0621424 Vali Loss: 0.0733863 Test Loss: 0.0852267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0637451\n",
      "\tspeed: 0.0336s/iter; left time: 384.1429s\n",
      "\titers: 200, epoch: 49 | loss: 0.0613794\n",
      "\tspeed: 0.0134s/iter; left time: 152.5403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 222 | Train Loss: 0.0623963 Vali Loss: 0.0733564 Test Loss: 0.0851370\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0618812\n",
      "\tspeed: 0.0352s/iter; left time: 394.5993s\n",
      "\titers: 200, epoch: 50 | loss: 0.0641346\n",
      "\tspeed: 0.0168s/iter; left time: 186.6601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0621585 Vali Loss: 0.0733848 Test Loss: 0.0852025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0649407\n",
      "\tspeed: 0.0378s/iter; left time: 415.8682s\n",
      "\titers: 200, epoch: 51 | loss: 0.0656235\n",
      "\tspeed: 0.0135s/iter; left time: 147.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0622085 Vali Loss: 0.0733106 Test Loss: 0.0850968\n",
      "Validation loss decreased (0.073334 --> 0.073311).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0622754\n",
      "\tspeed: 0.0378s/iter; left time: 406.9921s\n",
      "\titers: 200, epoch: 52 | loss: 0.0594684\n",
      "\tspeed: 0.0210s/iter; left time: 224.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0621938 Vali Loss: 0.0733696 Test Loss: 0.0852140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0596151\n",
      "\tspeed: 0.0372s/iter; left time: 393.1662s\n",
      "\titers: 200, epoch: 53 | loss: 0.0625431\n",
      "\tspeed: 0.0204s/iter; left time: 213.1805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0621405 Vali Loss: 0.0734119 Test Loss: 0.0853638\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0608095\n",
      "\tspeed: 0.0369s/iter; left time: 380.8693s\n",
      "\titers: 200, epoch: 54 | loss: 0.0644153\n",
      "\tspeed: 0.0184s/iter; left time: 188.0897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0621808 Vali Loss: 0.0734113 Test Loss: 0.0854056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0639046\n",
      "\tspeed: 0.0350s/iter; left time: 353.8778s\n",
      "\titers: 200, epoch: 55 | loss: 0.0600558\n",
      "\tspeed: 0.0188s/iter; left time: 188.2758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0622240 Vali Loss: 0.0733632 Test Loss: 0.0851608\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0624808\n",
      "\tspeed: 0.0334s/iter; left time: 330.0334s\n",
      "\titers: 200, epoch: 56 | loss: 0.0646345\n",
      "\tspeed: 0.0168s/iter; left time: 164.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.0621265 Vali Loss: 0.0733335 Test Loss: 0.0851809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0647558\n",
      "\tspeed: 0.0384s/iter; left time: 370.8690s\n",
      "\titers: 200, epoch: 57 | loss: 0.0650051\n",
      "\tspeed: 0.0207s/iter; left time: 198.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0620756 Vali Loss: 0.0733596 Test Loss: 0.0852566\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0651121\n",
      "\tspeed: 0.0390s/iter; left time: 368.0055s\n",
      "\titers: 200, epoch: 58 | loss: 0.0641824\n",
      "\tspeed: 0.0203s/iter; left time: 189.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0622327 Vali Loss: 0.0733660 Test Loss: 0.0853010\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0620119\n",
      "\tspeed: 0.0332s/iter; left time: 306.3893s\n",
      "\titers: 200, epoch: 59 | loss: 0.0617636\n",
      "\tspeed: 0.0135s/iter; left time: 123.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 222 | Train Loss: 0.0622559 Vali Loss: 0.0733840 Test Loss: 0.0851415\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0662671\n",
      "\tspeed: 0.0387s/iter; left time: 348.1835s\n",
      "\titers: 200, epoch: 60 | loss: 0.0604610\n",
      "\tspeed: 0.0203s/iter; left time: 180.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0621908 Vali Loss: 0.0733975 Test Loss: 0.0853025\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0641209\n",
      "\tspeed: 0.0394s/iter; left time: 346.2607s\n",
      "\titers: 200, epoch: 61 | loss: 0.0599672\n",
      "\tspeed: 0.0215s/iter; left time: 186.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 222 | Train Loss: 0.0621525 Vali Loss: 0.0733382 Test Loss: 0.0851658\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02125689573585987, rmse:0.14579744637012482, mae:0.08509677648544312, rse:0.5639832615852356\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2332438\n",
      "\tspeed: 0.0194s/iter; left time: 428.7407s\n",
      "\titers: 200, epoch: 1 | loss: 0.2074515\n",
      "\tspeed: 0.0194s/iter; left time: 426.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.2327621 Vali Loss: 0.1756928 Test Loss: 0.1819052\n",
      "Validation loss decreased (inf --> 0.175693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349277\n",
      "\tspeed: 0.0407s/iter; left time: 889.7914s\n",
      "\titers: 200, epoch: 2 | loss: 0.0979945\n",
      "\tspeed: 0.0180s/iter; left time: 392.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.1311187 Vali Loss: 0.0962288 Test Loss: 0.1060121\n",
      "Validation loss decreased (0.175693 --> 0.096229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0915493\n",
      "\tspeed: 0.0423s/iter; left time: 916.3923s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815024\n",
      "\tspeed: 0.0152s/iter; left time: 327.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0894797 Vali Loss: 0.0865422 Test Loss: 0.0927320\n",
      "Validation loss decreased (0.096229 --> 0.086542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826185\n",
      "\tspeed: 0.0373s/iter; left time: 798.7128s\n",
      "\titers: 200, epoch: 4 | loss: 0.0810448\n",
      "\tspeed: 0.0162s/iter; left time: 346.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0814201 Vali Loss: 0.0835992 Test Loss: 0.0907592\n",
      "Validation loss decreased (0.086542 --> 0.083599).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743177\n",
      "\tspeed: 0.0401s/iter; left time: 850.9703s\n",
      "\titers: 200, epoch: 5 | loss: 0.0726720\n",
      "\tspeed: 0.0191s/iter; left time: 403.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0762408 Vali Loss: 0.0798601 Test Loss: 0.0898876\n",
      "Validation loss decreased (0.083599 --> 0.079860).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752211\n",
      "\tspeed: 0.0387s/iter; left time: 813.2760s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736725\n",
      "\tspeed: 0.0174s/iter; left time: 363.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0731852 Vali Loss: 0.0781419 Test Loss: 0.0883034\n",
      "Validation loss decreased (0.079860 --> 0.078142).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0714475\n",
      "\tspeed: 0.0454s/iter; left time: 942.1949s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729196\n",
      "\tspeed: 0.0201s/iter; left time: 414.8755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.0713721 Vali Loss: 0.0782305 Test Loss: 0.0877505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0675757\n",
      "\tspeed: 0.0459s/iter; left time: 943.8093s\n",
      "\titers: 200, epoch: 8 | loss: 0.0662482\n",
      "\tspeed: 0.0201s/iter; left time: 410.7095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 222 | Train Loss: 0.0694094 Vali Loss: 0.0770246 Test Loss: 0.0862378\n",
      "Validation loss decreased (0.078142 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703986\n",
      "\tspeed: 0.0425s/iter; left time: 863.5943s\n",
      "\titers: 200, epoch: 9 | loss: 0.0644566\n",
      "\tspeed: 0.0186s/iter; left time: 376.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0684228 Vali Loss: 0.0765546 Test Loss: 0.0865110\n",
      "Validation loss decreased (0.077025 --> 0.076555).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682109\n",
      "\tspeed: 0.0421s/iter; left time: 847.1006s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624587\n",
      "\tspeed: 0.0140s/iter; left time: 279.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0675123 Vali Loss: 0.0763682 Test Loss: 0.0864511\n",
      "Validation loss decreased (0.076555 --> 0.076368).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0663628\n",
      "\tspeed: 0.0400s/iter; left time: 794.7670s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664471\n",
      "\tspeed: 0.0199s/iter; left time: 393.4430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0666392 Vali Loss: 0.0760829 Test Loss: 0.0863217\n",
      "Validation loss decreased (0.076368 --> 0.076083).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652992\n",
      "\tspeed: 0.0346s/iter; left time: 679.6450s\n",
      "\titers: 200, epoch: 12 | loss: 0.0664515\n",
      "\tspeed: 0.0135s/iter; left time: 264.4772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 222 | Train Loss: 0.0662008 Vali Loss: 0.0757518 Test Loss: 0.0861047\n",
      "Validation loss decreased (0.076083 --> 0.075752).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637105\n",
      "\tspeed: 0.0383s/iter; left time: 743.5026s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685193\n",
      "\tspeed: 0.0188s/iter; left time: 362.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0658485 Vali Loss: 0.0758225 Test Loss: 0.0857897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0644000\n",
      "\tspeed: 0.0370s/iter; left time: 711.3082s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623599\n",
      "\tspeed: 0.0135s/iter; left time: 258.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 222 | Train Loss: 0.0656384 Vali Loss: 0.0758276 Test Loss: 0.0857630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0653574\n",
      "\tspeed: 0.0381s/iter; left time: 723.3787s\n",
      "\titers: 200, epoch: 15 | loss: 0.0642808\n",
      "\tspeed: 0.0179s/iter; left time: 338.1666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0649617 Vali Loss: 0.0751267 Test Loss: 0.0854411\n",
      "Validation loss decreased (0.075752 --> 0.075127).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0654096\n",
      "\tspeed: 0.0384s/iter; left time: 719.8730s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643842\n",
      "\tspeed: 0.0144s/iter; left time: 268.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 222 | Train Loss: 0.0647303 Vali Loss: 0.0751002 Test Loss: 0.0856649\n",
      "Validation loss decreased (0.075127 --> 0.075100).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0651560\n",
      "\tspeed: 0.0363s/iter; left time: 673.7368s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624879\n",
      "\tspeed: 0.0164s/iter; left time: 302.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0644860 Vali Loss: 0.0749637 Test Loss: 0.0855752\n",
      "Validation loss decreased (0.075100 --> 0.074964).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599624\n",
      "\tspeed: 0.0411s/iter; left time: 753.1011s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675098\n",
      "\tspeed: 0.0204s/iter; left time: 372.1090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0643688 Vali Loss: 0.0749513 Test Loss: 0.0854600\n",
      "Validation loss decreased (0.074964 --> 0.074951).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643213\n",
      "\tspeed: 0.0416s/iter; left time: 753.6871s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674118\n",
      "\tspeed: 0.0248s/iter; left time: 447.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 222 | Train Loss: 0.0639345 Vali Loss: 0.0749305 Test Loss: 0.0855196\n",
      "Validation loss decreased (0.074951 --> 0.074930).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0615831\n",
      "\tspeed: 0.0388s/iter; left time: 694.5940s\n",
      "\titers: 200, epoch: 20 | loss: 0.0625134\n",
      "\tspeed: 0.0182s/iter; left time: 323.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0638769 Vali Loss: 0.0748858 Test Loss: 0.0855817\n",
      "Validation loss decreased (0.074930 --> 0.074886).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0644731\n",
      "\tspeed: 0.0414s/iter; left time: 730.5121s\n",
      "\titers: 200, epoch: 21 | loss: 0.0629087\n",
      "\tspeed: 0.0182s/iter; left time: 319.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0636836 Vali Loss: 0.0747631 Test Loss: 0.0854978\n",
      "Validation loss decreased (0.074886 --> 0.074763).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0624936\n",
      "\tspeed: 0.0342s/iter; left time: 596.0056s\n",
      "\titers: 200, epoch: 22 | loss: 0.0607735\n",
      "\tspeed: 0.0135s/iter; left time: 233.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 222 | Train Loss: 0.0635712 Vali Loss: 0.0746031 Test Loss: 0.0852415\n",
      "Validation loss decreased (0.074763 --> 0.074603).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619360\n",
      "\tspeed: 0.0405s/iter; left time: 696.5680s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600344\n",
      "\tspeed: 0.0196s/iter; left time: 334.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0635085 Vali Loss: 0.0745777 Test Loss: 0.0854060\n",
      "Validation loss decreased (0.074603 --> 0.074578).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0659707\n",
      "\tspeed: 0.0378s/iter; left time: 643.2262s\n",
      "\titers: 200, epoch: 24 | loss: 0.0657066\n",
      "\tspeed: 0.0165s/iter; left time: 279.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0634187 Vali Loss: 0.0744710 Test Loss: 0.0851947\n",
      "Validation loss decreased (0.074578 --> 0.074471).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0624706\n",
      "\tspeed: 0.0360s/iter; left time: 604.4620s\n",
      "\titers: 200, epoch: 25 | loss: 0.0642952\n",
      "\tspeed: 0.0167s/iter; left time: 278.9333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0633469 Vali Loss: 0.0746358 Test Loss: 0.0852612\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0618325\n",
      "\tspeed: 0.0337s/iter; left time: 557.9212s\n",
      "\titers: 200, epoch: 26 | loss: 0.0655627\n",
      "\tspeed: 0.0138s/iter; left time: 227.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 222 | Train Loss: 0.0632770 Vali Loss: 0.0744471 Test Loss: 0.0851457\n",
      "Validation loss decreased (0.074471 --> 0.074447).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0615555\n",
      "\tspeed: 0.0373s/iter; left time: 608.9719s\n",
      "\titers: 200, epoch: 27 | loss: 0.0622198\n",
      "\tspeed: 0.0183s/iter; left time: 297.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0631623 Vali Loss: 0.0745051 Test Loss: 0.0851635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0652423\n",
      "\tspeed: 0.0415s/iter; left time: 667.8522s\n",
      "\titers: 200, epoch: 28 | loss: 0.0600293\n",
      "\tspeed: 0.0176s/iter; left time: 282.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0632377 Vali Loss: 0.0745681 Test Loss: 0.0852453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616412\n",
      "\tspeed: 0.0328s/iter; left time: 520.8002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0613882\n",
      "\tspeed: 0.0136s/iter; left time: 214.1822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 222 | Train Loss: 0.0629997 Vali Loss: 0.0744263 Test Loss: 0.0852648\n",
      "Validation loss decreased (0.074447 --> 0.074426).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0631977\n",
      "\tspeed: 0.0385s/iter; left time: 603.1739s\n",
      "\titers: 200, epoch: 30 | loss: 0.0681532\n",
      "\tspeed: 0.0163s/iter; left time: 253.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0629121 Vali Loss: 0.0743438 Test Loss: 0.0851796\n",
      "Validation loss decreased (0.074426 --> 0.074344).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0653123\n",
      "\tspeed: 0.0399s/iter; left time: 615.4306s\n",
      "\titers: 200, epoch: 31 | loss: 0.0602726\n",
      "\tspeed: 0.0143s/iter; left time: 218.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0628694 Vali Loss: 0.0743088 Test Loss: 0.0852098\n",
      "Validation loss decreased (0.074344 --> 0.074309).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0678053\n",
      "\tspeed: 0.0356s/iter; left time: 541.0772s\n",
      "\titers: 200, epoch: 32 | loss: 0.0639176\n",
      "\tspeed: 0.0154s/iter; left time: 233.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0630652 Vali Loss: 0.0743524 Test Loss: 0.0851085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0634038\n",
      "\tspeed: 0.0373s/iter; left time: 559.7347s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641238\n",
      "\tspeed: 0.0171s/iter; left time: 255.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0628504 Vali Loss: 0.0743674 Test Loss: 0.0850242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647250\n",
      "\tspeed: 0.0356s/iter; left time: 525.3461s\n",
      "\titers: 200, epoch: 34 | loss: 0.0620727\n",
      "\tspeed: 0.0178s/iter; left time: 261.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0628530 Vali Loss: 0.0741896 Test Loss: 0.0850130\n",
      "Validation loss decreased (0.074309 --> 0.074190).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0634183\n",
      "\tspeed: 0.0367s/iter; left time: 533.3732s\n",
      "\titers: 200, epoch: 35 | loss: 0.0658303\n",
      "\tspeed: 0.0172s/iter; left time: 249.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0628536 Vali Loss: 0.0743202 Test Loss: 0.0850280\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0640776\n",
      "\tspeed: 0.0371s/iter; left time: 532.1272s\n",
      "\titers: 200, epoch: 36 | loss: 0.0637809\n",
      "\tspeed: 0.0171s/iter; left time: 243.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0628852 Vali Loss: 0.0742466 Test Loss: 0.0850965\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0623443\n",
      "\tspeed: 0.0377s/iter; left time: 531.4545s\n",
      "\titers: 200, epoch: 37 | loss: 0.0674361\n",
      "\tspeed: 0.0191s/iter; left time: 267.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0628581 Vali Loss: 0.0742130 Test Loss: 0.0851705\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0610113\n",
      "\tspeed: 0.0410s/iter; left time: 569.9964s\n",
      "\titers: 200, epoch: 38 | loss: 0.0588541\n",
      "\tspeed: 0.0206s/iter; left time: 284.2086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0626928 Vali Loss: 0.0741827 Test Loss: 0.0849982\n",
      "Validation loss decreased (0.074190 --> 0.074183).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0660007\n",
      "\tspeed: 0.0414s/iter; left time: 565.1594s\n",
      "\titers: 200, epoch: 39 | loss: 0.0616124\n",
      "\tspeed: 0.0202s/iter; left time: 274.4927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0627077 Vali Loss: 0.0742974 Test Loss: 0.0852043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0687570\n",
      "\tspeed: 0.0410s/iter; left time: 551.3268s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626596\n",
      "\tspeed: 0.0205s/iter; left time: 273.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0625951 Vali Loss: 0.0741326 Test Loss: 0.0850432\n",
      "Validation loss decreased (0.074183 --> 0.074133).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0602702\n",
      "\tspeed: 0.0399s/iter; left time: 527.4449s\n",
      "\titers: 200, epoch: 41 | loss: 0.0637936\n",
      "\tspeed: 0.0174s/iter; left time: 227.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0626203 Vali Loss: 0.0743554 Test Loss: 0.0852369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0601737\n",
      "\tspeed: 0.0439s/iter; left time: 570.4492s\n",
      "\titers: 200, epoch: 42 | loss: 0.0635296\n",
      "\tspeed: 0.0192s/iter; left time: 247.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.0626016 Vali Loss: 0.0741598 Test Loss: 0.0851039\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0614529\n",
      "\tspeed: 0.0372s/iter; left time: 474.9441s\n",
      "\titers: 200, epoch: 43 | loss: 0.0606279\n",
      "\tspeed: 0.0183s/iter; left time: 232.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0626950 Vali Loss: 0.0741802 Test Loss: 0.0850562\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644844\n",
      "\tspeed: 0.0386s/iter; left time: 484.6228s\n",
      "\titers: 200, epoch: 44 | loss: 0.0623570\n",
      "\tspeed: 0.0171s/iter; left time: 213.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0626810 Vali Loss: 0.0744489 Test Loss: 0.0852235\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0620079\n",
      "\tspeed: 0.0379s/iter; left time: 466.9008s\n",
      "\titers: 200, epoch: 45 | loss: 0.0646244\n",
      "\tspeed: 0.0185s/iter; left time: 226.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 222 | Train Loss: 0.0626365 Vali Loss: 0.0741991 Test Loss: 0.0851906\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0603739\n",
      "\tspeed: 0.0371s/iter; left time: 448.7549s\n",
      "\titers: 200, epoch: 46 | loss: 0.0606084\n",
      "\tspeed: 0.0176s/iter; left time: 211.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0625754 Vali Loss: 0.0741746 Test Loss: 0.0851851\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612067\n",
      "\tspeed: 0.0392s/iter; left time: 466.6403s\n",
      "\titers: 200, epoch: 47 | loss: 0.0609883\n",
      "\tspeed: 0.0203s/iter; left time: 239.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0624916 Vali Loss: 0.0741416 Test Loss: 0.0851222\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0546456\n",
      "\tspeed: 0.0395s/iter; left time: 461.2695s\n",
      "\titers: 200, epoch: 48 | loss: 0.0603762\n",
      "\tspeed: 0.0176s/iter; left time: 203.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0625896 Vali Loss: 0.0742560 Test Loss: 0.0853126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0633899\n",
      "\tspeed: 0.0377s/iter; left time: 432.0031s\n",
      "\titers: 200, epoch: 49 | loss: 0.0651736\n",
      "\tspeed: 0.0191s/iter; left time: 216.2063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0625229 Vali Loss: 0.0742220 Test Loss: 0.0850948\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0662610\n",
      "\tspeed: 0.0322s/iter; left time: 361.3977s\n",
      "\titers: 200, epoch: 50 | loss: 0.0648284\n",
      "\tspeed: 0.0135s/iter; left time: 150.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 222 | Train Loss: 0.0626584 Vali Loss: 0.0741758 Test Loss: 0.0851906\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02106647379696369, rmse:0.14514294266700745, mae:0.08504320681095123, rse:0.5614514946937561\n",
      "Intermediate time for FR and pred_len 96: 00h:10m:35.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2234798\n",
      "\tspeed: 0.0420s/iter; left time: 927.9303s\n",
      "\titers: 200, epoch: 1 | loss: 0.2088102\n",
      "\tspeed: 0.0145s/iter; left time: 319.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.2334017 Vali Loss: 0.1776932 Test Loss: 0.1817676\n",
      "Validation loss decreased (inf --> 0.177693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1246364\n",
      "\tspeed: 0.0329s/iter; left time: 719.8007s\n",
      "\titers: 200, epoch: 2 | loss: 0.0962806\n",
      "\tspeed: 0.0185s/iter; left time: 401.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.1296026 Vali Loss: 0.0987888 Test Loss: 0.1084949\n",
      "Validation loss decreased (0.177693 --> 0.098789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926511\n",
      "\tspeed: 0.0356s/iter; left time: 772.0357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870639\n",
      "\tspeed: 0.0138s/iter; left time: 298.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 222 | Train Loss: 0.0903701 Vali Loss: 0.0877677 Test Loss: 0.0957396\n",
      "Validation loss decreased (0.098789 --> 0.087768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827775\n",
      "\tspeed: 0.0365s/iter; left time: 782.3145s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805393\n",
      "\tspeed: 0.0163s/iter; left time: 348.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0822557 Vali Loss: 0.0853925 Test Loss: 0.0955968\n",
      "Validation loss decreased (0.087768 --> 0.085392).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0823312\n",
      "\tspeed: 0.0403s/iter; left time: 854.7074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792515\n",
      "\tspeed: 0.0169s/iter; left time: 357.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0776787 Vali Loss: 0.0823942 Test Loss: 0.0915224\n",
      "Validation loss decreased (0.085392 --> 0.082394).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0736471\n",
      "\tspeed: 0.0373s/iter; left time: 783.9266s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736030\n",
      "\tspeed: 0.0166s/iter; left time: 346.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0745265 Vali Loss: 0.0818601 Test Loss: 0.0929426\n",
      "Validation loss decreased (0.082394 --> 0.081860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712174\n",
      "\tspeed: 0.0409s/iter; left time: 848.6855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0709573\n",
      "\tspeed: 0.0204s/iter; left time: 422.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0726512 Vali Loss: 0.0807356 Test Loss: 0.0910757\n",
      "Validation loss decreased (0.081860 --> 0.080736).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0702406\n",
      "\tspeed: 0.0415s/iter; left time: 853.3605s\n",
      "\titers: 200, epoch: 8 | loss: 0.0717564\n",
      "\tspeed: 0.0190s/iter; left time: 388.9460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0716488 Vali Loss: 0.0805590 Test Loss: 0.0915492\n",
      "Validation loss decreased (0.080736 --> 0.080559).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704534\n",
      "\tspeed: 0.0379s/iter; left time: 770.6091s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725532\n",
      "\tspeed: 0.0162s/iter; left time: 328.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0704659 Vali Loss: 0.0796424 Test Loss: 0.0905985\n",
      "Validation loss decreased (0.080559 --> 0.079642).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704219\n",
      "\tspeed: 0.0377s/iter; left time: 758.6273s\n",
      "\titers: 200, epoch: 10 | loss: 0.0674980\n",
      "\tspeed: 0.0175s/iter; left time: 350.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0698026 Vali Loss: 0.0795738 Test Loss: 0.0907273\n",
      "Validation loss decreased (0.079642 --> 0.079574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727337\n",
      "\tspeed: 0.0396s/iter; left time: 787.7380s\n",
      "\titers: 200, epoch: 11 | loss: 0.0671647\n",
      "\tspeed: 0.0200s/iter; left time: 395.8567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0693997 Vali Loss: 0.0792396 Test Loss: 0.0906471\n",
      "Validation loss decreased (0.079574 --> 0.079240).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710371\n",
      "\tspeed: 0.0386s/iter; left time: 758.6270s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708320\n",
      "\tspeed: 0.0191s/iter; left time: 373.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0689154 Vali Loss: 0.0788275 Test Loss: 0.0903930\n",
      "Validation loss decreased (0.079240 --> 0.078828).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0635680\n",
      "\tspeed: 0.0401s/iter; left time: 778.9909s\n",
      "\titers: 200, epoch: 13 | loss: 0.0630454\n",
      "\tspeed: 0.0184s/iter; left time: 356.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0685797 Vali Loss: 0.0787910 Test Loss: 0.0905554\n",
      "Validation loss decreased (0.078828 --> 0.078791).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0685879\n",
      "\tspeed: 0.0385s/iter; left time: 740.1509s\n",
      "\titers: 200, epoch: 14 | loss: 0.0687533\n",
      "\tspeed: 0.0174s/iter; left time: 332.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0682373 Vali Loss: 0.0786533 Test Loss: 0.0904733\n",
      "Validation loss decreased (0.078791 --> 0.078653).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0678403\n",
      "\tspeed: 0.0407s/iter; left time: 772.0878s\n",
      "\titers: 200, epoch: 15 | loss: 0.0698767\n",
      "\tspeed: 0.0197s/iter; left time: 372.8840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0679334 Vali Loss: 0.0784564 Test Loss: 0.0909124\n",
      "Validation loss decreased (0.078653 --> 0.078456).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0700856\n",
      "\tspeed: 0.0387s/iter; left time: 725.7510s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626997\n",
      "\tspeed: 0.0170s/iter; left time: 317.8580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0676696 Vali Loss: 0.0785009 Test Loss: 0.0907203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685565\n",
      "\tspeed: 0.0395s/iter; left time: 731.8634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0664126\n",
      "\tspeed: 0.0238s/iter; left time: 439.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.0672094 Vali Loss: 0.0781273 Test Loss: 0.0906015\n",
      "Validation loss decreased (0.078456 --> 0.078127).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670132\n",
      "\tspeed: 0.0382s/iter; left time: 699.4725s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669249\n",
      "\tspeed: 0.0155s/iter; left time: 281.6242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0672603 Vali Loss: 0.0779196 Test Loss: 0.0904153\n",
      "Validation loss decreased (0.078127 --> 0.077920).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0710368\n",
      "\tspeed: 0.0385s/iter; left time: 696.3137s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682627\n",
      "\tspeed: 0.0175s/iter; left time: 314.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0669857 Vali Loss: 0.0778751 Test Loss: 0.0902119\n",
      "Validation loss decreased (0.077920 --> 0.077875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0657301\n",
      "\tspeed: 0.0428s/iter; left time: 765.0675s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647358\n",
      "\tspeed: 0.0178s/iter; left time: 316.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0667927 Vali Loss: 0.0778582 Test Loss: 0.0903987\n",
      "Validation loss decreased (0.077875 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0681141\n",
      "\tspeed: 0.0423s/iter; left time: 747.5846s\n",
      "\titers: 200, epoch: 21 | loss: 0.0677444\n",
      "\tspeed: 0.0200s/iter; left time: 351.1124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0667123 Vali Loss: 0.0779975 Test Loss: 0.0904759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0687355\n",
      "\tspeed: 0.0387s/iter; left time: 674.1421s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697549\n",
      "\tspeed: 0.0175s/iter; left time: 303.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0666015 Vali Loss: 0.0778401 Test Loss: 0.0906092\n",
      "Validation loss decreased (0.077858 --> 0.077840).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0621076\n",
      "\tspeed: 0.0398s/iter; left time: 684.8051s\n",
      "\titers: 200, epoch: 23 | loss: 0.0626924\n",
      "\tspeed: 0.0179s/iter; left time: 306.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0664471 Vali Loss: 0.0778884 Test Loss: 0.0904079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0643140\n",
      "\tspeed: 0.0415s/iter; left time: 704.6598s\n",
      "\titers: 200, epoch: 24 | loss: 0.0647285\n",
      "\tspeed: 0.0168s/iter; left time: 284.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0663410 Vali Loss: 0.0778038 Test Loss: 0.0905400\n",
      "Validation loss decreased (0.077840 --> 0.077804).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0628065\n",
      "\tspeed: 0.0375s/iter; left time: 628.1917s\n",
      "\titers: 200, epoch: 25 | loss: 0.0644072\n",
      "\tspeed: 0.0185s/iter; left time: 308.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0663549 Vali Loss: 0.0777790 Test Loss: 0.0906833\n",
      "Validation loss decreased (0.077804 --> 0.077779).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0691754\n",
      "\tspeed: 0.0376s/iter; left time: 623.0475s\n",
      "\titers: 200, epoch: 26 | loss: 0.0642033\n",
      "\tspeed: 0.0178s/iter; left time: 292.4690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0660613 Vali Loss: 0.0779034 Test Loss: 0.0905330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0694070\n",
      "\tspeed: 0.0374s/iter; left time: 611.3694s\n",
      "\titers: 200, epoch: 27 | loss: 0.0620312\n",
      "\tspeed: 0.0175s/iter; left time: 283.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0661828 Vali Loss: 0.0779134 Test Loss: 0.0911820\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0623799\n",
      "\tspeed: 0.0373s/iter; left time: 600.9108s\n",
      "\titers: 200, epoch: 28 | loss: 0.0651804\n",
      "\tspeed: 0.0181s/iter; left time: 289.7446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0662137 Vali Loss: 0.0777724 Test Loss: 0.0904204\n",
      "Validation loss decreased (0.077779 --> 0.077772).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0663736\n",
      "\tspeed: 0.0430s/iter; left time: 682.9353s\n",
      "\titers: 200, epoch: 29 | loss: 0.0627826\n",
      "\tspeed: 0.0202s/iter; left time: 318.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0659762 Vali Loss: 0.0777516 Test Loss: 0.0909365\n",
      "Validation loss decreased (0.077772 --> 0.077752).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0658481\n",
      "\tspeed: 0.0386s/iter; left time: 604.3846s\n",
      "\titers: 200, epoch: 30 | loss: 0.0680167\n",
      "\tspeed: 0.0164s/iter; left time: 254.6787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0658545 Vali Loss: 0.0777842 Test Loss: 0.0907960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0663877\n",
      "\tspeed: 0.0358s/iter; left time: 553.5470s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669244\n",
      "\tspeed: 0.0187s/iter; left time: 287.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0660432 Vali Loss: 0.0776771 Test Loss: 0.0908105\n",
      "Validation loss decreased (0.077752 --> 0.077677).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648231\n",
      "\tspeed: 0.0418s/iter; left time: 636.7219s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674317\n",
      "\tspeed: 0.0177s/iter; left time: 267.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0658408 Vali Loss: 0.0777454 Test Loss: 0.0911105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0678782\n",
      "\tspeed: 0.0398s/iter; left time: 596.3924s\n",
      "\titers: 200, epoch: 33 | loss: 0.0643301\n",
      "\tspeed: 0.0174s/iter; left time: 259.1428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0658295 Vali Loss: 0.0776912 Test Loss: 0.0908741\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0642984\n",
      "\tspeed: 0.0376s/iter; left time: 556.0756s\n",
      "\titers: 200, epoch: 34 | loss: 0.0663682\n",
      "\tspeed: 0.0173s/iter; left time: 254.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0658093 Vali Loss: 0.0778673 Test Loss: 0.0911142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0613116\n",
      "\tspeed: 0.0394s/iter; left time: 573.5234s\n",
      "\titers: 200, epoch: 35 | loss: 0.0663639\n",
      "\tspeed: 0.0178s/iter; left time: 257.2753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0657065 Vali Loss: 0.0776919 Test Loss: 0.0911537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0673880\n",
      "\tspeed: 0.0385s/iter; left time: 551.1756s\n",
      "\titers: 200, epoch: 36 | loss: 0.0655852\n",
      "\tspeed: 0.0184s/iter; left time: 262.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0658169 Vali Loss: 0.0775844 Test Loss: 0.0908827\n",
      "Validation loss decreased (0.077677 --> 0.077584).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0649085\n",
      "\tspeed: 0.0375s/iter; left time: 529.5353s\n",
      "\titers: 200, epoch: 37 | loss: 0.0687972\n",
      "\tspeed: 0.0174s/iter; left time: 243.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0656873 Vali Loss: 0.0776541 Test Loss: 0.0911079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0658109\n",
      "\tspeed: 0.0394s/iter; left time: 547.0495s\n",
      "\titers: 200, epoch: 38 | loss: 0.0646297\n",
      "\tspeed: 0.0165s/iter; left time: 228.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0656310 Vali Loss: 0.0777044 Test Loss: 0.0912068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0672379\n",
      "\tspeed: 0.0394s/iter; left time: 538.9655s\n",
      "\titers: 200, epoch: 39 | loss: 0.0658156\n",
      "\tspeed: 0.0178s/iter; left time: 241.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0656917 Vali Loss: 0.0777175 Test Loss: 0.0911222\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0664440\n",
      "\tspeed: 0.0378s/iter; left time: 508.7150s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646944\n",
      "\tspeed: 0.0213s/iter; left time: 284.4754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0656318 Vali Loss: 0.0776022 Test Loss: 0.0910128\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0668205\n",
      "\tspeed: 0.0353s/iter; left time: 466.3559s\n",
      "\titers: 200, epoch: 41 | loss: 0.0617029\n",
      "\tspeed: 0.0162s/iter; left time: 212.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0656555 Vali Loss: 0.0777193 Test Loss: 0.0908986\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0643047\n",
      "\tspeed: 0.0360s/iter; left time: 467.5743s\n",
      "\titers: 200, epoch: 42 | loss: 0.0623269\n",
      "\tspeed: 0.0137s/iter; left time: 176.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 222 | Train Loss: 0.0656471 Vali Loss: 0.0776249 Test Loss: 0.0909272\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0665438\n",
      "\tspeed: 0.0340s/iter; left time: 434.8640s\n",
      "\titers: 200, epoch: 43 | loss: 0.0665644\n",
      "\tspeed: 0.0136s/iter; left time: 172.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 222 | Train Loss: 0.0655494 Vali Loss: 0.0776643 Test Loss: 0.0912756\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0636138\n",
      "\tspeed: 0.0381s/iter; left time: 478.2023s\n",
      "\titers: 200, epoch: 44 | loss: 0.0667647\n",
      "\tspeed: 0.0218s/iter; left time: 271.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0655892 Vali Loss: 0.0776366 Test Loss: 0.0910807\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0639832\n",
      "\tspeed: 0.0382s/iter; left time: 471.0497s\n",
      "\titers: 200, epoch: 45 | loss: 0.0676277\n",
      "\tspeed: 0.0207s/iter; left time: 252.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0655630 Vali Loss: 0.0776766 Test Loss: 0.0912446\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0616794\n",
      "\tspeed: 0.0403s/iter; left time: 488.0305s\n",
      "\titers: 200, epoch: 46 | loss: 0.0644349\n",
      "\tspeed: 0.0169s/iter; left time: 203.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0655509 Vali Loss: 0.0777734 Test Loss: 0.0915146\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02406461164355278, rmse:0.15512773394584656, mae:0.09088271111249924, rse:0.6008243560791016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2319828\n",
      "\tspeed: 0.0208s/iter; left time: 460.0859s\n",
      "\titers: 200, epoch: 1 | loss: 0.2084626\n",
      "\tspeed: 0.0140s/iter; left time: 308.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.2307888 Vali Loss: 0.1796101 Test Loss: 0.1840003\n",
      "Validation loss decreased (inf --> 0.179610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1202659\n",
      "\tspeed: 0.0395s/iter; left time: 864.0371s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984675\n",
      "\tspeed: 0.0185s/iter; left time: 402.3269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.1274008 Vali Loss: 0.0990929 Test Loss: 0.1087501\n",
      "Validation loss decreased (0.179610 --> 0.099093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0897407\n",
      "\tspeed: 0.0387s/iter; left time: 839.1982s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855197\n",
      "\tspeed: 0.0172s/iter; left time: 369.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0903506 Vali Loss: 0.0879331 Test Loss: 0.0963403\n",
      "Validation loss decreased (0.099093 --> 0.087933).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0825203\n",
      "\tspeed: 0.0391s/iter; left time: 838.0633s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801537\n",
      "\tspeed: 0.0175s/iter; left time: 372.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0823310 Vali Loss: 0.0838364 Test Loss: 0.0929438\n",
      "Validation loss decreased (0.087933 --> 0.083836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749546\n",
      "\tspeed: 0.0413s/iter; left time: 876.9361s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733442\n",
      "\tspeed: 0.0206s/iter; left time: 433.9301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.0770342 Vali Loss: 0.0832020 Test Loss: 0.0923905\n",
      "Validation loss decreased (0.083836 --> 0.083202).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0756646\n",
      "\tspeed: 0.0414s/iter; left time: 868.2804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752125\n",
      "\tspeed: 0.0184s/iter; left time: 383.5524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0738238 Vali Loss: 0.0821684 Test Loss: 0.0924239\n",
      "Validation loss decreased (0.083202 --> 0.082168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748782\n",
      "\tspeed: 0.0412s/iter; left time: 854.7743s\n",
      "\titers: 200, epoch: 7 | loss: 0.0701208\n",
      "\tspeed: 0.0211s/iter; left time: 436.0155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0722716 Vali Loss: 0.0809990 Test Loss: 0.0909296\n",
      "Validation loss decreased (0.082168 --> 0.080999).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0695359\n",
      "\tspeed: 0.0409s/iter; left time: 839.8480s\n",
      "\titers: 200, epoch: 8 | loss: 0.0699999\n",
      "\tspeed: 0.0200s/iter; left time: 408.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0712797 Vali Loss: 0.0806755 Test Loss: 0.0912457\n",
      "Validation loss decreased (0.080999 --> 0.080676).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711375\n",
      "\tspeed: 0.0422s/iter; left time: 858.5809s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675557\n",
      "\tspeed: 0.0204s/iter; left time: 413.5276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0706966 Vali Loss: 0.0802653 Test Loss: 0.0908051\n",
      "Validation loss decreased (0.080676 --> 0.080265).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0673644\n",
      "\tspeed: 0.0418s/iter; left time: 840.8172s\n",
      "\titers: 200, epoch: 10 | loss: 0.0680034\n",
      "\tspeed: 0.0175s/iter; left time: 350.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0701715 Vali Loss: 0.0801495 Test Loss: 0.0909027\n",
      "Validation loss decreased (0.080265 --> 0.080150).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679069\n",
      "\tspeed: 0.0425s/iter; left time: 845.0243s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664247\n",
      "\tspeed: 0.0205s/iter; left time: 406.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0695156 Vali Loss: 0.0796842 Test Loss: 0.0904101\n",
      "Validation loss decreased (0.080150 --> 0.079684).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713230\n",
      "\tspeed: 0.0445s/iter; left time: 875.7984s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707975\n",
      "\tspeed: 0.0191s/iter; left time: 374.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0689532 Vali Loss: 0.0795897 Test Loss: 0.0903748\n",
      "Validation loss decreased (0.079684 --> 0.079590).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0669175\n",
      "\tspeed: 0.0384s/iter; left time: 745.5277s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701373\n",
      "\tspeed: 0.0136s/iter; left time: 263.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 222 | Train Loss: 0.0687951 Vali Loss: 0.0795658 Test Loss: 0.0910114\n",
      "Validation loss decreased (0.079590 --> 0.079566).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695180\n",
      "\tspeed: 0.0379s/iter; left time: 727.6017s\n",
      "\titers: 200, epoch: 14 | loss: 0.0676034\n",
      "\tspeed: 0.0170s/iter; left time: 325.7691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0686738 Vali Loss: 0.0796664 Test Loss: 0.0904864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605345\n",
      "\tspeed: 0.0377s/iter; left time: 716.1961s\n",
      "\titers: 200, epoch: 15 | loss: 0.0661341\n",
      "\tspeed: 0.0188s/iter; left time: 355.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0684131 Vali Loss: 0.0796360 Test Loss: 0.0920964\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723512\n",
      "\tspeed: 0.0383s/iter; left time: 718.3627s\n",
      "\titers: 200, epoch: 16 | loss: 0.0658480\n",
      "\tspeed: 0.0167s/iter; left time: 312.7029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0680571 Vali Loss: 0.0791825 Test Loss: 0.0913846\n",
      "Validation loss decreased (0.079566 --> 0.079182).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676597\n",
      "\tspeed: 0.0424s/iter; left time: 785.9359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0627009\n",
      "\tspeed: 0.0179s/iter; left time: 329.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0677229 Vali Loss: 0.0791503 Test Loss: 0.0911777\n",
      "Validation loss decreased (0.079182 --> 0.079150).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679536\n",
      "\tspeed: 0.0417s/iter; left time: 764.0177s\n",
      "\titers: 200, epoch: 18 | loss: 0.0679239\n",
      "\tspeed: 0.0200s/iter; left time: 364.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0676038 Vali Loss: 0.0791089 Test Loss: 0.0913257\n",
      "Validation loss decreased (0.079150 --> 0.079109).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0683040\n",
      "\tspeed: 0.0452s/iter; left time: 817.4763s\n",
      "\titers: 200, epoch: 19 | loss: 0.0664067\n",
      "\tspeed: 0.0223s/iter; left time: 401.4376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 222 | Train Loss: 0.0673737 Vali Loss: 0.0789633 Test Loss: 0.0914856\n",
      "Validation loss decreased (0.079109 --> 0.078963).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0683363\n",
      "\tspeed: 0.0455s/iter; left time: 813.8200s\n",
      "\titers: 200, epoch: 20 | loss: 0.0666111\n",
      "\tspeed: 0.0160s/iter; left time: 284.9897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0673123 Vali Loss: 0.0791622 Test Loss: 0.0923091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651823\n",
      "\tspeed: 0.0387s/iter; left time: 683.9202s\n",
      "\titers: 200, epoch: 21 | loss: 0.0675858\n",
      "\tspeed: 0.0210s/iter; left time: 368.9220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0672142 Vali Loss: 0.0792254 Test Loss: 0.0926093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0655182\n",
      "\tspeed: 0.0377s/iter; left time: 658.2587s\n",
      "\titers: 200, epoch: 22 | loss: 0.0667910\n",
      "\tspeed: 0.0177s/iter; left time: 306.8626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0669031 Vali Loss: 0.0788213 Test Loss: 0.0911421\n",
      "Validation loss decreased (0.078963 --> 0.078821).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0677871\n",
      "\tspeed: 0.0385s/iter; left time: 662.8042s\n",
      "\titers: 200, epoch: 23 | loss: 0.0615978\n",
      "\tspeed: 0.0178s/iter; left time: 303.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0670101 Vali Loss: 0.0786794 Test Loss: 0.0910406\n",
      "Validation loss decreased (0.078821 --> 0.078679).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0684268\n",
      "\tspeed: 0.0423s/iter; left time: 718.1358s\n",
      "\titers: 200, epoch: 24 | loss: 0.0691375\n",
      "\tspeed: 0.0176s/iter; left time: 297.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0669904 Vali Loss: 0.0788834 Test Loss: 0.0914515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0640026\n",
      "\tspeed: 0.0361s/iter; left time: 605.3894s\n",
      "\titers: 200, epoch: 25 | loss: 0.0652691\n",
      "\tspeed: 0.0171s/iter; left time: 285.9267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0668501 Vali Loss: 0.0787182 Test Loss: 0.0917424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0634801\n",
      "\tspeed: 0.0394s/iter; left time: 651.4845s\n",
      "\titers: 200, epoch: 26 | loss: 0.0674998\n",
      "\tspeed: 0.0189s/iter; left time: 310.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0667452 Vali Loss: 0.0787112 Test Loss: 0.0914333\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0656401\n",
      "\tspeed: 0.0363s/iter; left time: 592.7070s\n",
      "\titers: 200, epoch: 27 | loss: 0.0628682\n",
      "\tspeed: 0.0186s/iter; left time: 301.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0666480 Vali Loss: 0.0785765 Test Loss: 0.0913582\n",
      "Validation loss decreased (0.078679 --> 0.078576).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0666436\n",
      "\tspeed: 0.0374s/iter; left time: 602.4835s\n",
      "\titers: 200, epoch: 28 | loss: 0.0661310\n",
      "\tspeed: 0.0182s/iter; left time: 290.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0666455 Vali Loss: 0.0786015 Test Loss: 0.0910953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0668129\n",
      "\tspeed: 0.0391s/iter; left time: 620.4148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0659632\n",
      "\tspeed: 0.0188s/iter; left time: 296.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0665038 Vali Loss: 0.0785815 Test Loss: 0.0910819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0677124\n",
      "\tspeed: 0.0388s/iter; left time: 607.1669s\n",
      "\titers: 200, epoch: 30 | loss: 0.0662659\n",
      "\tspeed: 0.0177s/iter; left time: 275.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0664562 Vali Loss: 0.0785316 Test Loss: 0.0916162\n",
      "Validation loss decreased (0.078576 --> 0.078532).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0664014\n",
      "\tspeed: 0.0398s/iter; left time: 614.2327s\n",
      "\titers: 200, epoch: 31 | loss: 0.0675983\n",
      "\tspeed: 0.0181s/iter; left time: 277.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0665412 Vali Loss: 0.0784587 Test Loss: 0.0906658\n",
      "Validation loss decreased (0.078532 --> 0.078459).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0675416\n",
      "\tspeed: 0.0382s/iter; left time: 581.5416s\n",
      "\titers: 200, epoch: 32 | loss: 0.0640216\n",
      "\tspeed: 0.0169s/iter; left time: 255.5414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0664777 Vali Loss: 0.0783697 Test Loss: 0.0903753\n",
      "Validation loss decreased (0.078459 --> 0.078370).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0659781\n",
      "\tspeed: 0.0383s/iter; left time: 573.9901s\n",
      "\titers: 200, epoch: 33 | loss: 0.0637254\n",
      "\tspeed: 0.0174s/iter; left time: 259.3200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0664676 Vali Loss: 0.0785606 Test Loss: 0.0918490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0616548\n",
      "\tspeed: 0.0409s/iter; left time: 603.7818s\n",
      "\titers: 200, epoch: 34 | loss: 0.0680450\n",
      "\tspeed: 0.0185s/iter; left time: 271.7520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0663375 Vali Loss: 0.0784621 Test Loss: 0.0912215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0649782\n",
      "\tspeed: 0.0395s/iter; left time: 574.2563s\n",
      "\titers: 200, epoch: 35 | loss: 0.0701866\n",
      "\tspeed: 0.0172s/iter; left time: 248.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0663069 Vali Loss: 0.0784806 Test Loss: 0.0915692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0645071\n",
      "\tspeed: 0.0377s/iter; left time: 539.6144s\n",
      "\titers: 200, epoch: 36 | loss: 0.0655820\n",
      "\tspeed: 0.0175s/iter; left time: 248.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0662163 Vali Loss: 0.0784675 Test Loss: 0.0912538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0640461\n",
      "\tspeed: 0.0394s/iter; left time: 555.5494s\n",
      "\titers: 200, epoch: 37 | loss: 0.0639115\n",
      "\tspeed: 0.0176s/iter; left time: 246.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0662549 Vali Loss: 0.0785017 Test Loss: 0.0913716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0661257\n",
      "\tspeed: 0.0452s/iter; left time: 627.0010s\n",
      "\titers: 200, epoch: 38 | loss: 0.0696747\n",
      "\tspeed: 0.0176s/iter; left time: 242.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.0662728 Vali Loss: 0.0784343 Test Loss: 0.0914996\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0616808\n",
      "\tspeed: 0.0411s/iter; left time: 561.1223s\n",
      "\titers: 200, epoch: 39 | loss: 0.0674529\n",
      "\tspeed: 0.0184s/iter; left time: 249.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0662466 Vali Loss: 0.0783954 Test Loss: 0.0913800\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0670593\n",
      "\tspeed: 0.0384s/iter; left time: 515.8336s\n",
      "\titers: 200, epoch: 40 | loss: 0.0633850\n",
      "\tspeed: 0.0199s/iter; left time: 265.5372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0662610 Vali Loss: 0.0785325 Test Loss: 0.0916123\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0660525\n",
      "\tspeed: 0.0366s/iter; left time: 484.0771s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672518\n",
      "\tspeed: 0.0178s/iter; left time: 233.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0661967 Vali Loss: 0.0785772 Test Loss: 0.0923340\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0678602\n",
      "\tspeed: 0.0398s/iter; left time: 517.1286s\n",
      "\titers: 200, epoch: 42 | loss: 0.0668587\n",
      "\tspeed: 0.0184s/iter; left time: 237.2919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0663821 Vali Loss: 0.0784219 Test Loss: 0.0909432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023561760783195496, rmse:0.15349841117858887, mae:0.09037524461746216, rse:0.5945138931274414\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:36.93s\n",
      "Intermediate time for FR: 00h:32m:32.06s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2613267\n",
      "\tspeed: 0.0392s/iter; left time: 870.4805s\n",
      "\titers: 200, epoch: 1 | loss: 0.2446445\n",
      "\tspeed: 0.0180s/iter; left time: 397.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.2666068 Vali Loss: 0.1840600 Test Loss: 0.1914255\n",
      "Validation loss decreased (inf --> 0.184060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497402\n",
      "\tspeed: 0.0343s/iter; left time: 752.8987s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122778\n",
      "\tspeed: 0.0138s/iter; left time: 302.1122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.1534578 Vali Loss: 0.0864928 Test Loss: 0.0884348\n",
      "Validation loss decreased (0.184060 --> 0.086493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1031142\n",
      "\tspeed: 0.0343s/iter; left time: 746.3037s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902892\n",
      "\tspeed: 0.0175s/iter; left time: 379.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0977980 Vali Loss: 0.0769380 Test Loss: 0.0806744\n",
      "Validation loss decreased (0.086493 --> 0.076938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854379\n",
      "\tspeed: 0.0361s/iter; left time: 777.9086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809595\n",
      "\tspeed: 0.0185s/iter; left time: 396.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0846276 Vali Loss: 0.0736284 Test Loss: 0.0773814\n",
      "Validation loss decreased (0.076938 --> 0.073628).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748807\n",
      "\tspeed: 0.0385s/iter; left time: 819.3837s\n",
      "\titers: 200, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0192s/iter; left time: 407.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0772823 Vali Loss: 0.0687476 Test Loss: 0.0723286\n",
      "Validation loss decreased (0.073628 --> 0.068748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768507\n",
      "\tspeed: 0.0345s/iter; left time: 727.4867s\n",
      "\titers: 200, epoch: 6 | loss: 0.0710905\n",
      "\tspeed: 0.0187s/iter; left time: 392.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0735575 Vali Loss: 0.0683415 Test Loss: 0.0712536\n",
      "Validation loss decreased (0.068748 --> 0.068342).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0729222\n",
      "\tspeed: 0.0341s/iter; left time: 710.4905s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723143\n",
      "\tspeed: 0.0207s/iter; left time: 428.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0710755 Vali Loss: 0.0655078 Test Loss: 0.0690658\n",
      "Validation loss decreased (0.068342 --> 0.065508).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0695795\n",
      "\tspeed: 0.0356s/iter; left time: 735.0171s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734919\n",
      "\tspeed: 0.0134s/iter; left time: 274.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.0693097 Vali Loss: 0.0642290 Test Loss: 0.0678487\n",
      "Validation loss decreased (0.065508 --> 0.064229).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0642837\n",
      "\tspeed: 0.0311s/iter; left time: 635.2477s\n",
      "\titers: 200, epoch: 9 | loss: 0.0674841\n",
      "\tspeed: 0.0132s/iter; left time: 268.7490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 223 | Train Loss: 0.0678791 Vali Loss: 0.0636194 Test Loss: 0.0669367\n",
      "Validation loss decreased (0.064229 --> 0.063619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0673314\n",
      "\tspeed: 0.0353s/iter; left time: 713.0350s\n",
      "\titers: 200, epoch: 10 | loss: 0.0682601\n",
      "\tspeed: 0.0194s/iter; left time: 389.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0672177 Vali Loss: 0.0630238 Test Loss: 0.0665055\n",
      "Validation loss decreased (0.063619 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0671064\n",
      "\tspeed: 0.0366s/iter; left time: 731.2547s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658044\n",
      "\tspeed: 0.0177s/iter; left time: 351.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0662129 Vali Loss: 0.0630377 Test Loss: 0.0666590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0651188\n",
      "\tspeed: 0.0340s/iter; left time: 671.0878s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650911\n",
      "\tspeed: 0.0189s/iter; left time: 372.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0653732 Vali Loss: 0.0619107 Test Loss: 0.0653360\n",
      "Validation loss decreased (0.063024 --> 0.061911).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0632853\n",
      "\tspeed: 0.0344s/iter; left time: 670.6916s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712935\n",
      "\tspeed: 0.0186s/iter; left time: 360.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0646758 Vali Loss: 0.0623154 Test Loss: 0.0656084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0596975\n",
      "\tspeed: 0.0410s/iter; left time: 791.5529s\n",
      "\titers: 200, epoch: 14 | loss: 0.0668238\n",
      "\tspeed: 0.0205s/iter; left time: 392.8672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0641173 Vali Loss: 0.0612675 Test Loss: 0.0644853\n",
      "Validation loss decreased (0.061911 --> 0.061268).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0588378\n",
      "\tspeed: 0.0383s/iter; left time: 731.5467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0607067\n",
      "\tspeed: 0.0196s/iter; left time: 372.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0638006 Vali Loss: 0.0608089 Test Loss: 0.0640089\n",
      "Validation loss decreased (0.061268 --> 0.060809).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0661558\n",
      "\tspeed: 0.0369s/iter; left time: 696.0259s\n",
      "\titers: 200, epoch: 16 | loss: 0.0590718\n",
      "\tspeed: 0.0204s/iter; left time: 382.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0634317 Vali Loss: 0.0605441 Test Loss: 0.0635168\n",
      "Validation loss decreased (0.060809 --> 0.060544).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0618667\n",
      "\tspeed: 0.0399s/iter; left time: 744.2515s\n",
      "\titers: 200, epoch: 17 | loss: 0.0566609\n",
      "\tspeed: 0.0213s/iter; left time: 394.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0640653 Vali Loss: 0.0602748 Test Loss: 0.0635381\n",
      "Validation loss decreased (0.060544 --> 0.060275).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0654053\n",
      "\tspeed: 0.0385s/iter; left time: 709.5459s\n",
      "\titers: 200, epoch: 18 | loss: 0.0615840\n",
      "\tspeed: 0.0203s/iter; left time: 371.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0632089 Vali Loss: 0.0605393 Test Loss: 0.0638801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0613055\n",
      "\tspeed: 0.0372s/iter; left time: 676.6927s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682047\n",
      "\tspeed: 0.0220s/iter; left time: 397.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0627610 Vali Loss: 0.0601602 Test Loss: 0.0631403\n",
      "Validation loss decreased (0.060275 --> 0.060160).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0593312\n",
      "\tspeed: 0.0384s/iter; left time: 689.5834s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653080\n",
      "\tspeed: 0.0194s/iter; left time: 347.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0625884 Vali Loss: 0.0598175 Test Loss: 0.0629922\n",
      "Validation loss decreased (0.060160 --> 0.059817).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0676790\n",
      "\tspeed: 0.0411s/iter; left time: 729.4543s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658659\n",
      "\tspeed: 0.0224s/iter; left time: 395.8608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0624293 Vali Loss: 0.0600168 Test Loss: 0.0629384\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0614464\n",
      "\tspeed: 0.0354s/iter; left time: 620.2414s\n",
      "\titers: 200, epoch: 22 | loss: 0.0614755\n",
      "\tspeed: 0.0165s/iter; left time: 287.6452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0622742 Vali Loss: 0.0598513 Test Loss: 0.0629770\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0584518\n",
      "\tspeed: 0.0334s/iter; left time: 576.8014s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606909\n",
      "\tspeed: 0.0169s/iter; left time: 290.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0619770 Vali Loss: 0.0594832 Test Loss: 0.0625747\n",
      "Validation loss decreased (0.059817 --> 0.059483).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0611410\n",
      "\tspeed: 0.0367s/iter; left time: 626.9684s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620168\n",
      "\tspeed: 0.0186s/iter; left time: 315.2457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0620027 Vali Loss: 0.0597211 Test Loss: 0.0627181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0620445\n",
      "\tspeed: 0.0381s/iter; left time: 641.2737s\n",
      "\titers: 200, epoch: 25 | loss: 0.0627680\n",
      "\tspeed: 0.0205s/iter; left time: 343.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0616908 Vali Loss: 0.0594576 Test Loss: 0.0624559\n",
      "Validation loss decreased (0.059483 --> 0.059458).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0620271\n",
      "\tspeed: 0.0379s/iter; left time: 630.0251s\n",
      "\titers: 200, epoch: 26 | loss: 0.0575310\n",
      "\tspeed: 0.0180s/iter; left time: 297.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0617656 Vali Loss: 0.0596068 Test Loss: 0.0625476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0598931\n",
      "\tspeed: 0.0348s/iter; left time: 571.4102s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633982\n",
      "\tspeed: 0.0182s/iter; left time: 296.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0615633 Vali Loss: 0.0595073 Test Loss: 0.0624505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630150\n",
      "\tspeed: 0.0342s/iter; left time: 553.3334s\n",
      "\titers: 200, epoch: 28 | loss: 0.0613112\n",
      "\tspeed: 0.0188s/iter; left time: 302.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0615299 Vali Loss: 0.0594390 Test Loss: 0.0625015\n",
      "Validation loss decreased (0.059458 --> 0.059439).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0623488\n",
      "\tspeed: 0.0389s/iter; left time: 621.1002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0628008\n",
      "\tspeed: 0.0168s/iter; left time: 265.9654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0614410 Vali Loss: 0.0591361 Test Loss: 0.0620808\n",
      "Validation loss decreased (0.059439 --> 0.059136).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578748\n",
      "\tspeed: 0.0358s/iter; left time: 562.8179s\n",
      "\titers: 200, epoch: 30 | loss: 0.0640098\n",
      "\tspeed: 0.0184s/iter; left time: 287.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0613836 Vali Loss: 0.0591412 Test Loss: 0.0622279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0638591\n",
      "\tspeed: 0.0342s/iter; left time: 530.8493s\n",
      "\titers: 200, epoch: 31 | loss: 0.0630033\n",
      "\tspeed: 0.0188s/iter; left time: 290.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0614346 Vali Loss: 0.0593630 Test Loss: 0.0622768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0617785\n",
      "\tspeed: 0.0354s/iter; left time: 541.0564s\n",
      "\titers: 200, epoch: 32 | loss: 0.0627892\n",
      "\tspeed: 0.0172s/iter; left time: 261.0117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0612977 Vali Loss: 0.0591567 Test Loss: 0.0619966\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0603411\n",
      "\tspeed: 0.0414s/iter; left time: 623.9199s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641707\n",
      "\tspeed: 0.0225s/iter; left time: 336.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0613798 Vali Loss: 0.0589896 Test Loss: 0.0621368\n",
      "Validation loss decreased (0.059136 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0657505\n",
      "\tspeed: 0.0390s/iter; left time: 579.4446s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526833\n",
      "\tspeed: 0.0198s/iter; left time: 292.0924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0611487 Vali Loss: 0.0590259 Test Loss: 0.0620669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645364\n",
      "\tspeed: 0.0358s/iter; left time: 523.0043s\n",
      "\titers: 200, epoch: 35 | loss: 0.0628361\n",
      "\tspeed: 0.0177s/iter; left time: 257.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0609772 Vali Loss: 0.0591559 Test Loss: 0.0619222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0613310\n",
      "\tspeed: 0.0315s/iter; left time: 452.8304s\n",
      "\titers: 200, epoch: 36 | loss: 0.0621967\n",
      "\tspeed: 0.0194s/iter; left time: 276.9442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0610524 Vali Loss: 0.0590193 Test Loss: 0.0619030\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0577797\n",
      "\tspeed: 0.0341s/iter; left time: 483.6963s\n",
      "\titers: 200, epoch: 37 | loss: 0.0633397\n",
      "\tspeed: 0.0177s/iter; left time: 248.9751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0610985 Vali Loss: 0.0589273 Test Loss: 0.0618850\n",
      "Validation loss decreased (0.058990 --> 0.058927).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0607721\n",
      "\tspeed: 0.0336s/iter; left time: 468.7654s\n",
      "\titers: 200, epoch: 38 | loss: 0.0587756\n",
      "\tspeed: 0.0161s/iter; left time: 223.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0611439 Vali Loss: 0.0591564 Test Loss: 0.0619709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0606503\n",
      "\tspeed: 0.0338s/iter; left time: 463.8955s\n",
      "\titers: 200, epoch: 39 | loss: 0.0621387\n",
      "\tspeed: 0.0165s/iter; left time: 224.9604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0609651 Vali Loss: 0.0588507 Test Loss: 0.0619381\n",
      "Validation loss decreased (0.058927 --> 0.058851).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0650060\n",
      "\tspeed: 0.0357s/iter; left time: 482.3871s\n",
      "\titers: 200, epoch: 40 | loss: 0.0615220\n",
      "\tspeed: 0.0182s/iter; left time: 243.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0608909 Vali Loss: 0.0590737 Test Loss: 0.0619943\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0583368\n",
      "\tspeed: 0.0340s/iter; left time: 451.5528s\n",
      "\titers: 200, epoch: 41 | loss: 0.0623025\n",
      "\tspeed: 0.0201s/iter; left time: 264.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0610516 Vali Loss: 0.0589446 Test Loss: 0.0617396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0593722\n",
      "\tspeed: 0.0341s/iter; left time: 445.8905s\n",
      "\titers: 200, epoch: 42 | loss: 0.0642216\n",
      "\tspeed: 0.0132s/iter; left time: 170.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 223 | Train Loss: 0.0609676 Vali Loss: 0.0589558 Test Loss: 0.0618359\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0620654\n",
      "\tspeed: 0.0384s/iter; left time: 492.9891s\n",
      "\titers: 200, epoch: 43 | loss: 0.0551790\n",
      "\tspeed: 0.0188s/iter; left time: 239.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0609758 Vali Loss: 0.0590449 Test Loss: 0.0618489\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0608172\n",
      "\tspeed: 0.0354s/iter; left time: 446.1572s\n",
      "\titers: 200, epoch: 44 | loss: 0.0628253\n",
      "\tspeed: 0.0196s/iter; left time: 245.4804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0607553 Vali Loss: 0.0588690 Test Loss: 0.0617649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0613841\n",
      "\tspeed: 0.0366s/iter; left time: 453.8377s\n",
      "\titers: 200, epoch: 45 | loss: 0.0639292\n",
      "\tspeed: 0.0206s/iter; left time: 252.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0608602 Vali Loss: 0.0588656 Test Loss: 0.0618464\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0583891\n",
      "\tspeed: 0.0370s/iter; left time: 450.5684s\n",
      "\titers: 200, epoch: 46 | loss: 0.0602550\n",
      "\tspeed: 0.0177s/iter; left time: 213.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0609415 Vali Loss: 0.0587919 Test Loss: 0.0617911\n",
      "Validation loss decreased (0.058851 --> 0.058792).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0639604\n",
      "\tspeed: 0.0379s/iter; left time: 453.0558s\n",
      "\titers: 200, epoch: 47 | loss: 0.0653370\n",
      "\tspeed: 0.0194s/iter; left time: 229.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0608470 Vali Loss: 0.0588511 Test Loss: 0.0617494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0593503\n",
      "\tspeed: 0.0395s/iter; left time: 463.1102s\n",
      "\titers: 200, epoch: 48 | loss: 0.0613594\n",
      "\tspeed: 0.0185s/iter; left time: 214.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0609415 Vali Loss: 0.0588569 Test Loss: 0.0617537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0603362\n",
      "\tspeed: 0.0424s/iter; left time: 487.4355s\n",
      "\titers: 200, epoch: 49 | loss: 0.0597747\n",
      "\tspeed: 0.0218s/iter; left time: 248.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0608540 Vali Loss: 0.0588741 Test Loss: 0.0617944\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0653773\n",
      "\tspeed: 0.0401s/iter; left time: 451.7034s\n",
      "\titers: 200, epoch: 50 | loss: 0.0632145\n",
      "\tspeed: 0.0216s/iter; left time: 241.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0608770 Vali Loss: 0.0587537 Test Loss: 0.0618283\n",
      "Validation loss decreased (0.058792 --> 0.058754).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0580339\n",
      "\tspeed: 0.0388s/iter; left time: 428.6055s\n",
      "\titers: 200, epoch: 51 | loss: 0.0605934\n",
      "\tspeed: 0.0177s/iter; left time: 193.9244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0609557 Vali Loss: 0.0588175 Test Loss: 0.0617933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0606185\n",
      "\tspeed: 0.0358s/iter; left time: 388.0351s\n",
      "\titers: 200, epoch: 52 | loss: 0.0588947\n",
      "\tspeed: 0.0165s/iter; left time: 177.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0607469 Vali Loss: 0.0588645 Test Loss: 0.0618061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0596454\n",
      "\tspeed: 0.0361s/iter; left time: 383.0568s\n",
      "\titers: 200, epoch: 53 | loss: 0.0588593\n",
      "\tspeed: 0.0185s/iter; left time: 194.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0608250 Vali Loss: 0.0587320 Test Loss: 0.0618455\n",
      "Validation loss decreased (0.058754 --> 0.058732).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0631147\n",
      "\tspeed: 0.0350s/iter; left time: 363.7887s\n",
      "\titers: 200, epoch: 54 | loss: 0.0594384\n",
      "\tspeed: 0.0176s/iter; left time: 180.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0609803 Vali Loss: 0.0588939 Test Loss: 0.0618061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0568584\n",
      "\tspeed: 0.0346s/iter; left time: 351.5851s\n",
      "\titers: 200, epoch: 55 | loss: 0.0621192\n",
      "\tspeed: 0.0190s/iter; left time: 190.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0607608 Vali Loss: 0.0588212 Test Loss: 0.0617022\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0570619\n",
      "\tspeed: 0.0380s/iter; left time: 377.6111s\n",
      "\titers: 200, epoch: 56 | loss: 0.0623090\n",
      "\tspeed: 0.0229s/iter; left time: 225.6568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0607289 Vali Loss: 0.0587791 Test Loss: 0.0617858\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0594441\n",
      "\tspeed: 0.0388s/iter; left time: 376.7370s\n",
      "\titers: 200, epoch: 57 | loss: 0.0558800\n",
      "\tspeed: 0.0182s/iter; left time: 174.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0607479 Vali Loss: 0.0588879 Test Loss: 0.0617320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0600957\n",
      "\tspeed: 0.0318s/iter; left time: 301.8804s\n",
      "\titers: 200, epoch: 58 | loss: 0.0602918\n",
      "\tspeed: 0.0132s/iter; left time: 123.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0608448 Vali Loss: 0.0587269 Test Loss: 0.0617501\n",
      "Validation loss decreased (0.058732 --> 0.058727).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0602974\n",
      "\tspeed: 0.0336s/iter; left time: 311.3301s\n",
      "\titers: 200, epoch: 59 | loss: 0.0584449\n",
      "\tspeed: 0.0167s/iter; left time: 153.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0608016 Vali Loss: 0.0588245 Test Loss: 0.0618007\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0615578\n",
      "\tspeed: 0.0362s/iter; left time: 327.8013s\n",
      "\titers: 200, epoch: 60 | loss: 0.0613358\n",
      "\tspeed: 0.0177s/iter; left time: 158.6171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0606737 Vali Loss: 0.0588306 Test Loss: 0.0617119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0588411\n",
      "\tspeed: 0.0367s/iter; left time: 323.5792s\n",
      "\titers: 200, epoch: 61 | loss: 0.0587410\n",
      "\tspeed: 0.0214s/iter; left time: 186.2929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0608954 Vali Loss: 0.0588355 Test Loss: 0.0617781\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0578414\n",
      "\tspeed: 0.0360s/iter; left time: 309.6467s\n",
      "\titers: 200, epoch: 62 | loss: 0.0639606\n",
      "\tspeed: 0.0179s/iter; left time: 152.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0606342 Vali Loss: 0.0587989 Test Loss: 0.0617433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0601831\n",
      "\tspeed: 0.0360s/iter; left time: 301.2185s\n",
      "\titers: 200, epoch: 63 | loss: 0.0632877\n",
      "\tspeed: 0.0169s/iter; left time: 139.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0606488 Vali Loss: 0.0587607 Test Loss: 0.0617137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0606772\n",
      "\tspeed: 0.0321s/iter; left time: 261.2870s\n",
      "\titers: 200, epoch: 64 | loss: 0.0595985\n",
      "\tspeed: 0.0133s/iter; left time: 106.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 223 | Train Loss: 0.0606772 Vali Loss: 0.0588284 Test Loss: 0.0617719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0598041\n",
      "\tspeed: 0.0323s/iter; left time: 256.0558s\n",
      "\titers: 200, epoch: 65 | loss: 0.0576087\n",
      "\tspeed: 0.0175s/iter; left time: 136.9940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0610323 Vali Loss: 0.0588839 Test Loss: 0.0617702\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0596291\n",
      "\tspeed: 0.0336s/iter; left time: 259.2886s\n",
      "\titers: 200, epoch: 66 | loss: 0.0590288\n",
      "\tspeed: 0.0169s/iter; left time: 128.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0607707 Vali Loss: 0.0587562 Test Loss: 0.0617330\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0609282\n",
      "\tspeed: 0.0336s/iter; left time: 251.7096s\n",
      "\titers: 200, epoch: 67 | loss: 0.0632504\n",
      "\tspeed: 0.0172s/iter; left time: 127.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0608283 Vali Loss: 0.0589284 Test Loss: 0.0617660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0573190\n",
      "\tspeed: 0.0305s/iter; left time: 221.0954s\n",
      "\titers: 200, epoch: 68 | loss: 0.0583250\n",
      "\tspeed: 0.0170s/iter; left time: 121.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.0607404 Vali Loss: 0.0588340 Test Loss: 0.0616791\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010783816687762737, rmse:0.10384515672922134, mae:0.061750106513500214, rse:0.3923797011375427\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2633380\n",
      "\tspeed: 0.0213s/iter; left time: 473.4067s\n",
      "\titers: 200, epoch: 1 | loss: 0.2407372\n",
      "\tspeed: 0.0192s/iter; left time: 424.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.2640402 Vali Loss: 0.1804014 Test Loss: 0.1877910\n",
      "Validation loss decreased (inf --> 0.180401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1468459\n",
      "\tspeed: 0.0404s/iter; left time: 887.5370s\n",
      "\titers: 200, epoch: 2 | loss: 0.1099515\n",
      "\tspeed: 0.0191s/iter; left time: 417.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1528204 Vali Loss: 0.0868056 Test Loss: 0.0895790\n",
      "Validation loss decreased (0.180401 --> 0.086806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0964038\n",
      "\tspeed: 0.0387s/iter; left time: 841.0022s\n",
      "\titers: 200, epoch: 3 | loss: 0.0842642\n",
      "\tspeed: 0.0182s/iter; left time: 395.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0969877 Vali Loss: 0.0785030 Test Loss: 0.0825628\n",
      "Validation loss decreased (0.086806 --> 0.078503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810436\n",
      "\tspeed: 0.0420s/iter; left time: 904.5802s\n",
      "\titers: 200, epoch: 4 | loss: 0.0776492\n",
      "\tspeed: 0.0160s/iter; left time: 342.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0846801 Vali Loss: 0.0728767 Test Loss: 0.0769952\n",
      "Validation loss decreased (0.078503 --> 0.072877).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784938\n",
      "\tspeed: 0.0398s/iter; left time: 847.2530s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754372\n",
      "\tspeed: 0.0224s/iter; left time: 474.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0779213 Vali Loss: 0.0707370 Test Loss: 0.0739268\n",
      "Validation loss decreased (0.072877 --> 0.070737).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0719557\n",
      "\tspeed: 0.0379s/iter; left time: 799.7366s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751791\n",
      "\tspeed: 0.0210s/iter; left time: 441.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0745827 Vali Loss: 0.0686857 Test Loss: 0.0711119\n",
      "Validation loss decreased (0.070737 --> 0.068686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0687462\n",
      "\tspeed: 0.0369s/iter; left time: 769.1163s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699917\n",
      "\tspeed: 0.0188s/iter; left time: 391.3065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0719870 Vali Loss: 0.0662156 Test Loss: 0.0687054\n",
      "Validation loss decreased (0.068686 --> 0.066216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0733410\n",
      "\tspeed: 0.0388s/iter; left time: 801.2863s\n",
      "\titers: 200, epoch: 8 | loss: 0.0698235\n",
      "\tspeed: 0.0224s/iter; left time: 460.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0698144 Vali Loss: 0.0660703 Test Loss: 0.0690490\n",
      "Validation loss decreased (0.066216 --> 0.066070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645584\n",
      "\tspeed: 0.0380s/iter; left time: 774.9395s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675166\n",
      "\tspeed: 0.0198s/iter; left time: 402.0332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0686722 Vali Loss: 0.0640057 Test Loss: 0.0668120\n",
      "Validation loss decreased (0.066070 --> 0.064006).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0677028\n",
      "\tspeed: 0.0415s/iter; left time: 838.2584s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655631\n",
      "\tspeed: 0.0204s/iter; left time: 409.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0674993 Vali Loss: 0.0634299 Test Loss: 0.0662320\n",
      "Validation loss decreased (0.064006 --> 0.063430).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675405\n",
      "\tspeed: 0.0349s/iter; left time: 696.3599s\n",
      "\titers: 200, epoch: 11 | loss: 0.0689366\n",
      "\tspeed: 0.0180s/iter; left time: 358.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0662033 Vali Loss: 0.0624996 Test Loss: 0.0652963\n",
      "Validation loss decreased (0.063430 --> 0.062500).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0665987\n",
      "\tspeed: 0.0386s/iter; left time: 761.6582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0673204\n",
      "\tspeed: 0.0200s/iter; left time: 393.1114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0657239 Vali Loss: 0.0617468 Test Loss: 0.0645706\n",
      "Validation loss decreased (0.062500 --> 0.061747).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0607038\n",
      "\tspeed: 0.0390s/iter; left time: 762.3146s\n",
      "\titers: 200, epoch: 13 | loss: 0.0643402\n",
      "\tspeed: 0.0232s/iter; left time: 449.8927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0647358 Vali Loss: 0.0621991 Test Loss: 0.0647919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0612636\n",
      "\tspeed: 0.0397s/iter; left time: 766.4091s\n",
      "\titers: 200, epoch: 14 | loss: 0.0642949\n",
      "\tspeed: 0.0185s/iter; left time: 355.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0642953 Vali Loss: 0.0618577 Test Loss: 0.0641777\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638503\n",
      "\tspeed: 0.0384s/iter; left time: 731.9126s\n",
      "\titers: 200, epoch: 15 | loss: 0.0629039\n",
      "\tspeed: 0.0202s/iter; left time: 382.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0638525 Vali Loss: 0.0608925 Test Loss: 0.0636975\n",
      "Validation loss decreased (0.061747 --> 0.060893).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0654804\n",
      "\tspeed: 0.0393s/iter; left time: 740.5489s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626004\n",
      "\tspeed: 0.0183s/iter; left time: 343.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0635759 Vali Loss: 0.0613872 Test Loss: 0.0638123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0584193\n",
      "\tspeed: 0.0355s/iter; left time: 662.2514s\n",
      "\titers: 200, epoch: 17 | loss: 0.0640702\n",
      "\tspeed: 0.0196s/iter; left time: 363.0903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0632551 Vali Loss: 0.0610209 Test Loss: 0.0638186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0611378\n",
      "\tspeed: 0.0369s/iter; left time: 679.8868s\n",
      "\titers: 200, epoch: 18 | loss: 0.0612500\n",
      "\tspeed: 0.0177s/iter; left time: 323.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0628963 Vali Loss: 0.0606032 Test Loss: 0.0633813\n",
      "Validation loss decreased (0.060893 --> 0.060603).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0647264\n",
      "\tspeed: 0.0375s/iter; left time: 681.8500s\n",
      "\titers: 200, epoch: 19 | loss: 0.0600833\n",
      "\tspeed: 0.0197s/iter; left time: 356.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0627335 Vali Loss: 0.0602867 Test Loss: 0.0629789\n",
      "Validation loss decreased (0.060603 --> 0.060287).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0646587\n",
      "\tspeed: 0.0401s/iter; left time: 719.9705s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656286\n",
      "\tspeed: 0.0190s/iter; left time: 339.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0624415 Vali Loss: 0.0603150 Test Loss: 0.0628516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0615701\n",
      "\tspeed: 0.0386s/iter; left time: 684.7756s\n",
      "\titers: 200, epoch: 21 | loss: 0.0589596\n",
      "\tspeed: 0.0207s/iter; left time: 365.0449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0621869 Vali Loss: 0.0601617 Test Loss: 0.0627929\n",
      "Validation loss decreased (0.060287 --> 0.060162).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0636734\n",
      "\tspeed: 0.0400s/iter; left time: 700.8462s\n",
      "\titers: 200, epoch: 22 | loss: 0.0578523\n",
      "\tspeed: 0.0210s/iter; left time: 366.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0619746 Vali Loss: 0.0602780 Test Loss: 0.0630128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0594606\n",
      "\tspeed: 0.0410s/iter; left time: 708.6019s\n",
      "\titers: 200, epoch: 23 | loss: 0.0620950\n",
      "\tspeed: 0.0199s/iter; left time: 342.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0617785 Vali Loss: 0.0596992 Test Loss: 0.0623079\n",
      "Validation loss decreased (0.060162 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0690234\n",
      "\tspeed: 0.0421s/iter; left time: 719.3964s\n",
      "\titers: 200, epoch: 24 | loss: 0.0567295\n",
      "\tspeed: 0.0192s/iter; left time: 325.7787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0617492 Vali Loss: 0.0594711 Test Loss: 0.0622098\n",
      "Validation loss decreased (0.059699 --> 0.059471).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0596324\n",
      "\tspeed: 0.0400s/iter; left time: 673.2165s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655351\n",
      "\tspeed: 0.0212s/iter; left time: 354.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0616514 Vali Loss: 0.0594251 Test Loss: 0.0621977\n",
      "Validation loss decreased (0.059471 --> 0.059425).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628192\n",
      "\tspeed: 0.0376s/iter; left time: 625.6740s\n",
      "\titers: 200, epoch: 26 | loss: 0.0592243\n",
      "\tspeed: 0.0198s/iter; left time: 327.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0613750 Vali Loss: 0.0594440 Test Loss: 0.0619988\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0624912\n",
      "\tspeed: 0.0362s/iter; left time: 593.3288s\n",
      "\titers: 200, epoch: 27 | loss: 0.0627666\n",
      "\tspeed: 0.0174s/iter; left time: 284.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0613563 Vali Loss: 0.0592246 Test Loss: 0.0619628\n",
      "Validation loss decreased (0.059425 --> 0.059225).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0587200\n",
      "\tspeed: 0.0385s/iter; left time: 623.1470s\n",
      "\titers: 200, epoch: 28 | loss: 0.0633633\n",
      "\tspeed: 0.0224s/iter; left time: 359.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0613557 Vali Loss: 0.0592879 Test Loss: 0.0619209\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0608271\n",
      "\tspeed: 0.0431s/iter; left time: 687.2135s\n",
      "\titers: 200, epoch: 29 | loss: 0.0591856\n",
      "\tspeed: 0.0199s/iter; left time: 315.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0612707 Vali Loss: 0.0591873 Test Loss: 0.0619315\n",
      "Validation loss decreased (0.059225 --> 0.059187).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0615196\n",
      "\tspeed: 0.0358s/iter; left time: 563.1784s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605555\n",
      "\tspeed: 0.0209s/iter; left time: 326.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0611396 Vali Loss: 0.0592256 Test Loss: 0.0619340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0596062\n",
      "\tspeed: 0.0437s/iter; left time: 677.4585s\n",
      "\titers: 200, epoch: 31 | loss: 0.0569538\n",
      "\tspeed: 0.0162s/iter; left time: 249.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0612691 Vali Loss: 0.0592210 Test Loss: 0.0618494\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0607494\n",
      "\tspeed: 0.0374s/iter; left time: 571.9472s\n",
      "\titers: 200, epoch: 32 | loss: 0.0604401\n",
      "\tspeed: 0.0206s/iter; left time: 313.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0612039 Vali Loss: 0.0591996 Test Loss: 0.0618691\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0621250\n",
      "\tspeed: 0.0413s/iter; left time: 622.8915s\n",
      "\titers: 200, epoch: 33 | loss: 0.0618877\n",
      "\tspeed: 0.0226s/iter; left time: 338.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0609512 Vali Loss: 0.0591121 Test Loss: 0.0617181\n",
      "Validation loss decreased (0.059187 --> 0.059112).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0603437\n",
      "\tspeed: 0.0386s/iter; left time: 572.6668s\n",
      "\titers: 200, epoch: 34 | loss: 0.0601685\n",
      "\tspeed: 0.0196s/iter; left time: 288.9509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0609362 Vali Loss: 0.0589895 Test Loss: 0.0616054\n",
      "Validation loss decreased (0.059112 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0603186\n",
      "\tspeed: 0.0386s/iter; left time: 563.9672s\n",
      "\titers: 200, epoch: 35 | loss: 0.0646182\n",
      "\tspeed: 0.0193s/iter; left time: 280.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0609446 Vali Loss: 0.0590995 Test Loss: 0.0616625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0602006\n",
      "\tspeed: 0.0386s/iter; left time: 555.0865s\n",
      "\titers: 200, epoch: 36 | loss: 0.0625308\n",
      "\tspeed: 0.0215s/iter; left time: 306.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0608464 Vali Loss: 0.0589719 Test Loss: 0.0615951\n",
      "Validation loss decreased (0.058990 --> 0.058972).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0603607\n",
      "\tspeed: 0.0369s/iter; left time: 522.6183s\n",
      "\titers: 200, epoch: 37 | loss: 0.0596195\n",
      "\tspeed: 0.0169s/iter; left time: 238.0133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0609012 Vali Loss: 0.0589949 Test Loss: 0.0616022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0559763\n",
      "\tspeed: 0.0382s/iter; left time: 533.0055s\n",
      "\titers: 200, epoch: 38 | loss: 0.0637537\n",
      "\tspeed: 0.0199s/iter; left time: 275.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0609325 Vali Loss: 0.0590541 Test Loss: 0.0617086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0595457\n",
      "\tspeed: 0.0384s/iter; left time: 527.0238s\n",
      "\titers: 200, epoch: 39 | loss: 0.0604476\n",
      "\tspeed: 0.0194s/iter; left time: 264.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0608642 Vali Loss: 0.0589675 Test Loss: 0.0615786\n",
      "Validation loss decreased (0.058972 --> 0.058967).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0609431\n",
      "\tspeed: 0.0392s/iter; left time: 528.8669s\n",
      "\titers: 200, epoch: 40 | loss: 0.0603043\n",
      "\tspeed: 0.0195s/iter; left time: 261.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0608317 Vali Loss: 0.0590068 Test Loss: 0.0616565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0555320\n",
      "\tspeed: 0.0390s/iter; left time: 517.3796s\n",
      "\titers: 200, epoch: 41 | loss: 0.0621905\n",
      "\tspeed: 0.0199s/iter; left time: 262.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0607720 Vali Loss: 0.0589859 Test Loss: 0.0615265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0582666\n",
      "\tspeed: 0.0366s/iter; left time: 478.0866s\n",
      "\titers: 200, epoch: 42 | loss: 0.0639409\n",
      "\tspeed: 0.0204s/iter; left time: 264.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0610027 Vali Loss: 0.0589462 Test Loss: 0.0615786\n",
      "Validation loss decreased (0.058967 --> 0.058946).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0588901\n",
      "\tspeed: 0.0396s/iter; left time: 507.8555s\n",
      "\titers: 200, epoch: 43 | loss: 0.0626445\n",
      "\tspeed: 0.0197s/iter; left time: 250.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0609332 Vali Loss: 0.0589002 Test Loss: 0.0615589\n",
      "Validation loss decreased (0.058946 --> 0.058900).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0600454\n",
      "\tspeed: 0.0390s/iter; left time: 491.7814s\n",
      "\titers: 200, epoch: 44 | loss: 0.1046510\n",
      "\tspeed: 0.0201s/iter; left time: 251.0261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0610308 Vali Loss: 0.0588552 Test Loss: 0.0615211\n",
      "Validation loss decreased (0.058900 --> 0.058855).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0590341\n",
      "\tspeed: 0.0399s/iter; left time: 494.0496s\n",
      "\titers: 200, epoch: 45 | loss: 0.0561302\n",
      "\tspeed: 0.0200s/iter; left time: 245.3776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0607509 Vali Loss: 0.0588746 Test Loss: 0.0615488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0632354\n",
      "\tspeed: 0.0403s/iter; left time: 490.7538s\n",
      "\titers: 200, epoch: 46 | loss: 0.0581082\n",
      "\tspeed: 0.0212s/iter; left time: 256.1054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0606966 Vali Loss: 0.0587637 Test Loss: 0.0614949\n",
      "Validation loss decreased (0.058855 --> 0.058764).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0607580\n",
      "\tspeed: 0.0377s/iter; left time: 449.9873s\n",
      "\titers: 200, epoch: 47 | loss: 0.0596933\n",
      "\tspeed: 0.0185s/iter; left time: 219.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0607278 Vali Loss: 0.0589244 Test Loss: 0.0615901\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0610742\n",
      "\tspeed: 0.0424s/iter; left time: 496.5101s\n",
      "\titers: 200, epoch: 48 | loss: 0.0582518\n",
      "\tspeed: 0.0204s/iter; left time: 236.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0607390 Vali Loss: 0.0589122 Test Loss: 0.0614438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0593468\n",
      "\tspeed: 0.0406s/iter; left time: 466.5770s\n",
      "\titers: 200, epoch: 49 | loss: 0.0615602\n",
      "\tspeed: 0.0208s/iter; left time: 236.5162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0606177 Vali Loss: 0.0589179 Test Loss: 0.0615362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0635054\n",
      "\tspeed: 0.0365s/iter; left time: 412.0082s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601768\n",
      "\tspeed: 0.0174s/iter; left time: 194.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0606796 Vali Loss: 0.0588843 Test Loss: 0.0614741\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0623859\n",
      "\tspeed: 0.0358s/iter; left time: 395.7605s\n",
      "\titers: 200, epoch: 51 | loss: 0.0601044\n",
      "\tspeed: 0.0188s/iter; left time: 205.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0606953 Vali Loss: 0.0589977 Test Loss: 0.0615234\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0615386\n",
      "\tspeed: 0.0385s/iter; left time: 417.2955s\n",
      "\titers: 200, epoch: 52 | loss: 0.0631368\n",
      "\tspeed: 0.0174s/iter; left time: 187.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0606984 Vali Loss: 0.0588911 Test Loss: 0.0615143\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0584038\n",
      "\tspeed: 0.0354s/iter; left time: 374.9923s\n",
      "\titers: 200, epoch: 53 | loss: 0.0576594\n",
      "\tspeed: 0.0180s/iter; left time: 189.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0606154 Vali Loss: 0.0588870 Test Loss: 0.0614664\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0589344\n",
      "\tspeed: 0.0387s/iter; left time: 402.1461s\n",
      "\titers: 200, epoch: 54 | loss: 0.0547111\n",
      "\tspeed: 0.0239s/iter; left time: 246.1279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0607150 Vali Loss: 0.0588331 Test Loss: 0.0613789\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0620313\n",
      "\tspeed: 0.0386s/iter; left time: 392.4676s\n",
      "\titers: 200, epoch: 55 | loss: 0.0646649\n",
      "\tspeed: 0.0190s/iter; left time: 190.7973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0606030 Vali Loss: 0.0587150 Test Loss: 0.0614655\n",
      "Validation loss decreased (0.058764 --> 0.058715).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0569904\n",
      "\tspeed: 0.0375s/iter; left time: 372.8320s\n",
      "\titers: 200, epoch: 56 | loss: 0.0611081\n",
      "\tspeed: 0.0164s/iter; left time: 161.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0606916 Vali Loss: 0.0588263 Test Loss: 0.0614581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0595710\n",
      "\tspeed: 0.0390s/iter; left time: 378.6444s\n",
      "\titers: 200, epoch: 57 | loss: 0.0569403\n",
      "\tspeed: 0.0199s/iter; left time: 191.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0606114 Vali Loss: 0.0589005 Test Loss: 0.0614607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0623064\n",
      "\tspeed: 0.0357s/iter; left time: 338.8663s\n",
      "\titers: 200, epoch: 58 | loss: 0.0560119\n",
      "\tspeed: 0.0168s/iter; left time: 157.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0606619 Vali Loss: 0.0588734 Test Loss: 0.0614025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599943\n",
      "\tspeed: 0.0371s/iter; left time: 344.1354s\n",
      "\titers: 200, epoch: 59 | loss: 0.0617816\n",
      "\tspeed: 0.0178s/iter; left time: 163.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0606414 Vali Loss: 0.0589361 Test Loss: 0.0615093\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0620856\n",
      "\tspeed: 0.0396s/iter; left time: 357.7004s\n",
      "\titers: 200, epoch: 60 | loss: 0.0578703\n",
      "\tspeed: 0.0199s/iter; left time: 178.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0605521 Vali Loss: 0.0587123 Test Loss: 0.0614363\n",
      "Validation loss decreased (0.058715 --> 0.058712).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0607122\n",
      "\tspeed: 0.0359s/iter; left time: 317.0687s\n",
      "\titers: 200, epoch: 61 | loss: 0.0573786\n",
      "\tspeed: 0.0132s/iter; left time: 114.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 223 | Train Loss: 0.0608720 Vali Loss: 0.0588446 Test Loss: 0.0614883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0623740\n",
      "\tspeed: 0.0385s/iter; left time: 330.6444s\n",
      "\titers: 200, epoch: 62 | loss: 0.0598484\n",
      "\tspeed: 0.0186s/iter; left time: 158.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0606050 Vali Loss: 0.0591069 Test Loss: 0.0615584\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0644612\n",
      "\tspeed: 0.0401s/iter; left time: 335.4956s\n",
      "\titers: 200, epoch: 63 | loss: 0.0653639\n",
      "\tspeed: 0.0215s/iter; left time: 178.2865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0605841 Vali Loss: 0.0587080 Test Loss: 0.0614095\n",
      "Validation loss decreased (0.058712 --> 0.058708).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0615636\n",
      "\tspeed: 0.0387s/iter; left time: 315.6595s\n",
      "\titers: 200, epoch: 64 | loss: 0.0612560\n",
      "\tspeed: 0.0184s/iter; left time: 147.9514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0605828 Vali Loss: 0.0587152 Test Loss: 0.0614149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0568213\n",
      "\tspeed: 0.0387s/iter; left time: 306.7046s\n",
      "\titers: 200, epoch: 65 | loss: 0.0580689\n",
      "\tspeed: 0.0182s/iter; left time: 142.6696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0607041 Vali Loss: 0.0586771 Test Loss: 0.0613749\n",
      "Validation loss decreased (0.058708 --> 0.058677).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0628402\n",
      "\tspeed: 0.0376s/iter; left time: 289.8497s\n",
      "\titers: 200, epoch: 66 | loss: 0.0586477\n",
      "\tspeed: 0.0164s/iter; left time: 124.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0607409 Vali Loss: 0.0588695 Test Loss: 0.0614378\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0559702\n",
      "\tspeed: 0.0364s/iter; left time: 272.4474s\n",
      "\titers: 200, epoch: 67 | loss: 0.0600595\n",
      "\tspeed: 0.0168s/iter; left time: 123.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0606207 Vali Loss: 0.0585862 Test Loss: 0.0613823\n",
      "Validation loss decreased (0.058677 --> 0.058586).  Saving model ...\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0625885\n",
      "\tspeed: 0.0378s/iter; left time: 274.4712s\n",
      "\titers: 200, epoch: 68 | loss: 0.0582105\n",
      "\tspeed: 0.0198s/iter; left time: 141.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0605603 Vali Loss: 0.0588540 Test Loss: 0.0613979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0585478\n",
      "\tspeed: 0.0385s/iter; left time: 270.6026s\n",
      "\titers: 200, epoch: 69 | loss: 0.0620088\n",
      "\tspeed: 0.0178s/iter; left time: 123.4405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0605951 Vali Loss: 0.0588253 Test Loss: 0.0614400\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0557343\n",
      "\tspeed: 0.0388s/iter; left time: 264.2904s\n",
      "\titers: 200, epoch: 70 | loss: 0.0634730\n",
      "\tspeed: 0.0204s/iter; left time: 136.7531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0605650 Vali Loss: 0.0588185 Test Loss: 0.0613799\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0574628\n",
      "\tspeed: 0.0384s/iter; left time: 253.1393s\n",
      "\titers: 200, epoch: 71 | loss: 0.0592117\n",
      "\tspeed: 0.0171s/iter; left time: 110.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0605581 Vali Loss: 0.0588350 Test Loss: 0.0614624\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0650221\n",
      "\tspeed: 0.0404s/iter; left time: 257.1386s\n",
      "\titers: 200, epoch: 72 | loss: 0.0582021\n",
      "\tspeed: 0.0206s/iter; left time: 128.9062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0606202 Vali Loss: 0.0587745 Test Loss: 0.0614244\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0613363\n",
      "\tspeed: 0.0314s/iter; left time: 193.1666s\n",
      "\titers: 200, epoch: 73 | loss: 0.0613006\n",
      "\tspeed: 0.0158s/iter; left time: 95.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0606940 Vali Loss: 0.0588042 Test Loss: 0.0614254\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0612068\n",
      "\tspeed: 0.0362s/iter; left time: 214.2325s\n",
      "\titers: 200, epoch: 74 | loss: 0.0589065\n",
      "\tspeed: 0.0132s/iter; left time: 77.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.0606161 Vali Loss: 0.0588119 Test Loss: 0.0614026\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0618147\n",
      "\tspeed: 0.0375s/iter; left time: 213.7368s\n",
      "\titers: 200, epoch: 75 | loss: 0.0583402\n",
      "\tspeed: 0.0191s/iter; left time: 106.8579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0606162 Vali Loss: 0.0586362 Test Loss: 0.0613888\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0625675\n",
      "\tspeed: 0.0369s/iter; left time: 201.9549s\n",
      "\titers: 200, epoch: 76 | loss: 0.0587865\n",
      "\tspeed: 0.0184s/iter; left time: 98.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0605983 Vali Loss: 0.0586669 Test Loss: 0.0613694\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0594551\n",
      "\tspeed: 0.0394s/iter; left time: 206.7141s\n",
      "\titers: 200, epoch: 77 | loss: 0.0578571\n",
      "\tspeed: 0.0240s/iter; left time: 123.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0606334 Vali Loss: 0.0589045 Test Loss: 0.0614488\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010739559307694435, rmse:0.10363184660673141, mae:0.061382316052913666, rse:0.3915736973285675\n",
      "Intermediate time for IT and pred_len 24: 00h:13m:46.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2649924\n",
      "\tspeed: 0.0413s/iter; left time: 913.8624s\n",
      "\titers: 200, epoch: 1 | loss: 0.2459004\n",
      "\tspeed: 0.0137s/iter; left time: 301.1170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 222 | Train Loss: 0.2686695 Vali Loss: 0.1882363 Test Loss: 0.1964827\n",
      "Validation loss decreased (inf --> 0.188236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1441561\n",
      "\tspeed: 0.0355s/iter; left time: 776.8039s\n",
      "\titers: 200, epoch: 2 | loss: 0.1169897\n",
      "\tspeed: 0.0154s/iter; left time: 335.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.1534727 Vali Loss: 0.1040274 Test Loss: 0.1094590\n",
      "Validation loss decreased (0.188236 --> 0.104027).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072947\n",
      "\tspeed: 0.0366s/iter; left time: 791.9303s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013600\n",
      "\tspeed: 0.0177s/iter; left time: 381.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.1083181 Vali Loss: 0.0932522 Test Loss: 0.0968188\n",
      "Validation loss decreased (0.104027 --> 0.093252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962329\n",
      "\tspeed: 0.0390s/iter; left time: 836.8041s\n",
      "\titers: 200, epoch: 4 | loss: 0.0919321\n",
      "\tspeed: 0.0135s/iter; left time: 288.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0968963 Vali Loss: 0.0879308 Test Loss: 0.0922515\n",
      "Validation loss decreased (0.093252 --> 0.087931).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0865197\n",
      "\tspeed: 0.0379s/iter; left time: 803.5953s\n",
      "\titers: 200, epoch: 5 | loss: 0.0907869\n",
      "\tspeed: 0.0181s/iter; left time: 382.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0917756 Vali Loss: 0.0851810 Test Loss: 0.0912936\n",
      "Validation loss decreased (0.087931 --> 0.085181).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886005\n",
      "\tspeed: 0.0387s/iter; left time: 813.1224s\n",
      "\titers: 200, epoch: 6 | loss: 0.0916665\n",
      "\tspeed: 0.0145s/iter; left time: 302.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0891103 Vali Loss: 0.0829898 Test Loss: 0.0884985\n",
      "Validation loss decreased (0.085181 --> 0.082990).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0885330\n",
      "\tspeed: 0.0367s/iter; left time: 762.1519s\n",
      "\titers: 200, epoch: 7 | loss: 0.0854654\n",
      "\tspeed: 0.0180s/iter; left time: 371.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0865712 Vali Loss: 0.0822678 Test Loss: 0.0874631\n",
      "Validation loss decreased (0.082990 --> 0.082268).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0859759\n",
      "\tspeed: 0.0381s/iter; left time: 781.9639s\n",
      "\titers: 200, epoch: 8 | loss: 0.0871206\n",
      "\tspeed: 0.0189s/iter; left time: 387.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0855049 Vali Loss: 0.0819314 Test Loss: 0.0872992\n",
      "Validation loss decreased (0.082268 --> 0.081931).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820930\n",
      "\tspeed: 0.0363s/iter; left time: 737.9730s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811692\n",
      "\tspeed: 0.0173s/iter; left time: 350.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0844211 Vali Loss: 0.0812641 Test Loss: 0.0868622\n",
      "Validation loss decreased (0.081931 --> 0.081264).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0790341\n",
      "\tspeed: 0.0399s/iter; left time: 801.9423s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847388\n",
      "\tspeed: 0.0196s/iter; left time: 392.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0832799 Vali Loss: 0.0799906 Test Loss: 0.0853632\n",
      "Validation loss decreased (0.081264 --> 0.079991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803370\n",
      "\tspeed: 0.0416s/iter; left time: 826.4729s\n",
      "\titers: 200, epoch: 11 | loss: 0.0803964\n",
      "\tspeed: 0.0205s/iter; left time: 406.2545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0829627 Vali Loss: 0.0797984 Test Loss: 0.0852156\n",
      "Validation loss decreased (0.079991 --> 0.079798).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0796728\n",
      "\tspeed: 0.0417s/iter; left time: 820.1839s\n",
      "\titers: 200, epoch: 12 | loss: 0.0812863\n",
      "\tspeed: 0.0167s/iter; left time: 327.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0821226 Vali Loss: 0.0798440 Test Loss: 0.0849899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0798728\n",
      "\tspeed: 0.0393s/iter; left time: 763.9568s\n",
      "\titers: 200, epoch: 13 | loss: 0.0777141\n",
      "\tspeed: 0.0171s/iter; left time: 329.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0815629 Vali Loss: 0.0792634 Test Loss: 0.0848526\n",
      "Validation loss decreased (0.079798 --> 0.079263).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0809462\n",
      "\tspeed: 0.0409s/iter; left time: 785.1400s\n",
      "\titers: 200, epoch: 14 | loss: 0.0796807\n",
      "\tspeed: 0.0155s/iter; left time: 295.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0815085 Vali Loss: 0.0793738 Test Loss: 0.0847474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0786198\n",
      "\tspeed: 0.0328s/iter; left time: 622.3870s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829225\n",
      "\tspeed: 0.0186s/iter; left time: 351.9468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0811071 Vali Loss: 0.0794846 Test Loss: 0.0848899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779483\n",
      "\tspeed: 0.0333s/iter; left time: 624.5840s\n",
      "\titers: 200, epoch: 16 | loss: 0.0778324\n",
      "\tspeed: 0.0135s/iter; left time: 251.2907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 222 | Train Loss: 0.0806298 Vali Loss: 0.0789060 Test Loss: 0.0839967\n",
      "Validation loss decreased (0.079263 --> 0.078906).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808630\n",
      "\tspeed: 0.0405s/iter; left time: 750.7225s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814597\n",
      "\tspeed: 0.0225s/iter; left time: 415.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0803956 Vali Loss: 0.0786776 Test Loss: 0.0840534\n",
      "Validation loss decreased (0.078906 --> 0.078678).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0810252\n",
      "\tspeed: 0.0390s/iter; left time: 715.2181s\n",
      "\titers: 200, epoch: 18 | loss: 0.0778031\n",
      "\tspeed: 0.0168s/iter; left time: 306.1627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0800587 Vali Loss: 0.0797229 Test Loss: 0.0852232\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0798354\n",
      "\tspeed: 0.0326s/iter; left time: 590.5334s\n",
      "\titers: 200, epoch: 19 | loss: 0.0803785\n",
      "\tspeed: 0.0179s/iter; left time: 322.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0802608 Vali Loss: 0.0786860 Test Loss: 0.0842426\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790615\n",
      "\tspeed: 0.0404s/iter; left time: 722.0736s\n",
      "\titers: 200, epoch: 20 | loss: 0.0815033\n",
      "\tspeed: 0.0186s/iter; left time: 330.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0801266 Vali Loss: 0.0794325 Test Loss: 0.0848554\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0828814\n",
      "\tspeed: 0.0374s/iter; left time: 661.1873s\n",
      "\titers: 200, epoch: 21 | loss: 0.0766421\n",
      "\tspeed: 0.0172s/iter; left time: 302.7116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0796026 Vali Loss: 0.0787944 Test Loss: 0.0840462\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0806132\n",
      "\tspeed: 0.0342s/iter; left time: 596.2157s\n",
      "\titers: 200, epoch: 22 | loss: 0.0732058\n",
      "\tspeed: 0.0189s/iter; left time: 326.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0794383 Vali Loss: 0.0783449 Test Loss: 0.0838791\n",
      "Validation loss decreased (0.078678 --> 0.078345).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0789208\n",
      "\tspeed: 0.0408s/iter; left time: 702.1286s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793016\n",
      "\tspeed: 0.0196s/iter; left time: 335.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0794405 Vali Loss: 0.0784126 Test Loss: 0.0839449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0791395\n",
      "\tspeed: 0.0325s/iter; left time: 551.6353s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773762\n",
      "\tspeed: 0.0171s/iter; left time: 289.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 222 | Train Loss: 0.0791259 Vali Loss: 0.0781696 Test Loss: 0.0836211\n",
      "Validation loss decreased (0.078345 --> 0.078170).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758062\n",
      "\tspeed: 0.0434s/iter; left time: 728.5206s\n",
      "\titers: 200, epoch: 25 | loss: 0.0766327\n",
      "\tspeed: 0.0214s/iter; left time: 357.5608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 222 | Train Loss: 0.0792004 Vali Loss: 0.0779855 Test Loss: 0.0835670\n",
      "Validation loss decreased (0.078170 --> 0.077986).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0784141\n",
      "\tspeed: 0.0354s/iter; left time: 586.2944s\n",
      "\titers: 200, epoch: 26 | loss: 0.0779995\n",
      "\tspeed: 0.0134s/iter; left time: 221.1464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 222 | Train Loss: 0.0790333 Vali Loss: 0.0779703 Test Loss: 0.0835893\n",
      "Validation loss decreased (0.077986 --> 0.077970).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0801988\n",
      "\tspeed: 0.0331s/iter; left time: 540.5539s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799192\n",
      "\tspeed: 0.0172s/iter; left time: 279.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0789634 Vali Loss: 0.0785433 Test Loss: 0.0841170\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809430\n",
      "\tspeed: 0.0383s/iter; left time: 616.8119s\n",
      "\titers: 200, epoch: 28 | loss: 0.0762430\n",
      "\tspeed: 0.0202s/iter; left time: 322.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0788614 Vali Loss: 0.0783323 Test Loss: 0.0840029\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777347\n",
      "\tspeed: 0.0370s/iter; left time: 587.1324s\n",
      "\titers: 200, epoch: 29 | loss: 0.0806854\n",
      "\tspeed: 0.0164s/iter; left time: 258.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0787451 Vali Loss: 0.0779039 Test Loss: 0.0834712\n",
      "Validation loss decreased (0.077970 --> 0.077904).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778239\n",
      "\tspeed: 0.0370s/iter; left time: 578.7748s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771591\n",
      "\tspeed: 0.0163s/iter; left time: 253.9167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0786864 Vali Loss: 0.0778701 Test Loss: 0.0835060\n",
      "Validation loss decreased (0.077904 --> 0.077870).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0817337\n",
      "\tspeed: 0.0363s/iter; left time: 561.2592s\n",
      "\titers: 200, epoch: 31 | loss: 0.0799501\n",
      "\tspeed: 0.0197s/iter; left time: 302.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0787699 Vali Loss: 0.0783857 Test Loss: 0.0838893\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0790439\n",
      "\tspeed: 0.0352s/iter; left time: 535.6710s\n",
      "\titers: 200, epoch: 32 | loss: 0.0774869\n",
      "\tspeed: 0.0188s/iter; left time: 284.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0786186 Vali Loss: 0.0779820 Test Loss: 0.0836114\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0805306\n",
      "\tspeed: 0.0363s/iter; left time: 544.5297s\n",
      "\titers: 200, epoch: 33 | loss: 0.0801780\n",
      "\tspeed: 0.0173s/iter; left time: 258.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0785689 Vali Loss: 0.0782035 Test Loss: 0.0835488\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0788253\n",
      "\tspeed: 0.0396s/iter; left time: 585.2960s\n",
      "\titers: 200, epoch: 34 | loss: 0.0753295\n",
      "\tspeed: 0.0177s/iter; left time: 259.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0787260 Vali Loss: 0.0779253 Test Loss: 0.0836682\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768477\n",
      "\tspeed: 0.0443s/iter; left time: 644.9836s\n",
      "\titers: 200, epoch: 35 | loss: 0.0769447\n",
      "\tspeed: 0.0233s/iter; left time: 336.9430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 222 | Train Loss: 0.0785765 Vali Loss: 0.0782844 Test Loss: 0.0838309\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0795754\n",
      "\tspeed: 0.0434s/iter; left time: 622.1067s\n",
      "\titers: 200, epoch: 36 | loss: 0.0797847\n",
      "\tspeed: 0.0196s/iter; left time: 279.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0785016 Vali Loss: 0.0780071 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0832342\n",
      "\tspeed: 0.0414s/iter; left time: 584.5955s\n",
      "\titers: 200, epoch: 37 | loss: 0.0774548\n",
      "\tspeed: 0.0183s/iter; left time: 256.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0784543 Vali Loss: 0.0779903 Test Loss: 0.0835282\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802678\n",
      "\tspeed: 0.0379s/iter; left time: 526.3977s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797945\n",
      "\tspeed: 0.0263s/iter; left time: 363.0489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 222 | Train Loss: 0.0783770 Vali Loss: 0.0781965 Test Loss: 0.0838084\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0735248\n",
      "\tspeed: 0.0402s/iter; left time: 549.8673s\n",
      "\titers: 200, epoch: 39 | loss: 0.0799417\n",
      "\tspeed: 0.0212s/iter; left time: 287.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0783900 Vali Loss: 0.0778958 Test Loss: 0.0835715\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0789938\n",
      "\tspeed: 0.0369s/iter; left time: 496.4255s\n",
      "\titers: 200, epoch: 40 | loss: 0.0747399\n",
      "\tspeed: 0.0158s/iter; left time: 210.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0784124 Vali Loss: 0.0780216 Test Loss: 0.0836652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018412597477436066, rmse:0.1356930285692215, mae:0.08350596576929092, rse:0.5130699276924133\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2669699\n",
      "\tspeed: 0.0254s/iter; left time: 561.6804s\n",
      "\titers: 200, epoch: 1 | loss: 0.2450630\n",
      "\tspeed: 0.0185s/iter; left time: 407.5538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.2744923 Vali Loss: 0.1891254 Test Loss: 0.1977536\n",
      "Validation loss decreased (inf --> 0.189125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1374452\n",
      "\tspeed: 0.0390s/iter; left time: 854.1531s\n",
      "\titers: 200, epoch: 2 | loss: 0.1209822\n",
      "\tspeed: 0.0202s/iter; left time: 440.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.1514843 Vali Loss: 0.1045871 Test Loss: 0.1098326\n",
      "Validation loss decreased (0.189125 --> 0.104587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1118573\n",
      "\tspeed: 0.0410s/iter; left time: 887.7475s\n",
      "\titers: 200, epoch: 3 | loss: 0.1030534\n",
      "\tspeed: 0.0183s/iter; left time: 393.6556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.1093698 Vali Loss: 0.0961750 Test Loss: 0.1004811\n",
      "Validation loss decreased (0.104587 --> 0.096175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1103015\n",
      "\tspeed: 0.0375s/iter; left time: 803.0627s\n",
      "\titers: 200, epoch: 4 | loss: 0.0936483\n",
      "\tspeed: 0.0165s/iter; left time: 351.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0980030 Vali Loss: 0.0882828 Test Loss: 0.0927319\n",
      "Validation loss decreased (0.096175 --> 0.088283).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0889753\n",
      "\tspeed: 0.0484s/iter; left time: 1026.1309s\n",
      "\titers: 200, epoch: 5 | loss: 0.0982663\n",
      "\tspeed: 0.0182s/iter; left time: 384.8134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0919368 Vali Loss: 0.0855115 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.088283 --> 0.085512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839968\n",
      "\tspeed: 0.0406s/iter; left time: 851.1937s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844622\n",
      "\tspeed: 0.0192s/iter; left time: 400.7451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0886087 Vali Loss: 0.0842759 Test Loss: 0.0881643\n",
      "Validation loss decreased (0.085512 --> 0.084276).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0870719\n",
      "\tspeed: 0.0418s/iter; left time: 869.1411s\n",
      "\titers: 200, epoch: 7 | loss: 0.0901598\n",
      "\tspeed: 0.0199s/iter; left time: 411.1104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0869783 Vali Loss: 0.0831270 Test Loss: 0.0881475\n",
      "Validation loss decreased (0.084276 --> 0.083127).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0868821\n",
      "\tspeed: 0.0431s/iter; left time: 885.6637s\n",
      "\titers: 200, epoch: 8 | loss: 0.0865162\n",
      "\tspeed: 0.0191s/iter; left time: 390.9957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0854771 Vali Loss: 0.0816712 Test Loss: 0.0865686\n",
      "Validation loss decreased (0.083127 --> 0.081671).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0851794\n",
      "\tspeed: 0.0415s/iter; left time: 843.6508s\n",
      "\titers: 200, epoch: 9 | loss: 0.0889486\n",
      "\tspeed: 0.0193s/iter; left time: 391.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0842140 Vali Loss: 0.0809032 Test Loss: 0.0862001\n",
      "Validation loss decreased (0.081671 --> 0.080903).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0884752\n",
      "\tspeed: 0.0392s/iter; left time: 788.6576s\n",
      "\titers: 200, epoch: 10 | loss: 0.0834779\n",
      "\tspeed: 0.0134s/iter; left time: 268.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0834075 Vali Loss: 0.0806109 Test Loss: 0.0853274\n",
      "Validation loss decreased (0.080903 --> 0.080611).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0813067\n",
      "\tspeed: 0.0392s/iter; left time: 779.5457s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809828\n",
      "\tspeed: 0.0221s/iter; left time: 437.3112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0828738 Vali Loss: 0.0803249 Test Loss: 0.0854242\n",
      "Validation loss decreased (0.080611 --> 0.080325).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787641\n",
      "\tspeed: 0.0439s/iter; left time: 862.9870s\n",
      "\titers: 200, epoch: 12 | loss: 0.0846575\n",
      "\tspeed: 0.0164s/iter; left time: 320.4460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0823977 Vali Loss: 0.0802869 Test Loss: 0.0853479\n",
      "Validation loss decreased (0.080325 --> 0.080287).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0806332\n",
      "\tspeed: 0.0399s/iter; left time: 775.4642s\n",
      "\titers: 200, epoch: 13 | loss: 0.0780229\n",
      "\tspeed: 0.0194s/iter; left time: 375.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0821032 Vali Loss: 0.0796546 Test Loss: 0.0850520\n",
      "Validation loss decreased (0.080287 --> 0.079655).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807278\n",
      "\tspeed: 0.0385s/iter; left time: 739.0099s\n",
      "\titers: 200, epoch: 14 | loss: 0.0801523\n",
      "\tspeed: 0.0168s/iter; left time: 322.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0814515 Vali Loss: 0.0793224 Test Loss: 0.0846003\n",
      "Validation loss decreased (0.079655 --> 0.079322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0811834\n",
      "\tspeed: 0.0392s/iter; left time: 744.6885s\n",
      "\titers: 200, epoch: 15 | loss: 0.0824905\n",
      "\tspeed: 0.0177s/iter; left time: 334.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0811528 Vali Loss: 0.0791987 Test Loss: 0.0847875\n",
      "Validation loss decreased (0.079322 --> 0.079199).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0812803\n",
      "\tspeed: 0.0417s/iter; left time: 782.2313s\n",
      "\titers: 200, epoch: 16 | loss: 0.0791309\n",
      "\tspeed: 0.0210s/iter; left time: 392.8111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0812663 Vali Loss: 0.0791264 Test Loss: 0.0847761\n",
      "Validation loss decreased (0.079199 --> 0.079126).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814442\n",
      "\tspeed: 0.0460s/iter; left time: 853.8848s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843137\n",
      "\tspeed: 0.0239s/iter; left time: 441.6486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 222 | Train Loss: 0.0805641 Vali Loss: 0.0793165 Test Loss: 0.0850676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781366\n",
      "\tspeed: 0.0420s/iter; left time: 769.0049s\n",
      "\titers: 200, epoch: 18 | loss: 0.0777626\n",
      "\tspeed: 0.0178s/iter; left time: 323.5483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0801775 Vali Loss: 0.0786415 Test Loss: 0.0847553\n",
      "Validation loss decreased (0.079126 --> 0.078641).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766904\n",
      "\tspeed: 0.0339s/iter; left time: 613.8247s\n",
      "\titers: 200, epoch: 19 | loss: 0.0786663\n",
      "\tspeed: 0.0135s/iter; left time: 242.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 222 | Train Loss: 0.0800585 Vali Loss: 0.0784111 Test Loss: 0.0842944\n",
      "Validation loss decreased (0.078641 --> 0.078411).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0812891\n",
      "\tspeed: 0.0401s/iter; left time: 717.8911s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824140\n",
      "\tspeed: 0.0218s/iter; left time: 388.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0798285 Vali Loss: 0.0785157 Test Loss: 0.0841717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0775364\n",
      "\tspeed: 0.0407s/iter; left time: 718.1839s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771284\n",
      "\tspeed: 0.0193s/iter; left time: 339.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0796215 Vali Loss: 0.0784598 Test Loss: 0.0844882\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0826520\n",
      "\tspeed: 0.0363s/iter; left time: 632.8387s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745289\n",
      "\tspeed: 0.0175s/iter; left time: 302.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0794640 Vali Loss: 0.0783014 Test Loss: 0.0844967\n",
      "Validation loss decreased (0.078411 --> 0.078301).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0809165\n",
      "\tspeed: 0.0428s/iter; left time: 737.4392s\n",
      "\titers: 200, epoch: 23 | loss: 0.0799347\n",
      "\tspeed: 0.0203s/iter; left time: 346.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0792830 Vali Loss: 0.0785589 Test Loss: 0.0841373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0753420\n",
      "\tspeed: 0.0383s/iter; left time: 651.5439s\n",
      "\titers: 200, epoch: 24 | loss: 0.0770513\n",
      "\tspeed: 0.0186s/iter; left time: 314.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0792857 Vali Loss: 0.0784758 Test Loss: 0.0841427\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0783725\n",
      "\tspeed: 0.0393s/iter; left time: 658.4246s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784349\n",
      "\tspeed: 0.0173s/iter; left time: 288.8365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0791210 Vali Loss: 0.0780171 Test Loss: 0.0841317\n",
      "Validation loss decreased (0.078301 --> 0.078017).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799472\n",
      "\tspeed: 0.0387s/iter; left time: 640.6313s\n",
      "\titers: 200, epoch: 26 | loss: 0.0803593\n",
      "\tspeed: 0.0210s/iter; left time: 344.7944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0792566 Vali Loss: 0.0783194 Test Loss: 0.0843090\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0800453\n",
      "\tspeed: 0.0434s/iter; left time: 708.6678s\n",
      "\titers: 200, epoch: 27 | loss: 0.0855692\n",
      "\tspeed: 0.0203s/iter; left time: 329.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0790418 Vali Loss: 0.0781827 Test Loss: 0.0844223\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802417\n",
      "\tspeed: 0.0422s/iter; left time: 679.2249s\n",
      "\titers: 200, epoch: 28 | loss: 0.0781306\n",
      "\tspeed: 0.0187s/iter; left time: 300.0698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0789394 Vali Loss: 0.0781281 Test Loss: 0.0844924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744723\n",
      "\tspeed: 0.0385s/iter; left time: 611.2250s\n",
      "\titers: 200, epoch: 29 | loss: 0.0800503\n",
      "\tspeed: 0.0178s/iter; left time: 281.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0787147 Vali Loss: 0.0782186 Test Loss: 0.0847710\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0786771\n",
      "\tspeed: 0.0360s/iter; left time: 563.8231s\n",
      "\titers: 200, epoch: 30 | loss: 0.0785042\n",
      "\tspeed: 0.0183s/iter; left time: 284.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0788852 Vali Loss: 0.0782980 Test Loss: 0.0843329\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0824540\n",
      "\tspeed: 0.0391s/iter; left time: 602.9721s\n",
      "\titers: 200, epoch: 31 | loss: 0.0787745\n",
      "\tspeed: 0.0176s/iter; left time: 269.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0787516 Vali Loss: 0.0781605 Test Loss: 0.0843612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0798231\n",
      "\tspeed: 0.0390s/iter; left time: 593.1450s\n",
      "\titers: 200, epoch: 32 | loss: 0.0795925\n",
      "\tspeed: 0.0181s/iter; left time: 274.1536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0785447 Vali Loss: 0.0779584 Test Loss: 0.0845215\n",
      "Validation loss decreased (0.078017 --> 0.077958).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0787936\n",
      "\tspeed: 0.0376s/iter; left time: 563.5038s\n",
      "\titers: 200, epoch: 33 | loss: 0.0770558\n",
      "\tspeed: 0.0164s/iter; left time: 244.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0785042 Vali Loss: 0.0779346 Test Loss: 0.0844570\n",
      "Validation loss decreased (0.077958 --> 0.077935).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0774692\n",
      "\tspeed: 0.0388s/iter; left time: 573.5574s\n",
      "\titers: 200, epoch: 34 | loss: 0.0759537\n",
      "\tspeed: 0.0205s/iter; left time: 300.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0784329 Vali Loss: 0.0780995 Test Loss: 0.0843573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768622\n",
      "\tspeed: 0.0374s/iter; left time: 544.3676s\n",
      "\titers: 200, epoch: 35 | loss: 0.0767152\n",
      "\tspeed: 0.0221s/iter; left time: 319.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0785559 Vali Loss: 0.0779781 Test Loss: 0.0841425\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0778051\n",
      "\tspeed: 0.0387s/iter; left time: 554.9793s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777113\n",
      "\tspeed: 0.0177s/iter; left time: 251.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0784720 Vali Loss: 0.0779585 Test Loss: 0.0843921\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0785430\n",
      "\tspeed: 0.0384s/iter; left time: 542.4889s\n",
      "\titers: 200, epoch: 37 | loss: 0.0810425\n",
      "\tspeed: 0.0180s/iter; left time: 251.8626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0784679 Vali Loss: 0.0778323 Test Loss: 0.0842875\n",
      "Validation loss decreased (0.077935 --> 0.077832).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802566\n",
      "\tspeed: 0.0400s/iter; left time: 554.9027s\n",
      "\titers: 200, epoch: 38 | loss: 0.0764927\n",
      "\tspeed: 0.0226s/iter; left time: 311.8065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.0783907 Vali Loss: 0.0779225 Test Loss: 0.0842849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0792846\n",
      "\tspeed: 0.0377s/iter; left time: 515.2359s\n",
      "\titers: 200, epoch: 39 | loss: 0.0809628\n",
      "\tspeed: 0.0186s/iter; left time: 252.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0784432 Vali Loss: 0.0779092 Test Loss: 0.0843623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0783319\n",
      "\tspeed: 0.0365s/iter; left time: 490.8189s\n",
      "\titers: 200, epoch: 40 | loss: 0.0799557\n",
      "\tspeed: 0.0174s/iter; left time: 231.7444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0784310 Vali Loss: 0.0777476 Test Loss: 0.0844199\n",
      "Validation loss decreased (0.077832 --> 0.077748).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762456\n",
      "\tspeed: 0.0373s/iter; left time: 492.7569s\n",
      "\titers: 200, epoch: 41 | loss: 0.0742338\n",
      "\tspeed: 0.0172s/iter; left time: 225.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0783518 Vali Loss: 0.0777561 Test Loss: 0.0841875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0770126\n",
      "\tspeed: 0.0372s/iter; left time: 483.5478s\n",
      "\titers: 200, epoch: 42 | loss: 0.0793621\n",
      "\tspeed: 0.0180s/iter; left time: 231.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0783116 Vali Loss: 0.0775457 Test Loss: 0.0842376\n",
      "Validation loss decreased (0.077748 --> 0.077546).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0780495\n",
      "\tspeed: 0.0389s/iter; left time: 497.3256s\n",
      "\titers: 200, epoch: 43 | loss: 0.0755535\n",
      "\tspeed: 0.0228s/iter; left time: 289.4814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.0781984 Vali Loss: 0.0777200 Test Loss: 0.0841385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0757912\n",
      "\tspeed: 0.0445s/iter; left time: 559.0970s\n",
      "\titers: 200, epoch: 44 | loss: 0.0804827\n",
      "\tspeed: 0.0215s/iter; left time: 267.4119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0785006 Vali Loss: 0.0778034 Test Loss: 0.0842228\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0790154\n",
      "\tspeed: 0.0383s/iter; left time: 472.4690s\n",
      "\titers: 200, epoch: 45 | loss: 0.0779546\n",
      "\tspeed: 0.0172s/iter; left time: 210.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0782630 Vali Loss: 0.0776432 Test Loss: 0.0841934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0848608\n",
      "\tspeed: 0.0372s/iter; left time: 450.0961s\n",
      "\titers: 200, epoch: 46 | loss: 0.0808703\n",
      "\tspeed: 0.0204s/iter; left time: 245.4394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0783092 Vali Loss: 0.0777007 Test Loss: 0.0842784\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0782285\n",
      "\tspeed: 0.0414s/iter; left time: 492.3108s\n",
      "\titers: 200, epoch: 47 | loss: 0.0790537\n",
      "\tspeed: 0.0196s/iter; left time: 230.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0781918 Vali Loss: 0.0778294 Test Loss: 0.0842310\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0792304\n",
      "\tspeed: 0.0420s/iter; left time: 490.4330s\n",
      "\titers: 200, epoch: 48 | loss: 0.0792798\n",
      "\tspeed: 0.0201s/iter; left time: 232.7346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0782369 Vali Loss: 0.0777886 Test Loss: 0.0842740\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0789824\n",
      "\tspeed: 0.0360s/iter; left time: 412.3695s\n",
      "\titers: 200, epoch: 49 | loss: 0.0772062\n",
      "\tspeed: 0.0163s/iter; left time: 185.3240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0784395 Vali Loss: 0.0778968 Test Loss: 0.0843072\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0770739\n",
      "\tspeed: 0.0403s/iter; left time: 452.5815s\n",
      "\titers: 200, epoch: 50 | loss: 0.0764689\n",
      "\tspeed: 0.0197s/iter; left time: 218.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0782838 Vali Loss: 0.0778267 Test Loss: 0.0844131\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815865\n",
      "\tspeed: 0.0385s/iter; left time: 423.2561s\n",
      "\titers: 200, epoch: 51 | loss: 0.0847316\n",
      "\tspeed: 0.0177s/iter; left time: 193.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0783152 Vali Loss: 0.0775835 Test Loss: 0.0842785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0804158\n",
      "\tspeed: 0.0358s/iter; left time: 385.7553s\n",
      "\titers: 200, epoch: 52 | loss: 0.0765600\n",
      "\tspeed: 0.0177s/iter; left time: 189.4805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0782747 Vali Loss: 0.0777675 Test Loss: 0.0842551\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018542619422078133, rmse:0.13617128133773804, mae:0.08423762768507004, rse:0.5148782730102539\n",
      "Intermediate time for IT and pred_len 96: 00h:09m:00.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2623744\n",
      "\tspeed: 0.0422s/iter; left time: 932.5145s\n",
      "\titers: 200, epoch: 1 | loss: 0.2450005\n",
      "\tspeed: 0.0138s/iter; left time: 303.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 222 | Train Loss: 0.2712762 Vali Loss: 0.1892322 Test Loss: 0.1963542\n",
      "Validation loss decreased (inf --> 0.189232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1408351\n",
      "\tspeed: 0.0427s/iter; left time: 933.1961s\n",
      "\titers: 200, epoch: 2 | loss: 0.1200960\n",
      "\tspeed: 0.0138s/iter; left time: 301.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.1527142 Vali Loss: 0.1074763 Test Loss: 0.1128705\n",
      "Validation loss decreased (0.189232 --> 0.107476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1113417\n",
      "\tspeed: 0.0408s/iter; left time: 883.7054s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039628\n",
      "\tspeed: 0.0206s/iter; left time: 443.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1100681 Vali Loss: 0.0971555 Test Loss: 0.1001091\n",
      "Validation loss decreased (0.107476 --> 0.097156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0994959\n",
      "\tspeed: 0.0421s/iter; left time: 903.1029s\n",
      "\titers: 200, epoch: 4 | loss: 0.0961771\n",
      "\tspeed: 0.0191s/iter; left time: 406.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0994796 Vali Loss: 0.0918822 Test Loss: 0.0945576\n",
      "Validation loss decreased (0.097156 --> 0.091882).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978309\n",
      "\tspeed: 0.0388s/iter; left time: 823.4833s\n",
      "\titers: 200, epoch: 5 | loss: 0.0923279\n",
      "\tspeed: 0.0179s/iter; left time: 378.7386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0947662 Vali Loss: 0.0886997 Test Loss: 0.0922637\n",
      "Validation loss decreased (0.091882 --> 0.088700).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910314\n",
      "\tspeed: 0.0382s/iter; left time: 802.8903s\n",
      "\titers: 200, epoch: 6 | loss: 0.0867660\n",
      "\tspeed: 0.0175s/iter; left time: 366.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0920840 Vali Loss: 0.0879990 Test Loss: 0.0926584\n",
      "Validation loss decreased (0.088700 --> 0.087999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891643\n",
      "\tspeed: 0.0368s/iter; left time: 763.2842s\n",
      "\titers: 200, epoch: 7 | loss: 0.0895050\n",
      "\tspeed: 0.0181s/iter; left time: 373.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0902035 Vali Loss: 0.0859869 Test Loss: 0.0899814\n",
      "Validation loss decreased (0.087999 --> 0.085987).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0862706\n",
      "\tspeed: 0.0392s/iter; left time: 806.3777s\n",
      "\titers: 200, epoch: 8 | loss: 0.0882515\n",
      "\tspeed: 0.0198s/iter; left time: 404.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0887546 Vali Loss: 0.0849545 Test Loss: 0.0896388\n",
      "Validation loss decreased (0.085987 --> 0.084955).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0883243\n",
      "\tspeed: 0.0409s/iter; left time: 830.7197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0862404\n",
      "\tspeed: 0.0203s/iter; left time: 411.4703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0875899 Vali Loss: 0.0852935 Test Loss: 0.0899381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0867116\n",
      "\tspeed: 0.0379s/iter; left time: 762.3894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848586\n",
      "\tspeed: 0.0218s/iter; left time: 435.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0866538 Vali Loss: 0.0847252 Test Loss: 0.0892747\n",
      "Validation loss decreased (0.084955 --> 0.084725).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0855074\n",
      "\tspeed: 0.0397s/iter; left time: 789.9591s\n",
      "\titers: 200, epoch: 11 | loss: 0.0857905\n",
      "\tspeed: 0.0170s/iter; left time: 336.0390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0861807 Vali Loss: 0.0837049 Test Loss: 0.0884712\n",
      "Validation loss decreased (0.084725 --> 0.083705).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0823696\n",
      "\tspeed: 0.0413s/iter; left time: 811.3353s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843925\n",
      "\tspeed: 0.0193s/iter; left time: 377.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0855676 Vali Loss: 0.0834212 Test Loss: 0.0882320\n",
      "Validation loss decreased (0.083705 --> 0.083421).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0824965\n",
      "\tspeed: 0.0463s/iter; left time: 899.3947s\n",
      "\titers: 200, epoch: 13 | loss: 0.0787788\n",
      "\tspeed: 0.0201s/iter; left time: 387.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0852563 Vali Loss: 0.0835483 Test Loss: 0.0882946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841491\n",
      "\tspeed: 0.0371s/iter; left time: 712.5193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0836439\n",
      "\tspeed: 0.0186s/iter; left time: 355.9105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0848209 Vali Loss: 0.0830857 Test Loss: 0.0881342\n",
      "Validation loss decreased (0.083421 --> 0.083086).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0865259\n",
      "\tspeed: 0.0448s/iter; left time: 850.0742s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829420\n",
      "\tspeed: 0.0199s/iter; left time: 375.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0848062 Vali Loss: 0.0829537 Test Loss: 0.0883071\n",
      "Validation loss decreased (0.083086 --> 0.082954).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0844988\n",
      "\tspeed: 0.0427s/iter; left time: 802.3884s\n",
      "\titers: 200, epoch: 16 | loss: 0.0813226\n",
      "\tspeed: 0.0192s/iter; left time: 357.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0840173 Vali Loss: 0.0828866 Test Loss: 0.0883264\n",
      "Validation loss decreased (0.082954 --> 0.082887).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0822286\n",
      "\tspeed: 0.0435s/iter; left time: 807.1541s\n",
      "\titers: 200, epoch: 17 | loss: 0.0811582\n",
      "\tspeed: 0.0240s/iter; left time: 443.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0837539 Vali Loss: 0.0824189 Test Loss: 0.0878899\n",
      "Validation loss decreased (0.082887 --> 0.082419).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0801338\n",
      "\tspeed: 0.0357s/iter; left time: 655.0431s\n",
      "\titers: 200, epoch: 18 | loss: 0.0810253\n",
      "\tspeed: 0.0169s/iter; left time: 307.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0836768 Vali Loss: 0.0824808 Test Loss: 0.0882645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841864\n",
      "\tspeed: 0.0392s/iter; left time: 710.4017s\n",
      "\titers: 200, epoch: 19 | loss: 0.0849248\n",
      "\tspeed: 0.0222s/iter; left time: 400.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.0834017 Vali Loss: 0.0825050 Test Loss: 0.0881532\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811977\n",
      "\tspeed: 0.0436s/iter; left time: 778.9842s\n",
      "\titers: 200, epoch: 20 | loss: 0.0814986\n",
      "\tspeed: 0.0194s/iter; left time: 344.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0831224 Vali Loss: 0.0827331 Test Loss: 0.0884382\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0842526\n",
      "\tspeed: 0.0390s/iter; left time: 688.6463s\n",
      "\titers: 200, epoch: 21 | loss: 0.0844001\n",
      "\tspeed: 0.0173s/iter; left time: 304.5995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0832062 Vali Loss: 0.0822411 Test Loss: 0.0879636\n",
      "Validation loss decreased (0.082419 --> 0.082241).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0817567\n",
      "\tspeed: 0.0360s/iter; left time: 628.3895s\n",
      "\titers: 200, epoch: 22 | loss: 0.0820697\n",
      "\tspeed: 0.0169s/iter; left time: 292.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0832305 Vali Loss: 0.0823467 Test Loss: 0.0885551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0809216\n",
      "\tspeed: 0.0411s/iter; left time: 707.4402s\n",
      "\titers: 200, epoch: 23 | loss: 0.0813171\n",
      "\tspeed: 0.0201s/iter; left time: 343.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0828882 Vali Loss: 0.0824147 Test Loss: 0.0881744\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0809080\n",
      "\tspeed: 0.0391s/iter; left time: 664.2459s\n",
      "\titers: 200, epoch: 24 | loss: 0.0853437\n",
      "\tspeed: 0.0171s/iter; left time: 289.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0828422 Vali Loss: 0.0827910 Test Loss: 0.0886205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0824172\n",
      "\tspeed: 0.0359s/iter; left time: 602.9456s\n",
      "\titers: 200, epoch: 25 | loss: 0.0799203\n",
      "\tspeed: 0.0179s/iter; left time: 297.6686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0825665 Vali Loss: 0.0826381 Test Loss: 0.0884931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828128\n",
      "\tspeed: 0.0376s/iter; left time: 622.1433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0804897\n",
      "\tspeed: 0.0209s/iter; left time: 343.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0826134 Vali Loss: 0.0824440 Test Loss: 0.0884047\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0878159\n",
      "\tspeed: 0.0433s/iter; left time: 707.6951s\n",
      "\titers: 200, epoch: 27 | loss: 0.0820288\n",
      "\tspeed: 0.0195s/iter; left time: 317.1004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0825387 Vali Loss: 0.0824503 Test Loss: 0.0886938\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0832498\n",
      "\tspeed: 0.0436s/iter; left time: 702.4679s\n",
      "\titers: 200, epoch: 28 | loss: 0.0824159\n",
      "\tspeed: 0.0229s/iter; left time: 366.3496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 222 | Train Loss: 0.0823991 Vali Loss: 0.0822423 Test Loss: 0.0882074\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0837849\n",
      "\tspeed: 0.0392s/iter; left time: 622.2662s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780446\n",
      "\tspeed: 0.0164s/iter; left time: 258.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0823763 Vali Loss: 0.0823771 Test Loss: 0.0881678\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0845247\n",
      "\tspeed: 0.0383s/iter; left time: 599.5531s\n",
      "\titers: 200, epoch: 30 | loss: 0.0855861\n",
      "\tspeed: 0.0183s/iter; left time: 285.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0827045 Vali Loss: 0.0830361 Test Loss: 0.0885761\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0848081\n",
      "\tspeed: 0.0385s/iter; left time: 594.0858s\n",
      "\titers: 200, epoch: 31 | loss: 0.0832928\n",
      "\tspeed: 0.0186s/iter; left time: 284.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0823795 Vali Loss: 0.0821888 Test Loss: 0.0883767\n",
      "Validation loss decreased (0.082241 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0802322\n",
      "\tspeed: 0.0365s/iter; left time: 555.8525s\n",
      "\titers: 200, epoch: 32 | loss: 0.0831175\n",
      "\tspeed: 0.0170s/iter; left time: 257.5731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0822764 Vali Loss: 0.0824038 Test Loss: 0.0882548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0830918\n",
      "\tspeed: 0.0379s/iter; left time: 567.9521s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793728\n",
      "\tspeed: 0.0175s/iter; left time: 260.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0821784 Vali Loss: 0.0822476 Test Loss: 0.0882046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0776519\n",
      "\tspeed: 0.0357s/iter; left time: 527.5003s\n",
      "\titers: 200, epoch: 34 | loss: 0.0819596\n",
      "\tspeed: 0.0172s/iter; left time: 252.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0822438 Vali Loss: 0.0821295 Test Loss: 0.0883762\n",
      "Validation loss decreased (0.082189 --> 0.082130).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0787440\n",
      "\tspeed: 0.0363s/iter; left time: 528.8079s\n",
      "\titers: 200, epoch: 35 | loss: 0.0771109\n",
      "\tspeed: 0.0170s/iter; left time: 245.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0823118 Vali Loss: 0.0824794 Test Loss: 0.0887839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0816495\n",
      "\tspeed: 0.0371s/iter; left time: 532.0796s\n",
      "\titers: 200, epoch: 36 | loss: 0.0814413\n",
      "\tspeed: 0.0177s/iter; left time: 252.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0820317 Vali Loss: 0.0820441 Test Loss: 0.0881821\n",
      "Validation loss decreased (0.082130 --> 0.082044).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0828957\n",
      "\tspeed: 0.0377s/iter; left time: 532.1887s\n",
      "\titers: 200, epoch: 37 | loss: 0.0850870\n",
      "\tspeed: 0.0136s/iter; left time: 190.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 222 | Train Loss: 0.0820310 Vali Loss: 0.0821765 Test Loss: 0.0884298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0838884\n",
      "\tspeed: 0.0381s/iter; left time: 528.5618s\n",
      "\titers: 200, epoch: 38 | loss: 0.0814081\n",
      "\tspeed: 0.0180s/iter; left time: 248.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0820474 Vali Loss: 0.0821589 Test Loss: 0.0885091\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0784536\n",
      "\tspeed: 0.0364s/iter; left time: 497.2850s\n",
      "\titers: 200, epoch: 39 | loss: 0.0867268\n",
      "\tspeed: 0.0171s/iter; left time: 231.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0820567 Vali Loss: 0.0822583 Test Loss: 0.0884373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0830478\n",
      "\tspeed: 0.0383s/iter; left time: 514.4419s\n",
      "\titers: 200, epoch: 40 | loss: 0.0777736\n",
      "\tspeed: 0.0201s/iter; left time: 268.1275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0819677 Vali Loss: 0.0822046 Test Loss: 0.0884621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0835645\n",
      "\tspeed: 0.0370s/iter; left time: 489.7506s\n",
      "\titers: 200, epoch: 41 | loss: 0.0800434\n",
      "\tspeed: 0.0177s/iter; left time: 232.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0819560 Vali Loss: 0.0820218 Test Loss: 0.0882482\n",
      "Validation loss decreased (0.082044 --> 0.082022).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845304\n",
      "\tspeed: 0.0393s/iter; left time: 511.2130s\n",
      "\titers: 200, epoch: 42 | loss: 0.0816610\n",
      "\tspeed: 0.0181s/iter; left time: 233.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 222 | Train Loss: 0.0820568 Vali Loss: 0.0820582 Test Loss: 0.0882806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0810728\n",
      "\tspeed: 0.0358s/iter; left time: 457.6482s\n",
      "\titers: 200, epoch: 43 | loss: 0.0854628\n",
      "\tspeed: 0.0166s/iter; left time: 210.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0819868 Vali Loss: 0.0821145 Test Loss: 0.0884622\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0822338\n",
      "\tspeed: 0.0340s/iter; left time: 426.5821s\n",
      "\titers: 200, epoch: 44 | loss: 0.0816598\n",
      "\tspeed: 0.0138s/iter; left time: 171.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 222 | Train Loss: 0.0818978 Vali Loss: 0.0820457 Test Loss: 0.0884021\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0839961\n",
      "\tspeed: 0.0326s/iter; left time: 402.0445s\n",
      "\titers: 200, epoch: 45 | loss: 0.0836015\n",
      "\tspeed: 0.0136s/iter; left time: 166.6696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 222 | Train Loss: 0.0818034 Vali Loss: 0.0821953 Test Loss: 0.0883732\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0802597\n",
      "\tspeed: 0.0405s/iter; left time: 490.1185s\n",
      "\titers: 200, epoch: 46 | loss: 0.0779905\n",
      "\tspeed: 0.0236s/iter; left time: 283.4760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 222 | Train Loss: 0.0817427 Vali Loss: 0.0819662 Test Loss: 0.0884531\n",
      "Validation loss decreased (0.082022 --> 0.081966).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0824521\n",
      "\tspeed: 0.0421s/iter; left time: 500.7916s\n",
      "\titers: 200, epoch: 47 | loss: 0.0803926\n",
      "\tspeed: 0.0196s/iter; left time: 230.8275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0819594 Vali Loss: 0.0825168 Test Loss: 0.0884939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0816119\n",
      "\tspeed: 0.0367s/iter; left time: 428.2661s\n",
      "\titers: 200, epoch: 48 | loss: 0.0852106\n",
      "\tspeed: 0.0179s/iter; left time: 207.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0820579 Vali Loss: 0.0820884 Test Loss: 0.0883255\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0818182\n",
      "\tspeed: 0.0394s/iter; left time: 450.5132s\n",
      "\titers: 200, epoch: 49 | loss: 0.0817004\n",
      "\tspeed: 0.0191s/iter; left time: 216.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0819418 Vali Loss: 0.0818370 Test Loss: 0.0881932\n",
      "Validation loss decreased (0.081966 --> 0.081837).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0834935\n",
      "\tspeed: 0.0417s/iter; left time: 467.5784s\n",
      "\titers: 200, epoch: 50 | loss: 0.0805027\n",
      "\tspeed: 0.0190s/iter; left time: 211.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0818667 Vali Loss: 0.0822212 Test Loss: 0.0882141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0783036\n",
      "\tspeed: 0.0385s/iter; left time: 423.6380s\n",
      "\titers: 200, epoch: 51 | loss: 0.0795352\n",
      "\tspeed: 0.0187s/iter; left time: 204.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0818968 Vali Loss: 0.0819246 Test Loss: 0.0882194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0833366\n",
      "\tspeed: 0.0384s/iter; left time: 414.3575s\n",
      "\titers: 200, epoch: 52 | loss: 0.0854200\n",
      "\tspeed: 0.0198s/iter; left time: 211.6212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0817988 Vali Loss: 0.0819509 Test Loss: 0.0882387\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0786324\n",
      "\tspeed: 0.0403s/iter; left time: 425.3125s\n",
      "\titers: 200, epoch: 53 | loss: 0.0790665\n",
      "\tspeed: 0.0183s/iter; left time: 191.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0818386 Vali Loss: 0.0823388 Test Loss: 0.0882767\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0830407\n",
      "\tspeed: 0.0407s/iter; left time: 420.8391s\n",
      "\titers: 200, epoch: 54 | loss: 0.0790486\n",
      "\tspeed: 0.0178s/iter; left time: 182.0746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0818012 Vali Loss: 0.0819960 Test Loss: 0.0884223\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0769131\n",
      "\tspeed: 0.0379s/iter; left time: 383.1029s\n",
      "\titers: 200, epoch: 55 | loss: 0.0849257\n",
      "\tspeed: 0.0171s/iter; left time: 171.0689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0818655 Vali Loss: 0.0820058 Test Loss: 0.0883152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0862380\n",
      "\tspeed: 0.0385s/iter; left time: 381.0898s\n",
      "\titers: 200, epoch: 56 | loss: 0.0817307\n",
      "\tspeed: 0.0182s/iter; left time: 178.6350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0820245 Vali Loss: 0.0821021 Test Loss: 0.0881774\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0795083\n",
      "\tspeed: 0.0380s/iter; left time: 367.3364s\n",
      "\titers: 200, epoch: 57 | loss: 0.0812620\n",
      "\tspeed: 0.0193s/iter; left time: 184.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0818150 Vali Loss: 0.0820054 Test Loss: 0.0883177\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0845081\n",
      "\tspeed: 0.0393s/iter; left time: 370.8215s\n",
      "\titers: 200, epoch: 58 | loss: 0.0835808\n",
      "\tspeed: 0.0182s/iter; left time: 169.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0819062 Vali Loss: 0.0819882 Test Loss: 0.0882302\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0817004\n",
      "\tspeed: 0.0464s/iter; left time: 428.4921s\n",
      "\titers: 200, epoch: 59 | loss: 0.0857204\n",
      "\tspeed: 0.0198s/iter; left time: 180.7911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.0819953 Vali Loss: 0.0819777 Test Loss: 0.0883877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02009870857000351, rmse:0.1417699158191681, mae:0.08819320052862167, rse:0.53654545545578\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2712563\n",
      "\tspeed: 0.0220s/iter; left time: 486.2469s\n",
      "\titers: 200, epoch: 1 | loss: 0.2490055\n",
      "\tspeed: 0.0177s/iter; left time: 388.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.2747137 Vali Loss: 0.1928143 Test Loss: 0.1985855\n",
      "Validation loss decreased (inf --> 0.192814).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1475603\n",
      "\tspeed: 0.0411s/iter; left time: 899.9397s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184002\n",
      "\tspeed: 0.0215s/iter; left time: 467.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1543333 Vali Loss: 0.1072151 Test Loss: 0.1128805\n",
      "Validation loss decreased (0.192814 --> 0.107215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1093291\n",
      "\tspeed: 0.0427s/iter; left time: 924.9190s\n",
      "\titers: 200, epoch: 3 | loss: 0.1044130\n",
      "\tspeed: 0.0193s/iter; left time: 416.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1114542 Vali Loss: 0.0979469 Test Loss: 0.1012931\n",
      "Validation loss decreased (0.107215 --> 0.097947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1022294\n",
      "\tspeed: 0.0400s/iter; left time: 856.7215s\n",
      "\titers: 200, epoch: 4 | loss: 0.0971455\n",
      "\tspeed: 0.0195s/iter; left time: 416.4581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.1020911 Vali Loss: 0.0929810 Test Loss: 0.0952793\n",
      "Validation loss decreased (0.097947 --> 0.092981).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0972201\n",
      "\tspeed: 0.0400s/iter; left time: 849.0362s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956559\n",
      "\tspeed: 0.0181s/iter; left time: 382.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0962046 Vali Loss: 0.0889489 Test Loss: 0.0927465\n",
      "Validation loss decreased (0.092981 --> 0.088949).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916785\n",
      "\tspeed: 0.0410s/iter; left time: 861.5311s\n",
      "\titers: 200, epoch: 6 | loss: 0.0933037\n",
      "\tspeed: 0.0184s/iter; left time: 384.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0925845 Vali Loss: 0.0879964 Test Loss: 0.0919507\n",
      "Validation loss decreased (0.088949 --> 0.087996).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896356\n",
      "\tspeed: 0.0402s/iter; left time: 834.3126s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882480\n",
      "\tspeed: 0.0230s/iter; left time: 475.5883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0903009 Vali Loss: 0.0864873 Test Loss: 0.0906692\n",
      "Validation loss decreased (0.087996 --> 0.086487).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0867063\n",
      "\tspeed: 0.0365s/iter; left time: 750.9150s\n",
      "\titers: 200, epoch: 8 | loss: 0.0857418\n",
      "\tspeed: 0.0206s/iter; left time: 420.5074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0887536 Vali Loss: 0.0856702 Test Loss: 0.0896701\n",
      "Validation loss decreased (0.086487 --> 0.085670).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0900326\n",
      "\tspeed: 0.0399s/iter; left time: 811.6551s\n",
      "\titers: 200, epoch: 9 | loss: 0.0843220\n",
      "\tspeed: 0.0205s/iter; left time: 414.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0874678 Vali Loss: 0.0853976 Test Loss: 0.0898667\n",
      "Validation loss decreased (0.085670 --> 0.085398).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0881722\n",
      "\tspeed: 0.0428s/iter; left time: 860.1713s\n",
      "\titers: 200, epoch: 10 | loss: 0.0830235\n",
      "\tspeed: 0.0205s/iter; left time: 409.9147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0865154 Vali Loss: 0.0847643 Test Loss: 0.0892309\n",
      "Validation loss decreased (0.085398 --> 0.084764).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0850319\n",
      "\tspeed: 0.0389s/iter; left time: 773.4181s\n",
      "\titers: 200, epoch: 11 | loss: 0.0851163\n",
      "\tspeed: 0.0215s/iter; left time: 425.0839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0859890 Vali Loss: 0.0846788 Test Loss: 0.0884777\n",
      "Validation loss decreased (0.084764 --> 0.084679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0867555\n",
      "\tspeed: 0.0391s/iter; left time: 769.2648s\n",
      "\titers: 200, epoch: 12 | loss: 0.0873440\n",
      "\tspeed: 0.0202s/iter; left time: 395.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0855398 Vali Loss: 0.0846019 Test Loss: 0.0891452\n",
      "Validation loss decreased (0.084679 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0830634\n",
      "\tspeed: 0.0408s/iter; left time: 793.5907s\n",
      "\titers: 200, epoch: 13 | loss: 0.0849355\n",
      "\tspeed: 0.0188s/iter; left time: 362.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0847453 Vali Loss: 0.0845939 Test Loss: 0.0891996\n",
      "Validation loss decreased (0.084602 --> 0.084594).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0888833\n",
      "\tspeed: 0.0376s/iter; left time: 721.8674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0820894\n",
      "\tspeed: 0.0168s/iter; left time: 321.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0845855 Vali Loss: 0.0839425 Test Loss: 0.0884560\n",
      "Validation loss decreased (0.084594 --> 0.083942).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0871443\n",
      "\tspeed: 0.0414s/iter; left time: 786.5460s\n",
      "\titers: 200, epoch: 15 | loss: 0.0820118\n",
      "\tspeed: 0.0184s/iter; left time: 346.9405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0842505 Vali Loss: 0.0837001 Test Loss: 0.0886381\n",
      "Validation loss decreased (0.083942 --> 0.083700).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0873144\n",
      "\tspeed: 0.0374s/iter; left time: 701.6750s\n",
      "\titers: 200, epoch: 16 | loss: 0.0815480\n",
      "\tspeed: 0.0168s/iter; left time: 313.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0838815 Vali Loss: 0.0839674 Test Loss: 0.0879909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0838181\n",
      "\tspeed: 0.0385s/iter; left time: 713.9200s\n",
      "\titers: 200, epoch: 17 | loss: 0.0831851\n",
      "\tspeed: 0.0173s/iter; left time: 319.5032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0837566 Vali Loss: 0.0838716 Test Loss: 0.0885497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0827826\n",
      "\tspeed: 0.0368s/iter; left time: 673.8713s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845723\n",
      "\tspeed: 0.0157s/iter; left time: 287.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0834298 Vali Loss: 0.0836627 Test Loss: 0.0887304\n",
      "Validation loss decreased (0.083700 --> 0.083663).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0812503\n",
      "\tspeed: 0.0406s/iter; left time: 735.3722s\n",
      "\titers: 200, epoch: 19 | loss: 0.0835254\n",
      "\tspeed: 0.0136s/iter; left time: 244.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0834923 Vali Loss: 0.0836854 Test Loss: 0.0883439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815291\n",
      "\tspeed: 0.0415s/iter; left time: 742.4929s\n",
      "\titers: 200, epoch: 20 | loss: 0.0821135\n",
      "\tspeed: 0.0210s/iter; left time: 374.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0830429 Vali Loss: 0.0838270 Test Loss: 0.0889554\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799186\n",
      "\tspeed: 0.0412s/iter; left time: 728.0956s\n",
      "\titers: 200, epoch: 21 | loss: 0.0854063\n",
      "\tspeed: 0.0180s/iter; left time: 316.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0828098 Vali Loss: 0.0836667 Test Loss: 0.0883499\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0878938\n",
      "\tspeed: 0.0418s/iter; left time: 728.2761s\n",
      "\titers: 200, epoch: 22 | loss: 0.0862450\n",
      "\tspeed: 0.0196s/iter; left time: 340.1476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0827896 Vali Loss: 0.0836010 Test Loss: 0.0884958\n",
      "Validation loss decreased (0.083663 --> 0.083601).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0814758\n",
      "\tspeed: 0.0458s/iter; left time: 788.3833s\n",
      "\titers: 200, epoch: 23 | loss: 0.0839890\n",
      "\tspeed: 0.0197s/iter; left time: 337.6991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0826417 Vali Loss: 0.0836368 Test Loss: 0.0884014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0784697\n",
      "\tspeed: 0.0399s/iter; left time: 677.6778s\n",
      "\titers: 200, epoch: 24 | loss: 0.0790533\n",
      "\tspeed: 0.0216s/iter; left time: 364.9393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0827528 Vali Loss: 0.0829785 Test Loss: 0.0880086\n",
      "Validation loss decreased (0.083601 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0845103\n",
      "\tspeed: 0.0416s/iter; left time: 697.2632s\n",
      "\titers: 200, epoch: 25 | loss: 0.0846483\n",
      "\tspeed: 0.0166s/iter; left time: 276.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0824630 Vali Loss: 0.0838180 Test Loss: 0.0891874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821375\n",
      "\tspeed: 0.0400s/iter; left time: 661.5532s\n",
      "\titers: 200, epoch: 26 | loss: 0.0806116\n",
      "\tspeed: 0.0209s/iter; left time: 343.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0822775 Vali Loss: 0.0833788 Test Loss: 0.0884062\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0811948\n",
      "\tspeed: 0.0340s/iter; left time: 555.9681s\n",
      "\titers: 200, epoch: 27 | loss: 0.0827033\n",
      "\tspeed: 0.0135s/iter; left time: 219.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 222 | Train Loss: 0.0821459 Vali Loss: 0.0831527 Test Loss: 0.0880050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0815737\n",
      "\tspeed: 0.0380s/iter; left time: 611.4583s\n",
      "\titers: 200, epoch: 28 | loss: 0.0822114\n",
      "\tspeed: 0.0210s/iter; left time: 335.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0823929 Vali Loss: 0.0835644 Test Loss: 0.0885297\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0823265\n",
      "\tspeed: 0.0384s/iter; left time: 609.2537s\n",
      "\titers: 200, epoch: 29 | loss: 0.0828064\n",
      "\tspeed: 0.0189s/iter; left time: 297.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0821245 Vali Loss: 0.0835258 Test Loss: 0.0883994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0825101\n",
      "\tspeed: 0.0415s/iter; left time: 649.3808s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805133\n",
      "\tspeed: 0.0200s/iter; left time: 311.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0820209 Vali Loss: 0.0834555 Test Loss: 0.0884562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0806998\n",
      "\tspeed: 0.0417s/iter; left time: 644.4910s\n",
      "\titers: 200, epoch: 31 | loss: 0.0799772\n",
      "\tspeed: 0.0200s/iter; left time: 307.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0820380 Vali Loss: 0.0830150 Test Loss: 0.0880995\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0818871\n",
      "\tspeed: 0.0406s/iter; left time: 617.1582s\n",
      "\titers: 200, epoch: 32 | loss: 0.0836088\n",
      "\tspeed: 0.0166s/iter; left time: 250.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0821489 Vali Loss: 0.0835289 Test Loss: 0.0884418\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0831489\n",
      "\tspeed: 0.0353s/iter; left time: 529.9775s\n",
      "\titers: 200, epoch: 33 | loss: 0.0810823\n",
      "\tspeed: 0.0176s/iter; left time: 261.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0818812 Vali Loss: 0.0830940 Test Loss: 0.0881459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0825568\n",
      "\tspeed: 0.0369s/iter; left time: 544.6306s\n",
      "\titers: 200, epoch: 34 | loss: 0.0790253\n",
      "\tspeed: 0.0179s/iter; left time: 262.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0821900 Vali Loss: 0.0837752 Test Loss: 0.0887844\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019392775371670723, rmse:0.13925795257091522, mae:0.08800852298736572, rse:0.5270386338233948\n",
      "Intermediate time for IT and pred_len 168: 00h:09m:12.52s\n",
      "Intermediate time for IT: 00h:31m:59.22s\n",
      "Total time: 02h:21m:29.17s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.0710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0218  0.1477  0.0921\n",
       "        96        0.0421  0.2052  0.1341\n",
       "        168       0.0451  0.2123  0.1407\n",
       "ES      24        0.0119  0.1092  0.0710\n",
       "        96        0.0232  0.1524  0.1037\n",
       "        168       0.0288  0.1695  0.1156\n",
       "FR      24        0.0109  0.1046  0.0604\n",
       "        96        0.0212  0.1455  0.0851\n",
       "        168       0.0238  0.1543  0.0906\n",
       "GB      24        0.0278  0.1667  0.1075\n",
       "        96        0.0444  0.2107  0.1453\n",
       "        168       0.0465  0.2156  0.1511\n",
       "IT      24        0.0108  0.1037  0.0616\n",
       "        96        0.0185  0.1359  0.0839\n",
       "        168       0.0197  0.1405  0.0881"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin_512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1377620\n",
      "\tspeed: 0.0516s/iter; left time: 1146.4683s\n",
      "\titers: 200, epoch: 1 | loss: 0.1331571\n",
      "\tspeed: 0.0202s/iter; left time: 447.2872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.1453482 Vali Loss: 0.1329798 Test Loss: 0.1404460\n",
      "Validation loss decreased (inf --> 0.132980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888074\n",
      "\tspeed: 0.0435s/iter; left time: 956.4626s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833257\n",
      "\tspeed: 0.0208s/iter; left time: 454.4895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0907465 Vali Loss: 0.0932071 Test Loss: 0.0952885\n",
      "Validation loss decreased (0.132980 --> 0.093207).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0798651\n",
      "\tspeed: 0.0430s/iter; left time: 934.8903s\n",
      "\titers: 200, epoch: 3 | loss: 0.0787375\n",
      "\tspeed: 0.0202s/iter; left time: 438.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0800946 Vali Loss: 0.0905630 Test Loss: 0.0926788\n",
      "Validation loss decreased (0.093207 --> 0.090563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760598\n",
      "\tspeed: 0.0437s/iter; left time: 940.5804s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808980\n",
      "\tspeed: 0.0202s/iter; left time: 433.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0775830 Vali Loss: 0.0891190 Test Loss: 0.0911665\n",
      "Validation loss decreased (0.090563 --> 0.089119).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723912\n",
      "\tspeed: 0.0422s/iter; left time: 899.6101s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723543\n",
      "\tspeed: 0.0203s/iter; left time: 430.8675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0761593 Vali Loss: 0.0886862 Test Loss: 0.0910422\n",
      "Validation loss decreased (0.089119 --> 0.088686).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765568\n",
      "\tspeed: 0.0427s/iter; left time: 901.1392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699121\n",
      "\tspeed: 0.0202s/iter; left time: 423.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0752030 Vali Loss: 0.0876890 Test Loss: 0.0898936\n",
      "Validation loss decreased (0.088686 --> 0.087689).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0778858\n",
      "\tspeed: 0.0424s/iter; left time: 884.1862s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760663\n",
      "\tspeed: 0.0203s/iter; left time: 420.5730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0744312 Vali Loss: 0.0877597 Test Loss: 0.0899073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724502\n",
      "\tspeed: 0.0422s/iter; left time: 870.1276s\n",
      "\titers: 200, epoch: 8 | loss: 0.0764935\n",
      "\tspeed: 0.0203s/iter; left time: 416.4660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0739043 Vali Loss: 0.0875343 Test Loss: 0.0895265\n",
      "Validation loss decreased (0.087689 --> 0.087534).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0737842\n",
      "\tspeed: 0.0427s/iter; left time: 872.4782s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747992\n",
      "\tspeed: 0.0203s/iter; left time: 411.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0733728 Vali Loss: 0.0873164 Test Loss: 0.0893410\n",
      "Validation loss decreased (0.087534 --> 0.087316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0719237\n",
      "\tspeed: 0.0432s/iter; left time: 872.2513s\n",
      "\titers: 200, epoch: 10 | loss: 0.0724368\n",
      "\tspeed: 0.0211s/iter; left time: 423.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0730262 Vali Loss: 0.0869467 Test Loss: 0.0888946\n",
      "Validation loss decreased (0.087316 --> 0.086947).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0737773\n",
      "\tspeed: 0.0455s/iter; left time: 908.2155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0743373\n",
      "\tspeed: 0.0210s/iter; left time: 417.8416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0726791 Vali Loss: 0.0867940 Test Loss: 0.0891478\n",
      "Validation loss decreased (0.086947 --> 0.086794).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0736400\n",
      "\tspeed: 0.0441s/iter; left time: 871.3079s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708776\n",
      "\tspeed: 0.0203s/iter; left time: 398.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0723108 Vali Loss: 0.0869861 Test Loss: 0.0890500\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767957\n",
      "\tspeed: 0.0434s/iter; left time: 847.4184s\n",
      "\titers: 200, epoch: 13 | loss: 0.0688413\n",
      "\tspeed: 0.0203s/iter; left time: 393.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0720886 Vali Loss: 0.0866983 Test Loss: 0.0888124\n",
      "Validation loss decreased (0.086794 --> 0.086698).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748507\n",
      "\tspeed: 0.0429s/iter; left time: 828.5915s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752109\n",
      "\tspeed: 0.0203s/iter; left time: 390.5856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0718346 Vali Loss: 0.0864202 Test Loss: 0.0885207\n",
      "Validation loss decreased (0.086698 --> 0.086420).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0716572\n",
      "\tspeed: 0.0433s/iter; left time: 825.5453s\n",
      "\titers: 200, epoch: 15 | loss: 0.0657806\n",
      "\tspeed: 0.0203s/iter; left time: 385.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0716526 Vali Loss: 0.0864495 Test Loss: 0.0887857\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789233\n",
      "\tspeed: 0.0435s/iter; left time: 819.3659s\n",
      "\titers: 200, epoch: 16 | loss: 0.0641973\n",
      "\tspeed: 0.0202s/iter; left time: 379.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0713889 Vali Loss: 0.0865192 Test Loss: 0.0888268\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0698746\n",
      "\tspeed: 0.0444s/iter; left time: 827.1375s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688530\n",
      "\tspeed: 0.0204s/iter; left time: 378.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0712813 Vali Loss: 0.0865746 Test Loss: 0.0887761\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0705122\n",
      "\tspeed: 0.0419s/iter; left time: 771.7571s\n",
      "\titers: 200, epoch: 18 | loss: 0.0665664\n",
      "\tspeed: 0.0206s/iter; left time: 376.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0711397 Vali Loss: 0.0860920 Test Loss: 0.0882421\n",
      "Validation loss decreased (0.086420 --> 0.086092).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734606\n",
      "\tspeed: 0.0443s/iter; left time: 805.1676s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721858\n",
      "\tspeed: 0.0203s/iter; left time: 366.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0710384 Vali Loss: 0.0861576 Test Loss: 0.0884578\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0654154\n",
      "\tspeed: 0.0435s/iter; left time: 781.2544s\n",
      "\titers: 200, epoch: 20 | loss: 0.0704334\n",
      "\tspeed: 0.0203s/iter; left time: 362.1083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0708815 Vali Loss: 0.0860841 Test Loss: 0.0884543\n",
      "Validation loss decreased (0.086092 --> 0.086084).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0704005\n",
      "\tspeed: 0.0438s/iter; left time: 777.4176s\n",
      "\titers: 200, epoch: 21 | loss: 0.0737988\n",
      "\tspeed: 0.0216s/iter; left time: 381.8961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0707670 Vali Loss: 0.0862926 Test Loss: 0.0886377\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0721828\n",
      "\tspeed: 0.0426s/iter; left time: 746.3925s\n",
      "\titers: 200, epoch: 22 | loss: 0.0683760\n",
      "\tspeed: 0.0201s/iter; left time: 350.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0707525 Vali Loss: 0.0862330 Test Loss: 0.0885451\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0712790\n",
      "\tspeed: 0.0414s/iter; left time: 716.1270s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664731\n",
      "\tspeed: 0.0219s/iter; left time: 377.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0706326 Vali Loss: 0.0860521 Test Loss: 0.0883970\n",
      "Validation loss decreased (0.086084 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0719056\n",
      "\tspeed: 0.0424s/iter; left time: 724.6626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0743402\n",
      "\tspeed: 0.0203s/iter; left time: 343.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0705806 Vali Loss: 0.0860364 Test Loss: 0.0883415\n",
      "Validation loss decreased (0.086052 --> 0.086036).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0744661\n",
      "\tspeed: 0.0427s/iter; left time: 720.0926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703637\n",
      "\tspeed: 0.0203s/iter; left time: 339.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0704644 Vali Loss: 0.0861248 Test Loss: 0.0883861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0754146\n",
      "\tspeed: 0.0420s/iter; left time: 698.2320s\n",
      "\titers: 200, epoch: 26 | loss: 0.0687559\n",
      "\tspeed: 0.0203s/iter; left time: 334.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0704554 Vali Loss: 0.0860874 Test Loss: 0.0883929\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0707269\n",
      "\tspeed: 0.0422s/iter; left time: 692.7104s\n",
      "\titers: 200, epoch: 27 | loss: 0.0722130\n",
      "\tspeed: 0.0203s/iter; left time: 330.5877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0703973 Vali Loss: 0.0859733 Test Loss: 0.0883172\n",
      "Validation loss decreased (0.086036 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0718899\n",
      "\tspeed: 0.0432s/iter; left time: 698.2637s\n",
      "\titers: 200, epoch: 28 | loss: 0.0679354\n",
      "\tspeed: 0.0204s/iter; left time: 328.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0703655 Vali Loss: 0.0859604 Test Loss: 0.0882858\n",
      "Validation loss decreased (0.085973 --> 0.085960).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0685098\n",
      "\tspeed: 0.0436s/iter; left time: 695.3703s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695105\n",
      "\tspeed: 0.0202s/iter; left time: 321.0411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0703027 Vali Loss: 0.0858766 Test Loss: 0.0882976\n",
      "Validation loss decreased (0.085960 --> 0.085877).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0663614\n",
      "\tspeed: 0.0423s/iter; left time: 665.3646s\n",
      "\titers: 200, epoch: 30 | loss: 0.0624843\n",
      "\tspeed: 0.0202s/iter; left time: 316.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0702440 Vali Loss: 0.0860104 Test Loss: 0.0882794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0719281\n",
      "\tspeed: 0.0429s/iter; left time: 664.9687s\n",
      "\titers: 200, epoch: 31 | loss: 0.0734896\n",
      "\tspeed: 0.0203s/iter; left time: 312.3268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0701998 Vali Loss: 0.0859208 Test Loss: 0.0883869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0735732\n",
      "\tspeed: 0.0426s/iter; left time: 651.4180s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749194\n",
      "\tspeed: 0.0201s/iter; left time: 305.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0702025 Vali Loss: 0.0860025 Test Loss: 0.0882937\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0700230\n",
      "\tspeed: 0.0426s/iter; left time: 642.2503s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736882\n",
      "\tspeed: 0.0202s/iter; left time: 303.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0701933 Vali Loss: 0.0858771 Test Loss: 0.0882897\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0699568\n",
      "\tspeed: 0.0422s/iter; left time: 626.4804s\n",
      "\titers: 200, epoch: 34 | loss: 0.0675075\n",
      "\tspeed: 0.0202s/iter; left time: 298.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0701062 Vali Loss: 0.0859168 Test Loss: 0.0882931\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0730426\n",
      "\tspeed: 0.0426s/iter; left time: 622.0811s\n",
      "\titers: 200, epoch: 35 | loss: 0.0688081\n",
      "\tspeed: 0.0204s/iter; left time: 296.3077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0701136 Vali Loss: 0.0858744 Test Loss: 0.0882826\n",
      "Validation loss decreased (0.085877 --> 0.085874).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0683707\n",
      "\tspeed: 0.0443s/iter; left time: 637.3572s\n",
      "\titers: 200, epoch: 36 | loss: 0.0742975\n",
      "\tspeed: 0.0205s/iter; left time: 292.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0700752 Vali Loss: 0.0858524 Test Loss: 0.0882819\n",
      "Validation loss decreased (0.085874 --> 0.085852).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0703321\n",
      "\tspeed: 0.0424s/iter; left time: 601.2197s\n",
      "\titers: 200, epoch: 37 | loss: 0.0681579\n",
      "\tspeed: 0.0202s/iter; left time: 284.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0700722 Vali Loss: 0.0857042 Test Loss: 0.0882949\n",
      "Validation loss decreased (0.085852 --> 0.085704).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0655152\n",
      "\tspeed: 0.0440s/iter; left time: 613.5367s\n",
      "\titers: 200, epoch: 38 | loss: 0.0710653\n",
      "\tspeed: 0.0202s/iter; left time: 280.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0700892 Vali Loss: 0.0858994 Test Loss: 0.0883125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0681975\n",
      "\tspeed: 0.0421s/iter; left time: 577.3897s\n",
      "\titers: 200, epoch: 39 | loss: 0.0754815\n",
      "\tspeed: 0.0202s/iter; left time: 275.6103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0700331 Vali Loss: 0.0858777 Test Loss: 0.0883352\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0760496\n",
      "\tspeed: 0.0437s/iter; left time: 590.3250s\n",
      "\titers: 200, epoch: 40 | loss: 0.0736035\n",
      "\tspeed: 0.0202s/iter; left time: 270.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0700364 Vali Loss: 0.0858603 Test Loss: 0.0882848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0707247\n",
      "\tspeed: 0.0423s/iter; left time: 561.6240s\n",
      "\titers: 200, epoch: 41 | loss: 0.0743177\n",
      "\tspeed: 0.0204s/iter; left time: 268.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0700012 Vali Loss: 0.0858633 Test Loss: 0.0883278\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0643289\n",
      "\tspeed: 0.0431s/iter; left time: 562.2696s\n",
      "\titers: 200, epoch: 42 | loss: 0.0673361\n",
      "\tspeed: 0.0204s/iter; left time: 264.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0700437 Vali Loss: 0.0859221 Test Loss: 0.0882951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0728683\n",
      "\tspeed: 0.0426s/iter; left time: 546.7929s\n",
      "\titers: 200, epoch: 43 | loss: 0.0736488\n",
      "\tspeed: 0.0202s/iter; left time: 257.7479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0700448 Vali Loss: 0.0858595 Test Loss: 0.0882998\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0736444\n",
      "\tspeed: 0.0414s/iter; left time: 521.5477s\n",
      "\titers: 200, epoch: 44 | loss: 0.0684188\n",
      "\tspeed: 0.0202s/iter; left time: 252.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0700184 Vali Loss: 0.0858557 Test Loss: 0.0883078\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0672928\n",
      "\tspeed: 0.0417s/iter; left time: 516.3853s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710432\n",
      "\tspeed: 0.0202s/iter; left time: 247.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0699807 Vali Loss: 0.0858151 Test Loss: 0.0882778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0693341\n",
      "\tspeed: 0.0425s/iter; left time: 517.0966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0697667\n",
      "\tspeed: 0.0202s/iter; left time: 244.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0699792 Vali Loss: 0.0858377 Test Loss: 0.0882814\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0700781\n",
      "\tspeed: 0.0478s/iter; left time: 571.4219s\n",
      "\titers: 200, epoch: 47 | loss: 0.0698581\n",
      "\tspeed: 0.0204s/iter; left time: 241.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0699734 Vali Loss: 0.0857794 Test Loss: 0.0882770\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021164411678910255, rmse:0.1454799324274063, mae:0.08829488605260849, rse:0.5134187936782837\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1457768\n",
      "\tspeed: 0.0227s/iter; left time: 504.0993s\n",
      "\titers: 200, epoch: 1 | loss: 0.1252733\n",
      "\tspeed: 0.0203s/iter; left time: 447.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.1449153 Vali Loss: 0.1321275 Test Loss: 0.1399126\n",
      "Validation loss decreased (inf --> 0.132128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0941418\n",
      "\tspeed: 0.0444s/iter; left time: 974.8132s\n",
      "\titers: 200, epoch: 2 | loss: 0.0837390\n",
      "\tspeed: 0.0240s/iter; left time: 525.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0905597 Vali Loss: 0.0936815 Test Loss: 0.0959281\n",
      "Validation loss decreased (0.132128 --> 0.093681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803334\n",
      "\tspeed: 0.0438s/iter; left time: 953.0274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0787160\n",
      "\tspeed: 0.0202s/iter; left time: 438.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0803617 Vali Loss: 0.0908617 Test Loss: 0.0933133\n",
      "Validation loss decreased (0.093681 --> 0.090862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0769821\n",
      "\tspeed: 0.0439s/iter; left time: 945.8652s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811432\n",
      "\tspeed: 0.0206s/iter; left time: 442.3487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0777963 Vali Loss: 0.0896347 Test Loss: 0.0919774\n",
      "Validation loss decreased (0.090862 --> 0.089635).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0762891\n",
      "\tspeed: 0.0435s/iter; left time: 925.9525s\n",
      "\titers: 200, epoch: 5 | loss: 0.0739720\n",
      "\tspeed: 0.0204s/iter; left time: 432.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0763399 Vali Loss: 0.0885874 Test Loss: 0.0913498\n",
      "Validation loss decreased (0.089635 --> 0.088587).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770344\n",
      "\tspeed: 0.0443s/iter; left time: 934.2972s\n",
      "\titers: 200, epoch: 6 | loss: 0.0747715\n",
      "\tspeed: 0.0203s/iter; left time: 425.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0753659 Vali Loss: 0.0882910 Test Loss: 0.0905402\n",
      "Validation loss decreased (0.088587 --> 0.088291).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0718601\n",
      "\tspeed: 0.0442s/iter; left time: 921.3748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733004\n",
      "\tspeed: 0.0201s/iter; left time: 418.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0745911 Vali Loss: 0.0876026 Test Loss: 0.0900850\n",
      "Validation loss decreased (0.088291 --> 0.087603).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0689812\n",
      "\tspeed: 0.0476s/iter; left time: 981.7564s\n",
      "\titers: 200, epoch: 8 | loss: 0.0701391\n",
      "\tspeed: 0.0208s/iter; left time: 427.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0739652 Vali Loss: 0.0871537 Test Loss: 0.0895751\n",
      "Validation loss decreased (0.087603 --> 0.087154).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0760083\n",
      "\tspeed: 0.0474s/iter; left time: 968.4938s\n",
      "\titers: 200, epoch: 9 | loss: 0.0687121\n",
      "\tspeed: 0.0203s/iter; left time: 412.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0735100 Vali Loss: 0.0871594 Test Loss: 0.0892767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0737165\n",
      "\tspeed: 0.0442s/iter; left time: 892.5291s\n",
      "\titers: 200, epoch: 10 | loss: 0.0737987\n",
      "\tspeed: 0.0202s/iter; left time: 405.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0729942 Vali Loss: 0.0868440 Test Loss: 0.0893486\n",
      "Validation loss decreased (0.087154 --> 0.086844).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0700159\n",
      "\tspeed: 0.0455s/iter; left time: 909.0059s\n",
      "\titers: 200, epoch: 11 | loss: 0.0704054\n",
      "\tspeed: 0.0209s/iter; left time: 415.4822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0726223 Vali Loss: 0.0867505 Test Loss: 0.0891334\n",
      "Validation loss decreased (0.086844 --> 0.086751).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716849\n",
      "\tspeed: 0.0450s/iter; left time: 888.3358s\n",
      "\titers: 200, epoch: 12 | loss: 0.0716616\n",
      "\tspeed: 0.0208s/iter; left time: 408.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0724141 Vali Loss: 0.0865553 Test Loss: 0.0886712\n",
      "Validation loss decreased (0.086751 --> 0.086555).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0736970\n",
      "\tspeed: 0.0447s/iter; left time: 872.9498s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727175\n",
      "\tspeed: 0.0202s/iter; left time: 393.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0720431 Vali Loss: 0.0867599 Test Loss: 0.0888985\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0737206\n",
      "\tspeed: 0.0439s/iter; left time: 848.2172s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717015\n",
      "\tspeed: 0.0202s/iter; left time: 387.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0718532 Vali Loss: 0.0863841 Test Loss: 0.0888101\n",
      "Validation loss decreased (0.086555 --> 0.086384).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0652375\n",
      "\tspeed: 0.0441s/iter; left time: 841.7685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728162\n",
      "\tspeed: 0.0204s/iter; left time: 387.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0716433 Vali Loss: 0.0865551 Test Loss: 0.0889171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0733988\n",
      "\tspeed: 0.0426s/iter; left time: 804.2002s\n",
      "\titers: 200, epoch: 16 | loss: 0.0780583\n",
      "\tspeed: 0.0202s/iter; left time: 378.4105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0714775 Vali Loss: 0.0860504 Test Loss: 0.0887519\n",
      "Validation loss decreased (0.086384 --> 0.086050).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0712492\n",
      "\tspeed: 0.0458s/iter; left time: 854.2368s\n",
      "\titers: 200, epoch: 17 | loss: 0.0724499\n",
      "\tspeed: 0.0208s/iter; left time: 385.1312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0713560 Vali Loss: 0.0862834 Test Loss: 0.0887359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0705642\n",
      "\tspeed: 0.0425s/iter; left time: 781.6247s\n",
      "\titers: 200, epoch: 18 | loss: 0.0676103\n",
      "\tspeed: 0.0202s/iter; left time: 368.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0712196 Vali Loss: 0.0863363 Test Loss: 0.0887021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0751437\n",
      "\tspeed: 0.0440s/iter; left time: 800.5046s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767686\n",
      "\tspeed: 0.0207s/iter; left time: 374.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0710074 Vali Loss: 0.0862366 Test Loss: 0.0886476\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0716588\n",
      "\tspeed: 0.0450s/iter; left time: 807.6772s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717877\n",
      "\tspeed: 0.0207s/iter; left time: 369.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0709683 Vali Loss: 0.0862968 Test Loss: 0.0884768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0685550\n",
      "\tspeed: 0.0453s/iter; left time: 803.1805s\n",
      "\titers: 200, epoch: 21 | loss: 0.0744878\n",
      "\tspeed: 0.0208s/iter; left time: 366.0997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0708859 Vali Loss: 0.0861431 Test Loss: 0.0885609\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0760119\n",
      "\tspeed: 0.0434s/iter; left time: 759.6356s\n",
      "\titers: 200, epoch: 22 | loss: 0.0736952\n",
      "\tspeed: 0.0202s/iter; left time: 352.5925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0707929 Vali Loss: 0.0860547 Test Loss: 0.0884532\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0745036\n",
      "\tspeed: 0.0424s/iter; left time: 732.8733s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747955\n",
      "\tspeed: 0.0203s/iter; left time: 348.3416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0706562 Vali Loss: 0.0860047 Test Loss: 0.0884360\n",
      "Validation loss decreased (0.086050 --> 0.086005).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0708071\n",
      "\tspeed: 0.0429s/iter; left time: 732.5096s\n",
      "\titers: 200, epoch: 24 | loss: 0.0678734\n",
      "\tspeed: 0.0202s/iter; left time: 343.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0706411 Vali Loss: 0.0860184 Test Loss: 0.0884502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0730850\n",
      "\tspeed: 0.0452s/iter; left time: 761.8594s\n",
      "\titers: 200, epoch: 25 | loss: 0.0710742\n",
      "\tspeed: 0.0202s/iter; left time: 339.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0705115 Vali Loss: 0.0860475 Test Loss: 0.0884337\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0691141\n",
      "\tspeed: 0.0425s/iter; left time: 707.2785s\n",
      "\titers: 200, epoch: 26 | loss: 0.0715527\n",
      "\tspeed: 0.0203s/iter; left time: 335.1610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0705173 Vali Loss: 0.0859123 Test Loss: 0.0884577\n",
      "Validation loss decreased (0.086005 --> 0.085912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0708010\n",
      "\tspeed: 0.0430s/iter; left time: 704.5863s\n",
      "\titers: 200, epoch: 27 | loss: 0.0720125\n",
      "\tspeed: 0.0203s/iter; left time: 330.3869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0704899 Vali Loss: 0.0859065 Test Loss: 0.0884899\n",
      "Validation loss decreased (0.085912 --> 0.085906).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0679489\n",
      "\tspeed: 0.0451s/iter; left time: 729.7777s\n",
      "\titers: 200, epoch: 28 | loss: 0.0665388\n",
      "\tspeed: 0.0227s/iter; left time: 365.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0703913 Vali Loss: 0.0859528 Test Loss: 0.0884685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0738064\n",
      "\tspeed: 0.0488s/iter; left time: 778.2452s\n",
      "\titers: 200, epoch: 29 | loss: 0.0637311\n",
      "\tspeed: 0.0213s/iter; left time: 337.5245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0703952 Vali Loss: 0.0859381 Test Loss: 0.0883920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0663082\n",
      "\tspeed: 0.0485s/iter; left time: 762.6154s\n",
      "\titers: 200, epoch: 30 | loss: 0.0738428\n",
      "\tspeed: 0.0203s/iter; left time: 317.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0703855 Vali Loss: 0.0860211 Test Loss: 0.0884518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0764009\n",
      "\tspeed: 0.0436s/iter; left time: 676.8768s\n",
      "\titers: 200, epoch: 31 | loss: 0.0703388\n",
      "\tspeed: 0.0203s/iter; left time: 313.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0703043 Vali Loss: 0.0858619 Test Loss: 0.0884074\n",
      "Validation loss decreased (0.085906 --> 0.085862).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0676657\n",
      "\tspeed: 0.0470s/iter; left time: 719.0749s\n",
      "\titers: 200, epoch: 32 | loss: 0.0715819\n",
      "\tspeed: 0.0205s/iter; left time: 311.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0702856 Vali Loss: 0.0858205 Test Loss: 0.0883952\n",
      "Validation loss decreased (0.085862 --> 0.085820).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0742193\n",
      "\tspeed: 0.0427s/iter; left time: 643.9770s\n",
      "\titers: 200, epoch: 33 | loss: 0.0728853\n",
      "\tspeed: 0.0201s/iter; left time: 301.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0702507 Vali Loss: 0.0859160 Test Loss: 0.0883657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0671273\n",
      "\tspeed: 0.0467s/iter; left time: 692.9150s\n",
      "\titers: 200, epoch: 34 | loss: 0.0662728\n",
      "\tspeed: 0.0205s/iter; left time: 302.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0702694 Vali Loss: 0.0858999 Test Loss: 0.0884102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0713012\n",
      "\tspeed: 0.0445s/iter; left time: 650.0643s\n",
      "\titers: 200, epoch: 35 | loss: 0.0675659\n",
      "\tspeed: 0.0204s/iter; left time: 295.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0701994 Vali Loss: 0.0859093 Test Loss: 0.0883762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0693318\n",
      "\tspeed: 0.0453s/iter; left time: 652.4892s\n",
      "\titers: 200, epoch: 36 | loss: 0.0719519\n",
      "\tspeed: 0.0203s/iter; left time: 289.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0701461 Vali Loss: 0.0859410 Test Loss: 0.0884031\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0675402\n",
      "\tspeed: 0.0479s/iter; left time: 678.9127s\n",
      "\titers: 200, epoch: 37 | loss: 0.0690155\n",
      "\tspeed: 0.0243s/iter; left time: 341.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0701522 Vali Loss: 0.0858340 Test Loss: 0.0884018\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0654251\n",
      "\tspeed: 0.0474s/iter; left time: 661.4621s\n",
      "\titers: 200, epoch: 38 | loss: 0.0732168\n",
      "\tspeed: 0.0202s/iter; left time: 280.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0701636 Vali Loss: 0.0858784 Test Loss: 0.0883626\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0722284\n",
      "\tspeed: 0.0434s/iter; left time: 596.0516s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711096\n",
      "\tspeed: 0.0203s/iter; left time: 275.9997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0701109 Vali Loss: 0.0858834 Test Loss: 0.0883787\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0696561\n",
      "\tspeed: 0.0482s/iter; left time: 650.4158s\n",
      "\titers: 200, epoch: 40 | loss: 0.0666966\n",
      "\tspeed: 0.0206s/iter; left time: 276.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0700936 Vali Loss: 0.0858105 Test Loss: 0.0884116\n",
      "Validation loss decreased (0.085820 --> 0.085810).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0688744\n",
      "\tspeed: 0.0476s/iter; left time: 632.3667s\n",
      "\titers: 200, epoch: 41 | loss: 0.0608446\n",
      "\tspeed: 0.0205s/iter; left time: 270.7712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0701393 Vali Loss: 0.0858541 Test Loss: 0.0883775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0718032\n",
      "\tspeed: 0.0425s/iter; left time: 555.1812s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704036\n",
      "\tspeed: 0.0223s/iter; left time: 289.3846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0700828 Vali Loss: 0.0859317 Test Loss: 0.0883932\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0673954\n",
      "\tspeed: 0.0424s/iter; left time: 544.0667s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753617\n",
      "\tspeed: 0.0204s/iter; left time: 259.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0700743 Vali Loss: 0.0858525 Test Loss: 0.0883952\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0685175\n",
      "\tspeed: 0.0440s/iter; left time: 555.2726s\n",
      "\titers: 200, epoch: 44 | loss: 0.0723481\n",
      "\tspeed: 0.0207s/iter; left time: 258.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0700939 Vali Loss: 0.0858894 Test Loss: 0.0883860\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0728776\n",
      "\tspeed: 0.0456s/iter; left time: 565.3735s\n",
      "\titers: 200, epoch: 45 | loss: 0.0681969\n",
      "\tspeed: 0.0202s/iter; left time: 248.0734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0700548 Vali Loss: 0.0858970 Test Loss: 0.0883587\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0755119\n",
      "\tspeed: 0.0438s/iter; left time: 533.1028s\n",
      "\titers: 200, epoch: 46 | loss: 0.0740993\n",
      "\tspeed: 0.0203s/iter; left time: 244.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0700972 Vali Loss: 0.0858533 Test Loss: 0.0883693\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0730135\n",
      "\tspeed: 0.0437s/iter; left time: 521.3775s\n",
      "\titers: 200, epoch: 47 | loss: 0.0729510\n",
      "\tspeed: 0.0202s/iter; left time: 239.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0701239 Vali Loss: 0.0857148 Test Loss: 0.0883617\n",
      "Validation loss decreased (0.085810 --> 0.085715).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0732426\n",
      "\tspeed: 0.0461s/iter; left time: 540.6517s\n",
      "\titers: 200, epoch: 48 | loss: 0.0719958\n",
      "\tspeed: 0.0209s/iter; left time: 242.8430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0700542 Vali Loss: 0.0858251 Test Loss: 0.0883674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0672705\n",
      "\tspeed: 0.0497s/iter; left time: 571.0243s\n",
      "\titers: 200, epoch: 49 | loss: 0.0687461\n",
      "\tspeed: 0.0234s/iter; left time: 266.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0699939 Vali Loss: 0.0859427 Test Loss: 0.0883658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0673964\n",
      "\tspeed: 0.0487s/iter; left time: 548.6975s\n",
      "\titers: 200, epoch: 50 | loss: 0.0689610\n",
      "\tspeed: 0.0237s/iter; left time: 264.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0700048 Vali Loss: 0.0858370 Test Loss: 0.0883595\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0664425\n",
      "\tspeed: 0.0465s/iter; left time: 514.2297s\n",
      "\titers: 200, epoch: 51 | loss: 0.0649861\n",
      "\tspeed: 0.0203s/iter; left time: 222.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0700657 Vali Loss: 0.0858117 Test Loss: 0.0883545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0652465\n",
      "\tspeed: 0.0432s/iter; left time: 467.3853s\n",
      "\titers: 200, epoch: 52 | loss: 0.0679388\n",
      "\tspeed: 0.0202s/iter; left time: 216.9027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0700437 Vali Loss: 0.0858057 Test Loss: 0.0883716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0666868\n",
      "\tspeed: 0.0448s/iter; left time: 474.8767s\n",
      "\titers: 200, epoch: 53 | loss: 0.0691082\n",
      "\tspeed: 0.0206s/iter; left time: 216.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0700784 Vali Loss: 0.0858263 Test Loss: 0.0883597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0712501\n",
      "\tspeed: 0.0450s/iter; left time: 467.1492s\n",
      "\titers: 200, epoch: 54 | loss: 0.0699723\n",
      "\tspeed: 0.0208s/iter; left time: 214.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0700281 Vali Loss: 0.0858022 Test Loss: 0.0883665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0657935\n",
      "\tspeed: 0.0455s/iter; left time: 461.9370s\n",
      "\titers: 200, epoch: 55 | loss: 0.0701052\n",
      "\tspeed: 0.0205s/iter; left time: 206.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0700248 Vali Loss: 0.0857346 Test Loss: 0.0883552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0770572\n",
      "\tspeed: 0.0442s/iter; left time: 438.8808s\n",
      "\titers: 200, epoch: 56 | loss: 0.0719003\n",
      "\tspeed: 0.0202s/iter; left time: 199.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0700405 Vali Loss: 0.0857840 Test Loss: 0.0883552\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0756484\n",
      "\tspeed: 0.0466s/iter; left time: 452.9183s\n",
      "\titers: 200, epoch: 57 | loss: 0.0654768\n",
      "\tspeed: 0.0204s/iter; left time: 195.6671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0699883 Vali Loss: 0.0858165 Test Loss: 0.0883590\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0211266428232193, rmse:0.14535006880760193, mae:0.08836168050765991, rse:0.5129605531692505\n",
      "Intermediate time for DE and pred_len 24: 00h:11m:25.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1524173\n",
      "\tspeed: 0.0492s/iter; left time: 1087.4326s\n",
      "\titers: 200, epoch: 1 | loss: 0.1376555\n",
      "\tspeed: 0.0207s/iter; left time: 455.0291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 222 | Train Loss: 0.1509101 Vali Loss: 0.1419197 Test Loss: 0.1509736\n",
      "Validation loss decreased (inf --> 0.141920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1143035\n",
      "\tspeed: 0.0447s/iter; left time: 977.9788s\n",
      "\titers: 200, epoch: 2 | loss: 0.1107902\n",
      "\tspeed: 0.0231s/iter; left time: 503.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 222 | Train Loss: 0.1142266 Vali Loss: 0.1206089 Test Loss: 0.1280332\n",
      "Validation loss decreased (0.141920 --> 0.120609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1042700\n",
      "\tspeed: 0.0468s/iter; left time: 1012.8091s\n",
      "\titers: 200, epoch: 3 | loss: 0.1045718\n",
      "\tspeed: 0.0206s/iter; left time: 443.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1059373 Vali Loss: 0.1186047 Test Loss: 0.1271009\n",
      "Validation loss decreased (0.120609 --> 0.118605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1047857\n",
      "\tspeed: 0.0450s/iter; left time: 963.5920s\n",
      "\titers: 200, epoch: 4 | loss: 0.1055623\n",
      "\tspeed: 0.0207s/iter; left time: 442.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1039810 Vali Loss: 0.1181816 Test Loss: 0.1272979\n",
      "Validation loss decreased (0.118605 --> 0.118182).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1024781\n",
      "\tspeed: 0.0452s/iter; left time: 958.1243s\n",
      "\titers: 200, epoch: 5 | loss: 0.1004525\n",
      "\tspeed: 0.0205s/iter; left time: 433.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1025587 Vali Loss: 0.1181679 Test Loss: 0.1265675\n",
      "Validation loss decreased (0.118182 --> 0.118168).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1010168\n",
      "\tspeed: 0.0453s/iter; left time: 950.9864s\n",
      "\titers: 200, epoch: 6 | loss: 0.1001576\n",
      "\tspeed: 0.0207s/iter; left time: 432.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1014520 Vali Loss: 0.1177441 Test Loss: 0.1267738\n",
      "Validation loss decreased (0.118168 --> 0.117744).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1006957\n",
      "\tspeed: 0.0453s/iter; left time: 940.0998s\n",
      "\titers: 200, epoch: 7 | loss: 0.0977427\n",
      "\tspeed: 0.0206s/iter; left time: 425.3451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1004819 Vali Loss: 0.1177376 Test Loss: 0.1280067\n",
      "Validation loss decreased (0.117744 --> 0.117738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977355\n",
      "\tspeed: 0.0450s/iter; left time: 924.0643s\n",
      "\titers: 200, epoch: 8 | loss: 0.1036791\n",
      "\tspeed: 0.0205s/iter; left time: 419.7479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0996189 Vali Loss: 0.1170966 Test Loss: 0.1263143\n",
      "Validation loss decreased (0.117738 --> 0.117097).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0948315\n",
      "\tspeed: 0.0437s/iter; left time: 887.8766s\n",
      "\titers: 200, epoch: 9 | loss: 0.0954899\n",
      "\tspeed: 0.0205s/iter; left time: 414.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0988391 Vali Loss: 0.1175358 Test Loss: 0.1276048\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0962800\n",
      "\tspeed: 0.0454s/iter; left time: 912.5820s\n",
      "\titers: 200, epoch: 10 | loss: 0.1045076\n",
      "\tspeed: 0.0206s/iter; left time: 411.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0980904 Vali Loss: 0.1174850 Test Loss: 0.1270542\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022221\n",
      "\tspeed: 0.0447s/iter; left time: 888.8109s\n",
      "\titers: 200, epoch: 11 | loss: 0.0880432\n",
      "\tspeed: 0.0206s/iter; left time: 406.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0974045 Vali Loss: 0.1176496 Test Loss: 0.1277446\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1004666\n",
      "\tspeed: 0.0441s/iter; left time: 867.5372s\n",
      "\titers: 200, epoch: 12 | loss: 0.0968740\n",
      "\tspeed: 0.0205s/iter; left time: 401.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0967256 Vali Loss: 0.1180355 Test Loss: 0.1289542\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0900581\n",
      "\tspeed: 0.0441s/iter; left time: 856.6514s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018033\n",
      "\tspeed: 0.0207s/iter; left time: 400.9422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0961563 Vali Loss: 0.1178257 Test Loss: 0.1280551\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0965116\n",
      "\tspeed: 0.0440s/iter; left time: 846.0772s\n",
      "\titers: 200, epoch: 14 | loss: 0.0987123\n",
      "\tspeed: 0.0208s/iter; left time: 397.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0956710 Vali Loss: 0.1181532 Test Loss: 0.1281280\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024824\n",
      "\tspeed: 0.0439s/iter; left time: 833.3786s\n",
      "\titers: 200, epoch: 15 | loss: 0.0948251\n",
      "\tspeed: 0.0206s/iter; left time: 390.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0951574 Vali Loss: 0.1183789 Test Loss: 0.1280938\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0915638\n",
      "\tspeed: 0.0439s/iter; left time: 823.2623s\n",
      "\titers: 200, epoch: 16 | loss: 0.0945014\n",
      "\tspeed: 0.0204s/iter; left time: 381.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0948485 Vali Loss: 0.1189933 Test Loss: 0.1282932\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0922417\n",
      "\tspeed: 0.0433s/iter; left time: 802.4703s\n",
      "\titers: 200, epoch: 17 | loss: 0.0985789\n",
      "\tspeed: 0.0205s/iter; left time: 378.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0944620 Vali Loss: 0.1189997 Test Loss: 0.1288534\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0972988\n",
      "\tspeed: 0.0428s/iter; left time: 784.3138s\n",
      "\titers: 200, epoch: 18 | loss: 0.0951064\n",
      "\tspeed: 0.0205s/iter; left time: 374.2695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0941196 Vali Loss: 0.1189761 Test Loss: 0.1283312\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03620997816324234, rmse:0.1902891993522644, mae:0.12631428241729736, rse:0.6738525032997131\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1493461\n",
      "\tspeed: 0.0232s/iter; left time: 513.2044s\n",
      "\titers: 200, epoch: 1 | loss: 0.1479065\n",
      "\tspeed: 0.0207s/iter; left time: 455.0237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1538781 Vali Loss: 0.1434596 Test Loss: 0.1525874\n",
      "Validation loss decreased (inf --> 0.143460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1096694\n",
      "\tspeed: 0.0489s/iter; left time: 1069.9201s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064714\n",
      "\tspeed: 0.0206s/iter; left time: 447.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.1145557 Vali Loss: 0.1206607 Test Loss: 0.1278548\n",
      "Validation loss decreased (0.143460 --> 0.120661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1051263\n",
      "\tspeed: 0.0458s/iter; left time: 991.5758s\n",
      "\titers: 200, epoch: 3 | loss: 0.1054919\n",
      "\tspeed: 0.0205s/iter; left time: 441.0908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1059772 Vali Loss: 0.1190641 Test Loss: 0.1264836\n",
      "Validation loss decreased (0.120661 --> 0.119064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1031318\n",
      "\tspeed: 0.0450s/iter; left time: 963.8263s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004920\n",
      "\tspeed: 0.0205s/iter; left time: 438.2117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1037085 Vali Loss: 0.1182287 Test Loss: 0.1268836\n",
      "Validation loss decreased (0.119064 --> 0.118229).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0990141\n",
      "\tspeed: 0.0467s/iter; left time: 990.1697s\n",
      "\titers: 200, epoch: 5 | loss: 0.1040915\n",
      "\tspeed: 0.0208s/iter; left time: 440.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.1022432 Vali Loss: 0.1174019 Test Loss: 0.1264498\n",
      "Validation loss decreased (0.118229 --> 0.117402).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0992906\n",
      "\tspeed: 0.0512s/iter; left time: 1075.3027s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999557\n",
      "\tspeed: 0.0205s/iter; left time: 427.5329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.1011384 Vali Loss: 0.1166721 Test Loss: 0.1268098\n",
      "Validation loss decreased (0.117402 --> 0.116672).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020196\n",
      "\tspeed: 0.0491s/iter; left time: 1019.0379s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027390\n",
      "\tspeed: 0.0205s/iter; left time: 423.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1001519 Vali Loss: 0.1173412 Test Loss: 0.1278075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1012332\n",
      "\tspeed: 0.0440s/iter; left time: 904.0826s\n",
      "\titers: 200, epoch: 8 | loss: 0.1009310\n",
      "\tspeed: 0.0205s/iter; left time: 418.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0993421 Vali Loss: 0.1172197 Test Loss: 0.1266936\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0965441\n",
      "\tspeed: 0.0444s/iter; left time: 901.9909s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015403\n",
      "\tspeed: 0.0205s/iter; left time: 414.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0985947 Vali Loss: 0.1171518 Test Loss: 0.1276691\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0992449\n",
      "\tspeed: 0.0450s/iter; left time: 903.8399s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947690\n",
      "\tspeed: 0.0207s/iter; left time: 413.6470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0978520 Vali Loss: 0.1172757 Test Loss: 0.1272541\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0921533\n",
      "\tspeed: 0.0476s/iter; left time: 946.3795s\n",
      "\titers: 200, epoch: 11 | loss: 0.0919316\n",
      "\tspeed: 0.0220s/iter; left time: 434.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.0971611 Vali Loss: 0.1173731 Test Loss: 0.1279765\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0905442\n",
      "\tspeed: 0.0443s/iter; left time: 871.8372s\n",
      "\titers: 200, epoch: 12 | loss: 0.0966975\n",
      "\tspeed: 0.0206s/iter; left time: 402.0788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0965935 Vali Loss: 0.1175434 Test Loss: 0.1281740\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1010280\n",
      "\tspeed: 0.0445s/iter; left time: 865.1339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980886\n",
      "\tspeed: 0.0207s/iter; left time: 400.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0961168 Vali Loss: 0.1179774 Test Loss: 0.1277166\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0928001\n",
      "\tspeed: 0.0454s/iter; left time: 872.1869s\n",
      "\titers: 200, epoch: 14 | loss: 0.0949198\n",
      "\tspeed: 0.0217s/iter; left time: 414.1452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.0956684 Vali Loss: 0.1185466 Test Loss: 0.1288423\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0978055\n",
      "\tspeed: 0.0488s/iter; left time: 926.8981s\n",
      "\titers: 200, epoch: 15 | loss: 0.0955613\n",
      "\tspeed: 0.0233s/iter; left time: 440.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 222 | Train Loss: 0.0951910 Vali Loss: 0.1184319 Test Loss: 0.1284154\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0934686\n",
      "\tspeed: 0.0468s/iter; left time: 878.6823s\n",
      "\titers: 200, epoch: 16 | loss: 0.0895684\n",
      "\tspeed: 0.0207s/iter; left time: 386.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0947558 Vali Loss: 0.1186671 Test Loss: 0.1287236\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03633616864681244, rmse:0.19062048196792603, mae:0.12680983543395996, rse:0.6750257015228271\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:58.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1493730\n",
      "\tspeed: 0.0493s/iter; left time: 1088.5949s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348861\n",
      "\tspeed: 0.0207s/iter; left time: 455.0498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1536933 Vali Loss: 0.1435465 Test Loss: 0.1536371\n",
      "Validation loss decreased (inf --> 0.143547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1155291\n",
      "\tspeed: 0.0449s/iter; left time: 982.5421s\n",
      "\titers: 200, epoch: 2 | loss: 0.1154785\n",
      "\tspeed: 0.0210s/iter; left time: 458.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1194270 Vali Loss: 0.1243183 Test Loss: 0.1335826\n",
      "Validation loss decreased (0.143547 --> 0.124318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089895\n",
      "\tspeed: 0.0459s/iter; left time: 993.4215s\n",
      "\titers: 200, epoch: 3 | loss: 0.1105580\n",
      "\tspeed: 0.0209s/iter; left time: 450.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1114872 Vali Loss: 0.1230036 Test Loss: 0.1318090\n",
      "Validation loss decreased (0.124318 --> 0.123004).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125762\n",
      "\tspeed: 0.0458s/iter; left time: 981.1908s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051730\n",
      "\tspeed: 0.0211s/iter; left time: 449.1915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1093482 Vali Loss: 0.1217615 Test Loss: 0.1329889\n",
      "Validation loss decreased (0.123004 --> 0.121761).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088185\n",
      "\tspeed: 0.0482s/iter; left time: 1021.9351s\n",
      "\titers: 200, epoch: 5 | loss: 0.1081393\n",
      "\tspeed: 0.0207s/iter; left time: 437.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1075922 Vali Loss: 0.1219820 Test Loss: 0.1326067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1074302\n",
      "\tspeed: 0.0444s/iter; left time: 932.9340s\n",
      "\titers: 200, epoch: 6 | loss: 0.1066736\n",
      "\tspeed: 0.0207s/iter; left time: 432.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1062116 Vali Loss: 0.1223952 Test Loss: 0.1331618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1034273\n",
      "\tspeed: 0.0457s/iter; left time: 949.9659s\n",
      "\titers: 200, epoch: 7 | loss: 0.1078559\n",
      "\tspeed: 0.0209s/iter; left time: 431.6033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.1049377 Vali Loss: 0.1228965 Test Loss: 0.1333257\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1055134\n",
      "\tspeed: 0.0454s/iter; left time: 933.8580s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035193\n",
      "\tspeed: 0.0212s/iter; left time: 434.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1037794 Vali Loss: 0.1227627 Test Loss: 0.1338401\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1046917\n",
      "\tspeed: 0.0445s/iter; left time: 905.3342s\n",
      "\titers: 200, epoch: 9 | loss: 0.1029501\n",
      "\tspeed: 0.0207s/iter; left time: 418.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1026955 Vali Loss: 0.1234626 Test Loss: 0.1339383\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1011553\n",
      "\tspeed: 0.0460s/iter; left time: 924.0719s\n",
      "\titers: 200, epoch: 10 | loss: 0.1008271\n",
      "\tspeed: 0.0212s/iter; left time: 425.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.1018061 Vali Loss: 0.1235942 Test Loss: 0.1344436\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1024787\n",
      "\tspeed: 0.0450s/iter; left time: 895.5921s\n",
      "\titers: 200, epoch: 11 | loss: 0.1039159\n",
      "\tspeed: 0.0208s/iter; left time: 411.7888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1009805 Vali Loss: 0.1240946 Test Loss: 0.1352518\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1048472\n",
      "\tspeed: 0.0438s/iter; left time: 861.4138s\n",
      "\titers: 200, epoch: 12 | loss: 0.1024140\n",
      "\tspeed: 0.0207s/iter; left time: 405.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1003043 Vali Loss: 0.1237323 Test Loss: 0.1354390\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0958448\n",
      "\tspeed: 0.0458s/iter; left time: 889.8664s\n",
      "\titers: 200, epoch: 13 | loss: 0.0903871\n",
      "\tspeed: 0.0210s/iter; left time: 406.3731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0995771 Vali Loss: 0.1244490 Test Loss: 0.1354229\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0991989\n",
      "\tspeed: 0.0446s/iter; left time: 856.1963s\n",
      "\titers: 200, epoch: 14 | loss: 0.1015474\n",
      "\tspeed: 0.0208s/iter; left time: 397.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0989815 Vali Loss: 0.1245893 Test Loss: 0.1356362\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03838725388050079, rmse:0.19592665135860443, mae:0.13298889994621277, rse:0.6939879655838013\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1545939\n",
      "\tspeed: 0.0253s/iter; left time: 559.3556s\n",
      "\titers: 200, epoch: 1 | loss: 0.1435521\n",
      "\tspeed: 0.0209s/iter; left time: 459.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.1547203 Vali Loss: 0.1446904 Test Loss: 0.1549158\n",
      "Validation loss decreased (inf --> 0.144690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1209661\n",
      "\tspeed: 0.0500s/iter; left time: 1093.5230s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121802\n",
      "\tspeed: 0.0208s/iter; left time: 452.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1194862 Vali Loss: 0.1244744 Test Loss: 0.1334681\n",
      "Validation loss decreased (0.144690 --> 0.124474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1112454\n",
      "\tspeed: 0.0475s/iter; left time: 1027.8672s\n",
      "\titers: 200, epoch: 3 | loss: 0.1089399\n",
      "\tspeed: 0.0207s/iter; left time: 446.0300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1115655 Vali Loss: 0.1223467 Test Loss: 0.1330402\n",
      "Validation loss decreased (0.124474 --> 0.122347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083752\n",
      "\tspeed: 0.0490s/iter; left time: 1050.1912s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114829\n",
      "\tspeed: 0.0210s/iter; left time: 447.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 222 | Train Loss: 0.1094200 Vali Loss: 0.1217436 Test Loss: 0.1327693\n",
      "Validation loss decreased (0.122347 --> 0.121744).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106140\n",
      "\tspeed: 0.0468s/iter; left time: 992.6585s\n",
      "\titers: 200, epoch: 5 | loss: 0.1070590\n",
      "\tspeed: 0.0211s/iter; left time: 444.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1078469 Vali Loss: 0.1213761 Test Loss: 0.1337309\n",
      "Validation loss decreased (0.121744 --> 0.121376).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023702\n",
      "\tspeed: 0.0462s/iter; left time: 969.8188s\n",
      "\titers: 200, epoch: 6 | loss: 0.1037819\n",
      "\tspeed: 0.0209s/iter; left time: 436.0667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1065838 Vali Loss: 0.1213986 Test Loss: 0.1324311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1053879\n",
      "\tspeed: 0.0449s/iter; left time: 932.8005s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040352\n",
      "\tspeed: 0.0217s/iter; left time: 448.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.1053461 Vali Loss: 0.1224677 Test Loss: 0.1340889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1058151\n",
      "\tspeed: 0.0467s/iter; left time: 960.3867s\n",
      "\titers: 200, epoch: 8 | loss: 0.1074986\n",
      "\tspeed: 0.0208s/iter; left time: 425.6736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1042542 Vali Loss: 0.1224826 Test Loss: 0.1335548\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1029493\n",
      "\tspeed: 0.0463s/iter; left time: 940.9182s\n",
      "\titers: 200, epoch: 9 | loss: 0.1044914\n",
      "\tspeed: 0.0208s/iter; left time: 420.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.1032393 Vali Loss: 0.1229950 Test Loss: 0.1343948\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033724\n",
      "\tspeed: 0.0462s/iter; left time: 929.5454s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998028\n",
      "\tspeed: 0.0207s/iter; left time: 414.4573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1023178 Vali Loss: 0.1227403 Test Loss: 0.1339128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1045528\n",
      "\tspeed: 0.0463s/iter; left time: 920.9187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0997359\n",
      "\tspeed: 0.0208s/iter; left time: 411.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1015179 Vali Loss: 0.1233486 Test Loss: 0.1345846\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0988714\n",
      "\tspeed: 0.0467s/iter; left time: 917.4554s\n",
      "\titers: 200, epoch: 12 | loss: 0.1020011\n",
      "\tspeed: 0.0217s/iter; left time: 425.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.1007181 Vali Loss: 0.1237301 Test Loss: 0.1346024\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0986675\n",
      "\tspeed: 0.0452s/iter; left time: 879.3556s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007935\n",
      "\tspeed: 0.0208s/iter; left time: 401.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1000609 Vali Loss: 0.1238479 Test Loss: 0.1345209\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0994495\n",
      "\tspeed: 0.0488s/iter; left time: 936.9610s\n",
      "\titers: 200, epoch: 14 | loss: 0.1003585\n",
      "\tspeed: 0.0218s/iter; left time: 415.9385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 222 | Train Loss: 0.0993972 Vali Loss: 0.1239429 Test Loss: 0.1347224\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1006648\n",
      "\tspeed: 0.0476s/iter; left time: 903.4635s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967785\n",
      "\tspeed: 0.0208s/iter; left time: 393.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0988245 Vali Loss: 0.1245895 Test Loss: 0.1352046\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03865373134613037, rmse:0.19660551846027374, mae:0.1337309181690216, rse:0.6963925957679749\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:28.81s\n",
      "Intermediate time for DE: 00h:18m:52.47s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1245538\n",
      "\tspeed: 0.0466s/iter; left time: 1034.0053s\n",
      "\titers: 200, epoch: 1 | loss: 0.1193508\n",
      "\tspeed: 0.0202s/iter; left time: 447.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.1320163 Vali Loss: 0.1245875 Test Loss: 0.1461333\n",
      "Validation loss decreased (inf --> 0.124587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0868936\n",
      "\tspeed: 0.0424s/iter; left time: 931.8190s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824948\n",
      "\tspeed: 0.0203s/iter; left time: 443.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0873454 Vali Loss: 0.0911156 Test Loss: 0.1036532\n",
      "Validation loss decreased (0.124587 --> 0.091116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0830222\n",
      "\tspeed: 0.0417s/iter; left time: 907.7330s\n",
      "\titers: 200, epoch: 3 | loss: 0.0809143\n",
      "\tspeed: 0.0202s/iter; left time: 438.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0794605 Vali Loss: 0.0906545 Test Loss: 0.1033716\n",
      "Validation loss decreased (0.091116 --> 0.090655).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0737462\n",
      "\tspeed: 0.0416s/iter; left time: 895.3551s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764762\n",
      "\tspeed: 0.0201s/iter; left time: 431.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0778884 Vali Loss: 0.0895036 Test Loss: 0.1019894\n",
      "Validation loss decreased (0.090655 --> 0.089504).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748554\n",
      "\tspeed: 0.0424s/iter; left time: 903.9439s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787883\n",
      "\tspeed: 0.0212s/iter; left time: 450.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0768939 Vali Loss: 0.0892633 Test Loss: 0.1015204\n",
      "Validation loss decreased (0.089504 --> 0.089263).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774865\n",
      "\tspeed: 0.0424s/iter; left time: 895.0058s\n",
      "\titers: 200, epoch: 6 | loss: 0.0687670\n",
      "\tspeed: 0.0203s/iter; left time: 425.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0760719 Vali Loss: 0.0887188 Test Loss: 0.1013631\n",
      "Validation loss decreased (0.089263 --> 0.088719).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794277\n",
      "\tspeed: 0.0422s/iter; left time: 880.9719s\n",
      "\titers: 200, epoch: 7 | loss: 0.0783006\n",
      "\tspeed: 0.0202s/iter; left time: 419.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0755215 Vali Loss: 0.0884939 Test Loss: 0.1010215\n",
      "Validation loss decreased (0.088719 --> 0.088494).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0808822\n",
      "\tspeed: 0.0425s/iter; left time: 876.4985s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738747\n",
      "\tspeed: 0.0205s/iter; left time: 420.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0750306 Vali Loss: 0.0885551 Test Loss: 0.1008470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0753432\n",
      "\tspeed: 0.0425s/iter; left time: 868.1294s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756893\n",
      "\tspeed: 0.0205s/iter; left time: 415.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0746559 Vali Loss: 0.0882864 Test Loss: 0.1009005\n",
      "Validation loss decreased (0.088494 --> 0.088286).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772406\n",
      "\tspeed: 0.0416s/iter; left time: 840.0113s\n",
      "\titers: 200, epoch: 10 | loss: 0.0709329\n",
      "\tspeed: 0.0202s/iter; left time: 406.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0742579 Vali Loss: 0.0877797 Test Loss: 0.1006359\n",
      "Validation loss decreased (0.088286 --> 0.087780).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712409\n",
      "\tspeed: 0.0429s/iter; left time: 856.2318s\n",
      "\titers: 200, epoch: 11 | loss: 0.0741729\n",
      "\tspeed: 0.0219s/iter; left time: 434.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0739608 Vali Loss: 0.0876342 Test Loss: 0.1006879\n",
      "Validation loss decreased (0.087780 --> 0.087634).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716036\n",
      "\tspeed: 0.0434s/iter; left time: 857.1130s\n",
      "\titers: 200, epoch: 12 | loss: 0.0784244\n",
      "\tspeed: 0.0202s/iter; left time: 397.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0736575 Vali Loss: 0.0876265 Test Loss: 0.1003132\n",
      "Validation loss decreased (0.087634 --> 0.087626).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0780636\n",
      "\tspeed: 0.0440s/iter; left time: 859.6778s\n",
      "\titers: 200, epoch: 13 | loss: 0.0722463\n",
      "\tspeed: 0.0205s/iter; left time: 398.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0734256 Vali Loss: 0.0879852 Test Loss: 0.1002514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0723765\n",
      "\tspeed: 0.0410s/iter; left time: 792.2912s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740850\n",
      "\tspeed: 0.0202s/iter; left time: 388.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0732319 Vali Loss: 0.0877230 Test Loss: 0.1007441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781691\n",
      "\tspeed: 0.0424s/iter; left time: 809.6719s\n",
      "\titers: 200, epoch: 15 | loss: 0.0714054\n",
      "\tspeed: 0.0202s/iter; left time: 382.5329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0730466 Vali Loss: 0.0874200 Test Loss: 0.1003688\n",
      "Validation loss decreased (0.087626 --> 0.087420).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0743991\n",
      "\tspeed: 0.0436s/iter; left time: 823.0074s\n",
      "\titers: 200, epoch: 16 | loss: 0.0702656\n",
      "\tspeed: 0.0202s/iter; left time: 378.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0728245 Vali Loss: 0.0875251 Test Loss: 0.0997652\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0700721\n",
      "\tspeed: 0.0410s/iter; left time: 763.8480s\n",
      "\titers: 200, epoch: 17 | loss: 0.0700401\n",
      "\tspeed: 0.0207s/iter; left time: 383.5241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0727253 Vali Loss: 0.0874153 Test Loss: 0.1002916\n",
      "Validation loss decreased (0.087420 --> 0.087415).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0683779\n",
      "\tspeed: 0.0439s/iter; left time: 807.6513s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788795\n",
      "\tspeed: 0.0202s/iter; left time: 370.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0726098 Vali Loss: 0.0874863 Test Loss: 0.1003539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0754172\n",
      "\tspeed: 0.0414s/iter; left time: 753.5937s\n",
      "\titers: 200, epoch: 19 | loss: 0.0710411\n",
      "\tspeed: 0.0210s/iter; left time: 379.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0724277 Vali Loss: 0.0873710 Test Loss: 0.1002471\n",
      "Validation loss decreased (0.087415 --> 0.087371).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0704229\n",
      "\tspeed: 0.0419s/iter; left time: 752.4309s\n",
      "\titers: 200, epoch: 20 | loss: 0.0737026\n",
      "\tspeed: 0.0202s/iter; left time: 360.1115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0723517 Vali Loss: 0.0872004 Test Loss: 0.0998096\n",
      "Validation loss decreased (0.087371 --> 0.087200).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0779368\n",
      "\tspeed: 0.0422s/iter; left time: 749.4646s\n",
      "\titers: 200, epoch: 21 | loss: 0.0668418\n",
      "\tspeed: 0.0202s/iter; left time: 355.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0721640 Vali Loss: 0.0873678 Test Loss: 0.1000081\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0728579\n",
      "\tspeed: 0.0412s/iter; left time: 721.5670s\n",
      "\titers: 200, epoch: 22 | loss: 0.0695429\n",
      "\tspeed: 0.0202s/iter; left time: 351.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0721171 Vali Loss: 0.0874775 Test Loss: 0.1000183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725927\n",
      "\tspeed: 0.0417s/iter; left time: 720.6464s\n",
      "\titers: 200, epoch: 23 | loss: 0.0731604\n",
      "\tspeed: 0.0202s/iter; left time: 348.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0720598 Vali Loss: 0.0872967 Test Loss: 0.0999678\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695920\n",
      "\tspeed: 0.0417s/iter; left time: 712.2015s\n",
      "\titers: 200, epoch: 24 | loss: 0.0698831\n",
      "\tspeed: 0.0202s/iter; left time: 343.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0720017 Vali Loss: 0.0873407 Test Loss: 0.0999223\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0730174\n",
      "\tspeed: 0.0420s/iter; left time: 708.4376s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705021\n",
      "\tspeed: 0.0202s/iter; left time: 338.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0718928 Vali Loss: 0.0874773 Test Loss: 0.0999954\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0720082\n",
      "\tspeed: 0.0426s/iter; left time: 708.9767s\n",
      "\titers: 200, epoch: 26 | loss: 0.0749689\n",
      "\tspeed: 0.0202s/iter; left time: 333.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0718386 Vali Loss: 0.0872480 Test Loss: 0.1000875\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0690476\n",
      "\tspeed: 0.0421s/iter; left time: 690.4394s\n",
      "\titers: 200, epoch: 27 | loss: 0.0762815\n",
      "\tspeed: 0.0202s/iter; left time: 329.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0717959 Vali Loss: 0.0873084 Test Loss: 0.1000690\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662941\n",
      "\tspeed: 0.0415s/iter; left time: 671.8041s\n",
      "\titers: 200, epoch: 28 | loss: 0.0713398\n",
      "\tspeed: 0.0203s/iter; left time: 326.0237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0717514 Vali Loss: 0.0874166 Test Loss: 0.0999382\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0712486\n",
      "\tspeed: 0.0409s/iter; left time: 652.5755s\n",
      "\titers: 200, epoch: 29 | loss: 0.0713688\n",
      "\tspeed: 0.0203s/iter; left time: 321.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0716657 Vali Loss: 0.0874740 Test Loss: 0.1000175\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701106\n",
      "\tspeed: 0.0428s/iter; left time: 672.6608s\n",
      "\titers: 200, epoch: 30 | loss: 0.0703013\n",
      "\tspeed: 0.0205s/iter; left time: 320.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0716929 Vali Loss: 0.0874791 Test Loss: 0.0999701\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025066357105970383, rmse:0.15832358598709106, mae:0.09980963915586472, rse:0.5461714863777161\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1316381\n",
      "\tspeed: 0.0222s/iter; left time: 492.6150s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189893\n",
      "\tspeed: 0.0202s/iter; left time: 445.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1318637 Vali Loss: 0.1257667 Test Loss: 0.1473826\n",
      "Validation loss decreased (inf --> 0.125767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0804733\n",
      "\tspeed: 0.0429s/iter; left time: 943.7066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0837715\n",
      "\tspeed: 0.0202s/iter; left time: 441.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0872514 Vali Loss: 0.0914942 Test Loss: 0.1030172\n",
      "Validation loss decreased (0.125767 --> 0.091494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802076\n",
      "\tspeed: 0.0434s/iter; left time: 944.8886s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792366\n",
      "\tspeed: 0.0202s/iter; left time: 438.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0795148 Vali Loss: 0.0903231 Test Loss: 0.1021462\n",
      "Validation loss decreased (0.091494 --> 0.090323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0777420\n",
      "\tspeed: 0.0438s/iter; left time: 943.9086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0830372\n",
      "\tspeed: 0.0202s/iter; left time: 432.2527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0780833 Vali Loss: 0.0899352 Test Loss: 0.1017437\n",
      "Validation loss decreased (0.090323 --> 0.089935).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746766\n",
      "\tspeed: 0.0428s/iter; left time: 911.8641s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765880\n",
      "\tspeed: 0.0202s/iter; left time: 428.6129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0769704 Vali Loss: 0.0888692 Test Loss: 0.1018413\n",
      "Validation loss decreased (0.089935 --> 0.088869).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0712161\n",
      "\tspeed: 0.0431s/iter; left time: 908.2698s\n",
      "\titers: 200, epoch: 6 | loss: 0.0817630\n",
      "\tspeed: 0.0202s/iter; left time: 423.8343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0762015 Vali Loss: 0.0887459 Test Loss: 0.1008157\n",
      "Validation loss decreased (0.088869 --> 0.088746).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744762\n",
      "\tspeed: 0.0417s/iter; left time: 870.5059s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711609\n",
      "\tspeed: 0.0202s/iter; left time: 419.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0756196 Vali Loss: 0.0886844 Test Loss: 0.1012741\n",
      "Validation loss decreased (0.088746 --> 0.088684).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0704018\n",
      "\tspeed: 0.0423s/iter; left time: 872.8708s\n",
      "\titers: 200, epoch: 8 | loss: 0.0712215\n",
      "\tspeed: 0.0202s/iter; left time: 415.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0751655 Vali Loss: 0.0883547 Test Loss: 0.1006802\n",
      "Validation loss decreased (0.088684 --> 0.088355).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729938\n",
      "\tspeed: 0.0423s/iter; left time: 862.8269s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740399\n",
      "\tspeed: 0.0201s/iter; left time: 409.3658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0747317 Vali Loss: 0.0881412 Test Loss: 0.1010895\n",
      "Validation loss decreased (0.088355 --> 0.088141).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0729757\n",
      "\tspeed: 0.0421s/iter; left time: 850.4363s\n",
      "\titers: 200, epoch: 10 | loss: 0.0725498\n",
      "\tspeed: 0.0202s/iter; left time: 406.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0744343 Vali Loss: 0.0881507 Test Loss: 0.1003969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747517\n",
      "\tspeed: 0.0425s/iter; left time: 849.6667s\n",
      "\titers: 200, epoch: 11 | loss: 0.0693537\n",
      "\tspeed: 0.0203s/iter; left time: 404.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0740383 Vali Loss: 0.0883014 Test Loss: 0.1005403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0746406\n",
      "\tspeed: 0.0424s/iter; left time: 837.4803s\n",
      "\titers: 200, epoch: 12 | loss: 0.0791859\n",
      "\tspeed: 0.0202s/iter; left time: 396.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0738218 Vali Loss: 0.0880803 Test Loss: 0.1009541\n",
      "Validation loss decreased (0.088141 --> 0.088080).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0745249\n",
      "\tspeed: 0.0421s/iter; left time: 822.1637s\n",
      "\titers: 200, epoch: 13 | loss: 0.0710853\n",
      "\tspeed: 0.0202s/iter; left time: 393.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0735844 Vali Loss: 0.0880425 Test Loss: 0.1003806\n",
      "Validation loss decreased (0.088080 --> 0.088042).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0728968\n",
      "\tspeed: 0.0427s/iter; left time: 823.5547s\n",
      "\titers: 200, epoch: 14 | loss: 0.0770301\n",
      "\tspeed: 0.0203s/iter; left time: 389.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0733856 Vali Loss: 0.0880058 Test Loss: 0.1005221\n",
      "Validation loss decreased (0.088042 --> 0.088006).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0687174\n",
      "\tspeed: 0.0438s/iter; left time: 835.2909s\n",
      "\titers: 200, epoch: 15 | loss: 0.0733057\n",
      "\tspeed: 0.0206s/iter; left time: 391.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0731552 Vali Loss: 0.0878088 Test Loss: 0.1004939\n",
      "Validation loss decreased (0.088006 --> 0.087809).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0774167\n",
      "\tspeed: 0.0436s/iter; left time: 822.5681s\n",
      "\titers: 200, epoch: 16 | loss: 0.0681987\n",
      "\tspeed: 0.0206s/iter; left time: 387.2582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0730194 Vali Loss: 0.0879110 Test Loss: 0.1001263\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0701981\n",
      "\tspeed: 0.0463s/iter; left time: 863.1147s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726979\n",
      "\tspeed: 0.0225s/iter; left time: 417.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0728549 Vali Loss: 0.0877198 Test Loss: 0.1002269\n",
      "Validation loss decreased (0.087809 --> 0.087720).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0761764\n",
      "\tspeed: 0.0442s/iter; left time: 814.2269s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675779\n",
      "\tspeed: 0.0203s/iter; left time: 372.1017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0726795 Vali Loss: 0.0878120 Test Loss: 0.1002679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728223\n",
      "\tspeed: 0.0426s/iter; left time: 775.3469s\n",
      "\titers: 200, epoch: 19 | loss: 0.0702625\n",
      "\tspeed: 0.0202s/iter; left time: 365.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0725949 Vali Loss: 0.0878242 Test Loss: 0.1002075\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0759793\n",
      "\tspeed: 0.0473s/iter; left time: 850.2857s\n",
      "\titers: 200, epoch: 20 | loss: 0.0753382\n",
      "\tspeed: 0.0235s/iter; left time: 419.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0724604 Vali Loss: 0.0875356 Test Loss: 0.0999771\n",
      "Validation loss decreased (0.087720 --> 0.087536).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0693763\n",
      "\tspeed: 0.0448s/iter; left time: 795.2245s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732517\n",
      "\tspeed: 0.0205s/iter; left time: 362.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0723575 Vali Loss: 0.0877151 Test Loss: 0.1001181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0744058\n",
      "\tspeed: 0.0440s/iter; left time: 770.4846s\n",
      "\titers: 200, epoch: 22 | loss: 0.0704008\n",
      "\tspeed: 0.0209s/iter; left time: 363.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0722824 Vali Loss: 0.0878338 Test Loss: 0.1003786\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0714997\n",
      "\tspeed: 0.0431s/iter; left time: 745.7217s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724914\n",
      "\tspeed: 0.0202s/iter; left time: 348.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0722317 Vali Loss: 0.0877764 Test Loss: 0.1000006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0732833\n",
      "\tspeed: 0.0452s/iter; left time: 771.8750s\n",
      "\titers: 200, epoch: 24 | loss: 0.0717905\n",
      "\tspeed: 0.0221s/iter; left time: 374.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0721765 Vali Loss: 0.0875644 Test Loss: 0.1000643\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0736292\n",
      "\tspeed: 0.0463s/iter; left time: 780.8687s\n",
      "\titers: 200, epoch: 25 | loss: 0.0744468\n",
      "\tspeed: 0.0208s/iter; left time: 348.3458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0720735 Vali Loss: 0.0875618 Test Loss: 0.1001873\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0766363\n",
      "\tspeed: 0.0438s/iter; left time: 728.2646s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686396\n",
      "\tspeed: 0.0206s/iter; left time: 341.0094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0720146 Vali Loss: 0.0877111 Test Loss: 0.1003131\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0702155\n",
      "\tspeed: 0.0438s/iter; left time: 718.7080s\n",
      "\titers: 200, epoch: 27 | loss: 0.0738547\n",
      "\tspeed: 0.0202s/iter; left time: 329.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0719643 Vali Loss: 0.0878107 Test Loss: 0.1002065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662930\n",
      "\tspeed: 0.0436s/iter; left time: 705.7199s\n",
      "\titers: 200, epoch: 28 | loss: 0.0730352\n",
      "\tspeed: 0.0208s/iter; left time: 333.7881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0718557 Vali Loss: 0.0875460 Test Loss: 0.1002405\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0679301\n",
      "\tspeed: 0.0437s/iter; left time: 697.6721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0746320\n",
      "\tspeed: 0.0202s/iter; left time: 320.9502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0718953 Vali Loss: 0.0877073 Test Loss: 0.1002467\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0757640\n",
      "\tspeed: 0.0460s/iter; left time: 723.1421s\n",
      "\titers: 200, epoch: 30 | loss: 0.0700460\n",
      "\tspeed: 0.0207s/iter; left time: 323.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0718369 Vali Loss: 0.0876634 Test Loss: 0.1001616\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025245342403650284, rmse:0.1588878333568573, mae:0.09997709840536118, rse:0.5481179356575012\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:32.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1391340\n",
      "\tspeed: 0.0494s/iter; left time: 1091.9321s\n",
      "\titers: 200, epoch: 1 | loss: 0.1294459\n",
      "\tspeed: 0.0205s/iter; left time: 451.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1366978 Vali Loss: 0.1332021 Test Loss: 0.1571302\n",
      "Validation loss decreased (inf --> 0.133202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1072894\n",
      "\tspeed: 0.0455s/iter; left time: 996.5809s\n",
      "\titers: 200, epoch: 2 | loss: 0.1038330\n",
      "\tspeed: 0.0205s/iter; left time: 447.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1089461 Vali Loss: 0.1171002 Test Loss: 0.1376970\n",
      "Validation loss decreased (0.133202 --> 0.117100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1037527\n",
      "\tspeed: 0.0464s/iter; left time: 1004.8378s\n",
      "\titers: 200, epoch: 3 | loss: 0.1006318\n",
      "\tspeed: 0.0207s/iter; left time: 447.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1035151 Vali Loss: 0.1159704 Test Loss: 0.1387321\n",
      "Validation loss decreased (0.117100 --> 0.115970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1028366\n",
      "\tspeed: 0.0456s/iter; left time: 978.4148s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009857\n",
      "\tspeed: 0.0223s/iter; left time: 475.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 222 | Train Loss: 0.1019687 Vali Loss: 0.1149616 Test Loss: 0.1388284\n",
      "Validation loss decreased (0.115970 --> 0.114962).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027559\n",
      "\tspeed: 0.0456s/iter; left time: 966.3251s\n",
      "\titers: 200, epoch: 5 | loss: 0.0966023\n",
      "\tspeed: 0.0210s/iter; left time: 443.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.1006534 Vali Loss: 0.1143389 Test Loss: 0.1378390\n",
      "Validation loss decreased (0.114962 --> 0.114339).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0977534\n",
      "\tspeed: 0.0461s/iter; left time: 967.4960s\n",
      "\titers: 200, epoch: 6 | loss: 0.0962298\n",
      "\tspeed: 0.0209s/iter; left time: 436.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0993841 Vali Loss: 0.1143134 Test Loss: 0.1383425\n",
      "Validation loss decreased (0.114339 --> 0.114313).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0956495\n",
      "\tspeed: 0.0452s/iter; left time: 937.8250s\n",
      "\titers: 200, epoch: 7 | loss: 0.0957610\n",
      "\tspeed: 0.0229s/iter; left time: 473.9596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.0983473 Vali Loss: 0.1153788 Test Loss: 0.1413461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988411\n",
      "\tspeed: 0.0468s/iter; left time: 960.6707s\n",
      "\titers: 200, epoch: 8 | loss: 0.0984808\n",
      "\tspeed: 0.0238s/iter; left time: 485.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 222 | Train Loss: 0.0973812 Vali Loss: 0.1147210 Test Loss: 0.1412276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0964626\n",
      "\tspeed: 0.0439s/iter; left time: 892.6751s\n",
      "\titers: 200, epoch: 9 | loss: 0.0983345\n",
      "\tspeed: 0.0207s/iter; left time: 418.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0964990 Vali Loss: 0.1150134 Test Loss: 0.1414429\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0986145\n",
      "\tspeed: 0.0445s/iter; left time: 895.2683s\n",
      "\titers: 200, epoch: 10 | loss: 0.0970875\n",
      "\tspeed: 0.0208s/iter; left time: 416.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0957000 Vali Loss: 0.1156965 Test Loss: 0.1424831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0956377\n",
      "\tspeed: 0.0447s/iter; left time: 888.6525s\n",
      "\titers: 200, epoch: 11 | loss: 0.0877157\n",
      "\tspeed: 0.0207s/iter; left time: 409.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0950120 Vali Loss: 0.1158557 Test Loss: 0.1428586\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0920662\n",
      "\tspeed: 0.0448s/iter; left time: 881.1547s\n",
      "\titers: 200, epoch: 12 | loss: 0.0953401\n",
      "\tspeed: 0.0209s/iter; left time: 408.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0943653 Vali Loss: 0.1162093 Test Loss: 0.1423433\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0910163\n",
      "\tspeed: 0.0433s/iter; left time: 841.1008s\n",
      "\titers: 200, epoch: 13 | loss: 0.0945153\n",
      "\tspeed: 0.0206s/iter; left time: 398.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0938186 Vali Loss: 0.1164151 Test Loss: 0.1431366\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0924109\n",
      "\tspeed: 0.0442s/iter; left time: 849.7284s\n",
      "\titers: 200, epoch: 14 | loss: 0.1011545\n",
      "\tspeed: 0.0214s/iter; left time: 408.5678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0932703 Vali Loss: 0.1169312 Test Loss: 0.1422117\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0963840\n",
      "\tspeed: 0.0483s/iter; left time: 917.2155s\n",
      "\titers: 200, epoch: 15 | loss: 0.0922663\n",
      "\tspeed: 0.0246s/iter; left time: 464.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 222 | Train Loss: 0.0928472 Vali Loss: 0.1172794 Test Loss: 0.1440095\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0926247\n",
      "\tspeed: 0.0455s/iter; left time: 854.6622s\n",
      "\titers: 200, epoch: 16 | loss: 0.0894351\n",
      "\tspeed: 0.0210s/iter; left time: 391.6585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.0924225 Vali Loss: 0.1171198 Test Loss: 0.1441160\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041190098971128464, rmse:0.20295344293117523, mae:0.1383424699306488, rse:0.7018412947654724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1436757\n",
      "\tspeed: 0.0228s/iter; left time: 503.4956s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275351\n",
      "\tspeed: 0.0202s/iter; left time: 445.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1375560 Vali Loss: 0.1335425 Test Loss: 0.1576445\n",
      "Validation loss decreased (inf --> 0.133542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1139604\n",
      "\tspeed: 0.0448s/iter; left time: 979.3844s\n",
      "\titers: 200, epoch: 2 | loss: 0.1103632\n",
      "\tspeed: 0.0209s/iter; left time: 455.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1089231 Vali Loss: 0.1169632 Test Loss: 0.1386081\n",
      "Validation loss decreased (0.133542 --> 0.116963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1008757\n",
      "\tspeed: 0.0456s/iter; left time: 986.8720s\n",
      "\titers: 200, epoch: 3 | loss: 0.1075748\n",
      "\tspeed: 0.0207s/iter; left time: 446.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1034855 Vali Loss: 0.1153261 Test Loss: 0.1380497\n",
      "Validation loss decreased (0.116963 --> 0.115326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1038997\n",
      "\tspeed: 0.0493s/iter; left time: 1057.1760s\n",
      "\titers: 200, epoch: 4 | loss: 0.1024713\n",
      "\tspeed: 0.0203s/iter; left time: 433.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.1020489 Vali Loss: 0.1151815 Test Loss: 0.1390630\n",
      "Validation loss decreased (0.115326 --> 0.115182).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0970171\n",
      "\tspeed: 0.0480s/iter; left time: 1017.8074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965252\n",
      "\tspeed: 0.0231s/iter; left time: 487.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 222 | Train Loss: 0.1007201 Vali Loss: 0.1150978 Test Loss: 0.1384744\n",
      "Validation loss decreased (0.115182 --> 0.115098).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1004887\n",
      "\tspeed: 0.0468s/iter; left time: 983.1891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0988707\n",
      "\tspeed: 0.0205s/iter; left time: 427.2678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0994372 Vali Loss: 0.1147263 Test Loss: 0.1402649\n",
      "Validation loss decreased (0.115098 --> 0.114726).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0943152\n",
      "\tspeed: 0.0464s/iter; left time: 964.1413s\n",
      "\titers: 200, epoch: 7 | loss: 0.0976625\n",
      "\tspeed: 0.0202s/iter; left time: 418.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0983336 Vali Loss: 0.1143886 Test Loss: 0.1392285\n",
      "Validation loss decreased (0.114726 --> 0.114389).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982479\n",
      "\tspeed: 0.0465s/iter; left time: 954.8889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0985090\n",
      "\tspeed: 0.0212s/iter; left time: 433.3988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0973381 Vali Loss: 0.1150463 Test Loss: 0.1400844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0977509\n",
      "\tspeed: 0.0472s/iter; left time: 958.4282s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018345\n",
      "\tspeed: 0.0220s/iter; left time: 445.7486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 222 | Train Loss: 0.0963773 Vali Loss: 0.1154857 Test Loss: 0.1409592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004527\n",
      "\tspeed: 0.0454s/iter; left time: 911.8012s\n",
      "\titers: 200, epoch: 10 | loss: 0.0957800\n",
      "\tspeed: 0.0206s/iter; left time: 411.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0955798 Vali Loss: 0.1152807 Test Loss: 0.1415275\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0985380\n",
      "\tspeed: 0.0456s/iter; left time: 905.7556s\n",
      "\titers: 200, epoch: 11 | loss: 0.0947711\n",
      "\tspeed: 0.0206s/iter; left time: 408.0694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0948730 Vali Loss: 0.1152554 Test Loss: 0.1405089\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0927626\n",
      "\tspeed: 0.0486s/iter; left time: 954.8181s\n",
      "\titers: 200, epoch: 12 | loss: 0.0925700\n",
      "\tspeed: 0.0249s/iter; left time: 487.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 222 | Train Loss: 0.0942080 Vali Loss: 0.1154412 Test Loss: 0.1403674\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0891852\n",
      "\tspeed: 0.0490s/iter; left time: 952.9286s\n",
      "\titers: 200, epoch: 13 | loss: 0.0975689\n",
      "\tspeed: 0.0203s/iter; left time: 392.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.0935346 Vali Loss: 0.1156007 Test Loss: 0.1414463\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0955518\n",
      "\tspeed: 0.0469s/iter; left time: 901.2586s\n",
      "\titers: 200, epoch: 14 | loss: 0.0971746\n",
      "\tspeed: 0.0206s/iter; left time: 392.9509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0930098 Vali Loss: 0.1156332 Test Loss: 0.1418874\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0951752\n",
      "\tspeed: 0.0447s/iter; left time: 849.7723s\n",
      "\titers: 200, epoch: 15 | loss: 0.0953973\n",
      "\tspeed: 0.0209s/iter; left time: 395.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0925135 Vali Loss: 0.1157806 Test Loss: 0.1422308\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0898672\n",
      "\tspeed: 0.0457s/iter; left time: 857.6813s\n",
      "\titers: 200, epoch: 16 | loss: 0.0925093\n",
      "\tspeed: 0.0205s/iter; left time: 383.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0920800 Vali Loss: 0.1161607 Test Loss: 0.1426911\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0929775\n",
      "\tspeed: 0.0448s/iter; left time: 831.3237s\n",
      "\titers: 200, epoch: 17 | loss: 0.0954786\n",
      "\tspeed: 0.0206s/iter; left time: 380.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0916726 Vali Loss: 0.1161384 Test Loss: 0.1421496\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0417085736989975, rmse:0.2042267769575119, mae:0.1392284780740738, rse:0.7062445878982544\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:55.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1373202\n",
      "\tspeed: 0.0484s/iter; left time: 1069.1032s\n",
      "\titers: 200, epoch: 1 | loss: 0.1252467\n",
      "\tspeed: 0.0208s/iter; left time: 458.6032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.1389222 Vali Loss: 0.1349856 Test Loss: 0.1598018\n",
      "Validation loss decreased (inf --> 0.134986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122128\n",
      "\tspeed: 0.0456s/iter; left time: 998.1025s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079677\n",
      "\tspeed: 0.0220s/iter; left time: 479.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.1131975 Vali Loss: 0.1214083 Test Loss: 0.1451236\n",
      "Validation loss decreased (0.134986 --> 0.121408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034206\n",
      "\tspeed: 0.0446s/iter; left time: 966.2669s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043421\n",
      "\tspeed: 0.0208s/iter; left time: 449.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1080478 Vali Loss: 0.1201505 Test Loss: 0.1443600\n",
      "Validation loss decreased (0.121408 --> 0.120150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087200\n",
      "\tspeed: 0.0459s/iter; left time: 984.1099s\n",
      "\titers: 200, epoch: 4 | loss: 0.1071104\n",
      "\tspeed: 0.0209s/iter; left time: 445.3451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1063557 Vali Loss: 0.1193448 Test Loss: 0.1461046\n",
      "Validation loss decreased (0.120150 --> 0.119345).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1057442\n",
      "\tspeed: 0.0448s/iter; left time: 949.6124s\n",
      "\titers: 200, epoch: 5 | loss: 0.1050189\n",
      "\tspeed: 0.0208s/iter; left time: 438.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1047705 Vali Loss: 0.1199602 Test Loss: 0.1469353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1035884\n",
      "\tspeed: 0.0439s/iter; left time: 920.4999s\n",
      "\titers: 200, epoch: 6 | loss: 0.1028865\n",
      "\tspeed: 0.0208s/iter; left time: 435.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1033385 Vali Loss: 0.1201154 Test Loss: 0.1477719\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1040604\n",
      "\tspeed: 0.0437s/iter; left time: 907.8339s\n",
      "\titers: 200, epoch: 7 | loss: 0.1048123\n",
      "\tspeed: 0.0222s/iter; left time: 459.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.1019903 Vali Loss: 0.1204109 Test Loss: 0.1473069\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1037528\n",
      "\tspeed: 0.0447s/iter; left time: 918.7157s\n",
      "\titers: 200, epoch: 8 | loss: 0.1012953\n",
      "\tspeed: 0.0208s/iter; left time: 424.7608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1007835 Vali Loss: 0.1208614 Test Loss: 0.1469147\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0994017\n",
      "\tspeed: 0.0436s/iter; left time: 886.2262s\n",
      "\titers: 200, epoch: 9 | loss: 0.0974450\n",
      "\tspeed: 0.0207s/iter; left time: 419.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0996704 Vali Loss: 0.1215357 Test Loss: 0.1469999\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0994996\n",
      "\tspeed: 0.0470s/iter; left time: 944.5120s\n",
      "\titers: 200, epoch: 10 | loss: 0.0935437\n",
      "\tspeed: 0.0236s/iter; left time: 471.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 222 | Train Loss: 0.0987500 Vali Loss: 0.1218729 Test Loss: 0.1478823\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0980836\n",
      "\tspeed: 0.0458s/iter; left time: 910.5043s\n",
      "\titers: 200, epoch: 11 | loss: 0.1002329\n",
      "\tspeed: 0.0208s/iter; left time: 411.6675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.0979103 Vali Loss: 0.1220121 Test Loss: 0.1479882\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0998512\n",
      "\tspeed: 0.0436s/iter; left time: 857.6810s\n",
      "\titers: 200, epoch: 12 | loss: 0.0985839\n",
      "\tspeed: 0.0208s/iter; left time: 406.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0971625 Vali Loss: 0.1218347 Test Loss: 0.1476824\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0923920\n",
      "\tspeed: 0.0436s/iter; left time: 847.7265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0923602\n",
      "\tspeed: 0.0207s/iter; left time: 400.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0965703 Vali Loss: 0.1228353 Test Loss: 0.1483873\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0952713\n",
      "\tspeed: 0.0440s/iter; left time: 845.8321s\n",
      "\titers: 200, epoch: 14 | loss: 0.0980010\n",
      "\tspeed: 0.0209s/iter; left time: 398.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0959371 Vali Loss: 0.1225557 Test Loss: 0.1488546\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04462922737002373, rmse:0.21125631034374237, mae:0.14610466361045837, rse:0.7324559688568115\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1399875\n",
      "\tspeed: 0.0230s/iter; left time: 507.8724s\n",
      "\titers: 200, epoch: 1 | loss: 0.1310472\n",
      "\tspeed: 0.0207s/iter; left time: 456.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1400455 Vali Loss: 0.1359005 Test Loss: 0.1608648\n",
      "Validation loss decreased (inf --> 0.135900).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1128559\n",
      "\tspeed: 0.0485s/iter; left time: 1060.0771s\n",
      "\titers: 200, epoch: 2 | loss: 0.1061890\n",
      "\tspeed: 0.0207s/iter; left time: 450.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1132691 Vali Loss: 0.1212965 Test Loss: 0.1450290\n",
      "Validation loss decreased (0.135900 --> 0.121296).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072506\n",
      "\tspeed: 0.0457s/iter; left time: 989.4897s\n",
      "\titers: 200, epoch: 3 | loss: 0.1026814\n",
      "\tspeed: 0.0208s/iter; left time: 448.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1080803 Vali Loss: 0.1203585 Test Loss: 0.1448011\n",
      "Validation loss decreased (0.121296 --> 0.120359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1034077\n",
      "\tspeed: 0.0485s/iter; left time: 1040.3810s\n",
      "\titers: 200, epoch: 4 | loss: 0.1059202\n",
      "\tspeed: 0.0211s/iter; left time: 449.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.1063214 Vali Loss: 0.1201209 Test Loss: 0.1460340\n",
      "Validation loss decreased (0.120359 --> 0.120121).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1073632\n",
      "\tspeed: 0.0468s/iter; left time: 992.5399s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047156\n",
      "\tspeed: 0.0209s/iter; left time: 442.1501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1048057 Vali Loss: 0.1202695 Test Loss: 0.1469195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1002077\n",
      "\tspeed: 0.0486s/iter; left time: 1019.3666s\n",
      "\titers: 200, epoch: 6 | loss: 0.1027514\n",
      "\tspeed: 0.0223s/iter; left time: 466.3115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 222 | Train Loss: 0.1034037 Vali Loss: 0.1207923 Test Loss: 0.1470542\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020967\n",
      "\tspeed: 0.0451s/iter; left time: 936.4592s\n",
      "\titers: 200, epoch: 7 | loss: 0.1017379\n",
      "\tspeed: 0.0207s/iter; left time: 428.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1019944 Vali Loss: 0.1215709 Test Loss: 0.1473326\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0983533\n",
      "\tspeed: 0.0465s/iter; left time: 955.0197s\n",
      "\titers: 200, epoch: 8 | loss: 0.1026895\n",
      "\tspeed: 0.0217s/iter; left time: 443.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.1007716 Vali Loss: 0.1214891 Test Loss: 0.1465448\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0971727\n",
      "\tspeed: 0.0457s/iter; left time: 928.8220s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977275\n",
      "\tspeed: 0.0208s/iter; left time: 420.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0996027 Vali Loss: 0.1219952 Test Loss: 0.1457000\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1001611\n",
      "\tspeed: 0.0444s/iter; left time: 891.7156s\n",
      "\titers: 200, epoch: 10 | loss: 0.0941948\n",
      "\tspeed: 0.0208s/iter; left time: 415.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0985269 Vali Loss: 0.1219137 Test Loss: 0.1464871\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0980969\n",
      "\tspeed: 0.0446s/iter; left time: 886.0352s\n",
      "\titers: 200, epoch: 11 | loss: 0.0957821\n",
      "\tspeed: 0.0207s/iter; left time: 409.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0975671 Vali Loss: 0.1224838 Test Loss: 0.1479414\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0979652\n",
      "\tspeed: 0.0452s/iter; left time: 887.8532s\n",
      "\titers: 200, epoch: 12 | loss: 0.0986547\n",
      "\tspeed: 0.0208s/iter; left time: 407.3769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0968352 Vali Loss: 0.1234622 Test Loss: 0.1485585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0959965\n",
      "\tspeed: 0.0447s/iter; left time: 868.1511s\n",
      "\titers: 200, epoch: 13 | loss: 0.0975268\n",
      "\tspeed: 0.0207s/iter; left time: 400.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0960343 Vali Loss: 0.1230865 Test Loss: 0.1488032\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966426\n",
      "\tspeed: 0.0477s/iter; left time: 916.4758s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959285\n",
      "\tspeed: 0.0218s/iter; left time: 416.4856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 222 | Train Loss: 0.0954758 Vali Loss: 0.1235398 Test Loss: 0.1493324\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043955180794000626, rmse:0.20965491235256195, mae:0.14603397250175476, rse:0.7269037365913391\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:21.35s\n",
      "Intermediate time for GB: 00h:13m:49.48s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1316995\n",
      "\tspeed: 0.0431s/iter; left time: 957.6066s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141251\n",
      "\tspeed: 0.0134s/iter; left time: 296.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.1388009 Vali Loss: 0.1032024 Test Loss: 0.1168016\n",
      "Validation loss decreased (inf --> 0.103202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753117\n",
      "\tspeed: 0.0374s/iter; left time: 821.1906s\n",
      "\titers: 200, epoch: 2 | loss: 0.0700653\n",
      "\tspeed: 0.0175s/iter; left time: 382.2372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0781472 Vali Loss: 0.0636964 Test Loss: 0.0712593\n",
      "Validation loss decreased (0.103202 --> 0.063696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0654178\n",
      "\tspeed: 0.0370s/iter; left time: 804.5164s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637424\n",
      "\tspeed: 0.0171s/iter; left time: 370.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0660025 Vali Loss: 0.0599544 Test Loss: 0.0667734\n",
      "Validation loss decreased (0.063696 --> 0.059954).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0626357\n",
      "\tspeed: 0.0383s/iter; left time: 823.7783s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616973\n",
      "\tspeed: 0.0205s/iter; left time: 440.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0627820 Vali Loss: 0.0584413 Test Loss: 0.0651201\n",
      "Validation loss decreased (0.059954 --> 0.058441).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597465\n",
      "\tspeed: 0.0376s/iter; left time: 801.3428s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628638\n",
      "\tspeed: 0.0179s/iter; left time: 378.9896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0607773 Vali Loss: 0.0571405 Test Loss: 0.0639895\n",
      "Validation loss decreased (0.058441 --> 0.057140).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0581293\n",
      "\tspeed: 0.0376s/iter; left time: 793.4824s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603281\n",
      "\tspeed: 0.0198s/iter; left time: 414.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0595351 Vali Loss: 0.0563911 Test Loss: 0.0632125\n",
      "Validation loss decreased (0.057140 --> 0.056391).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572485\n",
      "\tspeed: 0.0427s/iter; left time: 890.7723s\n",
      "\titers: 200, epoch: 7 | loss: 0.0633266\n",
      "\tspeed: 0.0201s/iter; left time: 417.5290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0586153 Vali Loss: 0.0557108 Test Loss: 0.0625067\n",
      "Validation loss decreased (0.056391 --> 0.055711).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580989\n",
      "\tspeed: 0.0410s/iter; left time: 845.5719s\n",
      "\titers: 200, epoch: 8 | loss: 0.0594967\n",
      "\tspeed: 0.0176s/iter; left time: 361.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0579161 Vali Loss: 0.0554014 Test Loss: 0.0624003\n",
      "Validation loss decreased (0.055711 --> 0.055401).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0566262\n",
      "\tspeed: 0.0381s/iter; left time: 778.8772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0580742\n",
      "\tspeed: 0.0184s/iter; left time: 374.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0573197 Vali Loss: 0.0551629 Test Loss: 0.0619437\n",
      "Validation loss decreased (0.055401 --> 0.055163).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0574894\n",
      "\tspeed: 0.0355s/iter; left time: 716.0825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0554423\n",
      "\tspeed: 0.0171s/iter; left time: 343.4946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0567822 Vali Loss: 0.0549117 Test Loss: 0.0618298\n",
      "Validation loss decreased (0.055163 --> 0.054912).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0557017\n",
      "\tspeed: 0.0377s/iter; left time: 753.6886s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550354\n",
      "\tspeed: 0.0199s/iter; left time: 396.2461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0563969 Vali Loss: 0.0545084 Test Loss: 0.0614069\n",
      "Validation loss decreased (0.054912 --> 0.054508).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0554453\n",
      "\tspeed: 0.0390s/iter; left time: 770.4682s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549488\n",
      "\tspeed: 0.0213s/iter; left time: 418.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0560216 Vali Loss: 0.0542625 Test Loss: 0.0613297\n",
      "Validation loss decreased (0.054508 --> 0.054262).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0548906\n",
      "\tspeed: 0.0380s/iter; left time: 742.0706s\n",
      "\titers: 200, epoch: 13 | loss: 0.0515662\n",
      "\tspeed: 0.0180s/iter; left time: 349.5277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0556743 Vali Loss: 0.0539333 Test Loss: 0.0611367\n",
      "Validation loss decreased (0.054262 --> 0.053933).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0579218\n",
      "\tspeed: 0.0373s/iter; left time: 720.3849s\n",
      "\titers: 200, epoch: 14 | loss: 0.0566411\n",
      "\tspeed: 0.0197s/iter; left time: 378.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0554574 Vali Loss: 0.0540107 Test Loss: 0.0610427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0552307\n",
      "\tspeed: 0.0346s/iter; left time: 660.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0498056\n",
      "\tspeed: 0.0139s/iter; left time: 263.5032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 223 | Train Loss: 0.0552210 Vali Loss: 0.0537867 Test Loss: 0.0607748\n",
      "Validation loss decreased (0.053933 --> 0.053787).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0554657\n",
      "\tspeed: 0.0376s/iter; left time: 708.7577s\n",
      "\titers: 200, epoch: 16 | loss: 0.0549961\n",
      "\tspeed: 0.0188s/iter; left time: 352.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0550161 Vali Loss: 0.0537058 Test Loss: 0.0605868\n",
      "Validation loss decreased (0.053787 --> 0.053706).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0519610\n",
      "\tspeed: 0.0350s/iter; left time: 651.8098s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539479\n",
      "\tspeed: 0.0182s/iter; left time: 336.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0548506 Vali Loss: 0.0534832 Test Loss: 0.0606072\n",
      "Validation loss decreased (0.053706 --> 0.053483).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0553518\n",
      "\tspeed: 0.0369s/iter; left time: 679.2633s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537826\n",
      "\tspeed: 0.0181s/iter; left time: 330.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0546287 Vali Loss: 0.0535239 Test Loss: 0.0606159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0583664\n",
      "\tspeed: 0.0349s/iter; left time: 634.0137s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547581\n",
      "\tspeed: 0.0165s/iter; left time: 299.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0545056 Vali Loss: 0.0534241 Test Loss: 0.0604186\n",
      "Validation loss decreased (0.053483 --> 0.053424).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0523117\n",
      "\tspeed: 0.0375s/iter; left time: 674.3840s\n",
      "\titers: 200, epoch: 20 | loss: 0.0532579\n",
      "\tspeed: 0.0177s/iter; left time: 316.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0543870 Vali Loss: 0.0532939 Test Loss: 0.0603940\n",
      "Validation loss decreased (0.053424 --> 0.053294).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560750\n",
      "\tspeed: 0.0376s/iter; left time: 666.6546s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536320\n",
      "\tspeed: 0.0191s/iter; left time: 337.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0542489 Vali Loss: 0.0532824 Test Loss: 0.0603685\n",
      "Validation loss decreased (0.053294 --> 0.053282).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0560204\n",
      "\tspeed: 0.0334s/iter; left time: 585.7139s\n",
      "\titers: 200, epoch: 22 | loss: 0.0563516\n",
      "\tspeed: 0.0138s/iter; left time: 240.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 223 | Train Loss: 0.0541246 Vali Loss: 0.0531777 Test Loss: 0.0602670\n",
      "Validation loss decreased (0.053282 --> 0.053178).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535806\n",
      "\tspeed: 0.0437s/iter; left time: 755.1134s\n",
      "\titers: 200, epoch: 23 | loss: 0.0535378\n",
      "\tspeed: 0.0252s/iter; left time: 433.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0540704 Vali Loss: 0.0531272 Test Loss: 0.0603012\n",
      "Validation loss decreased (0.053178 --> 0.053127).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0553329\n",
      "\tspeed: 0.0394s/iter; left time: 671.8070s\n",
      "\titers: 200, epoch: 24 | loss: 0.0525381\n",
      "\tspeed: 0.0182s/iter; left time: 309.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0539805 Vali Loss: 0.0530649 Test Loss: 0.0601410\n",
      "Validation loss decreased (0.053127 --> 0.053065).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0558837\n",
      "\tspeed: 0.0327s/iter; left time: 550.7320s\n",
      "\titers: 200, epoch: 25 | loss: 0.0529701\n",
      "\tspeed: 0.0137s/iter; left time: 229.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 223 | Train Loss: 0.0539539 Vali Loss: 0.0531422 Test Loss: 0.0603021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0545564\n",
      "\tspeed: 0.0341s/iter; left time: 567.4678s\n",
      "\titers: 200, epoch: 26 | loss: 0.0530715\n",
      "\tspeed: 0.0178s/iter; left time: 294.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0538603 Vali Loss: 0.0530226 Test Loss: 0.0601278\n",
      "Validation loss decreased (0.053065 --> 0.053023).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0532174\n",
      "\tspeed: 0.0414s/iter; left time: 678.4047s\n",
      "\titers: 200, epoch: 27 | loss: 0.0540173\n",
      "\tspeed: 0.0177s/iter; left time: 288.0548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0537944 Vali Loss: 0.0531358 Test Loss: 0.0603184\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0534904\n",
      "\tspeed: 0.0382s/iter; left time: 618.1814s\n",
      "\titers: 200, epoch: 28 | loss: 0.0565198\n",
      "\tspeed: 0.0192s/iter; left time: 307.9917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0536968 Vali Loss: 0.0530144 Test Loss: 0.0601502\n",
      "Validation loss decreased (0.053023 --> 0.053014).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0532487\n",
      "\tspeed: 0.0411s/iter; left time: 655.0765s\n",
      "\titers: 200, epoch: 29 | loss: 0.0540307\n",
      "\tspeed: 0.0199s/iter; left time: 315.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0536420 Vali Loss: 0.0529004 Test Loss: 0.0600759\n",
      "Validation loss decreased (0.053014 --> 0.052900).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0549091\n",
      "\tspeed: 0.0395s/iter; left time: 621.0986s\n",
      "\titers: 200, epoch: 30 | loss: 0.0536877\n",
      "\tspeed: 0.0197s/iter; left time: 308.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0536557 Vali Loss: 0.0528685 Test Loss: 0.0600261\n",
      "Validation loss decreased (0.052900 --> 0.052869).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0558098\n",
      "\tspeed: 0.0388s/iter; left time: 601.7633s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540309\n",
      "\tspeed: 0.0154s/iter; left time: 237.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0535692 Vali Loss: 0.0528232 Test Loss: 0.0599682\n",
      "Validation loss decreased (0.052869 --> 0.052823).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0518655\n",
      "\tspeed: 0.0378s/iter; left time: 577.5512s\n",
      "\titers: 200, epoch: 32 | loss: 0.0544275\n",
      "\tspeed: 0.0212s/iter; left time: 321.3381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0535782 Vali Loss: 0.0529200 Test Loss: 0.0600195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0532053\n",
      "\tspeed: 0.0371s/iter; left time: 559.2628s\n",
      "\titers: 200, epoch: 33 | loss: 0.0574757\n",
      "\tspeed: 0.0170s/iter; left time: 254.5805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0535288 Vali Loss: 0.0529404 Test Loss: 0.0599531\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0531600\n",
      "\tspeed: 0.0364s/iter; left time: 540.3176s\n",
      "\titers: 200, epoch: 34 | loss: 0.0514306\n",
      "\tspeed: 0.0179s/iter; left time: 263.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0534653 Vali Loss: 0.0529173 Test Loss: 0.0599504\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0577433\n",
      "\tspeed: 0.0361s/iter; left time: 527.0491s\n",
      "\titers: 200, epoch: 35 | loss: 0.0542314\n",
      "\tspeed: 0.0176s/iter; left time: 256.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0534373 Vali Loss: 0.0528478 Test Loss: 0.0599264\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536150\n",
      "\tspeed: 0.0360s/iter; left time: 517.8381s\n",
      "\titers: 200, epoch: 36 | loss: 0.0552578\n",
      "\tspeed: 0.0169s/iter; left time: 241.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0534215 Vali Loss: 0.0527947 Test Loss: 0.0599559\n",
      "Validation loss decreased (0.052823 --> 0.052795).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0531414\n",
      "\tspeed: 0.0402s/iter; left time: 570.3208s\n",
      "\titers: 200, epoch: 37 | loss: 0.0564911\n",
      "\tspeed: 0.0216s/iter; left time: 304.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0534031 Vali Loss: 0.0528054 Test Loss: 0.0599714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0499778\n",
      "\tspeed: 0.0392s/iter; left time: 546.4894s\n",
      "\titers: 200, epoch: 38 | loss: 0.0562997\n",
      "\tspeed: 0.0205s/iter; left time: 284.3706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0534020 Vali Loss: 0.0528030 Test Loss: 0.0599147\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0570159\n",
      "\tspeed: 0.0349s/iter; left time: 479.6317s\n",
      "\titers: 200, epoch: 39 | loss: 0.0555769\n",
      "\tspeed: 0.0192s/iter; left time: 261.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0534392 Vali Loss: 0.0528528 Test Loss: 0.0599047\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0583478\n",
      "\tspeed: 0.0374s/iter; left time: 505.2647s\n",
      "\titers: 200, epoch: 40 | loss: 0.0530812\n",
      "\tspeed: 0.0163s/iter; left time: 218.3623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0533981 Vali Loss: 0.0528209 Test Loss: 0.0599330\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0509223\n",
      "\tspeed: 0.0338s/iter; left time: 448.7076s\n",
      "\titers: 200, epoch: 41 | loss: 0.0539606\n",
      "\tspeed: 0.0133s/iter; left time: 175.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 223 | Train Loss: 0.0533542 Vali Loss: 0.0528439 Test Loss: 0.0599277\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0554237\n",
      "\tspeed: 0.0344s/iter; left time: 448.9888s\n",
      "\titers: 200, epoch: 42 | loss: 0.0513511\n",
      "\tspeed: 0.0160s/iter; left time: 206.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0533427 Vali Loss: 0.0528117 Test Loss: 0.0599001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0539495\n",
      "\tspeed: 0.0378s/iter; left time: 485.5753s\n",
      "\titers: 200, epoch: 43 | loss: 0.0524452\n",
      "\tspeed: 0.0196s/iter; left time: 249.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0533459 Vali Loss: 0.0528399 Test Loss: 0.0599234\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0521136\n",
      "\tspeed: 0.0382s/iter; left time: 481.5755s\n",
      "\titers: 200, epoch: 44 | loss: 0.0538409\n",
      "\tspeed: 0.0184s/iter; left time: 230.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0533581 Vali Loss: 0.0527968 Test Loss: 0.0599255\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551839\n",
      "\tspeed: 0.0364s/iter; left time: 451.5522s\n",
      "\titers: 200, epoch: 45 | loss: 0.0576281\n",
      "\tspeed: 0.0179s/iter; left time: 220.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0532998 Vali Loss: 0.0527747 Test Loss: 0.0598784\n",
      "Validation loss decreased (0.052795 --> 0.052775).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0546356\n",
      "\tspeed: 0.0341s/iter; left time: 414.6796s\n",
      "\titers: 200, epoch: 46 | loss: 0.0515077\n",
      "\tspeed: 0.0133s/iter; left time: 161.0040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 223 | Train Loss: 0.0533832 Vali Loss: 0.0527760 Test Loss: 0.0598803\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0566568\n",
      "\tspeed: 0.0338s/iter; left time: 403.2180s\n",
      "\titers: 200, epoch: 47 | loss: 0.0536150\n",
      "\tspeed: 0.0176s/iter; left time: 208.4618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0532688 Vali Loss: 0.0527572 Test Loss: 0.0598731\n",
      "Validation loss decreased (0.052775 --> 0.052757).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0512226\n",
      "\tspeed: 0.0358s/iter; left time: 419.8102s\n",
      "\titers: 200, epoch: 48 | loss: 0.0538536\n",
      "\tspeed: 0.0166s/iter; left time: 192.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0533162 Vali Loss: 0.0527923 Test Loss: 0.0598735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0547711\n",
      "\tspeed: 0.0357s/iter; left time: 410.9461s\n",
      "\titers: 200, epoch: 49 | loss: 0.0540554\n",
      "\tspeed: 0.0180s/iter; left time: 205.5241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0533095 Vali Loss: 0.0528575 Test Loss: 0.0599115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0558562\n",
      "\tspeed: 0.0338s/iter; left time: 380.8593s\n",
      "\titers: 200, epoch: 50 | loss: 0.0542776\n",
      "\tspeed: 0.0157s/iter; left time: 174.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0532881 Vali Loss: 0.0527705 Test Loss: 0.0598596\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525961\n",
      "\tspeed: 0.0386s/iter; left time: 426.0324s\n",
      "\titers: 200, epoch: 51 | loss: 0.0501428\n",
      "\tspeed: 0.0144s/iter; left time: 157.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0533268 Vali Loss: 0.0527942 Test Loss: 0.0599114\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0518946\n",
      "\tspeed: 0.0381s/iter; left time: 413.0078s\n",
      "\titers: 200, epoch: 52 | loss: 0.0535070\n",
      "\tspeed: 0.0185s/iter; left time: 198.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0533619 Vali Loss: 0.0527725 Test Loss: 0.0598789\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0509580\n",
      "\tspeed: 0.0391s/iter; left time: 415.1692s\n",
      "\titers: 200, epoch: 53 | loss: 0.0513624\n",
      "\tspeed: 0.0146s/iter; left time: 153.4618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0532672 Vali Loss: 0.0527749 Test Loss: 0.0598215\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0529234\n",
      "\tspeed: 0.0381s/iter; left time: 395.6190s\n",
      "\titers: 200, epoch: 54 | loss: 0.0518621\n",
      "\tspeed: 0.0180s/iter; left time: 184.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0532337 Vali Loss: 0.0527125 Test Loss: 0.0598412\n",
      "Validation loss decreased (0.052757 --> 0.052712).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0518500\n",
      "\tspeed: 0.0388s/iter; left time: 394.2635s\n",
      "\titers: 200, epoch: 55 | loss: 0.0541460\n",
      "\tspeed: 0.0179s/iter; left time: 180.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0532687 Vali Loss: 0.0527248 Test Loss: 0.0598364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0546397\n",
      "\tspeed: 0.0358s/iter; left time: 355.3744s\n",
      "\titers: 200, epoch: 56 | loss: 0.0533278\n",
      "\tspeed: 0.0167s/iter; left time: 164.1879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0532993 Vali Loss: 0.0527509 Test Loss: 0.0598879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0507129\n",
      "\tspeed: 0.0361s/iter; left time: 351.1199s\n",
      "\titers: 200, epoch: 57 | loss: 0.0525631\n",
      "\tspeed: 0.0147s/iter; left time: 141.4020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0532417 Vali Loss: 0.0527850 Test Loss: 0.0598703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0544153\n",
      "\tspeed: 0.0373s/iter; left time: 354.1502s\n",
      "\titers: 200, epoch: 58 | loss: 0.0543238\n",
      "\tspeed: 0.0200s/iter; left time: 187.5168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0533058 Vali Loss: 0.0527756 Test Loss: 0.0598527\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0522374\n",
      "\tspeed: 0.0372s/iter; left time: 344.9975s\n",
      "\titers: 200, epoch: 59 | loss: 0.0498423\n",
      "\tspeed: 0.0174s/iter; left time: 159.4236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0533134 Vali Loss: 0.0527256 Test Loss: 0.0598280\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0550154\n",
      "\tspeed: 0.0360s/iter; left time: 325.5235s\n",
      "\titers: 200, epoch: 60 | loss: 0.0514611\n",
      "\tspeed: 0.0167s/iter; left time: 149.3119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0532866 Vali Loss: 0.0527578 Test Loss: 0.0598664\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0532482\n",
      "\tspeed: 0.0357s/iter; left time: 314.6071s\n",
      "\titers: 200, epoch: 61 | loss: 0.0500082\n",
      "\tspeed: 0.0175s/iter; left time: 152.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0532991 Vali Loss: 0.0527316 Test Loss: 0.0598439\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0535209\n",
      "\tspeed: 0.0364s/iter; left time: 313.1960s\n",
      "\titers: 200, epoch: 62 | loss: 0.0564954\n",
      "\tspeed: 0.0183s/iter; left time: 155.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0532937 Vali Loss: 0.0527752 Test Loss: 0.0599005\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0562234\n",
      "\tspeed: 0.0374s/iter; left time: 313.1318s\n",
      "\titers: 200, epoch: 63 | loss: 0.0527221\n",
      "\tspeed: 0.0171s/iter; left time: 141.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0532077 Vali Loss: 0.0526952 Test Loss: 0.0598742\n",
      "Validation loss decreased (0.052712 --> 0.052695).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0523311\n",
      "\tspeed: 0.0418s/iter; left time: 340.6265s\n",
      "\titers: 200, epoch: 64 | loss: 0.0501934\n",
      "\tspeed: 0.0202s/iter; left time: 162.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0533022 Vali Loss: 0.0526945 Test Loss: 0.0598112\n",
      "Validation loss decreased (0.052695 --> 0.052695).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0488487\n",
      "\tspeed: 0.0429s/iter; left time: 339.8019s\n",
      "\titers: 200, epoch: 65 | loss: 0.0526960\n",
      "\tspeed: 0.0230s/iter; left time: 180.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0532533 Vali Loss: 0.0526663 Test Loss: 0.0598420\n",
      "Validation loss decreased (0.052695 --> 0.052666).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0551626\n",
      "\tspeed: 0.0439s/iter; left time: 338.1571s\n",
      "\titers: 200, epoch: 66 | loss: 0.0526931\n",
      "\tspeed: 0.0136s/iter; left time: 103.5032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0532409 Vali Loss: 0.0527513 Test Loss: 0.0598395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0492182\n",
      "\tspeed: 0.0380s/iter; left time: 284.6146s\n",
      "\titers: 200, epoch: 67 | loss: 0.0516458\n",
      "\tspeed: 0.0186s/iter; left time: 137.2170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0532456 Vali Loss: 0.0527583 Test Loss: 0.0598773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0503426\n",
      "\tspeed: 0.0416s/iter; left time: 301.8876s\n",
      "\titers: 200, epoch: 68 | loss: 0.0492057\n",
      "\tspeed: 0.0184s/iter; left time: 131.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0533037 Vali Loss: 0.0528016 Test Loss: 0.0598760\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0563033\n",
      "\tspeed: 0.0369s/iter; left time: 259.7953s\n",
      "\titers: 200, epoch: 69 | loss: 0.0535067\n",
      "\tspeed: 0.0168s/iter; left time: 116.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0532901 Vali Loss: 0.0527125 Test Loss: 0.0598423\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0536549\n",
      "\tspeed: 0.0348s/iter; left time: 236.8226s\n",
      "\titers: 200, epoch: 70 | loss: 0.0525305\n",
      "\tspeed: 0.0171s/iter; left time: 114.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0531956 Vali Loss: 0.0526928 Test Loss: 0.0598347\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0520030\n",
      "\tspeed: 0.0401s/iter; left time: 264.2329s\n",
      "\titers: 200, epoch: 71 | loss: 0.0519187\n",
      "\tspeed: 0.0227s/iter; left time: 147.1263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0532231 Vali Loss: 0.0527542 Test Loss: 0.0598499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0514218\n",
      "\tspeed: 0.0395s/iter; left time: 251.3738s\n",
      "\titers: 200, epoch: 72 | loss: 0.0523330\n",
      "\tspeed: 0.0184s/iter; left time: 115.6129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0532516 Vali Loss: 0.0527266 Test Loss: 0.0598373\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0524723\n",
      "\tspeed: 0.0355s/iter; left time: 218.0553s\n",
      "\titers: 200, epoch: 73 | loss: 0.0513882\n",
      "\tspeed: 0.0186s/iter; left time: 112.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0532378 Vali Loss: 0.0527320 Test Loss: 0.0598274\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0509985\n",
      "\tspeed: 0.0374s/iter; left time: 221.6092s\n",
      "\titers: 200, epoch: 74 | loss: 0.0536287\n",
      "\tspeed: 0.0166s/iter; left time: 96.8180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0532384 Vali Loss: 0.0527682 Test Loss: 0.0598474\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0567453\n",
      "\tspeed: 0.0366s/iter; left time: 208.3367s\n",
      "\titers: 200, epoch: 75 | loss: 0.0507657\n",
      "\tspeed: 0.0186s/iter; left time: 104.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0532159 Vali Loss: 0.0528101 Test Loss: 0.0598465\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00981175433844328, rmse:0.09905429929494858, mae:0.05984200909733772, rse:0.291504830121994\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1467757\n",
      "\tspeed: 0.0203s/iter; left time: 451.3509s\n",
      "\titers: 200, epoch: 1 | loss: 0.1164621\n",
      "\tspeed: 0.0176s/iter; left time: 389.0483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1440508 Vali Loss: 0.1056515 Test Loss: 0.1192468\n",
      "Validation loss decreased (inf --> 0.105651).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754276\n",
      "\tspeed: 0.0360s/iter; left time: 790.6989s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709371\n",
      "\tspeed: 0.0168s/iter; left time: 366.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0783426 Vali Loss: 0.0632315 Test Loss: 0.0708277\n",
      "Validation loss decreased (0.105651 --> 0.063231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0647759\n",
      "\tspeed: 0.0367s/iter; left time: 798.5296s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638451\n",
      "\tspeed: 0.0178s/iter; left time: 384.6237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0658213 Vali Loss: 0.0599350 Test Loss: 0.0669212\n",
      "Validation loss decreased (0.063231 --> 0.059935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0665304\n",
      "\tspeed: 0.0373s/iter; left time: 804.0691s\n",
      "\titers: 200, epoch: 4 | loss: 0.0669489\n",
      "\tspeed: 0.0173s/iter; left time: 371.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0625526 Vali Loss: 0.0581557 Test Loss: 0.0647896\n",
      "Validation loss decreased (0.059935 --> 0.058156).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0627726\n",
      "\tspeed: 0.0384s/iter; left time: 818.9490s\n",
      "\titers: 200, epoch: 5 | loss: 0.0580662\n",
      "\tspeed: 0.0203s/iter; left time: 431.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0607671 Vali Loss: 0.0571319 Test Loss: 0.0641151\n",
      "Validation loss decreased (0.058156 --> 0.057132).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601331\n",
      "\tspeed: 0.0359s/iter; left time: 757.8305s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619630\n",
      "\tspeed: 0.0198s/iter; left time: 414.9220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0594726 Vali Loss: 0.0564902 Test Loss: 0.0634188\n",
      "Validation loss decreased (0.057132 --> 0.056490).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590419\n",
      "\tspeed: 0.0413s/iter; left time: 860.6214s\n",
      "\titers: 200, epoch: 7 | loss: 0.0579300\n",
      "\tspeed: 0.0188s/iter; left time: 389.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0586132 Vali Loss: 0.0560480 Test Loss: 0.0629785\n",
      "Validation loss decreased (0.056490 --> 0.056048).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0559717\n",
      "\tspeed: 0.0411s/iter; left time: 847.4533s\n",
      "\titers: 200, epoch: 8 | loss: 0.0565732\n",
      "\tspeed: 0.0172s/iter; left time: 353.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0578419 Vali Loss: 0.0555114 Test Loss: 0.0622749\n",
      "Validation loss decreased (0.056048 --> 0.055511).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0591304\n",
      "\tspeed: 0.0327s/iter; left time: 668.2228s\n",
      "\titers: 200, epoch: 9 | loss: 0.0564255\n",
      "\tspeed: 0.0167s/iter; left time: 339.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0573091 Vali Loss: 0.0550520 Test Loss: 0.0619997\n",
      "Validation loss decreased (0.055511 --> 0.055052).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585687\n",
      "\tspeed: 0.0360s/iter; left time: 727.8651s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550101\n",
      "\tspeed: 0.0180s/iter; left time: 361.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0568313 Vali Loss: 0.0548890 Test Loss: 0.0617063\n",
      "Validation loss decreased (0.055052 --> 0.054889).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569986\n",
      "\tspeed: 0.0350s/iter; left time: 699.6857s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581613\n",
      "\tspeed: 0.0150s/iter; left time: 297.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.0564355 Vali Loss: 0.0545754 Test Loss: 0.0615259\n",
      "Validation loss decreased (0.054889 --> 0.054575).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549039\n",
      "\tspeed: 0.0327s/iter; left time: 645.6396s\n",
      "\titers: 200, epoch: 12 | loss: 0.0566016\n",
      "\tspeed: 0.0134s/iter; left time: 262.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.0560368 Vali Loss: 0.0545691 Test Loss: 0.0614121\n",
      "Validation loss decreased (0.054575 --> 0.054569).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0572035\n",
      "\tspeed: 0.0394s/iter; left time: 768.7457s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575324\n",
      "\tspeed: 0.0156s/iter; left time: 303.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0557380 Vali Loss: 0.0539345 Test Loss: 0.0609002\n",
      "Validation loss decreased (0.054569 --> 0.053935).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0546958\n",
      "\tspeed: 0.0377s/iter; left time: 727.1425s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563415\n",
      "\tspeed: 0.0195s/iter; left time: 375.3241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0554415 Vali Loss: 0.0541797 Test Loss: 0.0609455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0552105\n",
      "\tspeed: 0.0410s/iter; left time: 782.1083s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539713\n",
      "\tspeed: 0.0214s/iter; left time: 406.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0552444 Vali Loss: 0.0537382 Test Loss: 0.0609059\n",
      "Validation loss decreased (0.053935 --> 0.053738).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0572122\n",
      "\tspeed: 0.0370s/iter; left time: 698.3299s\n",
      "\titers: 200, epoch: 16 | loss: 0.0582818\n",
      "\tspeed: 0.0170s/iter; left time: 318.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0549486 Vali Loss: 0.0536832 Test Loss: 0.0606915\n",
      "Validation loss decreased (0.053738 --> 0.053683).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0557481\n",
      "\tspeed: 0.0394s/iter; left time: 734.3078s\n",
      "\titers: 200, epoch: 17 | loss: 0.0526645\n",
      "\tspeed: 0.0198s/iter; left time: 366.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0547905 Vali Loss: 0.0535385 Test Loss: 0.0605094\n",
      "Validation loss decreased (0.053683 --> 0.053539).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0551304\n",
      "\tspeed: 0.0381s/iter; left time: 701.7770s\n",
      "\titers: 200, epoch: 18 | loss: 0.0553528\n",
      "\tspeed: 0.0134s/iter; left time: 245.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.0546656 Vali Loss: 0.0535100 Test Loss: 0.0606461\n",
      "Validation loss decreased (0.053539 --> 0.053510).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0536823\n",
      "\tspeed: 0.0384s/iter; left time: 698.4941s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542180\n",
      "\tspeed: 0.0183s/iter; left time: 331.6751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0545140 Vali Loss: 0.0534422 Test Loss: 0.0605302\n",
      "Validation loss decreased (0.053510 --> 0.053442).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0516972\n",
      "\tspeed: 0.0343s/iter; left time: 615.6038s\n",
      "\titers: 200, epoch: 20 | loss: 0.0558626\n",
      "\tspeed: 0.0171s/iter; left time: 305.9637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0543648 Vali Loss: 0.0533294 Test Loss: 0.0603036\n",
      "Validation loss decreased (0.053442 --> 0.053329).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0503682\n",
      "\tspeed: 0.0349s/iter; left time: 619.0208s\n",
      "\titers: 200, epoch: 21 | loss: 0.0524922\n",
      "\tspeed: 0.0196s/iter; left time: 345.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0542276 Vali Loss: 0.0532841 Test Loss: 0.0603827\n",
      "Validation loss decreased (0.053329 --> 0.053284).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0503461\n",
      "\tspeed: 0.0405s/iter; left time: 709.9680s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564250\n",
      "\tspeed: 0.0168s/iter; left time: 293.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0541924 Vali Loss: 0.0531586 Test Loss: 0.0603020\n",
      "Validation loss decreased (0.053284 --> 0.053159).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0565586\n",
      "\tspeed: 0.0356s/iter; left time: 616.0740s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520363\n",
      "\tspeed: 0.0190s/iter; left time: 326.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0540139 Vali Loss: 0.0532235 Test Loss: 0.0601536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0557458\n",
      "\tspeed: 0.0365s/iter; left time: 623.6999s\n",
      "\titers: 200, epoch: 24 | loss: 0.0529669\n",
      "\tspeed: 0.0163s/iter; left time: 275.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0539933 Vali Loss: 0.0532314 Test Loss: 0.0602122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0505629\n",
      "\tspeed: 0.0358s/iter; left time: 602.7736s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552466\n",
      "\tspeed: 0.0181s/iter; left time: 303.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0538970 Vali Loss: 0.0532618 Test Loss: 0.0602501\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0515085\n",
      "\tspeed: 0.0374s/iter; left time: 622.2590s\n",
      "\titers: 200, epoch: 26 | loss: 0.0523433\n",
      "\tspeed: 0.0211s/iter; left time: 349.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0537509 Vali Loss: 0.0529835 Test Loss: 0.0600329\n",
      "Validation loss decreased (0.053159 --> 0.052983).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0551435\n",
      "\tspeed: 0.0413s/iter; left time: 678.0080s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532478\n",
      "\tspeed: 0.0236s/iter; left time: 384.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0537657 Vali Loss: 0.0530946 Test Loss: 0.0601632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0537928\n",
      "\tspeed: 0.0419s/iter; left time: 677.6488s\n",
      "\titers: 200, epoch: 28 | loss: 0.0545598\n",
      "\tspeed: 0.0179s/iter; left time: 287.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0537319 Vali Loss: 0.0528908 Test Loss: 0.0600820\n",
      "Validation loss decreased (0.052983 --> 0.052891).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0535150\n",
      "\tspeed: 0.0397s/iter; left time: 633.8223s\n",
      "\titers: 200, epoch: 29 | loss: 0.0597187\n",
      "\tspeed: 0.0177s/iter; left time: 280.2045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0536271 Vali Loss: 0.0529555 Test Loss: 0.0600062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0501314\n",
      "\tspeed: 0.0336s/iter; left time: 528.0840s\n",
      "\titers: 200, epoch: 30 | loss: 0.0544182\n",
      "\tspeed: 0.0172s/iter; left time: 268.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0535906 Vali Loss: 0.0529559 Test Loss: 0.0600415\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0569321\n",
      "\tspeed: 0.0384s/iter; left time: 595.1677s\n",
      "\titers: 200, epoch: 31 | loss: 0.0535196\n",
      "\tspeed: 0.0207s/iter; left time: 318.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0535711 Vali Loss: 0.0529331 Test Loss: 0.0601126\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0578551\n",
      "\tspeed: 0.0357s/iter; left time: 545.1663s\n",
      "\titers: 200, epoch: 32 | loss: 0.0557241\n",
      "\tspeed: 0.0194s/iter; left time: 294.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0535923 Vali Loss: 0.0529477 Test Loss: 0.0600146\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0555400\n",
      "\tspeed: 0.0359s/iter; left time: 540.5057s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544455\n",
      "\tspeed: 0.0165s/iter; left time: 246.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0535305 Vali Loss: 0.0529216 Test Loss: 0.0600054\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0519639\n",
      "\tspeed: 0.0364s/iter; left time: 540.9206s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526796\n",
      "\tspeed: 0.0167s/iter; left time: 246.5287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0534899 Vali Loss: 0.0529121 Test Loss: 0.0599936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0519826\n",
      "\tspeed: 0.0380s/iter; left time: 555.8067s\n",
      "\titers: 200, epoch: 35 | loss: 0.0549644\n",
      "\tspeed: 0.0185s/iter; left time: 269.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0534534 Vali Loss: 0.0528573 Test Loss: 0.0599338\n",
      "Validation loss decreased (0.052891 --> 0.052857).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0554111\n",
      "\tspeed: 0.0371s/iter; left time: 533.3783s\n",
      "\titers: 200, epoch: 36 | loss: 0.0551376\n",
      "\tspeed: 0.0160s/iter; left time: 229.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0535004 Vali Loss: 0.0528406 Test Loss: 0.0599369\n",
      "Validation loss decreased (0.052857 --> 0.052841).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0523691\n",
      "\tspeed: 0.0377s/iter; left time: 534.2958s\n",
      "\titers: 200, epoch: 37 | loss: 0.0527352\n",
      "\tspeed: 0.0179s/iter; left time: 251.9286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0534619 Vali Loss: 0.0528652 Test Loss: 0.0599760\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0519051\n",
      "\tspeed: 0.0368s/iter; left time: 513.6869s\n",
      "\titers: 200, epoch: 38 | loss: 0.0507388\n",
      "\tspeed: 0.0159s/iter; left time: 220.3260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0533976 Vali Loss: 0.0528322 Test Loss: 0.0599426\n",
      "Validation loss decreased (0.052841 --> 0.052832).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0539290\n",
      "\tspeed: 0.0395s/iter; left time: 542.4299s\n",
      "\titers: 200, epoch: 39 | loss: 0.0510029\n",
      "\tspeed: 0.0183s/iter; left time: 249.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0534101 Vali Loss: 0.0528825 Test Loss: 0.0599659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0541807\n",
      "\tspeed: 0.0396s/iter; left time: 534.6550s\n",
      "\titers: 200, epoch: 40 | loss: 0.0534920\n",
      "\tspeed: 0.0198s/iter; left time: 265.7807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0534044 Vali Loss: 0.0528023 Test Loss: 0.0599518\n",
      "Validation loss decreased (0.052832 --> 0.052802).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0532344\n",
      "\tspeed: 0.0390s/iter; left time: 517.3841s\n",
      "\titers: 200, epoch: 41 | loss: 0.0511478\n",
      "\tspeed: 0.0179s/iter; left time: 235.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0533126 Vali Loss: 0.0528436 Test Loss: 0.0599003\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0555697\n",
      "\tspeed: 0.0360s/iter; left time: 469.7361s\n",
      "\titers: 200, epoch: 42 | loss: 0.0517087\n",
      "\tspeed: 0.0169s/iter; left time: 218.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0533487 Vali Loss: 0.0528054 Test Loss: 0.0599857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0567743\n",
      "\tspeed: 0.0369s/iter; left time: 473.1286s\n",
      "\titers: 200, epoch: 43 | loss: 0.0543428\n",
      "\tspeed: 0.0183s/iter; left time: 232.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0533792 Vali Loss: 0.0527863 Test Loss: 0.0598556\n",
      "Validation loss decreased (0.052802 --> 0.052786).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0514207\n",
      "\tspeed: 0.0358s/iter; left time: 452.0903s\n",
      "\titers: 200, epoch: 44 | loss: 0.0540226\n",
      "\tspeed: 0.0176s/iter; left time: 219.9999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0533138 Vali Loss: 0.0528640 Test Loss: 0.0598857\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0554004\n",
      "\tspeed: 0.0380s/iter; left time: 470.3482s\n",
      "\titers: 200, epoch: 45 | loss: 0.0548455\n",
      "\tspeed: 0.0169s/iter; left time: 207.3066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0533171 Vali Loss: 0.0528222 Test Loss: 0.0598525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0528835\n",
      "\tspeed: 0.0326s/iter; left time: 396.2211s\n",
      "\titers: 200, epoch: 46 | loss: 0.0566729\n",
      "\tspeed: 0.0173s/iter; left time: 208.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0532889 Vali Loss: 0.0528414 Test Loss: 0.0598576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528474\n",
      "\tspeed: 0.0418s/iter; left time: 498.8467s\n",
      "\titers: 200, epoch: 47 | loss: 0.0537862\n",
      "\tspeed: 0.0203s/iter; left time: 240.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0533096 Vali Loss: 0.0528519 Test Loss: 0.0599552\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0510302\n",
      "\tspeed: 0.0410s/iter; left time: 480.9647s\n",
      "\titers: 200, epoch: 48 | loss: 0.0522373\n",
      "\tspeed: 0.0178s/iter; left time: 206.8532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0533109 Vali Loss: 0.0527700 Test Loss: 0.0598513\n",
      "Validation loss decreased (0.052786 --> 0.052770).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0523930\n",
      "\tspeed: 0.0371s/iter; left time: 426.2014s\n",
      "\titers: 200, epoch: 49 | loss: 0.0514444\n",
      "\tspeed: 0.0175s/iter; left time: 199.8878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0533779 Vali Loss: 0.0528197 Test Loss: 0.0598431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0518146\n",
      "\tspeed: 0.0360s/iter; left time: 405.5742s\n",
      "\titers: 200, epoch: 50 | loss: 0.0508468\n",
      "\tspeed: 0.0166s/iter; left time: 185.5697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0532561 Vali Loss: 0.0527520 Test Loss: 0.0598477\n",
      "Validation loss decreased (0.052770 --> 0.052752).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0552119\n",
      "\tspeed: 0.0392s/iter; left time: 433.5727s\n",
      "\titers: 200, epoch: 51 | loss: 0.0513284\n",
      "\tspeed: 0.0173s/iter; left time: 189.6797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0533002 Vali Loss: 0.0528053 Test Loss: 0.0598766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0502459\n",
      "\tspeed: 0.0436s/iter; left time: 472.2388s\n",
      "\titers: 200, epoch: 52 | loss: 0.0507049\n",
      "\tspeed: 0.0216s/iter; left time: 231.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0532786 Vali Loss: 0.0528084 Test Loss: 0.0598998\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531949\n",
      "\tspeed: 0.0399s/iter; left time: 423.1756s\n",
      "\titers: 200, epoch: 53 | loss: 0.0523739\n",
      "\tspeed: 0.0161s/iter; left time: 168.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0532865 Vali Loss: 0.0528019 Test Loss: 0.0598628\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0565997\n",
      "\tspeed: 0.0379s/iter; left time: 393.8639s\n",
      "\titers: 200, epoch: 54 | loss: 0.0515698\n",
      "\tspeed: 0.0207s/iter; left time: 212.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0533134 Vali Loss: 0.0527626 Test Loss: 0.0598642\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0497599\n",
      "\tspeed: 0.0391s/iter; left time: 397.2466s\n",
      "\titers: 200, epoch: 55 | loss: 0.0521798\n",
      "\tspeed: 0.0183s/iter; left time: 184.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0532548 Vali Loss: 0.0527978 Test Loss: 0.0598765\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0563315\n",
      "\tspeed: 0.0369s/iter; left time: 366.1472s\n",
      "\titers: 200, epoch: 56 | loss: 0.0558246\n",
      "\tspeed: 0.0187s/iter; left time: 183.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0532699 Vali Loss: 0.0527844 Test Loss: 0.0598873\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0504109\n",
      "\tspeed: 0.0380s/iter; left time: 369.2541s\n",
      "\titers: 200, epoch: 57 | loss: 0.0524185\n",
      "\tspeed: 0.0183s/iter; left time: 175.7682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0532714 Vali Loss: 0.0527749 Test Loss: 0.0599248\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0561023\n",
      "\tspeed: 0.0408s/iter; left time: 387.1680s\n",
      "\titers: 200, epoch: 58 | loss: 0.0551928\n",
      "\tspeed: 0.0191s/iter; left time: 178.9339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0532676 Vali Loss: 0.0528307 Test Loss: 0.0598583\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0531481\n",
      "\tspeed: 0.0396s/iter; left time: 366.8374s\n",
      "\titers: 200, epoch: 59 | loss: 0.0528730\n",
      "\tspeed: 0.0185s/iter; left time: 169.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0533142 Vali Loss: 0.0528002 Test Loss: 0.0599143\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0531018\n",
      "\tspeed: 0.0323s/iter; left time: 292.3500s\n",
      "\titers: 200, epoch: 60 | loss: 0.0488852\n",
      "\tspeed: 0.0161s/iter; left time: 143.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.0532967 Vali Loss: 0.0527826 Test Loss: 0.0598348\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009835402481257915, rmse:0.09917359799146652, mae:0.059847697615623474, rse:0.29185590147972107\n",
      "Intermediate time for ES and pred_len 24: 00h:12m:40.54s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1385792\n",
      "\tspeed: 0.0418s/iter; left time: 922.8227s\n",
      "\titers: 200, epoch: 1 | loss: 0.1182649\n",
      "\tspeed: 0.0138s/iter; left time: 304.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 222 | Train Loss: 0.1422816 Vali Loss: 0.1110743 Test Loss: 0.1262151\n",
      "Validation loss decreased (inf --> 0.111074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0940955\n",
      "\tspeed: 0.0361s/iter; left time: 789.8993s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868063\n",
      "\tspeed: 0.0179s/iter; left time: 388.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0947397 Vali Loss: 0.0840065 Test Loss: 0.0971727\n",
      "Validation loss decreased (0.111074 --> 0.084007).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819319\n",
      "\tspeed: 0.0339s/iter; left time: 733.2520s\n",
      "\titers: 200, epoch: 3 | loss: 0.0813856\n",
      "\tspeed: 0.0139s/iter; left time: 299.1397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 222 | Train Loss: 0.0850253 Vali Loss: 0.0804326 Test Loss: 0.0922306\n",
      "Validation loss decreased (0.084007 --> 0.080433).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853557\n",
      "\tspeed: 0.0385s/iter; left time: 825.4243s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803397\n",
      "\tspeed: 0.0190s/iter; left time: 405.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0820097 Vali Loss: 0.0790990 Test Loss: 0.0901591\n",
      "Validation loss decreased (0.080433 --> 0.079099).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773442\n",
      "\tspeed: 0.0364s/iter; left time: 771.2434s\n",
      "\titers: 200, epoch: 5 | loss: 0.0794379\n",
      "\tspeed: 0.0163s/iter; left time: 344.2450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0802541 Vali Loss: 0.0779930 Test Loss: 0.0893422\n",
      "Validation loss decreased (0.079099 --> 0.077993).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0801928\n",
      "\tspeed: 0.0372s/iter; left time: 780.8804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0775122\n",
      "\tspeed: 0.0145s/iter; left time: 302.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0790663 Vali Loss: 0.0773713 Test Loss: 0.0885687\n",
      "Validation loss decreased (0.077993 --> 0.077371).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0827232\n",
      "\tspeed: 0.0374s/iter; left time: 777.2461s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769958\n",
      "\tspeed: 0.0178s/iter; left time: 367.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0780358 Vali Loss: 0.0768461 Test Loss: 0.0886996\n",
      "Validation loss decreased (0.077371 --> 0.076846).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803140\n",
      "\tspeed: 0.0429s/iter; left time: 881.9475s\n",
      "\titers: 200, epoch: 8 | loss: 0.0835532\n",
      "\tspeed: 0.0182s/iter; left time: 372.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0773143 Vali Loss: 0.0767974 Test Loss: 0.0883062\n",
      "Validation loss decreased (0.076846 --> 0.076797).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758626\n",
      "\tspeed: 0.0372s/iter; left time: 755.4763s\n",
      "\titers: 200, epoch: 9 | loss: 0.0754276\n",
      "\tspeed: 0.0168s/iter; left time: 340.7860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0766813 Vali Loss: 0.0761630 Test Loss: 0.0879551\n",
      "Validation loss decreased (0.076797 --> 0.076163).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0774494\n",
      "\tspeed: 0.0390s/iter; left time: 784.1279s\n",
      "\titers: 200, epoch: 10 | loss: 0.0764233\n",
      "\tspeed: 0.0171s/iter; left time: 341.2613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0761750 Vali Loss: 0.0761160 Test Loss: 0.0880627\n",
      "Validation loss decreased (0.076163 --> 0.076116).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761549\n",
      "\tspeed: 0.0404s/iter; left time: 802.9580s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758734\n",
      "\tspeed: 0.0198s/iter; left time: 391.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0756397 Vali Loss: 0.0764169 Test Loss: 0.0880045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733976\n",
      "\tspeed: 0.0403s/iter; left time: 792.8424s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740174\n",
      "\tspeed: 0.0210s/iter; left time: 411.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0751572 Vali Loss: 0.0763195 Test Loss: 0.0878364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0753438\n",
      "\tspeed: 0.0393s/iter; left time: 763.7671s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696612\n",
      "\tspeed: 0.0168s/iter; left time: 324.3294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0747899 Vali Loss: 0.0761209 Test Loss: 0.0876478\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0717187\n",
      "\tspeed: 0.0377s/iter; left time: 724.9368s\n",
      "\titers: 200, epoch: 14 | loss: 0.0775156\n",
      "\tspeed: 0.0176s/iter; left time: 336.9017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0744144 Vali Loss: 0.0762893 Test Loss: 0.0880117\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0762417\n",
      "\tspeed: 0.0408s/iter; left time: 774.2272s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766109\n",
      "\tspeed: 0.0186s/iter; left time: 351.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0741577 Vali Loss: 0.0764239 Test Loss: 0.0877684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0722115\n",
      "\tspeed: 0.0369s/iter; left time: 691.7749s\n",
      "\titers: 200, epoch: 16 | loss: 0.0734648\n",
      "\tspeed: 0.0183s/iter; left time: 341.1600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0738055 Vali Loss: 0.0765991 Test Loss: 0.0878521\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0731867\n",
      "\tspeed: 0.0368s/iter; left time: 682.2852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715154\n",
      "\tspeed: 0.0180s/iter; left time: 331.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0735952 Vali Loss: 0.0766645 Test Loss: 0.0880254\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720490\n",
      "\tspeed: 0.0409s/iter; left time: 749.7457s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710261\n",
      "\tspeed: 0.0198s/iter; left time: 361.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0733917 Vali Loss: 0.0765840 Test Loss: 0.0879875\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720148\n",
      "\tspeed: 0.0399s/iter; left time: 722.5319s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727974\n",
      "\tspeed: 0.0182s/iter; left time: 328.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0731387 Vali Loss: 0.0767742 Test Loss: 0.0878816\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0704931\n",
      "\tspeed: 0.0355s/iter; left time: 634.0286s\n",
      "\titers: 200, epoch: 20 | loss: 0.0714912\n",
      "\tspeed: 0.0180s/iter; left time: 319.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0729367 Vali Loss: 0.0769131 Test Loss: 0.0881956\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018609222024679184, rmse:0.13641561567783356, mae:0.08806268125772476, rse:0.40074804425239563\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1396330\n",
      "\tspeed: 0.0216s/iter; left time: 476.9372s\n",
      "\titers: 200, epoch: 1 | loss: 0.1213302\n",
      "\tspeed: 0.0181s/iter; left time: 398.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.1457219 Vali Loss: 0.1121407 Test Loss: 0.1275937\n",
      "Validation loss decreased (inf --> 0.112141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0912201\n",
      "\tspeed: 0.0426s/iter; left time: 932.1851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0882925\n",
      "\tspeed: 0.0220s/iter; left time: 478.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0949045 Vali Loss: 0.0846372 Test Loss: 0.0970425\n",
      "Validation loss decreased (0.112141 --> 0.084637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829771\n",
      "\tspeed: 0.0374s/iter; left time: 810.8109s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822514\n",
      "\tspeed: 0.0139s/iter; left time: 300.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 222 | Train Loss: 0.0852785 Vali Loss: 0.0806705 Test Loss: 0.0927752\n",
      "Validation loss decreased (0.084637 --> 0.080670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0812255\n",
      "\tspeed: 0.0395s/iter; left time: 845.8137s\n",
      "\titers: 200, epoch: 4 | loss: 0.0798196\n",
      "\tspeed: 0.0206s/iter; left time: 439.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0822354 Vali Loss: 0.0790638 Test Loss: 0.0905020\n",
      "Validation loss decreased (0.080670 --> 0.079064).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827816\n",
      "\tspeed: 0.0400s/iter; left time: 848.0679s\n",
      "\titers: 200, epoch: 5 | loss: 0.0786814\n",
      "\tspeed: 0.0195s/iter; left time: 410.9834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0803928 Vali Loss: 0.0774791 Test Loss: 0.0898778\n",
      "Validation loss decreased (0.079064 --> 0.077479).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0819603\n",
      "\tspeed: 0.0436s/iter; left time: 915.7001s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820871\n",
      "\tspeed: 0.0224s/iter; left time: 467.2814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 222 | Train Loss: 0.0791081 Vali Loss: 0.0770491 Test Loss: 0.0889440\n",
      "Validation loss decreased (0.077479 --> 0.077049).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787272\n",
      "\tspeed: 0.0412s/iter; left time: 855.7896s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773578\n",
      "\tspeed: 0.0188s/iter; left time: 387.7701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0780979 Vali Loss: 0.0765015 Test Loss: 0.0891745\n",
      "Validation loss decreased (0.077049 --> 0.076502).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781270\n",
      "\tspeed: 0.0425s/iter; left time: 872.3538s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740148\n",
      "\tspeed: 0.0202s/iter; left time: 413.8971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0774201 Vali Loss: 0.0763370 Test Loss: 0.0887460\n",
      "Validation loss decreased (0.076502 --> 0.076337).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0750064\n",
      "\tspeed: 0.0416s/iter; left time: 844.9036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0765117\n",
      "\tspeed: 0.0152s/iter; left time: 307.9165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0766232 Vali Loss: 0.0761677 Test Loss: 0.0883636\n",
      "Validation loss decreased (0.076337 --> 0.076168).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763836\n",
      "\tspeed: 0.0389s/iter; left time: 782.3702s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785546\n",
      "\tspeed: 0.0160s/iter; left time: 320.0337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0759909 Vali Loss: 0.0761631 Test Loss: 0.0884192\n",
      "Validation loss decreased (0.076168 --> 0.076163).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733672\n",
      "\tspeed: 0.0400s/iter; left time: 794.3536s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749607\n",
      "\tspeed: 0.0173s/iter; left time: 341.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0755088 Vali Loss: 0.0759973 Test Loss: 0.0885333\n",
      "Validation loss decreased (0.076163 --> 0.075997).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752866\n",
      "\tspeed: 0.0381s/iter; left time: 748.2066s\n",
      "\titers: 200, epoch: 12 | loss: 0.0750062\n",
      "\tspeed: 0.0173s/iter; left time: 338.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0750073 Vali Loss: 0.0764667 Test Loss: 0.0888668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0768752\n",
      "\tspeed: 0.0392s/iter; left time: 761.3544s\n",
      "\titers: 200, epoch: 13 | loss: 0.0734315\n",
      "\tspeed: 0.0193s/iter; left time: 372.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0745932 Vali Loss: 0.0767907 Test Loss: 0.0889507\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0741726\n",
      "\tspeed: 0.0429s/iter; left time: 824.0659s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754283\n",
      "\tspeed: 0.0195s/iter; left time: 373.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0742355 Vali Loss: 0.0759581 Test Loss: 0.0885926\n",
      "Validation loss decreased (0.075997 --> 0.075958).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0735364\n",
      "\tspeed: 0.0416s/iter; left time: 789.7698s\n",
      "\titers: 200, epoch: 15 | loss: 0.0741121\n",
      "\tspeed: 0.0177s/iter; left time: 333.5168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0738368 Vali Loss: 0.0766400 Test Loss: 0.0887072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707955\n",
      "\tspeed: 0.0344s/iter; left time: 644.8644s\n",
      "\titers: 200, epoch: 16 | loss: 0.0723389\n",
      "\tspeed: 0.0144s/iter; left time: 269.0419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 222 | Train Loss: 0.0735910 Vali Loss: 0.0766705 Test Loss: 0.0885460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0771165\n",
      "\tspeed: 0.0417s/iter; left time: 773.0594s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713694\n",
      "\tspeed: 0.0187s/iter; left time: 344.5441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0732946 Vali Loss: 0.0768329 Test Loss: 0.0886512\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0734466\n",
      "\tspeed: 0.0375s/iter; left time: 686.6494s\n",
      "\titers: 200, epoch: 18 | loss: 0.0739590\n",
      "\tspeed: 0.0167s/iter; left time: 304.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0730735 Vali Loss: 0.0767900 Test Loss: 0.0886660\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0715153\n",
      "\tspeed: 0.0380s/iter; left time: 687.5398s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727631\n",
      "\tspeed: 0.0174s/iter; left time: 313.5253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0728860 Vali Loss: 0.0768873 Test Loss: 0.0887517\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720705\n",
      "\tspeed: 0.0378s/iter; left time: 675.2212s\n",
      "\titers: 200, epoch: 20 | loss: 0.0705768\n",
      "\tspeed: 0.0201s/iter; left time: 357.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0727090 Vali Loss: 0.0771412 Test Loss: 0.0886753\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0741459\n",
      "\tspeed: 0.0403s/iter; left time: 711.2318s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731180\n",
      "\tspeed: 0.0214s/iter; left time: 375.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0724857 Vali Loss: 0.0769636 Test Loss: 0.0889456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695235\n",
      "\tspeed: 0.0415s/iter; left time: 723.8892s\n",
      "\titers: 200, epoch: 22 | loss: 0.0769061\n",
      "\tspeed: 0.0204s/iter; left time: 352.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0723888 Vali Loss: 0.0770241 Test Loss: 0.0888251\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0714454\n",
      "\tspeed: 0.0425s/iter; left time: 731.9328s\n",
      "\titers: 200, epoch: 23 | loss: 0.0772988\n",
      "\tspeed: 0.0201s/iter; left time: 344.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0722007 Vali Loss: 0.0771746 Test Loss: 0.0889443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0717129\n",
      "\tspeed: 0.0413s/iter; left time: 702.3744s\n",
      "\titers: 200, epoch: 24 | loss: 0.0700341\n",
      "\tspeed: 0.0202s/iter; left time: 341.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0721136 Vali Loss: 0.0771229 Test Loss: 0.0888303\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019223757088184357, rmse:0.13864976167678833, mae:0.08859264105558395, rse:0.40731126070022583\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:24.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1419178\n",
      "\tspeed: 0.0396s/iter; left time: 875.2158s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218042\n",
      "\tspeed: 0.0159s/iter; left time: 350.3600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.1460080 Vali Loss: 0.1142403 Test Loss: 0.1288312\n",
      "Validation loss decreased (inf --> 0.114240).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938460\n",
      "\tspeed: 0.0375s/iter; left time: 819.4252s\n",
      "\titers: 200, epoch: 2 | loss: 0.0907256\n",
      "\tspeed: 0.0185s/iter; left time: 402.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0986767 Vali Loss: 0.0892960 Test Loss: 0.1027659\n",
      "Validation loss decreased (0.114240 --> 0.089296).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890074\n",
      "\tspeed: 0.0336s/iter; left time: 727.0533s\n",
      "\titers: 200, epoch: 3 | loss: 0.0864204\n",
      "\tspeed: 0.0138s/iter; left time: 297.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 222 | Train Loss: 0.0898288 Vali Loss: 0.0860181 Test Loss: 0.0980162\n",
      "Validation loss decreased (0.089296 --> 0.086018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0850793\n",
      "\tspeed: 0.0347s/iter; left time: 743.6516s\n",
      "\titers: 200, epoch: 4 | loss: 0.0855337\n",
      "\tspeed: 0.0141s/iter; left time: 299.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 222 | Train Loss: 0.0868986 Vali Loss: 0.0842173 Test Loss: 0.0959453\n",
      "Validation loss decreased (0.086018 --> 0.084217).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884514\n",
      "\tspeed: 0.0373s/iter; left time: 792.0828s\n",
      "\titers: 200, epoch: 5 | loss: 0.0869118\n",
      "\tspeed: 0.0192s/iter; left time: 405.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0849935 Vali Loss: 0.0835914 Test Loss: 0.0956317\n",
      "Validation loss decreased (0.084217 --> 0.083591).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844436\n",
      "\tspeed: 0.0348s/iter; left time: 730.3185s\n",
      "\titers: 200, epoch: 6 | loss: 0.0804927\n",
      "\tspeed: 0.0138s/iter; left time: 287.8540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 222 | Train Loss: 0.0835954 Vali Loss: 0.0831221 Test Loss: 0.0951930\n",
      "Validation loss decreased (0.083591 --> 0.083122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0848672\n",
      "\tspeed: 0.0372s/iter; left time: 772.7626s\n",
      "\titers: 200, epoch: 7 | loss: 0.0833731\n",
      "\tspeed: 0.0138s/iter; left time: 284.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0825271 Vali Loss: 0.0834027 Test Loss: 0.0949781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816349\n",
      "\tspeed: 0.0416s/iter; left time: 855.4585s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795291\n",
      "\tspeed: 0.0190s/iter; left time: 388.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0816343 Vali Loss: 0.0834496 Test Loss: 0.0943506\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0801985\n",
      "\tspeed: 0.0353s/iter; left time: 718.0532s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789727\n",
      "\tspeed: 0.0175s/iter; left time: 353.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0808285 Vali Loss: 0.0832434 Test Loss: 0.0948098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0789460\n",
      "\tspeed: 0.0408s/iter; left time: 820.7057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0793623\n",
      "\tspeed: 0.0180s/iter; left time: 360.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0801699 Vali Loss: 0.0840384 Test Loss: 0.0950431\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782779\n",
      "\tspeed: 0.0372s/iter; left time: 739.3944s\n",
      "\titers: 200, epoch: 11 | loss: 0.0744008\n",
      "\tspeed: 0.0175s/iter; left time: 345.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0795492 Vali Loss: 0.0839513 Test Loss: 0.0948496\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0824304\n",
      "\tspeed: 0.0394s/iter; left time: 775.1753s\n",
      "\titers: 200, epoch: 12 | loss: 0.0820806\n",
      "\tspeed: 0.0143s/iter; left time: 279.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0790670 Vali Loss: 0.0842792 Test Loss: 0.0945874\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767531\n",
      "\tspeed: 0.0337s/iter; left time: 654.5744s\n",
      "\titers: 200, epoch: 13 | loss: 0.0758726\n",
      "\tspeed: 0.0165s/iter; left time: 319.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0786045 Vali Loss: 0.0837859 Test Loss: 0.0941948\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0780526\n",
      "\tspeed: 0.0385s/iter; left time: 740.2574s\n",
      "\titers: 200, epoch: 14 | loss: 0.0802356\n",
      "\tspeed: 0.0222s/iter; left time: 424.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0782086 Vali Loss: 0.0844041 Test Loss: 0.0945527\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0777676\n",
      "\tspeed: 0.0385s/iter; left time: 731.2037s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769631\n",
      "\tspeed: 0.0199s/iter; left time: 376.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0778722 Vali Loss: 0.0846492 Test Loss: 0.0945489\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0792369\n",
      "\tspeed: 0.0378s/iter; left time: 708.8383s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751409\n",
      "\tspeed: 0.0187s/iter; left time: 349.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0775368 Vali Loss: 0.0848033 Test Loss: 0.0944460\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021050771698355675, rmse:0.14508883655071259, mae:0.09519297629594803, rse:0.4262579679489136\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1491076\n",
      "\tspeed: 0.0205s/iter; left time: 454.0339s\n",
      "\titers: 200, epoch: 1 | loss: 0.1225820\n",
      "\tspeed: 0.0179s/iter; left time: 393.3760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.1508209 Vali Loss: 0.1170672 Test Loss: 0.1316793\n",
      "Validation loss decreased (inf --> 0.117067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0952042\n",
      "\tspeed: 0.0446s/iter; left time: 975.6663s\n",
      "\titers: 200, epoch: 2 | loss: 0.0908106\n",
      "\tspeed: 0.0225s/iter; left time: 490.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 222 | Train Loss: 0.0986042 Vali Loss: 0.0892380 Test Loss: 0.1026220\n",
      "Validation loss decreased (0.117067 --> 0.089238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899375\n",
      "\tspeed: 0.0419s/iter; left time: 906.8913s\n",
      "\titers: 200, epoch: 3 | loss: 0.0904875\n",
      "\tspeed: 0.0202s/iter; left time: 435.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0897521 Vali Loss: 0.0863482 Test Loss: 0.0983548\n",
      "Validation loss decreased (0.089238 --> 0.086348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870577\n",
      "\tspeed: 0.0460s/iter; left time: 985.7507s\n",
      "\titers: 200, epoch: 4 | loss: 0.0853903\n",
      "\tspeed: 0.0245s/iter; left time: 522.7826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 222 | Train Loss: 0.0868030 Vali Loss: 0.0842877 Test Loss: 0.0954756\n",
      "Validation loss decreased (0.086348 --> 0.084288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0837674\n",
      "\tspeed: 0.0394s/iter; left time: 835.9781s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848464\n",
      "\tspeed: 0.0188s/iter; left time: 397.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0848583 Vali Loss: 0.0836557 Test Loss: 0.0948262\n",
      "Validation loss decreased (0.084288 --> 0.083656).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0867948\n",
      "\tspeed: 0.0389s/iter; left time: 816.1829s\n",
      "\titers: 200, epoch: 6 | loss: 0.0840204\n",
      "\tspeed: 0.0187s/iter; left time: 390.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0834474 Vali Loss: 0.0831851 Test Loss: 0.0940405\n",
      "Validation loss decreased (0.083656 --> 0.083185).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0793353\n",
      "\tspeed: 0.0331s/iter; left time: 686.7118s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800309\n",
      "\tspeed: 0.0174s/iter; left time: 359.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.0823776 Vali Loss: 0.0827318 Test Loss: 0.0943198\n",
      "Validation loss decreased (0.083185 --> 0.082732).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0851633\n",
      "\tspeed: 0.0336s/iter; left time: 689.9811s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797006\n",
      "\tspeed: 0.0181s/iter; left time: 369.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.0816098 Vali Loss: 0.0830750 Test Loss: 0.0943304\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820580\n",
      "\tspeed: 0.0392s/iter; left time: 797.6888s\n",
      "\titers: 200, epoch: 9 | loss: 0.0822506\n",
      "\tspeed: 0.0186s/iter; left time: 375.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0808132 Vali Loss: 0.0834377 Test Loss: 0.0944934\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811251\n",
      "\tspeed: 0.0407s/iter; left time: 817.9082s\n",
      "\titers: 200, epoch: 10 | loss: 0.0813748\n",
      "\tspeed: 0.0237s/iter; left time: 474.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.0802260 Vali Loss: 0.0836181 Test Loss: 0.0951462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0820613\n",
      "\tspeed: 0.0420s/iter; left time: 834.5513s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791761\n",
      "\tspeed: 0.0186s/iter; left time: 367.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0796129 Vali Loss: 0.0840106 Test Loss: 0.0947623\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0797480\n",
      "\tspeed: 0.0398s/iter; left time: 782.8128s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788590\n",
      "\tspeed: 0.0219s/iter; left time: 428.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0791221 Vali Loss: 0.0840702 Test Loss: 0.0949853\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0780291\n",
      "\tspeed: 0.0373s/iter; left time: 725.8537s\n",
      "\titers: 200, epoch: 13 | loss: 0.0762511\n",
      "\tspeed: 0.0189s/iter; left time: 366.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0786572 Vali Loss: 0.0839808 Test Loss: 0.0949025\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0789614\n",
      "\tspeed: 0.0454s/iter; left time: 871.6980s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800479\n",
      "\tspeed: 0.0222s/iter; left time: 424.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 222 | Train Loss: 0.0781925 Vali Loss: 0.0845038 Test Loss: 0.0951699\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766873\n",
      "\tspeed: 0.0340s/iter; left time: 645.1569s\n",
      "\titers: 200, epoch: 15 | loss: 0.0790221\n",
      "\tspeed: 0.0138s/iter; left time: 261.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 222 | Train Loss: 0.0777871 Vali Loss: 0.0847439 Test Loss: 0.0950600\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736712\n",
      "\tspeed: 0.0399s/iter; left time: 749.1985s\n",
      "\titers: 200, epoch: 16 | loss: 0.0767810\n",
      "\tspeed: 0.0206s/iter; left time: 384.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0774590 Vali Loss: 0.0845887 Test Loss: 0.0954648\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0769775\n",
      "\tspeed: 0.0400s/iter; left time: 741.7888s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766874\n",
      "\tspeed: 0.0229s/iter; left time: 421.6608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0771319 Vali Loss: 0.0846804 Test Loss: 0.0948352\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02092847041785717, rmse:0.14466676115989685, mae:0.09431979805231094, rse:0.4250178933143616\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:19.57s\n",
      "Intermediate time for ES: 00h:20m:24.99s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0972968\n",
      "\tspeed: 0.0423s/iter; left time: 938.6695s\n",
      "\titers: 200, epoch: 1 | loss: 0.0835901\n",
      "\tspeed: 0.0142s/iter; left time: 314.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.1023422 Vali Loss: 0.0872367 Test Loss: 0.0961149\n",
      "Validation loss decreased (inf --> 0.087237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0555479\n",
      "\tspeed: 0.0415s/iter; left time: 912.0892s\n",
      "\titers: 200, epoch: 2 | loss: 0.0535272\n",
      "\tspeed: 0.0206s/iter; left time: 450.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0578725 Vali Loss: 0.0586904 Test Loss: 0.0620993\n",
      "Validation loss decreased (0.087237 --> 0.058690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0467731\n",
      "\tspeed: 0.0351s/iter; left time: 763.2353s\n",
      "\titers: 200, epoch: 3 | loss: 0.0513020\n",
      "\tspeed: 0.0163s/iter; left time: 353.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0498668 Vali Loss: 0.0565236 Test Loss: 0.0599087\n",
      "Validation loss decreased (0.058690 --> 0.056524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0484350\n",
      "\tspeed: 0.0338s/iter; left time: 727.6181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0484511\n",
      "\tspeed: 0.0136s/iter; left time: 291.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 223 | Train Loss: 0.0479381 Vali Loss: 0.0553647 Test Loss: 0.0584692\n",
      "Validation loss decreased (0.056524 --> 0.055365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461941\n",
      "\tspeed: 0.0341s/iter; left time: 725.9355s\n",
      "\titers: 200, epoch: 5 | loss: 0.0454064\n",
      "\tspeed: 0.0175s/iter; left time: 371.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0466679 Vali Loss: 0.0544165 Test Loss: 0.0576759\n",
      "Validation loss decreased (0.055365 --> 0.054416).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0474706\n",
      "\tspeed: 0.0346s/iter; left time: 729.5295s\n",
      "\titers: 200, epoch: 6 | loss: 0.0420185\n",
      "\tspeed: 0.0169s/iter; left time: 355.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0456721 Vali Loss: 0.0539492 Test Loss: 0.0574161\n",
      "Validation loss decreased (0.054416 --> 0.053949).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0447662\n",
      "\tspeed: 0.0360s/iter; left time: 751.4698s\n",
      "\titers: 200, epoch: 7 | loss: 0.0476614\n",
      "\tspeed: 0.0134s/iter; left time: 277.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.0449843 Vali Loss: 0.0533046 Test Loss: 0.0570047\n",
      "Validation loss decreased (0.053949 --> 0.053305).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0463143\n",
      "\tspeed: 0.0342s/iter; left time: 705.0140s\n",
      "\titers: 200, epoch: 8 | loss: 0.0445193\n",
      "\tspeed: 0.0172s/iter; left time: 353.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0444156 Vali Loss: 0.0529553 Test Loss: 0.0569518\n",
      "Validation loss decreased (0.053305 --> 0.052955).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0473611\n",
      "\tspeed: 0.0444s/iter; left time: 906.3784s\n",
      "\titers: 200, epoch: 9 | loss: 0.0446129\n",
      "\tspeed: 0.0177s/iter; left time: 360.5538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0440040 Vali Loss: 0.0528103 Test Loss: 0.0568375\n",
      "Validation loss decreased (0.052955 --> 0.052810).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0421216\n",
      "\tspeed: 0.0332s/iter; left time: 671.2149s\n",
      "\titers: 200, epoch: 10 | loss: 0.0406660\n",
      "\tspeed: 0.0139s/iter; left time: 279.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 223 | Train Loss: 0.0436476 Vali Loss: 0.0526095 Test Loss: 0.0562941\n",
      "Validation loss decreased (0.052810 --> 0.052610).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0413142\n",
      "\tspeed: 0.0312s/iter; left time: 623.4211s\n",
      "\titers: 200, epoch: 11 | loss: 0.0460138\n",
      "\tspeed: 0.0149s/iter; left time: 295.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0433556 Vali Loss: 0.0524401 Test Loss: 0.0561836\n",
      "Validation loss decreased (0.052610 --> 0.052440).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0412763\n",
      "\tspeed: 0.0367s/iter; left time: 724.9779s\n",
      "\titers: 200, epoch: 12 | loss: 0.0437591\n",
      "\tspeed: 0.0172s/iter; left time: 337.2368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0430420 Vali Loss: 0.0522945 Test Loss: 0.0564056\n",
      "Validation loss decreased (0.052440 --> 0.052295).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0469876\n",
      "\tspeed: 0.0365s/iter; left time: 712.1354s\n",
      "\titers: 200, epoch: 13 | loss: 0.0400449\n",
      "\tspeed: 0.0184s/iter; left time: 357.4796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0428177 Vali Loss: 0.0523434 Test Loss: 0.0562297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0439443\n",
      "\tspeed: 0.0343s/iter; left time: 662.3098s\n",
      "\titers: 200, epoch: 14 | loss: 0.0439977\n",
      "\tspeed: 0.0171s/iter; left time: 328.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0426225 Vali Loss: 0.0519527 Test Loss: 0.0560063\n",
      "Validation loss decreased (0.052295 --> 0.051953).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0402205\n",
      "\tspeed: 0.0361s/iter; left time: 689.5136s\n",
      "\titers: 200, epoch: 15 | loss: 0.0391533\n",
      "\tspeed: 0.0171s/iter; left time: 323.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0424658 Vali Loss: 0.0520548 Test Loss: 0.0562132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0441784\n",
      "\tspeed: 0.0412s/iter; left time: 777.1789s\n",
      "\titers: 200, epoch: 16 | loss: 0.0396394\n",
      "\tspeed: 0.0202s/iter; left time: 379.1514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0423164 Vali Loss: 0.0519706 Test Loss: 0.0558837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0432056\n",
      "\tspeed: 0.0370s/iter; left time: 688.6955s\n",
      "\titers: 200, epoch: 17 | loss: 0.0391308\n",
      "\tspeed: 0.0179s/iter; left time: 331.3294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0421640 Vali Loss: 0.0517851 Test Loss: 0.0558091\n",
      "Validation loss decreased (0.051953 --> 0.051785).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0432721\n",
      "\tspeed: 0.0379s/iter; left time: 698.4477s\n",
      "\titers: 200, epoch: 18 | loss: 0.0407191\n",
      "\tspeed: 0.0170s/iter; left time: 310.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0420739 Vali Loss: 0.0517640 Test Loss: 0.0557817\n",
      "Validation loss decreased (0.051785 --> 0.051764).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458490\n",
      "\tspeed: 0.0396s/iter; left time: 720.0762s\n",
      "\titers: 200, epoch: 19 | loss: 0.0409154\n",
      "\tspeed: 0.0228s/iter; left time: 411.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0420063 Vali Loss: 0.0516544 Test Loss: 0.0558792\n",
      "Validation loss decreased (0.051764 --> 0.051654).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0403619\n",
      "\tspeed: 0.0409s/iter; left time: 735.4134s\n",
      "\titers: 200, epoch: 20 | loss: 0.0397678\n",
      "\tspeed: 0.0194s/iter; left time: 346.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0418462 Vali Loss: 0.0515542 Test Loss: 0.0557899\n",
      "Validation loss decreased (0.051654 --> 0.051554).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0427584\n",
      "\tspeed: 0.0410s/iter; left time: 727.3959s\n",
      "\titers: 200, epoch: 21 | loss: 0.0409719\n",
      "\tspeed: 0.0211s/iter; left time: 372.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0418080 Vali Loss: 0.0515218 Test Loss: 0.0558280\n",
      "Validation loss decreased (0.051554 --> 0.051522).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0440947\n",
      "\tspeed: 0.0419s/iter; left time: 733.6697s\n",
      "\titers: 200, epoch: 22 | loss: 0.0412953\n",
      "\tspeed: 0.0198s/iter; left time: 344.3614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0416895 Vali Loss: 0.0514271 Test Loss: 0.0559200\n",
      "Validation loss decreased (0.051522 --> 0.051427).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0432241\n",
      "\tspeed: 0.0385s/iter; left time: 666.1189s\n",
      "\titers: 200, epoch: 23 | loss: 0.0398869\n",
      "\tspeed: 0.0209s/iter; left time: 358.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0416161 Vali Loss: 0.0515037 Test Loss: 0.0557439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0416468\n",
      "\tspeed: 0.0368s/iter; left time: 628.9009s\n",
      "\titers: 200, epoch: 24 | loss: 0.0433521\n",
      "\tspeed: 0.0188s/iter; left time: 318.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0415637 Vali Loss: 0.0514572 Test Loss: 0.0557153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0402204\n",
      "\tspeed: 0.0358s/iter; left time: 602.8087s\n",
      "\titers: 200, epoch: 25 | loss: 0.0420431\n",
      "\tspeed: 0.0183s/iter; left time: 307.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0415263 Vali Loss: 0.0512957 Test Loss: 0.0557569\n",
      "Validation loss decreased (0.051427 --> 0.051296).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0432566\n",
      "\tspeed: 0.0380s/iter; left time: 631.5691s\n",
      "\titers: 200, epoch: 26 | loss: 0.0413730\n",
      "\tspeed: 0.0194s/iter; left time: 321.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0414606 Vali Loss: 0.0513362 Test Loss: 0.0555813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0396581\n",
      "\tspeed: 0.0360s/iter; left time: 590.9477s\n",
      "\titers: 200, epoch: 27 | loss: 0.0430993\n",
      "\tspeed: 0.0167s/iter; left time: 272.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0414404 Vali Loss: 0.0513440 Test Loss: 0.0555508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0396969\n",
      "\tspeed: 0.0347s/iter; left time: 561.8847s\n",
      "\titers: 200, epoch: 28 | loss: 0.0414456\n",
      "\tspeed: 0.0164s/iter; left time: 263.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0413930 Vali Loss: 0.0512838 Test Loss: 0.0555733\n",
      "Validation loss decreased (0.051296 --> 0.051284).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0379120\n",
      "\tspeed: 0.0400s/iter; left time: 638.7287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0430093\n",
      "\tspeed: 0.0188s/iter; left time: 298.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0413189 Vali Loss: 0.0512891 Test Loss: 0.0556797\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0396469\n",
      "\tspeed: 0.0395s/iter; left time: 622.1376s\n",
      "\titers: 200, epoch: 30 | loss: 0.0422378\n",
      "\tspeed: 0.0218s/iter; left time: 340.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0413511 Vali Loss: 0.0512911 Test Loss: 0.0555649\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0423966\n",
      "\tspeed: 0.0353s/iter; left time: 548.0724s\n",
      "\titers: 200, epoch: 31 | loss: 0.0426152\n",
      "\tspeed: 0.0159s/iter; left time: 245.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0412606 Vali Loss: 0.0512824 Test Loss: 0.0556308\n",
      "Validation loss decreased (0.051284 --> 0.051282).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0400357\n",
      "\tspeed: 0.0391s/iter; left time: 597.3586s\n",
      "\titers: 200, epoch: 32 | loss: 0.0430665\n",
      "\tspeed: 0.0190s/iter; left time: 289.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0412074 Vali Loss: 0.0512889 Test Loss: 0.0556499\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0403546\n",
      "\tspeed: 0.0359s/iter; left time: 540.1397s\n",
      "\titers: 200, epoch: 33 | loss: 0.0430244\n",
      "\tspeed: 0.0163s/iter; left time: 243.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0412333 Vali Loss: 0.0512238 Test Loss: 0.0556083\n",
      "Validation loss decreased (0.051282 --> 0.051224).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0421166\n",
      "\tspeed: 0.0360s/iter; left time: 534.3466s\n",
      "\titers: 200, epoch: 34 | loss: 0.0384824\n",
      "\tspeed: 0.0166s/iter; left time: 245.1082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0412096 Vali Loss: 0.0513099 Test Loss: 0.0555894\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0446529\n",
      "\tspeed: 0.0370s/iter; left time: 540.5066s\n",
      "\titers: 200, epoch: 35 | loss: 0.0403341\n",
      "\tspeed: 0.0164s/iter; left time: 237.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0411815 Vali Loss: 0.0512493 Test Loss: 0.0555889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0451221\n",
      "\tspeed: 0.0351s/iter; left time: 505.4825s\n",
      "\titers: 200, epoch: 36 | loss: 0.0403850\n",
      "\tspeed: 0.0163s/iter; left time: 233.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 223 | Train Loss: 0.0411741 Vali Loss: 0.0512079 Test Loss: 0.0555942\n",
      "Validation loss decreased (0.051224 --> 0.051208).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0445333\n",
      "\tspeed: 0.0372s/iter; left time: 527.0014s\n",
      "\titers: 200, epoch: 37 | loss: 0.0443588\n",
      "\tspeed: 0.0174s/iter; left time: 245.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0411521 Vali Loss: 0.0511658 Test Loss: 0.0555457\n",
      "Validation loss decreased (0.051208 --> 0.051166).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0385740\n",
      "\tspeed: 0.0329s/iter; left time: 458.8874s\n",
      "\titers: 200, epoch: 38 | loss: 0.0417012\n",
      "\tspeed: 0.0199s/iter; left time: 276.0491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0411606 Vali Loss: 0.0512327 Test Loss: 0.0555915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0420521\n",
      "\tspeed: 0.0426s/iter; left time: 585.1380s\n",
      "\titers: 200, epoch: 39 | loss: 0.0432682\n",
      "\tspeed: 0.0156s/iter; left time: 212.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0411222 Vali Loss: 0.0512164 Test Loss: 0.0556060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0433432\n",
      "\tspeed: 0.0390s/iter; left time: 526.9433s\n",
      "\titers: 200, epoch: 40 | loss: 0.0435472\n",
      "\tspeed: 0.0206s/iter; left time: 275.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0411435 Vali Loss: 0.0512553 Test Loss: 0.0555915\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0399226\n",
      "\tspeed: 0.0392s/iter; left time: 521.1291s\n",
      "\titers: 200, epoch: 41 | loss: 0.0396243\n",
      "\tspeed: 0.0198s/iter; left time: 261.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0411485 Vali Loss: 0.0512054 Test Loss: 0.0555794\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0409963\n",
      "\tspeed: 0.0355s/iter; left time: 463.7081s\n",
      "\titers: 200, epoch: 42 | loss: 0.0413123\n",
      "\tspeed: 0.0163s/iter; left time: 211.0321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0411111 Vali Loss: 0.0512560 Test Loss: 0.0555779\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0430647\n",
      "\tspeed: 0.0397s/iter; left time: 509.3844s\n",
      "\titers: 200, epoch: 43 | loss: 0.0385486\n",
      "\tspeed: 0.0205s/iter; left time: 261.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0411183 Vali Loss: 0.0511901 Test Loss: 0.0555540\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0421188\n",
      "\tspeed: 0.0371s/iter; left time: 467.7883s\n",
      "\titers: 200, epoch: 44 | loss: 0.0434327\n",
      "\tspeed: 0.0178s/iter; left time: 222.8071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0410857 Vali Loss: 0.0512272 Test Loss: 0.0555719\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0425756\n",
      "\tspeed: 0.0371s/iter; left time: 459.1065s\n",
      "\titers: 200, epoch: 45 | loss: 0.0415331\n",
      "\tspeed: 0.0177s/iter; left time: 217.2188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0411120 Vali Loss: 0.0512752 Test Loss: 0.0556068\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0384888\n",
      "\tspeed: 0.0389s/iter; left time: 473.6627s\n",
      "\titers: 200, epoch: 46 | loss: 0.0434502\n",
      "\tspeed: 0.0182s/iter; left time: 219.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0410712 Vali Loss: 0.0511977 Test Loss: 0.0555515\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0412127\n",
      "\tspeed: 0.0392s/iter; left time: 468.5102s\n",
      "\titers: 200, epoch: 47 | loss: 0.0459818\n",
      "\tspeed: 0.0199s/iter; left time: 236.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0410261 Vali Loss: 0.0511490 Test Loss: 0.0555687\n",
      "Validation loss decreased (0.051166 --> 0.051149).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0408425\n",
      "\tspeed: 0.0412s/iter; left time: 482.8872s\n",
      "\titers: 200, epoch: 48 | loss: 0.0376916\n",
      "\tspeed: 0.0171s/iter; left time: 198.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0410817 Vali Loss: 0.0511940 Test Loss: 0.0555730\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0403547\n",
      "\tspeed: 0.0349s/iter; left time: 400.9490s\n",
      "\titers: 200, epoch: 49 | loss: 0.0429389\n",
      "\tspeed: 0.0173s/iter; left time: 197.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0410529 Vali Loss: 0.0512483 Test Loss: 0.0555758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0406631\n",
      "\tspeed: 0.0345s/iter; left time: 389.1738s\n",
      "\titers: 200, epoch: 50 | loss: 0.0436259\n",
      "\tspeed: 0.0177s/iter; left time: 197.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0411125 Vali Loss: 0.0511801 Test Loss: 0.0555535\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0385960\n",
      "\tspeed: 0.0363s/iter; left time: 401.3647s\n",
      "\titers: 200, epoch: 51 | loss: 0.0423439\n",
      "\tspeed: 0.0183s/iter; left time: 200.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0410476 Vali Loss: 0.0512162 Test Loss: 0.0555791\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0413587\n",
      "\tspeed: 0.0371s/iter; left time: 401.9361s\n",
      "\titers: 200, epoch: 52 | loss: 0.0386867\n",
      "\tspeed: 0.0176s/iter; left time: 188.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0410498 Vali Loss: 0.0512396 Test Loss: 0.0555405\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0413097\n",
      "\tspeed: 0.0408s/iter; left time: 432.2047s\n",
      "\titers: 200, epoch: 53 | loss: 0.0427092\n",
      "\tspeed: 0.0175s/iter; left time: 183.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0410592 Vali Loss: 0.0512210 Test Loss: 0.0555653\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0409088\n",
      "\tspeed: 0.0388s/iter; left time: 403.1025s\n",
      "\titers: 200, epoch: 54 | loss: 0.0432247\n",
      "\tspeed: 0.0170s/iter; left time: 174.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0410258 Vali Loss: 0.0511522 Test Loss: 0.0555603\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0421819\n",
      "\tspeed: 0.0414s/iter; left time: 420.1739s\n",
      "\titers: 200, epoch: 55 | loss: 0.0419570\n",
      "\tspeed: 0.0188s/iter; left time: 189.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0410515 Vali Loss: 0.0511869 Test Loss: 0.0555556\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0406773\n",
      "\tspeed: 0.0309s/iter; left time: 306.5796s\n",
      "\titers: 200, epoch: 56 | loss: 0.0426186\n",
      "\tspeed: 0.0177s/iter; left time: 174.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0410750 Vali Loss: 0.0512158 Test Loss: 0.0555549\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0388264\n",
      "\tspeed: 0.0377s/iter; left time: 366.0386s\n",
      "\titers: 200, epoch: 57 | loss: 0.0422632\n",
      "\tspeed: 0.0226s/iter; left time: 216.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0410575 Vali Loss: 0.0511896 Test Loss: 0.0555442\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010113997384905815, rmse:0.10056836903095245, mae:0.05556872487068176, rse:0.38798999786376953\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1016152\n",
      "\tspeed: 0.0205s/iter; left time: 454.2983s\n",
      "\titers: 200, epoch: 1 | loss: 0.0844582\n",
      "\tspeed: 0.0184s/iter; left time: 407.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.1038980 Vali Loss: 0.0882040 Test Loss: 0.0965774\n",
      "Validation loss decreased (inf --> 0.088204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0532787\n",
      "\tspeed: 0.0396s/iter; left time: 871.1122s\n",
      "\titers: 200, epoch: 2 | loss: 0.0511585\n",
      "\tspeed: 0.0180s/iter; left time: 393.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0579113 Vali Loss: 0.0591120 Test Loss: 0.0622490\n",
      "Validation loss decreased (0.088204 --> 0.059112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0512012\n",
      "\tspeed: 0.0361s/iter; left time: 784.8980s\n",
      "\titers: 200, epoch: 3 | loss: 0.0488324\n",
      "\tspeed: 0.0176s/iter; left time: 382.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0500474 Vali Loss: 0.0570830 Test Loss: 0.0599861\n",
      "Validation loss decreased (0.059112 --> 0.057083).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0488231\n",
      "\tspeed: 0.0386s/iter; left time: 830.0936s\n",
      "\titers: 200, epoch: 4 | loss: 0.0482010\n",
      "\tspeed: 0.0170s/iter; left time: 363.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0479661 Vali Loss: 0.0554429 Test Loss: 0.0590104\n",
      "Validation loss decreased (0.057083 --> 0.055443).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0452801\n",
      "\tspeed: 0.0375s/iter; left time: 799.3122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0495539\n",
      "\tspeed: 0.0197s/iter; left time: 417.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0464933 Vali Loss: 0.0542506 Test Loss: 0.0581385\n",
      "Validation loss decreased (0.055443 --> 0.054251).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0416188\n",
      "\tspeed: 0.0343s/iter; left time: 723.3060s\n",
      "\titers: 200, epoch: 6 | loss: 0.0501786\n",
      "\tspeed: 0.0162s/iter; left time: 340.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0454781 Vali Loss: 0.0539334 Test Loss: 0.0577582\n",
      "Validation loss decreased (0.054251 --> 0.053933).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0446660\n",
      "\tspeed: 0.0389s/iter; left time: 811.3737s\n",
      "\titers: 200, epoch: 7 | loss: 0.0454207\n",
      "\tspeed: 0.0194s/iter; left time: 402.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0447840 Vali Loss: 0.0535547 Test Loss: 0.0575306\n",
      "Validation loss decreased (0.053933 --> 0.053555).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0427376\n",
      "\tspeed: 0.0350s/iter; left time: 723.2150s\n",
      "\titers: 200, epoch: 8 | loss: 0.0399747\n",
      "\tspeed: 0.0134s/iter; left time: 275.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 223 | Train Loss: 0.0442095 Vali Loss: 0.0530401 Test Loss: 0.0569660\n",
      "Validation loss decreased (0.053555 --> 0.053040).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0434754\n",
      "\tspeed: 0.0411s/iter; left time: 838.8029s\n",
      "\titers: 200, epoch: 9 | loss: 0.0456122\n",
      "\tspeed: 0.0205s/iter; left time: 415.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0437835 Vali Loss: 0.0526686 Test Loss: 0.0568152\n",
      "Validation loss decreased (0.053040 --> 0.052669).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0449904\n",
      "\tspeed: 0.0413s/iter; left time: 834.1732s\n",
      "\titers: 200, epoch: 10 | loss: 0.0428781\n",
      "\tspeed: 0.0171s/iter; left time: 343.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0434304 Vali Loss: 0.0524344 Test Loss: 0.0564493\n",
      "Validation loss decreased (0.052669 --> 0.052434).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424473\n",
      "\tspeed: 0.0402s/iter; left time: 802.3431s\n",
      "\titers: 200, epoch: 11 | loss: 0.0476073\n",
      "\tspeed: 0.0199s/iter; left time: 394.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0431803 Vali Loss: 0.0523924 Test Loss: 0.0567452\n",
      "Validation loss decreased (0.052434 --> 0.052392).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436329\n",
      "\tspeed: 0.0358s/iter; left time: 706.8598s\n",
      "\titers: 200, epoch: 12 | loss: 0.0438799\n",
      "\tspeed: 0.0205s/iter; left time: 403.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0429407 Vali Loss: 0.0520577 Test Loss: 0.0561142\n",
      "Validation loss decreased (0.052392 --> 0.052058).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434043\n",
      "\tspeed: 0.0408s/iter; left time: 796.9265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0433934\n",
      "\tspeed: 0.0170s/iter; left time: 330.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0426748 Vali Loss: 0.0520190 Test Loss: 0.0566565\n",
      "Validation loss decreased (0.052058 --> 0.052019).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0424824\n",
      "\tspeed: 0.0398s/iter; left time: 768.3492s\n",
      "\titers: 200, epoch: 14 | loss: 0.0439998\n",
      "\tspeed: 0.0206s/iter; left time: 395.0918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0424939 Vali Loss: 0.0518654 Test Loss: 0.0561566\n",
      "Validation loss decreased (0.052019 --> 0.051865).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0402049\n",
      "\tspeed: 0.0380s/iter; left time: 725.5397s\n",
      "\titers: 200, epoch: 15 | loss: 0.0406416\n",
      "\tspeed: 0.0173s/iter; left time: 327.7881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0423416 Vali Loss: 0.0518783 Test Loss: 0.0561662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0448629\n",
      "\tspeed: 0.0368s/iter; left time: 694.5306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0452112\n",
      "\tspeed: 0.0179s/iter; left time: 335.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0421754 Vali Loss: 0.0517294 Test Loss: 0.0562171\n",
      "Validation loss decreased (0.051865 --> 0.051729).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0427255\n",
      "\tspeed: 0.0332s/iter; left time: 618.3397s\n",
      "\titers: 200, epoch: 17 | loss: 0.0420655\n",
      "\tspeed: 0.0136s/iter; left time: 251.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 223 | Train Loss: 0.0420863 Vali Loss: 0.0516368 Test Loss: 0.0559209\n",
      "Validation loss decreased (0.051729 --> 0.051637).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413365\n",
      "\tspeed: 0.0396s/iter; left time: 729.7469s\n",
      "\titers: 200, epoch: 18 | loss: 0.0444465\n",
      "\tspeed: 0.0198s/iter; left time: 362.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0419402 Vali Loss: 0.0515347 Test Loss: 0.0560028\n",
      "Validation loss decreased (0.051637 --> 0.051535).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0466044\n",
      "\tspeed: 0.0368s/iter; left time: 668.7905s\n",
      "\titers: 200, epoch: 19 | loss: 0.0387301\n",
      "\tspeed: 0.0170s/iter; left time: 307.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0418089 Vali Loss: 0.0515540 Test Loss: 0.0558922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0408242\n",
      "\tspeed: 0.0360s/iter; left time: 646.8080s\n",
      "\titers: 200, epoch: 20 | loss: 0.0425226\n",
      "\tspeed: 0.0177s/iter; left time: 316.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0417571 Vali Loss: 0.0515427 Test Loss: 0.0557826\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0427348\n",
      "\tspeed: 0.0376s/iter; left time: 666.3037s\n",
      "\titers: 200, epoch: 21 | loss: 0.0428970\n",
      "\tspeed: 0.0166s/iter; left time: 292.4789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0415922 Vali Loss: 0.0514735 Test Loss: 0.0557090\n",
      "Validation loss decreased (0.051535 --> 0.051473).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0434679\n",
      "\tspeed: 0.0385s/iter; left time: 674.2916s\n",
      "\titers: 200, epoch: 22 | loss: 0.0419072\n",
      "\tspeed: 0.0184s/iter; left time: 319.7597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0415537 Vali Loss: 0.0513715 Test Loss: 0.0559654\n",
      "Validation loss decreased (0.051473 --> 0.051372).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0438716\n",
      "\tspeed: 0.0396s/iter; left time: 684.5059s\n",
      "\titers: 200, epoch: 23 | loss: 0.0403121\n",
      "\tspeed: 0.0231s/iter; left time: 397.1038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0415641 Vali Loss: 0.0513606 Test Loss: 0.0557802\n",
      "Validation loss decreased (0.051372 --> 0.051361).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0402274\n",
      "\tspeed: 0.0384s/iter; left time: 655.8394s\n",
      "\titers: 200, epoch: 24 | loss: 0.0448519\n",
      "\tspeed: 0.0170s/iter; left time: 288.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0414247 Vali Loss: 0.0513891 Test Loss: 0.0557042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0407031\n",
      "\tspeed: 0.0452s/iter; left time: 761.2161s\n",
      "\titers: 200, epoch: 25 | loss: 0.0407442\n",
      "\tspeed: 0.0191s/iter; left time: 320.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0413873 Vali Loss: 0.0513522 Test Loss: 0.0556792\n",
      "Validation loss decreased (0.051361 --> 0.051352).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0402611\n",
      "\tspeed: 0.0408s/iter; left time: 679.1078s\n",
      "\titers: 200, epoch: 26 | loss: 0.0409915\n",
      "\tspeed: 0.0203s/iter; left time: 335.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0412945 Vali Loss: 0.0512191 Test Loss: 0.0555967\n",
      "Validation loss decreased (0.051352 --> 0.051219).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0418679\n",
      "\tspeed: 0.0443s/iter; left time: 727.2401s\n",
      "\titers: 200, epoch: 27 | loss: 0.0400379\n",
      "\tspeed: 0.0216s/iter; left time: 351.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0412685 Vali Loss: 0.0512595 Test Loss: 0.0556316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0413720\n",
      "\tspeed: 0.0399s/iter; left time: 644.9183s\n",
      "\titers: 200, epoch: 28 | loss: 0.0429710\n",
      "\tspeed: 0.0170s/iter; left time: 273.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0412733 Vali Loss: 0.0513094 Test Loss: 0.0555828\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0393783\n",
      "\tspeed: 0.0388s/iter; left time: 619.8282s\n",
      "\titers: 200, epoch: 29 | loss: 0.0407652\n",
      "\tspeed: 0.0221s/iter; left time: 349.8362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0411786 Vali Loss: 0.0512146 Test Loss: 0.0556575\n",
      "Validation loss decreased (0.051219 --> 0.051215).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0410326\n",
      "\tspeed: 0.0384s/iter; left time: 604.1105s\n",
      "\titers: 200, epoch: 30 | loss: 0.0397318\n",
      "\tspeed: 0.0171s/iter; left time: 267.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0411702 Vali Loss: 0.0512536 Test Loss: 0.0557220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0424782\n",
      "\tspeed: 0.0384s/iter; left time: 596.3626s\n",
      "\titers: 200, epoch: 31 | loss: 0.0430690\n",
      "\tspeed: 0.0187s/iter; left time: 288.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0411608 Vali Loss: 0.0512182 Test Loss: 0.0555703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0409948\n",
      "\tspeed: 0.0438s/iter; left time: 669.2848s\n",
      "\titers: 200, epoch: 32 | loss: 0.0415020\n",
      "\tspeed: 0.0238s/iter; left time: 361.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0411308 Vali Loss: 0.0512713 Test Loss: 0.0556108\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0410596\n",
      "\tspeed: 0.0393s/iter; left time: 591.8741s\n",
      "\titers: 200, epoch: 33 | loss: 0.0395203\n",
      "\tspeed: 0.0204s/iter; left time: 305.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0410615 Vali Loss: 0.0511898 Test Loss: 0.0555836\n",
      "Validation loss decreased (0.051215 --> 0.051190).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0392694\n",
      "\tspeed: 0.0418s/iter; left time: 620.1578s\n",
      "\titers: 200, epoch: 34 | loss: 0.0411598\n",
      "\tspeed: 0.0196s/iter; left time: 288.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0410936 Vali Loss: 0.0511487 Test Loss: 0.0556268\n",
      "Validation loss decreased (0.051190 --> 0.051149).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0383482\n",
      "\tspeed: 0.0416s/iter; left time: 608.0070s\n",
      "\titers: 200, epoch: 35 | loss: 0.0388404\n",
      "\tspeed: 0.0200s/iter; left time: 290.9305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0410964 Vali Loss: 0.0512062 Test Loss: 0.0555795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0411525\n",
      "\tspeed: 0.0363s/iter; left time: 522.9333s\n",
      "\titers: 200, epoch: 36 | loss: 0.0424198\n",
      "\tspeed: 0.0165s/iter; left time: 236.0552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0410620 Vali Loss: 0.0511820 Test Loss: 0.0555601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0405026\n",
      "\tspeed: 0.0386s/iter; left time: 547.2188s\n",
      "\titers: 200, epoch: 37 | loss: 0.0387546\n",
      "\tspeed: 0.0199s/iter; left time: 279.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0410529 Vali Loss: 0.0511342 Test Loss: 0.0555378\n",
      "Validation loss decreased (0.051149 --> 0.051134).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0411451\n",
      "\tspeed: 0.0395s/iter; left time: 550.7021s\n",
      "\titers: 200, epoch: 38 | loss: 0.0435212\n",
      "\tspeed: 0.0208s/iter; left time: 287.5793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0409982 Vali Loss: 0.0511362 Test Loss: 0.0555808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0374739\n",
      "\tspeed: 0.0365s/iter; left time: 501.1347s\n",
      "\titers: 200, epoch: 39 | loss: 0.0412064\n",
      "\tspeed: 0.0179s/iter; left time: 244.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0410183 Vali Loss: 0.0511766 Test Loss: 0.0555925\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0377801\n",
      "\tspeed: 0.0382s/iter; left time: 515.3832s\n",
      "\titers: 200, epoch: 40 | loss: 0.0403162\n",
      "\tspeed: 0.0176s/iter; left time: 235.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0409794 Vali Loss: 0.0511287 Test Loss: 0.0555262\n",
      "Validation loss decreased (0.051134 --> 0.051129).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0425979\n",
      "\tspeed: 0.0323s/iter; left time: 429.6134s\n",
      "\titers: 200, epoch: 41 | loss: 0.0380866\n",
      "\tspeed: 0.0134s/iter; left time: 176.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0409976 Vali Loss: 0.0511951 Test Loss: 0.0555292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0398204\n",
      "\tspeed: 0.0351s/iter; left time: 458.3274s\n",
      "\titers: 200, epoch: 42 | loss: 0.0393772\n",
      "\tspeed: 0.0177s/iter; left time: 229.9753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0409570 Vali Loss: 0.0511611 Test Loss: 0.0555607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0399844\n",
      "\tspeed: 0.0389s/iter; left time: 498.7365s\n",
      "\titers: 200, epoch: 43 | loss: 0.0374557\n",
      "\tspeed: 0.0183s/iter; left time: 232.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0409702 Vali Loss: 0.0511306 Test Loss: 0.0555513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0412356\n",
      "\tspeed: 0.0378s/iter; left time: 476.2639s\n",
      "\titers: 200, epoch: 44 | loss: 0.0419733\n",
      "\tspeed: 0.0220s/iter; left time: 275.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0409739 Vali Loss: 0.0511605 Test Loss: 0.0555509\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0415762\n",
      "\tspeed: 0.0364s/iter; left time: 451.2213s\n",
      "\titers: 200, epoch: 45 | loss: 0.0408802\n",
      "\tspeed: 0.0141s/iter; left time: 172.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409689 Vali Loss: 0.0511169 Test Loss: 0.0555100\n",
      "Validation loss decreased (0.051129 --> 0.051117).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0379390\n",
      "\tspeed: 0.0402s/iter; left time: 488.7660s\n",
      "\titers: 200, epoch: 46 | loss: 0.0412013\n",
      "\tspeed: 0.0203s/iter; left time: 245.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0409192 Vali Loss: 0.0511241 Test Loss: 0.0555216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0414135\n",
      "\tspeed: 0.0353s/iter; left time: 422.0096s\n",
      "\titers: 200, epoch: 47 | loss: 0.0431607\n",
      "\tspeed: 0.0173s/iter; left time: 205.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0409505 Vali Loss: 0.0511769 Test Loss: 0.0555238\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0441840\n",
      "\tspeed: 0.0369s/iter; left time: 432.8027s\n",
      "\titers: 200, epoch: 48 | loss: 0.0387574\n",
      "\tspeed: 0.0186s/iter; left time: 215.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0409281 Vali Loss: 0.0511203 Test Loss: 0.0555348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0412677\n",
      "\tspeed: 0.0365s/iter; left time: 419.1887s\n",
      "\titers: 200, epoch: 49 | loss: 0.0444454\n",
      "\tspeed: 0.0181s/iter; left time: 206.2098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0409125 Vali Loss: 0.0511119 Test Loss: 0.0555223\n",
      "Validation loss decreased (0.051117 --> 0.051112).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0423242\n",
      "\tspeed: 0.0375s/iter; left time: 422.8508s\n",
      "\titers: 200, epoch: 50 | loss: 0.0438875\n",
      "\tspeed: 0.0170s/iter; left time: 190.4313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0409516 Vali Loss: 0.0511585 Test Loss: 0.0555335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0376107\n",
      "\tspeed: 0.0372s/iter; left time: 410.7328s\n",
      "\titers: 200, epoch: 51 | loss: 0.0427560\n",
      "\tspeed: 0.0175s/iter; left time: 192.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0409174 Vali Loss: 0.0511308 Test Loss: 0.0555284\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0379333\n",
      "\tspeed: 0.0360s/iter; left time: 389.7518s\n",
      "\titers: 200, epoch: 52 | loss: 0.0398937\n",
      "\tspeed: 0.0210s/iter; left time: 225.4992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0409482 Vali Loss: 0.0511684 Test Loss: 0.0555120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0404721\n",
      "\tspeed: 0.0364s/iter; left time: 385.9005s\n",
      "\titers: 200, epoch: 53 | loss: 0.0426684\n",
      "\tspeed: 0.0141s/iter; left time: 147.6589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409154 Vali Loss: 0.0510899 Test Loss: 0.0555248\n",
      "Validation loss decreased (0.051112 --> 0.051090).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0420862\n",
      "\tspeed: 0.0419s/iter; left time: 434.9267s\n",
      "\titers: 200, epoch: 54 | loss: 0.0408903\n",
      "\tspeed: 0.0203s/iter; left time: 208.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0409427 Vali Loss: 0.0511313 Test Loss: 0.0555267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0419054\n",
      "\tspeed: 0.0388s/iter; left time: 394.4872s\n",
      "\titers: 200, epoch: 55 | loss: 0.0430650\n",
      "\tspeed: 0.0162s/iter; left time: 162.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0409549 Vali Loss: 0.0511246 Test Loss: 0.0555279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0421893\n",
      "\tspeed: 0.0352s/iter; left time: 350.1311s\n",
      "\titers: 200, epoch: 56 | loss: 0.0407559\n",
      "\tspeed: 0.0166s/iter; left time: 163.2385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0409714 Vali Loss: 0.0511561 Test Loss: 0.0555301\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0391232\n",
      "\tspeed: 0.0391s/iter; left time: 380.2044s\n",
      "\titers: 200, epoch: 57 | loss: 0.0394421\n",
      "\tspeed: 0.0186s/iter; left time: 178.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0408828 Vali Loss: 0.0511559 Test Loss: 0.0555225\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0425469\n",
      "\tspeed: 0.0437s/iter; left time: 414.3968s\n",
      "\titers: 200, epoch: 58 | loss: 0.0422341\n",
      "\tspeed: 0.0248s/iter; left time: 232.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0409506 Vali Loss: 0.0511137 Test Loss: 0.0555127\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0424963\n",
      "\tspeed: 0.0372s/iter; left time: 344.7145s\n",
      "\titers: 200, epoch: 59 | loss: 0.0390750\n",
      "\tspeed: 0.0180s/iter; left time: 164.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0409654 Vali Loss: 0.0511508 Test Loss: 0.0555269\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0414468\n",
      "\tspeed: 0.0375s/iter; left time: 339.2343s\n",
      "\titers: 200, epoch: 60 | loss: 0.0378787\n",
      "\tspeed: 0.0178s/iter; left time: 159.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0409690 Vali Loss: 0.0510783 Test Loss: 0.0555309\n",
      "Validation loss decreased (0.051090 --> 0.051078).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0425635\n",
      "\tspeed: 0.0340s/iter; left time: 300.1827s\n",
      "\titers: 200, epoch: 61 | loss: 0.0433908\n",
      "\tspeed: 0.0137s/iter; left time: 119.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 223 | Train Loss: 0.0409005 Vali Loss: 0.0510851 Test Loss: 0.0555206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0405143\n",
      "\tspeed: 0.0402s/iter; left time: 345.4718s\n",
      "\titers: 200, epoch: 62 | loss: 0.0420481\n",
      "\tspeed: 0.0203s/iter; left time: 172.1553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0408878 Vali Loss: 0.0511705 Test Loss: 0.0555193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0414406\n",
      "\tspeed: 0.0424s/iter; left time: 354.7779s\n",
      "\titers: 200, epoch: 63 | loss: 0.0448667\n",
      "\tspeed: 0.0185s/iter; left time: 153.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0408672 Vali Loss: 0.0511999 Test Loss: 0.0555356\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0416664\n",
      "\tspeed: 0.0392s/iter; left time: 319.7464s\n",
      "\titers: 200, epoch: 64 | loss: 0.0393695\n",
      "\tspeed: 0.0173s/iter; left time: 139.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0409323 Vali Loss: 0.0511123 Test Loss: 0.0555272\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0392141\n",
      "\tspeed: 0.0411s/iter; left time: 325.9326s\n",
      "\titers: 200, epoch: 65 | loss: 0.0401084\n",
      "\tspeed: 0.0179s/iter; left time: 139.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0408717 Vali Loss: 0.0511417 Test Loss: 0.0555287\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0427233\n",
      "\tspeed: 0.0343s/iter; left time: 264.2820s\n",
      "\titers: 200, epoch: 66 | loss: 0.0408923\n",
      "\tspeed: 0.0137s/iter; left time: 104.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 223 | Train Loss: 0.0408870 Vali Loss: 0.0510280 Test Loss: 0.0555211\n",
      "Validation loss decreased (0.051078 --> 0.051028).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0380682\n",
      "\tspeed: 0.0394s/iter; left time: 294.8586s\n",
      "\titers: 200, epoch: 67 | loss: 0.0414953\n",
      "\tspeed: 0.0205s/iter; left time: 151.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0408882 Vali Loss: 0.0511818 Test Loss: 0.0555200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0418769\n",
      "\tspeed: 0.0401s/iter; left time: 291.2574s\n",
      "\titers: 200, epoch: 68 | loss: 0.0399697\n",
      "\tspeed: 0.0175s/iter; left time: 125.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0409064 Vali Loss: 0.0511255 Test Loss: 0.0555203\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0423414\n",
      "\tspeed: 0.0362s/iter; left time: 254.7282s\n",
      "\titers: 200, epoch: 69 | loss: 0.0394856\n",
      "\tspeed: 0.0178s/iter; left time: 123.6048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0409026 Vali Loss: 0.0511169 Test Loss: 0.0555225\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0402280\n",
      "\tspeed: 0.0401s/iter; left time: 272.9508s\n",
      "\titers: 200, epoch: 70 | loss: 0.0413966\n",
      "\tspeed: 0.0169s/iter; left time: 113.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0408983 Vali Loss: 0.0510506 Test Loss: 0.0555263\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0432355\n",
      "\tspeed: 0.0361s/iter; left time: 237.7007s\n",
      "\titers: 200, epoch: 71 | loss: 0.0393544\n",
      "\tspeed: 0.0196s/iter; left time: 127.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0408638 Vali Loss: 0.0510727 Test Loss: 0.0555079\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0418266\n",
      "\tspeed: 0.0328s/iter; left time: 208.8198s\n",
      "\titers: 200, epoch: 72 | loss: 0.0401750\n",
      "\tspeed: 0.0189s/iter; left time: 118.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0409211 Vali Loss: 0.0511256 Test Loss: 0.0555259\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0431482\n",
      "\tspeed: 0.0359s/iter; left time: 220.3263s\n",
      "\titers: 200, epoch: 73 | loss: 0.0406357\n",
      "\tspeed: 0.0208s/iter; left time: 125.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0408989 Vali Loss: 0.0511320 Test Loss: 0.0555230\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0461008\n",
      "\tspeed: 0.0454s/iter; left time: 269.0449s\n",
      "\titers: 200, epoch: 74 | loss: 0.0402901\n",
      "\tspeed: 0.0198s/iter; left time: 115.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0408954 Vali Loss: 0.0511215 Test Loss: 0.0555252\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0423226\n",
      "\tspeed: 0.0405s/iter; left time: 231.0896s\n",
      "\titers: 200, epoch: 75 | loss: 0.0400881\n",
      "\tspeed: 0.0179s/iter; left time: 100.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0408863 Vali Loss: 0.0511423 Test Loss: 0.0555282\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0409252\n",
      "\tspeed: 0.0396s/iter; left time: 217.0503s\n",
      "\titers: 200, epoch: 76 | loss: 0.0417138\n",
      "\tspeed: 0.0238s/iter; left time: 127.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0409062 Vali Loss: 0.0511411 Test Loss: 0.0555150\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0100859384983778, rmse:0.10042877495288849, mae:0.05552108958363533, rse:0.3874514102935791\n",
      "Intermediate time for FR and pred_len 24: 00h:12m:39.39s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1062069\n",
      "\tspeed: 0.0432s/iter; left time: 955.8210s\n",
      "\titers: 200, epoch: 1 | loss: 0.0911371\n",
      "\tspeed: 0.0138s/iter; left time: 303.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 222 | Train Loss: 0.1059454 Vali Loss: 0.0940332 Test Loss: 0.1034762\n",
      "Validation loss decreased (inf --> 0.094033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694722\n",
      "\tspeed: 0.0381s/iter; left time: 834.1563s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679546\n",
      "\tspeed: 0.0142s/iter; left time: 308.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0712257 Vali Loss: 0.0754970 Test Loss: 0.0831373\n",
      "Validation loss decreased (0.094033 --> 0.075497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0648793\n",
      "\tspeed: 0.0363s/iter; left time: 786.0563s\n",
      "\titers: 200, epoch: 3 | loss: 0.0634551\n",
      "\tspeed: 0.0182s/iter; left time: 391.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0641144 Vali Loss: 0.0730106 Test Loss: 0.0820418\n",
      "Validation loss decreased (0.075497 --> 0.073011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627153\n",
      "\tspeed: 0.0364s/iter; left time: 781.2588s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635921\n",
      "\tspeed: 0.0169s/iter; left time: 360.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0622810 Vali Loss: 0.0720113 Test Loss: 0.0819087\n",
      "Validation loss decreased (0.073011 --> 0.072011).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0570810\n",
      "\tspeed: 0.0379s/iter; left time: 803.7059s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585973\n",
      "\tspeed: 0.0178s/iter; left time: 376.1773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0612017 Vali Loss: 0.0714426 Test Loss: 0.0810771\n",
      "Validation loss decreased (0.072011 --> 0.071443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595340\n",
      "\tspeed: 0.0465s/iter; left time: 975.4660s\n",
      "\titers: 200, epoch: 6 | loss: 0.0611477\n",
      "\tspeed: 0.0288s/iter; left time: 601.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0603931 Vali Loss: 0.0708800 Test Loss: 0.0809585\n",
      "Validation loss decreased (0.071443 --> 0.070880).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607294\n",
      "\tspeed: 0.0411s/iter; left time: 853.9059s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582943\n",
      "\tspeed: 0.0162s/iter; left time: 333.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0597628 Vali Loss: 0.0706432 Test Loss: 0.0810148\n",
      "Validation loss decreased (0.070880 --> 0.070643).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0608875\n",
      "\tspeed: 0.0378s/iter; left time: 777.0907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620087\n",
      "\tspeed: 0.0181s/iter; left time: 369.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0592277 Vali Loss: 0.0704308 Test Loss: 0.0813834\n",
      "Validation loss decreased (0.070643 --> 0.070431).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0573937\n",
      "\tspeed: 0.0393s/iter; left time: 798.8919s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587755\n",
      "\tspeed: 0.0179s/iter; left time: 362.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0587172 Vali Loss: 0.0699367 Test Loss: 0.0809945\n",
      "Validation loss decreased (0.070431 --> 0.069937).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0545534\n",
      "\tspeed: 0.0405s/iter; left time: 814.6226s\n",
      "\titers: 200, epoch: 10 | loss: 0.0619751\n",
      "\tspeed: 0.0196s/iter; left time: 391.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0583128 Vali Loss: 0.0701495 Test Loss: 0.0809270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0620650\n",
      "\tspeed: 0.0365s/iter; left time: 725.9230s\n",
      "\titers: 200, epoch: 11 | loss: 0.0518779\n",
      "\tspeed: 0.0223s/iter; left time: 441.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0579400 Vali Loss: 0.0700839 Test Loss: 0.0807595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0577957\n",
      "\tspeed: 0.0346s/iter; left time: 679.4551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0583173\n",
      "\tspeed: 0.0137s/iter; left time: 268.7056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 222 | Train Loss: 0.0576169 Vali Loss: 0.0700784 Test Loss: 0.0805763\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559797\n",
      "\tspeed: 0.0368s/iter; left time: 715.0825s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602909\n",
      "\tspeed: 0.0170s/iter; left time: 329.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0573345 Vali Loss: 0.0701772 Test Loss: 0.0805046\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0599460\n",
      "\tspeed: 0.0400s/iter; left time: 768.6949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590913\n",
      "\tspeed: 0.0196s/iter; left time: 375.4034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0570554 Vali Loss: 0.0700844 Test Loss: 0.0812757\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0572859\n",
      "\tspeed: 0.0363s/iter; left time: 690.1208s\n",
      "\titers: 200, epoch: 15 | loss: 0.0550680\n",
      "\tspeed: 0.0184s/iter; left time: 348.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0567927 Vali Loss: 0.0702127 Test Loss: 0.0811241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0530863\n",
      "\tspeed: 0.0374s/iter; left time: 702.3416s\n",
      "\titers: 200, epoch: 16 | loss: 0.0541040\n",
      "\tspeed: 0.0179s/iter; left time: 333.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0565628 Vali Loss: 0.0703821 Test Loss: 0.0814753\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0587605\n",
      "\tspeed: 0.0375s/iter; left time: 695.0526s\n",
      "\titers: 200, epoch: 17 | loss: 0.0569587\n",
      "\tspeed: 0.0165s/iter; left time: 305.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0564356 Vali Loss: 0.0705810 Test Loss: 0.0815717\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547622\n",
      "\tspeed: 0.0370s/iter; left time: 677.5970s\n",
      "\titers: 200, epoch: 18 | loss: 0.0583991\n",
      "\tspeed: 0.0177s/iter; left time: 322.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0562317 Vali Loss: 0.0705525 Test Loss: 0.0812532\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0541225\n",
      "\tspeed: 0.0366s/iter; left time: 661.9653s\n",
      "\titers: 200, epoch: 19 | loss: 0.0555958\n",
      "\tspeed: 0.0176s/iter; left time: 317.4453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0560346 Vali Loss: 0.0704106 Test Loss: 0.0812706\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019158266484737396, rmse:0.13841338455677032, mae:0.08099443465471268, rse:0.535419762134552\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1070282\n",
      "\tspeed: 0.0231s/iter; left time: 511.0715s\n",
      "\titers: 200, epoch: 1 | loss: 0.0921922\n",
      "\tspeed: 0.0179s/iter; left time: 393.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.1105856 Vali Loss: 0.0957573 Test Loss: 0.1052951\n",
      "Validation loss decreased (inf --> 0.095757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0687287\n",
      "\tspeed: 0.0413s/iter; left time: 904.2190s\n",
      "\titers: 200, epoch: 2 | loss: 0.0666846\n",
      "\tspeed: 0.0167s/iter; left time: 362.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0716305 Vali Loss: 0.0761581 Test Loss: 0.0831268\n",
      "Validation loss decreased (0.095757 --> 0.076158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0651576\n",
      "\tspeed: 0.0386s/iter; left time: 836.0538s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649192\n",
      "\tspeed: 0.0181s/iter; left time: 391.2153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0644668 Vali Loss: 0.0730964 Test Loss: 0.0816858\n",
      "Validation loss decreased (0.076158 --> 0.073096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614052\n",
      "\tspeed: 0.0423s/iter; left time: 905.9080s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635957\n",
      "\tspeed: 0.0184s/iter; left time: 392.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0623122 Vali Loss: 0.0721284 Test Loss: 0.0813545\n",
      "Validation loss decreased (0.073096 --> 0.072128).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0589113\n",
      "\tspeed: 0.0411s/iter; left time: 871.7397s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596293\n",
      "\tspeed: 0.0186s/iter; left time: 393.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0611410 Vali Loss: 0.0715151 Test Loss: 0.0805755\n",
      "Validation loss decreased (0.072128 --> 0.071515).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602990\n",
      "\tspeed: 0.0387s/iter; left time: 811.4713s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603326\n",
      "\tspeed: 0.0180s/iter; left time: 375.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0602310 Vali Loss: 0.0713828 Test Loss: 0.0811690\n",
      "Validation loss decreased (0.071515 --> 0.071383).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0619216\n",
      "\tspeed: 0.0370s/iter; left time: 767.8395s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599451\n",
      "\tspeed: 0.0173s/iter; left time: 357.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0596504 Vali Loss: 0.0705745 Test Loss: 0.0804830\n",
      "Validation loss decreased (0.071383 --> 0.070574).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574787\n",
      "\tspeed: 0.0421s/iter; left time: 865.6991s\n",
      "\titers: 200, epoch: 8 | loss: 0.0598171\n",
      "\tspeed: 0.0214s/iter; left time: 437.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0591260 Vali Loss: 0.0703984 Test Loss: 0.0800487\n",
      "Validation loss decreased (0.070574 --> 0.070398).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0598655\n",
      "\tspeed: 0.0382s/iter; left time: 776.6547s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555406\n",
      "\tspeed: 0.0183s/iter; left time: 370.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0586564 Vali Loss: 0.0704212 Test Loss: 0.0804032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596658\n",
      "\tspeed: 0.0397s/iter; left time: 798.9943s\n",
      "\titers: 200, epoch: 10 | loss: 0.0567299\n",
      "\tspeed: 0.0177s/iter; left time: 354.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0583348 Vali Loss: 0.0700433 Test Loss: 0.0800011\n",
      "Validation loss decreased (0.070398 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569278\n",
      "\tspeed: 0.0415s/iter; left time: 825.6342s\n",
      "\titers: 200, epoch: 11 | loss: 0.0596646\n",
      "\tspeed: 0.0229s/iter; left time: 452.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0579184 Vali Loss: 0.0700189 Test Loss: 0.0801705\n",
      "Validation loss decreased (0.070043 --> 0.070019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0593013\n",
      "\tspeed: 0.0388s/iter; left time: 762.1402s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607879\n",
      "\tspeed: 0.0173s/iter; left time: 338.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0576436 Vali Loss: 0.0699916 Test Loss: 0.0800698\n",
      "Validation loss decreased (0.070019 --> 0.069992).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586637\n",
      "\tspeed: 0.0394s/iter; left time: 766.5105s\n",
      "\titers: 200, epoch: 13 | loss: 0.0584758\n",
      "\tspeed: 0.0167s/iter; left time: 323.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0574045 Vali Loss: 0.0701679 Test Loss: 0.0804994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0547756\n",
      "\tspeed: 0.0413s/iter; left time: 793.5031s\n",
      "\titers: 200, epoch: 14 | loss: 0.0613745\n",
      "\tspeed: 0.0195s/iter; left time: 373.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0570940 Vali Loss: 0.0701328 Test Loss: 0.0801409\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587209\n",
      "\tspeed: 0.0401s/iter; left time: 761.9992s\n",
      "\titers: 200, epoch: 15 | loss: 0.0545327\n",
      "\tspeed: 0.0182s/iter; left time: 343.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0568947 Vali Loss: 0.0700188 Test Loss: 0.0799581\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0561400\n",
      "\tspeed: 0.0329s/iter; left time: 617.2159s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518986\n",
      "\tspeed: 0.0135s/iter; left time: 252.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 222 | Train Loss: 0.0567093 Vali Loss: 0.0700918 Test Loss: 0.0803692\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0566552\n",
      "\tspeed: 0.0381s/iter; left time: 706.8703s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546824\n",
      "\tspeed: 0.0194s/iter; left time: 357.4953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0565063 Vali Loss: 0.0702716 Test Loss: 0.0800106\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0541089\n",
      "\tspeed: 0.0351s/iter; left time: 642.8904s\n",
      "\titers: 200, epoch: 18 | loss: 0.0571168\n",
      "\tspeed: 0.0139s/iter; left time: 254.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 222 | Train Loss: 0.0563131 Vali Loss: 0.0702645 Test Loss: 0.0802990\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0570814\n",
      "\tspeed: 0.0355s/iter; left time: 642.6285s\n",
      "\titers: 200, epoch: 19 | loss: 0.0556679\n",
      "\tspeed: 0.0185s/iter; left time: 333.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0561583 Vali Loss: 0.0702643 Test Loss: 0.0807801\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0554411\n",
      "\tspeed: 0.0403s/iter; left time: 720.3670s\n",
      "\titers: 200, epoch: 20 | loss: 0.0554581\n",
      "\tspeed: 0.0138s/iter; left time: 245.2895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0560586 Vali Loss: 0.0701924 Test Loss: 0.0803515\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0557920\n",
      "\tspeed: 0.0381s/iter; left time: 673.6715s\n",
      "\titers: 200, epoch: 21 | loss: 0.0553373\n",
      "\tspeed: 0.0232s/iter; left time: 407.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0559468 Vali Loss: 0.0701994 Test Loss: 0.0804567\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0601400\n",
      "\tspeed: 0.0417s/iter; left time: 726.7885s\n",
      "\titers: 200, epoch: 22 | loss: 0.0538859\n",
      "\tspeed: 0.0171s/iter; left time: 296.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0558123 Vali Loss: 0.0703021 Test Loss: 0.0806775\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019102666527032852, rmse:0.1382123976945877, mae:0.08006981760263443, rse:0.5346422791481018\n",
      "Intermediate time for FR and pred_len 96: 00h:04m:05.21s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1035177\n",
      "\tspeed: 0.0416s/iter; left time: 919.6871s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885830\n",
      "\tspeed: 0.0142s/iter; left time: 312.0777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 222 | Train Loss: 0.1091662 Vali Loss: 0.0966668 Test Loss: 0.1046627\n",
      "Validation loss decreased (inf --> 0.096667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0699403\n",
      "\tspeed: 0.0379s/iter; left time: 830.0278s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688861\n",
      "\tspeed: 0.0184s/iter; left time: 400.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0750753 Vali Loss: 0.0789234 Test Loss: 0.0871920\n",
      "Validation loss decreased (0.096667 --> 0.078923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0676268\n",
      "\tspeed: 0.0422s/iter; left time: 914.6900s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675568\n",
      "\tspeed: 0.0178s/iter; left time: 383.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0678775 Vali Loss: 0.0767840 Test Loss: 0.0861761\n",
      "Validation loss decreased (0.078923 --> 0.076784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0656040\n",
      "\tspeed: 0.0381s/iter; left time: 815.9371s\n",
      "\titers: 200, epoch: 4 | loss: 0.0662547\n",
      "\tspeed: 0.0195s/iter; left time: 415.5041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0660218 Vali Loss: 0.0758449 Test Loss: 0.0861068\n",
      "Validation loss decreased (0.076784 --> 0.075845).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693748\n",
      "\tspeed: 0.0448s/iter; left time: 950.6467s\n",
      "\titers: 200, epoch: 5 | loss: 0.0651196\n",
      "\tspeed: 0.0227s/iter; left time: 480.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 222 | Train Loss: 0.0650218 Vali Loss: 0.0755094 Test Loss: 0.0860099\n",
      "Validation loss decreased (0.075845 --> 0.075509).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0625797\n",
      "\tspeed: 0.0440s/iter; left time: 922.9533s\n",
      "\titers: 200, epoch: 6 | loss: 0.0645481\n",
      "\tspeed: 0.0199s/iter; left time: 415.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0642131 Vali Loss: 0.0751771 Test Loss: 0.0857808\n",
      "Validation loss decreased (0.075509 --> 0.075177).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0633708\n",
      "\tspeed: 0.0391s/iter; left time: 812.8658s\n",
      "\titers: 200, epoch: 7 | loss: 0.0636878\n",
      "\tspeed: 0.0137s/iter; left time: 282.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 222 | Train Loss: 0.0635094 Vali Loss: 0.0747235 Test Loss: 0.0860413\n",
      "Validation loss decreased (0.075177 --> 0.074724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0631453\n",
      "\tspeed: 0.0356s/iter; left time: 730.9431s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620447\n",
      "\tspeed: 0.0136s/iter; left time: 277.4710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 222 | Train Loss: 0.0629824 Vali Loss: 0.0744852 Test Loss: 0.0863849\n",
      "Validation loss decreased (0.074724 --> 0.074485).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620380\n",
      "\tspeed: 0.0362s/iter; left time: 736.3633s\n",
      "\titers: 200, epoch: 9 | loss: 0.0622737\n",
      "\tspeed: 0.0137s/iter; left time: 276.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 222 | Train Loss: 0.0624497 Vali Loss: 0.0742484 Test Loss: 0.0861185\n",
      "Validation loss decreased (0.074485 --> 0.074248).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0606811\n",
      "\tspeed: 0.0396s/iter; left time: 796.3624s\n",
      "\titers: 200, epoch: 10 | loss: 0.0606540\n",
      "\tspeed: 0.0211s/iter; left time: 422.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0619848 Vali Loss: 0.0742773 Test Loss: 0.0866752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0644910\n",
      "\tspeed: 0.0385s/iter; left time: 766.1086s\n",
      "\titers: 200, epoch: 11 | loss: 0.0594626\n",
      "\tspeed: 0.0187s/iter; left time: 369.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0615691 Vali Loss: 0.0743613 Test Loss: 0.0866369\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0641662\n",
      "\tspeed: 0.0406s/iter; left time: 797.4025s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635806\n",
      "\tspeed: 0.0179s/iter; left time: 350.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0612073 Vali Loss: 0.0744398 Test Loss: 0.0861651\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0560868\n",
      "\tspeed: 0.0394s/iter; left time: 765.3019s\n",
      "\titers: 200, epoch: 13 | loss: 0.0553107\n",
      "\tspeed: 0.0190s/iter; left time: 368.3121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0608429 Vali Loss: 0.0745337 Test Loss: 0.0864010\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0604716\n",
      "\tspeed: 0.0414s/iter; left time: 795.6642s\n",
      "\titers: 200, epoch: 14 | loss: 0.0614669\n",
      "\tspeed: 0.0213s/iter; left time: 406.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0605791 Vali Loss: 0.0743380 Test Loss: 0.0871643\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0591253\n",
      "\tspeed: 0.0405s/iter; left time: 769.6379s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619591\n",
      "\tspeed: 0.0184s/iter; left time: 348.3645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0602921 Vali Loss: 0.0747064 Test Loss: 0.0868458\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0626334\n",
      "\tspeed: 0.0404s/iter; left time: 759.0396s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555398\n",
      "\tspeed: 0.0186s/iter; left time: 347.7678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0600553 Vali Loss: 0.0746274 Test Loss: 0.0867082\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595827\n",
      "\tspeed: 0.0412s/iter; left time: 765.0607s\n",
      "\titers: 200, epoch: 17 | loss: 0.0593603\n",
      "\tspeed: 0.0188s/iter; left time: 346.8046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0598396 Vali Loss: 0.0746704 Test Loss: 0.0869478\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0594063\n",
      "\tspeed: 0.0339s/iter; left time: 620.5112s\n",
      "\titers: 200, epoch: 18 | loss: 0.0594017\n",
      "\tspeed: 0.0135s/iter; left time: 246.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 222 | Train Loss: 0.0596267 Vali Loss: 0.0745926 Test Loss: 0.0865889\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0625796\n",
      "\tspeed: 0.0382s/iter; left time: 691.2168s\n",
      "\titers: 200, epoch: 19 | loss: 0.0608385\n",
      "\tspeed: 0.0160s/iter; left time: 287.7179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0594290 Vali Loss: 0.0748989 Test Loss: 0.0867655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021062400192022324, rmse:0.14512890577316284, mae:0.08611854165792465, rse:0.56209796667099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1077867\n",
      "\tspeed: 0.0223s/iter; left time: 493.7921s\n",
      "\titers: 200, epoch: 1 | loss: 0.0918360\n",
      "\tspeed: 0.0200s/iter; left time: 439.4654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1104249 Vali Loss: 0.0975360 Test Loss: 0.1053589\n",
      "Validation loss decreased (inf --> 0.097536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745982\n",
      "\tspeed: 0.0427s/iter; left time: 933.3895s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709568\n",
      "\tspeed: 0.0179s/iter; left time: 390.4453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0751404 Vali Loss: 0.0800276 Test Loss: 0.0873288\n",
      "Validation loss decreased (0.097536 --> 0.080028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689390\n",
      "\tspeed: 0.0416s/iter; left time: 900.2311s\n",
      "\titers: 200, epoch: 3 | loss: 0.0728767\n",
      "\tspeed: 0.0203s/iter; left time: 436.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0681322 Vali Loss: 0.0766989 Test Loss: 0.0861845\n",
      "Validation loss decreased (0.080028 --> 0.076699).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659705\n",
      "\tspeed: 0.0409s/iter; left time: 876.9962s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663830\n",
      "\tspeed: 0.0195s/iter; left time: 416.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0660956 Vali Loss: 0.0758365 Test Loss: 0.0861607\n",
      "Validation loss decreased (0.076699 --> 0.075836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0670353\n",
      "\tspeed: 0.0421s/iter; left time: 894.0384s\n",
      "\titers: 200, epoch: 5 | loss: 0.0637681\n",
      "\tspeed: 0.0193s/iter; left time: 407.3425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0649803 Vali Loss: 0.0754585 Test Loss: 0.0854851\n",
      "Validation loss decreased (0.075836 --> 0.075458).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633890\n",
      "\tspeed: 0.0355s/iter; left time: 745.9703s\n",
      "\titers: 200, epoch: 6 | loss: 0.0622270\n",
      "\tspeed: 0.0160s/iter; left time: 335.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0641333 Vali Loss: 0.0749259 Test Loss: 0.0856561\n",
      "Validation loss decreased (0.075458 --> 0.074926).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0634366\n",
      "\tspeed: 0.0489s/iter; left time: 1016.3659s\n",
      "\titers: 200, epoch: 7 | loss: 0.0666687\n",
      "\tspeed: 0.0254s/iter; left time: 524.2425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.0634242 Vali Loss: 0.0750449 Test Loss: 0.0859632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0625369\n",
      "\tspeed: 0.0443s/iter; left time: 909.6818s\n",
      "\titers: 200, epoch: 8 | loss: 0.0641002\n",
      "\tspeed: 0.0182s/iter; left time: 371.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0628247 Vali Loss: 0.0745941 Test Loss: 0.0854712\n",
      "Validation loss decreased (0.074926 --> 0.074594).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0646787\n",
      "\tspeed: 0.0418s/iter; left time: 850.4168s\n",
      "\titers: 200, epoch: 9 | loss: 0.0618471\n",
      "\tspeed: 0.0211s/iter; left time: 427.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0623321 Vali Loss: 0.0745732 Test Loss: 0.0854541\n",
      "Validation loss decreased (0.074594 --> 0.074573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0597549\n",
      "\tspeed: 0.0420s/iter; left time: 844.0094s\n",
      "\titers: 200, epoch: 10 | loss: 0.0622743\n",
      "\tspeed: 0.0199s/iter; left time: 398.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0618727 Vali Loss: 0.0744078 Test Loss: 0.0860073\n",
      "Validation loss decreased (0.074573 --> 0.074408).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0608343\n",
      "\tspeed: 0.0408s/iter; left time: 812.0242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625011\n",
      "\tspeed: 0.0189s/iter; left time: 373.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0614378 Vali Loss: 0.0746438 Test Loss: 0.0855577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0597012\n",
      "\tspeed: 0.0392s/iter; left time: 770.0564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0647461\n",
      "\tspeed: 0.0140s/iter; left time: 274.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0609949 Vali Loss: 0.0744267 Test Loss: 0.0859095\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0584395\n",
      "\tspeed: 0.0421s/iter; left time: 819.0806s\n",
      "\titers: 200, epoch: 13 | loss: 0.0601505\n",
      "\tspeed: 0.0234s/iter; left time: 451.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0606442 Vali Loss: 0.0746011 Test Loss: 0.0858856\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0594592\n",
      "\tspeed: 0.0412s/iter; left time: 792.3377s\n",
      "\titers: 200, epoch: 14 | loss: 0.0589294\n",
      "\tspeed: 0.0224s/iter; left time: 427.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0602582 Vali Loss: 0.0747873 Test Loss: 0.0863035\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0589795\n",
      "\tspeed: 0.0384s/iter; left time: 729.6217s\n",
      "\titers: 200, epoch: 15 | loss: 0.0600168\n",
      "\tspeed: 0.0203s/iter; left time: 383.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0599949 Vali Loss: 0.0746121 Test Loss: 0.0861639\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0591202\n",
      "\tspeed: 0.0419s/iter; left time: 786.9303s\n",
      "\titers: 200, epoch: 16 | loss: 0.0614986\n",
      "\tspeed: 0.0196s/iter; left time: 365.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0596549 Vali Loss: 0.0749896 Test Loss: 0.0862312\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0611145\n",
      "\tspeed: 0.0404s/iter; left time: 748.7412s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582533\n",
      "\tspeed: 0.0204s/iter; left time: 377.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0594545 Vali Loss: 0.0748358 Test Loss: 0.0862467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0590767\n",
      "\tspeed: 0.0422s/iter; left time: 773.0206s\n",
      "\titers: 200, epoch: 18 | loss: 0.0607313\n",
      "\tspeed: 0.0210s/iter; left time: 383.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0591955 Vali Loss: 0.0746910 Test Loss: 0.0863504\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0560378\n",
      "\tspeed: 0.0430s/iter; left time: 778.2976s\n",
      "\titers: 200, epoch: 19 | loss: 0.0554660\n",
      "\tspeed: 0.0232s/iter; left time: 417.4476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0589750 Vali Loss: 0.0750621 Test Loss: 0.0863930\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0554921\n",
      "\tspeed: 0.0410s/iter; left time: 733.7490s\n",
      "\titers: 200, epoch: 20 | loss: 0.0570317\n",
      "\tspeed: 0.0179s/iter; left time: 317.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0588582 Vali Loss: 0.0748109 Test Loss: 0.0861590\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021153468638658524, rmse:0.14544232189655304, mae:0.08600733429193497, rse:0.5633118748664856\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:04.49s\n",
      "Intermediate time for FR: 00h:20m:49.09s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1437141\n",
      "\tspeed: 0.0420s/iter; left time: 932.0346s\n",
      "\titers: 200, epoch: 1 | loss: 0.1202728\n",
      "\tspeed: 0.0133s/iter; left time: 295.0386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.1473575 Vali Loss: 0.1040505 Test Loss: 0.1061582\n",
      "Validation loss decreased (inf --> 0.104051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786979\n",
      "\tspeed: 0.0333s/iter; left time: 732.0762s\n",
      "\titers: 200, epoch: 2 | loss: 0.0696097\n",
      "\tspeed: 0.0134s/iter; left time: 293.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 223 | Train Loss: 0.0794989 Vali Loss: 0.0625565 Test Loss: 0.0657934\n",
      "Validation loss decreased (0.104051 --> 0.062556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0703888\n",
      "\tspeed: 0.0321s/iter; left time: 697.7150s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639449\n",
      "\tspeed: 0.0145s/iter; left time: 314.7218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.0662476 Vali Loss: 0.0600103 Test Loss: 0.0630265\n",
      "Validation loss decreased (0.062556 --> 0.060010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638470\n",
      "\tspeed: 0.0323s/iter; left time: 695.9385s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634168\n",
      "\tspeed: 0.0171s/iter; left time: 365.9083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0632372 Vali Loss: 0.0585600 Test Loss: 0.0613613\n",
      "Validation loss decreased (0.060010 --> 0.058560).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598216\n",
      "\tspeed: 0.0344s/iter; left time: 733.8724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0611462\n",
      "\tspeed: 0.0162s/iter; left time: 342.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0614596 Vali Loss: 0.0578987 Test Loss: 0.0606158\n",
      "Validation loss decreased (0.058560 --> 0.057899).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0628600\n",
      "\tspeed: 0.0355s/iter; left time: 748.3312s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613859\n",
      "\tspeed: 0.0181s/iter; left time: 380.1603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0602969 Vali Loss: 0.0571664 Test Loss: 0.0599109\n",
      "Validation loss decreased (0.057899 --> 0.057166).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629263\n",
      "\tspeed: 0.0349s/iter; left time: 728.5799s\n",
      "\titers: 200, epoch: 7 | loss: 0.0618758\n",
      "\tspeed: 0.0134s/iter; left time: 277.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0593715 Vali Loss: 0.0567083 Test Loss: 0.0594389\n",
      "Validation loss decreased (0.057166 --> 0.056708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583243\n",
      "\tspeed: 0.0392s/iter; left time: 809.8112s\n",
      "\titers: 200, epoch: 8 | loss: 0.0627724\n",
      "\tspeed: 0.0163s/iter; left time: 334.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0586772 Vali Loss: 0.0564547 Test Loss: 0.0591058\n",
      "Validation loss decreased (0.056708 --> 0.056455).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0574953\n",
      "\tspeed: 0.0364s/iter; left time: 742.2816s\n",
      "\titers: 200, epoch: 9 | loss: 0.0589773\n",
      "\tspeed: 0.0168s/iter; left time: 340.8544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0581441 Vali Loss: 0.0561909 Test Loss: 0.0592300\n",
      "Validation loss decreased (0.056455 --> 0.056191).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0582775\n",
      "\tspeed: 0.0360s/iter; left time: 727.3471s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605522\n",
      "\tspeed: 0.0180s/iter; left time: 362.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0576170 Vali Loss: 0.0557791 Test Loss: 0.0587170\n",
      "Validation loss decreased (0.056191 --> 0.055779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0580367\n",
      "\tspeed: 0.0352s/iter; left time: 702.8092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568590\n",
      "\tspeed: 0.0174s/iter; left time: 345.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0571562 Vali Loss: 0.0557032 Test Loss: 0.0586645\n",
      "Validation loss decreased (0.055779 --> 0.055703).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0566044\n",
      "\tspeed: 0.0369s/iter; left time: 727.9943s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560334\n",
      "\tspeed: 0.0136s/iter; left time: 266.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0568466 Vali Loss: 0.0555272 Test Loss: 0.0584557\n",
      "Validation loss decreased (0.055703 --> 0.055527).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0578054\n",
      "\tspeed: 0.0385s/iter; left time: 752.2854s\n",
      "\titers: 200, epoch: 13 | loss: 0.0580276\n",
      "\tspeed: 0.0216s/iter; left time: 419.9668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0565366 Vali Loss: 0.0554281 Test Loss: 0.0582080\n",
      "Validation loss decreased (0.055527 --> 0.055428).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0534266\n",
      "\tspeed: 0.0350s/iter; left time: 675.9434s\n",
      "\titers: 200, epoch: 14 | loss: 0.0599993\n",
      "\tspeed: 0.0134s/iter; left time: 257.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0562468 Vali Loss: 0.0551934 Test Loss: 0.0581527\n",
      "Validation loss decreased (0.055428 --> 0.055193).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0507638\n",
      "\tspeed: 0.0356s/iter; left time: 679.3486s\n",
      "\titers: 200, epoch: 15 | loss: 0.0534341\n",
      "\tspeed: 0.0185s/iter; left time: 351.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0560631 Vali Loss: 0.0551052 Test Loss: 0.0582090\n",
      "Validation loss decreased (0.055193 --> 0.055105).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0579467\n",
      "\tspeed: 0.0363s/iter; left time: 683.9085s\n",
      "\titers: 200, epoch: 16 | loss: 0.0523164\n",
      "\tspeed: 0.0173s/iter; left time: 324.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0558284 Vali Loss: 0.0549966 Test Loss: 0.0579619\n",
      "Validation loss decreased (0.055105 --> 0.054997).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0546378\n",
      "\tspeed: 0.0407s/iter; left time: 758.3759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0494858\n",
      "\tspeed: 0.0139s/iter; left time: 256.7204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0556673 Vali Loss: 0.0549475 Test Loss: 0.0580232\n",
      "Validation loss decreased (0.054997 --> 0.054948).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0566570\n",
      "\tspeed: 0.0371s/iter; left time: 682.4562s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543237\n",
      "\tspeed: 0.0174s/iter; left time: 318.5517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0555143 Vali Loss: 0.0547563 Test Loss: 0.0578066\n",
      "Validation loss decreased (0.054948 --> 0.054756).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0517749\n",
      "\tspeed: 0.0342s/iter; left time: 621.9767s\n",
      "\titers: 200, epoch: 19 | loss: 0.0594399\n",
      "\tspeed: 0.0166s/iter; left time: 300.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0553137 Vali Loss: 0.0548575 Test Loss: 0.0578166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517547\n",
      "\tspeed: 0.0369s/iter; left time: 662.6455s\n",
      "\titers: 200, epoch: 20 | loss: 0.0545478\n",
      "\tspeed: 0.0227s/iter; left time: 405.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0552275 Vali Loss: 0.0547745 Test Loss: 0.0577862\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0579641\n",
      "\tspeed: 0.0382s/iter; left time: 678.3788s\n",
      "\titers: 200, epoch: 21 | loss: 0.0598810\n",
      "\tspeed: 0.0175s/iter; left time: 308.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0550678 Vali Loss: 0.0548671 Test Loss: 0.0576951\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0547208\n",
      "\tspeed: 0.0326s/iter; left time: 571.1964s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551438\n",
      "\tspeed: 0.0161s/iter; left time: 280.1127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0549465 Vali Loss: 0.0545769 Test Loss: 0.0576395\n",
      "Validation loss decreased (0.054756 --> 0.054577).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0522552\n",
      "\tspeed: 0.0312s/iter; left time: 539.3917s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531761\n",
      "\tspeed: 0.0134s/iter; left time: 230.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 223 | Train Loss: 0.0548522 Vali Loss: 0.0545799 Test Loss: 0.0575342\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0555362\n",
      "\tspeed: 0.0372s/iter; left time: 634.2367s\n",
      "\titers: 200, epoch: 24 | loss: 0.0567952\n",
      "\tspeed: 0.0190s/iter; left time: 321.6645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0547935 Vali Loss: 0.0546119 Test Loss: 0.0576456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0544293\n",
      "\tspeed: 0.0398s/iter; left time: 669.9892s\n",
      "\titers: 200, epoch: 25 | loss: 0.0560157\n",
      "\tspeed: 0.0199s/iter; left time: 333.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0547403 Vali Loss: 0.0545309 Test Loss: 0.0575463\n",
      "Validation loss decreased (0.054577 --> 0.054531).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552145\n",
      "\tspeed: 0.0338s/iter; left time: 562.7796s\n",
      "\titers: 200, epoch: 26 | loss: 0.0523813\n",
      "\tspeed: 0.0139s/iter; left time: 228.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 223 | Train Loss: 0.0546760 Vali Loss: 0.0546120 Test Loss: 0.0574939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0498847\n",
      "\tspeed: 0.0317s/iter; left time: 519.4650s\n",
      "\titers: 200, epoch: 27 | loss: 0.0569689\n",
      "\tspeed: 0.0183s/iter; left time: 298.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0546453 Vali Loss: 0.0545067 Test Loss: 0.0575095\n",
      "Validation loss decreased (0.054531 --> 0.054507).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0548774\n",
      "\tspeed: 0.0356s/iter; left time: 575.9231s\n",
      "\titers: 200, epoch: 28 | loss: 0.0542072\n",
      "\tspeed: 0.0176s/iter; left time: 282.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0545379 Vali Loss: 0.0545554 Test Loss: 0.0574967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0556643\n",
      "\tspeed: 0.0375s/iter; left time: 598.4597s\n",
      "\titers: 200, epoch: 29 | loss: 0.0557755\n",
      "\tspeed: 0.0205s/iter; left time: 325.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0545560 Vali Loss: 0.0544951 Test Loss: 0.0574771\n",
      "Validation loss decreased (0.054507 --> 0.054495).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0524115\n",
      "\tspeed: 0.0390s/iter; left time: 613.4820s\n",
      "\titers: 200, epoch: 30 | loss: 0.0564072\n",
      "\tspeed: 0.0193s/iter; left time: 301.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0544738 Vali Loss: 0.0544940 Test Loss: 0.0573979\n",
      "Validation loss decreased (0.054495 --> 0.054494).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0547487\n",
      "\tspeed: 0.0406s/iter; left time: 629.2269s\n",
      "\titers: 200, epoch: 31 | loss: 0.0544232\n",
      "\tspeed: 0.0149s/iter; left time: 229.9252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0544534 Vali Loss: 0.0544229 Test Loss: 0.0574727\n",
      "Validation loss decreased (0.054494 --> 0.054423).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0549972\n",
      "\tspeed: 0.0401s/iter; left time: 612.8848s\n",
      "\titers: 200, epoch: 32 | loss: 0.0562423\n",
      "\tspeed: 0.0172s/iter; left time: 261.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0544292 Vali Loss: 0.0544749 Test Loss: 0.0574404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533379\n",
      "\tspeed: 0.0344s/iter; left time: 518.0257s\n",
      "\titers: 200, epoch: 33 | loss: 0.0570548\n",
      "\tspeed: 0.0134s/iter; left time: 199.9784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 223 | Train Loss: 0.0543950 Vali Loss: 0.0544427 Test Loss: 0.0573982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0599561\n",
      "\tspeed: 0.0346s/iter; left time: 513.1149s\n",
      "\titers: 200, epoch: 34 | loss: 0.0478511\n",
      "\tspeed: 0.0162s/iter; left time: 239.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0543360 Vali Loss: 0.0544710 Test Loss: 0.0573913\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0565528\n",
      "\tspeed: 0.0338s/iter; left time: 493.4802s\n",
      "\titers: 200, epoch: 35 | loss: 0.0547007\n",
      "\tspeed: 0.0138s/iter; left time: 200.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.0543475 Vali Loss: 0.0544766 Test Loss: 0.0573905\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0555519\n",
      "\tspeed: 0.0401s/iter; left time: 577.7181s\n",
      "\titers: 200, epoch: 36 | loss: 0.0550744\n",
      "\tspeed: 0.0252s/iter; left time: 360.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 223 | Train Loss: 0.0543169 Vali Loss: 0.0544324 Test Loss: 0.0573493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0497372\n",
      "\tspeed: 0.0452s/iter; left time: 641.1635s\n",
      "\titers: 200, epoch: 37 | loss: 0.0548988\n",
      "\tspeed: 0.0249s/iter; left time: 349.9675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.0543114 Vali Loss: 0.0544259 Test Loss: 0.0573501\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0524311\n",
      "\tspeed: 0.0388s/iter; left time: 541.2789s\n",
      "\titers: 200, epoch: 38 | loss: 0.0502245\n",
      "\tspeed: 0.0137s/iter; left time: 190.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0542727 Vali Loss: 0.0544341 Test Loss: 0.0573430\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0549961\n",
      "\tspeed: 0.0413s/iter; left time: 566.3767s\n",
      "\titers: 200, epoch: 39 | loss: 0.0554169\n",
      "\tspeed: 0.0242s/iter; left time: 329.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 223 | Train Loss: 0.0542233 Vali Loss: 0.0544203 Test Loss: 0.0573913\n",
      "Validation loss decreased (0.054423 --> 0.054420).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0589265\n",
      "\tspeed: 0.0396s/iter; left time: 535.1922s\n",
      "\titers: 200, epoch: 40 | loss: 0.0545380\n",
      "\tspeed: 0.0143s/iter; left time: 191.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0541895 Vali Loss: 0.0544312 Test Loss: 0.0573921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0514425\n",
      "\tspeed: 0.0365s/iter; left time: 485.2210s\n",
      "\titers: 200, epoch: 41 | loss: 0.0546664\n",
      "\tspeed: 0.0209s/iter; left time: 275.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0542150 Vali Loss: 0.0544562 Test Loss: 0.0573339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0527747\n",
      "\tspeed: 0.0398s/iter; left time: 519.5033s\n",
      "\titers: 200, epoch: 42 | loss: 0.0571540\n",
      "\tspeed: 0.0197s/iter; left time: 255.3627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0542251 Vali Loss: 0.0543620 Test Loss: 0.0573478\n",
      "Validation loss decreased (0.054420 --> 0.054362).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0545769\n",
      "\tspeed: 0.0415s/iter; left time: 533.0917s\n",
      "\titers: 200, epoch: 43 | loss: 0.0487132\n",
      "\tspeed: 0.0188s/iter; left time: 240.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0541730 Vali Loss: 0.0544308 Test Loss: 0.0573220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0549140\n",
      "\tspeed: 0.0386s/iter; left time: 487.3699s\n",
      "\titers: 200, epoch: 44 | loss: 0.0541150\n",
      "\tspeed: 0.0171s/iter; left time: 213.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0541844 Vali Loss: 0.0543843 Test Loss: 0.0573276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0561807\n",
      "\tspeed: 0.0399s/iter; left time: 494.8889s\n",
      "\titers: 200, epoch: 45 | loss: 0.0577909\n",
      "\tspeed: 0.0213s/iter; left time: 261.6446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0542173 Vali Loss: 0.0543567 Test Loss: 0.0573231\n",
      "Validation loss decreased (0.054362 --> 0.054357).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0528438\n",
      "\tspeed: 0.0431s/iter; left time: 524.7830s\n",
      "\titers: 200, epoch: 46 | loss: 0.0534124\n",
      "\tspeed: 0.0211s/iter; left time: 253.9984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0541766 Vali Loss: 0.0543808 Test Loss: 0.0573528\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0567638\n",
      "\tspeed: 0.0335s/iter; left time: 400.5548s\n",
      "\titers: 200, epoch: 47 | loss: 0.0585442\n",
      "\tspeed: 0.0134s/iter; left time: 158.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 223 | Train Loss: 0.0541377 Vali Loss: 0.0543566 Test Loss: 0.0573289\n",
      "Validation loss decreased (0.054357 --> 0.054357).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0531348\n",
      "\tspeed: 0.0393s/iter; left time: 460.5859s\n",
      "\titers: 200, epoch: 48 | loss: 0.0536503\n",
      "\tspeed: 0.0170s/iter; left time: 198.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0541386 Vali Loss: 0.0543648 Test Loss: 0.0573217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0546740\n",
      "\tspeed: 0.0356s/iter; left time: 409.0567s\n",
      "\titers: 200, epoch: 49 | loss: 0.0523493\n",
      "\tspeed: 0.0206s/iter; left time: 234.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0541804 Vali Loss: 0.0544772 Test Loss: 0.0573325\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0597721\n",
      "\tspeed: 0.0361s/iter; left time: 406.8512s\n",
      "\titers: 200, epoch: 50 | loss: 0.0574830\n",
      "\tspeed: 0.0171s/iter; left time: 190.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0541391 Vali Loss: 0.0543154 Test Loss: 0.0573175\n",
      "Validation loss decreased (0.054357 --> 0.054315).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0517157\n",
      "\tspeed: 0.0400s/iter; left time: 442.2668s\n",
      "\titers: 200, epoch: 51 | loss: 0.0543908\n",
      "\tspeed: 0.0172s/iter; left time: 188.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0541472 Vali Loss: 0.0544369 Test Loss: 0.0573316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0534936\n",
      "\tspeed: 0.0385s/iter; left time: 417.3458s\n",
      "\titers: 200, epoch: 52 | loss: 0.0539709\n",
      "\tspeed: 0.0207s/iter; left time: 222.5737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0541734 Vali Loss: 0.0543713 Test Loss: 0.0573250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0534478\n",
      "\tspeed: 0.0360s/iter; left time: 382.0122s\n",
      "\titers: 200, epoch: 53 | loss: 0.0533508\n",
      "\tspeed: 0.0170s/iter; left time: 178.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0541721 Vali Loss: 0.0543045 Test Loss: 0.0573308\n",
      "Validation loss decreased (0.054315 --> 0.054305).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0566261\n",
      "\tspeed: 0.0401s/iter; left time: 416.5054s\n",
      "\titers: 200, epoch: 54 | loss: 0.0536463\n",
      "\tspeed: 0.0147s/iter; left time: 151.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0541532 Vali Loss: 0.0543599 Test Loss: 0.0573395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0516758\n",
      "\tspeed: 0.0349s/iter; left time: 354.4204s\n",
      "\titers: 200, epoch: 55 | loss: 0.0550711\n",
      "\tspeed: 0.0167s/iter; left time: 167.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0541062 Vali Loss: 0.0544328 Test Loss: 0.0573259\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0518979\n",
      "\tspeed: 0.0377s/iter; left time: 374.8705s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546270\n",
      "\tspeed: 0.0194s/iter; left time: 190.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0541035 Vali Loss: 0.0543275 Test Loss: 0.0573261\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0519868\n",
      "\tspeed: 0.0339s/iter; left time: 329.2277s\n",
      "\titers: 200, epoch: 57 | loss: 0.0487076\n",
      "\tspeed: 0.0134s/iter; left time: 128.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 223 | Train Loss: 0.0540881 Vali Loss: 0.0544441 Test Loss: 0.0573369\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0535206\n",
      "\tspeed: 0.0360s/iter; left time: 341.7021s\n",
      "\titers: 200, epoch: 58 | loss: 0.0532416\n",
      "\tspeed: 0.0180s/iter; left time: 168.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0540898 Vali Loss: 0.0543797 Test Loss: 0.0573186\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0541536\n",
      "\tspeed: 0.0319s/iter; left time: 295.8607s\n",
      "\titers: 200, epoch: 59 | loss: 0.0514462\n",
      "\tspeed: 0.0134s/iter; left time: 123.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0540908 Vali Loss: 0.0543509 Test Loss: 0.0573090\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0540834\n",
      "\tspeed: 0.0339s/iter; left time: 306.2366s\n",
      "\titers: 200, epoch: 60 | loss: 0.0541283\n",
      "\tspeed: 0.0169s/iter; left time: 151.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0540814 Vali Loss: 0.0543827 Test Loss: 0.0573260\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0535569\n",
      "\tspeed: 0.0390s/iter; left time: 343.6868s\n",
      "\titers: 200, epoch: 61 | loss: 0.0517383\n",
      "\tspeed: 0.0181s/iter; left time: 157.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0541284 Vali Loss: 0.0543494 Test Loss: 0.0573032\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0527989\n",
      "\tspeed: 0.0431s/iter; left time: 370.4153s\n",
      "\titers: 200, epoch: 62 | loss: 0.0550649\n",
      "\tspeed: 0.0244s/iter; left time: 207.2221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0541128 Vali Loss: 0.0543446 Test Loss: 0.0573197\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0532350\n",
      "\tspeed: 0.0454s/iter; left time: 379.9728s\n",
      "\titers: 200, epoch: 63 | loss: 0.0585323\n",
      "\tspeed: 0.0196s/iter; left time: 162.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0540723 Vali Loss: 0.0543704 Test Loss: 0.0573123\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010047940537333488, rmse:0.10023941844701767, mae:0.05733075737953186, rse:0.3787554204463959\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1457470\n",
      "\tspeed: 0.0204s/iter; left time: 451.7956s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212814\n",
      "\tspeed: 0.0167s/iter; left time: 369.4927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1459539 Vali Loss: 0.1040013 Test Loss: 0.1058989\n",
      "Validation loss decreased (inf --> 0.104001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0735337\n",
      "\tspeed: 0.0369s/iter; left time: 812.0485s\n",
      "\titers: 200, epoch: 2 | loss: 0.0678748\n",
      "\tspeed: 0.0179s/iter; left time: 392.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0787547 Vali Loss: 0.0630875 Test Loss: 0.0660941\n",
      "Validation loss decreased (0.104001 --> 0.063087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0614651\n",
      "\tspeed: 0.0355s/iter; left time: 771.4864s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644938\n",
      "\tspeed: 0.0204s/iter; left time: 442.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0658965 Vali Loss: 0.0599379 Test Loss: 0.0628037\n",
      "Validation loss decreased (0.063087 --> 0.059938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0564353\n",
      "\tspeed: 0.0385s/iter; left time: 828.3286s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625806\n",
      "\tspeed: 0.0185s/iter; left time: 396.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0629268 Vali Loss: 0.0587714 Test Loss: 0.0615863\n",
      "Validation loss decreased (0.059938 --> 0.058771).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0617238\n",
      "\tspeed: 0.0394s/iter; left time: 839.3770s\n",
      "\titers: 200, epoch: 5 | loss: 0.0560861\n",
      "\tspeed: 0.0180s/iter; left time: 381.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0611850 Vali Loss: 0.0578189 Test Loss: 0.0607687\n",
      "Validation loss decreased (0.058771 --> 0.057819).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602753\n",
      "\tspeed: 0.0440s/iter; left time: 927.1388s\n",
      "\titers: 200, epoch: 6 | loss: 0.0623668\n",
      "\tspeed: 0.0214s/iter; left time: 449.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0600620 Vali Loss: 0.0572946 Test Loss: 0.0603376\n",
      "Validation loss decreased (0.057819 --> 0.057295).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0618545\n",
      "\tspeed: 0.0375s/iter; left time: 782.9741s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571011\n",
      "\tspeed: 0.0186s/iter; left time: 387.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0591845 Vali Loss: 0.0567151 Test Loss: 0.0593557\n",
      "Validation loss decreased (0.057295 --> 0.056715).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569976\n",
      "\tspeed: 0.0343s/iter; left time: 708.4527s\n",
      "\titers: 200, epoch: 8 | loss: 0.0547543\n",
      "\tspeed: 0.0139s/iter; left time: 285.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 223 | Train Loss: 0.0585031 Vali Loss: 0.0565237 Test Loss: 0.0594544\n",
      "Validation loss decreased (0.056715 --> 0.056524).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543804\n",
      "\tspeed: 0.0353s/iter; left time: 720.8242s\n",
      "\titers: 200, epoch: 9 | loss: 0.0541981\n",
      "\tspeed: 0.0178s/iter; left time: 361.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0579559 Vali Loss: 0.0560343 Test Loss: 0.0588984\n",
      "Validation loss decreased (0.056524 --> 0.056034).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570921\n",
      "\tspeed: 0.0380s/iter; left time: 766.4315s\n",
      "\titers: 200, epoch: 10 | loss: 0.0581235\n",
      "\tspeed: 0.0173s/iter; left time: 347.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0575088 Vali Loss: 0.0558357 Test Loss: 0.0587457\n",
      "Validation loss decreased (0.056034 --> 0.055836).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552207\n",
      "\tspeed: 0.0441s/iter; left time: 881.6711s\n",
      "\titers: 200, epoch: 11 | loss: 0.0588722\n",
      "\tspeed: 0.0212s/iter; left time: 420.4657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0570487 Vali Loss: 0.0556468 Test Loss: 0.0584348\n",
      "Validation loss decreased (0.055836 --> 0.055647).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0534963\n",
      "\tspeed: 0.0400s/iter; left time: 789.0074s\n",
      "\titers: 200, epoch: 12 | loss: 0.0539707\n",
      "\tspeed: 0.0199s/iter; left time: 390.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0566552 Vali Loss: 0.0553410 Test Loss: 0.0584786\n",
      "Validation loss decreased (0.055647 --> 0.055341).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0584711\n",
      "\tspeed: 0.0388s/iter; left time: 756.7349s\n",
      "\titers: 200, epoch: 13 | loss: 0.0566057\n",
      "\tspeed: 0.0160s/iter; left time: 310.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0564258 Vali Loss: 0.0552816 Test Loss: 0.0582519\n",
      "Validation loss decreased (0.055341 --> 0.055282).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0520671\n",
      "\tspeed: 0.0355s/iter; left time: 685.7878s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569811\n",
      "\tspeed: 0.0134s/iter; left time: 256.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0560954 Vali Loss: 0.0549893 Test Loss: 0.0582455\n",
      "Validation loss decreased (0.055282 --> 0.054989).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0569312\n",
      "\tspeed: 0.0384s/iter; left time: 731.9323s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552006\n",
      "\tspeed: 0.0187s/iter; left time: 354.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0558732 Vali Loss: 0.0549642 Test Loss: 0.0580239\n",
      "Validation loss decreased (0.054989 --> 0.054964).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0571530\n",
      "\tspeed: 0.0358s/iter; left time: 675.6723s\n",
      "\titers: 200, epoch: 16 | loss: 0.0589899\n",
      "\tspeed: 0.0158s/iter; left time: 295.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0557248 Vali Loss: 0.0547921 Test Loss: 0.0579900\n",
      "Validation loss decreased (0.054964 --> 0.054792).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562732\n",
      "\tspeed: 0.0325s/iter; left time: 605.3607s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565000\n",
      "\tspeed: 0.0135s/iter; left time: 249.3376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0554609 Vali Loss: 0.0548219 Test Loss: 0.0579466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0519799\n",
      "\tspeed: 0.0358s/iter; left time: 658.4027s\n",
      "\titers: 200, epoch: 18 | loss: 0.0570995\n",
      "\tspeed: 0.0181s/iter; left time: 331.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0553718 Vali Loss: 0.0547836 Test Loss: 0.0577883\n",
      "Validation loss decreased (0.054792 --> 0.054784).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0518282\n",
      "\tspeed: 0.0351s/iter; left time: 638.8487s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545539\n",
      "\tspeed: 0.0165s/iter; left time: 299.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 223 | Train Loss: 0.0551896 Vali Loss: 0.0547974 Test Loss: 0.0578146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540750\n",
      "\tspeed: 0.0371s/iter; left time: 666.2291s\n",
      "\titers: 200, epoch: 20 | loss: 0.0540472\n",
      "\tspeed: 0.0175s/iter; left time: 312.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0550423 Vali Loss: 0.0545340 Test Loss: 0.0576575\n",
      "Validation loss decreased (0.054784 --> 0.054534).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0573169\n",
      "\tspeed: 0.0370s/iter; left time: 655.7263s\n",
      "\titers: 200, epoch: 21 | loss: 0.0534556\n",
      "\tspeed: 0.0170s/iter; left time: 300.4881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0549825 Vali Loss: 0.0545961 Test Loss: 0.0576964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0500688\n",
      "\tspeed: 0.0394s/iter; left time: 689.6049s\n",
      "\titers: 200, epoch: 22 | loss: 0.0542406\n",
      "\tspeed: 0.0175s/iter; left time: 305.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0548066 Vali Loss: 0.0544466 Test Loss: 0.0575707\n",
      "Validation loss decreased (0.054534 --> 0.054447).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543506\n",
      "\tspeed: 0.0403s/iter; left time: 696.5723s\n",
      "\titers: 200, epoch: 23 | loss: 0.0511582\n",
      "\tspeed: 0.0205s/iter; left time: 352.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0548099 Vali Loss: 0.0544230 Test Loss: 0.0575399\n",
      "Validation loss decreased (0.054447 --> 0.054423).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0563163\n",
      "\tspeed: 0.0364s/iter; left time: 621.5568s\n",
      "\titers: 200, epoch: 24 | loss: 0.0528216\n",
      "\tspeed: 0.0165s/iter; left time: 279.4823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0546903 Vali Loss: 0.0544592 Test Loss: 0.0576670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573277\n",
      "\tspeed: 0.0353s/iter; left time: 594.2334s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567908\n",
      "\tspeed: 0.0162s/iter; left time: 270.9863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0546120 Vali Loss: 0.0544652 Test Loss: 0.0575388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0506411\n",
      "\tspeed: 0.0363s/iter; left time: 604.3114s\n",
      "\titers: 200, epoch: 26 | loss: 0.0512063\n",
      "\tspeed: 0.0172s/iter; left time: 283.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0545133 Vali Loss: 0.0543853 Test Loss: 0.0574952\n",
      "Validation loss decreased (0.054423 --> 0.054385).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0564387\n",
      "\tspeed: 0.0359s/iter; left time: 588.7451s\n",
      "\titers: 200, epoch: 27 | loss: 0.0522222\n",
      "\tspeed: 0.0174s/iter; left time: 284.1824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0545519 Vali Loss: 0.0543366 Test Loss: 0.0575403\n",
      "Validation loss decreased (0.054385 --> 0.054337).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0520204\n",
      "\tspeed: 0.0402s/iter; left time: 650.5074s\n",
      "\titers: 200, epoch: 28 | loss: 0.0540037\n",
      "\tspeed: 0.0214s/iter; left time: 343.9838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0544933 Vali Loss: 0.0543301 Test Loss: 0.0574681\n",
      "Validation loss decreased (0.054337 --> 0.054330).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0606421\n",
      "\tspeed: 0.0391s/iter; left time: 623.4054s\n",
      "\titers: 200, epoch: 29 | loss: 0.0493314\n",
      "\tspeed: 0.0200s/iter; left time: 317.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0543511 Vali Loss: 0.0544114 Test Loss: 0.0574708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0521616\n",
      "\tspeed: 0.0371s/iter; left time: 584.2875s\n",
      "\titers: 200, epoch: 30 | loss: 0.0577205\n",
      "\tspeed: 0.0166s/iter; left time: 259.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0543719 Vali Loss: 0.0542955 Test Loss: 0.0574528\n",
      "Validation loss decreased (0.054330 --> 0.054296).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550280\n",
      "\tspeed: 0.0360s/iter; left time: 558.8705s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515638\n",
      "\tspeed: 0.0172s/iter; left time: 264.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0543415 Vali Loss: 0.0542877 Test Loss: 0.0573975\n",
      "Validation loss decreased (0.054296 --> 0.054288).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0558943\n",
      "\tspeed: 0.0340s/iter; left time: 520.4960s\n",
      "\titers: 200, epoch: 32 | loss: 0.0559343\n",
      "\tspeed: 0.0138s/iter; left time: 209.0253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 223 | Train Loss: 0.0542692 Vali Loss: 0.0543188 Test Loss: 0.0574333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0514998\n",
      "\tspeed: 0.0451s/iter; left time: 679.1864s\n",
      "\titers: 200, epoch: 33 | loss: 0.0556597\n",
      "\tspeed: 0.0135s/iter; left time: 201.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0542699 Vali Loss: 0.0542458 Test Loss: 0.0574188\n",
      "Validation loss decreased (0.054288 --> 0.054246).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0529556\n",
      "\tspeed: 0.0381s/iter; left time: 566.0992s\n",
      "\titers: 200, epoch: 34 | loss: 0.0511045\n",
      "\tspeed: 0.0174s/iter; left time: 257.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0542249 Vali Loss: 0.0542811 Test Loss: 0.0573638\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0547141\n",
      "\tspeed: 0.0369s/iter; left time: 539.4354s\n",
      "\titers: 200, epoch: 35 | loss: 0.0541711\n",
      "\tspeed: 0.0187s/iter; left time: 271.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0541732 Vali Loss: 0.0542286 Test Loss: 0.0573742\n",
      "Validation loss decreased (0.054246 --> 0.054229).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0518640\n",
      "\tspeed: 0.0338s/iter; left time: 487.2924s\n",
      "\titers: 200, epoch: 36 | loss: 0.0490506\n",
      "\tspeed: 0.0134s/iter; left time: 191.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 223 | Train Loss: 0.0541447 Vali Loss: 0.0542492 Test Loss: 0.0573756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0552060\n",
      "\tspeed: 0.0315s/iter; left time: 447.1343s\n",
      "\titers: 200, epoch: 37 | loss: 0.0555272\n",
      "\tspeed: 0.0161s/iter; left time: 227.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 223 | Train Loss: 0.0541290 Vali Loss: 0.0542685 Test Loss: 0.0573609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0561671\n",
      "\tspeed: 0.0366s/iter; left time: 510.6540s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542916\n",
      "\tspeed: 0.0182s/iter; left time: 252.2457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0541513 Vali Loss: 0.0542041 Test Loss: 0.0573852\n",
      "Validation loss decreased (0.054229 --> 0.054204).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0548895\n",
      "\tspeed: 0.0349s/iter; left time: 479.7523s\n",
      "\titers: 200, epoch: 39 | loss: 0.0531467\n",
      "\tspeed: 0.0171s/iter; left time: 232.3873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 223 | Train Loss: 0.0541213 Vali Loss: 0.0542176 Test Loss: 0.0573834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0544214\n",
      "\tspeed: 0.0369s/iter; left time: 498.7444s\n",
      "\titers: 200, epoch: 40 | loss: 0.0583453\n",
      "\tspeed: 0.0182s/iter; left time: 244.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0541214 Vali Loss: 0.0542773 Test Loss: 0.0573329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545420\n",
      "\tspeed: 0.0384s/iter; left time: 509.6323s\n",
      "\titers: 200, epoch: 41 | loss: 0.0548785\n",
      "\tspeed: 0.0199s/iter; left time: 262.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0540730 Vali Loss: 0.0541359 Test Loss: 0.0573272\n",
      "Validation loss decreased (0.054204 --> 0.054136).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0548791\n",
      "\tspeed: 0.0402s/iter; left time: 524.7269s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539936\n",
      "\tspeed: 0.0182s/iter; left time: 235.6905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0541721 Vali Loss: 0.0541827 Test Loss: 0.0573282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0493114\n",
      "\tspeed: 0.0365s/iter; left time: 467.9710s\n",
      "\titers: 200, epoch: 43 | loss: 0.0559705\n",
      "\tspeed: 0.0161s/iter; left time: 204.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.0540417 Vali Loss: 0.0541714 Test Loss: 0.0573361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0538946\n",
      "\tspeed: 0.0387s/iter; left time: 487.5642s\n",
      "\titers: 200, epoch: 44 | loss: 0.0526558\n",
      "\tspeed: 0.0169s/iter; left time: 211.7036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0540138 Vali Loss: 0.0541919 Test Loss: 0.0573418\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0559968\n",
      "\tspeed: 0.0375s/iter; left time: 464.8857s\n",
      "\titers: 200, epoch: 45 | loss: 0.0524948\n",
      "\tspeed: 0.0182s/iter; left time: 224.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0539771 Vali Loss: 0.0542035 Test Loss: 0.0573577\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0502052\n",
      "\tspeed: 0.0380s/iter; left time: 462.2127s\n",
      "\titers: 200, epoch: 46 | loss: 0.0565050\n",
      "\tspeed: 0.0177s/iter; left time: 213.4405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0539581 Vali Loss: 0.0541779 Test Loss: 0.0573358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0516009\n",
      "\tspeed: 0.0385s/iter; left time: 459.4079s\n",
      "\titers: 200, epoch: 47 | loss: 0.0566236\n",
      "\tspeed: 0.0169s/iter; left time: 200.3634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0540851 Vali Loss: 0.0541903 Test Loss: 0.0573625\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0521797\n",
      "\tspeed: 0.0397s/iter; left time: 465.0753s\n",
      "\titers: 200, epoch: 48 | loss: 0.0546335\n",
      "\tspeed: 0.0191s/iter; left time: 222.1080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0540186 Vali Loss: 0.0542303 Test Loss: 0.0573607\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543171\n",
      "\tspeed: 0.0396s/iter; left time: 455.5602s\n",
      "\titers: 200, epoch: 49 | loss: 0.0555856\n",
      "\tspeed: 0.0174s/iter; left time: 198.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0540589 Vali Loss: 0.0542267 Test Loss: 0.0573241\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0540652\n",
      "\tspeed: 0.0382s/iter; left time: 431.1245s\n",
      "\titers: 200, epoch: 50 | loss: 0.0513050\n",
      "\tspeed: 0.0176s/iter; left time: 196.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0540571 Vali Loss: 0.0541554 Test Loss: 0.0573193\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0561543\n",
      "\tspeed: 0.0377s/iter; left time: 416.0704s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515594\n",
      "\tspeed: 0.0205s/iter; left time: 224.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0539728 Vali Loss: 0.0542120 Test Loss: 0.0573304\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01009416114538908, rmse:0.10046970099210739, mae:0.05732718110084534, rse:0.3796255588531494\n",
      "Intermediate time for IT and pred_len 24: 00h:10m:36.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1479913\n",
      "\tspeed: 0.0446s/iter; left time: 986.2020s\n",
      "\titers: 200, epoch: 1 | loss: 0.1278358\n",
      "\tspeed: 0.0139s/iter; left time: 305.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.1509340 Vali Loss: 0.1113346 Test Loss: 0.1137485\n",
      "Validation loss decreased (inf --> 0.111335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0944444\n",
      "\tspeed: 0.0371s/iter; left time: 811.9452s\n",
      "\titers: 200, epoch: 2 | loss: 0.0874377\n",
      "\tspeed: 0.0162s/iter; left time: 353.5777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0967178 Vali Loss: 0.0823285 Test Loss: 0.0860342\n",
      "Validation loss decreased (0.111335 --> 0.082329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0855469\n",
      "\tspeed: 0.0475s/iter; left time: 1027.9397s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833481\n",
      "\tspeed: 0.0254s/iter; left time: 546.6825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0849238 Vali Loss: 0.0799034 Test Loss: 0.0836877\n",
      "Validation loss decreased (0.082329 --> 0.079903).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0803793\n",
      "\tspeed: 0.0376s/iter; left time: 805.9851s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802156\n",
      "\tspeed: 0.0176s/iter; left time: 374.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0819894 Vali Loss: 0.0792200 Test Loss: 0.0827178\n",
      "Validation loss decreased (0.079903 --> 0.079220).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758407\n",
      "\tspeed: 0.0411s/iter; left time: 871.8308s\n",
      "\titers: 200, epoch: 5 | loss: 0.0790727\n",
      "\tspeed: 0.0236s/iter; left time: 498.9035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0801684 Vali Loss: 0.0781376 Test Loss: 0.0819063\n",
      "Validation loss decreased (0.079220 --> 0.078138).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774131\n",
      "\tspeed: 0.0468s/iter; left time: 981.7007s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802438\n",
      "\tspeed: 0.0252s/iter; left time: 526.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.0789265 Vali Loss: 0.0777756 Test Loss: 0.0824706\n",
      "Validation loss decreased (0.078138 --> 0.077776).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0807875\n",
      "\tspeed: 0.0419s/iter; left time: 870.8928s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759878\n",
      "\tspeed: 0.0245s/iter; left time: 506.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 222 | Train Loss: 0.0779415 Vali Loss: 0.0775908 Test Loss: 0.0817274\n",
      "Validation loss decreased (0.077776 --> 0.077591).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776044\n",
      "\tspeed: 0.0448s/iter; left time: 920.5095s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787301\n",
      "\tspeed: 0.0195s/iter; left time: 399.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0772210 Vali Loss: 0.0777705 Test Loss: 0.0818364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0761995\n",
      "\tspeed: 0.0394s/iter; left time: 801.7784s\n",
      "\titers: 200, epoch: 9 | loss: 0.0761909\n",
      "\tspeed: 0.0197s/iter; left time: 398.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0764416 Vali Loss: 0.0772596 Test Loss: 0.0815428\n",
      "Validation loss decreased (0.077591 --> 0.077260).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0737678\n",
      "\tspeed: 0.0413s/iter; left time: 830.7124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0789659\n",
      "\tspeed: 0.0230s/iter; left time: 459.9267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 222 | Train Loss: 0.0759295 Vali Loss: 0.0771065 Test Loss: 0.0816032\n",
      "Validation loss decreased (0.077260 --> 0.077106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0737865\n",
      "\tspeed: 0.0409s/iter; left time: 812.4808s\n",
      "\titers: 200, epoch: 11 | loss: 0.0757708\n",
      "\tspeed: 0.0190s/iter; left time: 375.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0754028 Vali Loss: 0.0772729 Test Loss: 0.0818641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0741639\n",
      "\tspeed: 0.0450s/iter; left time: 884.7269s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756052\n",
      "\tspeed: 0.0234s/iter; left time: 457.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 222 | Train Loss: 0.0749426 Vali Loss: 0.0769817 Test Loss: 0.0816899\n",
      "Validation loss decreased (0.077106 --> 0.076982).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764486\n",
      "\tspeed: 0.0395s/iter; left time: 768.3032s\n",
      "\titers: 200, epoch: 13 | loss: 0.0700148\n",
      "\tspeed: 0.0196s/iter; left time: 379.8653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0745547 Vali Loss: 0.0767195 Test Loss: 0.0818730\n",
      "Validation loss decreased (0.076982 --> 0.076719).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748338\n",
      "\tspeed: 0.0388s/iter; left time: 745.2516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0736856\n",
      "\tspeed: 0.0197s/iter; left time: 376.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0742038 Vali Loss: 0.0770429 Test Loss: 0.0819860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0710020\n",
      "\tspeed: 0.0416s/iter; left time: 789.9903s\n",
      "\titers: 200, epoch: 15 | loss: 0.0764227\n",
      "\tspeed: 0.0151s/iter; left time: 285.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0739223 Vali Loss: 0.0769741 Test Loss: 0.0822614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0726425\n",
      "\tspeed: 0.0357s/iter; left time: 670.9218s\n",
      "\titers: 200, epoch: 16 | loss: 0.0715808\n",
      "\tspeed: 0.0172s/iter; left time: 321.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0736787 Vali Loss: 0.0767621 Test Loss: 0.0819819\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0750257\n",
      "\tspeed: 0.0400s/iter; left time: 741.2306s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748659\n",
      "\tspeed: 0.0244s/iter; left time: 450.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0733470 Vali Loss: 0.0768514 Test Loss: 0.0819608\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0742110\n",
      "\tspeed: 0.0395s/iter; left time: 723.1175s\n",
      "\titers: 200, epoch: 18 | loss: 0.0717777\n",
      "\tspeed: 0.0197s/iter; left time: 359.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0730956 Vali Loss: 0.0767223 Test Loss: 0.0822662\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0722852\n",
      "\tspeed: 0.0397s/iter; left time: 719.3086s\n",
      "\titers: 200, epoch: 19 | loss: 0.0741850\n",
      "\tspeed: 0.0246s/iter; left time: 443.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 222 | Train Loss: 0.0728978 Vali Loss: 0.0768149 Test Loss: 0.0822847\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0732617\n",
      "\tspeed: 0.0442s/iter; left time: 791.2326s\n",
      "\titers: 200, epoch: 20 | loss: 0.0732149\n",
      "\tspeed: 0.0253s/iter; left time: 449.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 222 | Train Loss: 0.0727018 Vali Loss: 0.0770359 Test Loss: 0.0822300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748833\n",
      "\tspeed: 0.0403s/iter; left time: 711.1877s\n",
      "\titers: 200, epoch: 21 | loss: 0.0715385\n",
      "\tspeed: 0.0211s/iter; left time: 370.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0726482 Vali Loss: 0.0766319 Test Loss: 0.0822742\n",
      "Validation loss decreased (0.076719 --> 0.076632).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0743030\n",
      "\tspeed: 0.0391s/iter; left time: 681.7008s\n",
      "\titers: 200, epoch: 22 | loss: 0.0664359\n",
      "\tspeed: 0.0185s/iter; left time: 320.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0724633 Vali Loss: 0.0767149 Test Loss: 0.0823296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716617\n",
      "\tspeed: 0.0391s/iter; left time: 672.6379s\n",
      "\titers: 200, epoch: 23 | loss: 0.0722532\n",
      "\tspeed: 0.0189s/iter; left time: 323.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0722818 Vali Loss: 0.0766305 Test Loss: 0.0823729\n",
      "Validation loss decreased (0.076632 --> 0.076631).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0720586\n",
      "\tspeed: 0.0426s/iter; left time: 724.1382s\n",
      "\titers: 200, epoch: 24 | loss: 0.0716495\n",
      "\tspeed: 0.0218s/iter; left time: 368.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 222 | Train Loss: 0.0722082 Vali Loss: 0.0764609 Test Loss: 0.0823976\n",
      "Validation loss decreased (0.076631 --> 0.076461).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0696182\n",
      "\tspeed: 0.0419s/iter; left time: 703.2987s\n",
      "\titers: 200, epoch: 25 | loss: 0.0691295\n",
      "\tspeed: 0.0196s/iter; left time: 327.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0720955 Vali Loss: 0.0764957 Test Loss: 0.0823104\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704603\n",
      "\tspeed: 0.0404s/iter; left time: 668.1200s\n",
      "\titers: 200, epoch: 26 | loss: 0.0709266\n",
      "\tspeed: 0.0223s/iter; left time: 366.6436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0719527 Vali Loss: 0.0766552 Test Loss: 0.0824931\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0737579\n",
      "\tspeed: 0.0401s/iter; left time: 655.1259s\n",
      "\titers: 200, epoch: 27 | loss: 0.0734456\n",
      "\tspeed: 0.0247s/iter; left time: 400.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0718870 Vali Loss: 0.0765219 Test Loss: 0.0824327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0746302\n",
      "\tspeed: 0.0400s/iter; left time: 643.7998s\n",
      "\titers: 200, epoch: 28 | loss: 0.0706372\n",
      "\tspeed: 0.0196s/iter; left time: 313.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0718018 Vali Loss: 0.0766459 Test Loss: 0.0824851\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0708578\n",
      "\tspeed: 0.0429s/iter; left time: 680.6728s\n",
      "\titers: 200, epoch: 29 | loss: 0.0740411\n",
      "\tspeed: 0.0187s/iter; left time: 295.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0717345 Vali Loss: 0.0766056 Test Loss: 0.0824427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0681985\n",
      "\tspeed: 0.0413s/iter; left time: 646.5664s\n",
      "\titers: 200, epoch: 30 | loss: 0.0703355\n",
      "\tspeed: 0.0236s/iter; left time: 367.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 222 | Train Loss: 0.0716702 Vali Loss: 0.0765500 Test Loss: 0.0824766\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0732219\n",
      "\tspeed: 0.0388s/iter; left time: 599.2940s\n",
      "\titers: 200, epoch: 31 | loss: 0.0738415\n",
      "\tspeed: 0.0198s/iter; left time: 304.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0715997 Vali Loss: 0.0765868 Test Loss: 0.0825680\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0717585\n",
      "\tspeed: 0.0381s/iter; left time: 579.4553s\n",
      "\titers: 200, epoch: 32 | loss: 0.0688524\n",
      "\tspeed: 0.0170s/iter; left time: 256.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0715143 Vali Loss: 0.0766407 Test Loss: 0.0825292\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0734595\n",
      "\tspeed: 0.0402s/iter; left time: 602.3704s\n",
      "\titers: 200, epoch: 33 | loss: 0.0716384\n",
      "\tspeed: 0.0137s/iter; left time: 204.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.0715773 Vali Loss: 0.0765254 Test Loss: 0.0825964\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0721276\n",
      "\tspeed: 0.0371s/iter; left time: 548.4174s\n",
      "\titers: 200, epoch: 34 | loss: 0.0688771\n",
      "\tspeed: 0.0235s/iter; left time: 345.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0715188 Vali Loss: 0.0764844 Test Loss: 0.0825642\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019081197679042816, rmse:0.13813470304012299, mae:0.08239757269620895, rse:0.5223022103309631\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1533576\n",
      "\tspeed: 0.0218s/iter; left time: 482.3726s\n",
      "\titers: 200, epoch: 1 | loss: 0.1258173\n",
      "\tspeed: 0.0187s/iter; left time: 410.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.1576304 Vali Loss: 0.1141917 Test Loss: 0.1167547\n",
      "Validation loss decreased (inf --> 0.114192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0951879\n",
      "\tspeed: 0.0402s/iter; left time: 879.2543s\n",
      "\titers: 200, epoch: 2 | loss: 0.0837960\n",
      "\tspeed: 0.0244s/iter; left time: 532.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0973957 Vali Loss: 0.0826617 Test Loss: 0.0860800\n",
      "Validation loss decreased (0.114192 --> 0.082662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0884477\n",
      "\tspeed: 0.0418s/iter; left time: 905.1471s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840303\n",
      "\tspeed: 0.0235s/iter; left time: 507.3149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0855458 Vali Loss: 0.0800506 Test Loss: 0.0840646\n",
      "Validation loss decreased (0.082662 --> 0.080051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0832313\n",
      "\tspeed: 0.0397s/iter; left time: 850.1922s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811868\n",
      "\tspeed: 0.0189s/iter; left time: 404.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0824560 Vali Loss: 0.0791275 Test Loss: 0.0833916\n",
      "Validation loss decreased (0.080051 --> 0.079128).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0832734\n",
      "\tspeed: 0.0412s/iter; left time: 874.0192s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773675\n",
      "\tspeed: 0.0197s/iter; left time: 416.6412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0806732 Vali Loss: 0.0784330 Test Loss: 0.0825905\n",
      "Validation loss decreased (0.079128 --> 0.078433).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749405\n",
      "\tspeed: 0.0390s/iter; left time: 819.0159s\n",
      "\titers: 200, epoch: 6 | loss: 0.0764417\n",
      "\tspeed: 0.0201s/iter; left time: 420.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0794197 Vali Loss: 0.0778552 Test Loss: 0.0824325\n",
      "Validation loss decreased (0.078433 --> 0.077855).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774064\n",
      "\tspeed: 0.0424s/iter; left time: 881.4330s\n",
      "\titers: 200, epoch: 7 | loss: 0.0777140\n",
      "\tspeed: 0.0197s/iter; left time: 408.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0784178 Vali Loss: 0.0777865 Test Loss: 0.0823786\n",
      "Validation loss decreased (0.077855 --> 0.077787).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0733291\n",
      "\tspeed: 0.0406s/iter; left time: 834.7617s\n",
      "\titers: 200, epoch: 8 | loss: 0.0773760\n",
      "\tspeed: 0.0227s/iter; left time: 463.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.0776072 Vali Loss: 0.0780508 Test Loss: 0.0824674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769634\n",
      "\tspeed: 0.0432s/iter; left time: 878.5319s\n",
      "\titers: 200, epoch: 9 | loss: 0.0784815\n",
      "\tspeed: 0.0214s/iter; left time: 432.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.0768281 Vali Loss: 0.0779679 Test Loss: 0.0825637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738475\n",
      "\tspeed: 0.0436s/iter; left time: 875.9413s\n",
      "\titers: 200, epoch: 10 | loss: 0.0752034\n",
      "\tspeed: 0.0189s/iter; left time: 377.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0761850 Vali Loss: 0.0779151 Test Loss: 0.0822135\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0749963\n",
      "\tspeed: 0.0383s/iter; left time: 760.8732s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817791\n",
      "\tspeed: 0.0205s/iter; left time: 406.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0756182 Vali Loss: 0.0779250 Test Loss: 0.0825613\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0721691\n",
      "\tspeed: 0.0437s/iter; left time: 858.1957s\n",
      "\titers: 200, epoch: 12 | loss: 0.0701382\n",
      "\tspeed: 0.0219s/iter; left time: 428.0610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0751046 Vali Loss: 0.0777670 Test Loss: 0.0824181\n",
      "Validation loss decreased (0.077787 --> 0.077767).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0747601\n",
      "\tspeed: 0.0387s/iter; left time: 751.7007s\n",
      "\titers: 200, epoch: 13 | loss: 0.0777101\n",
      "\tspeed: 0.0186s/iter; left time: 360.3758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0746368 Vali Loss: 0.0776885 Test Loss: 0.0826153\n",
      "Validation loss decreased (0.077767 --> 0.077689).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0761022\n",
      "\tspeed: 0.0414s/iter; left time: 794.5970s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747421\n",
      "\tspeed: 0.0201s/iter; left time: 384.3988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0742460 Vali Loss: 0.0775988 Test Loss: 0.0827038\n",
      "Validation loss decreased (0.077689 --> 0.077599).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0761102\n",
      "\tspeed: 0.0435s/iter; left time: 826.7309s\n",
      "\titers: 200, epoch: 15 | loss: 0.0775206\n",
      "\tspeed: 0.0198s/iter; left time: 374.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0738772 Vali Loss: 0.0777743 Test Loss: 0.0824912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0778928\n",
      "\tspeed: 0.0404s/iter; left time: 758.7449s\n",
      "\titers: 200, epoch: 16 | loss: 0.0724049\n",
      "\tspeed: 0.0195s/iter; left time: 363.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0736273 Vali Loss: 0.0777686 Test Loss: 0.0826381\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0735264\n",
      "\tspeed: 0.0399s/iter; left time: 739.4876s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736347\n",
      "\tspeed: 0.0200s/iter; left time: 369.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0732885 Vali Loss: 0.0778704 Test Loss: 0.0827113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0711130\n",
      "\tspeed: 0.0395s/iter; left time: 724.0321s\n",
      "\titers: 200, epoch: 18 | loss: 0.0744401\n",
      "\tspeed: 0.0190s/iter; left time: 346.1764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0730587 Vali Loss: 0.0776919 Test Loss: 0.0828117\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0717083\n",
      "\tspeed: 0.0370s/iter; left time: 669.0248s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709039\n",
      "\tspeed: 0.0162s/iter; left time: 292.0411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0727871 Vali Loss: 0.0779120 Test Loss: 0.0827605\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0732300\n",
      "\tspeed: 0.0446s/iter; left time: 797.4718s\n",
      "\titers: 200, epoch: 20 | loss: 0.0696942\n",
      "\tspeed: 0.0215s/iter; left time: 383.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 222 | Train Loss: 0.0726441 Vali Loss: 0.0776963 Test Loss: 0.0829178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0725246\n",
      "\tspeed: 0.0444s/iter; left time: 784.3014s\n",
      "\titers: 200, epoch: 21 | loss: 0.0735690\n",
      "\tspeed: 0.0257s/iter; left time: 451.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 222 | Train Loss: 0.0724413 Vali Loss: 0.0779955 Test Loss: 0.0828458\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0741724\n",
      "\tspeed: 0.0407s/iter; left time: 709.2066s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696557\n",
      "\tspeed: 0.0179s/iter; left time: 309.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0723066 Vali Loss: 0.0777500 Test Loss: 0.0827996\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0730049\n",
      "\tspeed: 0.0380s/iter; left time: 655.0362s\n",
      "\titers: 200, epoch: 23 | loss: 0.0770885\n",
      "\tspeed: 0.0195s/iter; left time: 333.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0721054 Vali Loss: 0.0777183 Test Loss: 0.0829464\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0714237\n",
      "\tspeed: 0.0432s/iter; left time: 734.9282s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685248\n",
      "\tspeed: 0.0205s/iter; left time: 345.7656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0719408 Vali Loss: 0.0778894 Test Loss: 0.0830260\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019132712855935097, rmse:0.13832105696201324, mae:0.08270382136106491, rse:0.523006796836853\n",
      "Intermediate time for IT and pred_len 96: 00h:06m:07.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1511273\n",
      "\tspeed: 0.0426s/iter; left time: 941.7778s\n",
      "\titers: 200, epoch: 1 | loss: 0.1284135\n",
      "\tspeed: 0.0138s/iter; left time: 303.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 222 | Train Loss: 0.1545354 Vali Loss: 0.1137063 Test Loss: 0.1152426\n",
      "Validation loss decreased (inf --> 0.113706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0969478\n",
      "\tspeed: 0.0371s/iter; left time: 812.1898s\n",
      "\titers: 200, epoch: 2 | loss: 0.0926904\n",
      "\tspeed: 0.0176s/iter; left time: 383.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.1000738 Vali Loss: 0.0867909 Test Loss: 0.0896652\n",
      "Validation loss decreased (0.113706 --> 0.086791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895848\n",
      "\tspeed: 0.0397s/iter; left time: 859.2184s\n",
      "\titers: 200, epoch: 3 | loss: 0.0869072\n",
      "\tspeed: 0.0188s/iter; left time: 404.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0889273 Vali Loss: 0.0849855 Test Loss: 0.0876178\n",
      "Validation loss decreased (0.086791 --> 0.084986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842540\n",
      "\tspeed: 0.0369s/iter; left time: 791.2771s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836375\n",
      "\tspeed: 0.0172s/iter; left time: 367.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0860014 Vali Loss: 0.0839167 Test Loss: 0.0870948\n",
      "Validation loss decreased (0.084986 --> 0.083917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878106\n",
      "\tspeed: 0.0361s/iter; left time: 764.7688s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826082\n",
      "\tspeed: 0.0166s/iter; left time: 349.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0842845 Vali Loss: 0.0834434 Test Loss: 0.0865216\n",
      "Validation loss decreased (0.083917 --> 0.083443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0829514\n",
      "\tspeed: 0.0396s/iter; left time: 830.7115s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800144\n",
      "\tspeed: 0.0176s/iter; left time: 368.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0830598 Vali Loss: 0.0831548 Test Loss: 0.0866774\n",
      "Validation loss decreased (0.083443 --> 0.083155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0819800\n",
      "\tspeed: 0.0447s/iter; left time: 928.2452s\n",
      "\titers: 200, epoch: 7 | loss: 0.0816035\n",
      "\tspeed: 0.0203s/iter; left time: 418.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0820256 Vali Loss: 0.0824952 Test Loss: 0.0866495\n",
      "Validation loss decreased (0.083155 --> 0.082495).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774417\n",
      "\tspeed: 0.0408s/iter; left time: 839.0354s\n",
      "\titers: 200, epoch: 8 | loss: 0.0815069\n",
      "\tspeed: 0.0204s/iter; left time: 417.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0811775 Vali Loss: 0.0824350 Test Loss: 0.0868916\n",
      "Validation loss decreased (0.082495 --> 0.082435).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795188\n",
      "\tspeed: 0.0395s/iter; left time: 802.4357s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800427\n",
      "\tspeed: 0.0175s/iter; left time: 354.2029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0803991 Vali Loss: 0.0822061 Test Loss: 0.0870736\n",
      "Validation loss decreased (0.082435 --> 0.082206).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0786815\n",
      "\tspeed: 0.0403s/iter; left time: 810.8257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0799806\n",
      "\tspeed: 0.0178s/iter; left time: 355.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0797950 Vali Loss: 0.0823512 Test Loss: 0.0870933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773146\n",
      "\tspeed: 0.0390s/iter; left time: 775.8410s\n",
      "\titers: 200, epoch: 11 | loss: 0.0775672\n",
      "\tspeed: 0.0212s/iter; left time: 418.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0792294 Vali Loss: 0.0822670 Test Loss: 0.0872804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0768763\n",
      "\tspeed: 0.0390s/iter; left time: 765.9677s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775509\n",
      "\tspeed: 0.0151s/iter; left time: 294.6034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0786548 Vali Loss: 0.0821998 Test Loss: 0.0874658\n",
      "Validation loss decreased (0.082206 --> 0.082200).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0765423\n",
      "\tspeed: 0.0427s/iter; left time: 830.4492s\n",
      "\titers: 200, epoch: 13 | loss: 0.0733127\n",
      "\tspeed: 0.0176s/iter; left time: 340.8168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0782090 Vali Loss: 0.0822336 Test Loss: 0.0874937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779215\n",
      "\tspeed: 0.0345s/iter; left time: 662.9610s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762614\n",
      "\tspeed: 0.0177s/iter; left time: 337.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0778680 Vali Loss: 0.0824925 Test Loss: 0.0876414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790489\n",
      "\tspeed: 0.0326s/iter; left time: 619.9857s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753192\n",
      "\tspeed: 0.0168s/iter; left time: 316.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 222 | Train Loss: 0.0775088 Vali Loss: 0.0822421 Test Loss: 0.0876591\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789232\n",
      "\tspeed: 0.0366s/iter; left time: 686.4678s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763271\n",
      "\tspeed: 0.0218s/iter; left time: 406.1038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0771489 Vali Loss: 0.0820594 Test Loss: 0.0878380\n",
      "Validation loss decreased (0.082200 --> 0.082059).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0762497\n",
      "\tspeed: 0.0406s/iter; left time: 752.2853s\n",
      "\titers: 200, epoch: 17 | loss: 0.0743699\n",
      "\tspeed: 0.0182s/iter; left time: 336.3023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0768502 Vali Loss: 0.0820484 Test Loss: 0.0879283\n",
      "Validation loss decreased (0.082059 --> 0.082048).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0770328\n",
      "\tspeed: 0.0431s/iter; left time: 789.5588s\n",
      "\titers: 200, epoch: 18 | loss: 0.0743557\n",
      "\tspeed: 0.0205s/iter; left time: 373.7829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0766060 Vali Loss: 0.0820828 Test Loss: 0.0878034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0768865\n",
      "\tspeed: 0.0421s/iter; left time: 762.0062s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760066\n",
      "\tspeed: 0.0203s/iter; left time: 365.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0764403 Vali Loss: 0.0823880 Test Loss: 0.0880246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0750059\n",
      "\tspeed: 0.0397s/iter; left time: 710.6742s\n",
      "\titers: 200, epoch: 20 | loss: 0.0737242\n",
      "\tspeed: 0.0175s/iter; left time: 311.2240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0761727 Vali Loss: 0.0822698 Test Loss: 0.0881581\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0772035\n",
      "\tspeed: 0.0364s/iter; left time: 643.2837s\n",
      "\titers: 200, epoch: 21 | loss: 0.0769025\n",
      "\tspeed: 0.0173s/iter; left time: 303.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0759846 Vali Loss: 0.0822420 Test Loss: 0.0879624\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747891\n",
      "\tspeed: 0.0322s/iter; left time: 562.2678s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747228\n",
      "\tspeed: 0.0147s/iter; left time: 255.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 222 | Train Loss: 0.0757410 Vali Loss: 0.0823883 Test Loss: 0.0882011\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0726893\n",
      "\tspeed: 0.0373s/iter; left time: 641.9917s\n",
      "\titers: 200, epoch: 23 | loss: 0.0734958\n",
      "\tspeed: 0.0182s/iter; left time: 310.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0756528 Vali Loss: 0.0825400 Test Loss: 0.0881473\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0737475\n",
      "\tspeed: 0.0363s/iter; left time: 617.0124s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759268\n",
      "\tspeed: 0.0190s/iter; left time: 320.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0754443 Vali Loss: 0.0828874 Test Loss: 0.0881508\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0743462\n",
      "\tspeed: 0.0424s/iter; left time: 710.4827s\n",
      "\titers: 200, epoch: 25 | loss: 0.0731567\n",
      "\tspeed: 0.0197s/iter; left time: 328.2386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0753598 Vali Loss: 0.0825872 Test Loss: 0.0881039\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0768582\n",
      "\tspeed: 0.0439s/iter; left time: 725.8515s\n",
      "\titers: 200, epoch: 26 | loss: 0.0737997\n",
      "\tspeed: 0.0168s/iter; left time: 276.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0752374 Vali Loss: 0.0828212 Test Loss: 0.0882001\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0745803\n",
      "\tspeed: 0.0374s/iter; left time: 610.8256s\n",
      "\titers: 200, epoch: 27 | loss: 0.0746478\n",
      "\tspeed: 0.0183s/iter; left time: 297.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0751304 Vali Loss: 0.0828184 Test Loss: 0.0882027\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020889976993203163, rmse:0.1445336490869522, mae:0.08792824298143387, rse:0.5470051765441895\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1561929\n",
      "\tspeed: 0.0233s/iter; left time: 514.5005s\n",
      "\titers: 200, epoch: 1 | loss: 0.1332895\n",
      "\tspeed: 0.0188s/iter; left time: 413.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.1582038 Vali Loss: 0.1151954 Test Loss: 0.1168885\n",
      "Validation loss decreased (inf --> 0.115195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0999831\n",
      "\tspeed: 0.0441s/iter; left time: 964.7421s\n",
      "\titers: 200, epoch: 2 | loss: 0.0900242\n",
      "\tspeed: 0.0194s/iter; left time: 422.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1003476 Vali Loss: 0.0870494 Test Loss: 0.0899166\n",
      "Validation loss decreased (0.115195 --> 0.087049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0898099\n",
      "\tspeed: 0.0508s/iter; left time: 1100.8903s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893715\n",
      "\tspeed: 0.0158s/iter; left time: 339.9433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0889001 Vali Loss: 0.0850172 Test Loss: 0.0876961\n",
      "Validation loss decreased (0.087049 --> 0.085017).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855390\n",
      "\tspeed: 0.0442s/iter; left time: 946.4871s\n",
      "\titers: 200, epoch: 4 | loss: 0.0884911\n",
      "\tspeed: 0.0142s/iter; left time: 303.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0859274 Vali Loss: 0.0841143 Test Loss: 0.0874824\n",
      "Validation loss decreased (0.085017 --> 0.084114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821658\n",
      "\tspeed: 0.0434s/iter; left time: 921.4996s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827167\n",
      "\tspeed: 0.0200s/iter; left time: 423.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0841874 Vali Loss: 0.0836332 Test Loss: 0.0871012\n",
      "Validation loss decreased (0.084114 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0825866\n",
      "\tspeed: 0.0404s/iter; left time: 847.0191s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813892\n",
      "\tspeed: 0.0138s/iter; left time: 288.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0828479 Vali Loss: 0.0831578 Test Loss: 0.0870840\n",
      "Validation loss decreased (0.083633 --> 0.083158).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0827411\n",
      "\tspeed: 0.0466s/iter; left time: 967.7903s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774040\n",
      "\tspeed: 0.0220s/iter; left time: 453.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 222 | Train Loss: 0.0818339 Vali Loss: 0.0833448 Test Loss: 0.0871060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0827025\n",
      "\tspeed: 0.0427s/iter; left time: 878.2782s\n",
      "\titers: 200, epoch: 8 | loss: 0.0804649\n",
      "\tspeed: 0.0215s/iter; left time: 439.9193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0809391 Vali Loss: 0.0826941 Test Loss: 0.0870640\n",
      "Validation loss decreased (0.083158 --> 0.082694).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0828826\n",
      "\tspeed: 0.0411s/iter; left time: 836.0154s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779737\n",
      "\tspeed: 0.0203s/iter; left time: 411.0310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0802574 Vali Loss: 0.0831513 Test Loss: 0.0876771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0780620\n",
      "\tspeed: 0.0380s/iter; left time: 763.9509s\n",
      "\titers: 200, epoch: 10 | loss: 0.0802324\n",
      "\tspeed: 0.0177s/iter; left time: 354.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0795079 Vali Loss: 0.0828169 Test Loss: 0.0875696\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0794836\n",
      "\tspeed: 0.0412s/iter; left time: 818.1940s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756611\n",
      "\tspeed: 0.0175s/iter; left time: 346.4758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0788920 Vali Loss: 0.0830490 Test Loss: 0.0875587\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0751350\n",
      "\tspeed: 0.0400s/iter; left time: 786.8514s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785783\n",
      "\tspeed: 0.0183s/iter; left time: 356.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0783920 Vali Loss: 0.0830297 Test Loss: 0.0880364\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0786314\n",
      "\tspeed: 0.0376s/iter; left time: 731.5936s\n",
      "\titers: 200, epoch: 13 | loss: 0.0812047\n",
      "\tspeed: 0.0166s/iter; left time: 320.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0778880 Vali Loss: 0.0826431 Test Loss: 0.0878088\n",
      "Validation loss decreased (0.082694 --> 0.082643).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0741372\n",
      "\tspeed: 0.0389s/iter; left time: 747.9181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0792787\n",
      "\tspeed: 0.0178s/iter; left time: 340.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0774693 Vali Loss: 0.0830399 Test Loss: 0.0879610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778458\n",
      "\tspeed: 0.0426s/iter; left time: 809.7898s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763431\n",
      "\tspeed: 0.0199s/iter; left time: 376.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0771448 Vali Loss: 0.0830153 Test Loss: 0.0879107\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782199\n",
      "\tspeed: 0.0412s/iter; left time: 773.7360s\n",
      "\titers: 200, epoch: 16 | loss: 0.0785109\n",
      "\tspeed: 0.0174s/iter; left time: 324.8697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0767155 Vali Loss: 0.0832598 Test Loss: 0.0881204\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777831\n",
      "\tspeed: 0.0391s/iter; left time: 724.6554s\n",
      "\titers: 200, epoch: 17 | loss: 0.0776070\n",
      "\tspeed: 0.0184s/iter; left time: 338.5877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0764665 Vali Loss: 0.0834128 Test Loss: 0.0881967\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0777894\n",
      "\tspeed: 0.0370s/iter; left time: 678.8411s\n",
      "\titers: 200, epoch: 18 | loss: 0.0784742\n",
      "\tspeed: 0.0166s/iter; left time: 303.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0762101 Vali Loss: 0.0835959 Test Loss: 0.0880539\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0771491\n",
      "\tspeed: 0.0385s/iter; left time: 696.5961s\n",
      "\titers: 200, epoch: 19 | loss: 0.0752347\n",
      "\tspeed: 0.0141s/iter; left time: 254.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0758418 Vali Loss: 0.0832237 Test Loss: 0.0882843\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0776931\n",
      "\tspeed: 0.0357s/iter; left time: 637.8333s\n",
      "\titers: 200, epoch: 20 | loss: 0.0713874\n",
      "\tspeed: 0.0138s/iter; left time: 245.5743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 222 | Train Loss: 0.0756150 Vali Loss: 0.0835871 Test Loss: 0.0882557\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0746432\n",
      "\tspeed: 0.0335s/iter; left time: 592.2414s\n",
      "\titers: 200, epoch: 21 | loss: 0.0757268\n",
      "\tspeed: 0.0179s/iter; left time: 313.5504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0754327 Vali Loss: 0.0834544 Test Loss: 0.0883727\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747342\n",
      "\tspeed: 0.0383s/iter; left time: 668.2026s\n",
      "\titers: 200, epoch: 22 | loss: 0.0749737\n",
      "\tspeed: 0.0174s/iter; left time: 301.5095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0752481 Vali Loss: 0.0832728 Test Loss: 0.0882992\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0739278\n",
      "\tspeed: 0.0380s/iter; left time: 654.3458s\n",
      "\titers: 200, epoch: 23 | loss: 0.0763191\n",
      "\tspeed: 0.0173s/iter; left time: 296.1428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0750705 Vali Loss: 0.0835554 Test Loss: 0.0882526\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020881883800029755, rmse:0.14450564980506897, mae:0.08780878037214279, rse:0.5468991994857788\n",
      "Intermediate time for IT and pred_len 168: 00h:05m:00.45s\n",
      "Intermediate time for IT: 00h:21m:44.05s\n",
      "Total time: 01h:35m:40.10s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1466  0.0902\n",
       "        96        0.0392  0.1978  0.1303\n",
       "        168       0.0418  0.2043  0.1370\n",
       "ES      24        0.0109  0.1042  0.0654\n",
       "        96        0.0211  0.1450  0.0960\n",
       "        168       0.0249  0.1572  0.1052\n",
       "FR      24        0.0105  0.1026  0.0580\n",
       "        96        0.0201  0.1419  0.0828\n",
       "        168       0.0225  0.1498  0.0883\n",
       "GB      24        0.0265  0.1626  0.1037\n",
       "        96        0.0429  0.2072  0.1420\n",
       "        168       0.0454  0.2130  0.1486\n",
       "IT      24        0.0104  0.1020  0.0594\n",
       "        96        0.0188  0.1371  0.0832\n",
       "        168       0.0203  0.1425  0.0880"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2551474\n",
      "\tspeed: 0.0459s/iter; left time: 1018.0444s\n",
      "\titers: 200, epoch: 1 | loss: 0.2432507\n",
      "\tspeed: 0.0201s/iter; left time: 445.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.2668637 Vali Loss: 0.2238720 Test Loss: 0.2261513\n",
      "Validation loss decreased (inf --> 0.223872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1460399\n",
      "\tspeed: 0.0449s/iter; left time: 986.5072s\n",
      "\titers: 200, epoch: 2 | loss: 0.1216822\n",
      "\tspeed: 0.0203s/iter; left time: 443.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.1540140 Vali Loss: 0.1182901 Test Loss: 0.1211827\n",
      "Validation loss decreased (0.223872 --> 0.118290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1031451\n",
      "\tspeed: 0.0425s/iter; left time: 924.8917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0994028\n",
      "\tspeed: 0.0203s/iter; left time: 438.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.1050465 Vali Loss: 0.1039644 Test Loss: 0.1058513\n",
      "Validation loss decreased (0.118290 --> 0.103964).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0926209\n",
      "\tspeed: 0.0427s/iter; left time: 919.1911s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939199\n",
      "\tspeed: 0.0201s/iter; left time: 429.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0937571 Vali Loss: 0.1005288 Test Loss: 0.1036960\n",
      "Validation loss decreased (0.103964 --> 0.100529).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850811\n",
      "\tspeed: 0.0422s/iter; left time: 900.2106s\n",
      "\titers: 200, epoch: 5 | loss: 0.0833859\n",
      "\tspeed: 0.0210s/iter; left time: 444.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0885040 Vali Loss: 0.0979386 Test Loss: 0.1008237\n",
      "Validation loss decreased (0.100529 --> 0.097939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0871982\n",
      "\tspeed: 0.0442s/iter; left time: 932.0331s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802622\n",
      "\tspeed: 0.0208s/iter; left time: 436.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0855585 Vali Loss: 0.0960701 Test Loss: 0.0991458\n",
      "Validation loss decreased (0.097939 --> 0.096070).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0858348\n",
      "\tspeed: 0.0455s/iter; left time: 949.2762s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834494\n",
      "\tspeed: 0.0226s/iter; left time: 469.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0836893 Vali Loss: 0.0947459 Test Loss: 0.0976809\n",
      "Validation loss decreased (0.096070 --> 0.094746).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0848817\n",
      "\tspeed: 0.0442s/iter; left time: 911.6917s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845404\n",
      "\tspeed: 0.0203s/iter; left time: 416.5580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0825642 Vali Loss: 0.0944185 Test Loss: 0.0969981\n",
      "Validation loss decreased (0.094746 --> 0.094418).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0807175\n",
      "\tspeed: 0.0429s/iter; left time: 875.6897s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817962\n",
      "\tspeed: 0.0202s/iter; left time: 411.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0816720 Vali Loss: 0.0936054 Test Loss: 0.0966767\n",
      "Validation loss decreased (0.094418 --> 0.093605).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0784829\n",
      "\tspeed: 0.0434s/iter; left time: 875.5609s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803997\n",
      "\tspeed: 0.0205s/iter; left time: 411.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0807184 Vali Loss: 0.0934066 Test Loss: 0.0967435\n",
      "Validation loss decreased (0.093605 --> 0.093407).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819594\n",
      "\tspeed: 0.0444s/iter; left time: 887.6285s\n",
      "\titers: 200, epoch: 11 | loss: 0.0865497\n",
      "\tspeed: 0.0212s/iter; left time: 421.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0801734 Vali Loss: 0.0931065 Test Loss: 0.0961571\n",
      "Validation loss decreased (0.093407 --> 0.093107).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0791169\n",
      "\tspeed: 0.0428s/iter; left time: 844.5598s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787896\n",
      "\tspeed: 0.0231s/iter; left time: 453.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0795977 Vali Loss: 0.0921469 Test Loss: 0.0951979\n",
      "Validation loss decreased (0.093107 --> 0.092147).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847492\n",
      "\tspeed: 0.0444s/iter; left time: 866.9641s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785450\n",
      "\tspeed: 0.0203s/iter; left time: 394.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0789553 Vali Loss: 0.0926504 Test Loss: 0.0946430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0829063\n",
      "\tspeed: 0.0428s/iter; left time: 826.0486s\n",
      "\titers: 200, epoch: 14 | loss: 0.0806567\n",
      "\tspeed: 0.0207s/iter; left time: 397.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0787015 Vali Loss: 0.0915155 Test Loss: 0.0943696\n",
      "Validation loss decreased (0.092147 --> 0.091516).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0762333\n",
      "\tspeed: 0.0454s/iter; left time: 865.3069s\n",
      "\titers: 200, epoch: 15 | loss: 0.0717894\n",
      "\tspeed: 0.0206s/iter; left time: 391.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0784450 Vali Loss: 0.0928697 Test Loss: 0.0947774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0849216\n",
      "\tspeed: 0.0445s/iter; left time: 838.6607s\n",
      "\titers: 200, epoch: 16 | loss: 0.0702852\n",
      "\tspeed: 0.0208s/iter; left time: 390.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0778535 Vali Loss: 0.0908958 Test Loss: 0.0936488\n",
      "Validation loss decreased (0.091516 --> 0.090896).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0746360\n",
      "\tspeed: 0.0483s/iter; left time: 900.4128s\n",
      "\titers: 200, epoch: 17 | loss: 0.0754247\n",
      "\tspeed: 0.0215s/iter; left time: 398.3855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0778101 Vali Loss: 0.0920660 Test Loss: 0.0938107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0796930\n",
      "\tspeed: 0.0437s/iter; left time: 805.2274s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769788\n",
      "\tspeed: 0.0202s/iter; left time: 369.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0775739 Vali Loss: 0.0911418 Test Loss: 0.0939341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0831764\n",
      "\tspeed: 0.0417s/iter; left time: 759.0600s\n",
      "\titers: 200, epoch: 19 | loss: 0.0808170\n",
      "\tspeed: 0.0201s/iter; left time: 363.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0774244 Vali Loss: 0.0907504 Test Loss: 0.0931982\n",
      "Validation loss decreased (0.090896 --> 0.090750).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0716149\n",
      "\tspeed: 0.0427s/iter; left time: 767.8783s\n",
      "\titers: 200, epoch: 20 | loss: 0.0760816\n",
      "\tspeed: 0.0202s/iter; left time: 361.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0772027 Vali Loss: 0.0906361 Test Loss: 0.0929811\n",
      "Validation loss decreased (0.090750 --> 0.090636).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749635\n",
      "\tspeed: 0.0440s/iter; left time: 780.2071s\n",
      "\titers: 200, epoch: 21 | loss: 0.0808887\n",
      "\tspeed: 0.0241s/iter; left time: 424.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0770270 Vali Loss: 0.0912815 Test Loss: 0.0931846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0787776\n",
      "\tspeed: 0.0467s/iter; left time: 818.6210s\n",
      "\titers: 200, epoch: 22 | loss: 0.0730315\n",
      "\tspeed: 0.0250s/iter; left time: 435.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0768111 Vali Loss: 0.0906218 Test Loss: 0.0928346\n",
      "Validation loss decreased (0.090636 --> 0.090622).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767148\n",
      "\tspeed: 0.0439s/iter; left time: 760.0709s\n",
      "\titers: 200, epoch: 23 | loss: 0.0704466\n",
      "\tspeed: 0.0207s/iter; left time: 355.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0768343 Vali Loss: 0.0902418 Test Loss: 0.0928105\n",
      "Validation loss decreased (0.090622 --> 0.090242).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0786109\n",
      "\tspeed: 0.0472s/iter; left time: 805.6535s\n",
      "\titers: 200, epoch: 24 | loss: 0.0816796\n",
      "\tspeed: 0.0203s/iter; left time: 344.5657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0768173 Vali Loss: 0.0915265 Test Loss: 0.0935371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0799610\n",
      "\tspeed: 0.0427s/iter; left time: 719.4588s\n",
      "\titers: 200, epoch: 25 | loss: 0.0757982\n",
      "\tspeed: 0.0252s/iter; left time: 422.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0765245 Vali Loss: 0.0903133 Test Loss: 0.0926046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0829906\n",
      "\tspeed: 0.0434s/iter; left time: 720.9500s\n",
      "\titers: 200, epoch: 26 | loss: 0.0752078\n",
      "\tspeed: 0.0207s/iter; left time: 342.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0767063 Vali Loss: 0.0907616 Test Loss: 0.0928094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0766492\n",
      "\tspeed: 0.0433s/iter; left time: 709.5858s\n",
      "\titers: 200, epoch: 27 | loss: 0.0786701\n",
      "\tspeed: 0.0208s/iter; left time: 338.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0764181 Vali Loss: 0.0901262 Test Loss: 0.0925877\n",
      "Validation loss decreased (0.090242 --> 0.090126).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0784914\n",
      "\tspeed: 0.0474s/iter; left time: 766.7646s\n",
      "\titers: 200, epoch: 28 | loss: 0.0745633\n",
      "\tspeed: 0.0215s/iter; left time: 345.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0764216 Vali Loss: 0.0901526 Test Loss: 0.0923966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0747117\n",
      "\tspeed: 0.0445s/iter; left time: 710.1630s\n",
      "\titers: 200, epoch: 29 | loss: 0.0750493\n",
      "\tspeed: 0.0232s/iter; left time: 367.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0762765 Vali Loss: 0.0906515 Test Loss: 0.0927716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733853\n",
      "\tspeed: 0.0426s/iter; left time: 670.0673s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688315\n",
      "\tspeed: 0.0203s/iter; left time: 317.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0762149 Vali Loss: 0.0904111 Test Loss: 0.0925728\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0777000\n",
      "\tspeed: 0.0423s/iter; left time: 655.7932s\n",
      "\titers: 200, epoch: 31 | loss: 0.0803295\n",
      "\tspeed: 0.0203s/iter; left time: 312.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0762395 Vali Loss: 0.0902504 Test Loss: 0.0925031\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0813218\n",
      "\tspeed: 0.0423s/iter; left time: 646.8656s\n",
      "\titers: 200, epoch: 32 | loss: 0.0807492\n",
      "\tspeed: 0.0228s/iter; left time: 346.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0762469 Vali Loss: 0.0904030 Test Loss: 0.0924835\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0759100\n",
      "\tspeed: 0.0425s/iter; left time: 640.1203s\n",
      "\titers: 200, epoch: 33 | loss: 0.0789927\n",
      "\tspeed: 0.0201s/iter; left time: 300.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0760764 Vali Loss: 0.0904389 Test Loss: 0.0925347\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0766042\n",
      "\tspeed: 0.0468s/iter; left time: 694.9628s\n",
      "\titers: 200, epoch: 34 | loss: 0.0764266\n",
      "\tspeed: 0.0246s/iter; left time: 362.4161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 223 | Train Loss: 0.0760347 Vali Loss: 0.0900640 Test Loss: 0.0923488\n",
      "Validation loss decreased (0.090126 --> 0.090064).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0786287\n",
      "\tspeed: 0.0439s/iter; left time: 642.2215s\n",
      "\titers: 200, epoch: 35 | loss: 0.0746180\n",
      "\tspeed: 0.0202s/iter; left time: 293.7828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0761513 Vali Loss: 0.0902407 Test Loss: 0.0924330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0749169\n",
      "\tspeed: 0.0455s/iter; left time: 655.5729s\n",
      "\titers: 200, epoch: 36 | loss: 0.0796616\n",
      "\tspeed: 0.0203s/iter; left time: 290.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0759159 Vali Loss: 0.0899827 Test Loss: 0.0923898\n",
      "Validation loss decreased (0.090064 --> 0.089983).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0782966\n",
      "\tspeed: 0.0428s/iter; left time: 606.6552s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751562\n",
      "\tspeed: 0.0202s/iter; left time: 284.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0760409 Vali Loss: 0.0900562 Test Loss: 0.0924457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0712603\n",
      "\tspeed: 0.0446s/iter; left time: 622.4312s\n",
      "\titers: 200, epoch: 38 | loss: 0.0760157\n",
      "\tspeed: 0.0215s/iter; left time: 298.0179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0759507 Vali Loss: 0.0900844 Test Loss: 0.0923730\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0731397\n",
      "\tspeed: 0.0433s/iter; left time: 595.0386s\n",
      "\titers: 200, epoch: 39 | loss: 0.0794201\n",
      "\tspeed: 0.0208s/iter; left time: 283.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0759710 Vali Loss: 0.0901734 Test Loss: 0.0923374\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0817736\n",
      "\tspeed: 0.0424s/iter; left time: 573.2067s\n",
      "\titers: 200, epoch: 40 | loss: 0.0793654\n",
      "\tspeed: 0.0200s/iter; left time: 268.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0758759 Vali Loss: 0.0899806 Test Loss: 0.0922941\n",
      "Validation loss decreased (0.089983 --> 0.089981).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0760485\n",
      "\tspeed: 0.0422s/iter; left time: 560.8135s\n",
      "\titers: 200, epoch: 41 | loss: 0.0804850\n",
      "\tspeed: 0.0201s/iter; left time: 264.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0759402 Vali Loss: 0.0901777 Test Loss: 0.0923692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0706304\n",
      "\tspeed: 0.0427s/iter; left time: 557.0304s\n",
      "\titers: 200, epoch: 42 | loss: 0.0729233\n",
      "\tspeed: 0.0205s/iter; left time: 265.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0759457 Vali Loss: 0.0904252 Test Loss: 0.0925111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0790886\n",
      "\tspeed: 0.0464s/iter; left time: 596.1048s\n",
      "\titers: 200, epoch: 43 | loss: 0.0814318\n",
      "\tspeed: 0.0231s/iter; left time: 294.6488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0759084 Vali Loss: 0.0899477 Test Loss: 0.0922394\n",
      "Validation loss decreased (0.089981 --> 0.089948).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0786488\n",
      "\tspeed: 0.0422s/iter; left time: 532.8411s\n",
      "\titers: 200, epoch: 44 | loss: 0.0755523\n",
      "\tspeed: 0.0200s/iter; left time: 250.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0757828 Vali Loss: 0.0901779 Test Loss: 0.0923653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0733363\n",
      "\tspeed: 0.0416s/iter; left time: 515.3320s\n",
      "\titers: 200, epoch: 45 | loss: 0.0768012\n",
      "\tspeed: 0.0202s/iter; left time: 248.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0758640 Vali Loss: 0.0898905 Test Loss: 0.0922444\n",
      "Validation loss decreased (0.089948 --> 0.089891).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0751334\n",
      "\tspeed: 0.0423s/iter; left time: 514.0824s\n",
      "\titers: 200, epoch: 46 | loss: 0.0761013\n",
      "\tspeed: 0.0220s/iter; left time: 265.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0758378 Vali Loss: 0.0901122 Test Loss: 0.0922677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0758792\n",
      "\tspeed: 0.0421s/iter; left time: 502.7535s\n",
      "\titers: 200, epoch: 47 | loss: 0.0769830\n",
      "\tspeed: 0.0205s/iter; left time: 242.6360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0758577 Vali Loss: 0.0898865 Test Loss: 0.0922733\n",
      "Validation loss decreased (0.089891 --> 0.089886).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0755687\n",
      "\tspeed: 0.0429s/iter; left time: 502.6961s\n",
      "\titers: 200, epoch: 48 | loss: 0.0684738\n",
      "\tspeed: 0.0213s/iter; left time: 247.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0758337 Vali Loss: 0.0901259 Test Loss: 0.0923032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0780505\n",
      "\tspeed: 0.0424s/iter; left time: 487.5371s\n",
      "\titers: 200, epoch: 49 | loss: 0.0805702\n",
      "\tspeed: 0.0212s/iter; left time: 241.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0757781 Vali Loss: 0.0902890 Test Loss: 0.0924151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0776887\n",
      "\tspeed: 0.0432s/iter; left time: 487.4987s\n",
      "\titers: 200, epoch: 50 | loss: 0.0776037\n",
      "\tspeed: 0.0203s/iter; left time: 226.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0758782 Vali Loss: 0.0899573 Test Loss: 0.0922979\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0753882\n",
      "\tspeed: 0.0427s/iter; left time: 472.1626s\n",
      "\titers: 200, epoch: 51 | loss: 0.0724134\n",
      "\tspeed: 0.0208s/iter; left time: 227.2989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0757393 Vali Loss: 0.0902660 Test Loss: 0.0922951\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0755895\n",
      "\tspeed: 0.0433s/iter; left time: 468.8097s\n",
      "\titers: 200, epoch: 52 | loss: 0.0731984\n",
      "\tspeed: 0.0202s/iter; left time: 217.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0757159 Vali Loss: 0.0901273 Test Loss: 0.0922962\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0751628\n",
      "\tspeed: 0.0453s/iter; left time: 479.9597s\n",
      "\titers: 200, epoch: 53 | loss: 0.0780671\n",
      "\tspeed: 0.0209s/iter; left time: 219.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0758241 Vali Loss: 0.0900409 Test Loss: 0.0922524\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0734993\n",
      "\tspeed: 0.0426s/iter; left time: 441.9782s\n",
      "\titers: 200, epoch: 54 | loss: 0.0789594\n",
      "\tspeed: 0.0206s/iter; left time: 211.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0758112 Vali Loss: 0.0901230 Test Loss: 0.0922837\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0770739\n",
      "\tspeed: 0.0438s/iter; left time: 445.2844s\n",
      "\titers: 200, epoch: 55 | loss: 0.0766134\n",
      "\tspeed: 0.0206s/iter; left time: 207.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0756895 Vali Loss: 0.0897605 Test Loss: 0.0921850\n",
      "Validation loss decreased (0.089886 --> 0.089760).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0714346\n",
      "\tspeed: 0.0428s/iter; left time: 425.2094s\n",
      "\titers: 200, epoch: 56 | loss: 0.0775620\n",
      "\tspeed: 0.0205s/iter; left time: 202.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0757827 Vali Loss: 0.0898352 Test Loss: 0.0922000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0780214\n",
      "\tspeed: 0.0427s/iter; left time: 414.6680s\n",
      "\titers: 200, epoch: 57 | loss: 0.0744787\n",
      "\tspeed: 0.0204s/iter; left time: 196.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0758389 Vali Loss: 0.0899776 Test Loss: 0.0922067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0730577\n",
      "\tspeed: 0.0434s/iter; left time: 411.7772s\n",
      "\titers: 200, epoch: 58 | loss: 0.0724419\n",
      "\tspeed: 0.0200s/iter; left time: 187.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0758324 Vali Loss: 0.0902179 Test Loss: 0.0923441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0772266\n",
      "\tspeed: 0.0414s/iter; left time: 383.3724s\n",
      "\titers: 200, epoch: 59 | loss: 0.0724157\n",
      "\tspeed: 0.0201s/iter; left time: 184.1908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0758184 Vali Loss: 0.0899658 Test Loss: 0.0922477\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0779026\n",
      "\tspeed: 0.0422s/iter; left time: 381.2483s\n",
      "\titers: 200, epoch: 60 | loss: 0.0778434\n",
      "\tspeed: 0.0235s/iter; left time: 209.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0757282 Vali Loss: 0.0900866 Test Loss: 0.0923297\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0761693\n",
      "\tspeed: 0.0422s/iter; left time: 372.0031s\n",
      "\titers: 200, epoch: 61 | loss: 0.0769647\n",
      "\tspeed: 0.0207s/iter; left time: 180.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0757709 Vali Loss: 0.0900442 Test Loss: 0.0923081\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0724088\n",
      "\tspeed: 0.0422s/iter; left time: 362.5111s\n",
      "\titers: 200, epoch: 62 | loss: 0.0770181\n",
      "\tspeed: 0.0200s/iter; left time: 169.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0757130 Vali Loss: 0.0899358 Test Loss: 0.0922996\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0824577\n",
      "\tspeed: 0.0418s/iter; left time: 350.3825s\n",
      "\titers: 200, epoch: 63 | loss: 0.0750519\n",
      "\tspeed: 0.0201s/iter; left time: 166.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0757345 Vali Loss: 0.0898351 Test Loss: 0.0921792\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0733577\n",
      "\tspeed: 0.0410s/iter; left time: 333.8501s\n",
      "\titers: 200, epoch: 64 | loss: 0.0708779\n",
      "\tspeed: 0.0201s/iter; left time: 162.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0757627 Vali Loss: 0.0899927 Test Loss: 0.0922466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0763176\n",
      "\tspeed: 0.0419s/iter; left time: 332.2810s\n",
      "\titers: 200, epoch: 65 | loss: 0.0740640\n",
      "\tspeed: 0.0203s/iter; left time: 158.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0756659 Vali Loss: 0.0900139 Test Loss: 0.0922281\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021770920604467392, rmse:0.14754971861839294, mae:0.09218499064445496, rse:0.5207234025001526\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2690482\n",
      "\tspeed: 0.0238s/iter; left time: 528.3241s\n",
      "\titers: 200, epoch: 1 | loss: 0.2657327\n",
      "\tspeed: 0.0202s/iter; left time: 445.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.2704633 Vali Loss: 0.2223115 Test Loss: 0.2248250\n",
      "Validation loss decreased (inf --> 0.222311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482837\n",
      "\tspeed: 0.0469s/iter; left time: 1031.7474s\n",
      "\titers: 200, epoch: 2 | loss: 0.1158016\n",
      "\tspeed: 0.0209s/iter; left time: 457.0043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.1525808 Vali Loss: 0.1137699 Test Loss: 0.1151182\n",
      "Validation loss decreased (0.222311 --> 0.113770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056265\n",
      "\tspeed: 0.0457s/iter; left time: 994.9609s\n",
      "\titers: 200, epoch: 3 | loss: 0.1027019\n",
      "\tspeed: 0.0206s/iter; left time: 446.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.1028301 Vali Loss: 0.1022478 Test Loss: 0.1034218\n",
      "Validation loss decreased (0.113770 --> 0.102248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0959680\n",
      "\tspeed: 0.0440s/iter; left time: 948.1110s\n",
      "\titers: 200, epoch: 4 | loss: 0.0917668\n",
      "\tspeed: 0.0203s/iter; left time: 434.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0926323 Vali Loss: 0.1012006 Test Loss: 0.1035642\n",
      "Validation loss decreased (0.102248 --> 0.101201).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895127\n",
      "\tspeed: 0.0439s/iter; left time: 935.9115s\n",
      "\titers: 200, epoch: 5 | loss: 0.0910337\n",
      "\tspeed: 0.0231s/iter; left time: 488.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0879356 Vali Loss: 0.1026857 Test Loss: 0.1047157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0865112\n",
      "\tspeed: 0.0434s/iter; left time: 914.8798s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826559\n",
      "\tspeed: 0.0201s/iter; left time: 422.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0855119 Vali Loss: 0.0961093 Test Loss: 0.0984576\n",
      "Validation loss decreased (0.101201 --> 0.096109).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855684\n",
      "\tspeed: 0.0448s/iter; left time: 934.5104s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826875\n",
      "\tspeed: 0.0200s/iter; left time: 414.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0836208 Vali Loss: 0.0949075 Test Loss: 0.0979425\n",
      "Validation loss decreased (0.096109 --> 0.094907).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0855871\n",
      "\tspeed: 0.0431s/iter; left time: 890.3957s\n",
      "\titers: 200, epoch: 8 | loss: 0.0835874\n",
      "\tspeed: 0.0202s/iter; left time: 415.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0826147 Vali Loss: 0.0944877 Test Loss: 0.0977451\n",
      "Validation loss decreased (0.094907 --> 0.094488).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804175\n",
      "\tspeed: 0.0428s/iter; left time: 874.1051s\n",
      "\titers: 200, epoch: 9 | loss: 0.0806948\n",
      "\tspeed: 0.0200s/iter; left time: 405.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0813928 Vali Loss: 0.0938870 Test Loss: 0.0963996\n",
      "Validation loss decreased (0.094488 --> 0.093887).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0782151\n",
      "\tspeed: 0.0452s/iter; left time: 913.1531s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771089\n",
      "\tspeed: 0.0205s/iter; left time: 411.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0809815 Vali Loss: 0.0933232 Test Loss: 0.0965916\n",
      "Validation loss decreased (0.093887 --> 0.093323).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0837242\n",
      "\tspeed: 0.0431s/iter; left time: 861.5832s\n",
      "\titers: 200, epoch: 11 | loss: 0.0726382\n",
      "\tspeed: 0.0203s/iter; left time: 402.8738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0801455 Vali Loss: 0.0934604 Test Loss: 0.0958622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754714\n",
      "\tspeed: 0.0431s/iter; left time: 851.4355s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837562\n",
      "\tspeed: 0.0203s/iter; left time: 397.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0796965 Vali Loss: 0.0922704 Test Loss: 0.0946606\n",
      "Validation loss decreased (0.093323 --> 0.092270).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872200\n",
      "\tspeed: 0.0428s/iter; left time: 836.2228s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782231\n",
      "\tspeed: 0.0207s/iter; left time: 402.9442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0793188 Vali Loss: 0.0918262 Test Loss: 0.0947884\n",
      "Validation loss decreased (0.092270 --> 0.091826).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766850\n",
      "\tspeed: 0.0479s/iter; left time: 925.2842s\n",
      "\titers: 200, epoch: 14 | loss: 0.0802228\n",
      "\tspeed: 0.0222s/iter; left time: 425.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0787686 Vali Loss: 0.0916737 Test Loss: 0.0941335\n",
      "Validation loss decreased (0.091826 --> 0.091674).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0821675\n",
      "\tspeed: 0.0431s/iter; left time: 822.3540s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822299\n",
      "\tspeed: 0.0229s/iter; left time: 434.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0783110 Vali Loss: 0.0927818 Test Loss: 0.0945928\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0768079\n",
      "\tspeed: 0.0443s/iter; left time: 834.9768s\n",
      "\titers: 200, epoch: 16 | loss: 0.0720540\n",
      "\tspeed: 0.0201s/iter; left time: 377.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0780134 Vali Loss: 0.0911310 Test Loss: 0.0939451\n",
      "Validation loss decreased (0.091674 --> 0.091131).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0797201\n",
      "\tspeed: 0.0426s/iter; left time: 794.2123s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744011\n",
      "\tspeed: 0.0200s/iter; left time: 370.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0779091 Vali Loss: 0.0909791 Test Loss: 0.0935009\n",
      "Validation loss decreased (0.091131 --> 0.090979).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765691\n",
      "\tspeed: 0.0430s/iter; left time: 792.3533s\n",
      "\titers: 200, epoch: 18 | loss: 0.0816458\n",
      "\tspeed: 0.0201s/iter; left time: 368.4985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0776151 Vali Loss: 0.0909137 Test Loss: 0.0934092\n",
      "Validation loss decreased (0.090979 --> 0.090914).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730380\n",
      "\tspeed: 0.0426s/iter; left time: 774.7026s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760622\n",
      "\tspeed: 0.0200s/iter; left time: 361.2194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0774823 Vali Loss: 0.0913616 Test Loss: 0.0933854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717250\n",
      "\tspeed: 0.0428s/iter; left time: 768.6330s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820573\n",
      "\tspeed: 0.0202s/iter; left time: 361.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0773356 Vali Loss: 0.0905771 Test Loss: 0.0930068\n",
      "Validation loss decreased (0.090914 --> 0.090577).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0793903\n",
      "\tspeed: 0.0428s/iter; left time: 759.6340s\n",
      "\titers: 200, epoch: 21 | loss: 0.0780636\n",
      "\tspeed: 0.0202s/iter; left time: 357.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0771456 Vali Loss: 0.0904109 Test Loss: 0.0928583\n",
      "Validation loss decreased (0.090577 --> 0.090411).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0777267\n",
      "\tspeed: 0.0434s/iter; left time: 760.7087s\n",
      "\titers: 200, epoch: 22 | loss: 0.0722126\n",
      "\tspeed: 0.0201s/iter; left time: 350.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0770543 Vali Loss: 0.0915218 Test Loss: 0.0934001\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0766328\n",
      "\tspeed: 0.0451s/iter; left time: 779.2842s\n",
      "\titers: 200, epoch: 23 | loss: 0.0684822\n",
      "\tspeed: 0.0202s/iter; left time: 347.7565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0768432 Vali Loss: 0.0903650 Test Loss: 0.0926346\n",
      "Validation loss decreased (0.090411 --> 0.090365).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0784689\n",
      "\tspeed: 0.0432s/iter; left time: 737.6686s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759460\n",
      "\tspeed: 0.0200s/iter; left time: 338.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0766120 Vali Loss: 0.0904842 Test Loss: 0.0925846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0746728\n",
      "\tspeed: 0.0429s/iter; left time: 723.2028s\n",
      "\titers: 200, epoch: 25 | loss: 0.0797455\n",
      "\tspeed: 0.0202s/iter; left time: 338.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0766469 Vali Loss: 0.0902146 Test Loss: 0.0926205\n",
      "Validation loss decreased (0.090365 --> 0.090215).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0747347\n",
      "\tspeed: 0.0435s/iter; left time: 722.5690s\n",
      "\titers: 200, epoch: 26 | loss: 0.0790192\n",
      "\tspeed: 0.0202s/iter; left time: 334.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0765807 Vali Loss: 0.0901931 Test Loss: 0.0924875\n",
      "Validation loss decreased (0.090215 --> 0.090193).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789229\n",
      "\tspeed: 0.0437s/iter; left time: 717.1333s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742214\n",
      "\tspeed: 0.0202s/iter; left time: 329.8556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0765636 Vali Loss: 0.0903746 Test Loss: 0.0923825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0839163\n",
      "\tspeed: 0.0460s/iter; left time: 744.8378s\n",
      "\titers: 200, epoch: 28 | loss: 0.0786108\n",
      "\tspeed: 0.0209s/iter; left time: 336.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0764924 Vali Loss: 0.0900318 Test Loss: 0.0922259\n",
      "Validation loss decreased (0.090193 --> 0.090032).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0794161\n",
      "\tspeed: 0.0439s/iter; left time: 700.5748s\n",
      "\titers: 200, epoch: 29 | loss: 0.0799167\n",
      "\tspeed: 0.0226s/iter; left time: 358.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0764207 Vali Loss: 0.0903167 Test Loss: 0.0924859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0792144\n",
      "\tspeed: 0.0440s/iter; left time: 693.0723s\n",
      "\titers: 200, epoch: 30 | loss: 0.0792654\n",
      "\tspeed: 0.0200s/iter; left time: 313.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0763410 Vali Loss: 0.0900657 Test Loss: 0.0922183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0734143\n",
      "\tspeed: 0.0456s/iter; left time: 707.0243s\n",
      "\titers: 200, epoch: 31 | loss: 0.0754072\n",
      "\tspeed: 0.0200s/iter; left time: 307.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0761650 Vali Loss: 0.0901884 Test Loss: 0.0921875\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0739676\n",
      "\tspeed: 0.0424s/iter; left time: 648.4159s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764657\n",
      "\tspeed: 0.0202s/iter; left time: 307.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0762222 Vali Loss: 0.0902136 Test Loss: 0.0922444\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0711847\n",
      "\tspeed: 0.0424s/iter; left time: 639.1622s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719252\n",
      "\tspeed: 0.0225s/iter; left time: 337.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0761187 Vali Loss: 0.0902977 Test Loss: 0.0922513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0733805\n",
      "\tspeed: 0.0449s/iter; left time: 666.8030s\n",
      "\titers: 200, epoch: 34 | loss: 0.0727109\n",
      "\tspeed: 0.0207s/iter; left time: 305.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0761814 Vali Loss: 0.0900516 Test Loss: 0.0922492\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732718\n",
      "\tspeed: 0.0427s/iter; left time: 624.5269s\n",
      "\titers: 200, epoch: 35 | loss: 0.0749703\n",
      "\tspeed: 0.0203s/iter; left time: 294.0576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0761930 Vali Loss: 0.0900128 Test Loss: 0.0921448\n",
      "Validation loss decreased (0.090032 --> 0.090013).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0766798\n",
      "\tspeed: 0.0434s/iter; left time: 624.9499s\n",
      "\titers: 200, epoch: 36 | loss: 0.0750102\n",
      "\tspeed: 0.0203s/iter; left time: 289.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0760836 Vali Loss: 0.0898830 Test Loss: 0.0920632\n",
      "Validation loss decreased (0.090013 --> 0.089883).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0715126\n",
      "\tspeed: 0.0434s/iter; left time: 614.8970s\n",
      "\titers: 200, epoch: 37 | loss: 0.0778742\n",
      "\tspeed: 0.0203s/iter; left time: 285.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0760820 Vali Loss: 0.0897833 Test Loss: 0.0920799\n",
      "Validation loss decreased (0.089883 --> 0.089783).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829859\n",
      "\tspeed: 0.0462s/iter; left time: 645.0433s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762555\n",
      "\tspeed: 0.0206s/iter; left time: 284.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0760130 Vali Loss: 0.0897898 Test Loss: 0.0920178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0805645\n",
      "\tspeed: 0.0431s/iter; left time: 592.0042s\n",
      "\titers: 200, epoch: 39 | loss: 0.0714110\n",
      "\tspeed: 0.0201s/iter; left time: 273.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0760181 Vali Loss: 0.0902636 Test Loss: 0.0921534\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0692887\n",
      "\tspeed: 0.0521s/iter; left time: 703.6400s\n",
      "\titers: 200, epoch: 40 | loss: 0.0778426\n",
      "\tspeed: 0.0267s/iter; left time: 357.8059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0759935 Vali Loss: 0.0900973 Test Loss: 0.0920592\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0776406\n",
      "\tspeed: 0.0443s/iter; left time: 588.5793s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807740\n",
      "\tspeed: 0.0203s/iter; left time: 268.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0759819 Vali Loss: 0.0901239 Test Loss: 0.0921484\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0771315\n",
      "\tspeed: 0.0423s/iter; left time: 552.2357s\n",
      "\titers: 200, epoch: 42 | loss: 0.0792104\n",
      "\tspeed: 0.0199s/iter; left time: 257.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0759037 Vali Loss: 0.0902524 Test Loss: 0.0922276\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0745168\n",
      "\tspeed: 0.0433s/iter; left time: 556.1639s\n",
      "\titers: 200, epoch: 43 | loss: 0.0744583\n",
      "\tspeed: 0.0202s/iter; left time: 256.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0759841 Vali Loss: 0.0900033 Test Loss: 0.0919992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0741830\n",
      "\tspeed: 0.0435s/iter; left time: 548.1873s\n",
      "\titers: 200, epoch: 44 | loss: 0.0781158\n",
      "\tspeed: 0.0209s/iter; left time: 261.1312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0760082 Vali Loss: 0.0902275 Test Loss: 0.0920613\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0744472\n",
      "\tspeed: 0.0442s/iter; left time: 547.9584s\n",
      "\titers: 200, epoch: 45 | loss: 0.0767980\n",
      "\tspeed: 0.0222s/iter; left time: 272.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0758981 Vali Loss: 0.0899390 Test Loss: 0.0919780\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0772938\n",
      "\tspeed: 0.0448s/iter; left time: 545.5238s\n",
      "\titers: 200, epoch: 46 | loss: 0.0725428\n",
      "\tspeed: 0.0206s/iter; left time: 248.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0759235 Vali Loss: 0.0900554 Test Loss: 0.0920169\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0756535\n",
      "\tspeed: 0.0438s/iter; left time: 523.3825s\n",
      "\titers: 200, epoch: 47 | loss: 0.0725707\n",
      "\tspeed: 0.0206s/iter; left time: 244.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0758647 Vali Loss: 0.0901466 Test Loss: 0.0921033\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02188282459974289, rmse:0.14792844653129578, mae:0.09207988530397415, rse:0.522059977054596\n",
      "Intermediate time for DE and pred_len 24: 00h:12m:15.82s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2746008\n",
      "\tspeed: 0.0493s/iter; left time: 1088.8647s\n",
      "\titers: 200, epoch: 1 | loss: 0.2514527\n",
      "\tspeed: 0.0204s/iter; left time: 449.1079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.2698757 Vali Loss: 0.2293017 Test Loss: 0.2318186\n",
      "Validation loss decreased (inf --> 0.229302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492694\n",
      "\tspeed: 0.0445s/iter; left time: 974.2709s\n",
      "\titers: 200, epoch: 2 | loss: 0.1347827\n",
      "\tspeed: 0.0203s/iter; left time: 442.2835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1624832 Vali Loss: 0.1391781 Test Loss: 0.1439656\n",
      "Validation loss decreased (0.229302 --> 0.139178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1229763\n",
      "\tspeed: 0.0450s/iter; left time: 974.0044s\n",
      "\titers: 200, epoch: 3 | loss: 0.1150210\n",
      "\tspeed: 0.0203s/iter; left time: 437.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1233960 Vali Loss: 0.1294220 Test Loss: 0.1383118\n",
      "Validation loss decreased (0.139178 --> 0.129422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1141142\n",
      "\tspeed: 0.0433s/iter; left time: 928.3148s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133401\n",
      "\tspeed: 0.0203s/iter; left time: 433.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1151363 Vali Loss: 0.1264710 Test Loss: 0.1364030\n",
      "Validation loss decreased (0.129422 --> 0.126471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1109501\n",
      "\tspeed: 0.0433s/iter; left time: 919.4348s\n",
      "\titers: 200, epoch: 5 | loss: 0.1127798\n",
      "\tspeed: 0.0204s/iter; left time: 430.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1110755 Vali Loss: 0.1256932 Test Loss: 0.1349780\n",
      "Validation loss decreased (0.126471 --> 0.125693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1092230\n",
      "\tspeed: 0.0445s/iter; left time: 934.5592s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076659\n",
      "\tspeed: 0.0204s/iter; left time: 425.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1088447 Vali Loss: 0.1248127 Test Loss: 0.1327785\n",
      "Validation loss decreased (0.125693 --> 0.124813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1058396\n",
      "\tspeed: 0.0447s/iter; left time: 928.4004s\n",
      "\titers: 200, epoch: 7 | loss: 0.1048053\n",
      "\tspeed: 0.0204s/iter; left time: 421.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1074621 Vali Loss: 0.1242875 Test Loss: 0.1321853\n",
      "Validation loss decreased (0.124813 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1044636\n",
      "\tspeed: 0.0450s/iter; left time: 923.9425s\n",
      "\titers: 200, epoch: 8 | loss: 0.1106110\n",
      "\tspeed: 0.0205s/iter; left time: 419.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1064293 Vali Loss: 0.1245186 Test Loss: 0.1325380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1028444\n",
      "\tspeed: 0.0431s/iter; left time: 876.3089s\n",
      "\titers: 200, epoch: 9 | loss: 0.1033391\n",
      "\tspeed: 0.0203s/iter; left time: 409.9674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1060250 Vali Loss: 0.1257819 Test Loss: 0.1342924\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1019384\n",
      "\tspeed: 0.0438s/iter; left time: 880.4753s\n",
      "\titers: 200, epoch: 10 | loss: 0.1127677\n",
      "\tspeed: 0.0205s/iter; left time: 409.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1051250 Vali Loss: 0.1261847 Test Loss: 0.1348590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1105345\n",
      "\tspeed: 0.0428s/iter; left time: 850.3643s\n",
      "\titers: 200, epoch: 11 | loss: 0.0960624\n",
      "\tspeed: 0.0203s/iter; left time: 400.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1045347 Vali Loss: 0.1262054 Test Loss: 0.1351160\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1078019\n",
      "\tspeed: 0.0444s/iter; left time: 872.8978s\n",
      "\titers: 200, epoch: 12 | loss: 0.1036723\n",
      "\tspeed: 0.0203s/iter; left time: 396.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1040074 Vali Loss: 0.1268728 Test Loss: 0.1366953\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0956001\n",
      "\tspeed: 0.0436s/iter; left time: 846.8266s\n",
      "\titers: 200, epoch: 13 | loss: 0.1090278\n",
      "\tspeed: 0.0224s/iter; left time: 432.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1036443 Vali Loss: 0.1239581 Test Loss: 0.1338916\n",
      "Validation loss decreased (0.124288 --> 0.123958).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1035504\n",
      "\tspeed: 0.0437s/iter; left time: 839.9596s\n",
      "\titers: 200, epoch: 14 | loss: 0.1060487\n",
      "\tspeed: 0.0206s/iter; left time: 393.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1032384 Vali Loss: 0.1256748 Test Loss: 0.1361385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1129628\n",
      "\tspeed: 0.0438s/iter; left time: 831.0782s\n",
      "\titers: 200, epoch: 15 | loss: 0.1020180\n",
      "\tspeed: 0.0204s/iter; left time: 385.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1028863 Vali Loss: 0.1249194 Test Loss: 0.1358103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1013643\n",
      "\tspeed: 0.0433s/iter; left time: 811.8683s\n",
      "\titers: 200, epoch: 16 | loss: 0.1023591\n",
      "\tspeed: 0.0203s/iter; left time: 378.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1027078 Vali Loss: 0.1254926 Test Loss: 0.1374308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1028595\n",
      "\tspeed: 0.0436s/iter; left time: 808.8254s\n",
      "\titers: 200, epoch: 17 | loss: 0.1062037\n",
      "\tspeed: 0.0205s/iter; left time: 377.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1023961 Vali Loss: 0.1247974 Test Loss: 0.1360857\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1051540\n",
      "\tspeed: 0.0439s/iter; left time: 804.7546s\n",
      "\titers: 200, epoch: 18 | loss: 0.1016844\n",
      "\tspeed: 0.0203s/iter; left time: 369.6484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1021692 Vali Loss: 0.1236309 Test Loss: 0.1358653\n",
      "Validation loss decreased (0.123958 --> 0.123631).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0980886\n",
      "\tspeed: 0.0430s/iter; left time: 778.9658s\n",
      "\titers: 200, epoch: 19 | loss: 0.0989304\n",
      "\tspeed: 0.0204s/iter; left time: 367.9671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1020997 Vali Loss: 0.1242423 Test Loss: 0.1365159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0994082\n",
      "\tspeed: 0.0419s/iter; left time: 748.5721s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025019\n",
      "\tspeed: 0.0202s/iter; left time: 360.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1017810 Vali Loss: 0.1236135 Test Loss: 0.1353629\n",
      "Validation loss decreased (0.123631 --> 0.123613).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1010832\n",
      "\tspeed: 0.0432s/iter; left time: 762.3878s\n",
      "\titers: 200, epoch: 21 | loss: 0.1020031\n",
      "\tspeed: 0.0204s/iter; left time: 357.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1016102 Vali Loss: 0.1237748 Test Loss: 0.1351325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1072670\n",
      "\tspeed: 0.0429s/iter; left time: 747.7045s\n",
      "\titers: 200, epoch: 22 | loss: 0.0955645\n",
      "\tspeed: 0.0203s/iter; left time: 351.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.1015021 Vali Loss: 0.1242287 Test Loss: 0.1366241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1039758\n",
      "\tspeed: 0.0423s/iter; left time: 728.1376s\n",
      "\titers: 200, epoch: 23 | loss: 0.1001585\n",
      "\tspeed: 0.0203s/iter; left time: 347.1270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1012979 Vali Loss: 0.1236947 Test Loss: 0.1362057\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1015419\n",
      "\tspeed: 0.0434s/iter; left time: 737.6736s\n",
      "\titers: 200, epoch: 24 | loss: 0.1029821\n",
      "\tspeed: 0.0204s/iter; left time: 344.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1012101 Vali Loss: 0.1228898 Test Loss: 0.1353223\n",
      "Validation loss decreased (0.123613 --> 0.122890).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1006997\n",
      "\tspeed: 0.0449s/iter; left time: 752.8172s\n",
      "\titers: 200, epoch: 25 | loss: 0.1036851\n",
      "\tspeed: 0.0204s/iter; left time: 340.7323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1011557 Vali Loss: 0.1235861 Test Loss: 0.1363387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1022189\n",
      "\tspeed: 0.0435s/iter; left time: 719.7084s\n",
      "\titers: 200, epoch: 26 | loss: 0.1006631\n",
      "\tspeed: 0.0206s/iter; left time: 338.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1010096 Vali Loss: 0.1235806 Test Loss: 0.1365928\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0983847\n",
      "\tspeed: 0.0448s/iter; left time: 731.1053s\n",
      "\titers: 200, epoch: 27 | loss: 0.1016240\n",
      "\tspeed: 0.0204s/iter; left time: 330.9626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1009450 Vali Loss: 0.1230507 Test Loss: 0.1359318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1026335\n",
      "\tspeed: 0.0429s/iter; left time: 690.3526s\n",
      "\titers: 200, epoch: 28 | loss: 0.1020207\n",
      "\tspeed: 0.0203s/iter; left time: 324.7376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1007601 Vali Loss: 0.1238459 Test Loss: 0.1372463\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1021552\n",
      "\tspeed: 0.0454s/iter; left time: 720.8068s\n",
      "\titers: 200, epoch: 29 | loss: 0.1018350\n",
      "\tspeed: 0.0203s/iter; left time: 320.8480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1007110 Vali Loss: 0.1231984 Test Loss: 0.1362782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1000956\n",
      "\tspeed: 0.0419s/iter; left time: 656.8221s\n",
      "\titers: 200, epoch: 30 | loss: 0.0969561\n",
      "\tspeed: 0.0202s/iter; left time: 315.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.1007576 Vali Loss: 0.1226942 Test Loss: 0.1350585\n",
      "Validation loss decreased (0.122890 --> 0.122694).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1027024\n",
      "\tspeed: 0.0437s/iter; left time: 674.0332s\n",
      "\titers: 200, epoch: 31 | loss: 0.1042811\n",
      "\tspeed: 0.0204s/iter; left time: 312.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1006005 Vali Loss: 0.1229716 Test Loss: 0.1359890\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0981697\n",
      "\tspeed: 0.0425s/iter; left time: 646.2455s\n",
      "\titers: 200, epoch: 32 | loss: 0.0995496\n",
      "\tspeed: 0.0204s/iter; left time: 308.0629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1005524 Vali Loss: 0.1228913 Test Loss: 0.1353133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1058541\n",
      "\tspeed: 0.0437s/iter; left time: 656.1067s\n",
      "\titers: 200, epoch: 33 | loss: 0.0986717\n",
      "\tspeed: 0.0202s/iter; left time: 301.5863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1005826 Vali Loss: 0.1226582 Test Loss: 0.1358778\n",
      "Validation loss decreased (0.122694 --> 0.122658).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1002448\n",
      "\tspeed: 0.0435s/iter; left time: 642.4540s\n",
      "\titers: 200, epoch: 34 | loss: 0.1039753\n",
      "\tspeed: 0.0205s/iter; left time: 300.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1004527 Vali Loss: 0.1232586 Test Loss: 0.1365952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0940850\n",
      "\tspeed: 0.0424s/iter; left time: 616.5015s\n",
      "\titers: 200, epoch: 35 | loss: 0.1029950\n",
      "\tspeed: 0.0203s/iter; left time: 292.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1004678 Vali Loss: 0.1227602 Test Loss: 0.1357923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1029373\n",
      "\tspeed: 0.0440s/iter; left time: 629.9304s\n",
      "\titers: 200, epoch: 36 | loss: 0.1054347\n",
      "\tspeed: 0.0204s/iter; left time: 289.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1004078 Vali Loss: 0.1227727 Test Loss: 0.1358065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1081109\n",
      "\tspeed: 0.0426s/iter; left time: 600.5023s\n",
      "\titers: 200, epoch: 37 | loss: 0.0991923\n",
      "\tspeed: 0.0203s/iter; left time: 284.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.1003935 Vali Loss: 0.1230432 Test Loss: 0.1360274\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1074517\n",
      "\tspeed: 0.0425s/iter; left time: 589.7496s\n",
      "\titers: 200, epoch: 38 | loss: 0.1009870\n",
      "\tspeed: 0.0204s/iter; left time: 280.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1003523 Vali Loss: 0.1227690 Test Loss: 0.1360568\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0948013\n",
      "\tspeed: 0.0437s/iter; left time: 597.3693s\n",
      "\titers: 200, epoch: 39 | loss: 0.0981326\n",
      "\tspeed: 0.0214s/iter; left time: 290.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.1004339 Vali Loss: 0.1229201 Test Loss: 0.1361592\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0993517\n",
      "\tspeed: 0.0436s/iter; left time: 586.0372s\n",
      "\titers: 200, epoch: 40 | loss: 0.1014140\n",
      "\tspeed: 0.0203s/iter; left time: 270.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.1002876 Vali Loss: 0.1227761 Test Loss: 0.1359072\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0989447\n",
      "\tspeed: 0.0439s/iter; left time: 580.8967s\n",
      "\titers: 200, epoch: 41 | loss: 0.1099960\n",
      "\tspeed: 0.0204s/iter; left time: 267.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1002325 Vali Loss: 0.1226757 Test Loss: 0.1358664\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1030385\n",
      "\tspeed: 0.0430s/iter; left time: 559.4425s\n",
      "\titers: 200, epoch: 42 | loss: 0.0987012\n",
      "\tspeed: 0.0203s/iter; left time: 261.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.1002886 Vali Loss: 0.1227850 Test Loss: 0.1359752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0982130\n",
      "\tspeed: 0.0423s/iter; left time: 540.1416s\n",
      "\titers: 200, epoch: 43 | loss: 0.0974052\n",
      "\tspeed: 0.0204s/iter; left time: 258.9552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1003444 Vali Loss: 0.1222139 Test Loss: 0.1353274\n",
      "Validation loss decreased (0.122658 --> 0.122214).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0966651\n",
      "\tspeed: 0.0437s/iter; left time: 549.1021s\n",
      "\titers: 200, epoch: 44 | loss: 0.1020363\n",
      "\tspeed: 0.0205s/iter; left time: 255.1864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1002789 Vali Loss: 0.1226460 Test Loss: 0.1358935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0998923\n",
      "\tspeed: 0.0426s/iter; left time: 525.4117s\n",
      "\titers: 200, epoch: 45 | loss: 0.1030129\n",
      "\tspeed: 0.0203s/iter; left time: 247.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1002502 Vali Loss: 0.1225560 Test Loss: 0.1356725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1024632\n",
      "\tspeed: 0.0428s/iter; left time: 518.3679s\n",
      "\titers: 200, epoch: 46 | loss: 0.0993016\n",
      "\tspeed: 0.0204s/iter; left time: 245.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1002555 Vali Loss: 0.1223647 Test Loss: 0.1355448\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1035789\n",
      "\tspeed: 0.0429s/iter; left time: 509.5409s\n",
      "\titers: 200, epoch: 47 | loss: 0.0957147\n",
      "\tspeed: 0.0203s/iter; left time: 238.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1001944 Vali Loss: 0.1229249 Test Loss: 0.1360979\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0991891\n",
      "\tspeed: 0.0426s/iter; left time: 497.5875s\n",
      "\titers: 200, epoch: 48 | loss: 0.0935006\n",
      "\tspeed: 0.0203s/iter; left time: 234.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1002300 Vali Loss: 0.1223428 Test Loss: 0.1355022\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0980361\n",
      "\tspeed: 0.0471s/iter; left time: 539.1233s\n",
      "\titers: 200, epoch: 49 | loss: 0.0991728\n",
      "\tspeed: 0.0207s/iter; left time: 235.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.1001759 Vali Loss: 0.1224179 Test Loss: 0.1355893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0994642\n",
      "\tspeed: 0.0433s/iter; left time: 486.2576s\n",
      "\titers: 200, epoch: 50 | loss: 0.1009895\n",
      "\tspeed: 0.0204s/iter; left time: 226.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1001639 Vali Loss: 0.1221785 Test Loss: 0.1352349\n",
      "Validation loss decreased (0.122214 --> 0.122179).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0987073\n",
      "\tspeed: 0.0454s/iter; left time: 499.2904s\n",
      "\titers: 200, epoch: 51 | loss: 0.0991311\n",
      "\tspeed: 0.0203s/iter; left time: 220.8329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1002218 Vali Loss: 0.1223758 Test Loss: 0.1355910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1037601\n",
      "\tspeed: 0.0455s/iter; left time: 490.1657s\n",
      "\titers: 200, epoch: 52 | loss: 0.0984696\n",
      "\tspeed: 0.0204s/iter; left time: 218.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1001934 Vali Loss: 0.1226441 Test Loss: 0.1358739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1021746\n",
      "\tspeed: 0.0434s/iter; left time: 457.7388s\n",
      "\titers: 200, epoch: 53 | loss: 0.1018147\n",
      "\tspeed: 0.0203s/iter; left time: 212.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1001650 Vali Loss: 0.1227890 Test Loss: 0.1359922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1007738\n",
      "\tspeed: 0.0428s/iter; left time: 441.8220s\n",
      "\titers: 200, epoch: 54 | loss: 0.1033273\n",
      "\tspeed: 0.0203s/iter; left time: 207.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1001679 Vali Loss: 0.1231412 Test Loss: 0.1365046\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1000785\n",
      "\tspeed: 0.0425s/iter; left time: 429.7084s\n",
      "\titers: 200, epoch: 55 | loss: 0.1052800\n",
      "\tspeed: 0.0204s/iter; left time: 204.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1001285 Vali Loss: 0.1222991 Test Loss: 0.1355074\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1022447\n",
      "\tspeed: 0.0433s/iter; left time: 428.3868s\n",
      "\titers: 200, epoch: 56 | loss: 0.1039488\n",
      "\tspeed: 0.0205s/iter; left time: 200.9714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1000040 Vali Loss: 0.1224804 Test Loss: 0.1359329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1056654\n",
      "\tspeed: 0.0456s/iter; left time: 440.6167s\n",
      "\titers: 200, epoch: 57 | loss: 0.1034027\n",
      "\tspeed: 0.0204s/iter; left time: 195.5639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.1001704 Vali Loss: 0.1227876 Test Loss: 0.1363264\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1005686\n",
      "\tspeed: 0.0431s/iter; left time: 407.0047s\n",
      "\titers: 200, epoch: 58 | loss: 0.0983072\n",
      "\tspeed: 0.0203s/iter; left time: 189.3953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1001412 Vali Loss: 0.1227559 Test Loss: 0.1361562\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1005821\n",
      "\tspeed: 0.0425s/iter; left time: 391.7971s\n",
      "\titers: 200, epoch: 59 | loss: 0.0988197\n",
      "\tspeed: 0.0203s/iter; left time: 184.8702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1001613 Vali Loss: 0.1223188 Test Loss: 0.1354785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.1040010\n",
      "\tspeed: 0.0436s/iter; left time: 392.3528s\n",
      "\titers: 200, epoch: 60 | loss: 0.0978208\n",
      "\tspeed: 0.0202s/iter; left time: 180.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1001361 Vali Loss: 0.1230012 Test Loss: 0.1364686\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04340914264321327, rmse:0.2083486020565033, mae:0.13523496687412262, rse:0.7378045320510864\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2644310\n",
      "\tspeed: 0.0225s/iter; left time: 497.4702s\n",
      "\titers: 200, epoch: 1 | loss: 0.2517203\n",
      "\tspeed: 0.0205s/iter; left time: 451.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.2714728 Vali Loss: 0.2290613 Test Loss: 0.2317390\n",
      "Validation loss decreased (inf --> 0.229061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1558459\n",
      "\tspeed: 0.0447s/iter; left time: 978.1731s\n",
      "\titers: 200, epoch: 2 | loss: 0.1308161\n",
      "\tspeed: 0.0203s/iter; left time: 441.4880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1623632 Vali Loss: 0.1391634 Test Loss: 0.1442310\n",
      "Validation loss decreased (0.229061 --> 0.139163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1262097\n",
      "\tspeed: 0.0449s/iter; left time: 973.4148s\n",
      "\titers: 200, epoch: 3 | loss: 0.1221988\n",
      "\tspeed: 0.0220s/iter; left time: 473.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.1247924 Vali Loss: 0.1285259 Test Loss: 0.1363316\n",
      "Validation loss decreased (0.139163 --> 0.128526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1116177\n",
      "\tspeed: 0.0439s/iter; left time: 940.3164s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129111\n",
      "\tspeed: 0.0202s/iter; left time: 431.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1145915 Vali Loss: 0.1257595 Test Loss: 0.1340147\n",
      "Validation loss decreased (0.128526 --> 0.125759).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1033075\n",
      "\tspeed: 0.0441s/iter; left time: 935.8931s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064940\n",
      "\tspeed: 0.0202s/iter; left time: 426.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1106250 Vali Loss: 0.1245823 Test Loss: 0.1331115\n",
      "Validation loss decreased (0.125759 --> 0.124582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1061657\n",
      "\tspeed: 0.0439s/iter; left time: 922.4110s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098838\n",
      "\tspeed: 0.0203s/iter; left time: 423.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1087908 Vali Loss: 0.1249903 Test Loss: 0.1338880\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1084789\n",
      "\tspeed: 0.0431s/iter; left time: 895.3024s\n",
      "\titers: 200, epoch: 7 | loss: 0.1140483\n",
      "\tspeed: 0.0203s/iter; left time: 418.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1072994 Vali Loss: 0.1264852 Test Loss: 0.1340602\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098727\n",
      "\tspeed: 0.0434s/iter; left time: 891.1414s\n",
      "\titers: 200, epoch: 8 | loss: 0.1146306\n",
      "\tspeed: 0.0202s/iter; left time: 413.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1063628 Vali Loss: 0.1240705 Test Loss: 0.1315209\n",
      "Validation loss decreased (0.124582 --> 0.124070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1115242\n",
      "\tspeed: 0.0460s/iter; left time: 934.7052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1031145\n",
      "\tspeed: 0.0205s/iter; left time: 414.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.1056624 Vali Loss: 0.1263402 Test Loss: 0.1336622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067512\n",
      "\tspeed: 0.0439s/iter; left time: 883.3463s\n",
      "\titers: 200, epoch: 10 | loss: 0.1040183\n",
      "\tspeed: 0.0204s/iter; left time: 407.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1050005 Vali Loss: 0.1251166 Test Loss: 0.1326799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1089376\n",
      "\tspeed: 0.0448s/iter; left time: 890.5814s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986640\n",
      "\tspeed: 0.0204s/iter; left time: 404.0482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1045842 Vali Loss: 0.1240261 Test Loss: 0.1322822\n",
      "Validation loss decreased (0.124070 --> 0.124026).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066567\n",
      "\tspeed: 0.0447s/iter; left time: 878.0730s\n",
      "\titers: 200, epoch: 12 | loss: 0.1005452\n",
      "\tspeed: 0.0205s/iter; left time: 400.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1040709 Vali Loss: 0.1257275 Test Loss: 0.1339570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1006553\n",
      "\tspeed: 0.0435s/iter; left time: 846.2876s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049977\n",
      "\tspeed: 0.0203s/iter; left time: 392.0356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1036637 Vali Loss: 0.1257253 Test Loss: 0.1338510\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0959458\n",
      "\tspeed: 0.0427s/iter; left time: 820.3572s\n",
      "\titers: 200, epoch: 14 | loss: 0.1034217\n",
      "\tspeed: 0.0203s/iter; left time: 388.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1034468 Vali Loss: 0.1255327 Test Loss: 0.1356756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1008628\n",
      "\tspeed: 0.0438s/iter; left time: 831.2817s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011707\n",
      "\tspeed: 0.0203s/iter; left time: 383.3634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1029629 Vali Loss: 0.1264527 Test Loss: 0.1365733\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1021052\n",
      "\tspeed: 0.0432s/iter; left time: 811.1647s\n",
      "\titers: 200, epoch: 16 | loss: 0.1040429\n",
      "\tspeed: 0.0203s/iter; left time: 379.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1027325 Vali Loss: 0.1243456 Test Loss: 0.1328561\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1048103\n",
      "\tspeed: 0.0449s/iter; left time: 832.1285s\n",
      "\titers: 200, epoch: 17 | loss: 0.1021821\n",
      "\tspeed: 0.0202s/iter; left time: 373.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1024323 Vali Loss: 0.1234998 Test Loss: 0.1329888\n",
      "Validation loss decreased (0.124026 --> 0.123500).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1026683\n",
      "\tspeed: 0.0469s/iter; left time: 859.3073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0989553\n",
      "\tspeed: 0.0221s/iter; left time: 402.0244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1022891 Vali Loss: 0.1259734 Test Loss: 0.1368130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1009428\n",
      "\tspeed: 0.0431s/iter; left time: 780.5326s\n",
      "\titers: 200, epoch: 19 | loss: 0.1040189\n",
      "\tspeed: 0.0206s/iter; left time: 370.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1022190 Vali Loss: 0.1257375 Test Loss: 0.1346503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1026354\n",
      "\tspeed: 0.0442s/iter; left time: 789.9403s\n",
      "\titers: 200, epoch: 20 | loss: 0.1002588\n",
      "\tspeed: 0.0203s/iter; left time: 360.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1018585 Vali Loss: 0.1253074 Test Loss: 0.1350731\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1005532\n",
      "\tspeed: 0.0453s/iter; left time: 800.5533s\n",
      "\titers: 200, epoch: 21 | loss: 0.0934714\n",
      "\tspeed: 0.0203s/iter; left time: 355.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1017166 Vali Loss: 0.1254313 Test Loss: 0.1365214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1041646\n",
      "\tspeed: 0.0456s/iter; left time: 795.6805s\n",
      "\titers: 200, epoch: 22 | loss: 0.1001442\n",
      "\tspeed: 0.0205s/iter; left time: 354.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1017033 Vali Loss: 0.1260002 Test Loss: 0.1364065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1053329\n",
      "\tspeed: 0.0444s/iter; left time: 763.8632s\n",
      "\titers: 200, epoch: 23 | loss: 0.0997870\n",
      "\tspeed: 0.0203s/iter; left time: 346.9888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1014405 Vali Loss: 0.1269710 Test Loss: 0.1371964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1001726\n",
      "\tspeed: 0.0455s/iter; left time: 772.8455s\n",
      "\titers: 200, epoch: 24 | loss: 0.0986712\n",
      "\tspeed: 0.0235s/iter; left time: 396.3600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 222 | Train Loss: 0.1014841 Vali Loss: 0.1259731 Test Loss: 0.1364085\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0971417\n",
      "\tspeed: 0.0445s/iter; left time: 746.6546s\n",
      "\titers: 200, epoch: 25 | loss: 0.0972540\n",
      "\tspeed: 0.0203s/iter; left time: 337.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1012330 Vali Loss: 0.1254518 Test Loss: 0.1343188\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0966127\n",
      "\tspeed: 0.0457s/iter; left time: 755.7913s\n",
      "\titers: 200, epoch: 26 | loss: 0.1000932\n",
      "\tspeed: 0.0220s/iter; left time: 361.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.1012501 Vali Loss: 0.1263892 Test Loss: 0.1373893\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1027568\n",
      "\tspeed: 0.0471s/iter; left time: 768.3206s\n",
      "\titers: 200, epoch: 27 | loss: 0.1002008\n",
      "\tspeed: 0.0208s/iter; left time: 336.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1010386 Vali Loss: 0.1256889 Test Loss: 0.1365835\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04084043577313423, rmse:0.20209017395973206, mae:0.1329888105392456, rse:0.7156420946121216\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:33.53s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2635712\n",
      "\tspeed: 0.0492s/iter; left time: 1087.6817s\n",
      "\titers: 200, epoch: 1 | loss: 0.2505818\n",
      "\tspeed: 0.0207s/iter; left time: 454.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.2714522 Vali Loss: 0.2291701 Test Loss: 0.2326015\n",
      "Validation loss decreased (inf --> 0.229170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1508654\n",
      "\tspeed: 0.0443s/iter; left time: 968.2843s\n",
      "\titers: 200, epoch: 2 | loss: 0.1371257\n",
      "\tspeed: 0.0205s/iter; left time: 447.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1640857 Vali Loss: 0.1416273 Test Loss: 0.1485835\n",
      "Validation loss decreased (0.229170 --> 0.141627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1233250\n",
      "\tspeed: 0.0449s/iter; left time: 972.9388s\n",
      "\titers: 200, epoch: 3 | loss: 0.1236663\n",
      "\tspeed: 0.0207s/iter; left time: 446.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1269506 Vali Loss: 0.1366062 Test Loss: 0.1493749\n",
      "Validation loss decreased (0.141627 --> 0.136606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1219652\n",
      "\tspeed: 0.0457s/iter; left time: 980.6367s\n",
      "\titers: 200, epoch: 4 | loss: 0.1137599\n",
      "\tspeed: 0.0223s/iter; left time: 474.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 222 | Train Loss: 0.1188799 Vali Loss: 0.1308372 Test Loss: 0.1418802\n",
      "Validation loss decreased (0.136606 --> 0.130837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1190454\n",
      "\tspeed: 0.0470s/iter; left time: 997.9745s\n",
      "\titers: 200, epoch: 5 | loss: 0.1164137\n",
      "\tspeed: 0.0206s/iter; left time: 435.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.1155872 Vali Loss: 0.1299212 Test Loss: 0.1408072\n",
      "Validation loss decreased (0.130837 --> 0.129921).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1164058\n",
      "\tspeed: 0.0458s/iter; left time: 960.7721s\n",
      "\titers: 200, epoch: 6 | loss: 0.1132132\n",
      "\tspeed: 0.0204s/iter; left time: 426.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1134714 Vali Loss: 0.1308232 Test Loss: 0.1423041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104720\n",
      "\tspeed: 0.0445s/iter; left time: 924.3156s\n",
      "\titers: 200, epoch: 7 | loss: 0.1137908\n",
      "\tspeed: 0.0204s/iter; left time: 420.7955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1122399 Vali Loss: 0.1317047 Test Loss: 0.1434711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1121600\n",
      "\tspeed: 0.0449s/iter; left time: 922.7920s\n",
      "\titers: 200, epoch: 8 | loss: 0.1126190\n",
      "\tspeed: 0.0204s/iter; left time: 417.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1111663 Vali Loss: 0.1357587 Test Loss: 0.1516875\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1132699\n",
      "\tspeed: 0.0457s/iter; left time: 928.4832s\n",
      "\titers: 200, epoch: 9 | loss: 0.1096397\n",
      "\tspeed: 0.0205s/iter; left time: 415.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1106153 Vali Loss: 0.1315435 Test Loss: 0.1457874\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1088877\n",
      "\tspeed: 0.0456s/iter; left time: 917.5941s\n",
      "\titers: 200, epoch: 10 | loss: 0.1072207\n",
      "\tspeed: 0.0203s/iter; left time: 405.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1096746 Vali Loss: 0.1307920 Test Loss: 0.1449525\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1129742\n",
      "\tspeed: 0.0480s/iter; left time: 954.3165s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104764\n",
      "\tspeed: 0.0213s/iter; left time: 422.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.1092887 Vali Loss: 0.1300609 Test Loss: 0.1449732\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1130502\n",
      "\tspeed: 0.0451s/iter; left time: 886.9544s\n",
      "\titers: 200, epoch: 12 | loss: 0.1096532\n",
      "\tspeed: 0.0204s/iter; left time: 398.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1086675 Vali Loss: 0.1291688 Test Loss: 0.1437897\n",
      "Validation loss decreased (0.129921 --> 0.129169).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032140\n",
      "\tspeed: 0.0479s/iter; left time: 931.8713s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990243\n",
      "\tspeed: 0.0204s/iter; left time: 393.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1080841 Vali Loss: 0.1294795 Test Loss: 0.1436269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1076146\n",
      "\tspeed: 0.0486s/iter; left time: 933.1067s\n",
      "\titers: 200, epoch: 14 | loss: 0.1087734\n",
      "\tspeed: 0.0225s/iter; left time: 429.9207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 222 | Train Loss: 0.1079351 Vali Loss: 0.1275356 Test Loss: 0.1418951\n",
      "Validation loss decreased (0.129169 --> 0.127536).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1076952\n",
      "\tspeed: 0.0493s/iter; left time: 936.2936s\n",
      "\titers: 200, epoch: 15 | loss: 0.1095065\n",
      "\tspeed: 0.0211s/iter; left time: 398.4524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.1076429 Vali Loss: 0.1281830 Test Loss: 0.1446722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1086038\n",
      "\tspeed: 0.0464s/iter; left time: 871.8481s\n",
      "\titers: 200, epoch: 16 | loss: 0.1030773\n",
      "\tspeed: 0.0209s/iter; left time: 389.9743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1071818 Vali Loss: 0.1278302 Test Loss: 0.1433857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1056638\n",
      "\tspeed: 0.0439s/iter; left time: 813.8075s\n",
      "\titers: 200, epoch: 17 | loss: 0.1042433\n",
      "\tspeed: 0.0204s/iter; left time: 375.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1071794 Vali Loss: 0.1285924 Test Loss: 0.1446194\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1053060\n",
      "\tspeed: 0.0464s/iter; left time: 850.5290s\n",
      "\titers: 200, epoch: 18 | loss: 0.1094116\n",
      "\tspeed: 0.0213s/iter; left time: 387.7466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1068149 Vali Loss: 0.1272435 Test Loss: 0.1427091\n",
      "Validation loss decreased (0.127536 --> 0.127243).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1108867\n",
      "\tspeed: 0.0454s/iter; left time: 821.8468s\n",
      "\titers: 200, epoch: 19 | loss: 0.1097524\n",
      "\tspeed: 0.0214s/iter; left time: 385.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.1064583 Vali Loss: 0.1268616 Test Loss: 0.1427672\n",
      "Validation loss decreased (0.127243 --> 0.126862).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1038617\n",
      "\tspeed: 0.0458s/iter; left time: 819.8977s\n",
      "\titers: 200, epoch: 20 | loss: 0.1059494\n",
      "\tspeed: 0.0207s/iter; left time: 367.2441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1062101 Vali Loss: 0.1266779 Test Loss: 0.1428877\n",
      "Validation loss decreased (0.126862 --> 0.126678).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033215\n",
      "\tspeed: 0.0458s/iter; left time: 808.9095s\n",
      "\titers: 200, epoch: 21 | loss: 0.1048715\n",
      "\tspeed: 0.0208s/iter; left time: 365.3630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1062270 Vali Loss: 0.1276238 Test Loss: 0.1445345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1037091\n",
      "\tspeed: 0.0460s/iter; left time: 802.7580s\n",
      "\titers: 200, epoch: 22 | loss: 0.1078178\n",
      "\tspeed: 0.0208s/iter; left time: 361.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1059321 Vali Loss: 0.1267027 Test Loss: 0.1432244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1041584\n",
      "\tspeed: 0.0486s/iter; left time: 836.9952s\n",
      "\titers: 200, epoch: 23 | loss: 0.1000154\n",
      "\tspeed: 0.0243s/iter; left time: 416.3897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 222 | Train Loss: 0.1058848 Vali Loss: 0.1268779 Test Loss: 0.1424203\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1026665\n",
      "\tspeed: 0.0446s/iter; left time: 757.8311s\n",
      "\titers: 200, epoch: 24 | loss: 0.1068058\n",
      "\tspeed: 0.0204s/iter; left time: 344.1807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1058591 Vali Loss: 0.1262804 Test Loss: 0.1424438\n",
      "Validation loss decreased (0.126678 --> 0.126280).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1042366\n",
      "\tspeed: 0.0459s/iter; left time: 770.2692s\n",
      "\titers: 200, epoch: 25 | loss: 0.1067096\n",
      "\tspeed: 0.0203s/iter; left time: 339.0291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1056078 Vali Loss: 0.1267104 Test Loss: 0.1430844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1093422\n",
      "\tspeed: 0.0448s/iter; left time: 741.3437s\n",
      "\titers: 200, epoch: 26 | loss: 0.1035668\n",
      "\tspeed: 0.0203s/iter; left time: 333.8307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1055133 Vali Loss: 0.1270550 Test Loss: 0.1438429\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1037734\n",
      "\tspeed: 0.0443s/iter; left time: 722.8229s\n",
      "\titers: 200, epoch: 27 | loss: 0.1029718\n",
      "\tspeed: 0.0203s/iter; left time: 329.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1054176 Vali Loss: 0.1262701 Test Loss: 0.1428297\n",
      "Validation loss decreased (0.126280 --> 0.126270).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1046086\n",
      "\tspeed: 0.0454s/iter; left time: 731.8259s\n",
      "\titers: 200, epoch: 28 | loss: 0.1028433\n",
      "\tspeed: 0.0210s/iter; left time: 335.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1053458 Vali Loss: 0.1264106 Test Loss: 0.1432624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1039153\n",
      "\tspeed: 0.0482s/iter; left time: 765.8114s\n",
      "\titers: 200, epoch: 29 | loss: 0.1044010\n",
      "\tspeed: 0.0206s/iter; left time: 324.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 222 | Train Loss: 0.1052193 Vali Loss: 0.1259411 Test Loss: 0.1422317\n",
      "Validation loss decreased (0.126270 --> 0.125941).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1020727\n",
      "\tspeed: 0.0471s/iter; left time: 738.1923s\n",
      "\titers: 200, epoch: 30 | loss: 0.1071113\n",
      "\tspeed: 0.0204s/iter; left time: 317.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.1052012 Vali Loss: 0.1258453 Test Loss: 0.1425649\n",
      "Validation loss decreased (0.125941 --> 0.125845).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1079093\n",
      "\tspeed: 0.0495s/iter; left time: 764.7310s\n",
      "\titers: 200, epoch: 31 | loss: 0.1101111\n",
      "\tspeed: 0.0206s/iter; left time: 315.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.1050924 Vali Loss: 0.1261823 Test Loss: 0.1432493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1044770\n",
      "\tspeed: 0.0494s/iter; left time: 751.5197s\n",
      "\titers: 200, epoch: 32 | loss: 0.1037062\n",
      "\tspeed: 0.0210s/iter; left time: 316.9531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 222 | Train Loss: 0.1050540 Vali Loss: 0.1260934 Test Loss: 0.1428397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1051383\n",
      "\tspeed: 0.0463s/iter; left time: 694.8954s\n",
      "\titers: 200, epoch: 33 | loss: 0.1025543\n",
      "\tspeed: 0.0215s/iter; left time: 320.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.1050585 Vali Loss: 0.1261664 Test Loss: 0.1434357\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1060019\n",
      "\tspeed: 0.0478s/iter; left time: 705.6128s\n",
      "\titers: 200, epoch: 34 | loss: 0.1090982\n",
      "\tspeed: 0.0223s/iter; left time: 326.6170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.1049983 Vali Loss: 0.1263918 Test Loss: 0.1437126\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1018900\n",
      "\tspeed: 0.0452s/iter; left time: 657.7052s\n",
      "\titers: 200, epoch: 35 | loss: 0.1032309\n",
      "\tspeed: 0.0204s/iter; left time: 294.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1050053 Vali Loss: 0.1262742 Test Loss: 0.1440051\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1098305\n",
      "\tspeed: 0.0455s/iter; left time: 652.0229s\n",
      "\titers: 200, epoch: 36 | loss: 0.1090532\n",
      "\tspeed: 0.0208s/iter; left time: 295.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1049113 Vali Loss: 0.1259437 Test Loss: 0.1433206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1012445\n",
      "\tspeed: 0.0458s/iter; left time: 645.5444s\n",
      "\titers: 200, epoch: 37 | loss: 0.1029525\n",
      "\tspeed: 0.0205s/iter; left time: 287.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1048600 Vali Loss: 0.1261355 Test Loss: 0.1437023\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1011759\n",
      "\tspeed: 0.0448s/iter; left time: 622.4224s\n",
      "\titers: 200, epoch: 38 | loss: 0.1020085\n",
      "\tspeed: 0.0208s/iter; left time: 286.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1048106 Vali Loss: 0.1260846 Test Loss: 0.1427205\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1081446\n",
      "\tspeed: 0.0458s/iter; left time: 625.2278s\n",
      "\titers: 200, epoch: 39 | loss: 0.1047102\n",
      "\tspeed: 0.0204s/iter; left time: 276.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.1049029 Vali Loss: 0.1261722 Test Loss: 0.1429999\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1027207\n",
      "\tspeed: 0.0441s/iter; left time: 592.7369s\n",
      "\titers: 200, epoch: 40 | loss: 0.1031509\n",
      "\tspeed: 0.0203s/iter; left time: 271.3663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1048176 Vali Loss: 0.1258087 Test Loss: 0.1429110\n",
      "Validation loss decreased (0.125845 --> 0.125809).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1084505\n",
      "\tspeed: 0.0454s/iter; left time: 599.9678s\n",
      "\titers: 200, epoch: 41 | loss: 0.1063763\n",
      "\tspeed: 0.0233s/iter; left time: 305.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.1048004 Vali Loss: 0.1260300 Test Loss: 0.1431440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1037070\n",
      "\tspeed: 0.0447s/iter; left time: 581.3173s\n",
      "\titers: 200, epoch: 42 | loss: 0.0985596\n",
      "\tspeed: 0.0205s/iter; left time: 264.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1047334 Vali Loss: 0.1259820 Test Loss: 0.1429048\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1047863\n",
      "\tspeed: 0.0452s/iter; left time: 577.1552s\n",
      "\titers: 200, epoch: 43 | loss: 0.1066994\n",
      "\tspeed: 0.0204s/iter; left time: 258.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1048005 Vali Loss: 0.1257820 Test Loss: 0.1428812\n",
      "Validation loss decreased (0.125809 --> 0.125782).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1029892\n",
      "\tspeed: 0.0451s/iter; left time: 565.9253s\n",
      "\titers: 200, epoch: 44 | loss: 0.1043477\n",
      "\tspeed: 0.0203s/iter; left time: 252.7149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1047804 Vali Loss: 0.1262902 Test Loss: 0.1438335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1020061\n",
      "\tspeed: 0.0453s/iter; left time: 558.3820s\n",
      "\titers: 200, epoch: 45 | loss: 0.1090222\n",
      "\tspeed: 0.0214s/iter; left time: 262.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1047420 Vali Loss: 0.1259686 Test Loss: 0.1430282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1056381\n",
      "\tspeed: 0.0441s/iter; left time: 533.8617s\n",
      "\titers: 200, epoch: 46 | loss: 0.1050418\n",
      "\tspeed: 0.0203s/iter; left time: 244.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1046810 Vali Loss: 0.1261729 Test Loss: 0.1438249\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1090499\n",
      "\tspeed: 0.0442s/iter; left time: 525.9571s\n",
      "\titers: 200, epoch: 47 | loss: 0.1054865\n",
      "\tspeed: 0.0204s/iter; left time: 240.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1047337 Vali Loss: 0.1261556 Test Loss: 0.1435580\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1041568\n",
      "\tspeed: 0.0450s/iter; left time: 525.5767s\n",
      "\titers: 200, epoch: 48 | loss: 0.1082203\n",
      "\tspeed: 0.0204s/iter; left time: 236.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1047066 Vali Loss: 0.1259478 Test Loss: 0.1431990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1073269\n",
      "\tspeed: 0.0455s/iter; left time: 520.8900s\n",
      "\titers: 200, epoch: 49 | loss: 0.1065548\n",
      "\tspeed: 0.0206s/iter; left time: 233.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1047069 Vali Loss: 0.1259166 Test Loss: 0.1426549\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1035100\n",
      "\tspeed: 0.0456s/iter; left time: 511.9663s\n",
      "\titers: 200, epoch: 50 | loss: 0.1045742\n",
      "\tspeed: 0.0218s/iter; left time: 242.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.1045960 Vali Loss: 0.1257866 Test Loss: 0.1427472\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1047946\n",
      "\tspeed: 0.0453s/iter; left time: 498.8876s\n",
      "\titers: 200, epoch: 51 | loss: 0.1056989\n",
      "\tspeed: 0.0204s/iter; left time: 222.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1046224 Vali Loss: 0.1262049 Test Loss: 0.1436868\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1077790\n",
      "\tspeed: 0.0448s/iter; left time: 482.8073s\n",
      "\titers: 200, epoch: 52 | loss: 0.1084152\n",
      "\tspeed: 0.0212s/iter; left time: 225.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.1046219 Vali Loss: 0.1257649 Test Loss: 0.1430751\n",
      "Validation loss decreased (0.125782 --> 0.125765).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1022902\n",
      "\tspeed: 0.0464s/iter; left time: 489.4715s\n",
      "\titers: 200, epoch: 53 | loss: 0.0999769\n",
      "\tspeed: 0.0210s/iter; left time: 219.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1046869 Vali Loss: 0.1258842 Test Loss: 0.1429341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1066160\n",
      "\tspeed: 0.0450s/iter; left time: 465.5550s\n",
      "\titers: 200, epoch: 54 | loss: 0.1075375\n",
      "\tspeed: 0.0211s/iter; left time: 215.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.1046579 Vali Loss: 0.1260206 Test Loss: 0.1434988\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0984180\n",
      "\tspeed: 0.0447s/iter; left time: 452.0640s\n",
      "\titers: 200, epoch: 55 | loss: 0.1051654\n",
      "\tspeed: 0.0209s/iter; left time: 209.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1046924 Vali Loss: 0.1261065 Test Loss: 0.1433332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1052093\n",
      "\tspeed: 0.0468s/iter; left time: 463.2383s\n",
      "\titers: 200, epoch: 56 | loss: 0.1066872\n",
      "\tspeed: 0.0229s/iter; left time: 224.1597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 222 | Train Loss: 0.1046459 Vali Loss: 0.1258322 Test Loss: 0.1427461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1064580\n",
      "\tspeed: 0.0456s/iter; left time: 440.5181s\n",
      "\titers: 200, epoch: 57 | loss: 0.1035502\n",
      "\tspeed: 0.0209s/iter; left time: 200.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1046452 Vali Loss: 0.1260563 Test Loss: 0.1435452\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1044552\n",
      "\tspeed: 0.0442s/iter; left time: 417.5464s\n",
      "\titers: 200, epoch: 58 | loss: 0.1059206\n",
      "\tspeed: 0.0206s/iter; left time: 192.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1046005 Vali Loss: 0.1258516 Test Loss: 0.1427021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1065851\n",
      "\tspeed: 0.0448s/iter; left time: 413.5402s\n",
      "\titers: 200, epoch: 59 | loss: 0.1070579\n",
      "\tspeed: 0.0209s/iter; left time: 190.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1046313 Vali Loss: 0.1259600 Test Loss: 0.1434012\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.1046154\n",
      "\tspeed: 0.0452s/iter; left time: 407.2127s\n",
      "\titers: 200, epoch: 60 | loss: 0.1000190\n",
      "\tspeed: 0.0209s/iter; left time: 186.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1045699 Vali Loss: 0.1260350 Test Loss: 0.1433356\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.1069357\n",
      "\tspeed: 0.0466s/iter; left time: 408.8306s\n",
      "\titers: 200, epoch: 61 | loss: 0.1066801\n",
      "\tspeed: 0.0209s/iter; left time: 181.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.1046159 Vali Loss: 0.1262933 Test Loss: 0.1439901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1067538\n",
      "\tspeed: 0.0452s/iter; left time: 386.5101s\n",
      "\titers: 200, epoch: 62 | loss: 0.1066487\n",
      "\tspeed: 0.0209s/iter; left time: 176.6425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1045509 Vali Loss: 0.1259451 Test Loss: 0.1432046\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048424143344163895, rmse:0.22005486488342285, mae:0.14307503402233124, rse:0.7794520258903503\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2733041\n",
      "\tspeed: 0.0240s/iter; left time: 530.5074s\n",
      "\titers: 200, epoch: 1 | loss: 0.2486118\n",
      "\tspeed: 0.0211s/iter; left time: 464.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.2720052 Vali Loss: 0.2292754 Test Loss: 0.2321390\n",
      "Validation loss decreased (inf --> 0.229275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501245\n",
      "\tspeed: 0.0452s/iter; left time: 989.8765s\n",
      "\titers: 200, epoch: 2 | loss: 0.1419022\n",
      "\tspeed: 0.0209s/iter; left time: 455.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.1636119 Vali Loss: 0.1440349 Test Loss: 0.1509175\n",
      "Validation loss decreased (0.229275 --> 0.144035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1302628\n",
      "\tspeed: 0.0487s/iter; left time: 1053.8802s\n",
      "\titers: 200, epoch: 3 | loss: 0.1214185\n",
      "\tspeed: 0.0219s/iter; left time: 471.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.1282141 Vali Loss: 0.1328316 Test Loss: 0.1453151\n",
      "Validation loss decreased (0.144035 --> 0.132832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1173071\n",
      "\tspeed: 0.0462s/iter; left time: 989.4776s\n",
      "\titers: 200, epoch: 4 | loss: 0.1165423\n",
      "\tspeed: 0.0243s/iter; left time: 518.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 222 | Train Loss: 0.1197912 Vali Loss: 0.1308119 Test Loss: 0.1437014\n",
      "Validation loss decreased (0.132832 --> 0.130812).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1130587\n",
      "\tspeed: 0.0482s/iter; left time: 1021.7636s\n",
      "\titers: 200, epoch: 5 | loss: 0.1200719\n",
      "\tspeed: 0.0209s/iter; left time: 442.2331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.1163651 Vali Loss: 0.1289939 Test Loss: 0.1387951\n",
      "Validation loss decreased (0.130812 --> 0.128994).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1133281\n",
      "\tspeed: 0.0462s/iter; left time: 970.4892s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126720\n",
      "\tspeed: 0.0207s/iter; left time: 432.5633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.1143900 Vali Loss: 0.1289839 Test Loss: 0.1393874\n",
      "Validation loss decreased (0.128994 --> 0.128984).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1136062\n",
      "\tspeed: 0.0470s/iter; left time: 975.1818s\n",
      "\titers: 200, epoch: 7 | loss: 0.1068207\n",
      "\tspeed: 0.0214s/iter; left time: 442.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1129568 Vali Loss: 0.1288813 Test Loss: 0.1396884\n",
      "Validation loss decreased (0.128984 --> 0.128881).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1109090\n",
      "\tspeed: 0.0466s/iter; left time: 958.2273s\n",
      "\titers: 200, epoch: 8 | loss: 0.1150609\n",
      "\tspeed: 0.0232s/iter; left time: 473.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.1119167 Vali Loss: 0.1274864 Test Loss: 0.1367660\n",
      "Validation loss decreased (0.128881 --> 0.127486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1099020\n",
      "\tspeed: 0.0472s/iter; left time: 959.7491s\n",
      "\titers: 200, epoch: 9 | loss: 0.1079431\n",
      "\tspeed: 0.0212s/iter; left time: 429.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.1112272 Vali Loss: 0.1272544 Test Loss: 0.1383725\n",
      "Validation loss decreased (0.127486 --> 0.127254).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1099395\n",
      "\tspeed: 0.0553s/iter; left time: 1111.1559s\n",
      "\titers: 200, epoch: 10 | loss: 0.1108703\n",
      "\tspeed: 0.0227s/iter; left time: 454.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 222 | Train Loss: 0.1104818 Vali Loss: 0.1289230 Test Loss: 0.1409940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1105483\n",
      "\tspeed: 0.0485s/iter; left time: 963.3611s\n",
      "\titers: 200, epoch: 11 | loss: 0.1057599\n",
      "\tspeed: 0.0211s/iter; left time: 416.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.1096762 Vali Loss: 0.1277673 Test Loss: 0.1389453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1108596\n",
      "\tspeed: 0.0474s/iter; left time: 932.5733s\n",
      "\titers: 200, epoch: 12 | loss: 0.1118881\n",
      "\tspeed: 0.0241s/iter; left time: 470.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 222 | Train Loss: 0.1091056 Vali Loss: 0.1276943 Test Loss: 0.1410744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1093146\n",
      "\tspeed: 0.0470s/iter; left time: 914.4155s\n",
      "\titers: 200, epoch: 13 | loss: 0.1094457\n",
      "\tspeed: 0.0220s/iter; left time: 425.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.1088402 Vali Loss: 0.1278117 Test Loss: 0.1405839\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1091221\n",
      "\tspeed: 0.0476s/iter; left time: 915.4496s\n",
      "\titers: 200, epoch: 14 | loss: 0.1050427\n",
      "\tspeed: 0.0217s/iter; left time: 415.4760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.1081201 Vali Loss: 0.1274476 Test Loss: 0.1421491\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1038304\n",
      "\tspeed: 0.0457s/iter; left time: 867.4686s\n",
      "\titers: 200, epoch: 15 | loss: 0.1066700\n",
      "\tspeed: 0.0209s/iter; left time: 395.6615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1076028 Vali Loss: 0.1285415 Test Loss: 0.1428325\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1085553\n",
      "\tspeed: 0.0463s/iter; left time: 869.1554s\n",
      "\titers: 200, epoch: 16 | loss: 0.1015527\n",
      "\tspeed: 0.0210s/iter; left time: 391.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1071608 Vali Loss: 0.1279540 Test Loss: 0.1432049\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1035085\n",
      "\tspeed: 0.0503s/iter; left time: 932.9572s\n",
      "\titers: 200, epoch: 17 | loss: 0.1029408\n",
      "\tspeed: 0.0237s/iter; left time: 437.1348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 222 | Train Loss: 0.1068667 Vali Loss: 0.1280768 Test Loss: 0.1425950\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1006354\n",
      "\tspeed: 0.0461s/iter; left time: 845.1130s\n",
      "\titers: 200, epoch: 18 | loss: 0.1092632\n",
      "\tspeed: 0.0209s/iter; left time: 380.9290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.1065844 Vali Loss: 0.1277221 Test Loss: 0.1425489\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1035319\n",
      "\tspeed: 0.0480s/iter; left time: 868.7138s\n",
      "\titers: 200, epoch: 19 | loss: 0.1085452\n",
      "\tspeed: 0.0243s/iter; left time: 436.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 222 | Train Loss: 0.1063101 Vali Loss: 0.1279139 Test Loss: 0.1433686\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04185667261481285, rmse:0.20458903908729553, mae:0.13837240636348724, rse:0.7246708273887634\n",
      "Intermediate time for DE and pred_len 168: 00h:09m:22.19s\n",
      "Intermediate time for DE: 00h:31m:11.54s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2762307\n",
      "\tspeed: 0.0483s/iter; left time: 1072.9105s\n",
      "\titers: 200, epoch: 1 | loss: 0.2635011\n",
      "\tspeed: 0.0200s/iter; left time: 442.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.2846532 Vali Loss: 0.2345314 Test Loss: 0.2545903\n",
      "Validation loss decreased (inf --> 0.234531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462703\n",
      "\tspeed: 0.0422s/iter; left time: 926.9620s\n",
      "\titers: 200, epoch: 2 | loss: 0.1180813\n",
      "\tspeed: 0.0201s/iter; left time: 439.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.1548678 Vali Loss: 0.1075235 Test Loss: 0.1276649\n",
      "Validation loss decreased (0.234531 --> 0.107523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056325\n",
      "\tspeed: 0.0416s/iter; left time: 905.8583s\n",
      "\titers: 200, epoch: 3 | loss: 0.0978099\n",
      "\tspeed: 0.0200s/iter; left time: 433.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.1021520 Vali Loss: 0.1020983 Test Loss: 0.1142755\n",
      "Validation loss decreased (0.107523 --> 0.102098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859044\n",
      "\tspeed: 0.0417s/iter; left time: 897.6637s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863699\n",
      "\tspeed: 0.0202s/iter; left time: 433.5877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0910893 Vali Loss: 0.0958324 Test Loss: 0.1089872\n",
      "Validation loss decreased (0.102098 --> 0.095832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870712\n",
      "\tspeed: 0.0476s/iter; left time: 1014.1483s\n",
      "\titers: 200, epoch: 5 | loss: 0.0877185\n",
      "\tspeed: 0.0239s/iter; left time: 507.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 223 | Train Loss: 0.0873805 Vali Loss: 0.0958049 Test Loss: 0.1089031\n",
      "Validation loss decreased (0.095832 --> 0.095805).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0865226\n",
      "\tspeed: 0.0454s/iter; left time: 958.0623s\n",
      "\titers: 200, epoch: 6 | loss: 0.0773692\n",
      "\tspeed: 0.0202s/iter; left time: 424.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0851459 Vali Loss: 0.0935297 Test Loss: 0.1068609\n",
      "Validation loss decreased (0.095805 --> 0.093530).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0910266\n",
      "\tspeed: 0.0470s/iter; left time: 981.2347s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836363\n",
      "\tspeed: 0.0208s/iter; left time: 432.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0837980 Vali Loss: 0.0958510 Test Loss: 0.1085853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0929813\n",
      "\tspeed: 0.0430s/iter; left time: 887.3061s\n",
      "\titers: 200, epoch: 8 | loss: 0.0798118\n",
      "\tspeed: 0.0204s/iter; left time: 418.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0825603 Vali Loss: 0.0935541 Test Loss: 0.1069116\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0834011\n",
      "\tspeed: 0.0427s/iter; left time: 872.6449s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846200\n",
      "\tspeed: 0.0208s/iter; left time: 421.7069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0822000 Vali Loss: 0.0931175 Test Loss: 0.1068537\n",
      "Validation loss decreased (0.093530 --> 0.093118).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833874\n",
      "\tspeed: 0.0427s/iter; left time: 862.8177s\n",
      "\titers: 200, epoch: 10 | loss: 0.0764196\n",
      "\tspeed: 0.0203s/iter; left time: 407.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0813710 Vali Loss: 0.0927926 Test Loss: 0.1075682\n",
      "Validation loss decreased (0.093118 --> 0.092793).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0779778\n",
      "\tspeed: 0.0441s/iter; left time: 881.3113s\n",
      "\titers: 200, epoch: 11 | loss: 0.0850850\n",
      "\tspeed: 0.0202s/iter; left time: 401.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0807591 Vali Loss: 0.0936243 Test Loss: 0.1078661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0772677\n",
      "\tspeed: 0.0415s/iter; left time: 819.3574s\n",
      "\titers: 200, epoch: 12 | loss: 0.0849133\n",
      "\tspeed: 0.0202s/iter; left time: 397.6670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0806203 Vali Loss: 0.0925910 Test Loss: 0.1069170\n",
      "Validation loss decreased (0.092793 --> 0.092591).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0850292\n",
      "\tspeed: 0.0434s/iter; left time: 847.0108s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785023\n",
      "\tspeed: 0.0202s/iter; left time: 393.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0802062 Vali Loss: 0.0925909 Test Loss: 0.1061884\n",
      "Validation loss decreased (0.092591 --> 0.092591).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785980\n",
      "\tspeed: 0.0433s/iter; left time: 835.6028s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815690\n",
      "\tspeed: 0.0202s/iter; left time: 388.4163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0797629 Vali Loss: 0.0924830 Test Loss: 0.1066159\n",
      "Validation loss decreased (0.092591 --> 0.092483).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0841059\n",
      "\tspeed: 0.0427s/iter; left time: 815.1172s\n",
      "\titers: 200, epoch: 15 | loss: 0.0772365\n",
      "\tspeed: 0.0202s/iter; left time: 383.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0795653 Vali Loss: 0.0932157 Test Loss: 0.1072776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0795897\n",
      "\tspeed: 0.0432s/iter; left time: 815.3891s\n",
      "\titers: 200, epoch: 16 | loss: 0.0753777\n",
      "\tspeed: 0.0202s/iter; left time: 379.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0794256 Vali Loss: 0.0920563 Test Loss: 0.1061548\n",
      "Validation loss decreased (0.092483 --> 0.092056).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0772193\n",
      "\tspeed: 0.0449s/iter; left time: 835.8224s\n",
      "\titers: 200, epoch: 17 | loss: 0.0747934\n",
      "\tspeed: 0.0203s/iter; left time: 375.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 223 | Train Loss: 0.0793213 Vali Loss: 0.0931103 Test Loss: 0.1067440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747713\n",
      "\tspeed: 0.0414s/iter; left time: 762.5356s\n",
      "\titers: 200, epoch: 18 | loss: 0.0862258\n",
      "\tspeed: 0.0200s/iter; left time: 366.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0791298 Vali Loss: 0.0921512 Test Loss: 0.1064603\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0825629\n",
      "\tspeed: 0.0418s/iter; left time: 759.3959s\n",
      "\titers: 200, epoch: 19 | loss: 0.0780634\n",
      "\tspeed: 0.0200s/iter; left time: 362.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0787885 Vali Loss: 0.0922389 Test Loss: 0.1064509\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0749995\n",
      "\tspeed: 0.0414s/iter; left time: 742.9712s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809347\n",
      "\tspeed: 0.0202s/iter; left time: 361.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0787338 Vali Loss: 0.0917851 Test Loss: 0.1061701\n",
      "Validation loss decreased (0.092056 --> 0.091785).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0832797\n",
      "\tspeed: 0.0441s/iter; left time: 782.7416s\n",
      "\titers: 200, epoch: 21 | loss: 0.0727622\n",
      "\tspeed: 0.0202s/iter; left time: 356.6382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0786904 Vali Loss: 0.0932141 Test Loss: 0.1068489\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0788772\n",
      "\tspeed: 0.0429s/iter; left time: 751.1592s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747757\n",
      "\tspeed: 0.0202s/iter; left time: 351.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0784753 Vali Loss: 0.0922331 Test Loss: 0.1063197\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0788626\n",
      "\tspeed: 0.0455s/iter; left time: 787.7838s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793575\n",
      "\tspeed: 0.0208s/iter; left time: 357.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0784267 Vali Loss: 0.0918397 Test Loss: 0.1061428\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0749169\n",
      "\tspeed: 0.0414s/iter; left time: 707.0732s\n",
      "\titers: 200, epoch: 24 | loss: 0.0753831\n",
      "\tspeed: 0.0202s/iter; left time: 343.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0783742 Vali Loss: 0.0922403 Test Loss: 0.1065024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0784230\n",
      "\tspeed: 0.0416s/iter; left time: 700.9139s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784471\n",
      "\tspeed: 0.0202s/iter; left time: 338.7556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0782461 Vali Loss: 0.0925442 Test Loss: 0.1068081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763853\n",
      "\tspeed: 0.0432s/iter; left time: 718.9408s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793958\n",
      "\tspeed: 0.0203s/iter; left time: 336.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0782700 Vali Loss: 0.0923135 Test Loss: 0.1068690\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747001\n",
      "\tspeed: 0.0474s/iter; left time: 777.5013s\n",
      "\titers: 200, epoch: 27 | loss: 0.0807642\n",
      "\tspeed: 0.0232s/iter; left time: 377.6607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0781686 Vali Loss: 0.0923405 Test Loss: 0.1064812\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0738155\n",
      "\tspeed: 0.0424s/iter; left time: 686.1063s\n",
      "\titers: 200, epoch: 28 | loss: 0.0812550\n",
      "\tspeed: 0.0212s/iter; left time: 341.4397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0780317 Vali Loss: 0.0921537 Test Loss: 0.1063893\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0752697\n",
      "\tspeed: 0.0424s/iter; left time: 677.1167s\n",
      "\titers: 200, epoch: 29 | loss: 0.0774270\n",
      "\tspeed: 0.0203s/iter; left time: 321.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0779177 Vali Loss: 0.0927803 Test Loss: 0.1068341\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0787583\n",
      "\tspeed: 0.0416s/iter; left time: 654.6935s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751580\n",
      "\tspeed: 0.0202s/iter; left time: 316.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0778590 Vali Loss: 0.0923661 Test Loss: 0.1068291\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026821088045835495, rmse:0.16377145051956177, mae:0.10617007315158844, rse:0.5649650692939758\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2793686\n",
      "\tspeed: 0.0227s/iter; left time: 502.9149s\n",
      "\titers: 200, epoch: 1 | loss: 0.2693298\n",
      "\tspeed: 0.0203s/iter; left time: 447.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.2860429 Vali Loss: 0.2387114 Test Loss: 0.2581464\n",
      "Validation loss decreased (inf --> 0.238711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1410758\n",
      "\tspeed: 0.0457s/iter; left time: 1004.9937s\n",
      "\titers: 200, epoch: 2 | loss: 0.1199975\n",
      "\tspeed: 0.0203s/iter; left time: 443.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1571827 Vali Loss: 0.1098685 Test Loss: 0.1288528\n",
      "Validation loss decreased (0.238711 --> 0.109869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1047048\n",
      "\tspeed: 0.0466s/iter; left time: 1014.2962s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938154\n",
      "\tspeed: 0.0207s/iter; left time: 448.9157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1013627 Vali Loss: 0.0964666 Test Loss: 0.1093780\n",
      "Validation loss decreased (0.109869 --> 0.096467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0908748\n",
      "\tspeed: 0.0473s/iter; left time: 1019.0496s\n",
      "\titers: 200, epoch: 4 | loss: 0.0965955\n",
      "\tspeed: 0.0223s/iter; left time: 477.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0905734 Vali Loss: 0.0966123 Test Loss: 0.1098793\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856086\n",
      "\tspeed: 0.0428s/iter; left time: 912.9552s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853570\n",
      "\tspeed: 0.0203s/iter; left time: 430.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0865073 Vali Loss: 0.0934426 Test Loss: 0.1061646\n",
      "Validation loss decreased (0.096467 --> 0.093443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0795323\n",
      "\tspeed: 0.0430s/iter; left time: 906.9651s\n",
      "\titers: 200, epoch: 6 | loss: 0.0903210\n",
      "\tspeed: 0.0211s/iter; left time: 443.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0844781 Vali Loss: 0.0934596 Test Loss: 0.1064623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811414\n",
      "\tspeed: 0.0439s/iter; left time: 916.1863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0801971\n",
      "\tspeed: 0.0202s/iter; left time: 420.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0836599 Vali Loss: 0.0939470 Test Loss: 0.1066778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0799184\n",
      "\tspeed: 0.0445s/iter; left time: 917.9904s\n",
      "\titers: 200, epoch: 8 | loss: 0.0786862\n",
      "\tspeed: 0.0209s/iter; left time: 430.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0826515 Vali Loss: 0.0929084 Test Loss: 0.1069776\n",
      "Validation loss decreased (0.093443 --> 0.092908).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797641\n",
      "\tspeed: 0.0444s/iter; left time: 907.2075s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805009\n",
      "\tspeed: 0.0202s/iter; left time: 409.8619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0819511 Vali Loss: 0.0927792 Test Loss: 0.1072595\n",
      "Validation loss decreased (0.092908 --> 0.092779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793059\n",
      "\tspeed: 0.0436s/iter; left time: 881.1734s\n",
      "\titers: 200, epoch: 10 | loss: 0.0776059\n",
      "\tspeed: 0.0202s/iter; left time: 405.5002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0813555 Vali Loss: 0.0931993 Test Loss: 0.1069561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0812942\n",
      "\tspeed: 0.0444s/iter; left time: 886.4384s\n",
      "\titers: 200, epoch: 11 | loss: 0.0773368\n",
      "\tspeed: 0.0205s/iter; left time: 407.3909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0807996 Vali Loss: 0.0935010 Test Loss: 0.1081753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819042\n",
      "\tspeed: 0.0448s/iter; left time: 884.5508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0891401\n",
      "\tspeed: 0.0204s/iter; left time: 399.9753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0802689 Vali Loss: 0.0921093 Test Loss: 0.1080482\n",
      "Validation loss decreased (0.092779 --> 0.092109).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825793\n",
      "\tspeed: 0.0434s/iter; left time: 847.8232s\n",
      "\titers: 200, epoch: 13 | loss: 0.0778091\n",
      "\tspeed: 0.0203s/iter; left time: 393.7781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0802096 Vali Loss: 0.0923726 Test Loss: 0.1076031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0799974\n",
      "\tspeed: 0.0488s/iter; left time: 941.8471s\n",
      "\titers: 200, epoch: 14 | loss: 0.0840938\n",
      "\tspeed: 0.0200s/iter; left time: 383.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0799977 Vali Loss: 0.0940052 Test Loss: 0.1118738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0742097\n",
      "\tspeed: 0.0442s/iter; left time: 843.2188s\n",
      "\titers: 200, epoch: 15 | loss: 0.0788889\n",
      "\tspeed: 0.0203s/iter; left time: 384.8233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0796003 Vali Loss: 0.0926683 Test Loss: 0.1094749\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0827809\n",
      "\tspeed: 0.0434s/iter; left time: 818.2718s\n",
      "\titers: 200, epoch: 16 | loss: 0.0761974\n",
      "\tspeed: 0.0202s/iter; left time: 379.7104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0792026 Vali Loss: 0.0926945 Test Loss: 0.1080312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776870\n",
      "\tspeed: 0.0433s/iter; left time: 807.0912s\n",
      "\titers: 200, epoch: 17 | loss: 0.0801408\n",
      "\tspeed: 0.0209s/iter; left time: 386.9486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0792390 Vali Loss: 0.0917448 Test Loss: 0.1088138\n",
      "Validation loss decreased (0.092109 --> 0.091745).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0825436\n",
      "\tspeed: 0.0458s/iter; left time: 843.6806s\n",
      "\titers: 200, epoch: 18 | loss: 0.0730348\n",
      "\tspeed: 0.0202s/iter; left time: 370.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0791526 Vali Loss: 0.0928045 Test Loss: 0.1083731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0804147\n",
      "\tspeed: 0.0427s/iter; left time: 777.1038s\n",
      "\titers: 200, epoch: 19 | loss: 0.0762362\n",
      "\tspeed: 0.0211s/iter; left time: 381.3526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 223 | Train Loss: 0.0788301 Vali Loss: 0.0921725 Test Loss: 0.1092025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814857\n",
      "\tspeed: 0.0432s/iter; left time: 776.1115s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812849\n",
      "\tspeed: 0.0201s/iter; left time: 359.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0786442 Vali Loss: 0.0929008 Test Loss: 0.1094604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0769161\n",
      "\tspeed: 0.0430s/iter; left time: 763.2724s\n",
      "\titers: 200, epoch: 21 | loss: 0.0792939\n",
      "\tspeed: 0.0205s/iter; left time: 361.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0784565 Vali Loss: 0.0921167 Test Loss: 0.1095856\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779309\n",
      "\tspeed: 0.0452s/iter; left time: 791.8984s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750891\n",
      "\tspeed: 0.0203s/iter; left time: 352.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0784182 Vali Loss: 0.0918832 Test Loss: 0.1091213\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780503\n",
      "\tspeed: 0.0423s/iter; left time: 731.6312s\n",
      "\titers: 200, epoch: 23 | loss: 0.0786653\n",
      "\tspeed: 0.0203s/iter; left time: 348.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0784081 Vali Loss: 0.0925678 Test Loss: 0.1100193\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0802660\n",
      "\tspeed: 0.0434s/iter; left time: 740.5242s\n",
      "\titers: 200, epoch: 24 | loss: 0.0779760\n",
      "\tspeed: 0.0202s/iter; left time: 343.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0922913 Test Loss: 0.1099897\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0787994\n",
      "\tspeed: 0.0434s/iter; left time: 730.9627s\n",
      "\titers: 200, epoch: 25 | loss: 0.0808907\n",
      "\tspeed: 0.0203s/iter; left time: 339.6015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0781578 Vali Loss: 0.0923322 Test Loss: 0.1098471\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821575\n",
      "\tspeed: 0.0436s/iter; left time: 725.1020s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739094\n",
      "\tspeed: 0.0213s/iter; left time: 351.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0780644 Vali Loss: 0.0924523 Test Loss: 0.1103858\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0761999\n",
      "\tspeed: 0.0434s/iter; left time: 712.6704s\n",
      "\titers: 200, epoch: 27 | loss: 0.0786215\n",
      "\tspeed: 0.0200s/iter; left time: 325.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0780216 Vali Loss: 0.0919582 Test Loss: 0.1091315\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028750205412507057, rmse:0.16955885291099548, mae:0.10881377011537552, rse:0.5849299430847168\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:18.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2830859\n",
      "\tspeed: 0.0463s/iter; left time: 1023.0694s\n",
      "\titers: 200, epoch: 1 | loss: 0.2743740\n",
      "\tspeed: 0.0204s/iter; left time: 449.1174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.2865906 Vali Loss: 0.2415922 Test Loss: 0.2616447\n",
      "Validation loss decreased (inf --> 0.241592).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1478237\n",
      "\tspeed: 0.0432s/iter; left time: 946.0416s\n",
      "\titers: 200, epoch: 2 | loss: 0.1268669\n",
      "\tspeed: 0.0204s/iter; left time: 443.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1614316 Vali Loss: 0.1285596 Test Loss: 0.1510565\n",
      "Validation loss decreased (0.241592 --> 0.128560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1189906\n",
      "\tspeed: 0.0437s/iter; left time: 945.6054s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098326\n",
      "\tspeed: 0.0204s/iter; left time: 439.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1174459 Vali Loss: 0.1205229 Test Loss: 0.1438784\n",
      "Validation loss decreased (0.128560 --> 0.120523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124115\n",
      "\tspeed: 0.0436s/iter; left time: 933.5453s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102599\n",
      "\tspeed: 0.0206s/iter; left time: 440.1823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1116619 Vali Loss: 0.1212728 Test Loss: 0.1459699\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1115558\n",
      "\tspeed: 0.0429s/iter; left time: 910.7218s\n",
      "\titers: 200, epoch: 5 | loss: 0.1066562\n",
      "\tspeed: 0.0204s/iter; left time: 431.0541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.1089256 Vali Loss: 0.1229624 Test Loss: 0.1504071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1053467\n",
      "\tspeed: 0.0431s/iter; left time: 903.8968s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036319\n",
      "\tspeed: 0.0203s/iter; left time: 425.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1072726 Vali Loss: 0.1256787 Test Loss: 0.1525851\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1046161\n",
      "\tspeed: 0.0424s/iter; left time: 881.3801s\n",
      "\titers: 200, epoch: 7 | loss: 0.1032366\n",
      "\tspeed: 0.0203s/iter; left time: 419.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.1060321 Vali Loss: 0.1266989 Test Loss: 0.1591470\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1062903\n",
      "\tspeed: 0.0427s/iter; left time: 876.7246s\n",
      "\titers: 200, epoch: 8 | loss: 0.1077296\n",
      "\tspeed: 0.0221s/iter; left time: 451.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1051435 Vali Loss: 0.1254328 Test Loss: 0.1550419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043956\n",
      "\tspeed: 0.0458s/iter; left time: 931.0464s\n",
      "\titers: 200, epoch: 9 | loss: 0.1047444\n",
      "\tspeed: 0.0227s/iter; left time: 459.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 222 | Train Loss: 0.1047975 Vali Loss: 0.1283385 Test Loss: 0.1620889\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1064517\n",
      "\tspeed: 0.0427s/iter; left time: 859.1517s\n",
      "\titers: 200, epoch: 10 | loss: 0.1051306\n",
      "\tspeed: 0.0203s/iter; left time: 405.7928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.1040109 Vali Loss: 0.1263400 Test Loss: 0.1575660\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1020149\n",
      "\tspeed: 0.0439s/iter; left time: 873.5289s\n",
      "\titers: 200, epoch: 11 | loss: 0.0961309\n",
      "\tspeed: 0.0208s/iter; left time: 410.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.1033939 Vali Loss: 0.1245517 Test Loss: 0.1525567\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011116\n",
      "\tspeed: 0.0431s/iter; left time: 848.2368s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045583\n",
      "\tspeed: 0.0205s/iter; left time: 400.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.1028317 Vali Loss: 0.1266475 Test Loss: 0.1584357\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0991534\n",
      "\tspeed: 0.0432s/iter; left time: 840.5174s\n",
      "\titers: 200, epoch: 13 | loss: 0.1028156\n",
      "\tspeed: 0.0207s/iter; left time: 400.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1026982 Vali Loss: 0.1249986 Test Loss: 0.1543648\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04194752871990204, rmse:0.2048109620809555, mae:0.14387835562229156, rse:0.7082648277282715\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2857521\n",
      "\tspeed: 0.0226s/iter; left time: 499.0526s\n",
      "\titers: 200, epoch: 1 | loss: 0.2757615\n",
      "\tspeed: 0.0203s/iter; left time: 446.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.2916806 Vali Loss: 0.2445744 Test Loss: 0.2660964\n",
      "Validation loss decreased (inf --> 0.244574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1426474\n",
      "\tspeed: 0.0472s/iter; left time: 1033.1265s\n",
      "\titers: 200, epoch: 2 | loss: 0.1280049\n",
      "\tspeed: 0.0203s/iter; left time: 442.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.1630443 Vali Loss: 0.1273275 Test Loss: 0.1519118\n",
      "Validation loss decreased (0.244574 --> 0.127328).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1187076\n",
      "\tspeed: 0.0483s/iter; left time: 1045.4909s\n",
      "\titers: 200, epoch: 3 | loss: 0.1128903\n",
      "\tspeed: 0.0204s/iter; left time: 439.4453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1179070 Vali Loss: 0.1216799 Test Loss: 0.1441890\n",
      "Validation loss decreased (0.127328 --> 0.121680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1176371\n",
      "\tspeed: 0.0449s/iter; left time: 962.2916s\n",
      "\titers: 200, epoch: 4 | loss: 0.1096063\n",
      "\tspeed: 0.0205s/iter; left time: 436.3690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.1111886 Vali Loss: 0.1207477 Test Loss: 0.1466962\n",
      "Validation loss decreased (0.121680 --> 0.120748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166723\n",
      "\tspeed: 0.0446s/iter; left time: 945.3326s\n",
      "\titers: 200, epoch: 5 | loss: 0.1139806\n",
      "\tspeed: 0.0203s/iter; left time: 428.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.1086714 Vali Loss: 0.1235578 Test Loss: 0.1564359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026459\n",
      "\tspeed: 0.0440s/iter; left time: 923.9394s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138240\n",
      "\tspeed: 0.0216s/iter; left time: 451.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1069735 Vali Loss: 0.1237044 Test Loss: 0.1564380\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1069064\n",
      "\tspeed: 0.0451s/iter; left time: 936.4274s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059684\n",
      "\tspeed: 0.0206s/iter; left time: 426.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1059816 Vali Loss: 0.1225111 Test Loss: 0.1536749\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1027634\n",
      "\tspeed: 0.0451s/iter; left time: 926.1424s\n",
      "\titers: 200, epoch: 8 | loss: 0.1018030\n",
      "\tspeed: 0.0225s/iter; left time: 459.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 222 | Train Loss: 0.1056321 Vali Loss: 0.1218389 Test Loss: 0.1519313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063525\n",
      "\tspeed: 0.0459s/iter; left time: 932.9318s\n",
      "\titers: 200, epoch: 9 | loss: 0.1072328\n",
      "\tspeed: 0.0210s/iter; left time: 425.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1047135 Vali Loss: 0.1208165 Test Loss: 0.1489650\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0998539\n",
      "\tspeed: 0.0445s/iter; left time: 893.6364s\n",
      "\titers: 200, epoch: 10 | loss: 0.1041441\n",
      "\tspeed: 0.0205s/iter; left time: 409.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1039581 Vali Loss: 0.1213863 Test Loss: 0.1500021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1029014\n",
      "\tspeed: 0.0438s/iter; left time: 871.4536s\n",
      "\titers: 200, epoch: 11 | loss: 0.1065745\n",
      "\tspeed: 0.0204s/iter; left time: 402.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1035431 Vali Loss: 0.1209281 Test Loss: 0.1487738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1033012\n",
      "\tspeed: 0.0451s/iter; left time: 886.0714s\n",
      "\titers: 200, epoch: 12 | loss: 0.1080546\n",
      "\tspeed: 0.0203s/iter; left time: 397.2675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1033090 Vali Loss: 0.1216931 Test Loss: 0.1507952\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1062972\n",
      "\tspeed: 0.0442s/iter; left time: 858.8090s\n",
      "\titers: 200, epoch: 13 | loss: 0.1032194\n",
      "\tspeed: 0.0204s/iter; left time: 393.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.1027705 Vali Loss: 0.1215444 Test Loss: 0.1481337\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1045286\n",
      "\tspeed: 0.0444s/iter; left time: 852.9407s\n",
      "\titers: 200, epoch: 14 | loss: 0.1021893\n",
      "\tspeed: 0.0204s/iter; left time: 390.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1025529 Vali Loss: 0.1212421 Test Loss: 0.1494780\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04693262279033661, rmse:0.21663938462734222, mae:0.14669613540172577, rse:0.7491691708564758\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:08.80s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2847386\n",
      "\tspeed: 0.0488s/iter; left time: 1078.5333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2732988\n",
      "\tspeed: 0.0205s/iter; left time: 451.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.2875838 Vali Loss: 0.2422487 Test Loss: 0.2623464\n",
      "Validation loss decreased (inf --> 0.242249).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1490528\n",
      "\tspeed: 0.0449s/iter; left time: 981.9699s\n",
      "\titers: 200, epoch: 2 | loss: 0.1271268\n",
      "\tspeed: 0.0206s/iter; left time: 447.5867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1616939 Vali Loss: 0.1300322 Test Loss: 0.1555596\n",
      "Validation loss decreased (0.242249 --> 0.130032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1159026\n",
      "\tspeed: 0.0454s/iter; left time: 983.3987s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142748\n",
      "\tspeed: 0.0205s/iter; left time: 442.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.1201043 Vali Loss: 0.1246263 Test Loss: 0.1511487\n",
      "Validation loss decreased (0.130032 --> 0.124626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1161936\n",
      "\tspeed: 0.0455s/iter; left time: 975.6991s\n",
      "\titers: 200, epoch: 4 | loss: 0.1142678\n",
      "\tspeed: 0.0206s/iter; left time: 439.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1146955 Vali Loss: 0.1259331 Test Loss: 0.1559995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1156335\n",
      "\tspeed: 0.0437s/iter; left time: 926.6451s\n",
      "\titers: 200, epoch: 5 | loss: 0.1136656\n",
      "\tspeed: 0.0206s/iter; left time: 435.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1125922 Vali Loss: 0.1289697 Test Loss: 0.1656465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1125581\n",
      "\tspeed: 0.0434s/iter; left time: 911.3230s\n",
      "\titers: 200, epoch: 6 | loss: 0.1118595\n",
      "\tspeed: 0.0205s/iter; left time: 429.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1109664 Vali Loss: 0.1305788 Test Loss: 0.1679211\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1114427\n",
      "\tspeed: 0.0440s/iter; left time: 914.5409s\n",
      "\titers: 200, epoch: 7 | loss: 0.1108004\n",
      "\tspeed: 0.0206s/iter; left time: 424.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.1101296 Vali Loss: 0.1268001 Test Loss: 0.1582920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1117834\n",
      "\tspeed: 0.0436s/iter; left time: 895.8243s\n",
      "\titers: 200, epoch: 8 | loss: 0.1109027\n",
      "\tspeed: 0.0207s/iter; left time: 423.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1092303 Vali Loss: 0.1320953 Test Loss: 0.1703052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1069235\n",
      "\tspeed: 0.0441s/iter; left time: 895.3744s\n",
      "\titers: 200, epoch: 9 | loss: 0.1065887\n",
      "\tspeed: 0.0208s/iter; left time: 420.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1085968 Vali Loss: 0.1300069 Test Loss: 0.1626084\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1086212\n",
      "\tspeed: 0.0449s/iter; left time: 903.3908s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030650\n",
      "\tspeed: 0.0205s/iter; left time: 409.9741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1079234 Vali Loss: 0.1297312 Test Loss: 0.1594644\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1081972\n",
      "\tspeed: 0.0442s/iter; left time: 877.7755s\n",
      "\titers: 200, epoch: 11 | loss: 0.1104306\n",
      "\tspeed: 0.0207s/iter; left time: 409.5352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1075208 Vali Loss: 0.1284075 Test Loss: 0.1579085\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1100941\n",
      "\tspeed: 0.0440s/iter; left time: 864.8766s\n",
      "\titers: 200, epoch: 12 | loss: 0.1078582\n",
      "\tspeed: 0.0205s/iter; left time: 400.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1069388 Vali Loss: 0.1275865 Test Loss: 0.1551821\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1002419\n",
      "\tspeed: 0.0440s/iter; left time: 855.0907s\n",
      "\titers: 200, epoch: 13 | loss: 0.1029617\n",
      "\tspeed: 0.0206s/iter; left time: 398.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1065173 Vali Loss: 0.1302151 Test Loss: 0.1581639\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04640279710292816, rmse:0.21541307866573334, mae:0.15114876627922058, rse:0.7468680739402771\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2827889\n",
      "\tspeed: 0.0230s/iter; left time: 509.4022s\n",
      "\titers: 200, epoch: 1 | loss: 0.2717319\n",
      "\tspeed: 0.0207s/iter; left time: 455.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.2875044 Vali Loss: 0.2468908 Test Loss: 0.2667910\n",
      "Validation loss decreased (inf --> 0.246891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483081\n",
      "\tspeed: 0.0458s/iter; left time: 1002.9208s\n",
      "\titers: 200, epoch: 2 | loss: 0.1301151\n",
      "\tspeed: 0.0206s/iter; left time: 448.5834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1614167 Vali Loss: 0.1320312 Test Loss: 0.1557729\n",
      "Validation loss decreased (0.246891 --> 0.132031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1208680\n",
      "\tspeed: 0.0501s/iter; left time: 1085.3171s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123617\n",
      "\tspeed: 0.0206s/iter; left time: 443.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.1204286 Vali Loss: 0.1251208 Test Loss: 0.1511288\n",
      "Validation loss decreased (0.132031 --> 0.125121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124564\n",
      "\tspeed: 0.0478s/iter; left time: 1024.8678s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097842\n",
      "\tspeed: 0.0207s/iter; left time: 441.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.1146207 Vali Loss: 0.1287144 Test Loss: 0.1621836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1086292\n",
      "\tspeed: 0.0459s/iter; left time: 974.1550s\n",
      "\titers: 200, epoch: 5 | loss: 0.1128315\n",
      "\tspeed: 0.0205s/iter; left time: 432.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.1123435 Vali Loss: 0.1277754 Test Loss: 0.1615553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1128400\n",
      "\tspeed: 0.0438s/iter; left time: 918.6454s\n",
      "\titers: 200, epoch: 6 | loss: 0.1101898\n",
      "\tspeed: 0.0205s/iter; left time: 427.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1108323 Vali Loss: 0.1293614 Test Loss: 0.1619483\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1088920\n",
      "\tspeed: 0.0441s/iter; left time: 915.4794s\n",
      "\titers: 200, epoch: 7 | loss: 0.1099801\n",
      "\tspeed: 0.0205s/iter; left time: 422.8221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.1101685 Vali Loss: 0.1274933 Test Loss: 0.1573811\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1096876\n",
      "\tspeed: 0.0438s/iter; left time: 900.2242s\n",
      "\titers: 200, epoch: 8 | loss: 0.1091753\n",
      "\tspeed: 0.0205s/iter; left time: 420.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1093744 Vali Loss: 0.1286852 Test Loss: 0.1589296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1071864\n",
      "\tspeed: 0.0445s/iter; left time: 904.9110s\n",
      "\titers: 200, epoch: 9 | loss: 0.1103567\n",
      "\tspeed: 0.0205s/iter; left time: 415.3460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.1089083 Vali Loss: 0.1305566 Test Loss: 0.1642011\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1032997\n",
      "\tspeed: 0.0447s/iter; left time: 897.8975s\n",
      "\titers: 200, epoch: 10 | loss: 0.1062638\n",
      "\tspeed: 0.0206s/iter; left time: 412.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1078734 Vali Loss: 0.1292104 Test Loss: 0.1591856\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1080145\n",
      "\tspeed: 0.0450s/iter; left time: 894.9786s\n",
      "\titers: 200, epoch: 11 | loss: 0.1034257\n",
      "\tspeed: 0.0207s/iter; left time: 410.3172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.1075698 Vali Loss: 0.1302238 Test Loss: 0.1593552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1071013\n",
      "\tspeed: 0.0485s/iter; left time: 952.9730s\n",
      "\titers: 200, epoch: 12 | loss: 0.1045469\n",
      "\tspeed: 0.0220s/iter; left time: 430.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 222 | Train Loss: 0.1070806 Vali Loss: 0.1295131 Test Loss: 0.1613695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1073833\n",
      "\tspeed: 0.0442s/iter; left time: 859.6893s\n",
      "\titers: 200, epoch: 13 | loss: 0.1102557\n",
      "\tspeed: 0.0205s/iter; left time: 395.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.1067905 Vali Loss: 0.1295707 Test Loss: 0.1595024\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04654495418071747, rmse:0.2157427966594696, mae:0.15112879872322083, rse:0.7480112910270691\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:06.10s\n",
      "Intermediate time for GB: 00h:12m:33.39s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2734229\n",
      "\tspeed: 0.0414s/iter; left time: 920.0621s\n",
      "\titers: 200, epoch: 1 | loss: 0.2591398\n",
      "\tspeed: 0.0133s/iter; left time: 293.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 223 | Train Loss: 0.2797764 Vali Loss: 0.2077011 Test Loss: 0.2316831\n",
      "Validation loss decreased (inf --> 0.207701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501102\n",
      "\tspeed: 0.0330s/iter; left time: 724.8306s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156371\n",
      "\tspeed: 0.0133s/iter; left time: 290.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 223 | Train Loss: 0.1579866 Vali Loss: 0.0862343 Test Loss: 0.0958197\n",
      "Validation loss decreased (0.207701 --> 0.086234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1001764\n",
      "\tspeed: 0.0377s/iter; left time: 820.1684s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914646\n",
      "\tspeed: 0.0177s/iter; left time: 383.5372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0996259 Vali Loss: 0.0773804 Test Loss: 0.0889997\n",
      "Validation loss decreased (0.086234 --> 0.077380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0825320\n",
      "\tspeed: 0.0421s/iter; left time: 905.6007s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785926\n",
      "\tspeed: 0.0228s/iter; left time: 488.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0848808 Vali Loss: 0.0700407 Test Loss: 0.0814023\n",
      "Validation loss decreased (0.077380 --> 0.070041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759574\n",
      "\tspeed: 0.0421s/iter; left time: 897.2981s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730125\n",
      "\tspeed: 0.0163s/iter; left time: 345.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0764828 Vali Loss: 0.0672355 Test Loss: 0.0818017\n",
      "Validation loss decreased (0.070041 --> 0.067236).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0721011\n",
      "\tspeed: 0.0413s/iter; left time: 871.3548s\n",
      "\titers: 200, epoch: 6 | loss: 0.0727575\n",
      "\tspeed: 0.0202s/iter; left time: 423.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0723590 Vali Loss: 0.0652889 Test Loss: 0.0797523\n",
      "Validation loss decreased (0.067236 --> 0.065289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0692551\n",
      "\tspeed: 0.0422s/iter; left time: 880.0688s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711924\n",
      "\tspeed: 0.0159s/iter; left time: 329.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0708371 Vali Loss: 0.0639640 Test Loss: 0.0786748\n",
      "Validation loss decreased (0.065289 --> 0.063964).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0698496\n",
      "\tspeed: 0.0351s/iter; left time: 723.8807s\n",
      "\titers: 200, epoch: 8 | loss: 0.0680445\n",
      "\tspeed: 0.0213s/iter; left time: 437.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0689431 Vali Loss: 0.0626610 Test Loss: 0.0816812\n",
      "Validation loss decreased (0.063964 --> 0.062661).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672548\n",
      "\tspeed: 0.0457s/iter; left time: 933.6952s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681350\n",
      "\tspeed: 0.0199s/iter; left time: 404.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0672450 Vali Loss: 0.0624299 Test Loss: 0.0814141\n",
      "Validation loss decreased (0.062661 --> 0.062430).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0663894\n",
      "\tspeed: 0.0416s/iter; left time: 840.4020s\n",
      "\titers: 200, epoch: 10 | loss: 0.0668906\n",
      "\tspeed: 0.0187s/iter; left time: 376.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0666955 Vali Loss: 0.0616107 Test Loss: 0.0823262\n",
      "Validation loss decreased (0.062430 --> 0.061611).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0638787\n",
      "\tspeed: 0.0375s/iter; left time: 749.2767s\n",
      "\titers: 200, epoch: 11 | loss: 0.0628497\n",
      "\tspeed: 0.0190s/iter; left time: 378.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0660342 Vali Loss: 0.0623551 Test Loss: 0.0771238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0637039\n",
      "\tspeed: 0.0381s/iter; left time: 751.7328s\n",
      "\titers: 200, epoch: 12 | loss: 0.0641958\n",
      "\tspeed: 0.0199s/iter; left time: 390.8668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0653721 Vali Loss: 0.0610190 Test Loss: 0.0782874\n",
      "Validation loss decreased (0.061611 --> 0.061019).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646565\n",
      "\tspeed: 0.0397s/iter; left time: 774.5358s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586972\n",
      "\tspeed: 0.0202s/iter; left time: 393.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0643298 Vali Loss: 0.0609863 Test Loss: 0.0768389\n",
      "Validation loss decreased (0.061019 --> 0.060986).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0663159\n",
      "\tspeed: 0.0411s/iter; left time: 793.3082s\n",
      "\titers: 200, epoch: 14 | loss: 0.0670872\n",
      "\tspeed: 0.0179s/iter; left time: 344.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0644528 Vali Loss: 0.0608356 Test Loss: 0.0754247\n",
      "Validation loss decreased (0.060986 --> 0.060836).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638315\n",
      "\tspeed: 0.0432s/iter; left time: 823.5555s\n",
      "\titers: 200, epoch: 15 | loss: 0.0577864\n",
      "\tspeed: 0.0205s/iter; left time: 388.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0638601 Vali Loss: 0.0599702 Test Loss: 0.0777668\n",
      "Validation loss decreased (0.060836 --> 0.059970).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0630899\n",
      "\tspeed: 0.0397s/iter; left time: 747.8633s\n",
      "\titers: 200, epoch: 16 | loss: 0.0636763\n",
      "\tspeed: 0.0208s/iter; left time: 390.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0635268 Vali Loss: 0.0602922 Test Loss: 0.0782625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0641218\n",
      "\tspeed: 0.0476s/iter; left time: 886.8086s\n",
      "\titers: 200, epoch: 17 | loss: 0.0639976\n",
      "\tspeed: 0.0237s/iter; left time: 439.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0630966 Vali Loss: 0.0598330 Test Loss: 0.0770544\n",
      "Validation loss decreased (0.059970 --> 0.059833).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0695380\n",
      "\tspeed: 0.0422s/iter; left time: 777.3461s\n",
      "\titers: 200, epoch: 18 | loss: 0.0604190\n",
      "\tspeed: 0.0199s/iter; left time: 364.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0627721 Vali Loss: 0.0599829 Test Loss: 0.0771877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676237\n",
      "\tspeed: 0.0410s/iter; left time: 746.2375s\n",
      "\titers: 200, epoch: 19 | loss: 0.0617841\n",
      "\tspeed: 0.0198s/iter; left time: 358.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0624605 Vali Loss: 0.0592976 Test Loss: 0.0751091\n",
      "Validation loss decreased (0.059833 --> 0.059298).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0599678\n",
      "\tspeed: 0.0402s/iter; left time: 722.5991s\n",
      "\titers: 200, epoch: 20 | loss: 0.0608872\n",
      "\tspeed: 0.0205s/iter; left time: 366.1985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0624633 Vali Loss: 0.0594797 Test Loss: 0.0742862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0636331\n",
      "\tspeed: 0.0423s/iter; left time: 751.0152s\n",
      "\titers: 200, epoch: 21 | loss: 0.0605511\n",
      "\tspeed: 0.0220s/iter; left time: 388.7862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0621196 Vali Loss: 0.0590982 Test Loss: 0.0735378\n",
      "Validation loss decreased (0.059298 --> 0.059098).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0681865\n",
      "\tspeed: 0.0342s/iter; left time: 599.9069s\n",
      "\titers: 200, epoch: 22 | loss: 0.0630321\n",
      "\tspeed: 0.0131s/iter; left time: 228.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 223 | Train Loss: 0.0619806 Vali Loss: 0.0591053 Test Loss: 0.0748091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618666\n",
      "\tspeed: 0.0428s/iter; left time: 739.9454s\n",
      "\titers: 200, epoch: 23 | loss: 0.0637027\n",
      "\tspeed: 0.0249s/iter; left time: 428.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0616507 Vali Loss: 0.0588343 Test Loss: 0.0745264\n",
      "Validation loss decreased (0.059098 --> 0.058834).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621395\n",
      "\tspeed: 0.0390s/iter; left time: 665.0682s\n",
      "\titers: 200, epoch: 24 | loss: 0.0605529\n",
      "\tspeed: 0.0184s/iter; left time: 312.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0617294 Vali Loss: 0.0591653 Test Loss: 0.0739306\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0642471\n",
      "\tspeed: 0.0389s/iter; left time: 655.9248s\n",
      "\titers: 200, epoch: 25 | loss: 0.0604569\n",
      "\tspeed: 0.0134s/iter; left time: 224.8224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0615576 Vali Loss: 0.0589806 Test Loss: 0.0727910\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0616106\n",
      "\tspeed: 0.0395s/iter; left time: 657.1760s\n",
      "\titers: 200, epoch: 26 | loss: 0.0597703\n",
      "\tspeed: 0.0199s/iter; left time: 328.2927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0620085 Vali Loss: 0.0588338 Test Loss: 0.0719916\n",
      "Validation loss decreased (0.058834 --> 0.058834).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0596189\n",
      "\tspeed: 0.0381s/iter; left time: 625.3438s\n",
      "\titers: 200, epoch: 27 | loss: 0.0635520\n",
      "\tspeed: 0.0175s/iter; left time: 284.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0612380 Vali Loss: 0.0586246 Test Loss: 0.0727618\n",
      "Validation loss decreased (0.058834 --> 0.058625).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0588917\n",
      "\tspeed: 0.0364s/iter; left time: 588.7626s\n",
      "\titers: 200, epoch: 28 | loss: 0.0635731\n",
      "\tspeed: 0.0165s/iter; left time: 265.3091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0611303 Vali Loss: 0.0587932 Test Loss: 0.0731516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625889\n",
      "\tspeed: 0.0356s/iter; left time: 567.6461s\n",
      "\titers: 200, epoch: 29 | loss: 0.0612762\n",
      "\tspeed: 0.0171s/iter; left time: 271.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0612841 Vali Loss: 0.0586699 Test Loss: 0.0720458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0627371\n",
      "\tspeed: 0.0385s/iter; left time: 605.9821s\n",
      "\titers: 200, epoch: 30 | loss: 0.0609327\n",
      "\tspeed: 0.0202s/iter; left time: 315.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0611244 Vali Loss: 0.0587655 Test Loss: 0.0722661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0626832\n",
      "\tspeed: 0.0373s/iter; left time: 579.3150s\n",
      "\titers: 200, epoch: 31 | loss: 0.0611782\n",
      "\tspeed: 0.0178s/iter; left time: 274.6655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0608637 Vali Loss: 0.0585725 Test Loss: 0.0721224\n",
      "Validation loss decreased (0.058625 --> 0.058573).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0591056\n",
      "\tspeed: 0.0379s/iter; left time: 578.9974s\n",
      "\titers: 200, epoch: 32 | loss: 0.0608703\n",
      "\tspeed: 0.0232s/iter; left time: 353.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0611035 Vali Loss: 0.0585316 Test Loss: 0.0720294\n",
      "Validation loss decreased (0.058573 --> 0.058532).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0627462\n",
      "\tspeed: 0.0361s/iter; left time: 543.2079s\n",
      "\titers: 200, epoch: 33 | loss: 0.0638220\n",
      "\tspeed: 0.0133s/iter; left time: 198.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0609369 Vali Loss: 0.0589222 Test Loss: 0.0714391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0611427\n",
      "\tspeed: 0.0354s/iter; left time: 525.3292s\n",
      "\titers: 200, epoch: 34 | loss: 0.0592877\n",
      "\tspeed: 0.0189s/iter; left time: 278.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0609008 Vali Loss: 0.0587073 Test Loss: 0.0718306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0647226\n",
      "\tspeed: 0.0408s/iter; left time: 596.1808s\n",
      "\titers: 200, epoch: 35 | loss: 0.0613430\n",
      "\tspeed: 0.0186s/iter; left time: 270.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0610456 Vali Loss: 0.0587233 Test Loss: 0.0709572\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610038\n",
      "\tspeed: 0.0379s/iter; left time: 545.2383s\n",
      "\titers: 200, epoch: 36 | loss: 0.0639765\n",
      "\tspeed: 0.0175s/iter; left time: 249.5119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0608291 Vali Loss: 0.0585552 Test Loss: 0.0723657\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628329\n",
      "\tspeed: 0.0349s/iter; left time: 494.9488s\n",
      "\titers: 200, epoch: 37 | loss: 0.0624324\n",
      "\tspeed: 0.0177s/iter; left time: 249.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0609406 Vali Loss: 0.0585783 Test Loss: 0.0719445\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0570951\n",
      "\tspeed: 0.0428s/iter; left time: 597.2628s\n",
      "\titers: 200, epoch: 38 | loss: 0.0635981\n",
      "\tspeed: 0.0203s/iter; left time: 280.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0608932 Vali Loss: 0.0582021 Test Loss: 0.0709829\n",
      "Validation loss decreased (0.058532 --> 0.058202).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0648834\n",
      "\tspeed: 0.0426s/iter; left time: 585.0529s\n",
      "\titers: 200, epoch: 39 | loss: 0.0634245\n",
      "\tspeed: 0.0203s/iter; left time: 277.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 223 | Train Loss: 0.0607717 Vali Loss: 0.0584518 Test Loss: 0.0719673\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0667321\n",
      "\tspeed: 0.0375s/iter; left time: 506.7305s\n",
      "\titers: 200, epoch: 40 | loss: 0.0605432\n",
      "\tspeed: 0.0182s/iter; left time: 243.4897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0606790 Vali Loss: 0.0582629 Test Loss: 0.0711489\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0607338\n",
      "\tspeed: 0.0400s/iter; left time: 531.1396s\n",
      "\titers: 200, epoch: 41 | loss: 0.0625932\n",
      "\tspeed: 0.0223s/iter; left time: 293.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0607329 Vali Loss: 0.0583876 Test Loss: 0.0709399\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0610299\n",
      "\tspeed: 0.0412s/iter; left time: 538.1481s\n",
      "\titers: 200, epoch: 42 | loss: 0.0592471\n",
      "\tspeed: 0.0198s/iter; left time: 256.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0605536 Vali Loss: 0.0584407 Test Loss: 0.0717083\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0613073\n",
      "\tspeed: 0.0399s/iter; left time: 512.0023s\n",
      "\titers: 200, epoch: 43 | loss: 0.0620735\n",
      "\tspeed: 0.0189s/iter; left time: 240.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0605541 Vali Loss: 0.0583683 Test Loss: 0.0715528\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0572556\n",
      "\tspeed: 0.0373s/iter; left time: 471.0478s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614139\n",
      "\tspeed: 0.0158s/iter; left time: 197.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0606213 Vali Loss: 0.0583518 Test Loss: 0.0715966\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0610600\n",
      "\tspeed: 0.0379s/iter; left time: 469.8934s\n",
      "\titers: 200, epoch: 45 | loss: 0.0638830\n",
      "\tspeed: 0.0195s/iter; left time: 239.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0606214 Vali Loss: 0.0583446 Test Loss: 0.0709620\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0632091\n",
      "\tspeed: 0.0406s/iter; left time: 494.5425s\n",
      "\titers: 200, epoch: 46 | loss: 0.0578360\n",
      "\tspeed: 0.0214s/iter; left time: 257.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 223 | Train Loss: 0.0606273 Vali Loss: 0.0582291 Test Loss: 0.0716396\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0647540\n",
      "\tspeed: 0.0384s/iter; left time: 458.1504s\n",
      "\titers: 200, epoch: 47 | loss: 0.0604675\n",
      "\tspeed: 0.0199s/iter; left time: 235.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0607377 Vali Loss: 0.0581766 Test Loss: 0.0712587\n",
      "Validation loss decreased (0.058202 --> 0.058177).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0603332\n",
      "\tspeed: 0.0423s/iter; left time: 495.2192s\n",
      "\titers: 200, epoch: 48 | loss: 0.0626702\n",
      "\tspeed: 0.0200s/iter; left time: 232.4208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0606299 Vali Loss: 0.0583450 Test Loss: 0.0713740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0630806\n",
      "\tspeed: 0.0389s/iter; left time: 447.2580s\n",
      "\titers: 200, epoch: 49 | loss: 0.0596555\n",
      "\tspeed: 0.0198s/iter; left time: 225.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0604360 Vali Loss: 0.0584677 Test Loss: 0.0718548\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0638820\n",
      "\tspeed: 0.0370s/iter; left time: 417.0198s\n",
      "\titers: 200, epoch: 50 | loss: 0.0623280\n",
      "\tspeed: 0.0132s/iter; left time: 147.7918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0607593 Vali Loss: 0.0585534 Test Loss: 0.0712420\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0583699\n",
      "\tspeed: 0.0393s/iter; left time: 434.4850s\n",
      "\titers: 200, epoch: 51 | loss: 0.0574530\n",
      "\tspeed: 0.0193s/iter; left time: 211.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0605747 Vali Loss: 0.0583292 Test Loss: 0.0713487\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0591375\n",
      "\tspeed: 0.0372s/iter; left time: 402.4510s\n",
      "\titers: 200, epoch: 52 | loss: 0.0602642\n",
      "\tspeed: 0.0165s/iter; left time: 177.0149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0605271 Vali Loss: 0.0583008 Test Loss: 0.0709413\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0602914\n",
      "\tspeed: 0.0387s/iter; left time: 410.7503s\n",
      "\titers: 200, epoch: 53 | loss: 0.0605704\n",
      "\tspeed: 0.0239s/iter; left time: 251.0497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0605934 Vali Loss: 0.0583363 Test Loss: 0.0710621\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0597997\n",
      "\tspeed: 0.0390s/iter; left time: 404.9614s\n",
      "\titers: 200, epoch: 54 | loss: 0.0601996\n",
      "\tspeed: 0.0225s/iter; left time: 231.5169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0604698 Vali Loss: 0.0581101 Test Loss: 0.0708624\n",
      "Validation loss decreased (0.058177 --> 0.058110).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0588478\n",
      "\tspeed: 0.0402s/iter; left time: 407.9087s\n",
      "\titers: 200, epoch: 55 | loss: 0.0611312\n",
      "\tspeed: 0.0190s/iter; left time: 191.3613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0606346 Vali Loss: 0.0584171 Test Loss: 0.0711248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0626345\n",
      "\tspeed: 0.0396s/iter; left time: 392.9720s\n",
      "\titers: 200, epoch: 56 | loss: 0.0593741\n",
      "\tspeed: 0.0198s/iter; left time: 195.1627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0606858 Vali Loss: 0.0582332 Test Loss: 0.0709630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0606673\n",
      "\tspeed: 0.0379s/iter; left time: 367.9003s\n",
      "\titers: 200, epoch: 57 | loss: 0.0603442\n",
      "\tspeed: 0.0194s/iter; left time: 186.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0604547 Vali Loss: 0.0585694 Test Loss: 0.0713051\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0621592\n",
      "\tspeed: 0.0406s/iter; left time: 385.0269s\n",
      "\titers: 200, epoch: 58 | loss: 0.0647210\n",
      "\tspeed: 0.0208s/iter; left time: 195.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0605014 Vali Loss: 0.0583662 Test Loss: 0.0710849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0604595\n",
      "\tspeed: 0.0376s/iter; left time: 348.8942s\n",
      "\titers: 200, epoch: 59 | loss: 0.0580812\n",
      "\tspeed: 0.0178s/iter; left time: 163.4166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0605654 Vali Loss: 0.0582231 Test Loss: 0.0715041\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0636667\n",
      "\tspeed: 0.0362s/iter; left time: 327.7002s\n",
      "\titers: 200, epoch: 60 | loss: 0.0592665\n",
      "\tspeed: 0.0176s/iter; left time: 157.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0604897 Vali Loss: 0.0582843 Test Loss: 0.0711999\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0601453\n",
      "\tspeed: 0.0375s/iter; left time: 331.1764s\n",
      "\titers: 200, epoch: 61 | loss: 0.0581520\n",
      "\tspeed: 0.0175s/iter; left time: 152.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0605203 Vali Loss: 0.0583585 Test Loss: 0.0720579\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0599685\n",
      "\tspeed: 0.0420s/iter; left time: 361.5100s\n",
      "\titers: 200, epoch: 62 | loss: 0.0612502\n",
      "\tspeed: 0.0181s/iter; left time: 154.1161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0604107 Vali Loss: 0.0580978 Test Loss: 0.0713375\n",
      "Validation loss decreased (0.058110 --> 0.058098).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0600454\n",
      "\tspeed: 0.0393s/iter; left time: 329.3684s\n",
      "\titers: 200, epoch: 63 | loss: 0.0610860\n",
      "\tspeed: 0.0191s/iter; left time: 158.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0603876 Vali Loss: 0.0581605 Test Loss: 0.0709788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0585512\n",
      "\tspeed: 0.0367s/iter; left time: 299.0697s\n",
      "\titers: 200, epoch: 64 | loss: 0.0573843\n",
      "\tspeed: 0.0171s/iter; left time: 137.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0606150 Vali Loss: 0.0581815 Test Loss: 0.0715361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0555013\n",
      "\tspeed: 0.0414s/iter; left time: 328.6128s\n",
      "\titers: 200, epoch: 65 | loss: 0.0608431\n",
      "\tspeed: 0.0214s/iter; left time: 167.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0603913 Vali Loss: 0.0581201 Test Loss: 0.0710223\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0624073\n",
      "\tspeed: 0.0401s/iter; left time: 309.0720s\n",
      "\titers: 200, epoch: 66 | loss: 0.0613218\n",
      "\tspeed: 0.0202s/iter; left time: 153.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0604806 Vali Loss: 0.0582048 Test Loss: 0.0712893\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0566933\n",
      "\tspeed: 0.0397s/iter; left time: 296.9435s\n",
      "\titers: 200, epoch: 67 | loss: 0.0575886\n",
      "\tspeed: 0.0203s/iter; left time: 149.8142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0604509 Vali Loss: 0.0582309 Test Loss: 0.0714317\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0561184\n",
      "\tspeed: 0.0378s/iter; left time: 274.7451s\n",
      "\titers: 200, epoch: 68 | loss: 0.0544464\n",
      "\tspeed: 0.0140s/iter; left time: 100.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0604748 Vali Loss: 0.0583191 Test Loss: 0.0714386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0618815\n",
      "\tspeed: 0.0383s/iter; left time: 269.6860s\n",
      "\titers: 200, epoch: 69 | loss: 0.0603830\n",
      "\tspeed: 0.0196s/iter; left time: 136.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0604967 Vali Loss: 0.0584250 Test Loss: 0.0712096\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0605376\n",
      "\tspeed: 0.0416s/iter; left time: 283.3235s\n",
      "\titers: 200, epoch: 70 | loss: 0.0598305\n",
      "\tspeed: 0.0233s/iter; left time: 156.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0603894 Vali Loss: 0.0581378 Test Loss: 0.0708586\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0592535\n",
      "\tspeed: 0.0417s/iter; left time: 275.0904s\n",
      "\titers: 200, epoch: 71 | loss: 0.0590382\n",
      "\tspeed: 0.0198s/iter; left time: 128.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0604078 Vali Loss: 0.0583088 Test Loss: 0.0717112\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0595916\n",
      "\tspeed: 0.0400s/iter; left time: 254.4189s\n",
      "\titers: 200, epoch: 72 | loss: 0.0579982\n",
      "\tspeed: 0.0200s/iter; left time: 125.3357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0604241 Vali Loss: 0.0583643 Test Loss: 0.0725297\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012035089544951916, rmse:0.10970455408096313, mae:0.07133753597736359, rse:0.32284724712371826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2803350\n",
      "\tspeed: 0.0220s/iter; left time: 488.8962s\n",
      "\titers: 200, epoch: 1 | loss: 0.2575611\n",
      "\tspeed: 0.0194s/iter; left time: 429.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.2803172 Vali Loss: 0.2082613 Test Loss: 0.2316559\n",
      "Validation loss decreased (inf --> 0.208261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1483288\n",
      "\tspeed: 0.0406s/iter; left time: 891.9465s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121401\n",
      "\tspeed: 0.0199s/iter; left time: 435.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.1565978 Vali Loss: 0.0902821 Test Loss: 0.0989393\n",
      "Validation loss decreased (0.208261 --> 0.090282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1000984\n",
      "\tspeed: 0.0387s/iter; left time: 841.8111s\n",
      "\titers: 200, epoch: 3 | loss: 0.0889085\n",
      "\tspeed: 0.0175s/iter; left time: 380.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0975246 Vali Loss: 0.0740844 Test Loss: 0.0832097\n",
      "Validation loss decreased (0.090282 --> 0.074084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866115\n",
      "\tspeed: 0.0380s/iter; left time: 818.0840s\n",
      "\titers: 200, epoch: 4 | loss: 0.0850188\n",
      "\tspeed: 0.0191s/iter; left time: 409.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0862536 Vali Loss: 0.0705641 Test Loss: 0.0806000\n",
      "Validation loss decreased (0.074084 --> 0.070564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772351\n",
      "\tspeed: 0.0428s/iter; left time: 911.9488s\n",
      "\titers: 200, epoch: 5 | loss: 0.0778000\n",
      "\tspeed: 0.0199s/iter; left time: 422.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0779588 Vali Loss: 0.0672013 Test Loss: 0.0807283\n",
      "Validation loss decreased (0.070564 --> 0.067201).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711917\n",
      "\tspeed: 0.0378s/iter; left time: 796.4603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722112\n",
      "\tspeed: 0.0189s/iter; left time: 395.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0744477 Vali Loss: 0.0661554 Test Loss: 0.0860211\n",
      "Validation loss decreased (0.067201 --> 0.066155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739123\n",
      "\tspeed: 0.0354s/iter; left time: 739.1402s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742147\n",
      "\tspeed: 0.0166s/iter; left time: 345.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0716308 Vali Loss: 0.0647305 Test Loss: 0.0859744\n",
      "Validation loss decreased (0.066155 --> 0.064730).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0713335\n",
      "\tspeed: 0.0365s/iter; left time: 754.0023s\n",
      "\titers: 200, epoch: 8 | loss: 0.0682481\n",
      "\tspeed: 0.0145s/iter; left time: 297.6671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0695360 Vali Loss: 0.0645455 Test Loss: 0.0859980\n",
      "Validation loss decreased (0.064730 --> 0.064546).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0687030\n",
      "\tspeed: 0.0432s/iter; left time: 882.3743s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697583\n",
      "\tspeed: 0.0199s/iter; left time: 404.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0686131 Vali Loss: 0.0629123 Test Loss: 0.0801577\n",
      "Validation loss decreased (0.064546 --> 0.062912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684517\n",
      "\tspeed: 0.0404s/iter; left time: 815.6830s\n",
      "\titers: 200, epoch: 10 | loss: 0.0667424\n",
      "\tspeed: 0.0199s/iter; left time: 400.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0671330 Vali Loss: 0.0622508 Test Loss: 0.0774219\n",
      "Validation loss decreased (0.062912 --> 0.062251).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619685\n",
      "\tspeed: 0.0408s/iter; left time: 814.2703s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625683\n",
      "\tspeed: 0.0200s/iter; left time: 396.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0660573 Vali Loss: 0.0615198 Test Loss: 0.0774656\n",
      "Validation loss decreased (0.062251 --> 0.061520).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726550\n",
      "\tspeed: 0.0414s/iter; left time: 818.2966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0644123\n",
      "\tspeed: 0.0222s/iter; left time: 435.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0657273 Vali Loss: 0.0620292 Test Loss: 0.0781812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0650582\n",
      "\tspeed: 0.0384s/iter; left time: 748.8285s\n",
      "\titers: 200, epoch: 13 | loss: 0.0631247\n",
      "\tspeed: 0.0179s/iter; left time: 348.3120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0647720 Vali Loss: 0.0607914 Test Loss: 0.0755807\n",
      "Validation loss decreased (0.061520 --> 0.060791).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641611\n",
      "\tspeed: 0.0387s/iter; left time: 746.2495s\n",
      "\titers: 200, epoch: 14 | loss: 0.0662648\n",
      "\tspeed: 0.0184s/iter; left time: 352.5027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0643654 Vali Loss: 0.0608688 Test Loss: 0.0753162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0639788\n",
      "\tspeed: 0.0363s/iter; left time: 693.1295s\n",
      "\titers: 200, epoch: 15 | loss: 0.0637772\n",
      "\tspeed: 0.0174s/iter; left time: 330.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0637493 Vali Loss: 0.0603454 Test Loss: 0.0746442\n",
      "Validation loss decreased (0.060791 --> 0.060345).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0646336\n",
      "\tspeed: 0.0334s/iter; left time: 629.1186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0639375\n",
      "\tspeed: 0.0156s/iter; left time: 293.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0635661 Vali Loss: 0.0603865 Test Loss: 0.0745695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624194\n",
      "\tspeed: 0.0365s/iter; left time: 680.3096s\n",
      "\titers: 200, epoch: 17 | loss: 0.0644356\n",
      "\tspeed: 0.0202s/iter; left time: 375.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0632484 Vali Loss: 0.0601870 Test Loss: 0.0742894\n",
      "Validation loss decreased (0.060345 --> 0.060187).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0630162\n",
      "\tspeed: 0.0372s/iter; left time: 684.5223s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598314\n",
      "\tspeed: 0.0170s/iter; left time: 310.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0629594 Vali Loss: 0.0595147 Test Loss: 0.0732608\n",
      "Validation loss decreased (0.060187 --> 0.059515).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643004\n",
      "\tspeed: 0.0370s/iter; left time: 672.7652s\n",
      "\titers: 200, epoch: 19 | loss: 0.0667522\n",
      "\tspeed: 0.0170s/iter; left time: 307.8087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0626891 Vali Loss: 0.0593911 Test Loss: 0.0726724\n",
      "Validation loss decreased (0.059515 --> 0.059391).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621276\n",
      "\tspeed: 0.0384s/iter; left time: 690.3561s\n",
      "\titers: 200, epoch: 20 | loss: 0.0597470\n",
      "\tspeed: 0.0177s/iter; left time: 316.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0624875 Vali Loss: 0.0595826 Test Loss: 0.0720896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0612602\n",
      "\tspeed: 0.0328s/iter; left time: 582.7019s\n",
      "\titers: 200, epoch: 21 | loss: 0.0627079\n",
      "\tspeed: 0.0132s/iter; left time: 233.2184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 223 | Train Loss: 0.0622138 Vali Loss: 0.0592976 Test Loss: 0.0722283\n",
      "Validation loss decreased (0.059391 --> 0.059298).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0617739\n",
      "\tspeed: 0.0455s/iter; left time: 796.2544s\n",
      "\titers: 200, epoch: 22 | loss: 0.0627653\n",
      "\tspeed: 0.0236s/iter; left time: 410.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.0619760 Vali Loss: 0.0589683 Test Loss: 0.0714743\n",
      "Validation loss decreased (0.059298 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0598896\n",
      "\tspeed: 0.0406s/iter; left time: 702.1459s\n",
      "\titers: 200, epoch: 23 | loss: 0.0631920\n",
      "\tspeed: 0.0223s/iter; left time: 382.8169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0618875 Vali Loss: 0.0587703 Test Loss: 0.0712057\n",
      "Validation loss decreased (0.058968 --> 0.058770).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583961\n",
      "\tspeed: 0.0414s/iter; left time: 706.7962s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610948\n",
      "\tspeed: 0.0198s/iter; left time: 336.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0617510 Vali Loss: 0.0593059 Test Loss: 0.0719591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0580491\n",
      "\tspeed: 0.0425s/iter; left time: 716.6322s\n",
      "\titers: 200, epoch: 25 | loss: 0.0652222\n",
      "\tspeed: 0.0208s/iter; left time: 348.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0616693 Vali Loss: 0.0590747 Test Loss: 0.0716805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0642503\n",
      "\tspeed: 0.0412s/iter; left time: 685.0523s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594688\n",
      "\tspeed: 0.0198s/iter; left time: 327.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0615083 Vali Loss: 0.0594680 Test Loss: 0.0719661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0635411\n",
      "\tspeed: 0.0380s/iter; left time: 622.6695s\n",
      "\titers: 200, epoch: 27 | loss: 0.0603641\n",
      "\tspeed: 0.0223s/iter; left time: 362.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0613732 Vali Loss: 0.0590979 Test Loss: 0.0716480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0590103\n",
      "\tspeed: 0.0374s/iter; left time: 605.1310s\n",
      "\titers: 200, epoch: 28 | loss: 0.0609089\n",
      "\tspeed: 0.0179s/iter; left time: 287.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0612358 Vali Loss: 0.0587728 Test Loss: 0.0712729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596771\n",
      "\tspeed: 0.0379s/iter; left time: 605.2173s\n",
      "\titers: 200, epoch: 29 | loss: 0.0595601\n",
      "\tspeed: 0.0159s/iter; left time: 252.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0610402 Vali Loss: 0.0587477 Test Loss: 0.0714170\n",
      "Validation loss decreased (0.058770 --> 0.058748).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0619347\n",
      "\tspeed: 0.0372s/iter; left time: 585.8746s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606348\n",
      "\tspeed: 0.0223s/iter; left time: 349.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0611645 Vali Loss: 0.0587530 Test Loss: 0.0711717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0613811\n",
      "\tspeed: 0.0449s/iter; left time: 695.9157s\n",
      "\titers: 200, epoch: 31 | loss: 0.0604562\n",
      "\tspeed: 0.0250s/iter; left time: 385.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0611316 Vali Loss: 0.0584519 Test Loss: 0.0709715\n",
      "Validation loss decreased (0.058748 --> 0.058452).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0605088\n",
      "\tspeed: 0.0400s/iter; left time: 612.1303s\n",
      "\titers: 200, epoch: 32 | loss: 0.0672119\n",
      "\tspeed: 0.0192s/iter; left time: 290.9627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0610969 Vali Loss: 0.0583849 Test Loss: 0.0707176\n",
      "Validation loss decreased (0.058452 --> 0.058385).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0572636\n",
      "\tspeed: 0.0386s/iter; left time: 581.8048s\n",
      "\titers: 200, epoch: 33 | loss: 0.0620738\n",
      "\tspeed: 0.0155s/iter; left time: 232.1197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0610526 Vali Loss: 0.0584173 Test Loss: 0.0707011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0663672\n",
      "\tspeed: 0.0378s/iter; left time: 560.9163s\n",
      "\titers: 200, epoch: 34 | loss: 0.0620922\n",
      "\tspeed: 0.0175s/iter; left time: 258.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0608810 Vali Loss: 0.0588598 Test Loss: 0.0714231\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0639941\n",
      "\tspeed: 0.0393s/iter; left time: 575.0476s\n",
      "\titers: 200, epoch: 35 | loss: 0.0623683\n",
      "\tspeed: 0.0169s/iter; left time: 245.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0607366 Vali Loss: 0.0589204 Test Loss: 0.0713703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0612918\n",
      "\tspeed: 0.0413s/iter; left time: 594.0018s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612551\n",
      "\tspeed: 0.0212s/iter; left time: 303.1080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0609784 Vali Loss: 0.0585926 Test Loss: 0.0710650\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0589662\n",
      "\tspeed: 0.0407s/iter; left time: 577.5410s\n",
      "\titers: 200, epoch: 37 | loss: 0.0611438\n",
      "\tspeed: 0.0196s/iter; left time: 275.3609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0607585 Vali Loss: 0.0585449 Test Loss: 0.0707495\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0599900\n",
      "\tspeed: 0.0353s/iter; left time: 492.1948s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618140\n",
      "\tspeed: 0.0183s/iter; left time: 253.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0607697 Vali Loss: 0.0584142 Test Loss: 0.0706665\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0616662\n",
      "\tspeed: 0.0405s/iter; left time: 556.0048s\n",
      "\titers: 200, epoch: 39 | loss: 0.0635473\n",
      "\tspeed: 0.0223s/iter; left time: 303.8758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0605788 Vali Loss: 0.0585327 Test Loss: 0.0709554\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0612657\n",
      "\tspeed: 0.0412s/iter; left time: 556.6554s\n",
      "\titers: 200, epoch: 40 | loss: 0.0608891\n",
      "\tspeed: 0.0191s/iter; left time: 256.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0607439 Vali Loss: 0.0587597 Test Loss: 0.0710037\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0582456\n",
      "\tspeed: 0.0422s/iter; left time: 560.5393s\n",
      "\titers: 200, epoch: 41 | loss: 0.0610829\n",
      "\tspeed: 0.0189s/iter; left time: 248.4811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0606736 Vali Loss: 0.0584041 Test Loss: 0.0705513\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0610278\n",
      "\tspeed: 0.0376s/iter; left time: 490.5845s\n",
      "\titers: 200, epoch: 42 | loss: 0.0608318\n",
      "\tspeed: 0.0195s/iter; left time: 252.8569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0606727 Vali Loss: 0.0586551 Test Loss: 0.0710897\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011825245805084705, rmse:0.10874394327402115, mae:0.07071761041879654, rse:0.32002028822898865\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:16.34s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2736052\n",
      "\tspeed: 0.0416s/iter; left time: 919.7582s\n",
      "\titers: 200, epoch: 1 | loss: 0.2632492\n",
      "\tspeed: 0.0138s/iter; left time: 302.7470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 222 | Train Loss: 0.2820088 Vali Loss: 0.2145321 Test Loss: 0.2392163\n",
      "Validation loss decreased (inf --> 0.214532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443035\n",
      "\tspeed: 0.0421s/iter; left time: 921.5091s\n",
      "\titers: 200, epoch: 2 | loss: 0.1171579\n",
      "\tspeed: 0.0228s/iter; left time: 496.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.1566103 Vali Loss: 0.1021497 Test Loss: 0.1147590\n",
      "Validation loss decreased (0.214532 --> 0.102150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029422\n",
      "\tspeed: 0.0376s/iter; left time: 814.0103s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004539\n",
      "\tspeed: 0.0201s/iter; left time: 432.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.1075946 Vali Loss: 0.0927374 Test Loss: 0.1105644\n",
      "Validation loss decreased (0.102150 --> 0.092737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0945588\n",
      "\tspeed: 0.0372s/iter; left time: 798.4396s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923368\n",
      "\tspeed: 0.0223s/iter; left time: 476.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0960586 Vali Loss: 0.0868538 Test Loss: 0.1093112\n",
      "Validation loss decreased (0.092737 --> 0.086854).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870314\n",
      "\tspeed: 0.0452s/iter; left time: 957.9929s\n",
      "\titers: 200, epoch: 5 | loss: 0.0919901\n",
      "\tspeed: 0.0194s/iter; left time: 409.8205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0906975 Vali Loss: 0.0841453 Test Loss: 0.1088696\n",
      "Validation loss decreased (0.086854 --> 0.084145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0899552\n",
      "\tspeed: 0.0411s/iter; left time: 863.6969s\n",
      "\titers: 200, epoch: 6 | loss: 0.0853597\n",
      "\tspeed: 0.0222s/iter; left time: 462.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 222 | Train Loss: 0.0879212 Vali Loss: 0.0829789 Test Loss: 0.1075587\n",
      "Validation loss decreased (0.084145 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0906571\n",
      "\tspeed: 0.0395s/iter; left time: 821.1037s\n",
      "\titers: 200, epoch: 7 | loss: 0.0847237\n",
      "\tspeed: 0.0221s/iter; left time: 457.5676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 222 | Train Loss: 0.0863495 Vali Loss: 0.0817976 Test Loss: 0.1075792\n",
      "Validation loss decreased (0.082979 --> 0.081798).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0875130\n",
      "\tspeed: 0.0429s/iter; left time: 880.7622s\n",
      "\titers: 200, epoch: 8 | loss: 0.0924293\n",
      "\tspeed: 0.0199s/iter; left time: 407.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0849309 Vali Loss: 0.0810084 Test Loss: 0.1117717\n",
      "Validation loss decreased (0.081798 --> 0.081008).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0818318\n",
      "\tspeed: 0.0395s/iter; left time: 803.1211s\n",
      "\titers: 200, epoch: 9 | loss: 0.0829084\n",
      "\tspeed: 0.0194s/iter; left time: 393.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0841765 Vali Loss: 0.0805167 Test Loss: 0.1112050\n",
      "Validation loss decreased (0.081008 --> 0.080517).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0829857\n",
      "\tspeed: 0.0380s/iter; left time: 763.4391s\n",
      "\titers: 200, epoch: 10 | loss: 0.0831658\n",
      "\tspeed: 0.0208s/iter; left time: 415.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0832553 Vali Loss: 0.0805455 Test Loss: 0.1122987\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0824473\n",
      "\tspeed: 0.0363s/iter; left time: 721.1453s\n",
      "\titers: 200, epoch: 11 | loss: 0.0810061\n",
      "\tspeed: 0.0227s/iter; left time: 448.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0827405 Vali Loss: 0.0800260 Test Loss: 0.1080277\n",
      "Validation loss decreased (0.080517 --> 0.080026).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0822582\n",
      "\tspeed: 0.0395s/iter; left time: 775.6052s\n",
      "\titers: 200, epoch: 12 | loss: 0.0819651\n",
      "\tspeed: 0.0204s/iter; left time: 399.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0823618 Vali Loss: 0.0809900 Test Loss: 0.1009054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825042\n",
      "\tspeed: 0.0357s/iter; left time: 694.6460s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784602\n",
      "\tspeed: 0.0168s/iter; left time: 325.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0822133 Vali Loss: 0.0801974 Test Loss: 0.1046171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0790386\n",
      "\tspeed: 0.0364s/iter; left time: 700.0367s\n",
      "\titers: 200, epoch: 14 | loss: 0.0854282\n",
      "\tspeed: 0.0206s/iter; left time: 394.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0814955 Vali Loss: 0.0800733 Test Loss: 0.1055419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843044\n",
      "\tspeed: 0.0367s/iter; left time: 697.1395s\n",
      "\titers: 200, epoch: 15 | loss: 0.0819646\n",
      "\tspeed: 0.0181s/iter; left time: 341.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0814477 Vali Loss: 0.0800168 Test Loss: 0.1067444\n",
      "Validation loss decreased (0.080026 --> 0.080017).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0788339\n",
      "\tspeed: 0.0404s/iter; left time: 758.7057s\n",
      "\titers: 200, epoch: 16 | loss: 0.0818524\n",
      "\tspeed: 0.0175s/iter; left time: 327.2586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0808672 Vali Loss: 0.0796301 Test Loss: 0.1091263\n",
      "Validation loss decreased (0.080017 --> 0.079630).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810963\n",
      "\tspeed: 0.0404s/iter; left time: 750.0089s\n",
      "\titers: 200, epoch: 17 | loss: 0.0811919\n",
      "\tspeed: 0.0182s/iter; left time: 335.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0805257 Vali Loss: 0.0796749 Test Loss: 0.1080271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0794173\n",
      "\tspeed: 0.0376s/iter; left time: 688.8252s\n",
      "\titers: 200, epoch: 18 | loss: 0.0789100\n",
      "\tspeed: 0.0203s/iter; left time: 370.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0805847 Vali Loss: 0.0798890 Test Loss: 0.1028857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0782742\n",
      "\tspeed: 0.0417s/iter; left time: 755.1627s\n",
      "\titers: 200, epoch: 19 | loss: 0.0784676\n",
      "\tspeed: 0.0179s/iter; left time: 321.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0803351 Vali Loss: 0.0796942 Test Loss: 0.1051105\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0789921\n",
      "\tspeed: 0.0369s/iter; left time: 659.1357s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792069\n",
      "\tspeed: 0.0169s/iter; left time: 299.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.0799567 Vali Loss: 0.0794589 Test Loss: 0.1085698\n",
      "Validation loss decreased (0.079630 --> 0.079459).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0794683\n",
      "\tspeed: 0.0388s/iter; left time: 685.2198s\n",
      "\titers: 200, epoch: 21 | loss: 0.0818249\n",
      "\tspeed: 0.0170s/iter; left time: 298.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0800978 Vali Loss: 0.0798695 Test Loss: 0.1047418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0790459\n",
      "\tspeed: 0.0418s/iter; left time: 728.6061s\n",
      "\titers: 200, epoch: 22 | loss: 0.0759462\n",
      "\tspeed: 0.0229s/iter; left time: 397.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 222 | Train Loss: 0.0799170 Vali Loss: 0.0802823 Test Loss: 0.1047563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0786337\n",
      "\tspeed: 0.0382s/iter; left time: 657.9974s\n",
      "\titers: 200, epoch: 23 | loss: 0.0806328\n",
      "\tspeed: 0.0160s/iter; left time: 274.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0798040 Vali Loss: 0.0794180 Test Loss: 0.1073540\n",
      "Validation loss decreased (0.079459 --> 0.079418).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0760322\n",
      "\tspeed: 0.0411s/iter; left time: 697.9577s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821401\n",
      "\tspeed: 0.0218s/iter; left time: 368.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0797892 Vali Loss: 0.0796151 Test Loss: 0.1060932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0772340\n",
      "\tspeed: 0.0386s/iter; left time: 648.1333s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787995\n",
      "\tspeed: 0.0183s/iter; left time: 305.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0794597 Vali Loss: 0.0794219 Test Loss: 0.1073216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0778118\n",
      "\tspeed: 0.0405s/iter; left time: 670.1862s\n",
      "\titers: 200, epoch: 26 | loss: 0.0779257\n",
      "\tspeed: 0.0202s/iter; left time: 331.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0807394 Vali Loss: 0.0795315 Test Loss: 0.1035431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0823847\n",
      "\tspeed: 0.0389s/iter; left time: 634.5010s\n",
      "\titers: 200, epoch: 27 | loss: 0.0796326\n",
      "\tspeed: 0.0185s/iter; left time: 300.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0800514 Vali Loss: 0.0796474 Test Loss: 0.1041704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0773318\n",
      "\tspeed: 0.0372s/iter; left time: 598.9087s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778298\n",
      "\tspeed: 0.0203s/iter; left time: 325.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0793746 Vali Loss: 0.0794691 Test Loss: 0.1060363\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0796701\n",
      "\tspeed: 0.0369s/iter; left time: 585.4487s\n",
      "\titers: 200, epoch: 29 | loss: 0.0800269\n",
      "\tspeed: 0.0190s/iter; left time: 299.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0794556 Vali Loss: 0.0795925 Test Loss: 0.1068346\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0770347\n",
      "\tspeed: 0.0387s/iter; left time: 605.5767s\n",
      "\titers: 200, epoch: 30 | loss: 0.0802456\n",
      "\tspeed: 0.0170s/iter; left time: 265.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0794860 Vali Loss: 0.0793846 Test Loss: 0.1058029\n",
      "Validation loss decreased (0.079418 --> 0.079385).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0806104\n",
      "\tspeed: 0.0388s/iter; left time: 598.3949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0805081\n",
      "\tspeed: 0.0174s/iter; left time: 266.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.0793361 Vali Loss: 0.0794412 Test Loss: 0.1057922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776382\n",
      "\tspeed: 0.0370s/iter; left time: 562.8492s\n",
      "\titers: 200, epoch: 32 | loss: 0.0759733\n",
      "\tspeed: 0.0178s/iter; left time: 269.1286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0791413 Vali Loss: 0.0793291 Test Loss: 0.1056899\n",
      "Validation loss decreased (0.079385 --> 0.079329).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822738\n",
      "\tspeed: 0.0387s/iter; left time: 580.4836s\n",
      "\titers: 200, epoch: 33 | loss: 0.0759665\n",
      "\tspeed: 0.0208s/iter; left time: 309.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0792071 Vali Loss: 0.0793188 Test Loss: 0.1060055\n",
      "Validation loss decreased (0.079329 --> 0.079319).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0833341\n",
      "\tspeed: 0.0422s/iter; left time: 623.8758s\n",
      "\titers: 200, epoch: 34 | loss: 0.0800838\n",
      "\tspeed: 0.0180s/iter; left time: 264.8452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0795997 Vali Loss: 0.0795705 Test Loss: 0.1056227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0800573\n",
      "\tspeed: 0.0387s/iter; left time: 563.5836s\n",
      "\titers: 200, epoch: 35 | loss: 0.0797740\n",
      "\tspeed: 0.0194s/iter; left time: 279.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0790790 Vali Loss: 0.0794705 Test Loss: 0.1075593\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0796889\n",
      "\tspeed: 0.0398s/iter; left time: 569.8771s\n",
      "\titers: 200, epoch: 36 | loss: 0.0789199\n",
      "\tspeed: 0.0174s/iter; left time: 247.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0790394 Vali Loss: 0.0793967 Test Loss: 0.1054460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0809594\n",
      "\tspeed: 0.0333s/iter; left time: 470.2671s\n",
      "\titers: 200, epoch: 37 | loss: 0.0761129\n",
      "\tspeed: 0.0198s/iter; left time: 278.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0797229 Vali Loss: 0.0795006 Test Loss: 0.1052754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0801391\n",
      "\tspeed: 0.0400s/iter; left time: 555.6070s\n",
      "\titers: 200, epoch: 38 | loss: 0.0799272\n",
      "\tspeed: 0.0165s/iter; left time: 227.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0793253 Vali Loss: 0.0793680 Test Loss: 0.1042482\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0731748\n",
      "\tspeed: 0.0340s/iter; left time: 464.2445s\n",
      "\titers: 200, epoch: 39 | loss: 0.0759681\n",
      "\tspeed: 0.0202s/iter; left time: 273.5665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0791599 Vali Loss: 0.0794062 Test Loss: 0.1052876\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0807964\n",
      "\tspeed: 0.0424s/iter; left time: 570.4608s\n",
      "\titers: 200, epoch: 40 | loss: 0.0771302\n",
      "\tspeed: 0.0192s/iter; left time: 256.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0790388 Vali Loss: 0.0794293 Test Loss: 0.1057975\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0836560\n",
      "\tspeed: 0.0403s/iter; left time: 532.9682s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785259\n",
      "\tspeed: 0.0177s/iter; left time: 232.3487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0790498 Vali Loss: 0.0792747 Test Loss: 0.1050334\n",
      "Validation loss decreased (0.079319 --> 0.079275).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0776172\n",
      "\tspeed: 0.0428s/iter; left time: 556.9691s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767821\n",
      "\tspeed: 0.0234s/iter; left time: 302.0445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 222 | Train Loss: 0.0789913 Vali Loss: 0.0794345 Test Loss: 0.1060006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0781929\n",
      "\tspeed: 0.0415s/iter; left time: 529.7583s\n",
      "\titers: 200, epoch: 43 | loss: 0.0808915\n",
      "\tspeed: 0.0222s/iter; left time: 280.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0789933 Vali Loss: 0.0792438 Test Loss: 0.1065399\n",
      "Validation loss decreased (0.079275 --> 0.079244).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0794440\n",
      "\tspeed: 0.0412s/iter; left time: 517.4124s\n",
      "\titers: 200, epoch: 44 | loss: 0.0768947\n",
      "\tspeed: 0.0195s/iter; left time: 242.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0789396 Vali Loss: 0.0792829 Test Loss: 0.1052665\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0767747\n",
      "\tspeed: 0.0326s/iter; left time: 401.6360s\n",
      "\titers: 200, epoch: 45 | loss: 0.0813656\n",
      "\tspeed: 0.0132s/iter; left time: 161.8946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 222 | Train Loss: 0.0788868 Vali Loss: 0.0792649 Test Loss: 0.1054403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0801876\n",
      "\tspeed: 0.0388s/iter; left time: 470.0538s\n",
      "\titers: 200, epoch: 46 | loss: 0.0818402\n",
      "\tspeed: 0.0209s/iter; left time: 251.0356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0790246 Vali Loss: 0.0795171 Test Loss: 0.1061524\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0776780\n",
      "\tspeed: 0.0358s/iter; left time: 425.7090s\n",
      "\titers: 200, epoch: 47 | loss: 0.0776617\n",
      "\tspeed: 0.0184s/iter; left time: 216.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0790503 Vali Loss: 0.0793589 Test Loss: 0.1065618\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0787293\n",
      "\tspeed: 0.0389s/iter; left time: 453.9708s\n",
      "\titers: 200, epoch: 48 | loss: 0.0779946\n",
      "\tspeed: 0.0204s/iter; left time: 236.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0788890 Vali Loss: 0.0794486 Test Loss: 0.1072019\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0784116\n",
      "\tspeed: 0.0398s/iter; left time: 455.6189s\n",
      "\titers: 200, epoch: 49 | loss: 0.0840174\n",
      "\tspeed: 0.0179s/iter; left time: 203.5724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0790734 Vali Loss: 0.0795275 Test Loss: 0.1060289\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0797258\n",
      "\tspeed: 0.0367s/iter; left time: 411.6805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0782866\n",
      "\tspeed: 0.0188s/iter; left time: 209.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0788809 Vali Loss: 0.0792069 Test Loss: 0.1061280\n",
      "Validation loss decreased (0.079244 --> 0.079207).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0792235\n",
      "\tspeed: 0.0388s/iter; left time: 426.4861s\n",
      "\titers: 200, epoch: 51 | loss: 0.0801942\n",
      "\tspeed: 0.0164s/iter; left time: 179.0472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0789939 Vali Loss: 0.0792910 Test Loss: 0.1068094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0792178\n",
      "\tspeed: 0.0351s/iter; left time: 378.0650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0770822\n",
      "\tspeed: 0.0174s/iter; left time: 186.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0790832 Vali Loss: 0.0792130 Test Loss: 0.1049754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0768336\n",
      "\tspeed: 0.0339s/iter; left time: 357.8413s\n",
      "\titers: 200, epoch: 53 | loss: 0.0789928\n",
      "\tspeed: 0.0205s/iter; left time: 214.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0791616 Vali Loss: 0.0794049 Test Loss: 0.1072447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0766972\n",
      "\tspeed: 0.0415s/iter; left time: 429.0805s\n",
      "\titers: 200, epoch: 54 | loss: 0.0793522\n",
      "\tspeed: 0.0191s/iter; left time: 195.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0789057 Vali Loss: 0.0794337 Test Loss: 0.1055728\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0789461\n",
      "\tspeed: 0.0372s/iter; left time: 375.7755s\n",
      "\titers: 200, epoch: 55 | loss: 0.0785880\n",
      "\tspeed: 0.0200s/iter; left time: 199.8766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0789052 Vali Loss: 0.0791764 Test Loss: 0.1050162\n",
      "Validation loss decreased (0.079207 --> 0.079176).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0805046\n",
      "\tspeed: 0.0428s/iter; left time: 423.5058s\n",
      "\titers: 200, epoch: 56 | loss: 0.0815311\n",
      "\tspeed: 0.0201s/iter; left time: 196.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0791163 Vali Loss: 0.0792601 Test Loss: 0.1053911\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0772773\n",
      "\tspeed: 0.0390s/iter; left time: 376.8398s\n",
      "\titers: 200, epoch: 57 | loss: 0.0802374\n",
      "\tspeed: 0.0193s/iter; left time: 184.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 222 | Train Loss: 0.0789890 Vali Loss: 0.0792851 Test Loss: 0.1053438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0784494\n",
      "\tspeed: 0.0390s/iter; left time: 368.0824s\n",
      "\titers: 200, epoch: 58 | loss: 0.0803647\n",
      "\tspeed: 0.0206s/iter; left time: 193.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 222 | Train Loss: 0.0788573 Vali Loss: 0.0793364 Test Loss: 0.1058882\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0762803\n",
      "\tspeed: 0.0388s/iter; left time: 358.0013s\n",
      "\titers: 200, epoch: 59 | loss: 0.0783992\n",
      "\tspeed: 0.0218s/iter; left time: 199.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0788758 Vali Loss: 0.0791969 Test Loss: 0.1057142\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0825018\n",
      "\tspeed: 0.0378s/iter; left time: 340.7357s\n",
      "\titers: 200, epoch: 60 | loss: 0.0767532\n",
      "\tspeed: 0.0186s/iter; left time: 165.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0789938 Vali Loss: 0.0794343 Test Loss: 0.1060912\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0837195\n",
      "\tspeed: 0.0364s/iter; left time: 320.0021s\n",
      "\titers: 200, epoch: 61 | loss: 0.0781572\n",
      "\tspeed: 0.0165s/iter; left time: 143.1479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0788658 Vali Loss: 0.0793094 Test Loss: 0.1054503\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0807465\n",
      "\tspeed: 0.0327s/iter; left time: 279.5949s\n",
      "\titers: 200, epoch: 62 | loss: 0.0786767\n",
      "\tspeed: 0.0157s/iter; left time: 132.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 222 | Train Loss: 0.0788907 Vali Loss: 0.0794156 Test Loss: 0.1059766\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0781662\n",
      "\tspeed: 0.0385s/iter; left time: 320.7642s\n",
      "\titers: 200, epoch: 63 | loss: 0.0798408\n",
      "\tspeed: 0.0138s/iter; left time: 113.2776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0791201 Vali Loss: 0.0793008 Test Loss: 0.1065161\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0772898\n",
      "\tspeed: 0.0407s/iter; left time: 330.1720s\n",
      "\titers: 200, epoch: 64 | loss: 0.0802854\n",
      "\tspeed: 0.0201s/iter; left time: 161.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0788891 Vali Loss: 0.0797067 Test Loss: 0.1072320\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0743827\n",
      "\tspeed: 0.0396s/iter; left time: 312.9469s\n",
      "\titers: 200, epoch: 65 | loss: 0.0831507\n",
      "\tspeed: 0.0188s/iter; left time: 146.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0788639 Vali Loss: 0.0792007 Test Loss: 0.1048479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02376987598836422, rmse:0.1541748195886612, mae:0.10501614212989807, rse:0.45291921496391296\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2810470\n",
      "\tspeed: 0.0204s/iter; left time: 450.9532s\n",
      "\titers: 200, epoch: 1 | loss: 0.2589971\n",
      "\tspeed: 0.0192s/iter; left time: 421.5274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.2842580 Vali Loss: 0.2176934 Test Loss: 0.2430637\n",
      "Validation loss decreased (inf --> 0.217693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1428849\n",
      "\tspeed: 0.0431s/iter; left time: 943.3793s\n",
      "\titers: 200, epoch: 2 | loss: 0.1177629\n",
      "\tspeed: 0.0196s/iter; left time: 427.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.1566190 Vali Loss: 0.1053681 Test Loss: 0.1198546\n",
      "Validation loss decreased (0.217693 --> 0.105368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089350\n",
      "\tspeed: 0.0398s/iter; left time: 861.5857s\n",
      "\titers: 200, epoch: 3 | loss: 0.1000227\n",
      "\tspeed: 0.0237s/iter; left time: 510.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.1072686 Vali Loss: 0.0916175 Test Loss: 0.1095698\n",
      "Validation loss decreased (0.105368 --> 0.091617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0956034\n",
      "\tspeed: 0.0394s/iter; left time: 844.2328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0941442\n",
      "\tspeed: 0.0198s/iter; left time: 421.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0948761 Vali Loss: 0.0862199 Test Loss: 0.1078077\n",
      "Validation loss decreased (0.091617 --> 0.086220).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0916500\n",
      "\tspeed: 0.0390s/iter; left time: 827.2373s\n",
      "\titers: 200, epoch: 5 | loss: 0.0919713\n",
      "\tspeed: 0.0224s/iter; left time: 471.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0908284 Vali Loss: 0.0855985 Test Loss: 0.1063819\n",
      "Validation loss decreased (0.086220 --> 0.085599).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0832181\n",
      "\tspeed: 0.0422s/iter; left time: 886.4380s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862229\n",
      "\tspeed: 0.0177s/iter; left time: 370.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0884109 Vali Loss: 0.0834829 Test Loss: 0.1045711\n",
      "Validation loss decreased (0.085599 --> 0.083483).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0872452\n",
      "\tspeed: 0.0407s/iter; left time: 846.2543s\n",
      "\titers: 200, epoch: 7 | loss: 0.0880526\n",
      "\tspeed: 0.0188s/iter; left time: 387.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0868561 Vali Loss: 0.0827404 Test Loss: 0.1038241\n",
      "Validation loss decreased (0.083483 --> 0.082740).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873086\n",
      "\tspeed: 0.0355s/iter; left time: 728.5826s\n",
      "\titers: 200, epoch: 8 | loss: 0.0818132\n",
      "\tspeed: 0.0157s/iter; left time: 320.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 222 | Train Loss: 0.0854578 Vali Loss: 0.0854367 Test Loss: 0.1063910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0821413\n",
      "\tspeed: 0.0426s/iter; left time: 865.9103s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866865\n",
      "\tspeed: 0.0192s/iter; left time: 388.8350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0848729 Vali Loss: 0.0824220 Test Loss: 0.1041098\n",
      "Validation loss decreased (0.082740 --> 0.082422).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799296\n",
      "\tspeed: 0.0396s/iter; left time: 795.3500s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849174\n",
      "\tspeed: 0.0195s/iter; left time: 390.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0840741 Vali Loss: 0.0813358 Test Loss: 0.1034212\n",
      "Validation loss decreased (0.082422 --> 0.081336).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811578\n",
      "\tspeed: 0.0387s/iter; left time: 769.0809s\n",
      "\titers: 200, epoch: 11 | loss: 0.0790042\n",
      "\tspeed: 0.0196s/iter; left time: 388.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0830483 Vali Loss: 0.0805814 Test Loss: 0.1018861\n",
      "Validation loss decreased (0.081336 --> 0.080581).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0865190\n",
      "\tspeed: 0.0441s/iter; left time: 867.2405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0824904\n",
      "\tspeed: 0.0198s/iter; left time: 386.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.0829455 Vali Loss: 0.0818581 Test Loss: 0.1040239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0845788\n",
      "\tspeed: 0.0397s/iter; left time: 771.9829s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808019\n",
      "\tspeed: 0.0227s/iter; left time: 439.1868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 222 | Train Loss: 0.0825119 Vali Loss: 0.0802521 Test Loss: 0.1025698\n",
      "Validation loss decreased (0.080581 --> 0.080252).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800021\n",
      "\tspeed: 0.0396s/iter; left time: 761.1339s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800325\n",
      "\tspeed: 0.0187s/iter; left time: 357.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0818480 Vali Loss: 0.0801559 Test Loss: 0.1029230\n",
      "Validation loss decreased (0.080252 --> 0.080156).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0839747\n",
      "\tspeed: 0.0380s/iter; left time: 721.3365s\n",
      "\titers: 200, epoch: 15 | loss: 0.0872229\n",
      "\tspeed: 0.0194s/iter; left time: 366.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0818756 Vali Loss: 0.0803459 Test Loss: 0.1029744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0794405\n",
      "\tspeed: 0.0421s/iter; left time: 789.7370s\n",
      "\titers: 200, epoch: 16 | loss: 0.0777880\n",
      "\tspeed: 0.0225s/iter; left time: 420.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 222 | Train Loss: 0.0812288 Vali Loss: 0.0796655 Test Loss: 0.1032664\n",
      "Validation loss decreased (0.080156 --> 0.079665).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801393\n",
      "\tspeed: 0.0421s/iter; left time: 781.6817s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806118\n",
      "\tspeed: 0.0165s/iter; left time: 304.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0809478 Vali Loss: 0.0795601 Test Loss: 0.1028116\n",
      "Validation loss decreased (0.079665 --> 0.079560).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812949\n",
      "\tspeed: 0.0398s/iter; left time: 728.5751s\n",
      "\titers: 200, epoch: 18 | loss: 0.0829192\n",
      "\tspeed: 0.0214s/iter; left time: 390.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0809617 Vali Loss: 0.0797312 Test Loss: 0.1021368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0776868\n",
      "\tspeed: 0.0422s/iter; left time: 763.3887s\n",
      "\titers: 200, epoch: 19 | loss: 0.0802930\n",
      "\tspeed: 0.0189s/iter; left time: 339.5524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0806394 Vali Loss: 0.0795797 Test Loss: 0.1032248\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0839570\n",
      "\tspeed: 0.0386s/iter; left time: 690.3037s\n",
      "\titers: 200, epoch: 20 | loss: 0.0903985\n",
      "\tspeed: 0.0199s/iter; left time: 353.1956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0805856 Vali Loss: 0.0797428 Test Loss: 0.1031292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0777669\n",
      "\tspeed: 0.0434s/iter; left time: 765.6735s\n",
      "\titers: 200, epoch: 21 | loss: 0.0817776\n",
      "\tspeed: 0.0213s/iter; left time: 373.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.0802346 Vali Loss: 0.0792237 Test Loss: 0.1023476\n",
      "Validation loss decreased (0.079560 --> 0.079224).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0790358\n",
      "\tspeed: 0.0405s/iter; left time: 705.6701s\n",
      "\titers: 200, epoch: 22 | loss: 0.0821888\n",
      "\tspeed: 0.0191s/iter; left time: 331.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0802168 Vali Loss: 0.0791976 Test Loss: 0.1022222\n",
      "Validation loss decreased (0.079224 --> 0.079198).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802167\n",
      "\tspeed: 0.0428s/iter; left time: 736.5202s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791469\n",
      "\tspeed: 0.0237s/iter; left time: 406.4424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 222 | Train Loss: 0.0800416 Vali Loss: 0.0792813 Test Loss: 0.1030126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0794432\n",
      "\tspeed: 0.0404s/iter; left time: 686.5341s\n",
      "\titers: 200, epoch: 24 | loss: 0.0804316\n",
      "\tspeed: 0.0179s/iter; left time: 301.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0798016 Vali Loss: 0.0791978 Test Loss: 0.1020456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0815211\n",
      "\tspeed: 0.0413s/iter; left time: 692.4367s\n",
      "\titers: 200, epoch: 25 | loss: 0.0761523\n",
      "\tspeed: 0.0223s/iter; left time: 371.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 222 | Train Loss: 0.0797133 Vali Loss: 0.0792341 Test Loss: 0.1035025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0782770\n",
      "\tspeed: 0.0403s/iter; left time: 667.0536s\n",
      "\titers: 200, epoch: 26 | loss: 0.0795551\n",
      "\tspeed: 0.0135s/iter; left time: 222.2064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0796777 Vali Loss: 0.0791404 Test Loss: 0.1027319\n",
      "Validation loss decreased (0.079198 --> 0.079140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0820096\n",
      "\tspeed: 0.0408s/iter; left time: 666.7253s\n",
      "\titers: 200, epoch: 27 | loss: 0.0759461\n",
      "\tspeed: 0.0162s/iter; left time: 263.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0794938 Vali Loss: 0.0791340 Test Loss: 0.1030964\n",
      "Validation loss decreased (0.079140 --> 0.079134).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0820050\n",
      "\tspeed: 0.0406s/iter; left time: 654.1559s\n",
      "\titers: 200, epoch: 28 | loss: 0.0995732\n",
      "\tspeed: 0.0193s/iter; left time: 309.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0803654 Vali Loss: 0.0793823 Test Loss: 0.1027825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0787976\n",
      "\tspeed: 0.0393s/iter; left time: 624.7276s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788985\n",
      "\tspeed: 0.0209s/iter; left time: 329.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0795554 Vali Loss: 0.0791490 Test Loss: 0.1026566\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0781396\n",
      "\tspeed: 0.0425s/iter; left time: 665.5643s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771283\n",
      "\tspeed: 0.0213s/iter; left time: 331.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0795234 Vali Loss: 0.0792159 Test Loss: 0.1034529\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0786963\n",
      "\tspeed: 0.0413s/iter; left time: 637.8063s\n",
      "\titers: 200, epoch: 31 | loss: 0.0803929\n",
      "\tspeed: 0.0201s/iter; left time: 308.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0793471 Vali Loss: 0.0791961 Test Loss: 0.1027451\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0819115\n",
      "\tspeed: 0.0391s/iter; left time: 594.7878s\n",
      "\titers: 200, epoch: 32 | loss: 0.0808079\n",
      "\tspeed: 0.0177s/iter; left time: 266.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0794470 Vali Loss: 0.0791438 Test Loss: 0.1026879\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0762618\n",
      "\tspeed: 0.0352s/iter; left time: 528.0256s\n",
      "\titers: 200, epoch: 33 | loss: 0.0815164\n",
      "\tspeed: 0.0134s/iter; left time: 200.2836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 222 | Train Loss: 0.0794177 Vali Loss: 0.0792071 Test Loss: 0.1027365\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0749935\n",
      "\tspeed: 0.0369s/iter; left time: 545.8052s\n",
      "\titers: 200, epoch: 34 | loss: 0.0780543\n",
      "\tspeed: 0.0199s/iter; left time: 292.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0792908 Vali Loss: 0.0789458 Test Loss: 0.1024397\n",
      "Validation loss decreased (0.079134 --> 0.078946).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0782235\n",
      "\tspeed: 0.0403s/iter; left time: 586.2595s\n",
      "\titers: 200, epoch: 35 | loss: 0.0795221\n",
      "\tspeed: 0.0195s/iter; left time: 281.2209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0791714 Vali Loss: 0.0791555 Test Loss: 0.1031611\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0820126\n",
      "\tspeed: 0.0382s/iter; left time: 547.8615s\n",
      "\titers: 200, epoch: 36 | loss: 0.0786146\n",
      "\tspeed: 0.0172s/iter; left time: 244.0809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0796702 Vali Loss: 0.0791106 Test Loss: 0.1022685\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803640\n",
      "\tspeed: 0.0366s/iter; left time: 515.7578s\n",
      "\titers: 200, epoch: 37 | loss: 0.0808174\n",
      "\tspeed: 0.0137s/iter; left time: 192.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 222 | Train Loss: 0.0792411 Vali Loss: 0.0790062 Test Loss: 0.1028497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0790733\n",
      "\tspeed: 0.0379s/iter; left time: 526.5284s\n",
      "\titers: 200, epoch: 38 | loss: 0.0804619\n",
      "\tspeed: 0.0197s/iter; left time: 271.3645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0792892 Vali Loss: 0.0790832 Test Loss: 0.1028110\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0762917\n",
      "\tspeed: 0.0450s/iter; left time: 614.3624s\n",
      "\titers: 200, epoch: 39 | loss: 0.0776001\n",
      "\tspeed: 0.0212s/iter; left time: 287.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 222 | Train Loss: 0.0791708 Vali Loss: 0.0790128 Test Loss: 0.1030692\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0814784\n",
      "\tspeed: 0.0415s/iter; left time: 558.2509s\n",
      "\titers: 200, epoch: 40 | loss: 0.0833261\n",
      "\tspeed: 0.0198s/iter; left time: 264.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0791577 Vali Loss: 0.0788823 Test Loss: 0.1023154\n",
      "Validation loss decreased (0.078946 --> 0.078882).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0781104\n",
      "\tspeed: 0.0417s/iter; left time: 551.0961s\n",
      "\titers: 200, epoch: 41 | loss: 0.0804314\n",
      "\tspeed: 0.0204s/iter; left time: 267.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0791517 Vali Loss: 0.0789537 Test Loss: 0.1029243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0816227\n",
      "\tspeed: 0.0422s/iter; left time: 548.4843s\n",
      "\titers: 200, epoch: 42 | loss: 0.0790452\n",
      "\tspeed: 0.0216s/iter; left time: 278.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.0791252 Vali Loss: 0.0789561 Test Loss: 0.1028040\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0790205\n",
      "\tspeed: 0.0425s/iter; left time: 543.2872s\n",
      "\titers: 200, epoch: 43 | loss: 0.0782743\n",
      "\tspeed: 0.0201s/iter; left time: 254.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0790588 Vali Loss: 0.0788983 Test Loss: 0.1029840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0739642\n",
      "\tspeed: 0.0410s/iter; left time: 514.1613s\n",
      "\titers: 200, epoch: 44 | loss: 0.0761449\n",
      "\tspeed: 0.0202s/iter; left time: 251.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0790975 Vali Loss: 0.0791018 Test Loss: 0.1036198\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0774458\n",
      "\tspeed: 0.0441s/iter; left time: 544.3374s\n",
      "\titers: 200, epoch: 45 | loss: 0.0799462\n",
      "\tspeed: 0.0185s/iter; left time: 226.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0794921 Vali Loss: 0.0788967 Test Loss: 0.1025624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0784422\n",
      "\tspeed: 0.0401s/iter; left time: 485.4888s\n",
      "\titers: 200, epoch: 46 | loss: 0.0794881\n",
      "\tspeed: 0.0185s/iter; left time: 222.7008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0793124 Vali Loss: 0.0790206 Test Loss: 0.1033023\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0794085\n",
      "\tspeed: 0.0411s/iter; left time: 488.5752s\n",
      "\titers: 200, epoch: 47 | loss: 0.0817144\n",
      "\tspeed: 0.0241s/iter; left time: 283.6347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.0790663 Vali Loss: 0.0790133 Test Loss: 0.1029455\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0763003\n",
      "\tspeed: 0.0415s/iter; left time: 484.6144s\n",
      "\titers: 200, epoch: 48 | loss: 0.0763451\n",
      "\tspeed: 0.0195s/iter; left time: 226.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0789351 Vali Loss: 0.0787943 Test Loss: 0.1024749\n",
      "Validation loss decreased (0.078882 --> 0.078794).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0795730\n",
      "\tspeed: 0.0452s/iter; left time: 517.1865s\n",
      "\titers: 200, epoch: 49 | loss: 0.0759086\n",
      "\tspeed: 0.0205s/iter; left time: 232.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0790111 Vali Loss: 0.0789350 Test Loss: 0.1026037\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0815081\n",
      "\tspeed: 0.0416s/iter; left time: 466.9401s\n",
      "\titers: 200, epoch: 50 | loss: 0.0753445\n",
      "\tspeed: 0.0134s/iter; left time: 148.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0789808 Vali Loss: 0.0789486 Test Loss: 0.1029010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0784314\n",
      "\tspeed: 0.0371s/iter; left time: 408.1302s\n",
      "\titers: 200, epoch: 51 | loss: 0.0786514\n",
      "\tspeed: 0.0170s/iter; left time: 185.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0794860 Vali Loss: 0.0789050 Test Loss: 0.1026498\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0763737\n",
      "\tspeed: 0.0389s/iter; left time: 419.0379s\n",
      "\titers: 200, epoch: 52 | loss: 0.0796035\n",
      "\tspeed: 0.0190s/iter; left time: 203.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0789189 Vali Loss: 0.0789363 Test Loss: 0.1030508\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0794703\n",
      "\tspeed: 0.0435s/iter; left time: 458.9171s\n",
      "\titers: 200, epoch: 53 | loss: 0.0759548\n",
      "\tspeed: 0.0209s/iter; left time: 218.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0789999 Vali Loss: 0.0789349 Test Loss: 0.1028371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802278\n",
      "\tspeed: 0.0396s/iter; left time: 409.7294s\n",
      "\titers: 200, epoch: 54 | loss: 0.0752189\n",
      "\tspeed: 0.0178s/iter; left time: 182.5793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0792957 Vali Loss: 0.0788629 Test Loss: 0.1025980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0809674\n",
      "\tspeed: 0.0371s/iter; left time: 375.1149s\n",
      "\titers: 200, epoch: 55 | loss: 0.0801318\n",
      "\tspeed: 0.0168s/iter; left time: 168.3643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0790151 Vali Loss: 0.0788676 Test Loss: 0.1026907\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0795336\n",
      "\tspeed: 0.0394s/iter; left time: 390.1471s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784315\n",
      "\tspeed: 0.0212s/iter; left time: 207.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0790342 Vali Loss: 0.0788297 Test Loss: 0.1026216\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0769611\n",
      "\tspeed: 0.0384s/iter; left time: 371.4943s\n",
      "\titers: 200, epoch: 57 | loss: 0.0787185\n",
      "\tspeed: 0.0178s/iter; left time: 170.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0789022 Vali Loss: 0.0788922 Test Loss: 0.1029108\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0799873\n",
      "\tspeed: 0.0432s/iter; left time: 407.6495s\n",
      "\titers: 200, epoch: 58 | loss: 0.0774429\n",
      "\tspeed: 0.0213s/iter; left time: 199.1551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0797733 Vali Loss: 0.0790526 Test Loss: 0.1029665\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022674940526485443, rmse:0.15058200061321259, mae:0.1024748831987381, rse:0.4423646032810211\n",
      "Intermediate time for ES and pred_len 96: 00h:12m:14.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2752975\n",
      "\tspeed: 0.0406s/iter; left time: 896.9228s\n",
      "\titers: 200, epoch: 1 | loss: 0.2628833\n",
      "\tspeed: 0.0151s/iter; left time: 331.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 222 | Train Loss: 0.2844597 Vali Loss: 0.2161710 Test Loss: 0.2390840\n",
      "Validation loss decreased (inf --> 0.216171).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1424186\n",
      "\tspeed: 0.0351s/iter; left time: 768.3650s\n",
      "\titers: 200, epoch: 2 | loss: 0.1192986\n",
      "\tspeed: 0.0168s/iter; left time: 366.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.1557773 Vali Loss: 0.1054073 Test Loss: 0.1212500\n",
      "Validation loss decreased (0.216171 --> 0.105407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1097088\n",
      "\tspeed: 0.0356s/iter; left time: 771.2411s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013827\n",
      "\tspeed: 0.0170s/iter; left time: 366.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.1089300 Vali Loss: 0.0947460 Test Loss: 0.1189555\n",
      "Validation loss decreased (0.105407 --> 0.094746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0972929\n",
      "\tspeed: 0.0354s/iter; left time: 759.1964s\n",
      "\titers: 200, epoch: 4 | loss: 0.0936165\n",
      "\tspeed: 0.0136s/iter; left time: 290.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 222 | Train Loss: 0.0985258 Vali Loss: 0.0916113 Test Loss: 0.1213326\n",
      "Validation loss decreased (0.094746 --> 0.091611).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0950370\n",
      "\tspeed: 0.0377s/iter; left time: 799.6122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0936327\n",
      "\tspeed: 0.0185s/iter; left time: 390.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0938632 Vali Loss: 0.0910431 Test Loss: 0.1281624\n",
      "Validation loss decreased (0.091611 --> 0.091043).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913503\n",
      "\tspeed: 0.0372s/iter; left time: 781.4106s\n",
      "\titers: 200, epoch: 6 | loss: 0.0894877\n",
      "\tspeed: 0.0175s/iter; left time: 365.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0910923 Vali Loss: 0.0887452 Test Loss: 0.1254068\n",
      "Validation loss decreased (0.091043 --> 0.088745).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927720\n",
      "\tspeed: 0.0426s/iter; left time: 885.7766s\n",
      "\titers: 200, epoch: 7 | loss: 0.0898243\n",
      "\tspeed: 0.0228s/iter; left time: 470.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 222 | Train Loss: 0.0894418 Vali Loss: 0.0876978 Test Loss: 0.1303841\n",
      "Validation loss decreased (0.088745 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0880019\n",
      "\tspeed: 0.0407s/iter; left time: 835.5197s\n",
      "\titers: 200, epoch: 8 | loss: 0.0857032\n",
      "\tspeed: 0.0204s/iter; left time: 417.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0886992 Vali Loss: 0.0885285 Test Loss: 0.1267102\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0909302\n",
      "\tspeed: 0.0352s/iter; left time: 714.7789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0866868\n",
      "\tspeed: 0.0166s/iter; left time: 334.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0884096 Vali Loss: 0.0879896 Test Loss: 0.1284705\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0849414\n",
      "\tspeed: 0.0350s/iter; left time: 703.5883s\n",
      "\titers: 200, epoch: 10 | loss: 0.0871493\n",
      "\tspeed: 0.0181s/iter; left time: 362.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0869966 Vali Loss: 0.0876488 Test Loss: 0.1233509\n",
      "Validation loss decreased (0.087698 --> 0.087649).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0851709\n",
      "\tspeed: 0.0392s/iter; left time: 778.8836s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827767\n",
      "\tspeed: 0.0216s/iter; left time: 427.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 222 | Train Loss: 0.0866055 Vali Loss: 0.0874294 Test Loss: 0.1247353\n",
      "Validation loss decreased (0.087649 --> 0.087429).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0890604\n",
      "\tspeed: 0.0411s/iter; left time: 808.1171s\n",
      "\titers: 200, epoch: 12 | loss: 0.0885759\n",
      "\tspeed: 0.0200s/iter; left time: 391.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0861026 Vali Loss: 0.0872539 Test Loss: 0.1288937\n",
      "Validation loss decreased (0.087429 --> 0.087254).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843443\n",
      "\tspeed: 0.0396s/iter; left time: 770.0740s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830567\n",
      "\tspeed: 0.0227s/iter; left time: 438.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.0856770 Vali Loss: 0.0878993 Test Loss: 0.1245098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884936\n",
      "\tspeed: 0.0405s/iter; left time: 777.3840s\n",
      "\titers: 200, epoch: 14 | loss: 0.0858436\n",
      "\tspeed: 0.0239s/iter; left time: 455.9888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 222 | Train Loss: 0.0857994 Vali Loss: 0.0867274 Test Loss: 0.1248544\n",
      "Validation loss decreased (0.087254 --> 0.086727).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0850908\n",
      "\tspeed: 0.0431s/iter; left time: 818.9968s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837386\n",
      "\tspeed: 0.0214s/iter; left time: 405.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 222 | Train Loss: 0.0852563 Vali Loss: 0.0865545 Test Loss: 0.1218124\n",
      "Validation loss decreased (0.086727 --> 0.086554).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865563\n",
      "\tspeed: 0.0370s/iter; left time: 694.4353s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827111\n",
      "\tspeed: 0.0211s/iter; left time: 394.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0849347 Vali Loss: 0.0868268 Test Loss: 0.1255154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0817033\n",
      "\tspeed: 0.0405s/iter; left time: 751.9729s\n",
      "\titers: 200, epoch: 17 | loss: 0.0859018\n",
      "\tspeed: 0.0203s/iter; left time: 374.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 222 | Train Loss: 0.0846658 Vali Loss: 0.0860702 Test Loss: 0.1188532\n",
      "Validation loss decreased (0.086554 --> 0.086070).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0847445\n",
      "\tspeed: 0.0397s/iter; left time: 727.9866s\n",
      "\titers: 200, epoch: 18 | loss: 0.0858658\n",
      "\tspeed: 0.0199s/iter; left time: 362.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0844824 Vali Loss: 0.0862537 Test Loss: 0.1194086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0864146\n",
      "\tspeed: 0.0393s/iter; left time: 712.1575s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836390\n",
      "\tspeed: 0.0217s/iter; left time: 390.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0845590 Vali Loss: 0.0858532 Test Loss: 0.1201577\n",
      "Validation loss decreased (0.086070 --> 0.085853).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0812541\n",
      "\tspeed: 0.0393s/iter; left time: 703.4058s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817963\n",
      "\tspeed: 0.0198s/iter; left time: 351.8147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0840212 Vali Loss: 0.0860785 Test Loss: 0.1225875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0852292\n",
      "\tspeed: 0.0416s/iter; left time: 734.3409s\n",
      "\titers: 200, epoch: 21 | loss: 0.0850305\n",
      "\tspeed: 0.0213s/iter; left time: 374.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 222 | Train Loss: 0.0843181 Vali Loss: 0.0860471 Test Loss: 0.1155687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0892569\n",
      "\tspeed: 0.0396s/iter; left time: 690.0318s\n",
      "\titers: 200, epoch: 22 | loss: 0.0872808\n",
      "\tspeed: 0.0179s/iter; left time: 310.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0839909 Vali Loss: 0.0864659 Test Loss: 0.1188963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0801457\n",
      "\tspeed: 0.0378s/iter; left time: 650.3457s\n",
      "\titers: 200, epoch: 23 | loss: 0.0822681\n",
      "\tspeed: 0.0195s/iter; left time: 334.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 222 | Train Loss: 0.0839554 Vali Loss: 0.0859948 Test Loss: 0.1183260\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0808729\n",
      "\tspeed: 0.0388s/iter; left time: 659.5281s\n",
      "\titers: 200, epoch: 24 | loss: 0.0849282\n",
      "\tspeed: 0.0194s/iter; left time: 328.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0837325 Vali Loss: 0.0857487 Test Loss: 0.1177279\n",
      "Validation loss decreased (0.085853 --> 0.085749).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0826968\n",
      "\tspeed: 0.0407s/iter; left time: 682.0925s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812131\n",
      "\tspeed: 0.0203s/iter; left time: 337.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0836089 Vali Loss: 0.0858979 Test Loss: 0.1185065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0807150\n",
      "\tspeed: 0.0383s/iter; left time: 634.4700s\n",
      "\titers: 200, epoch: 26 | loss: 0.0824572\n",
      "\tspeed: 0.0192s/iter; left time: 315.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0836004 Vali Loss: 0.0858044 Test Loss: 0.1179804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0878729\n",
      "\tspeed: 0.0397s/iter; left time: 648.2597s\n",
      "\titers: 200, epoch: 27 | loss: 0.0849801\n",
      "\tspeed: 0.0203s/iter; left time: 328.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0834172 Vali Loss: 0.0857046 Test Loss: 0.1182020\n",
      "Validation loss decreased (0.085749 --> 0.085705).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0838583\n",
      "\tspeed: 0.0405s/iter; left time: 652.4541s\n",
      "\titers: 200, epoch: 28 | loss: 0.0813059\n",
      "\tspeed: 0.0195s/iter; left time: 312.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0834919 Vali Loss: 0.0855824 Test Loss: 0.1166778\n",
      "Validation loss decreased (0.085705 --> 0.085582).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0836871\n",
      "\tspeed: 0.0449s/iter; left time: 712.9921s\n",
      "\titers: 200, epoch: 29 | loss: 0.0847755\n",
      "\tspeed: 0.0199s/iter; left time: 314.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0832610 Vali Loss: 0.0857332 Test Loss: 0.1181185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0813245\n",
      "\tspeed: 0.0386s/iter; left time: 604.4368s\n",
      "\titers: 200, epoch: 30 | loss: 0.0840964\n",
      "\tspeed: 0.0201s/iter; left time: 312.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0832914 Vali Loss: 0.0856515 Test Loss: 0.1181112\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0852700\n",
      "\tspeed: 0.0423s/iter; left time: 652.6959s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829485\n",
      "\tspeed: 0.0221s/iter; left time: 338.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 222 | Train Loss: 0.0832763 Vali Loss: 0.0856775 Test Loss: 0.1183331\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0829257\n",
      "\tspeed: 0.0386s/iter; left time: 588.0440s\n",
      "\titers: 200, epoch: 32 | loss: 0.0838159\n",
      "\tspeed: 0.0193s/iter; left time: 291.8504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0831706 Vali Loss: 0.0858367 Test Loss: 0.1190393\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0832361\n",
      "\tspeed: 0.0435s/iter; left time: 652.2885s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795788\n",
      "\tspeed: 0.0249s/iter; left time: 371.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 222 | Train Loss: 0.0831138 Vali Loss: 0.0857219 Test Loss: 0.1188055\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0816920\n",
      "\tspeed: 0.0420s/iter; left time: 619.9262s\n",
      "\titers: 200, epoch: 34 | loss: 0.0846989\n",
      "\tspeed: 0.0190s/iter; left time: 279.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0832282 Vali Loss: 0.0860768 Test Loss: 0.1201008\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0790423\n",
      "\tspeed: 0.0437s/iter; left time: 636.6609s\n",
      "\titers: 200, epoch: 35 | loss: 0.0868318\n",
      "\tspeed: 0.0205s/iter; left time: 295.9646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0831745 Vali Loss: 0.0857664 Test Loss: 0.1191104\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0847716\n",
      "\tspeed: 0.0391s/iter; left time: 559.6354s\n",
      "\titers: 200, epoch: 36 | loss: 0.0838767\n",
      "\tspeed: 0.0198s/iter; left time: 281.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0830319 Vali Loss: 0.0855974 Test Loss: 0.1190438\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0833445\n",
      "\tspeed: 0.0380s/iter; left time: 535.6101s\n",
      "\titers: 200, epoch: 37 | loss: 0.0856886\n",
      "\tspeed: 0.0188s/iter; left time: 262.8912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0831598 Vali Loss: 0.0855662 Test Loss: 0.1180077\n",
      "Validation loss decreased (0.085582 --> 0.085566).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0799515\n",
      "\tspeed: 0.0424s/iter; left time: 588.6139s\n",
      "\titers: 200, epoch: 38 | loss: 0.0826600\n",
      "\tspeed: 0.0205s/iter; left time: 282.5360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 222 | Train Loss: 0.0829920 Vali Loss: 0.0855045 Test Loss: 0.1182730\n",
      "Validation loss decreased (0.085566 --> 0.085504).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0807335\n",
      "\tspeed: 0.0383s/iter; left time: 523.9899s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850193\n",
      "\tspeed: 0.0183s/iter; left time: 247.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0833037 Vali Loss: 0.0853972 Test Loss: 0.1170263\n",
      "Validation loss decreased (0.085504 --> 0.085397).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0820276\n",
      "\tspeed: 0.0398s/iter; left time: 534.9637s\n",
      "\titers: 200, epoch: 40 | loss: 0.0826481\n",
      "\tspeed: 0.0186s/iter; left time: 247.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0829577 Vali Loss: 0.0856202 Test Loss: 0.1181016\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0816047\n",
      "\tspeed: 0.0414s/iter; left time: 547.0110s\n",
      "\titers: 200, epoch: 41 | loss: 0.0825021\n",
      "\tspeed: 0.0211s/iter; left time: 277.3250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 222 | Train Loss: 0.0829118 Vali Loss: 0.0856374 Test Loss: 0.1184959\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0808047\n",
      "\tspeed: 0.0382s/iter; left time: 496.4929s\n",
      "\titers: 200, epoch: 42 | loss: 0.0821543\n",
      "\tspeed: 0.0212s/iter; left time: 273.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0829277 Vali Loss: 0.0857129 Test Loss: 0.1180947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0831353\n",
      "\tspeed: 0.0372s/iter; left time: 475.7284s\n",
      "\titers: 200, epoch: 43 | loss: 0.0829241\n",
      "\tspeed: 0.0158s/iter; left time: 199.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0830579 Vali Loss: 0.0854294 Test Loss: 0.1168746\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0778174\n",
      "\tspeed: 0.0393s/iter; left time: 493.0481s\n",
      "\titers: 200, epoch: 44 | loss: 0.0832195\n",
      "\tspeed: 0.0202s/iter; left time: 251.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0828615 Vali Loss: 0.0857532 Test Loss: 0.1190419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0844192\n",
      "\tspeed: 0.0379s/iter; left time: 467.4632s\n",
      "\titers: 200, epoch: 45 | loss: 0.0852992\n",
      "\tspeed: 0.0183s/iter; left time: 223.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0829083 Vali Loss: 0.0855670 Test Loss: 0.1176639\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0820408\n",
      "\tspeed: 0.0360s/iter; left time: 435.4624s\n",
      "\titers: 200, epoch: 46 | loss: 0.0804324\n",
      "\tspeed: 0.0151s/iter; left time: 181.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0830802 Vali Loss: 0.0856216 Test Loss: 0.1181498\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0838422\n",
      "\tspeed: 0.0354s/iter; left time: 420.7172s\n",
      "\titers: 200, epoch: 47 | loss: 0.0814822\n",
      "\tspeed: 0.0134s/iter; left time: 157.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 222 | Train Loss: 0.0829183 Vali Loss: 0.0857322 Test Loss: 0.1184879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0838435\n",
      "\tspeed: 0.0387s/iter; left time: 451.3486s\n",
      "\titers: 200, epoch: 48 | loss: 0.0887901\n",
      "\tspeed: 0.0208s/iter; left time: 240.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 222 | Train Loss: 0.0828074 Vali Loss: 0.0855418 Test Loss: 0.1179537\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0827551\n",
      "\tspeed: 0.0397s/iter; left time: 454.1100s\n",
      "\titers: 200, epoch: 49 | loss: 0.0847443\n",
      "\tspeed: 0.0201s/iter; left time: 228.5552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0830245 Vali Loss: 0.0855867 Test Loss: 0.1178466\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02988913655281067, rmse:0.1728847473859787, mae:0.11702635884284973, rse:0.5079198479652405\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2821897\n",
      "\tspeed: 0.0216s/iter; left time: 477.4982s\n",
      "\titers: 200, epoch: 1 | loss: 0.2662972\n",
      "\tspeed: 0.0194s/iter; left time: 426.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.2869222 Vali Loss: 0.2178283 Test Loss: 0.2410417\n",
      "Validation loss decreased (inf --> 0.217828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1402749\n",
      "\tspeed: 0.0445s/iter; left time: 972.5662s\n",
      "\titers: 200, epoch: 2 | loss: 0.1170134\n",
      "\tspeed: 0.0213s/iter; left time: 464.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.1546210 Vali Loss: 0.1089054 Test Loss: 0.1258108\n",
      "Validation loss decreased (0.217828 --> 0.108905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089977\n",
      "\tspeed: 0.0406s/iter; left time: 879.7298s\n",
      "\titers: 200, epoch: 3 | loss: 0.1009634\n",
      "\tspeed: 0.0189s/iter; left time: 408.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.1089586 Vali Loss: 0.0951688 Test Loss: 0.1160846\n",
      "Validation loss decreased (0.108905 --> 0.095169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0948937\n",
      "\tspeed: 0.0425s/iter; left time: 910.8174s\n",
      "\titers: 200, epoch: 4 | loss: 0.0920056\n",
      "\tspeed: 0.0192s/iter; left time: 408.6235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0974960 Vali Loss: 0.0899071 Test Loss: 0.1197113\n",
      "Validation loss decreased (0.095169 --> 0.089907).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0886399\n",
      "\tspeed: 0.0396s/iter; left time: 840.8275s\n",
      "\titers: 200, epoch: 5 | loss: 0.0907884\n",
      "\tspeed: 0.0192s/iter; left time: 405.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0925229 Vali Loss: 0.0882349 Test Loss: 0.1198818\n",
      "Validation loss decreased (0.089907 --> 0.088235).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0976840\n",
      "\tspeed: 0.0417s/iter; left time: 876.1996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848660\n",
      "\tspeed: 0.0195s/iter; left time: 408.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0902449 Vali Loss: 0.0874264 Test Loss: 0.1217533\n",
      "Validation loss decreased (0.088235 --> 0.087426).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0865841\n",
      "\tspeed: 0.0435s/iter; left time: 902.5675s\n",
      "\titers: 200, epoch: 7 | loss: 0.0873563\n",
      "\tspeed: 0.0215s/iter; left time: 443.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0897471 Vali Loss: 0.0867669 Test Loss: 0.1248483\n",
      "Validation loss decreased (0.087426 --> 0.086767).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843920\n",
      "\tspeed: 0.0372s/iter; left time: 764.2617s\n",
      "\titers: 200, epoch: 8 | loss: 0.0859653\n",
      "\tspeed: 0.0210s/iter; left time: 428.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0878318 Vali Loss: 0.0865790 Test Loss: 0.1223411\n",
      "Validation loss decreased (0.086767 --> 0.086579).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0863907\n",
      "\tspeed: 0.0411s/iter; left time: 836.3147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878436\n",
      "\tspeed: 0.0202s/iter; left time: 407.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0882253 Vali Loss: 0.0873237 Test Loss: 0.1209770\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0885530\n",
      "\tspeed: 0.0368s/iter; left time: 740.2682s\n",
      "\titers: 200, epoch: 10 | loss: 0.0851510\n",
      "\tspeed: 0.0176s/iter; left time: 351.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0867634 Vali Loss: 0.0861487 Test Loss: 0.1205170\n",
      "Validation loss decreased (0.086579 --> 0.086149).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0874344\n",
      "\tspeed: 0.0420s/iter; left time: 835.1294s\n",
      "\titers: 200, epoch: 11 | loss: 0.0863595\n",
      "\tspeed: 0.0197s/iter; left time: 389.6824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0872570 Vali Loss: 0.0868843 Test Loss: 0.1093109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830597\n",
      "\tspeed: 0.0396s/iter; left time: 778.0871s\n",
      "\titers: 200, epoch: 12 | loss: 0.0851362\n",
      "\tspeed: 0.0179s/iter; left time: 350.3825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0860929 Vali Loss: 0.0858989 Test Loss: 0.1195716\n",
      "Validation loss decreased (0.086149 --> 0.085899).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843017\n",
      "\tspeed: 0.0391s/iter; left time: 759.2112s\n",
      "\titers: 200, epoch: 13 | loss: 0.0812857\n",
      "\tspeed: 0.0161s/iter; left time: 311.3117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0854211 Vali Loss: 0.0858222 Test Loss: 0.1169128\n",
      "Validation loss decreased (0.085899 --> 0.085822).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841619\n",
      "\tspeed: 0.0400s/iter; left time: 768.1986s\n",
      "\titers: 200, epoch: 14 | loss: 0.0850563\n",
      "\tspeed: 0.0177s/iter; left time: 338.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0851428 Vali Loss: 0.0859217 Test Loss: 0.1162745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0841240\n",
      "\tspeed: 0.0387s/iter; left time: 734.9434s\n",
      "\titers: 200, epoch: 15 | loss: 0.0833289\n",
      "\tspeed: 0.0187s/iter; left time: 352.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0850074 Vali Loss: 0.0865957 Test Loss: 0.1217066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0830861\n",
      "\tspeed: 0.0362s/iter; left time: 680.4317s\n",
      "\titers: 200, epoch: 16 | loss: 0.0840037\n",
      "\tspeed: 0.0176s/iter; left time: 327.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0851832 Vali Loss: 0.0857930 Test Loss: 0.1104908\n",
      "Validation loss decreased (0.085822 --> 0.085793).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0843337\n",
      "\tspeed: 0.0330s/iter; left time: 611.6875s\n",
      "\titers: 200, epoch: 17 | loss: 0.0852274\n",
      "\tspeed: 0.0189s/iter; left time: 348.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0847358 Vali Loss: 0.0859714 Test Loss: 0.1197677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0847530\n",
      "\tspeed: 0.0405s/iter; left time: 741.7639s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827119\n",
      "\tspeed: 0.0199s/iter; left time: 362.3093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0849122 Vali Loss: 0.0861478 Test Loss: 0.1128591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0878472\n",
      "\tspeed: 0.0366s/iter; left time: 662.8682s\n",
      "\titers: 200, epoch: 19 | loss: 0.0837518\n",
      "\tspeed: 0.0136s/iter; left time: 244.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 222 | Train Loss: 0.0843614 Vali Loss: 0.0858992 Test Loss: 0.1152965\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0821137\n",
      "\tspeed: 0.0381s/iter; left time: 681.6375s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824019\n",
      "\tspeed: 0.0191s/iter; left time: 340.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0840971 Vali Loss: 0.0856594 Test Loss: 0.1176547\n",
      "Validation loss decreased (0.085793 --> 0.085659).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0854850\n",
      "\tspeed: 0.0408s/iter; left time: 719.9022s\n",
      "\titers: 200, epoch: 21 | loss: 0.0865156\n",
      "\tspeed: 0.0168s/iter; left time: 294.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0839960 Vali Loss: 0.0860197 Test Loss: 0.1178863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0861932\n",
      "\tspeed: 0.0388s/iter; left time: 676.5554s\n",
      "\titers: 200, epoch: 22 | loss: 0.0849553\n",
      "\tspeed: 0.0178s/iter; left time: 308.8175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0839448 Vali Loss: 0.0856153 Test Loss: 0.1129521\n",
      "Validation loss decreased (0.085659 --> 0.085615).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0820616\n",
      "\tspeed: 0.0416s/iter; left time: 715.3827s\n",
      "\titers: 200, epoch: 23 | loss: 0.0854930\n",
      "\tspeed: 0.0239s/iter; left time: 409.1528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0840585 Vali Loss: 0.0858276 Test Loss: 0.1156647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0851940\n",
      "\tspeed: 0.0430s/iter; left time: 730.3624s\n",
      "\titers: 200, epoch: 24 | loss: 0.0842922\n",
      "\tspeed: 0.0174s/iter; left time: 294.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0837446 Vali Loss: 0.0858859 Test Loss: 0.1151031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0862199\n",
      "\tspeed: 0.0427s/iter; left time: 716.6123s\n",
      "\titers: 200, epoch: 25 | loss: 0.0840616\n",
      "\tspeed: 0.0192s/iter; left time: 320.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0838487 Vali Loss: 0.0854888 Test Loss: 0.1125921\n",
      "Validation loss decreased (0.085615 --> 0.085489).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0849226\n",
      "\tspeed: 0.0433s/iter; left time: 716.6674s\n",
      "\titers: 200, epoch: 26 | loss: 0.0828406\n",
      "\tspeed: 0.0180s/iter; left time: 296.4431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0835528 Vali Loss: 0.0856917 Test Loss: 0.1148463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0807310\n",
      "\tspeed: 0.0398s/iter; left time: 650.4971s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837605\n",
      "\tspeed: 0.0237s/iter; left time: 384.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 222 | Train Loss: 0.0835648 Vali Loss: 0.0856213 Test Loss: 0.1142073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0844091\n",
      "\tspeed: 0.0416s/iter; left time: 669.9292s\n",
      "\titers: 200, epoch: 28 | loss: 0.0845645\n",
      "\tspeed: 0.0206s/iter; left time: 329.2876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0834028 Vali Loss: 0.0856825 Test Loss: 0.1177439\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0843583\n",
      "\tspeed: 0.0421s/iter; left time: 669.3646s\n",
      "\titers: 200, epoch: 29 | loss: 0.0869262\n",
      "\tspeed: 0.0231s/iter; left time: 363.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.0833694 Vali Loss: 0.0854174 Test Loss: 0.1140677\n",
      "Validation loss decreased (0.085489 --> 0.085417).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0819029\n",
      "\tspeed: 0.0401s/iter; left time: 628.5273s\n",
      "\titers: 200, epoch: 30 | loss: 0.0824094\n",
      "\tspeed: 0.0187s/iter; left time: 291.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0833229 Vali Loss: 0.0855661 Test Loss: 0.1136627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0805220\n",
      "\tspeed: 0.0431s/iter; left time: 665.1611s\n",
      "\titers: 200, epoch: 31 | loss: 0.0854735\n",
      "\tspeed: 0.0223s/iter; left time: 341.9589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 222 | Train Loss: 0.0834485 Vali Loss: 0.0855906 Test Loss: 0.1148575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0856634\n",
      "\tspeed: 0.0390s/iter; left time: 593.3670s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857480\n",
      "\tspeed: 0.0206s/iter; left time: 310.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0831953 Vali Loss: 0.0855765 Test Loss: 0.1134769\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0844713\n",
      "\tspeed: 0.0431s/iter; left time: 645.8177s\n",
      "\titers: 200, epoch: 33 | loss: 0.0828239\n",
      "\tspeed: 0.0239s/iter; left time: 355.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 222 | Train Loss: 0.0832462 Vali Loss: 0.0855763 Test Loss: 0.1142933\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0818999\n",
      "\tspeed: 0.0398s/iter; left time: 587.5637s\n",
      "\titers: 200, epoch: 34 | loss: 0.0871794\n",
      "\tspeed: 0.0192s/iter; left time: 282.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0831211 Vali Loss: 0.0857023 Test Loss: 0.1149117\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0847295\n",
      "\tspeed: 0.0389s/iter; left time: 565.9403s\n",
      "\titers: 200, epoch: 35 | loss: 0.0877135\n",
      "\tspeed: 0.0193s/iter; left time: 279.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0832192 Vali Loss: 0.0856881 Test Loss: 0.1154160\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0835417\n",
      "\tspeed: 0.0415s/iter; left time: 594.0777s\n",
      "\titers: 200, epoch: 36 | loss: 0.0807922\n",
      "\tspeed: 0.0187s/iter; left time: 265.4872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0830666 Vali Loss: 0.0854562 Test Loss: 0.1146717\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815550\n",
      "\tspeed: 0.0361s/iter; left time: 509.0045s\n",
      "\titers: 200, epoch: 37 | loss: 0.0827467\n",
      "\tspeed: 0.0178s/iter; left time: 248.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0830627 Vali Loss: 0.0855188 Test Loss: 0.1143365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0831372\n",
      "\tspeed: 0.0374s/iter; left time: 519.2990s\n",
      "\titers: 200, epoch: 38 | loss: 0.0816436\n",
      "\tspeed: 0.0188s/iter; left time: 258.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0829982 Vali Loss: 0.0853280 Test Loss: 0.1141640\n",
      "Validation loss decreased (0.085417 --> 0.085328).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0828349\n",
      "\tspeed: 0.0397s/iter; left time: 542.5488s\n",
      "\titers: 200, epoch: 39 | loss: 0.0799944\n",
      "\tspeed: 0.0223s/iter; left time: 302.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0831050 Vali Loss: 0.0855138 Test Loss: 0.1142776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0838986\n",
      "\tspeed: 0.0424s/iter; left time: 569.5237s\n",
      "\titers: 200, epoch: 40 | loss: 0.0845640\n",
      "\tspeed: 0.0208s/iter; left time: 277.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 222 | Train Loss: 0.0830937 Vali Loss: 0.0854541 Test Loss: 0.1141114\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0808545\n",
      "\tspeed: 0.0382s/iter; left time: 505.4669s\n",
      "\titers: 200, epoch: 41 | loss: 0.0814568\n",
      "\tspeed: 0.0166s/iter; left time: 218.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0829372 Vali Loss: 0.0854409 Test Loss: 0.1140873\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0817157\n",
      "\tspeed: 0.0425s/iter; left time: 552.4427s\n",
      "\titers: 200, epoch: 42 | loss: 0.0828290\n",
      "\tspeed: 0.0213s/iter; left time: 275.3760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 222 | Train Loss: 0.0831038 Vali Loss: 0.0856674 Test Loss: 0.1147176\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0826415\n",
      "\tspeed: 0.0384s/iter; left time: 490.1672s\n",
      "\titers: 200, epoch: 43 | loss: 0.0856394\n",
      "\tspeed: 0.0191s/iter; left time: 241.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0829656 Vali Loss: 0.0856309 Test Loss: 0.1150501\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0838955\n",
      "\tspeed: 0.0424s/iter; left time: 532.9407s\n",
      "\titers: 200, epoch: 44 | loss: 0.0803811\n",
      "\tspeed: 0.0198s/iter; left time: 247.1508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0829090 Vali Loss: 0.0854407 Test Loss: 0.1149802\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0877293\n",
      "\tspeed: 0.0397s/iter; left time: 490.1233s\n",
      "\titers: 200, epoch: 45 | loss: 0.0817341\n",
      "\tspeed: 0.0194s/iter; left time: 237.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0830114 Vali Loss: 0.0854746 Test Loss: 0.1146787\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0807717\n",
      "\tspeed: 0.0353s/iter; left time: 427.6414s\n",
      "\titers: 200, epoch: 46 | loss: 0.0828474\n",
      "\tspeed: 0.0199s/iter; left time: 239.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0828582 Vali Loss: 0.0854172 Test Loss: 0.1140642\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0841669\n",
      "\tspeed: 0.0387s/iter; left time: 460.3040s\n",
      "\titers: 200, epoch: 47 | loss: 0.0829546\n",
      "\tspeed: 0.0184s/iter; left time: 217.4382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0831731 Vali Loss: 0.0854332 Test Loss: 0.1138964\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0812709\n",
      "\tspeed: 0.0408s/iter; left time: 475.7302s\n",
      "\titers: 200, epoch: 48 | loss: 0.0801140\n",
      "\tspeed: 0.0176s/iter; left time: 203.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 222 | Train Loss: 0.0836791 Vali Loss: 0.0855523 Test Loss: 0.1143685\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0276211965829134, rmse:0.16619625687599182, mae:0.11416394263505936, rse:0.4882696568965912\n",
      "Intermediate time for ES and pred_len 168: 00h:09m:44.95s\n",
      "Intermediate time for ES: 00h:33m:16.21s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2236021\n",
      "\tspeed: 0.0431s/iter; left time: 956.9041s\n",
      "\titers: 200, epoch: 1 | loss: 0.2074823\n",
      "\tspeed: 0.0133s/iter; left time: 293.7634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 223 | Train Loss: 0.2296431 Vali Loss: 0.1732810 Test Loss: 0.1809211\n",
      "Validation loss decreased (inf --> 0.173281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1360764\n",
      "\tspeed: 0.0311s/iter; left time: 682.6362s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070553\n",
      "\tspeed: 0.0133s/iter; left time: 290.2195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 223 | Train Loss: 0.1396844 Vali Loss: 0.0805110 Test Loss: 0.0888648\n",
      "Validation loss decreased (0.173281 --> 0.080511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0867475\n",
      "\tspeed: 0.0306s/iter; left time: 664.6659s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819789\n",
      "\tspeed: 0.0133s/iter; left time: 287.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 223 | Train Loss: 0.0886421 Vali Loss: 0.0758004 Test Loss: 0.0803676\n",
      "Validation loss decreased (0.080511 --> 0.075800).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0735695\n",
      "\tspeed: 0.0329s/iter; left time: 708.5680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0739823\n",
      "\tspeed: 0.0170s/iter; left time: 363.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0747412 Vali Loss: 0.0700433 Test Loss: 0.0733856\n",
      "Validation loss decreased (0.075800 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643737\n",
      "\tspeed: 0.0374s/iter; left time: 796.0900s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621697\n",
      "\tspeed: 0.0212s/iter; left time: 449.8642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0664498 Vali Loss: 0.0659719 Test Loss: 0.0682993\n",
      "Validation loss decreased (0.070043 --> 0.065972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638608\n",
      "\tspeed: 0.0362s/iter; left time: 763.4744s\n",
      "\titers: 200, epoch: 6 | loss: 0.0557668\n",
      "\tspeed: 0.0166s/iter; left time: 348.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0618227 Vali Loss: 0.0629342 Test Loss: 0.0657877\n",
      "Validation loss decreased (0.065972 --> 0.062934).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0578528\n",
      "\tspeed: 0.0360s/iter; left time: 750.1977s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585506\n",
      "\tspeed: 0.0150s/iter; left time: 312.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0590780 Vali Loss: 0.0619209 Test Loss: 0.0649757\n",
      "Validation loss decreased (0.062934 --> 0.061921).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575072\n",
      "\tspeed: 0.0405s/iter; left time: 835.5666s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558983\n",
      "\tspeed: 0.0180s/iter; left time: 369.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0568973 Vali Loss: 0.0624090 Test Loss: 0.0652848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570882\n",
      "\tspeed: 0.0341s/iter; left time: 695.7735s\n",
      "\titers: 200, epoch: 9 | loss: 0.0554337\n",
      "\tspeed: 0.0165s/iter; left time: 335.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0553634 Vali Loss: 0.0605830 Test Loss: 0.0639263\n",
      "Validation loss decreased (0.061921 --> 0.060583).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0517657\n",
      "\tspeed: 0.0400s/iter; left time: 807.9229s\n",
      "\titers: 200, epoch: 10 | loss: 0.0521178\n",
      "\tspeed: 0.0202s/iter; left time: 406.2385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 223 | Train Loss: 0.0543636 Vali Loss: 0.0603368 Test Loss: 0.0634552\n",
      "Validation loss decreased (0.060583 --> 0.060337).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0519553\n",
      "\tspeed: 0.0346s/iter; left time: 691.5078s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556286\n",
      "\tspeed: 0.0135s/iter; left time: 268.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 223 | Train Loss: 0.0535645 Vali Loss: 0.0599187 Test Loss: 0.0630554\n",
      "Validation loss decreased (0.060337 --> 0.059919).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0516504\n",
      "\tspeed: 0.0306s/iter; left time: 604.3686s\n",
      "\titers: 200, epoch: 12 | loss: 0.0534213\n",
      "\tspeed: 0.0148s/iter; left time: 290.3425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 223 | Train Loss: 0.0529137 Vali Loss: 0.0594783 Test Loss: 0.0625498\n",
      "Validation loss decreased (0.059919 --> 0.059478).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0555475\n",
      "\tspeed: 0.0390s/iter; left time: 760.6740s\n",
      "\titers: 200, epoch: 13 | loss: 0.0584816\n",
      "\tspeed: 0.0195s/iter; left time: 378.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0524057 Vali Loss: 0.0593581 Test Loss: 0.0624754\n",
      "Validation loss decreased (0.059478 --> 0.059358).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542893\n",
      "\tspeed: 0.0359s/iter; left time: 693.1815s\n",
      "\titers: 200, epoch: 14 | loss: 0.0534149\n",
      "\tspeed: 0.0173s/iter; left time: 332.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0519929 Vali Loss: 0.0595860 Test Loss: 0.0625940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0527701\n",
      "\tspeed: 0.0361s/iter; left time: 689.1885s\n",
      "\titers: 200, epoch: 15 | loss: 0.0493728\n",
      "\tspeed: 0.0168s/iter; left time: 318.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0517307 Vali Loss: 0.0589212 Test Loss: 0.0621964\n",
      "Validation loss decreased (0.059358 --> 0.058921).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0520452\n",
      "\tspeed: 0.0382s/iter; left time: 720.7115s\n",
      "\titers: 200, epoch: 16 | loss: 0.0459705\n",
      "\tspeed: 0.0168s/iter; left time: 314.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0514461 Vali Loss: 0.0589452 Test Loss: 0.0618999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0505355\n",
      "\tspeed: 0.0353s/iter; left time: 657.5524s\n",
      "\titers: 200, epoch: 17 | loss: 0.0472499\n",
      "\tspeed: 0.0172s/iter; left time: 319.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0511582 Vali Loss: 0.0588045 Test Loss: 0.0617049\n",
      "Validation loss decreased (0.058921 --> 0.058804).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0510904\n",
      "\tspeed: 0.0368s/iter; left time: 676.9018s\n",
      "\titers: 200, epoch: 18 | loss: 0.0490897\n",
      "\tspeed: 0.0202s/iter; left time: 369.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0509984 Vali Loss: 0.0584419 Test Loss: 0.0615125\n",
      "Validation loss decreased (0.058804 --> 0.058442).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543168\n",
      "\tspeed: 0.0422s/iter; left time: 767.4304s\n",
      "\titers: 200, epoch: 19 | loss: 0.0495084\n",
      "\tspeed: 0.0165s/iter; left time: 298.0639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0507014 Vali Loss: 0.0585291 Test Loss: 0.0615802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0476689\n",
      "\tspeed: 0.0316s/iter; left time: 567.6231s\n",
      "\titers: 200, epoch: 20 | loss: 0.0483478\n",
      "\tspeed: 0.0135s/iter; left time: 241.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 223 | Train Loss: 0.0504669 Vali Loss: 0.0584182 Test Loss: 0.0615142\n",
      "Validation loss decreased (0.058442 --> 0.058418).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0530382\n",
      "\tspeed: 0.0388s/iter; left time: 687.6030s\n",
      "\titers: 200, epoch: 21 | loss: 0.0502974\n",
      "\tspeed: 0.0201s/iter; left time: 353.7303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0504094 Vali Loss: 0.0584650 Test Loss: 0.0613061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0517241\n",
      "\tspeed: 0.0369s/iter; left time: 646.3329s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502089\n",
      "\tspeed: 0.0177s/iter; left time: 307.7001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0504444 Vali Loss: 0.0588497 Test Loss: 0.0620846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0514007\n",
      "\tspeed: 0.0360s/iter; left time: 622.7216s\n",
      "\titers: 200, epoch: 23 | loss: 0.0492585\n",
      "\tspeed: 0.0168s/iter; left time: 288.7784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0500185 Vali Loss: 0.0583586 Test Loss: 0.0614094\n",
      "Validation loss decreased (0.058418 --> 0.058359).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0496051\n",
      "\tspeed: 0.0427s/iter; left time: 729.1959s\n",
      "\titers: 200, epoch: 24 | loss: 0.0515021\n",
      "\tspeed: 0.0238s/iter; left time: 404.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0501878 Vali Loss: 0.0579947 Test Loss: 0.0611901\n",
      "Validation loss decreased (0.058359 --> 0.057995).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0468790\n",
      "\tspeed: 0.0358s/iter; left time: 602.5947s\n",
      "\titers: 200, epoch: 25 | loss: 0.0514483\n",
      "\tspeed: 0.0164s/iter; left time: 274.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0498330 Vali Loss: 0.0578034 Test Loss: 0.0610533\n",
      "Validation loss decreased (0.057995 --> 0.057803).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0520252\n",
      "\tspeed: 0.0379s/iter; left time: 629.6228s\n",
      "\titers: 200, epoch: 26 | loss: 0.0486651\n",
      "\tspeed: 0.0152s/iter; left time: 251.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0498788 Vali Loss: 0.0577818 Test Loss: 0.0609126\n",
      "Validation loss decreased (0.057803 --> 0.057782).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0510661\n",
      "\tspeed: 0.0347s/iter; left time: 568.7184s\n",
      "\titers: 200, epoch: 27 | loss: 0.0510372\n",
      "\tspeed: 0.0133s/iter; left time: 216.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 223 | Train Loss: 0.0496795 Vali Loss: 0.0577717 Test Loss: 0.0609448\n",
      "Validation loss decreased (0.057782 --> 0.057772).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0492486\n",
      "\tspeed: 0.0344s/iter; left time: 557.3684s\n",
      "\titers: 200, epoch: 28 | loss: 0.0490624\n",
      "\tspeed: 0.0190s/iter; left time: 305.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0497134 Vali Loss: 0.0577583 Test Loss: 0.0608637\n",
      "Validation loss decreased (0.057772 --> 0.057758).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0447029\n",
      "\tspeed: 0.0435s/iter; left time: 693.4158s\n",
      "\titers: 200, epoch: 29 | loss: 0.0518960\n",
      "\tspeed: 0.0219s/iter; left time: 347.8580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0494149 Vali Loss: 0.0578336 Test Loss: 0.0609054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0467443\n",
      "\tspeed: 0.0354s/iter; left time: 556.3137s\n",
      "\titers: 200, epoch: 30 | loss: 0.0528328\n",
      "\tspeed: 0.0161s/iter; left time: 252.1584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0495071 Vali Loss: 0.0576725 Test Loss: 0.0608237\n",
      "Validation loss decreased (0.057758 --> 0.057673).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525649\n",
      "\tspeed: 0.0322s/iter; left time: 498.9192s\n",
      "\titers: 200, epoch: 31 | loss: 0.0509100\n",
      "\tspeed: 0.0136s/iter; left time: 209.3109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 223 | Train Loss: 0.0496710 Vali Loss: 0.0578038 Test Loss: 0.0610071\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0497216\n",
      "\tspeed: 0.0339s/iter; left time: 517.7503s\n",
      "\titers: 200, epoch: 32 | loss: 0.0518590\n",
      "\tspeed: 0.0138s/iter; left time: 209.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0493097 Vali Loss: 0.0579932 Test Loss: 0.0611472\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0471173\n",
      "\tspeed: 0.0309s/iter; left time: 465.1658s\n",
      "\titers: 200, epoch: 33 | loss: 0.0510127\n",
      "\tspeed: 0.0153s/iter; left time: 228.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 223 | Train Loss: 0.0496982 Vali Loss: 0.0577739 Test Loss: 0.0608639\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0507986\n",
      "\tspeed: 0.0350s/iter; left time: 518.8142s\n",
      "\titers: 200, epoch: 34 | loss: 0.0460285\n",
      "\tspeed: 0.0159s/iter; left time: 234.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0494031 Vali Loss: 0.0576002 Test Loss: 0.0606971\n",
      "Validation loss decreased (0.057673 --> 0.057600).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532590\n",
      "\tspeed: 0.0354s/iter; left time: 518.1789s\n",
      "\titers: 200, epoch: 35 | loss: 0.0478990\n",
      "\tspeed: 0.0172s/iter; left time: 249.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0491909 Vali Loss: 0.0575724 Test Loss: 0.0607575\n",
      "Validation loss decreased (0.057600 --> 0.057572).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536563\n",
      "\tspeed: 0.0360s/iter; left time: 518.3351s\n",
      "\titers: 200, epoch: 36 | loss: 0.0494200\n",
      "\tspeed: 0.0197s/iter; left time: 282.2193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0493233 Vali Loss: 0.0574575 Test Loss: 0.0607408\n",
      "Validation loss decreased (0.057572 --> 0.057457).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0514181\n",
      "\tspeed: 0.0329s/iter; left time: 465.7316s\n",
      "\titers: 200, epoch: 37 | loss: 0.0520622\n",
      "\tspeed: 0.0155s/iter; left time: 217.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 223 | Train Loss: 0.0493328 Vali Loss: 0.0575636 Test Loss: 0.0608380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0469239\n",
      "\tspeed: 0.0363s/iter; left time: 506.4350s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513847\n",
      "\tspeed: 0.0192s/iter; left time: 265.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0491634 Vali Loss: 0.0575453 Test Loss: 0.0607609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0485902\n",
      "\tspeed: 0.0423s/iter; left time: 580.5063s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522214\n",
      "\tspeed: 0.0215s/iter; left time: 293.2435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0491197 Vali Loss: 0.0574916 Test Loss: 0.0606667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0508878\n",
      "\tspeed: 0.0365s/iter; left time: 492.2792s\n",
      "\titers: 200, epoch: 40 | loss: 0.0510726\n",
      "\tspeed: 0.0171s/iter; left time: 229.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0491322 Vali Loss: 0.0574877 Test Loss: 0.0606639\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0474850\n",
      "\tspeed: 0.0333s/iter; left time: 442.7905s\n",
      "\titers: 200, epoch: 41 | loss: 0.0489669\n",
      "\tspeed: 0.0162s/iter; left time: 213.4800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0490654 Vali Loss: 0.0574554 Test Loss: 0.0606490\n",
      "Validation loss decreased (0.057457 --> 0.057455).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0482732\n",
      "\tspeed: 0.0360s/iter; left time: 470.3999s\n",
      "\titers: 200, epoch: 42 | loss: 0.0486201\n",
      "\tspeed: 0.0226s/iter; left time: 293.3975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0491024 Vali Loss: 0.0575753 Test Loss: 0.0607962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0493894\n",
      "\tspeed: 0.0396s/iter; left time: 507.6437s\n",
      "\titers: 200, epoch: 43 | loss: 0.0455434\n",
      "\tspeed: 0.0189s/iter; left time: 240.4892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0491048 Vali Loss: 0.0574100 Test Loss: 0.0606996\n",
      "Validation loss decreased (0.057455 --> 0.057410).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0484123\n",
      "\tspeed: 0.0393s/iter; left time: 495.7411s\n",
      "\titers: 200, epoch: 44 | loss: 0.0515075\n",
      "\tspeed: 0.0195s/iter; left time: 243.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0490080 Vali Loss: 0.0574107 Test Loss: 0.0606340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0502327\n",
      "\tspeed: 0.0387s/iter; left time: 479.2604s\n",
      "\titers: 200, epoch: 45 | loss: 0.0473230\n",
      "\tspeed: 0.0170s/iter; left time: 208.8321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0489649 Vali Loss: 0.0574543 Test Loss: 0.0607070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0476432\n",
      "\tspeed: 0.0345s/iter; left time: 420.2124s\n",
      "\titers: 200, epoch: 46 | loss: 0.0520346\n",
      "\tspeed: 0.0173s/iter; left time: 208.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0490683 Vali Loss: 0.0573822 Test Loss: 0.0606217\n",
      "Validation loss decreased (0.057410 --> 0.057382).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0490245\n",
      "\tspeed: 0.0382s/iter; left time: 456.3953s\n",
      "\titers: 200, epoch: 47 | loss: 0.0538171\n",
      "\tspeed: 0.0184s/iter; left time: 218.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0489807 Vali Loss: 0.0572679 Test Loss: 0.0605518\n",
      "Validation loss decreased (0.057382 --> 0.057268).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0475258\n",
      "\tspeed: 0.0372s/iter; left time: 436.1365s\n",
      "\titers: 200, epoch: 48 | loss: 0.0465208\n",
      "\tspeed: 0.0151s/iter; left time: 175.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0491117 Vali Loss: 0.0573993 Test Loss: 0.0606615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0471503\n",
      "\tspeed: 0.0397s/iter; left time: 456.5355s\n",
      "\titers: 200, epoch: 49 | loss: 0.0496441\n",
      "\tspeed: 0.0214s/iter; left time: 243.8779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0489702 Vali Loss: 0.0574515 Test Loss: 0.0606550\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0499291\n",
      "\tspeed: 0.0373s/iter; left time: 420.9876s\n",
      "\titers: 200, epoch: 50 | loss: 0.0515318\n",
      "\tspeed: 0.0196s/iter; left time: 218.8861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0490966 Vali Loss: 0.0574057 Test Loss: 0.0606869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0453082\n",
      "\tspeed: 0.0364s/iter; left time: 402.1342s\n",
      "\titers: 200, epoch: 51 | loss: 0.0507189\n",
      "\tspeed: 0.0185s/iter; left time: 202.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0490981 Vali Loss: 0.0574868 Test Loss: 0.0607159\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0471148\n",
      "\tspeed: 0.0381s/iter; left time: 412.9252s\n",
      "\titers: 200, epoch: 52 | loss: 0.0459591\n",
      "\tspeed: 0.0206s/iter; left time: 220.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 223 | Train Loss: 0.0489687 Vali Loss: 0.0573664 Test Loss: 0.0605892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0502054\n",
      "\tspeed: 0.0383s/iter; left time: 406.0897s\n",
      "\titers: 200, epoch: 53 | loss: 0.0481141\n",
      "\tspeed: 0.0193s/iter; left time: 202.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0489371 Vali Loss: 0.0574584 Test Loss: 0.0607231\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0486371\n",
      "\tspeed: 0.0345s/iter; left time: 357.9925s\n",
      "\titers: 200, epoch: 54 | loss: 0.0518243\n",
      "\tspeed: 0.0179s/iter; left time: 184.0541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0490533 Vali Loss: 0.0573801 Test Loss: 0.0607377\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0500921\n",
      "\tspeed: 0.0364s/iter; left time: 369.3293s\n",
      "\titers: 200, epoch: 55 | loss: 0.0491087\n",
      "\tspeed: 0.0184s/iter; left time: 185.5656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0489493 Vali Loss: 0.0574722 Test Loss: 0.0607315\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0487431\n",
      "\tspeed: 0.0335s/iter; left time: 332.7176s\n",
      "\titers: 200, epoch: 56 | loss: 0.0509029\n",
      "\tspeed: 0.0175s/iter; left time: 171.9279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0489758 Vali Loss: 0.0574516 Test Loss: 0.0606661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0471308\n",
      "\tspeed: 0.0396s/iter; left time: 385.0964s\n",
      "\titers: 200, epoch: 57 | loss: 0.0509828\n",
      "\tspeed: 0.0164s/iter; left time: 157.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0489801 Vali Loss: 0.0575116 Test Loss: 0.0607592\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011035501956939697, rmse:0.1050499975681305, mae:0.06055183708667755, rse:0.4052799940109253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2229232\n",
      "\tspeed: 0.0235s/iter; left time: 521.5916s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131954\n",
      "\tspeed: 0.0198s/iter; left time: 438.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.2279222 Vali Loss: 0.1772987 Test Loss: 0.1836136\n",
      "Validation loss decreased (inf --> 0.177299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1249637\n",
      "\tspeed: 0.0370s/iter; left time: 814.0346s\n",
      "\titers: 200, epoch: 2 | loss: 0.0974508\n",
      "\tspeed: 0.0169s/iter; left time: 370.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1351827 Vali Loss: 0.0813727 Test Loss: 0.0883006\n",
      "Validation loss decreased (0.177299 --> 0.081373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0826826\n",
      "\tspeed: 0.0385s/iter; left time: 838.3346s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779804\n",
      "\tspeed: 0.0135s/iter; left time: 291.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0842363 Vali Loss: 0.0744897 Test Loss: 0.0781360\n",
      "Validation loss decreased (0.081373 --> 0.074490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733077\n",
      "\tspeed: 0.0351s/iter; left time: 755.3450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0706052\n",
      "\tspeed: 0.0197s/iter; left time: 421.6409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0731312 Vali Loss: 0.0680141 Test Loss: 0.0700743\n",
      "Validation loss decreased (0.074490 --> 0.068014).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646106\n",
      "\tspeed: 0.0425s/iter; left time: 904.7395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0675028\n",
      "\tspeed: 0.0207s/iter; left time: 438.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0650462 Vali Loss: 0.0643297 Test Loss: 0.0671408\n",
      "Validation loss decreased (0.068014 --> 0.064330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591188\n",
      "\tspeed: 0.0433s/iter; left time: 912.8163s\n",
      "\titers: 200, epoch: 6 | loss: 0.0710175\n",
      "\tspeed: 0.0222s/iter; left time: 466.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0620537 Vali Loss: 0.0625399 Test Loss: 0.0661575\n",
      "Validation loss decreased (0.064330 --> 0.062540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595751\n",
      "\tspeed: 0.0448s/iter; left time: 934.0816s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573575\n",
      "\tspeed: 0.0214s/iter; left time: 443.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0584189 Vali Loss: 0.0616645 Test Loss: 0.0645398\n",
      "Validation loss decreased (0.062540 --> 0.061665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0562228\n",
      "\tspeed: 0.0377s/iter; left time: 778.7155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0559921\n",
      "\tspeed: 0.0187s/iter; left time: 384.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0567347 Vali Loss: 0.0625339 Test Loss: 0.0649768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550645\n",
      "\tspeed: 0.0385s/iter; left time: 785.9485s\n",
      "\titers: 200, epoch: 9 | loss: 0.0569895\n",
      "\tspeed: 0.0189s/iter; left time: 383.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0553669 Vali Loss: 0.0608301 Test Loss: 0.0641775\n",
      "Validation loss decreased (0.061665 --> 0.060830).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544550\n",
      "\tspeed: 0.0341s/iter; left time: 688.1749s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551585\n",
      "\tspeed: 0.0190s/iter; left time: 382.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0541188 Vali Loss: 0.0601871 Test Loss: 0.0634924\n",
      "Validation loss decreased (0.060830 --> 0.060187).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517126\n",
      "\tspeed: 0.0362s/iter; left time: 723.6523s\n",
      "\titers: 200, epoch: 11 | loss: 0.0560879\n",
      "\tspeed: 0.0175s/iter; left time: 347.3288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0533662 Vali Loss: 0.0604781 Test Loss: 0.0635637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0528089\n",
      "\tspeed: 0.0315s/iter; left time: 621.9067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0517684\n",
      "\tspeed: 0.0133s/iter; left time: 260.4772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 223 | Train Loss: 0.0528128 Vali Loss: 0.0597733 Test Loss: 0.0627881\n",
      "Validation loss decreased (0.060187 --> 0.059773).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0540974\n",
      "\tspeed: 0.0410s/iter; left time: 801.2345s\n",
      "\titers: 200, epoch: 13 | loss: 0.0540248\n",
      "\tspeed: 0.0228s/iter; left time: 443.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0521770 Vali Loss: 0.0591646 Test Loss: 0.0623447\n",
      "Validation loss decreased (0.059773 --> 0.059165).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0499439\n",
      "\tspeed: 0.0391s/iter; left time: 755.1222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0532585\n",
      "\tspeed: 0.0186s/iter; left time: 357.4412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0519601 Vali Loss: 0.0590841 Test Loss: 0.0623380\n",
      "Validation loss decreased (0.059165 --> 0.059084).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0540655\n",
      "\tspeed: 0.0404s/iter; left time: 771.5194s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485856\n",
      "\tspeed: 0.0175s/iter; left time: 331.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0519877 Vali Loss: 0.0587647 Test Loss: 0.0620551\n",
      "Validation loss decreased (0.059084 --> 0.058765).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0538359\n",
      "\tspeed: 0.0409s/iter; left time: 771.6544s\n",
      "\titers: 200, epoch: 16 | loss: 0.0534890\n",
      "\tspeed: 0.0223s/iter; left time: 418.9436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0511243 Vali Loss: 0.0587070 Test Loss: 0.0619348\n",
      "Validation loss decreased (0.058765 --> 0.058707).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0491434\n",
      "\tspeed: 0.0434s/iter; left time: 808.6783s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528754\n",
      "\tspeed: 0.0216s/iter; left time: 399.4806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0509761 Vali Loss: 0.0584687 Test Loss: 0.0615832\n",
      "Validation loss decreased (0.058707 --> 0.058469).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0493292\n",
      "\tspeed: 0.0386s/iter; left time: 711.0252s\n",
      "\titers: 200, epoch: 18 | loss: 0.0531685\n",
      "\tspeed: 0.0220s/iter; left time: 403.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0506763 Vali Loss: 0.0582606 Test Loss: 0.0614566\n",
      "Validation loss decreased (0.058469 --> 0.058261).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529053\n",
      "\tspeed: 0.0366s/iter; left time: 665.7816s\n",
      "\titers: 200, epoch: 19 | loss: 0.0497256\n",
      "\tspeed: 0.0177s/iter; left time: 319.7808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0505410 Vali Loss: 0.0581122 Test Loss: 0.0612906\n",
      "Validation loss decreased (0.058261 --> 0.058112).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0491694\n",
      "\tspeed: 0.0390s/iter; left time: 700.2603s\n",
      "\titers: 200, epoch: 20 | loss: 0.0501596\n",
      "\tspeed: 0.0169s/iter; left time: 302.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0503292 Vali Loss: 0.0583369 Test Loss: 0.0614038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0508207\n",
      "\tspeed: 0.0402s/iter; left time: 713.0908s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540633\n",
      "\tspeed: 0.0191s/iter; left time: 336.6472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0503592 Vali Loss: 0.0581978 Test Loss: 0.0612768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0496555\n",
      "\tspeed: 0.0397s/iter; left time: 696.1983s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534243\n",
      "\tspeed: 0.0217s/iter; left time: 377.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0501330 Vali Loss: 0.0578809 Test Loss: 0.0610519\n",
      "Validation loss decreased (0.058112 --> 0.057881).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0517100\n",
      "\tspeed: 0.0405s/iter; left time: 700.6019s\n",
      "\titers: 200, epoch: 23 | loss: 0.0478579\n",
      "\tspeed: 0.0186s/iter; left time: 319.4957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0498769 Vali Loss: 0.0577833 Test Loss: 0.0608692\n",
      "Validation loss decreased (0.057881 --> 0.057783).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0490868\n",
      "\tspeed: 0.0403s/iter; left time: 687.7352s\n",
      "\titers: 200, epoch: 24 | loss: 0.0514370\n",
      "\tspeed: 0.0202s/iter; left time: 342.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0498474 Vali Loss: 0.0577935 Test Loss: 0.0607914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0492130\n",
      "\tspeed: 0.0394s/iter; left time: 663.5559s\n",
      "\titers: 200, epoch: 25 | loss: 0.0489792\n",
      "\tspeed: 0.0167s/iter; left time: 280.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0497373 Vali Loss: 0.0577882 Test Loss: 0.0609075\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0515442\n",
      "\tspeed: 0.0354s/iter; left time: 588.3156s\n",
      "\titers: 200, epoch: 26 | loss: 0.0489699\n",
      "\tspeed: 0.0194s/iter; left time: 319.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0495722 Vali Loss: 0.0576558 Test Loss: 0.0608152\n",
      "Validation loss decreased (0.057783 --> 0.057656).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0485971\n",
      "\tspeed: 0.0412s/iter; left time: 675.1647s\n",
      "\titers: 200, epoch: 27 | loss: 0.0478701\n",
      "\tspeed: 0.0203s/iter; left time: 330.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0496339 Vali Loss: 0.0575417 Test Loss: 0.0606223\n",
      "Validation loss decreased (0.057656 --> 0.057542).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0498576\n",
      "\tspeed: 0.0383s/iter; left time: 620.1941s\n",
      "\titers: 200, epoch: 28 | loss: 0.0529318\n",
      "\tspeed: 0.0135s/iter; left time: 216.9227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0496269 Vali Loss: 0.0576183 Test Loss: 0.0606592\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0478204\n",
      "\tspeed: 0.0383s/iter; left time: 611.5140s\n",
      "\titers: 200, epoch: 29 | loss: 0.0485484\n",
      "\tspeed: 0.0163s/iter; left time: 259.2135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0493664 Vali Loss: 0.0574383 Test Loss: 0.0606688\n",
      "Validation loss decreased (0.057542 --> 0.057438).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0482211\n",
      "\tspeed: 0.0355s/iter; left time: 559.0726s\n",
      "\titers: 200, epoch: 30 | loss: 0.0488848\n",
      "\tspeed: 0.0174s/iter; left time: 271.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0492981 Vali Loss: 0.0575676 Test Loss: 0.0606407\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0501512\n",
      "\tspeed: 0.0330s/iter; left time: 511.6411s\n",
      "\titers: 200, epoch: 31 | loss: 0.0510716\n",
      "\tspeed: 0.0133s/iter; left time: 204.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0492856 Vali Loss: 0.0574316 Test Loss: 0.0604549\n",
      "Validation loss decreased (0.057438 --> 0.057432).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0489707\n",
      "\tspeed: 0.0425s/iter; left time: 649.1731s\n",
      "\titers: 200, epoch: 32 | loss: 0.0501955\n",
      "\tspeed: 0.0227s/iter; left time: 344.9957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0492434 Vali Loss: 0.0574214 Test Loss: 0.0604621\n",
      "Validation loss decreased (0.057432 --> 0.057421).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0473494\n",
      "\tspeed: 0.0406s/iter; left time: 611.3908s\n",
      "\titers: 200, epoch: 33 | loss: 0.0471059\n",
      "\tspeed: 0.0223s/iter; left time: 334.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0491912 Vali Loss: 0.0573679 Test Loss: 0.0604532\n",
      "Validation loss decreased (0.057421 --> 0.057368).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0467992\n",
      "\tspeed: 0.0420s/iter; left time: 622.9819s\n",
      "\titers: 200, epoch: 34 | loss: 0.0492968\n",
      "\tspeed: 0.0203s/iter; left time: 299.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0491803 Vali Loss: 0.0574905 Test Loss: 0.0606405\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0470877\n",
      "\tspeed: 0.0326s/iter; left time: 476.0594s\n",
      "\titers: 200, epoch: 35 | loss: 0.0462380\n",
      "\tspeed: 0.0132s/iter; left time: 191.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 223 | Train Loss: 0.0490107 Vali Loss: 0.0572901 Test Loss: 0.0603345\n",
      "Validation loss decreased (0.057368 --> 0.057290).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0478835\n",
      "\tspeed: 0.0404s/iter; left time: 582.1686s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486398\n",
      "\tspeed: 0.0218s/iter; left time: 312.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0490944 Vali Loss: 0.0572910 Test Loss: 0.0603712\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0479557\n",
      "\tspeed: 0.0320s/iter; left time: 453.3934s\n",
      "\titers: 200, epoch: 37 | loss: 0.0489345\n",
      "\tspeed: 0.0158s/iter; left time: 222.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0494170 Vali Loss: 0.0573440 Test Loss: 0.0604316\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0481758\n",
      "\tspeed: 0.0379s/iter; left time: 528.1994s\n",
      "\titers: 200, epoch: 38 | loss: 0.0517889\n",
      "\tspeed: 0.0188s/iter; left time: 259.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0490630 Vali Loss: 0.0571826 Test Loss: 0.0602354\n",
      "Validation loss decreased (0.057290 --> 0.057183).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0457301\n",
      "\tspeed: 0.0393s/iter; left time: 539.9282s\n",
      "\titers: 200, epoch: 39 | loss: 0.0485481\n",
      "\tspeed: 0.0162s/iter; left time: 220.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0490053 Vali Loss: 0.0572403 Test Loss: 0.0602771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0452573\n",
      "\tspeed: 0.0386s/iter; left time: 521.8253s\n",
      "\titers: 200, epoch: 40 | loss: 0.0494364\n",
      "\tspeed: 0.0175s/iter; left time: 234.2338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0489563 Vali Loss: 0.0571800 Test Loss: 0.0602402\n",
      "Validation loss decreased (0.057183 --> 0.057180).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0506086\n",
      "\tspeed: 0.0414s/iter; left time: 549.7969s\n",
      "\titers: 200, epoch: 41 | loss: 0.0454930\n",
      "\tspeed: 0.0199s/iter; left time: 262.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0488437 Vali Loss: 0.0572296 Test Loss: 0.0602630\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0481241\n",
      "\tspeed: 0.0401s/iter; left time: 523.1273s\n",
      "\titers: 200, epoch: 42 | loss: 0.0481783\n",
      "\tspeed: 0.0220s/iter; left time: 285.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 223 | Train Loss: 0.0489059 Vali Loss: 0.0572003 Test Loss: 0.0603421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0502890\n",
      "\tspeed: 0.0368s/iter; left time: 472.4956s\n",
      "\titers: 200, epoch: 43 | loss: 0.0449523\n",
      "\tspeed: 0.0175s/iter; left time: 222.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0488338 Vali Loss: 0.0572221 Test Loss: 0.0603067\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0488996\n",
      "\tspeed: 0.0372s/iter; left time: 469.0572s\n",
      "\titers: 200, epoch: 44 | loss: 0.0504843\n",
      "\tspeed: 0.0171s/iter; left time: 214.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0487729 Vali Loss: 0.0572168 Test Loss: 0.0602941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495345\n",
      "\tspeed: 0.0354s/iter; left time: 438.4071s\n",
      "\titers: 200, epoch: 45 | loss: 0.0511081\n",
      "\tspeed: 0.0168s/iter; left time: 206.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0488409 Vali Loss: 0.0571053 Test Loss: 0.0602380\n",
      "Validation loss decreased (0.057180 --> 0.057105).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0453051\n",
      "\tspeed: 0.0401s/iter; left time: 488.3285s\n",
      "\titers: 200, epoch: 46 | loss: 0.0496866\n",
      "\tspeed: 0.0197s/iter; left time: 237.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0488729 Vali Loss: 0.0572508 Test Loss: 0.0603855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0495115\n",
      "\tspeed: 0.0345s/iter; left time: 412.4130s\n",
      "\titers: 200, epoch: 47 | loss: 0.0513710\n",
      "\tspeed: 0.0133s/iter; left time: 158.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 223 | Train Loss: 0.0488442 Vali Loss: 0.0572697 Test Loss: 0.0603364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0499629\n",
      "\tspeed: 0.0391s/iter; left time: 458.7878s\n",
      "\titers: 200, epoch: 48 | loss: 0.0474884\n",
      "\tspeed: 0.0162s/iter; left time: 188.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0487454 Vali Loss: 0.0571224 Test Loss: 0.0602089\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0489947\n",
      "\tspeed: 0.0407s/iter; left time: 468.4589s\n",
      "\titers: 200, epoch: 49 | loss: 0.0513139\n",
      "\tspeed: 0.0231s/iter; left time: 263.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0488029 Vali Loss: 0.0571705 Test Loss: 0.0603408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0507773\n",
      "\tspeed: 0.0360s/iter; left time: 405.3312s\n",
      "\titers: 200, epoch: 50 | loss: 0.0517840\n",
      "\tspeed: 0.0166s/iter; left time: 185.5194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0488013 Vali Loss: 0.0572326 Test Loss: 0.0603317\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0470517\n",
      "\tspeed: 0.0367s/iter; left time: 405.8647s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508473\n",
      "\tspeed: 0.0211s/iter; left time: 230.8526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0487815 Vali Loss: 0.0571189 Test Loss: 0.0601991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0451237\n",
      "\tspeed: 0.0412s/iter; left time: 445.6630s\n",
      "\titers: 200, epoch: 52 | loss: 0.0477586\n",
      "\tspeed: 0.0191s/iter; left time: 205.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0487631 Vali Loss: 0.0572382 Test Loss: 0.0602812\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0480561\n",
      "\tspeed: 0.0415s/iter; left time: 439.9830s\n",
      "\titers: 200, epoch: 53 | loss: 0.0501801\n",
      "\tspeed: 0.0196s/iter; left time: 206.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0487478 Vali Loss: 0.0572642 Test Loss: 0.0604258\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0486216\n",
      "\tspeed: 0.0376s/iter; left time: 390.2099s\n",
      "\titers: 200, epoch: 54 | loss: 0.0515684\n",
      "\tspeed: 0.0211s/iter; left time: 216.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0488013 Vali Loss: 0.0572423 Test Loss: 0.0603036\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0485251\n",
      "\tspeed: 0.0380s/iter; left time: 386.1030s\n",
      "\titers: 200, epoch: 55 | loss: 0.0512241\n",
      "\tspeed: 0.0165s/iter; left time: 166.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0488301 Vali Loss: 0.0571032 Test Loss: 0.0602363\n",
      "Validation loss decreased (0.057105 --> 0.057103).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0494372\n",
      "\tspeed: 0.0394s/iter; left time: 391.4965s\n",
      "\titers: 200, epoch: 56 | loss: 0.0508592\n",
      "\tspeed: 0.0169s/iter; left time: 166.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0486512 Vali Loss: 0.0571337 Test Loss: 0.0602054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0483012\n",
      "\tspeed: 0.0404s/iter; left time: 392.0062s\n",
      "\titers: 200, epoch: 57 | loss: 0.0453609\n",
      "\tspeed: 0.0197s/iter; left time: 189.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0487472 Vali Loss: 0.0571260 Test Loss: 0.0602106\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0497502\n",
      "\tspeed: 0.0369s/iter; left time: 350.3826s\n",
      "\titers: 200, epoch: 58 | loss: 0.0494744\n",
      "\tspeed: 0.0212s/iter; left time: 199.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0487636 Vali Loss: 0.0570820 Test Loss: 0.0601979\n",
      "Validation loss decreased (0.057103 --> 0.057082).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0504931\n",
      "\tspeed: 0.0442s/iter; left time: 410.0105s\n",
      "\titers: 200, epoch: 59 | loss: 0.0460840\n",
      "\tspeed: 0.0183s/iter; left time: 168.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0486617 Vali Loss: 0.0570963 Test Loss: 0.0601800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0481434\n",
      "\tspeed: 0.0364s/iter; left time: 329.5593s\n",
      "\titers: 200, epoch: 60 | loss: 0.0457142\n",
      "\tspeed: 0.0179s/iter; left time: 160.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0487357 Vali Loss: 0.0570586 Test Loss: 0.0601705\n",
      "Validation loss decreased (0.057082 --> 0.057059).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0501712\n",
      "\tspeed: 0.0383s/iter; left time: 338.2543s\n",
      "\titers: 200, epoch: 61 | loss: 0.0504330\n",
      "\tspeed: 0.0189s/iter; left time: 164.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0487754 Vali Loss: 0.0570667 Test Loss: 0.0601745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0477528\n",
      "\tspeed: 0.0357s/iter; left time: 307.0233s\n",
      "\titers: 200, epoch: 62 | loss: 0.0490151\n",
      "\tspeed: 0.0177s/iter; left time: 150.0724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 223 | Train Loss: 0.0486548 Vali Loss: 0.0571455 Test Loss: 0.0601858\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0484906\n",
      "\tspeed: 0.0360s/iter; left time: 301.2623s\n",
      "\titers: 200, epoch: 63 | loss: 0.0544502\n",
      "\tspeed: 0.0172s/iter; left time: 142.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0486868 Vali Loss: 0.0573017 Test Loss: 0.0603552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0492642\n",
      "\tspeed: 0.0356s/iter; left time: 289.9639s\n",
      "\titers: 200, epoch: 64 | loss: 0.0498345\n",
      "\tspeed: 0.0168s/iter; left time: 135.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 223 | Train Loss: 0.0486830 Vali Loss: 0.0572332 Test Loss: 0.0603793\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0486930\n",
      "\tspeed: 0.0363s/iter; left time: 287.6460s\n",
      "\titers: 200, epoch: 65 | loss: 0.0488619\n",
      "\tspeed: 0.0167s/iter; left time: 130.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0487089 Vali Loss: 0.0571097 Test Loss: 0.0601833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0490691\n",
      "\tspeed: 0.0327s/iter; left time: 252.0923s\n",
      "\titers: 200, epoch: 66 | loss: 0.0487439\n",
      "\tspeed: 0.0132s/iter; left time: 100.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 223 | Train Loss: 0.0487926 Vali Loss: 0.0570433 Test Loss: 0.0602130\n",
      "Validation loss decreased (0.057059 --> 0.057043).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0451786\n",
      "\tspeed: 0.0355s/iter; left time: 265.5990s\n",
      "\titers: 200, epoch: 67 | loss: 0.0475316\n",
      "\tspeed: 0.0177s/iter; left time: 131.0283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0486549 Vali Loss: 0.0571768 Test Loss: 0.0602184\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0495597\n",
      "\tspeed: 0.0387s/iter; left time: 281.1195s\n",
      "\titers: 200, epoch: 68 | loss: 0.0467642\n",
      "\tspeed: 0.0223s/iter; left time: 159.4368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0487434 Vali Loss: 0.0572413 Test Loss: 0.0603635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0515573\n",
      "\tspeed: 0.0401s/iter; left time: 282.3558s\n",
      "\titers: 200, epoch: 69 | loss: 0.0472452\n",
      "\tspeed: 0.0177s/iter; left time: 122.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0486674 Vali Loss: 0.0571629 Test Loss: 0.0602624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0483436\n",
      "\tspeed: 0.0364s/iter; left time: 247.7162s\n",
      "\titers: 200, epoch: 70 | loss: 0.0492028\n",
      "\tspeed: 0.0203s/iter; left time: 136.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0488501 Vali Loss: 0.0573268 Test Loss: 0.0605140\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0507724\n",
      "\tspeed: 0.0401s/iter; left time: 264.0203s\n",
      "\titers: 200, epoch: 71 | loss: 0.0470218\n",
      "\tspeed: 0.0196s/iter; left time: 127.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0487067 Vali Loss: 0.0570265 Test Loss: 0.0601782\n",
      "Validation loss decreased (0.057043 --> 0.057027).  Saving model ...\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0502248\n",
      "\tspeed: 0.0388s/iter; left time: 246.8570s\n",
      "\titers: 200, epoch: 72 | loss: 0.0469751\n",
      "\tspeed: 0.0169s/iter; left time: 105.9874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0486459 Vali Loss: 0.0572870 Test Loss: 0.0604110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0506107\n",
      "\tspeed: 0.0350s/iter; left time: 214.9730s\n",
      "\titers: 200, epoch: 73 | loss: 0.0467111\n",
      "\tspeed: 0.0168s/iter; left time: 101.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0486245 Vali Loss: 0.0572505 Test Loss: 0.0603751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0534502\n",
      "\tspeed: 0.0356s/iter; left time: 210.6806s\n",
      "\titers: 200, epoch: 74 | loss: 0.0468832\n",
      "\tspeed: 0.0179s/iter; left time: 103.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0487680 Vali Loss: 0.0571395 Test Loss: 0.0602298\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0481216\n",
      "\tspeed: 0.0397s/iter; left time: 226.0582s\n",
      "\titers: 200, epoch: 75 | loss: 0.0474309\n",
      "\tspeed: 0.0193s/iter; left time: 107.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0486899 Vali Loss: 0.0570863 Test Loss: 0.0601322\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0505250\n",
      "\tspeed: 0.0396s/iter; left time: 217.1056s\n",
      "\titers: 200, epoch: 76 | loss: 0.0499156\n",
      "\tspeed: 0.0179s/iter; left time: 96.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0486352 Vali Loss: 0.0572839 Test Loss: 0.0603514\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0492026\n",
      "\tspeed: 0.0377s/iter; left time: 197.7787s\n",
      "\titers: 200, epoch: 77 | loss: 0.0488617\n",
      "\tspeed: 0.0180s/iter; left time: 92.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0485993 Vali Loss: 0.0571223 Test Loss: 0.0602114\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0487652\n",
      "\tspeed: 0.0381s/iter; left time: 191.7652s\n",
      "\titers: 200, epoch: 78 | loss: 0.0463388\n",
      "\tspeed: 0.0177s/iter; left time: 87.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0486306 Vali Loss: 0.0570852 Test Loss: 0.0602179\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0522110\n",
      "\tspeed: 0.0368s/iter; left time: 176.8127s\n",
      "\titers: 200, epoch: 79 | loss: 0.0446301\n",
      "\tspeed: 0.0177s/iter; left time: 83.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0488554 Vali Loss: 0.0570858 Test Loss: 0.0601446\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0448830\n",
      "\tspeed: 0.0364s/iter; left time: 167.0854s\n",
      "\titers: 200, epoch: 80 | loss: 0.0470769\n",
      "\tspeed: 0.0177s/iter; left time: 79.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0488327 Vali Loss: 0.0570648 Test Loss: 0.0601736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0455667\n",
      "\tspeed: 0.0379s/iter; left time: 165.3501s\n",
      "\titers: 200, epoch: 81 | loss: 0.0504325\n",
      "\tspeed: 0.0180s/iter; left time: 76.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0487624 Vali Loss: 0.0571202 Test Loss: 0.0602019\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010859417729079723, rmse:0.10420852899551392, mae:0.060178253799676895, rse:0.40203362703323364\n",
      "Intermediate time for FR and pred_len 24: 00h:12m:58.31s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2267028\n",
      "\tspeed: 0.0417s/iter; left time: 922.4209s\n",
      "\titers: 200, epoch: 1 | loss: 0.2135511\n",
      "\tspeed: 0.0135s/iter; left time: 296.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 222 | Train Loss: 0.2315591 Vali Loss: 0.1772272 Test Loss: 0.1834331\n",
      "Validation loss decreased (inf --> 0.177227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1293374\n",
      "\tspeed: 0.0320s/iter; left time: 700.3806s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015767\n",
      "\tspeed: 0.0135s/iter; left time: 294.3323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 222 | Train Loss: 0.1325314 Vali Loss: 0.0982890 Test Loss: 0.1072068\n",
      "Validation loss decreased (0.177227 --> 0.098289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0885466\n",
      "\tspeed: 0.0351s/iter; left time: 759.6892s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841450\n",
      "\tspeed: 0.0165s/iter; left time: 356.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0886659 Vali Loss: 0.0863668 Test Loss: 0.0925269\n",
      "Validation loss decreased (0.098289 --> 0.086367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0789470\n",
      "\tspeed: 0.0405s/iter; left time: 868.5872s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768474\n",
      "\tspeed: 0.0186s/iter; left time: 396.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0797773 Vali Loss: 0.0806557 Test Loss: 0.0911315\n",
      "Validation loss decreased (0.086367 --> 0.080656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693649\n",
      "\tspeed: 0.0399s/iter; left time: 845.3756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715431\n",
      "\tspeed: 0.0172s/iter; left time: 362.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0750615 Vali Loss: 0.0792125 Test Loss: 0.0885798\n",
      "Validation loss decreased (0.080656 --> 0.079212).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0718599\n",
      "\tspeed: 0.0356s/iter; left time: 747.1721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0684765\n",
      "\tspeed: 0.0170s/iter; left time: 355.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0718348 Vali Loss: 0.0776187 Test Loss: 0.0871840\n",
      "Validation loss decreased (0.079212 --> 0.077619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0692197\n",
      "\tspeed: 0.0406s/iter; left time: 844.2173s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668686\n",
      "\tspeed: 0.0138s/iter; left time: 284.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0699637 Vali Loss: 0.0770199 Test Loss: 0.0862746\n",
      "Validation loss decreased (0.077619 --> 0.077020).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694030\n",
      "\tspeed: 0.0361s/iter; left time: 742.2978s\n",
      "\titers: 200, epoch: 8 | loss: 0.0709295\n",
      "\tspeed: 0.0179s/iter; left time: 365.0858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0685380 Vali Loss: 0.0765425 Test Loss: 0.0860829\n",
      "Validation loss decreased (0.077020 --> 0.076542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0635232\n",
      "\tspeed: 0.0375s/iter; left time: 761.5104s\n",
      "\titers: 200, epoch: 9 | loss: 0.0662752\n",
      "\tspeed: 0.0176s/iter; left time: 355.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0676675 Vali Loss: 0.0762699 Test Loss: 0.0866981\n",
      "Validation loss decreased (0.076542 --> 0.076270).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0636201\n",
      "\tspeed: 0.0409s/iter; left time: 822.3644s\n",
      "\titers: 200, epoch: 10 | loss: 0.0709490\n",
      "\tspeed: 0.0175s/iter; left time: 349.5634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0667456 Vali Loss: 0.0757279 Test Loss: 0.0858754\n",
      "Validation loss decreased (0.076270 --> 0.075728).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0693292\n",
      "\tspeed: 0.0352s/iter; left time: 700.5433s\n",
      "\titers: 200, epoch: 11 | loss: 0.0601297\n",
      "\tspeed: 0.0170s/iter; left time: 336.3282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.0662411 Vali Loss: 0.0755199 Test Loss: 0.0858755\n",
      "Validation loss decreased (0.075728 --> 0.075520).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652160\n",
      "\tspeed: 0.0395s/iter; left time: 776.9844s\n",
      "\titers: 200, epoch: 12 | loss: 0.0678964\n",
      "\tspeed: 0.0149s/iter; left time: 290.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0655011 Vali Loss: 0.0760923 Test Loss: 0.0862923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0631842\n",
      "\tspeed: 0.0332s/iter; left time: 644.7398s\n",
      "\titers: 200, epoch: 13 | loss: 0.0668576\n",
      "\tspeed: 0.0165s/iter; left time: 318.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0651463 Vali Loss: 0.0749479 Test Loss: 0.0854728\n",
      "Validation loss decreased (0.075520 --> 0.074948).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689360\n",
      "\tspeed: 0.0387s/iter; left time: 743.7471s\n",
      "\titers: 200, epoch: 14 | loss: 0.0660432\n",
      "\tspeed: 0.0166s/iter; left time: 318.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0648640 Vali Loss: 0.0749733 Test Loss: 0.0859138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0653437\n",
      "\tspeed: 0.0401s/iter; left time: 761.5391s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631717\n",
      "\tspeed: 0.0197s/iter; left time: 372.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0646244 Vali Loss: 0.0749632 Test Loss: 0.0851869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618654\n",
      "\tspeed: 0.0394s/iter; left time: 739.8270s\n",
      "\titers: 200, epoch: 16 | loss: 0.0620756\n",
      "\tspeed: 0.0185s/iter; left time: 346.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0646136 Vali Loss: 0.0756751 Test Loss: 0.0865352\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0663635\n",
      "\tspeed: 0.0371s/iter; left time: 687.4661s\n",
      "\titers: 200, epoch: 17 | loss: 0.0649047\n",
      "\tspeed: 0.0181s/iter; left time: 333.7758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0643330 Vali Loss: 0.0746861 Test Loss: 0.0858784\n",
      "Validation loss decreased (0.074948 --> 0.074686).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631827\n",
      "\tspeed: 0.0353s/iter; left time: 647.4246s\n",
      "\titers: 200, epoch: 18 | loss: 0.0645057\n",
      "\tspeed: 0.0138s/iter; left time: 251.4712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 222 | Train Loss: 0.0638526 Vali Loss: 0.0742696 Test Loss: 0.0852134\n",
      "Validation loss decreased (0.074686 --> 0.074270).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0634702\n",
      "\tspeed: 0.0329s/iter; left time: 595.8415s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629722\n",
      "\tspeed: 0.0185s/iter; left time: 332.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0638927 Vali Loss: 0.0740166 Test Loss: 0.0853843\n",
      "Validation loss decreased (0.074270 --> 0.074017).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0611127\n",
      "\tspeed: 0.0395s/iter; left time: 706.2985s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653505\n",
      "\tspeed: 0.0151s/iter; left time: 268.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0636053 Vali Loss: 0.0738598 Test Loss: 0.0853267\n",
      "Validation loss decreased (0.074017 --> 0.073860).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0635018\n",
      "\tspeed: 0.0396s/iter; left time: 698.9827s\n",
      "\titers: 200, epoch: 21 | loss: 0.0593666\n",
      "\tspeed: 0.0183s/iter; left time: 321.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0635133 Vali Loss: 0.0739690 Test Loss: 0.0851553\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0633398\n",
      "\tspeed: 0.0341s/iter; left time: 595.5009s\n",
      "\titers: 200, epoch: 22 | loss: 0.0615648\n",
      "\tspeed: 0.0135s/iter; left time: 234.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 222 | Train Loss: 0.0632623 Vali Loss: 0.0739025 Test Loss: 0.0853512\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0616216\n",
      "\tspeed: 0.0353s/iter; left time: 608.6190s\n",
      "\titers: 200, epoch: 23 | loss: 0.0620393\n",
      "\tspeed: 0.0180s/iter; left time: 308.0214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0632685 Vali Loss: 0.0740019 Test Loss: 0.0856074\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0627577\n",
      "\tspeed: 0.0352s/iter; left time: 597.8473s\n",
      "\titers: 200, epoch: 24 | loss: 0.0652485\n",
      "\tspeed: 0.0165s/iter; left time: 279.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0630291 Vali Loss: 0.0738503 Test Loss: 0.0852864\n",
      "Validation loss decreased (0.073860 --> 0.073850).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0653873\n",
      "\tspeed: 0.0359s/iter; left time: 601.5023s\n",
      "\titers: 200, epoch: 25 | loss: 0.0658269\n",
      "\tspeed: 0.0182s/iter; left time: 302.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0630961 Vali Loss: 0.0737145 Test Loss: 0.0851739\n",
      "Validation loss decreased (0.073850 --> 0.073715).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0612837\n",
      "\tspeed: 0.0402s/iter; left time: 665.1029s\n",
      "\titers: 200, epoch: 26 | loss: 0.0609538\n",
      "\tspeed: 0.0210s/iter; left time: 345.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.0629769 Vali Loss: 0.0736573 Test Loss: 0.0851916\n",
      "Validation loss decreased (0.073715 --> 0.073657).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0634126\n",
      "\tspeed: 0.0380s/iter; left time: 620.6054s\n",
      "\titers: 200, epoch: 27 | loss: 0.0625662\n",
      "\tspeed: 0.0174s/iter; left time: 282.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0627763 Vali Loss: 0.0736640 Test Loss: 0.0852929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0636804\n",
      "\tspeed: 0.0388s/iter; left time: 624.2987s\n",
      "\titers: 200, epoch: 28 | loss: 0.0618400\n",
      "\tspeed: 0.0189s/iter; left time: 303.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0627862 Vali Loss: 0.0736277 Test Loss: 0.0852906\n",
      "Validation loss decreased (0.073657 --> 0.073628).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602461\n",
      "\tspeed: 0.0359s/iter; left time: 570.7147s\n",
      "\titers: 200, epoch: 29 | loss: 0.0611843\n",
      "\tspeed: 0.0185s/iter; left time: 291.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0626138 Vali Loss: 0.0737159 Test Loss: 0.0853415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0649850\n",
      "\tspeed: 0.0395s/iter; left time: 619.4693s\n",
      "\titers: 200, epoch: 30 | loss: 0.0591837\n",
      "\tspeed: 0.0176s/iter; left time: 273.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 222 | Train Loss: 0.0626210 Vali Loss: 0.0734907 Test Loss: 0.0852216\n",
      "Validation loss decreased (0.073628 --> 0.073491).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0608462\n",
      "\tspeed: 0.0375s/iter; left time: 578.8574s\n",
      "\titers: 200, epoch: 31 | loss: 0.0632942\n",
      "\tspeed: 0.0167s/iter; left time: 256.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0625991 Vali Loss: 0.0734548 Test Loss: 0.0850597\n",
      "Validation loss decreased (0.073491 --> 0.073455).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628746\n",
      "\tspeed: 0.0388s/iter; left time: 590.0808s\n",
      "\titers: 200, epoch: 32 | loss: 0.0601225\n",
      "\tspeed: 0.0183s/iter; left time: 277.3283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0624923 Vali Loss: 0.0735416 Test Loss: 0.0852687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0656446\n",
      "\tspeed: 0.0415s/iter; left time: 622.3641s\n",
      "\titers: 200, epoch: 33 | loss: 0.0621694\n",
      "\tspeed: 0.0193s/iter; left time: 287.6767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0626026 Vali Loss: 0.0734950 Test Loss: 0.0850879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0622397\n",
      "\tspeed: 0.0392s/iter; left time: 579.2816s\n",
      "\titers: 200, epoch: 34 | loss: 0.0640215\n",
      "\tspeed: 0.0172s/iter; left time: 252.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0625493 Vali Loss: 0.0734956 Test Loss: 0.0850923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0603158\n",
      "\tspeed: 0.0372s/iter; left time: 540.9042s\n",
      "\titers: 200, epoch: 35 | loss: 0.0613668\n",
      "\tspeed: 0.0175s/iter; left time: 253.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0624190 Vali Loss: 0.0734789 Test Loss: 0.0851558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618927\n",
      "\tspeed: 0.0359s/iter; left time: 514.2903s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608553\n",
      "\tspeed: 0.0177s/iter; left time: 251.8802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0623591 Vali Loss: 0.0735502 Test Loss: 0.0853786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669588\n",
      "\tspeed: 0.0358s/iter; left time: 504.7960s\n",
      "\titers: 200, epoch: 37 | loss: 0.0614287\n",
      "\tspeed: 0.0162s/iter; left time: 227.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0623217 Vali Loss: 0.0734225 Test Loss: 0.0852213\n",
      "Validation loss decreased (0.073455 --> 0.073422).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0647136\n",
      "\tspeed: 0.0341s/iter; left time: 472.8534s\n",
      "\titers: 200, epoch: 38 | loss: 0.0664441\n",
      "\tspeed: 0.0139s/iter; left time: 191.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 222 | Train Loss: 0.0623466 Vali Loss: 0.0734045 Test Loss: 0.0851296\n",
      "Validation loss decreased (0.073422 --> 0.073404).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0553426\n",
      "\tspeed: 0.0335s/iter; left time: 457.0952s\n",
      "\titers: 200, epoch: 39 | loss: 0.0591905\n",
      "\tspeed: 0.0135s/iter; left time: 183.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 222 | Train Loss: 0.0623191 Vali Loss: 0.0734078 Test Loss: 0.0852216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0611381\n",
      "\tspeed: 0.0367s/iter; left time: 493.5619s\n",
      "\titers: 200, epoch: 40 | loss: 0.0612438\n",
      "\tspeed: 0.0184s/iter; left time: 245.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0622629 Vali Loss: 0.0734093 Test Loss: 0.0852055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0598230\n",
      "\tspeed: 0.0379s/iter; left time: 500.4870s\n",
      "\titers: 200, epoch: 41 | loss: 0.0645696\n",
      "\tspeed: 0.0180s/iter; left time: 235.6359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0622982 Vali Loss: 0.0733894 Test Loss: 0.0852577\n",
      "Validation loss decreased (0.073404 --> 0.073389).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0657890\n",
      "\tspeed: 0.0365s/iter; left time: 474.6315s\n",
      "\titers: 200, epoch: 42 | loss: 0.0596970\n",
      "\tspeed: 0.0174s/iter; left time: 225.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0622755 Vali Loss: 0.0733945 Test Loss: 0.0852331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0649050\n",
      "\tspeed: 0.0357s/iter; left time: 456.6033s\n",
      "\titers: 200, epoch: 43 | loss: 0.0636251\n",
      "\tspeed: 0.0168s/iter; left time: 212.5147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0622306 Vali Loss: 0.0734597 Test Loss: 0.0852875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0583642\n",
      "\tspeed: 0.0363s/iter; left time: 456.1310s\n",
      "\titers: 200, epoch: 44 | loss: 0.0639238\n",
      "\tspeed: 0.0222s/iter; left time: 276.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0622259 Vali Loss: 0.0733659 Test Loss: 0.0851065\n",
      "Validation loss decreased (0.073389 --> 0.073366).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659315\n",
      "\tspeed: 0.0395s/iter; left time: 487.5685s\n",
      "\titers: 200, epoch: 45 | loss: 0.0602623\n",
      "\tspeed: 0.0163s/iter; left time: 199.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0621681 Vali Loss: 0.0735022 Test Loss: 0.0853961\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0611856\n",
      "\tspeed: 0.0383s/iter; left time: 464.0052s\n",
      "\titers: 200, epoch: 46 | loss: 0.0662605\n",
      "\tspeed: 0.0199s/iter; left time: 238.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0622885 Vali Loss: 0.0733904 Test Loss: 0.0852588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0666935\n",
      "\tspeed: 0.0376s/iter; left time: 447.4779s\n",
      "\titers: 200, epoch: 47 | loss: 0.0618797\n",
      "\tspeed: 0.0165s/iter; left time: 194.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0622976 Vali Loss: 0.0733338 Test Loss: 0.0851604\n",
      "Validation loss decreased (0.073366 --> 0.073334).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0614597\n",
      "\tspeed: 0.0365s/iter; left time: 426.2309s\n",
      "\titers: 200, epoch: 48 | loss: 0.0589264\n",
      "\tspeed: 0.0173s/iter; left time: 199.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0621424 Vali Loss: 0.0733863 Test Loss: 0.0852267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0637451\n",
      "\tspeed: 0.0390s/iter; left time: 446.6157s\n",
      "\titers: 200, epoch: 49 | loss: 0.0613794\n",
      "\tspeed: 0.0210s/iter; left time: 237.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0623963 Vali Loss: 0.0733564 Test Loss: 0.0851370\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0618812\n",
      "\tspeed: 0.0395s/iter; left time: 443.8087s\n",
      "\titers: 200, epoch: 50 | loss: 0.0641346\n",
      "\tspeed: 0.0168s/iter; left time: 187.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0621585 Vali Loss: 0.0733848 Test Loss: 0.0852025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0649407\n",
      "\tspeed: 0.0396s/iter; left time: 435.9313s\n",
      "\titers: 200, epoch: 51 | loss: 0.0656235\n",
      "\tspeed: 0.0171s/iter; left time: 186.2044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0622085 Vali Loss: 0.0733106 Test Loss: 0.0850968\n",
      "Validation loss decreased (0.073334 --> 0.073311).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0622754\n",
      "\tspeed: 0.0384s/iter; left time: 413.6406s\n",
      "\titers: 200, epoch: 52 | loss: 0.0594684\n",
      "\tspeed: 0.0175s/iter; left time: 187.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0621938 Vali Loss: 0.0733696 Test Loss: 0.0852140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0596151\n",
      "\tspeed: 0.0360s/iter; left time: 380.3202s\n",
      "\titers: 200, epoch: 53 | loss: 0.0625431\n",
      "\tspeed: 0.0176s/iter; left time: 183.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0621405 Vali Loss: 0.0734119 Test Loss: 0.0853638\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0608095\n",
      "\tspeed: 0.0331s/iter; left time: 341.9466s\n",
      "\titers: 200, epoch: 54 | loss: 0.0644153\n",
      "\tspeed: 0.0176s/iter; left time: 180.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0621808 Vali Loss: 0.0734113 Test Loss: 0.0854056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0639046\n",
      "\tspeed: 0.0397s/iter; left time: 401.7065s\n",
      "\titers: 200, epoch: 55 | loss: 0.0600558\n",
      "\tspeed: 0.0193s/iter; left time: 192.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0622240 Vali Loss: 0.0733632 Test Loss: 0.0851608\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0624808\n",
      "\tspeed: 0.0405s/iter; left time: 400.6035s\n",
      "\titers: 200, epoch: 56 | loss: 0.0646345\n",
      "\tspeed: 0.0204s/iter; left time: 199.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0621265 Vali Loss: 0.0733335 Test Loss: 0.0851809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0647558\n",
      "\tspeed: 0.0379s/iter; left time: 366.6101s\n",
      "\titers: 200, epoch: 57 | loss: 0.0650051\n",
      "\tspeed: 0.0177s/iter; left time: 169.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0620756 Vali Loss: 0.0733596 Test Loss: 0.0852566\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0651121\n",
      "\tspeed: 0.0400s/iter; left time: 377.5911s\n",
      "\titers: 200, epoch: 58 | loss: 0.0641824\n",
      "\tspeed: 0.0199s/iter; left time: 186.1410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0622327 Vali Loss: 0.0733660 Test Loss: 0.0853010\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0620119\n",
      "\tspeed: 0.0403s/iter; left time: 371.4840s\n",
      "\titers: 200, epoch: 59 | loss: 0.0617636\n",
      "\tspeed: 0.0167s/iter; left time: 152.0153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0622559 Vali Loss: 0.0733840 Test Loss: 0.0851415\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0662671\n",
      "\tspeed: 0.0372s/iter; left time: 335.3183s\n",
      "\titers: 200, epoch: 60 | loss: 0.0604610\n",
      "\tspeed: 0.0170s/iter; left time: 151.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0621908 Vali Loss: 0.0733975 Test Loss: 0.0853025\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0641209\n",
      "\tspeed: 0.0368s/iter; left time: 323.5108s\n",
      "\titers: 200, epoch: 61 | loss: 0.0599672\n",
      "\tspeed: 0.0174s/iter; left time: 150.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0621525 Vali Loss: 0.0733382 Test Loss: 0.0851658\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02125689573585987, rmse:0.14579744637012482, mae:0.08509677648544312, rse:0.5639832615852356\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2332438\n",
      "\tspeed: 0.0199s/iter; left time: 440.3811s\n",
      "\titers: 200, epoch: 1 | loss: 0.2074515\n",
      "\tspeed: 0.0177s/iter; left time: 388.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.2327621 Vali Loss: 0.1756928 Test Loss: 0.1819052\n",
      "Validation loss decreased (inf --> 0.175693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349277\n",
      "\tspeed: 0.0392s/iter; left time: 857.3286s\n",
      "\titers: 200, epoch: 2 | loss: 0.0979945\n",
      "\tspeed: 0.0135s/iter; left time: 294.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.1311187 Vali Loss: 0.0962288 Test Loss: 0.1060121\n",
      "Validation loss decreased (0.175693 --> 0.096229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0915493\n",
      "\tspeed: 0.0368s/iter; left time: 795.9846s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815024\n",
      "\tspeed: 0.0165s/iter; left time: 356.7402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0894797 Vali Loss: 0.0865422 Test Loss: 0.0927320\n",
      "Validation loss decreased (0.096229 --> 0.086542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826185\n",
      "\tspeed: 0.0406s/iter; left time: 870.3460s\n",
      "\titers: 200, epoch: 4 | loss: 0.0810448\n",
      "\tspeed: 0.0186s/iter; left time: 396.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 222 | Train Loss: 0.0814201 Vali Loss: 0.0835992 Test Loss: 0.0907592\n",
      "Validation loss decreased (0.086542 --> 0.083599).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743177\n",
      "\tspeed: 0.0343s/iter; left time: 728.5336s\n",
      "\titers: 200, epoch: 5 | loss: 0.0726720\n",
      "\tspeed: 0.0189s/iter; left time: 399.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0762408 Vali Loss: 0.0798601 Test Loss: 0.0898876\n",
      "Validation loss decreased (0.083599 --> 0.079860).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752211\n",
      "\tspeed: 0.0405s/iter; left time: 851.1171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736725\n",
      "\tspeed: 0.0176s/iter; left time: 366.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 222 | Train Loss: 0.0731852 Vali Loss: 0.0781419 Test Loss: 0.0883034\n",
      "Validation loss decreased (0.079860 --> 0.078142).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0714475\n",
      "\tspeed: 0.0382s/iter; left time: 793.2193s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729196\n",
      "\tspeed: 0.0168s/iter; left time: 347.9197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0713721 Vali Loss: 0.0782305 Test Loss: 0.0877505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0675757\n",
      "\tspeed: 0.0374s/iter; left time: 767.6662s\n",
      "\titers: 200, epoch: 8 | loss: 0.0662482\n",
      "\tspeed: 0.0171s/iter; left time: 350.1056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0694094 Vali Loss: 0.0770246 Test Loss: 0.0862378\n",
      "Validation loss decreased (0.078142 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703986\n",
      "\tspeed: 0.0465s/iter; left time: 945.9029s\n",
      "\titers: 200, epoch: 9 | loss: 0.0644566\n",
      "\tspeed: 0.0200s/iter; left time: 404.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 222 | Train Loss: 0.0684228 Vali Loss: 0.0765546 Test Loss: 0.0865110\n",
      "Validation loss decreased (0.077025 --> 0.076555).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682109\n",
      "\tspeed: 0.0370s/iter; left time: 744.3733s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624587\n",
      "\tspeed: 0.0173s/iter; left time: 345.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0675123 Vali Loss: 0.0763682 Test Loss: 0.0864511\n",
      "Validation loss decreased (0.076555 --> 0.076368).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0663628\n",
      "\tspeed: 0.0397s/iter; left time: 788.3715s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664471\n",
      "\tspeed: 0.0183s/iter; left time: 361.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0666392 Vali Loss: 0.0760829 Test Loss: 0.0863217\n",
      "Validation loss decreased (0.076368 --> 0.076083).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0652992\n",
      "\tspeed: 0.0397s/iter; left time: 780.8240s\n",
      "\titers: 200, epoch: 12 | loss: 0.0664515\n",
      "\tspeed: 0.0179s/iter; left time: 350.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0662008 Vali Loss: 0.0757518 Test Loss: 0.0861047\n",
      "Validation loss decreased (0.076083 --> 0.075752).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0637105\n",
      "\tspeed: 0.0429s/iter; left time: 834.7254s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685193\n",
      "\tspeed: 0.0234s/iter; left time: 451.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 222 | Train Loss: 0.0658485 Vali Loss: 0.0758225 Test Loss: 0.0857897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0644000\n",
      "\tspeed: 0.0409s/iter; left time: 786.6470s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623599\n",
      "\tspeed: 0.0202s/iter; left time: 386.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0656384 Vali Loss: 0.0758276 Test Loss: 0.0857630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0653574\n",
      "\tspeed: 0.0387s/iter; left time: 735.9372s\n",
      "\titers: 200, epoch: 15 | loss: 0.0642808\n",
      "\tspeed: 0.0171s/iter; left time: 323.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0649617 Vali Loss: 0.0751267 Test Loss: 0.0854411\n",
      "Validation loss decreased (0.075752 --> 0.075127).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0654096\n",
      "\tspeed: 0.0368s/iter; left time: 690.9402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643842\n",
      "\tspeed: 0.0177s/iter; left time: 330.2056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0647303 Vali Loss: 0.0751002 Test Loss: 0.0856649\n",
      "Validation loss decreased (0.075127 --> 0.075100).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0651560\n",
      "\tspeed: 0.0442s/iter; left time: 820.1404s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624879\n",
      "\tspeed: 0.0195s/iter; left time: 360.6097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0644860 Vali Loss: 0.0749637 Test Loss: 0.0855752\n",
      "Validation loss decreased (0.075100 --> 0.074964).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599624\n",
      "\tspeed: 0.0394s/iter; left time: 721.7973s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675098\n",
      "\tspeed: 0.0142s/iter; left time: 258.0823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0643688 Vali Loss: 0.0749513 Test Loss: 0.0854600\n",
      "Validation loss decreased (0.074964 --> 0.074951).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0643213\n",
      "\tspeed: 0.0370s/iter; left time: 669.1750s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674118\n",
      "\tspeed: 0.0218s/iter; left time: 392.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0639345 Vali Loss: 0.0749305 Test Loss: 0.0855196\n",
      "Validation loss decreased (0.074951 --> 0.074930).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0615831\n",
      "\tspeed: 0.0430s/iter; left time: 769.6945s\n",
      "\titers: 200, epoch: 20 | loss: 0.0625134\n",
      "\tspeed: 0.0214s/iter; left time: 381.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0638769 Vali Loss: 0.0748858 Test Loss: 0.0855817\n",
      "Validation loss decreased (0.074930 --> 0.074886).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0644731\n",
      "\tspeed: 0.0429s/iter; left time: 758.3725s\n",
      "\titers: 200, epoch: 21 | loss: 0.0629087\n",
      "\tspeed: 0.0200s/iter; left time: 351.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0636836 Vali Loss: 0.0747631 Test Loss: 0.0854978\n",
      "Validation loss decreased (0.074886 --> 0.074763).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0624936\n",
      "\tspeed: 0.0366s/iter; left time: 638.8777s\n",
      "\titers: 200, epoch: 22 | loss: 0.0607735\n",
      "\tspeed: 0.0190s/iter; left time: 329.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 222 | Train Loss: 0.0635712 Vali Loss: 0.0746031 Test Loss: 0.0852415\n",
      "Validation loss decreased (0.074763 --> 0.074603).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619360\n",
      "\tspeed: 0.0341s/iter; left time: 587.7659s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600344\n",
      "\tspeed: 0.0135s/iter; left time: 231.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 222 | Train Loss: 0.0635085 Vali Loss: 0.0745777 Test Loss: 0.0854060\n",
      "Validation loss decreased (0.074603 --> 0.074578).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0659707\n",
      "\tspeed: 0.0395s/iter; left time: 671.9791s\n",
      "\titers: 200, epoch: 24 | loss: 0.0657066\n",
      "\tspeed: 0.0189s/iter; left time: 318.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0634187 Vali Loss: 0.0744710 Test Loss: 0.0851947\n",
      "Validation loss decreased (0.074578 --> 0.074471).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0624706\n",
      "\tspeed: 0.0415s/iter; left time: 695.9334s\n",
      "\titers: 200, epoch: 25 | loss: 0.0642952\n",
      "\tspeed: 0.0175s/iter; left time: 291.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0633469 Vali Loss: 0.0746358 Test Loss: 0.0852612\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0618325\n",
      "\tspeed: 0.0372s/iter; left time: 615.0351s\n",
      "\titers: 200, epoch: 26 | loss: 0.0655627\n",
      "\tspeed: 0.0174s/iter; left time: 286.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0632770 Vali Loss: 0.0744471 Test Loss: 0.0851457\n",
      "Validation loss decreased (0.074471 --> 0.074447).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0615555\n",
      "\tspeed: 0.0473s/iter; left time: 772.6164s\n",
      "\titers: 200, epoch: 27 | loss: 0.0622198\n",
      "\tspeed: 0.0176s/iter; left time: 285.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0631623 Vali Loss: 0.0745051 Test Loss: 0.0851635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0652423\n",
      "\tspeed: 0.0410s/iter; left time: 659.8562s\n",
      "\titers: 200, epoch: 28 | loss: 0.0600293\n",
      "\tspeed: 0.0180s/iter; left time: 288.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0632377 Vali Loss: 0.0745681 Test Loss: 0.0852453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616412\n",
      "\tspeed: 0.0412s/iter; left time: 654.6165s\n",
      "\titers: 200, epoch: 29 | loss: 0.0613882\n",
      "\tspeed: 0.0207s/iter; left time: 325.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0629997 Vali Loss: 0.0744263 Test Loss: 0.0852648\n",
      "Validation loss decreased (0.074447 --> 0.074426).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0631977\n",
      "\tspeed: 0.0389s/iter; left time: 609.7394s\n",
      "\titers: 200, epoch: 30 | loss: 0.0681532\n",
      "\tspeed: 0.0166s/iter; left time: 259.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0629121 Vali Loss: 0.0743438 Test Loss: 0.0851796\n",
      "Validation loss decreased (0.074426 --> 0.074344).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0653123\n",
      "\tspeed: 0.0385s/iter; left time: 593.8595s\n",
      "\titers: 200, epoch: 31 | loss: 0.0602726\n",
      "\tspeed: 0.0181s/iter; left time: 278.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0628694 Vali Loss: 0.0743088 Test Loss: 0.0852098\n",
      "Validation loss decreased (0.074344 --> 0.074309).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0678053\n",
      "\tspeed: 0.0356s/iter; left time: 541.8499s\n",
      "\titers: 200, epoch: 32 | loss: 0.0639176\n",
      "\tspeed: 0.0166s/iter; left time: 251.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0630652 Vali Loss: 0.0743524 Test Loss: 0.0851085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0634038\n",
      "\tspeed: 0.0362s/iter; left time: 542.6964s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641238\n",
      "\tspeed: 0.0194s/iter; left time: 288.5741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0628504 Vali Loss: 0.0743674 Test Loss: 0.0850242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647250\n",
      "\tspeed: 0.0335s/iter; left time: 494.5288s\n",
      "\titers: 200, epoch: 34 | loss: 0.0620727\n",
      "\tspeed: 0.0135s/iter; left time: 197.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 222 | Train Loss: 0.0628530 Vali Loss: 0.0741896 Test Loss: 0.0850130\n",
      "Validation loss decreased (0.074309 --> 0.074190).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0634183\n",
      "\tspeed: 0.0359s/iter; left time: 522.9358s\n",
      "\titers: 200, epoch: 35 | loss: 0.0658303\n",
      "\tspeed: 0.0185s/iter; left time: 267.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0628536 Vali Loss: 0.0743202 Test Loss: 0.0850280\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0640776\n",
      "\tspeed: 0.0381s/iter; left time: 545.8905s\n",
      "\titers: 200, epoch: 36 | loss: 0.0637809\n",
      "\tspeed: 0.0178s/iter; left time: 253.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0628852 Vali Loss: 0.0742466 Test Loss: 0.0850965\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0623443\n",
      "\tspeed: 0.0328s/iter; left time: 463.2639s\n",
      "\titers: 200, epoch: 37 | loss: 0.0674361\n",
      "\tspeed: 0.0135s/iter; left time: 189.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 222 | Train Loss: 0.0628581 Vali Loss: 0.0742130 Test Loss: 0.0851705\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0610113\n",
      "\tspeed: 0.0371s/iter; left time: 515.8857s\n",
      "\titers: 200, epoch: 38 | loss: 0.0588541\n",
      "\tspeed: 0.0163s/iter; left time: 224.1959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0626928 Vali Loss: 0.0741827 Test Loss: 0.0849982\n",
      "Validation loss decreased (0.074190 --> 0.074183).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0660007\n",
      "\tspeed: 0.0386s/iter; left time: 527.2035s\n",
      "\titers: 200, epoch: 39 | loss: 0.0616124\n",
      "\tspeed: 0.0166s/iter; left time: 225.3546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0627077 Vali Loss: 0.0742974 Test Loss: 0.0852043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0687570\n",
      "\tspeed: 0.0351s/iter; left time: 471.9618s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626596\n",
      "\tspeed: 0.0135s/iter; left time: 180.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 222 | Train Loss: 0.0625951 Vali Loss: 0.0741326 Test Loss: 0.0850432\n",
      "Validation loss decreased (0.074183 --> 0.074133).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0602702\n",
      "\tspeed: 0.0375s/iter; left time: 495.6519s\n",
      "\titers: 200, epoch: 41 | loss: 0.0637936\n",
      "\tspeed: 0.0177s/iter; left time: 232.6305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0626203 Vali Loss: 0.0743554 Test Loss: 0.0852369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0601737\n",
      "\tspeed: 0.0434s/iter; left time: 564.3443s\n",
      "\titers: 200, epoch: 42 | loss: 0.0635296\n",
      "\tspeed: 0.0223s/iter; left time: 287.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 222 | Train Loss: 0.0626016 Vali Loss: 0.0741598 Test Loss: 0.0851039\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0614529\n",
      "\tspeed: 0.0367s/iter; left time: 469.1288s\n",
      "\titers: 200, epoch: 43 | loss: 0.0606279\n",
      "\tspeed: 0.0179s/iter; left time: 227.1158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0626950 Vali Loss: 0.0741802 Test Loss: 0.0850562\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644844\n",
      "\tspeed: 0.0419s/iter; left time: 526.6778s\n",
      "\titers: 200, epoch: 44 | loss: 0.0623570\n",
      "\tspeed: 0.0215s/iter; left time: 267.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0626810 Vali Loss: 0.0744489 Test Loss: 0.0852235\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0620079\n",
      "\tspeed: 0.0367s/iter; left time: 452.6265s\n",
      "\titers: 200, epoch: 45 | loss: 0.0646244\n",
      "\tspeed: 0.0168s/iter; left time: 205.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0626365 Vali Loss: 0.0741991 Test Loss: 0.0851906\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0603739\n",
      "\tspeed: 0.0361s/iter; left time: 437.5830s\n",
      "\titers: 200, epoch: 46 | loss: 0.0606084\n",
      "\tspeed: 0.0164s/iter; left time: 197.1869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0625754 Vali Loss: 0.0741746 Test Loss: 0.0851851\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612067\n",
      "\tspeed: 0.0362s/iter; left time: 430.8839s\n",
      "\titers: 200, epoch: 47 | loss: 0.0609883\n",
      "\tspeed: 0.0164s/iter; left time: 193.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0624916 Vali Loss: 0.0741416 Test Loss: 0.0851222\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0546456\n",
      "\tspeed: 0.0377s/iter; left time: 440.3390s\n",
      "\titers: 200, epoch: 48 | loss: 0.0603762\n",
      "\tspeed: 0.0204s/iter; left time: 235.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0625896 Vali Loss: 0.0742560 Test Loss: 0.0853126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0633899\n",
      "\tspeed: 0.0429s/iter; left time: 491.5394s\n",
      "\titers: 200, epoch: 49 | loss: 0.0651736\n",
      "\tspeed: 0.0136s/iter; left time: 154.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0625229 Vali Loss: 0.0742220 Test Loss: 0.0850948\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0662610\n",
      "\tspeed: 0.0364s/iter; left time: 408.0605s\n",
      "\titers: 200, epoch: 50 | loss: 0.0648284\n",
      "\tspeed: 0.0175s/iter; left time: 194.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0626584 Vali Loss: 0.0741758 Test Loss: 0.0851906\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02106647379696369, rmse:0.14514294266700745, mae:0.08504320681095123, rse:0.5614514946937561\n",
      "Intermediate time for FR and pred_len 96: 00h:10m:29.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2234798\n",
      "\tspeed: 0.0432s/iter; left time: 954.1999s\n",
      "\titers: 200, epoch: 1 | loss: 0.2088102\n",
      "\tspeed: 0.0138s/iter; left time: 304.0025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 222 | Train Loss: 0.2334017 Vali Loss: 0.1776932 Test Loss: 0.1817676\n",
      "Validation loss decreased (inf --> 0.177693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1246364\n",
      "\tspeed: 0.0331s/iter; left time: 723.8803s\n",
      "\titers: 200, epoch: 2 | loss: 0.0962806\n",
      "\tspeed: 0.0156s/iter; left time: 340.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 222 | Train Loss: 0.1296026 Vali Loss: 0.0987888 Test Loss: 0.1084949\n",
      "Validation loss decreased (0.177693 --> 0.098789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926511\n",
      "\tspeed: 0.0361s/iter; left time: 781.3836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870639\n",
      "\tspeed: 0.0175s/iter; left time: 377.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0903701 Vali Loss: 0.0877677 Test Loss: 0.0957396\n",
      "Validation loss decreased (0.098789 --> 0.087768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827775\n",
      "\tspeed: 0.0377s/iter; left time: 807.9397s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805393\n",
      "\tspeed: 0.0175s/iter; left time: 373.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0822557 Vali Loss: 0.0853925 Test Loss: 0.0955968\n",
      "Validation loss decreased (0.087768 --> 0.085392).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0823312\n",
      "\tspeed: 0.0359s/iter; left time: 761.6284s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792515\n",
      "\tspeed: 0.0178s/iter; left time: 374.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0776787 Vali Loss: 0.0823942 Test Loss: 0.0915224\n",
      "Validation loss decreased (0.085392 --> 0.082394).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0736471\n",
      "\tspeed: 0.0397s/iter; left time: 833.6448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736030\n",
      "\tspeed: 0.0168s/iter; left time: 350.0604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 222 | Train Loss: 0.0745265 Vali Loss: 0.0818601 Test Loss: 0.0929426\n",
      "Validation loss decreased (0.082394 --> 0.081860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712174\n",
      "\tspeed: 0.0354s/iter; left time: 735.2654s\n",
      "\titers: 200, epoch: 7 | loss: 0.0709573\n",
      "\tspeed: 0.0181s/iter; left time: 374.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0726512 Vali Loss: 0.0807356 Test Loss: 0.0910757\n",
      "Validation loss decreased (0.081860 --> 0.080736).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0702406\n",
      "\tspeed: 0.0358s/iter; left time: 735.4574s\n",
      "\titers: 200, epoch: 8 | loss: 0.0717564\n",
      "\tspeed: 0.0169s/iter; left time: 345.3966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0716488 Vali Loss: 0.0805590 Test Loss: 0.0915492\n",
      "Validation loss decreased (0.080736 --> 0.080559).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704534\n",
      "\tspeed: 0.0327s/iter; left time: 665.5788s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725532\n",
      "\tspeed: 0.0136s/iter; left time: 274.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 222 | Train Loss: 0.0704659 Vali Loss: 0.0796424 Test Loss: 0.0905985\n",
      "Validation loss decreased (0.080559 --> 0.079642).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704219\n",
      "\tspeed: 0.0334s/iter; left time: 671.5725s\n",
      "\titers: 200, epoch: 10 | loss: 0.0674980\n",
      "\tspeed: 0.0137s/iter; left time: 273.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 222 | Train Loss: 0.0698026 Vali Loss: 0.0795738 Test Loss: 0.0907273\n",
      "Validation loss decreased (0.079642 --> 0.079574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727337\n",
      "\tspeed: 0.0341s/iter; left time: 677.4091s\n",
      "\titers: 200, epoch: 11 | loss: 0.0671647\n",
      "\tspeed: 0.0165s/iter; left time: 326.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0693997 Vali Loss: 0.0792396 Test Loss: 0.0906471\n",
      "Validation loss decreased (0.079574 --> 0.079240).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710371\n",
      "\tspeed: 0.0382s/iter; left time: 750.9383s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708320\n",
      "\tspeed: 0.0169s/iter; left time: 330.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0689154 Vali Loss: 0.0788275 Test Loss: 0.0903930\n",
      "Validation loss decreased (0.079240 --> 0.078828).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0635680\n",
      "\tspeed: 0.0405s/iter; left time: 786.7025s\n",
      "\titers: 200, epoch: 13 | loss: 0.0630454\n",
      "\tspeed: 0.0186s/iter; left time: 359.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0685797 Vali Loss: 0.0787910 Test Loss: 0.0905554\n",
      "Validation loss decreased (0.078828 --> 0.078791).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0685879\n",
      "\tspeed: 0.0398s/iter; left time: 764.8012s\n",
      "\titers: 200, epoch: 14 | loss: 0.0687533\n",
      "\tspeed: 0.0180s/iter; left time: 343.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0682373 Vali Loss: 0.0786533 Test Loss: 0.0904733\n",
      "Validation loss decreased (0.078791 --> 0.078653).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0678403\n",
      "\tspeed: 0.0397s/iter; left time: 753.2526s\n",
      "\titers: 200, epoch: 15 | loss: 0.0698767\n",
      "\tspeed: 0.0178s/iter; left time: 336.7466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0679334 Vali Loss: 0.0784564 Test Loss: 0.0909124\n",
      "Validation loss decreased (0.078653 --> 0.078456).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0700856\n",
      "\tspeed: 0.0364s/iter; left time: 683.9002s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626997\n",
      "\tspeed: 0.0176s/iter; left time: 328.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0676696 Vali Loss: 0.0785009 Test Loss: 0.0907203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685565\n",
      "\tspeed: 0.0396s/iter; left time: 734.8508s\n",
      "\titers: 200, epoch: 17 | loss: 0.0664126\n",
      "\tspeed: 0.0195s/iter; left time: 359.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0672094 Vali Loss: 0.0781273 Test Loss: 0.0906015\n",
      "Validation loss decreased (0.078456 --> 0.078127).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670132\n",
      "\tspeed: 0.0391s/iter; left time: 717.3881s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669249\n",
      "\tspeed: 0.0172s/iter; left time: 312.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0672603 Vali Loss: 0.0779196 Test Loss: 0.0904153\n",
      "Validation loss decreased (0.078127 --> 0.077920).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0710368\n",
      "\tspeed: 0.0390s/iter; left time: 705.2679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682627\n",
      "\tspeed: 0.0197s/iter; left time: 355.1127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0669857 Vali Loss: 0.0778751 Test Loss: 0.0902119\n",
      "Validation loss decreased (0.077920 --> 0.077875).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0657301\n",
      "\tspeed: 0.0430s/iter; left time: 768.4301s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647358\n",
      "\tspeed: 0.0169s/iter; left time: 301.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0667927 Vali Loss: 0.0778582 Test Loss: 0.0903987\n",
      "Validation loss decreased (0.077875 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0681141\n",
      "\tspeed: 0.0400s/iter; left time: 707.0849s\n",
      "\titers: 200, epoch: 21 | loss: 0.0677444\n",
      "\tspeed: 0.0177s/iter; left time: 310.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0667123 Vali Loss: 0.0779975 Test Loss: 0.0904759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0687355\n",
      "\tspeed: 0.0358s/iter; left time: 623.6058s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697549\n",
      "\tspeed: 0.0184s/iter; left time: 319.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0666015 Vali Loss: 0.0778401 Test Loss: 0.0906092\n",
      "Validation loss decreased (0.077858 --> 0.077840).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0621076\n",
      "\tspeed: 0.0407s/iter; left time: 701.0940s\n",
      "\titers: 200, epoch: 23 | loss: 0.0626924\n",
      "\tspeed: 0.0137s/iter; left time: 233.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0664471 Vali Loss: 0.0778884 Test Loss: 0.0904079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0643140\n",
      "\tspeed: 0.0424s/iter; left time: 719.9993s\n",
      "\titers: 200, epoch: 24 | loss: 0.0647285\n",
      "\tspeed: 0.0246s/iter; left time: 414.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 222 | Train Loss: 0.0663410 Vali Loss: 0.0778038 Test Loss: 0.0905400\n",
      "Validation loss decreased (0.077840 --> 0.077804).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0628065\n",
      "\tspeed: 0.0401s/iter; left time: 673.3486s\n",
      "\titers: 200, epoch: 25 | loss: 0.0644072\n",
      "\tspeed: 0.0137s/iter; left time: 227.8409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0663549 Vali Loss: 0.0777790 Test Loss: 0.0906833\n",
      "Validation loss decreased (0.077804 --> 0.077779).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0691754\n",
      "\tspeed: 0.0401s/iter; left time: 662.9232s\n",
      "\titers: 200, epoch: 26 | loss: 0.0642033\n",
      "\tspeed: 0.0222s/iter; left time: 365.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0660613 Vali Loss: 0.0779034 Test Loss: 0.0905330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0694070\n",
      "\tspeed: 0.0467s/iter; left time: 762.8113s\n",
      "\titers: 200, epoch: 27 | loss: 0.0620312\n",
      "\tspeed: 0.0235s/iter; left time: 380.6622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 222 | Train Loss: 0.0661828 Vali Loss: 0.0779134 Test Loss: 0.0911820\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0623799\n",
      "\tspeed: 0.0393s/iter; left time: 633.2118s\n",
      "\titers: 200, epoch: 28 | loss: 0.0651804\n",
      "\tspeed: 0.0171s/iter; left time: 273.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0662137 Vali Loss: 0.0777724 Test Loss: 0.0904204\n",
      "Validation loss decreased (0.077779 --> 0.077772).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0663736\n",
      "\tspeed: 0.0365s/iter; left time: 579.7350s\n",
      "\titers: 200, epoch: 29 | loss: 0.0627826\n",
      "\tspeed: 0.0216s/iter; left time: 341.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0659762 Vali Loss: 0.0777516 Test Loss: 0.0909365\n",
      "Validation loss decreased (0.077772 --> 0.077752).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0658481\n",
      "\tspeed: 0.0389s/iter; left time: 609.8250s\n",
      "\titers: 200, epoch: 30 | loss: 0.0680167\n",
      "\tspeed: 0.0209s/iter; left time: 325.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0658545 Vali Loss: 0.0777842 Test Loss: 0.0907960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0663877\n",
      "\tspeed: 0.0445s/iter; left time: 687.1590s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669244\n",
      "\tspeed: 0.0205s/iter; left time: 314.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0660432 Vali Loss: 0.0776771 Test Loss: 0.0908105\n",
      "Validation loss decreased (0.077752 --> 0.077677).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648231\n",
      "\tspeed: 0.0420s/iter; left time: 639.1763s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674317\n",
      "\tspeed: 0.0205s/iter; left time: 309.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 222 | Train Loss: 0.0658408 Vali Loss: 0.0777454 Test Loss: 0.0911105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0678782\n",
      "\tspeed: 0.0370s/iter; left time: 555.5555s\n",
      "\titers: 200, epoch: 33 | loss: 0.0643301\n",
      "\tspeed: 0.0172s/iter; left time: 255.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0658295 Vali Loss: 0.0776912 Test Loss: 0.0908741\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0642984\n",
      "\tspeed: 0.0363s/iter; left time: 536.3609s\n",
      "\titers: 200, epoch: 34 | loss: 0.0663682\n",
      "\tspeed: 0.0182s/iter; left time: 267.7611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0658093 Vali Loss: 0.0778673 Test Loss: 0.0911142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0613116\n",
      "\tspeed: 0.0412s/iter; left time: 599.3282s\n",
      "\titers: 200, epoch: 35 | loss: 0.0663639\n",
      "\tspeed: 0.0189s/iter; left time: 273.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0657065 Vali Loss: 0.0776919 Test Loss: 0.0911537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0673880\n",
      "\tspeed: 0.0386s/iter; left time: 552.9480s\n",
      "\titers: 200, epoch: 36 | loss: 0.0655852\n",
      "\tspeed: 0.0172s/iter; left time: 244.3258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0658169 Vali Loss: 0.0775844 Test Loss: 0.0908827\n",
      "Validation loss decreased (0.077677 --> 0.077584).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0649085\n",
      "\tspeed: 0.0367s/iter; left time: 518.3602s\n",
      "\titers: 200, epoch: 37 | loss: 0.0687972\n",
      "\tspeed: 0.0177s/iter; left time: 247.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0656873 Vali Loss: 0.0776541 Test Loss: 0.0911079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0658109\n",
      "\tspeed: 0.0383s/iter; left time: 531.3020s\n",
      "\titers: 200, epoch: 38 | loss: 0.0646297\n",
      "\tspeed: 0.0169s/iter; left time: 233.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0656310 Vali Loss: 0.0777044 Test Loss: 0.0912068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0672379\n",
      "\tspeed: 0.0363s/iter; left time: 495.9096s\n",
      "\titers: 200, epoch: 39 | loss: 0.0658156\n",
      "\tspeed: 0.0205s/iter; left time: 277.6168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0656917 Vali Loss: 0.0777175 Test Loss: 0.0911222\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0664440\n",
      "\tspeed: 0.0382s/iter; left time: 513.3054s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646944\n",
      "\tspeed: 0.0175s/iter; left time: 233.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0656318 Vali Loss: 0.0776022 Test Loss: 0.0910128\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0668205\n",
      "\tspeed: 0.0368s/iter; left time: 487.1115s\n",
      "\titers: 200, epoch: 41 | loss: 0.0617029\n",
      "\tspeed: 0.0176s/iter; left time: 230.7592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.0656555 Vali Loss: 0.0777193 Test Loss: 0.0908986\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0643047\n",
      "\tspeed: 0.0410s/iter; left time: 533.3334s\n",
      "\titers: 200, epoch: 42 | loss: 0.0623269\n",
      "\tspeed: 0.0200s/iter; left time: 258.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0656471 Vali Loss: 0.0776249 Test Loss: 0.0909272\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0665438\n",
      "\tspeed: 0.0406s/iter; left time: 518.8101s\n",
      "\titers: 200, epoch: 43 | loss: 0.0665644\n",
      "\tspeed: 0.0231s/iter; left time: 292.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 222 | Train Loss: 0.0655494 Vali Loss: 0.0776643 Test Loss: 0.0912756\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0636138\n",
      "\tspeed: 0.0390s/iter; left time: 489.0803s\n",
      "\titers: 200, epoch: 44 | loss: 0.0667647\n",
      "\tspeed: 0.0220s/iter; left time: 274.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0655892 Vali Loss: 0.0776366 Test Loss: 0.0910807\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0639832\n",
      "\tspeed: 0.0406s/iter; left time: 501.2459s\n",
      "\titers: 200, epoch: 45 | loss: 0.0676277\n",
      "\tspeed: 0.0209s/iter; left time: 255.2940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0655630 Vali Loss: 0.0776766 Test Loss: 0.0912446\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0616794\n",
      "\tspeed: 0.0378s/iter; left time: 458.3439s\n",
      "\titers: 200, epoch: 46 | loss: 0.0644349\n",
      "\tspeed: 0.0189s/iter; left time: 227.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0655509 Vali Loss: 0.0777734 Test Loss: 0.0915146\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02406461164355278, rmse:0.15512773394584656, mae:0.09088271111249924, rse:0.6008243560791016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2319828\n",
      "\tspeed: 0.0229s/iter; left time: 507.1712s\n",
      "\titers: 200, epoch: 1 | loss: 0.2084626\n",
      "\tspeed: 0.0222s/iter; left time: 487.6825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.2307888 Vali Loss: 0.1796101 Test Loss: 0.1840003\n",
      "Validation loss decreased (inf --> 0.179610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1202659\n",
      "\tspeed: 0.0470s/iter; left time: 1028.5025s\n",
      "\titers: 200, epoch: 2 | loss: 0.0984675\n",
      "\tspeed: 0.0187s/iter; left time: 407.5882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.1274008 Vali Loss: 0.0990929 Test Loss: 0.1087501\n",
      "Validation loss decreased (0.179610 --> 0.099093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0897407\n",
      "\tspeed: 0.0387s/iter; left time: 838.5515s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855197\n",
      "\tspeed: 0.0214s/iter; left time: 461.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0903506 Vali Loss: 0.0879331 Test Loss: 0.0963403\n",
      "Validation loss decreased (0.099093 --> 0.087933).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0825203\n",
      "\tspeed: 0.0424s/iter; left time: 909.5420s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801537\n",
      "\tspeed: 0.0205s/iter; left time: 437.7161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0823310 Vali Loss: 0.0838364 Test Loss: 0.0929438\n",
      "Validation loss decreased (0.087933 --> 0.083836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749546\n",
      "\tspeed: 0.0417s/iter; left time: 884.9743s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733442\n",
      "\tspeed: 0.0201s/iter; left time: 423.6024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 222 | Train Loss: 0.0770342 Vali Loss: 0.0832020 Test Loss: 0.0923905\n",
      "Validation loss decreased (0.083836 --> 0.083202).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0756646\n",
      "\tspeed: 0.0454s/iter; left time: 952.5190s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752125\n",
      "\tspeed: 0.0192s/iter; left time: 400.3191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 222 | Train Loss: 0.0738238 Vali Loss: 0.0821684 Test Loss: 0.0924239\n",
      "Validation loss decreased (0.083202 --> 0.082168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748782\n",
      "\tspeed: 0.0372s/iter; left time: 771.7526s\n",
      "\titers: 200, epoch: 7 | loss: 0.0701208\n",
      "\tspeed: 0.0182s/iter; left time: 376.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0722716 Vali Loss: 0.0809990 Test Loss: 0.0909296\n",
      "Validation loss decreased (0.082168 --> 0.080999).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0695359\n",
      "\tspeed: 0.0390s/iter; left time: 801.9361s\n",
      "\titers: 200, epoch: 8 | loss: 0.0699999\n",
      "\tspeed: 0.0182s/iter; left time: 372.5597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0712797 Vali Loss: 0.0806755 Test Loss: 0.0912457\n",
      "Validation loss decreased (0.080999 --> 0.080676).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711375\n",
      "\tspeed: 0.0445s/iter; left time: 903.9193s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675557\n",
      "\tspeed: 0.0191s/iter; left time: 385.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 222 | Train Loss: 0.0706966 Vali Loss: 0.0802653 Test Loss: 0.0908051\n",
      "Validation loss decreased (0.080676 --> 0.080265).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0673644\n",
      "\tspeed: 0.0412s/iter; left time: 828.3610s\n",
      "\titers: 200, epoch: 10 | loss: 0.0680034\n",
      "\tspeed: 0.0203s/iter; left time: 405.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0701715 Vali Loss: 0.0801495 Test Loss: 0.0909027\n",
      "Validation loss decreased (0.080265 --> 0.080150).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0679069\n",
      "\tspeed: 0.0383s/iter; left time: 762.1493s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664247\n",
      "\tspeed: 0.0190s/iter; left time: 374.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0695156 Vali Loss: 0.0796842 Test Loss: 0.0904101\n",
      "Validation loss decreased (0.080150 --> 0.079684).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713230\n",
      "\tspeed: 0.0396s/iter; left time: 778.7545s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707975\n",
      "\tspeed: 0.0198s/iter; left time: 387.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0689532 Vali Loss: 0.0795897 Test Loss: 0.0903748\n",
      "Validation loss decreased (0.079684 --> 0.079590).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0669175\n",
      "\tspeed: 0.0399s/iter; left time: 775.6522s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701373\n",
      "\tspeed: 0.0179s/iter; left time: 346.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0687951 Vali Loss: 0.0795658 Test Loss: 0.0910114\n",
      "Validation loss decreased (0.079590 --> 0.079566).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695180\n",
      "\tspeed: 0.0400s/iter; left time: 768.5747s\n",
      "\titers: 200, epoch: 14 | loss: 0.0676034\n",
      "\tspeed: 0.0180s/iter; left time: 343.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0686738 Vali Loss: 0.0796664 Test Loss: 0.0904864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605345\n",
      "\tspeed: 0.0419s/iter; left time: 796.1110s\n",
      "\titers: 200, epoch: 15 | loss: 0.0661341\n",
      "\tspeed: 0.0200s/iter; left time: 377.1805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 222 | Train Loss: 0.0684131 Vali Loss: 0.0796360 Test Loss: 0.0920964\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723512\n",
      "\tspeed: 0.0410s/iter; left time: 769.6635s\n",
      "\titers: 200, epoch: 16 | loss: 0.0658480\n",
      "\tspeed: 0.0178s/iter; left time: 332.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 222 | Train Loss: 0.0680571 Vali Loss: 0.0791825 Test Loss: 0.0913846\n",
      "Validation loss decreased (0.079566 --> 0.079182).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0676597\n",
      "\tspeed: 0.0465s/iter; left time: 861.8298s\n",
      "\titers: 200, epoch: 17 | loss: 0.0627009\n",
      "\tspeed: 0.0195s/iter; left time: 358.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 222 | Train Loss: 0.0677229 Vali Loss: 0.0791503 Test Loss: 0.0911777\n",
      "Validation loss decreased (0.079182 --> 0.079150).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679536\n",
      "\tspeed: 0.0423s/iter; left time: 775.4604s\n",
      "\titers: 200, epoch: 18 | loss: 0.0679239\n",
      "\tspeed: 0.0162s/iter; left time: 294.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0676038 Vali Loss: 0.0791089 Test Loss: 0.0913257\n",
      "Validation loss decreased (0.079150 --> 0.079109).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0683040\n",
      "\tspeed: 0.0438s/iter; left time: 792.4627s\n",
      "\titers: 200, epoch: 19 | loss: 0.0664067\n",
      "\tspeed: 0.0192s/iter; left time: 346.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 222 | Train Loss: 0.0673737 Vali Loss: 0.0789633 Test Loss: 0.0914856\n",
      "Validation loss decreased (0.079109 --> 0.078963).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0683363\n",
      "\tspeed: 0.0386s/iter; left time: 690.5069s\n",
      "\titers: 200, epoch: 20 | loss: 0.0666111\n",
      "\tspeed: 0.0180s/iter; left time: 320.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0673123 Vali Loss: 0.0791622 Test Loss: 0.0923091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651823\n",
      "\tspeed: 0.0366s/iter; left time: 647.1328s\n",
      "\titers: 200, epoch: 21 | loss: 0.0675858\n",
      "\tspeed: 0.0171s/iter; left time: 300.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0672142 Vali Loss: 0.0792254 Test Loss: 0.0926093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0655182\n",
      "\tspeed: 0.0358s/iter; left time: 623.8362s\n",
      "\titers: 200, epoch: 22 | loss: 0.0667910\n",
      "\tspeed: 0.0176s/iter; left time: 304.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 222 | Train Loss: 0.0669031 Vali Loss: 0.0788213 Test Loss: 0.0911421\n",
      "Validation loss decreased (0.078963 --> 0.078821).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0677871\n",
      "\tspeed: 0.0424s/iter; left time: 729.3468s\n",
      "\titers: 200, epoch: 23 | loss: 0.0615978\n",
      "\tspeed: 0.0188s/iter; left time: 321.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 222 | Train Loss: 0.0670101 Vali Loss: 0.0786794 Test Loss: 0.0910406\n",
      "Validation loss decreased (0.078821 --> 0.078679).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0684268\n",
      "\tspeed: 0.0398s/iter; left time: 676.3128s\n",
      "\titers: 200, epoch: 24 | loss: 0.0691375\n",
      "\tspeed: 0.0179s/iter; left time: 302.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0669904 Vali Loss: 0.0788834 Test Loss: 0.0914515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0640026\n",
      "\tspeed: 0.0388s/iter; left time: 650.6417s\n",
      "\titers: 200, epoch: 25 | loss: 0.0652691\n",
      "\tspeed: 0.0173s/iter; left time: 289.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0668501 Vali Loss: 0.0787182 Test Loss: 0.0917424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0634801\n",
      "\tspeed: 0.0439s/iter; left time: 725.9697s\n",
      "\titers: 200, epoch: 26 | loss: 0.0674998\n",
      "\tspeed: 0.0233s/iter; left time: 383.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 222 | Train Loss: 0.0667452 Vali Loss: 0.0787112 Test Loss: 0.0914333\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0656401\n",
      "\tspeed: 0.0408s/iter; left time: 666.2305s\n",
      "\titers: 200, epoch: 27 | loss: 0.0628682\n",
      "\tspeed: 0.0188s/iter; left time: 305.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0666480 Vali Loss: 0.0785765 Test Loss: 0.0913582\n",
      "Validation loss decreased (0.078679 --> 0.078576).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0666436\n",
      "\tspeed: 0.0403s/iter; left time: 649.0542s\n",
      "\titers: 200, epoch: 28 | loss: 0.0661310\n",
      "\tspeed: 0.0165s/iter; left time: 263.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0666455 Vali Loss: 0.0786015 Test Loss: 0.0910953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0668129\n",
      "\tspeed: 0.0412s/iter; left time: 653.6960s\n",
      "\titers: 200, epoch: 29 | loss: 0.0659632\n",
      "\tspeed: 0.0180s/iter; left time: 283.8519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.0665038 Vali Loss: 0.0785815 Test Loss: 0.0910819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0677124\n",
      "\tspeed: 0.0398s/iter; left time: 622.9179s\n",
      "\titers: 200, epoch: 30 | loss: 0.0662659\n",
      "\tspeed: 0.0205s/iter; left time: 319.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0664562 Vali Loss: 0.0785316 Test Loss: 0.0916162\n",
      "Validation loss decreased (0.078576 --> 0.078532).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0664014\n",
      "\tspeed: 0.0444s/iter; left time: 685.5071s\n",
      "\titers: 200, epoch: 31 | loss: 0.0675983\n",
      "\tspeed: 0.0202s/iter; left time: 310.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0665412 Vali Loss: 0.0784587 Test Loss: 0.0906658\n",
      "Validation loss decreased (0.078532 --> 0.078459).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0675416\n",
      "\tspeed: 0.0413s/iter; left time: 628.7906s\n",
      "\titers: 200, epoch: 32 | loss: 0.0640216\n",
      "\tspeed: 0.0171s/iter; left time: 259.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0664777 Vali Loss: 0.0783697 Test Loss: 0.0903753\n",
      "Validation loss decreased (0.078459 --> 0.078370).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0659781\n",
      "\tspeed: 0.0408s/iter; left time: 612.1212s\n",
      "\titers: 200, epoch: 33 | loss: 0.0637254\n",
      "\tspeed: 0.0162s/iter; left time: 240.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0664676 Vali Loss: 0.0785606 Test Loss: 0.0918490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0616548\n",
      "\tspeed: 0.0419s/iter; left time: 618.6522s\n",
      "\titers: 200, epoch: 34 | loss: 0.0680450\n",
      "\tspeed: 0.0195s/iter; left time: 285.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 222 | Train Loss: 0.0663375 Vali Loss: 0.0784621 Test Loss: 0.0912215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0649782\n",
      "\tspeed: 0.0417s/iter; left time: 607.0620s\n",
      "\titers: 200, epoch: 35 | loss: 0.0701866\n",
      "\tspeed: 0.0200s/iter; left time: 289.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0663069 Vali Loss: 0.0784806 Test Loss: 0.0915692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0645071\n",
      "\tspeed: 0.0425s/iter; left time: 609.0118s\n",
      "\titers: 200, epoch: 36 | loss: 0.0655820\n",
      "\tspeed: 0.0210s/iter; left time: 298.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0662163 Vali Loss: 0.0784675 Test Loss: 0.0912538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0640461\n",
      "\tspeed: 0.0421s/iter; left time: 594.4223s\n",
      "\titers: 200, epoch: 37 | loss: 0.0639115\n",
      "\tspeed: 0.0177s/iter; left time: 247.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0662549 Vali Loss: 0.0785017 Test Loss: 0.0913716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0661257\n",
      "\tspeed: 0.0459s/iter; left time: 637.4721s\n",
      "\titers: 200, epoch: 38 | loss: 0.0696747\n",
      "\tspeed: 0.0243s/iter; left time: 334.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 222 | Train Loss: 0.0662728 Vali Loss: 0.0784343 Test Loss: 0.0914996\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0616808\n",
      "\tspeed: 0.0397s/iter; left time: 543.0284s\n",
      "\titers: 200, epoch: 39 | loss: 0.0674529\n",
      "\tspeed: 0.0192s/iter; left time: 260.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0662466 Vali Loss: 0.0783954 Test Loss: 0.0913800\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0670593\n",
      "\tspeed: 0.0425s/iter; left time: 571.3580s\n",
      "\titers: 200, epoch: 40 | loss: 0.0633850\n",
      "\tspeed: 0.0208s/iter; left time: 277.8770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.0662610 Vali Loss: 0.0785325 Test Loss: 0.0916123\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0660525\n",
      "\tspeed: 0.0394s/iter; left time: 521.1879s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672518\n",
      "\tspeed: 0.0168s/iter; left time: 220.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0661967 Vali Loss: 0.0785772 Test Loss: 0.0923340\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0678602\n",
      "\tspeed: 0.0427s/iter; left time: 554.6946s\n",
      "\titers: 200, epoch: 42 | loss: 0.0668587\n",
      "\tspeed: 0.0194s/iter; left time: 250.6988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0663821 Vali Loss: 0.0784219 Test Loss: 0.0909432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023561760783195496, rmse:0.15349841117858887, mae:0.09037524461746216, rse:0.5945138931274414\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:48.06s\n",
      "Intermediate time for FR: 00h:32m:16.14s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2613267\n",
      "\tspeed: 0.0419s/iter; left time: 929.5428s\n",
      "\titers: 200, epoch: 1 | loss: 0.2446445\n",
      "\tspeed: 0.0132s/iter; left time: 292.1130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 223 | Train Loss: 0.2666068 Vali Loss: 0.1840600 Test Loss: 0.1914255\n",
      "Validation loss decreased (inf --> 0.184060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497402\n",
      "\tspeed: 0.0345s/iter; left time: 757.2557s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122778\n",
      "\tspeed: 0.0187s/iter; left time: 409.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1534578 Vali Loss: 0.0864928 Test Loss: 0.0884348\n",
      "Validation loss decreased (0.184060 --> 0.086493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1031142\n",
      "\tspeed: 0.0349s/iter; left time: 758.5943s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902892\n",
      "\tspeed: 0.0155s/iter; left time: 334.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0977980 Vali Loss: 0.0769380 Test Loss: 0.0806744\n",
      "Validation loss decreased (0.086493 --> 0.076938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854379\n",
      "\tspeed: 0.0337s/iter; left time: 726.0199s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809595\n",
      "\tspeed: 0.0171s/iter; left time: 366.6371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0846276 Vali Loss: 0.0736284 Test Loss: 0.0773814\n",
      "Validation loss decreased (0.076938 --> 0.073628).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748807\n",
      "\tspeed: 0.0344s/iter; left time: 732.0774s\n",
      "\titers: 200, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0171s/iter; left time: 361.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0772823 Vali Loss: 0.0687476 Test Loss: 0.0723286\n",
      "Validation loss decreased (0.073628 --> 0.068748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768507\n",
      "\tspeed: 0.0359s/iter; left time: 758.0406s\n",
      "\titers: 200, epoch: 6 | loss: 0.0710905\n",
      "\tspeed: 0.0174s/iter; left time: 364.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0735575 Vali Loss: 0.0683415 Test Loss: 0.0712536\n",
      "Validation loss decreased (0.068748 --> 0.068342).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0729222\n",
      "\tspeed: 0.0318s/iter; left time: 662.6937s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723143\n",
      "\tspeed: 0.0133s/iter; left time: 275.2017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 223 | Train Loss: 0.0710755 Vali Loss: 0.0655078 Test Loss: 0.0690658\n",
      "Validation loss decreased (0.068342 --> 0.065508).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0695795\n",
      "\tspeed: 0.0384s/iter; left time: 793.5531s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734919\n",
      "\tspeed: 0.0172s/iter; left time: 353.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0693097 Vali Loss: 0.0642290 Test Loss: 0.0678487\n",
      "Validation loss decreased (0.065508 --> 0.064229).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0642837\n",
      "\tspeed: 0.0379s/iter; left time: 773.4985s\n",
      "\titers: 200, epoch: 9 | loss: 0.0674841\n",
      "\tspeed: 0.0179s/iter; left time: 362.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0678791 Vali Loss: 0.0636194 Test Loss: 0.0669367\n",
      "Validation loss decreased (0.064229 --> 0.063619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0673314\n",
      "\tspeed: 0.0363s/iter; left time: 732.5304s\n",
      "\titers: 200, epoch: 10 | loss: 0.0682601\n",
      "\tspeed: 0.0170s/iter; left time: 340.6656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0672177 Vali Loss: 0.0630238 Test Loss: 0.0665055\n",
      "Validation loss decreased (0.063619 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0671064\n",
      "\tspeed: 0.0320s/iter; left time: 639.3773s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658044\n",
      "\tspeed: 0.0133s/iter; left time: 263.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 223 | Train Loss: 0.0662129 Vali Loss: 0.0630377 Test Loss: 0.0666590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0651188\n",
      "\tspeed: 0.0340s/iter; left time: 670.7137s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650911\n",
      "\tspeed: 0.0178s/iter; left time: 349.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0653732 Vali Loss: 0.0619107 Test Loss: 0.0653360\n",
      "Validation loss decreased (0.063024 --> 0.061911).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0632853\n",
      "\tspeed: 0.0379s/iter; left time: 740.5045s\n",
      "\titers: 200, epoch: 13 | loss: 0.0712935\n",
      "\tspeed: 0.0175s/iter; left time: 339.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0646758 Vali Loss: 0.0623154 Test Loss: 0.0656084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0596975\n",
      "\tspeed: 0.0431s/iter; left time: 832.6166s\n",
      "\titers: 200, epoch: 14 | loss: 0.0668238\n",
      "\tspeed: 0.0226s/iter; left time: 433.6039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 223 | Train Loss: 0.0641173 Vali Loss: 0.0612675 Test Loss: 0.0644853\n",
      "Validation loss decreased (0.061911 --> 0.061268).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0588378\n",
      "\tspeed: 0.0399s/iter; left time: 761.1152s\n",
      "\titers: 200, epoch: 15 | loss: 0.0607067\n",
      "\tspeed: 0.0173s/iter; left time: 328.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0638006 Vali Loss: 0.0608089 Test Loss: 0.0640089\n",
      "Validation loss decreased (0.061268 --> 0.060809).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0661558\n",
      "\tspeed: 0.0417s/iter; left time: 786.5611s\n",
      "\titers: 200, epoch: 16 | loss: 0.0590718\n",
      "\tspeed: 0.0204s/iter; left time: 382.7497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0634317 Vali Loss: 0.0605441 Test Loss: 0.0635168\n",
      "Validation loss decreased (0.060809 --> 0.060544).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0618667\n",
      "\tspeed: 0.0402s/iter; left time: 749.0958s\n",
      "\titers: 200, epoch: 17 | loss: 0.0566609\n",
      "\tspeed: 0.0205s/iter; left time: 379.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 223 | Train Loss: 0.0640653 Vali Loss: 0.0602748 Test Loss: 0.0635381\n",
      "Validation loss decreased (0.060544 --> 0.060275).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0654053\n",
      "\tspeed: 0.0390s/iter; left time: 717.7307s\n",
      "\titers: 200, epoch: 18 | loss: 0.0615840\n",
      "\tspeed: 0.0181s/iter; left time: 331.3218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0632089 Vali Loss: 0.0605393 Test Loss: 0.0638801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0613055\n",
      "\tspeed: 0.0366s/iter; left time: 665.6117s\n",
      "\titers: 200, epoch: 19 | loss: 0.0682047\n",
      "\tspeed: 0.0185s/iter; left time: 335.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0627610 Vali Loss: 0.0601602 Test Loss: 0.0631403\n",
      "Validation loss decreased (0.060275 --> 0.060160).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0593312\n",
      "\tspeed: 0.0424s/iter; left time: 761.2970s\n",
      "\titers: 200, epoch: 20 | loss: 0.0653080\n",
      "\tspeed: 0.0214s/iter; left time: 383.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0625884 Vali Loss: 0.0598175 Test Loss: 0.0629922\n",
      "Validation loss decreased (0.060160 --> 0.059817).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0676790\n",
      "\tspeed: 0.0414s/iter; left time: 734.1198s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658659\n",
      "\tspeed: 0.0196s/iter; left time: 345.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0624293 Vali Loss: 0.0600168 Test Loss: 0.0629384\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0614464\n",
      "\tspeed: 0.0344s/iter; left time: 602.2228s\n",
      "\titers: 200, epoch: 22 | loss: 0.0614755\n",
      "\tspeed: 0.0218s/iter; left time: 380.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0622742 Vali Loss: 0.0598513 Test Loss: 0.0629770\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0584518\n",
      "\tspeed: 0.0395s/iter; left time: 682.6779s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606909\n",
      "\tspeed: 0.0227s/iter; left time: 390.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 223 | Train Loss: 0.0619770 Vali Loss: 0.0594832 Test Loss: 0.0625747\n",
      "Validation loss decreased (0.059817 --> 0.059483).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0611410\n",
      "\tspeed: 0.0417s/iter; left time: 712.5551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620168\n",
      "\tspeed: 0.0216s/iter; left time: 366.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0620027 Vali Loss: 0.0597211 Test Loss: 0.0627181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0620445\n",
      "\tspeed: 0.0341s/iter; left time: 575.3238s\n",
      "\titers: 200, epoch: 25 | loss: 0.0627680\n",
      "\tspeed: 0.0132s/iter; left time: 220.5784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 223 | Train Loss: 0.0616908 Vali Loss: 0.0594576 Test Loss: 0.0624559\n",
      "Validation loss decreased (0.059483 --> 0.059458).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0620271\n",
      "\tspeed: 0.0359s/iter; left time: 596.8888s\n",
      "\titers: 200, epoch: 26 | loss: 0.0575310\n",
      "\tspeed: 0.0198s/iter; left time: 327.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0617656 Vali Loss: 0.0596068 Test Loss: 0.0625476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0598931\n",
      "\tspeed: 0.0380s/iter; left time: 623.5258s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633982\n",
      "\tspeed: 0.0151s/iter; left time: 245.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0615633 Vali Loss: 0.0595073 Test Loss: 0.0624505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630150\n",
      "\tspeed: 0.0392s/iter; left time: 634.1092s\n",
      "\titers: 200, epoch: 28 | loss: 0.0613112\n",
      "\tspeed: 0.0236s/iter; left time: 378.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0615299 Vali Loss: 0.0594390 Test Loss: 0.0625015\n",
      "Validation loss decreased (0.059458 --> 0.059439).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0623488\n",
      "\tspeed: 0.0401s/iter; left time: 640.0959s\n",
      "\titers: 200, epoch: 29 | loss: 0.0628008\n",
      "\tspeed: 0.0166s/iter; left time: 262.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0614410 Vali Loss: 0.0591361 Test Loss: 0.0620808\n",
      "Validation loss decreased (0.059439 --> 0.059136).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578748\n",
      "\tspeed: 0.0373s/iter; left time: 587.5734s\n",
      "\titers: 200, epoch: 30 | loss: 0.0640098\n",
      "\tspeed: 0.0172s/iter; left time: 268.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0613836 Vali Loss: 0.0591412 Test Loss: 0.0622279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0638591\n",
      "\tspeed: 0.0387s/iter; left time: 600.1324s\n",
      "\titers: 200, epoch: 31 | loss: 0.0630033\n",
      "\tspeed: 0.0204s/iter; left time: 313.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0614346 Vali Loss: 0.0593630 Test Loss: 0.0622768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0617785\n",
      "\tspeed: 0.0372s/iter; left time: 569.0350s\n",
      "\titers: 200, epoch: 32 | loss: 0.0627892\n",
      "\tspeed: 0.0168s/iter; left time: 255.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0612977 Vali Loss: 0.0591567 Test Loss: 0.0619966\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0603411\n",
      "\tspeed: 0.0386s/iter; left time: 581.9217s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641707\n",
      "\tspeed: 0.0209s/iter; left time: 312.1005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 223 | Train Loss: 0.0613798 Vali Loss: 0.0589896 Test Loss: 0.0621368\n",
      "Validation loss decreased (0.059136 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0657505\n",
      "\tspeed: 0.0330s/iter; left time: 489.5588s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526833\n",
      "\tspeed: 0.0132s/iter; left time: 194.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 223 | Train Loss: 0.0611487 Vali Loss: 0.0590259 Test Loss: 0.0620669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645364\n",
      "\tspeed: 0.0396s/iter; left time: 579.1427s\n",
      "\titers: 200, epoch: 35 | loss: 0.0628361\n",
      "\tspeed: 0.0212s/iter; left time: 307.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0609772 Vali Loss: 0.0591559 Test Loss: 0.0619222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0613310\n",
      "\tspeed: 0.0383s/iter; left time: 551.2838s\n",
      "\titers: 200, epoch: 36 | loss: 0.0621967\n",
      "\tspeed: 0.0195s/iter; left time: 278.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0610524 Vali Loss: 0.0590193 Test Loss: 0.0619030\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0577797\n",
      "\tspeed: 0.0409s/iter; left time: 579.3626s\n",
      "\titers: 200, epoch: 37 | loss: 0.0633397\n",
      "\tspeed: 0.0185s/iter; left time: 260.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0610985 Vali Loss: 0.0589273 Test Loss: 0.0618850\n",
      "Validation loss decreased (0.058990 --> 0.058927).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0607721\n",
      "\tspeed: 0.0337s/iter; left time: 469.5395s\n",
      "\titers: 200, epoch: 38 | loss: 0.0587756\n",
      "\tspeed: 0.0159s/iter; left time: 219.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.0611439 Vali Loss: 0.0591564 Test Loss: 0.0619709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0606503\n",
      "\tspeed: 0.0382s/iter; left time: 524.6859s\n",
      "\titers: 200, epoch: 39 | loss: 0.0621387\n",
      "\tspeed: 0.0176s/iter; left time: 239.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0609651 Vali Loss: 0.0588507 Test Loss: 0.0619381\n",
      "Validation loss decreased (0.058927 --> 0.058851).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0650060\n",
      "\tspeed: 0.0380s/iter; left time: 513.7667s\n",
      "\titers: 200, epoch: 40 | loss: 0.0615220\n",
      "\tspeed: 0.0133s/iter; left time: 177.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0608909 Vali Loss: 0.0590737 Test Loss: 0.0619943\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0583368\n",
      "\tspeed: 0.0379s/iter; left time: 503.2457s\n",
      "\titers: 200, epoch: 41 | loss: 0.0623025\n",
      "\tspeed: 0.0167s/iter; left time: 220.6197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0610516 Vali Loss: 0.0589446 Test Loss: 0.0617396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0593722\n",
      "\tspeed: 0.0386s/iter; left time: 503.5643s\n",
      "\titers: 200, epoch: 42 | loss: 0.0642216\n",
      "\tspeed: 0.0186s/iter; left time: 240.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0609676 Vali Loss: 0.0589558 Test Loss: 0.0618359\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0620654\n",
      "\tspeed: 0.0399s/iter; left time: 511.5043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0551790\n",
      "\tspeed: 0.0236s/iter; left time: 301.1799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0609758 Vali Loss: 0.0590449 Test Loss: 0.0618489\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0608172\n",
      "\tspeed: 0.0404s/iter; left time: 509.8308s\n",
      "\titers: 200, epoch: 44 | loss: 0.0628253\n",
      "\tspeed: 0.0209s/iter; left time: 261.2628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0607553 Vali Loss: 0.0588690 Test Loss: 0.0617649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0613841\n",
      "\tspeed: 0.0336s/iter; left time: 415.7469s\n",
      "\titers: 200, epoch: 45 | loss: 0.0639292\n",
      "\tspeed: 0.0132s/iter; left time: 162.1643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 223 | Train Loss: 0.0608602 Vali Loss: 0.0588656 Test Loss: 0.0618464\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0583891\n",
      "\tspeed: 0.0356s/iter; left time: 432.5109s\n",
      "\titers: 200, epoch: 46 | loss: 0.0602550\n",
      "\tspeed: 0.0204s/iter; left time: 246.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 223 | Train Loss: 0.0609415 Vali Loss: 0.0587919 Test Loss: 0.0617911\n",
      "Validation loss decreased (0.058851 --> 0.058792).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0639604\n",
      "\tspeed: 0.0441s/iter; left time: 526.1049s\n",
      "\titers: 200, epoch: 47 | loss: 0.0653370\n",
      "\tspeed: 0.0216s/iter; left time: 255.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0608470 Vali Loss: 0.0588511 Test Loss: 0.0617494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0593503\n",
      "\tspeed: 0.0398s/iter; left time: 466.6454s\n",
      "\titers: 200, epoch: 48 | loss: 0.0613594\n",
      "\tspeed: 0.0184s/iter; left time: 213.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0609415 Vali Loss: 0.0588569 Test Loss: 0.0617537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0603362\n",
      "\tspeed: 0.0388s/iter; left time: 445.7200s\n",
      "\titers: 200, epoch: 49 | loss: 0.0597747\n",
      "\tspeed: 0.0214s/iter; left time: 243.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0608540 Vali Loss: 0.0588741 Test Loss: 0.0617944\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0653773\n",
      "\tspeed: 0.0401s/iter; left time: 452.0966s\n",
      "\titers: 200, epoch: 50 | loss: 0.0632145\n",
      "\tspeed: 0.0200s/iter; left time: 223.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0608770 Vali Loss: 0.0587537 Test Loss: 0.0618283\n",
      "Validation loss decreased (0.058792 --> 0.058754).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0580339\n",
      "\tspeed: 0.0342s/iter; left time: 378.3875s\n",
      "\titers: 200, epoch: 51 | loss: 0.0605934\n",
      "\tspeed: 0.0148s/iter; left time: 162.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0609557 Vali Loss: 0.0588175 Test Loss: 0.0617933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0606185\n",
      "\tspeed: 0.0397s/iter; left time: 430.1379s\n",
      "\titers: 200, epoch: 52 | loss: 0.0588947\n",
      "\tspeed: 0.0202s/iter; left time: 216.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0607469 Vali Loss: 0.0588645 Test Loss: 0.0618061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0596454\n",
      "\tspeed: 0.0379s/iter; left time: 401.4139s\n",
      "\titers: 200, epoch: 53 | loss: 0.0588593\n",
      "\tspeed: 0.0131s/iter; left time: 137.5603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.0608250 Vali Loss: 0.0587320 Test Loss: 0.0618455\n",
      "Validation loss decreased (0.058754 --> 0.058732).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0631147\n",
      "\tspeed: 0.0395s/iter; left time: 410.3508s\n",
      "\titers: 200, epoch: 54 | loss: 0.0594384\n",
      "\tspeed: 0.0202s/iter; left time: 207.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 223 | Train Loss: 0.0609803 Vali Loss: 0.0588939 Test Loss: 0.0618061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0568584\n",
      "\tspeed: 0.0419s/iter; left time: 425.8713s\n",
      "\titers: 200, epoch: 55 | loss: 0.0621192\n",
      "\tspeed: 0.0198s/iter; left time: 199.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0607608 Vali Loss: 0.0588212 Test Loss: 0.0617022\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0570619\n",
      "\tspeed: 0.0384s/iter; left time: 381.3602s\n",
      "\titers: 200, epoch: 56 | loss: 0.0623090\n",
      "\tspeed: 0.0190s/iter; left time: 186.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 223 | Train Loss: 0.0607289 Vali Loss: 0.0587791 Test Loss: 0.0617858\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0594441\n",
      "\tspeed: 0.0379s/iter; left time: 367.8494s\n",
      "\titers: 200, epoch: 57 | loss: 0.0558800\n",
      "\tspeed: 0.0194s/iter; left time: 186.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0607479 Vali Loss: 0.0588879 Test Loss: 0.0617320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0600957\n",
      "\tspeed: 0.0408s/iter; left time: 386.9804s\n",
      "\titers: 200, epoch: 58 | loss: 0.0602918\n",
      "\tspeed: 0.0232s/iter; left time: 218.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0608448 Vali Loss: 0.0587269 Test Loss: 0.0617501\n",
      "Validation loss decreased (0.058732 --> 0.058727).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0602974\n",
      "\tspeed: 0.0379s/iter; left time: 351.2098s\n",
      "\titers: 200, epoch: 59 | loss: 0.0584449\n",
      "\tspeed: 0.0203s/iter; left time: 185.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0608016 Vali Loss: 0.0588245 Test Loss: 0.0618007\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0615578\n",
      "\tspeed: 0.0377s/iter; left time: 340.9705s\n",
      "\titers: 200, epoch: 60 | loss: 0.0613358\n",
      "\tspeed: 0.0185s/iter; left time: 165.5157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0606737 Vali Loss: 0.0588306 Test Loss: 0.0617119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0588411\n",
      "\tspeed: 0.0381s/iter; left time: 335.7435s\n",
      "\titers: 200, epoch: 61 | loss: 0.0587410\n",
      "\tspeed: 0.0174s/iter; left time: 151.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0608954 Vali Loss: 0.0588355 Test Loss: 0.0617781\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0578414\n",
      "\tspeed: 0.0387s/iter; left time: 332.5622s\n",
      "\titers: 200, epoch: 62 | loss: 0.0639606\n",
      "\tspeed: 0.0135s/iter; left time: 114.3450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0606342 Vali Loss: 0.0587989 Test Loss: 0.0617433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0601831\n",
      "\tspeed: 0.0410s/iter; left time: 343.5317s\n",
      "\titers: 200, epoch: 63 | loss: 0.0632877\n",
      "\tspeed: 0.0174s/iter; left time: 144.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0606488 Vali Loss: 0.0587607 Test Loss: 0.0617137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0606772\n",
      "\tspeed: 0.0418s/iter; left time: 340.6402s\n",
      "\titers: 200, epoch: 64 | loss: 0.0595985\n",
      "\tspeed: 0.0246s/iter; left time: 198.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0606772 Vali Loss: 0.0588284 Test Loss: 0.0617719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0598041\n",
      "\tspeed: 0.0436s/iter; left time: 345.6228s\n",
      "\titers: 200, epoch: 65 | loss: 0.0576087\n",
      "\tspeed: 0.0225s/iter; left time: 176.0025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0610323 Vali Loss: 0.0588839 Test Loss: 0.0617702\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0596291\n",
      "\tspeed: 0.0379s/iter; left time: 292.3392s\n",
      "\titers: 200, epoch: 66 | loss: 0.0590288\n",
      "\tspeed: 0.0132s/iter; left time: 100.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 223 | Train Loss: 0.0607707 Vali Loss: 0.0587562 Test Loss: 0.0617330\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0609282\n",
      "\tspeed: 0.0368s/iter; left time: 275.2566s\n",
      "\titers: 200, epoch: 67 | loss: 0.0632504\n",
      "\tspeed: 0.0181s/iter; left time: 133.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0608283 Vali Loss: 0.0589284 Test Loss: 0.0617660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0573190\n",
      "\tspeed: 0.0391s/iter; left time: 283.6717s\n",
      "\titers: 200, epoch: 68 | loss: 0.0583250\n",
      "\tspeed: 0.0188s/iter; left time: 134.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0607404 Vali Loss: 0.0588340 Test Loss: 0.0616791\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010783816687762737, rmse:0.10384515672922134, mae:0.061750106513500214, rse:0.3923797011375427\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2633380\n",
      "\tspeed: 0.0239s/iter; left time: 529.8813s\n",
      "\titers: 200, epoch: 1 | loss: 0.2407372\n",
      "\tspeed: 0.0217s/iter; left time: 479.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.2640402 Vali Loss: 0.1804014 Test Loss: 0.1877910\n",
      "Validation loss decreased (inf --> 0.180401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1468459\n",
      "\tspeed: 0.0408s/iter; left time: 896.8737s\n",
      "\titers: 200, epoch: 2 | loss: 0.1099515\n",
      "\tspeed: 0.0189s/iter; left time: 413.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.1528204 Vali Loss: 0.0868056 Test Loss: 0.0895790\n",
      "Validation loss decreased (0.180401 --> 0.086806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0964038\n",
      "\tspeed: 0.0414s/iter; left time: 900.1064s\n",
      "\titers: 200, epoch: 3 | loss: 0.0842642\n",
      "\tspeed: 0.0186s/iter; left time: 402.7375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 223 | Train Loss: 0.0969877 Vali Loss: 0.0785030 Test Loss: 0.0825628\n",
      "Validation loss decreased (0.086806 --> 0.078503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810436\n",
      "\tspeed: 0.0419s/iter; left time: 902.3011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0776492\n",
      "\tspeed: 0.0190s/iter; left time: 406.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0846801 Vali Loss: 0.0728767 Test Loss: 0.0769952\n",
      "Validation loss decreased (0.078503 --> 0.072877).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784938\n",
      "\tspeed: 0.0374s/iter; left time: 796.0381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754372\n",
      "\tspeed: 0.0159s/iter; left time: 337.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.0779213 Vali Loss: 0.0707370 Test Loss: 0.0739268\n",
      "Validation loss decreased (0.072877 --> 0.070737).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0719557\n",
      "\tspeed: 0.0440s/iter; left time: 928.1873s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751791\n",
      "\tspeed: 0.0246s/iter; left time: 517.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0745827 Vali Loss: 0.0686857 Test Loss: 0.0711119\n",
      "Validation loss decreased (0.070737 --> 0.068686).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0687462\n",
      "\tspeed: 0.0451s/iter; left time: 941.0784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699917\n",
      "\tspeed: 0.0224s/iter; left time: 465.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0719870 Vali Loss: 0.0662156 Test Loss: 0.0687054\n",
      "Validation loss decreased (0.068686 --> 0.066216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0733410\n",
      "\tspeed: 0.0436s/iter; left time: 899.8341s\n",
      "\titers: 200, epoch: 8 | loss: 0.0698235\n",
      "\tspeed: 0.0221s/iter; left time: 453.2285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0698144 Vali Loss: 0.0660703 Test Loss: 0.0690490\n",
      "Validation loss decreased (0.066216 --> 0.066070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0645584\n",
      "\tspeed: 0.0370s/iter; left time: 755.9351s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675166\n",
      "\tspeed: 0.0189s/iter; left time: 384.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0686722 Vali Loss: 0.0640057 Test Loss: 0.0668120\n",
      "Validation loss decreased (0.066070 --> 0.064006).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0677028\n",
      "\tspeed: 0.0374s/iter; left time: 755.9223s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655631\n",
      "\tspeed: 0.0161s/iter; left time: 323.7281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 223 | Train Loss: 0.0674993 Vali Loss: 0.0634299 Test Loss: 0.0662320\n",
      "Validation loss decreased (0.064006 --> 0.063430).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675405\n",
      "\tspeed: 0.0422s/iter; left time: 843.6887s\n",
      "\titers: 200, epoch: 11 | loss: 0.0689366\n",
      "\tspeed: 0.0197s/iter; left time: 391.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0662033 Vali Loss: 0.0624996 Test Loss: 0.0652963\n",
      "Validation loss decreased (0.063430 --> 0.062500).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0665987\n",
      "\tspeed: 0.0429s/iter; left time: 846.4644s\n",
      "\titers: 200, epoch: 12 | loss: 0.0673204\n",
      "\tspeed: 0.0176s/iter; left time: 344.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0657239 Vali Loss: 0.0617468 Test Loss: 0.0645706\n",
      "Validation loss decreased (0.062500 --> 0.061747).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0607038\n",
      "\tspeed: 0.0411s/iter; left time: 801.9686s\n",
      "\titers: 200, epoch: 13 | loss: 0.0643402\n",
      "\tspeed: 0.0186s/iter; left time: 360.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0647358 Vali Loss: 0.0621991 Test Loss: 0.0647919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0612636\n",
      "\tspeed: 0.0394s/iter; left time: 760.4058s\n",
      "\titers: 200, epoch: 14 | loss: 0.0642949\n",
      "\tspeed: 0.0182s/iter; left time: 349.9146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0642953 Vali Loss: 0.0618577 Test Loss: 0.0641777\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638503\n",
      "\tspeed: 0.0446s/iter; left time: 851.6674s\n",
      "\titers: 200, epoch: 15 | loss: 0.0629039\n",
      "\tspeed: 0.0224s/iter; left time: 424.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0638525 Vali Loss: 0.0608925 Test Loss: 0.0636975\n",
      "Validation loss decreased (0.061747 --> 0.060893).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0654804\n",
      "\tspeed: 0.0434s/iter; left time: 819.0551s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626004\n",
      "\tspeed: 0.0250s/iter; left time: 468.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0635759 Vali Loss: 0.0613872 Test Loss: 0.0638123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0584193\n",
      "\tspeed: 0.0399s/iter; left time: 743.0050s\n",
      "\titers: 200, epoch: 17 | loss: 0.0640702\n",
      "\tspeed: 0.0188s/iter; left time: 347.9943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0632551 Vali Loss: 0.0610209 Test Loss: 0.0638186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0611378\n",
      "\tspeed: 0.0352s/iter; left time: 647.5405s\n",
      "\titers: 200, epoch: 18 | loss: 0.0612500\n",
      "\tspeed: 0.0163s/iter; left time: 298.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 223 | Train Loss: 0.0628963 Vali Loss: 0.0606032 Test Loss: 0.0633813\n",
      "Validation loss decreased (0.060893 --> 0.060603).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0647264\n",
      "\tspeed: 0.0346s/iter; left time: 629.6324s\n",
      "\titers: 200, epoch: 19 | loss: 0.0600833\n",
      "\tspeed: 0.0237s/iter; left time: 429.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0627335 Vali Loss: 0.0602867 Test Loss: 0.0629789\n",
      "Validation loss decreased (0.060603 --> 0.060287).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0646587\n",
      "\tspeed: 0.0377s/iter; left time: 677.2722s\n",
      "\titers: 200, epoch: 20 | loss: 0.0656286\n",
      "\tspeed: 0.0170s/iter; left time: 304.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0624415 Vali Loss: 0.0603150 Test Loss: 0.0628516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0615701\n",
      "\tspeed: 0.0410s/iter; left time: 727.4910s\n",
      "\titers: 200, epoch: 21 | loss: 0.0589596\n",
      "\tspeed: 0.0225s/iter; left time: 397.7028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0621869 Vali Loss: 0.0601617 Test Loss: 0.0627929\n",
      "Validation loss decreased (0.060287 --> 0.060162).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0636734\n",
      "\tspeed: 0.0396s/iter; left time: 694.5196s\n",
      "\titers: 200, epoch: 22 | loss: 0.0578523\n",
      "\tspeed: 0.0199s/iter; left time: 345.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0619746 Vali Loss: 0.0602780 Test Loss: 0.0630128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0594606\n",
      "\tspeed: 0.0414s/iter; left time: 716.5139s\n",
      "\titers: 200, epoch: 23 | loss: 0.0620950\n",
      "\tspeed: 0.0196s/iter; left time: 337.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 223 | Train Loss: 0.0617785 Vali Loss: 0.0596992 Test Loss: 0.0623079\n",
      "Validation loss decreased (0.060162 --> 0.059699).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0690234\n",
      "\tspeed: 0.0371s/iter; left time: 633.0893s\n",
      "\titers: 200, epoch: 24 | loss: 0.0567295\n",
      "\tspeed: 0.0180s/iter; left time: 304.8244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0617492 Vali Loss: 0.0594711 Test Loss: 0.0622098\n",
      "Validation loss decreased (0.059699 --> 0.059471).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0596324\n",
      "\tspeed: 0.0396s/iter; left time: 667.6478s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655351\n",
      "\tspeed: 0.0141s/iter; left time: 235.4539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0616514 Vali Loss: 0.0594251 Test Loss: 0.0621977\n",
      "Validation loss decreased (0.059471 --> 0.059425).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628192\n",
      "\tspeed: 0.0420s/iter; left time: 698.4217s\n",
      "\titers: 200, epoch: 26 | loss: 0.0592243\n",
      "\tspeed: 0.0228s/iter; left time: 376.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0613750 Vali Loss: 0.0594440 Test Loss: 0.0619988\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0624912\n",
      "\tspeed: 0.0396s/iter; left time: 648.8176s\n",
      "\titers: 200, epoch: 27 | loss: 0.0627666\n",
      "\tspeed: 0.0202s/iter; left time: 328.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0613563 Vali Loss: 0.0592246 Test Loss: 0.0619628\n",
      "Validation loss decreased (0.059425 --> 0.059225).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0587200\n",
      "\tspeed: 0.0417s/iter; left time: 674.1713s\n",
      "\titers: 200, epoch: 28 | loss: 0.0633633\n",
      "\tspeed: 0.0192s/iter; left time: 308.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0613557 Vali Loss: 0.0592879 Test Loss: 0.0619209\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0608271\n",
      "\tspeed: 0.0365s/iter; left time: 582.5570s\n",
      "\titers: 200, epoch: 29 | loss: 0.0591856\n",
      "\tspeed: 0.0181s/iter; left time: 286.6084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0612707 Vali Loss: 0.0591873 Test Loss: 0.0619315\n",
      "Validation loss decreased (0.059225 --> 0.059187).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0615196\n",
      "\tspeed: 0.0430s/iter; left time: 675.9730s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605555\n",
      "\tspeed: 0.0194s/iter; left time: 304.0369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0611396 Vali Loss: 0.0592256 Test Loss: 0.0619340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0596062\n",
      "\tspeed: 0.0360s/iter; left time: 557.9123s\n",
      "\titers: 200, epoch: 31 | loss: 0.0569538\n",
      "\tspeed: 0.0181s/iter; left time: 278.9208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0612691 Vali Loss: 0.0592210 Test Loss: 0.0618494\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0607494\n",
      "\tspeed: 0.0383s/iter; left time: 585.0867s\n",
      "\titers: 200, epoch: 32 | loss: 0.0604401\n",
      "\tspeed: 0.0182s/iter; left time: 276.4149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0612039 Vali Loss: 0.0591996 Test Loss: 0.0618691\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0621250\n",
      "\tspeed: 0.0422s/iter; left time: 635.6033s\n",
      "\titers: 200, epoch: 33 | loss: 0.0618877\n",
      "\tspeed: 0.0208s/iter; left time: 310.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0609512 Vali Loss: 0.0591121 Test Loss: 0.0617181\n",
      "Validation loss decreased (0.059187 --> 0.059112).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0603437\n",
      "\tspeed: 0.0379s/iter; left time: 562.3203s\n",
      "\titers: 200, epoch: 34 | loss: 0.0601685\n",
      "\tspeed: 0.0194s/iter; left time: 285.7669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0609362 Vali Loss: 0.0589895 Test Loss: 0.0616054\n",
      "Validation loss decreased (0.059112 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0603186\n",
      "\tspeed: 0.0400s/iter; left time: 584.3430s\n",
      "\titers: 200, epoch: 35 | loss: 0.0646182\n",
      "\tspeed: 0.0181s/iter; left time: 262.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0609446 Vali Loss: 0.0590995 Test Loss: 0.0616625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0602006\n",
      "\tspeed: 0.0352s/iter; left time: 506.7713s\n",
      "\titers: 200, epoch: 36 | loss: 0.0625308\n",
      "\tspeed: 0.0180s/iter; left time: 257.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0608464 Vali Loss: 0.0589719 Test Loss: 0.0615951\n",
      "Validation loss decreased (0.058990 --> 0.058972).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0603607\n",
      "\tspeed: 0.0400s/iter; left time: 566.4409s\n",
      "\titers: 200, epoch: 37 | loss: 0.0596195\n",
      "\tspeed: 0.0179s/iter; left time: 252.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0609012 Vali Loss: 0.0589949 Test Loss: 0.0616022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0559763\n",
      "\tspeed: 0.0364s/iter; left time: 507.6343s\n",
      "\titers: 200, epoch: 38 | loss: 0.0637537\n",
      "\tspeed: 0.0179s/iter; left time: 247.2480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0609325 Vali Loss: 0.0590541 Test Loss: 0.0617086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0595457\n",
      "\tspeed: 0.0377s/iter; left time: 518.0286s\n",
      "\titers: 200, epoch: 39 | loss: 0.0604476\n",
      "\tspeed: 0.0172s/iter; left time: 234.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0608642 Vali Loss: 0.0589675 Test Loss: 0.0615786\n",
      "Validation loss decreased (0.058972 --> 0.058967).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0609431\n",
      "\tspeed: 0.0389s/iter; left time: 524.9473s\n",
      "\titers: 200, epoch: 40 | loss: 0.0603043\n",
      "\tspeed: 0.0218s/iter; left time: 291.7962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0608317 Vali Loss: 0.0590068 Test Loss: 0.0616565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0555320\n",
      "\tspeed: 0.0382s/iter; left time: 506.8362s\n",
      "\titers: 200, epoch: 41 | loss: 0.0621905\n",
      "\tspeed: 0.0181s/iter; left time: 238.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0607720 Vali Loss: 0.0589859 Test Loss: 0.0615265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0582666\n",
      "\tspeed: 0.0430s/iter; left time: 561.8562s\n",
      "\titers: 200, epoch: 42 | loss: 0.0639409\n",
      "\tspeed: 0.0249s/iter; left time: 322.0951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.0610027 Vali Loss: 0.0589462 Test Loss: 0.0615786\n",
      "Validation loss decreased (0.058967 --> 0.058946).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0588901\n",
      "\tspeed: 0.0459s/iter; left time: 588.9965s\n",
      "\titers: 200, epoch: 43 | loss: 0.0626445\n",
      "\tspeed: 0.0210s/iter; left time: 267.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0609332 Vali Loss: 0.0589002 Test Loss: 0.0615589\n",
      "Validation loss decreased (0.058946 --> 0.058900).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0600454\n",
      "\tspeed: 0.0379s/iter; left time: 478.5524s\n",
      "\titers: 200, epoch: 44 | loss: 0.1046510\n",
      "\tspeed: 0.0181s/iter; left time: 226.0206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0610308 Vali Loss: 0.0588552 Test Loss: 0.0615211\n",
      "Validation loss decreased (0.058900 --> 0.058855).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0590341\n",
      "\tspeed: 0.0368s/iter; left time: 456.4594s\n",
      "\titers: 200, epoch: 45 | loss: 0.0561302\n",
      "\tspeed: 0.0170s/iter; left time: 208.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0607509 Vali Loss: 0.0588746 Test Loss: 0.0615488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0632354\n",
      "\tspeed: 0.0384s/iter; left time: 467.7416s\n",
      "\titers: 200, epoch: 46 | loss: 0.0581082\n",
      "\tspeed: 0.0161s/iter; left time: 194.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0606966 Vali Loss: 0.0587637 Test Loss: 0.0614949\n",
      "Validation loss decreased (0.058855 --> 0.058764).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0607580\n",
      "\tspeed: 0.0359s/iter; left time: 428.4691s\n",
      "\titers: 200, epoch: 47 | loss: 0.0596933\n",
      "\tspeed: 0.0162s/iter; left time: 192.3513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 223 | Train Loss: 0.0607278 Vali Loss: 0.0589244 Test Loss: 0.0615901\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0610742\n",
      "\tspeed: 0.0352s/iter; left time: 412.8788s\n",
      "\titers: 200, epoch: 48 | loss: 0.0582518\n",
      "\tspeed: 0.0170s/iter; left time: 197.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0607390 Vali Loss: 0.0589122 Test Loss: 0.0614438\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0593468\n",
      "\tspeed: 0.0370s/iter; left time: 425.1048s\n",
      "\titers: 200, epoch: 49 | loss: 0.0615602\n",
      "\tspeed: 0.0182s/iter; left time: 207.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0606177 Vali Loss: 0.0589179 Test Loss: 0.0615362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0635054\n",
      "\tspeed: 0.0349s/iter; left time: 393.6747s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601768\n",
      "\tspeed: 0.0173s/iter; left time: 192.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.0606796 Vali Loss: 0.0588843 Test Loss: 0.0614741\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0623859\n",
      "\tspeed: 0.0363s/iter; left time: 401.1339s\n",
      "\titers: 200, epoch: 51 | loss: 0.0601044\n",
      "\tspeed: 0.0165s/iter; left time: 180.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 223 | Train Loss: 0.0606953 Vali Loss: 0.0589977 Test Loss: 0.0615234\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0615386\n",
      "\tspeed: 0.0349s/iter; left time: 377.6789s\n",
      "\titers: 200, epoch: 52 | loss: 0.0631368\n",
      "\tspeed: 0.0175s/iter; left time: 187.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 223 | Train Loss: 0.0606984 Vali Loss: 0.0588911 Test Loss: 0.0615143\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0584038\n",
      "\tspeed: 0.0376s/iter; left time: 398.4644s\n",
      "\titers: 200, epoch: 53 | loss: 0.0576594\n",
      "\tspeed: 0.0165s/iter; left time: 173.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0606154 Vali Loss: 0.0588870 Test Loss: 0.0614664\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0589344\n",
      "\tspeed: 0.0372s/iter; left time: 386.2274s\n",
      "\titers: 200, epoch: 54 | loss: 0.0547111\n",
      "\tspeed: 0.0166s/iter; left time: 170.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 223 | Train Loss: 0.0607150 Vali Loss: 0.0588331 Test Loss: 0.0613789\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0620313\n",
      "\tspeed: 0.0375s/iter; left time: 380.5142s\n",
      "\titers: 200, epoch: 55 | loss: 0.0646649\n",
      "\tspeed: 0.0192s/iter; left time: 192.6545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 223 | Train Loss: 0.0606030 Vali Loss: 0.0587150 Test Loss: 0.0614655\n",
      "Validation loss decreased (0.058764 --> 0.058715).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0569904\n",
      "\tspeed: 0.0426s/iter; left time: 422.8624s\n",
      "\titers: 200, epoch: 56 | loss: 0.0611081\n",
      "\tspeed: 0.0230s/iter; left time: 226.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0606916 Vali Loss: 0.0588263 Test Loss: 0.0614581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0595710\n",
      "\tspeed: 0.0409s/iter; left time: 396.8339s\n",
      "\titers: 200, epoch: 57 | loss: 0.0569403\n",
      "\tspeed: 0.0176s/iter; left time: 169.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0606114 Vali Loss: 0.0589005 Test Loss: 0.0614607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0623064\n",
      "\tspeed: 0.0362s/iter; left time: 343.0670s\n",
      "\titers: 200, epoch: 58 | loss: 0.0560119\n",
      "\tspeed: 0.0135s/iter; left time: 126.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0606619 Vali Loss: 0.0588734 Test Loss: 0.0614025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599943\n",
      "\tspeed: 0.0318s/iter; left time: 294.5774s\n",
      "\titers: 200, epoch: 59 | loss: 0.0617816\n",
      "\tspeed: 0.0137s/iter; left time: 125.3198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 223 | Train Loss: 0.0606414 Vali Loss: 0.0589361 Test Loss: 0.0615093\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0620856\n",
      "\tspeed: 0.0327s/iter; left time: 295.8749s\n",
      "\titers: 200, epoch: 60 | loss: 0.0578703\n",
      "\tspeed: 0.0134s/iter; left time: 119.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 223 | Train Loss: 0.0605521 Vali Loss: 0.0587123 Test Loss: 0.0614363\n",
      "Validation loss decreased (0.058715 --> 0.058712).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0607122\n",
      "\tspeed: 0.0398s/iter; left time: 351.1022s\n",
      "\titers: 200, epoch: 61 | loss: 0.0573786\n",
      "\tspeed: 0.0207s/iter; left time: 180.5030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 223 | Train Loss: 0.0608720 Vali Loss: 0.0588446 Test Loss: 0.0614883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0623740\n",
      "\tspeed: 0.0381s/iter; left time: 327.3114s\n",
      "\titers: 200, epoch: 62 | loss: 0.0598484\n",
      "\tspeed: 0.0194s/iter; left time: 165.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0606050 Vali Loss: 0.0591069 Test Loss: 0.0615584\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0644612\n",
      "\tspeed: 0.0376s/iter; left time: 315.0518s\n",
      "\titers: 200, epoch: 63 | loss: 0.0653639\n",
      "\tspeed: 0.0185s/iter; left time: 153.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0605841 Vali Loss: 0.0587080 Test Loss: 0.0614095\n",
      "Validation loss decreased (0.058712 --> 0.058708).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0615636\n",
      "\tspeed: 0.0343s/iter; left time: 279.9657s\n",
      "\titers: 200, epoch: 64 | loss: 0.0612560\n",
      "\tspeed: 0.0165s/iter; left time: 132.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0605828 Vali Loss: 0.0587152 Test Loss: 0.0614149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0568213\n",
      "\tspeed: 0.0396s/iter; left time: 313.6726s\n",
      "\titers: 200, epoch: 65 | loss: 0.0580689\n",
      "\tspeed: 0.0230s/iter; left time: 180.1116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0607041 Vali Loss: 0.0586771 Test Loss: 0.0613749\n",
      "Validation loss decreased (0.058708 --> 0.058677).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0628402\n",
      "\tspeed: 0.0414s/iter; left time: 318.6574s\n",
      "\titers: 200, epoch: 66 | loss: 0.0586477\n",
      "\tspeed: 0.0203s/iter; left time: 154.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 223 | Train Loss: 0.0607409 Vali Loss: 0.0588695 Test Loss: 0.0614378\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0559702\n",
      "\tspeed: 0.0391s/iter; left time: 292.9200s\n",
      "\titers: 200, epoch: 67 | loss: 0.0600595\n",
      "\tspeed: 0.0198s/iter; left time: 146.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 223 | Train Loss: 0.0606207 Vali Loss: 0.0585862 Test Loss: 0.0613823\n",
      "Validation loss decreased (0.058677 --> 0.058586).  Saving model ...\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0625885\n",
      "\tspeed: 0.0431s/iter; left time: 313.2601s\n",
      "\titers: 200, epoch: 68 | loss: 0.0582105\n",
      "\tspeed: 0.0218s/iter; left time: 156.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0605603 Vali Loss: 0.0588540 Test Loss: 0.0613979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0585478\n",
      "\tspeed: 0.0412s/iter; left time: 290.0355s\n",
      "\titers: 200, epoch: 69 | loss: 0.0620088\n",
      "\tspeed: 0.0208s/iter; left time: 144.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.0605951 Vali Loss: 0.0588253 Test Loss: 0.0614400\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0557343\n",
      "\tspeed: 0.0390s/iter; left time: 265.7572s\n",
      "\titers: 200, epoch: 70 | loss: 0.0634730\n",
      "\tspeed: 0.0135s/iter; left time: 90.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0605650 Vali Loss: 0.0588185 Test Loss: 0.0613799\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0574628\n",
      "\tspeed: 0.0458s/iter; left time: 301.6564s\n",
      "\titers: 200, epoch: 71 | loss: 0.0592117\n",
      "\tspeed: 0.0243s/iter; left time: 157.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0605581 Vali Loss: 0.0588350 Test Loss: 0.0614624\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0650221\n",
      "\tspeed: 0.0372s/iter; left time: 237.1534s\n",
      "\titers: 200, epoch: 72 | loss: 0.0582021\n",
      "\tspeed: 0.0258s/iter; left time: 161.9741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0606202 Vali Loss: 0.0587745 Test Loss: 0.0614244\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0613363\n",
      "\tspeed: 0.0440s/iter; left time: 270.5594s\n",
      "\titers: 200, epoch: 73 | loss: 0.0613006\n",
      "\tspeed: 0.0247s/iter; left time: 149.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 223 | Train Loss: 0.0606940 Vali Loss: 0.0588042 Test Loss: 0.0614254\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0612068\n",
      "\tspeed: 0.0432s/iter; left time: 255.6201s\n",
      "\titers: 200, epoch: 74 | loss: 0.0589065\n",
      "\tspeed: 0.0272s/iter; left time: 158.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0606161 Vali Loss: 0.0588119 Test Loss: 0.0614026\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0618147\n",
      "\tspeed: 0.0403s/iter; left time: 229.7094s\n",
      "\titers: 200, epoch: 75 | loss: 0.0583402\n",
      "\tspeed: 0.0159s/iter; left time: 89.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0606162 Vali Loss: 0.0586362 Test Loss: 0.0613888\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0625675\n",
      "\tspeed: 0.0343s/iter; left time: 187.7279s\n",
      "\titers: 200, epoch: 76 | loss: 0.0587865\n",
      "\tspeed: 0.0174s/iter; left time: 93.5347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.0605983 Vali Loss: 0.0586669 Test Loss: 0.0613694\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0594551\n",
      "\tspeed: 0.0366s/iter; left time: 192.0072s\n",
      "\titers: 200, epoch: 77 | loss: 0.0578571\n",
      "\tspeed: 0.0176s/iter; left time: 90.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0606334 Vali Loss: 0.0589045 Test Loss: 0.0614488\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010739559307694435, rmse:0.10363184660673141, mae:0.061382316052913666, rse:0.3915736973285675\n",
      "Intermediate time for IT and pred_len 24: 00h:14m:04.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2649924\n",
      "\tspeed: 0.0420s/iter; left time: 928.3279s\n",
      "\titers: 200, epoch: 1 | loss: 0.2459004\n",
      "\tspeed: 0.0136s/iter; left time: 299.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 222 | Train Loss: 0.2686695 Vali Loss: 0.1882363 Test Loss: 0.1964827\n",
      "Validation loss decreased (inf --> 0.188236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1441561\n",
      "\tspeed: 0.0350s/iter; left time: 764.6951s\n",
      "\titers: 200, epoch: 2 | loss: 0.1169897\n",
      "\tspeed: 0.0175s/iter; left time: 380.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.1534727 Vali Loss: 0.1040274 Test Loss: 0.1094590\n",
      "Validation loss decreased (0.188236 --> 0.104027).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072947\n",
      "\tspeed: 0.0395s/iter; left time: 854.8735s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013600\n",
      "\tspeed: 0.0228s/iter; left time: 492.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 222 | Train Loss: 0.1083181 Vali Loss: 0.0932522 Test Loss: 0.0968188\n",
      "Validation loss decreased (0.104027 --> 0.093252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962329\n",
      "\tspeed: 0.0402s/iter; left time: 862.5547s\n",
      "\titers: 200, epoch: 4 | loss: 0.0919321\n",
      "\tspeed: 0.0215s/iter; left time: 458.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0968963 Vali Loss: 0.0879308 Test Loss: 0.0922515\n",
      "Validation loss decreased (0.093252 --> 0.087931).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0865197\n",
      "\tspeed: 0.0469s/iter; left time: 993.9724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0907869\n",
      "\tspeed: 0.0204s/iter; left time: 431.0063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 222 | Train Loss: 0.0917756 Vali Loss: 0.0851810 Test Loss: 0.0912936\n",
      "Validation loss decreased (0.087931 --> 0.085181).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0886005\n",
      "\tspeed: 0.0391s/iter; left time: 820.0371s\n",
      "\titers: 200, epoch: 6 | loss: 0.0916665\n",
      "\tspeed: 0.0175s/iter; left time: 365.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 222 | Train Loss: 0.0891103 Vali Loss: 0.0829898 Test Loss: 0.0884985\n",
      "Validation loss decreased (0.085181 --> 0.082990).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0885330\n",
      "\tspeed: 0.0419s/iter; left time: 870.1273s\n",
      "\titers: 200, epoch: 7 | loss: 0.0854654\n",
      "\tspeed: 0.0135s/iter; left time: 278.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0865712 Vali Loss: 0.0822678 Test Loss: 0.0874631\n",
      "Validation loss decreased (0.082990 --> 0.082268).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0859759\n",
      "\tspeed: 0.0386s/iter; left time: 793.2709s\n",
      "\titers: 200, epoch: 8 | loss: 0.0871206\n",
      "\tspeed: 0.0202s/iter; left time: 413.0781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0855049 Vali Loss: 0.0819314 Test Loss: 0.0872992\n",
      "Validation loss decreased (0.082268 --> 0.081931).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820930\n",
      "\tspeed: 0.0426s/iter; left time: 865.6925s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811692\n",
      "\tspeed: 0.0189s/iter; left time: 381.4725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0844211 Vali Loss: 0.0812641 Test Loss: 0.0868622\n",
      "Validation loss decreased (0.081931 --> 0.081264).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0790341\n",
      "\tspeed: 0.0399s/iter; left time: 801.8800s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847388\n",
      "\tspeed: 0.0206s/iter; left time: 413.0208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0832799 Vali Loss: 0.0799906 Test Loss: 0.0853632\n",
      "Validation loss decreased (0.081264 --> 0.079991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803370\n",
      "\tspeed: 0.0381s/iter; left time: 757.0258s\n",
      "\titers: 200, epoch: 11 | loss: 0.0803964\n",
      "\tspeed: 0.0205s/iter; left time: 405.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 222 | Train Loss: 0.0829627 Vali Loss: 0.0797984 Test Loss: 0.0852156\n",
      "Validation loss decreased (0.079991 --> 0.079798).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0796728\n",
      "\tspeed: 0.0404s/iter; left time: 794.8829s\n",
      "\titers: 200, epoch: 12 | loss: 0.0812863\n",
      "\tspeed: 0.0183s/iter; left time: 357.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0821226 Vali Loss: 0.0798440 Test Loss: 0.0849899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0798728\n",
      "\tspeed: 0.0372s/iter; left time: 722.8924s\n",
      "\titers: 200, epoch: 13 | loss: 0.0777141\n",
      "\tspeed: 0.0182s/iter; left time: 352.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0815629 Vali Loss: 0.0792634 Test Loss: 0.0848526\n",
      "Validation loss decreased (0.079798 --> 0.079263).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0809462\n",
      "\tspeed: 0.0356s/iter; left time: 684.4287s\n",
      "\titers: 200, epoch: 14 | loss: 0.0796807\n",
      "\tspeed: 0.0167s/iter; left time: 319.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0815085 Vali Loss: 0.0793738 Test Loss: 0.0847474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0786198\n",
      "\tspeed: 0.0361s/iter; left time: 685.5784s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829225\n",
      "\tspeed: 0.0178s/iter; left time: 335.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0811071 Vali Loss: 0.0794846 Test Loss: 0.0848899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779483\n",
      "\tspeed: 0.0365s/iter; left time: 685.1791s\n",
      "\titers: 200, epoch: 16 | loss: 0.0778324\n",
      "\tspeed: 0.0171s/iter; left time: 319.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.0806298 Vali Loss: 0.0789060 Test Loss: 0.0839967\n",
      "Validation loss decreased (0.079263 --> 0.078906).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808630\n",
      "\tspeed: 0.0401s/iter; left time: 744.2082s\n",
      "\titers: 200, epoch: 17 | loss: 0.0814597\n",
      "\tspeed: 0.0167s/iter; left time: 308.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0803956 Vali Loss: 0.0786776 Test Loss: 0.0840534\n",
      "Validation loss decreased (0.078906 --> 0.078678).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0810252\n",
      "\tspeed: 0.0352s/iter; left time: 645.6981s\n",
      "\titers: 200, epoch: 18 | loss: 0.0778031\n",
      "\tspeed: 0.0168s/iter; left time: 305.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0800587 Vali Loss: 0.0797229 Test Loss: 0.0852232\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0798354\n",
      "\tspeed: 0.0369s/iter; left time: 667.7635s\n",
      "\titers: 200, epoch: 19 | loss: 0.0803785\n",
      "\tspeed: 0.0178s/iter; left time: 320.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0802608 Vali Loss: 0.0786860 Test Loss: 0.0842426\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790615\n",
      "\tspeed: 0.0349s/iter; left time: 624.9169s\n",
      "\titers: 200, epoch: 20 | loss: 0.0815033\n",
      "\tspeed: 0.0176s/iter; left time: 312.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.0801266 Vali Loss: 0.0794325 Test Loss: 0.0848554\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0828814\n",
      "\tspeed: 0.0379s/iter; left time: 670.1954s\n",
      "\titers: 200, epoch: 21 | loss: 0.0766421\n",
      "\tspeed: 0.0200s/iter; left time: 351.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 222 | Train Loss: 0.0796026 Vali Loss: 0.0787944 Test Loss: 0.0840462\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0806132\n",
      "\tspeed: 0.0381s/iter; left time: 664.9116s\n",
      "\titers: 200, epoch: 22 | loss: 0.0732058\n",
      "\tspeed: 0.0181s/iter; left time: 313.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 222 | Train Loss: 0.0794383 Vali Loss: 0.0783449 Test Loss: 0.0838791\n",
      "Validation loss decreased (0.078678 --> 0.078345).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0789208\n",
      "\tspeed: 0.0406s/iter; left time: 698.4087s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793016\n",
      "\tspeed: 0.0202s/iter; left time: 345.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0794405 Vali Loss: 0.0784126 Test Loss: 0.0839449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0791395\n",
      "\tspeed: 0.0380s/iter; left time: 646.0515s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773762\n",
      "\tspeed: 0.0214s/iter; left time: 360.7964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 222 | Train Loss: 0.0791259 Vali Loss: 0.0781696 Test Loss: 0.0836211\n",
      "Validation loss decreased (0.078345 --> 0.078170).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758062\n",
      "\tspeed: 0.0402s/iter; left time: 674.9030s\n",
      "\titers: 200, epoch: 25 | loss: 0.0766327\n",
      "\tspeed: 0.0191s/iter; left time: 318.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 222 | Train Loss: 0.0792004 Vali Loss: 0.0779855 Test Loss: 0.0835670\n",
      "Validation loss decreased (0.078170 --> 0.077986).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0784141\n",
      "\tspeed: 0.0405s/iter; left time: 670.7408s\n",
      "\titers: 200, epoch: 26 | loss: 0.0779995\n",
      "\tspeed: 0.0197s/iter; left time: 324.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 222 | Train Loss: 0.0790333 Vali Loss: 0.0779703 Test Loss: 0.0835893\n",
      "Validation loss decreased (0.077986 --> 0.077970).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0801988\n",
      "\tspeed: 0.0367s/iter; left time: 598.4592s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799192\n",
      "\tspeed: 0.0188s/iter; left time: 305.5998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0789634 Vali Loss: 0.0785433 Test Loss: 0.0841170\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809430\n",
      "\tspeed: 0.0420s/iter; left time: 677.1315s\n",
      "\titers: 200, epoch: 28 | loss: 0.0762430\n",
      "\tspeed: 0.0175s/iter; left time: 280.7957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0788614 Vali Loss: 0.0783323 Test Loss: 0.0840029\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777347\n",
      "\tspeed: 0.0360s/iter; left time: 572.1787s\n",
      "\titers: 200, epoch: 29 | loss: 0.0806854\n",
      "\tspeed: 0.0171s/iter; left time: 269.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0787451 Vali Loss: 0.0779039 Test Loss: 0.0834712\n",
      "Validation loss decreased (0.077970 --> 0.077904).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778239\n",
      "\tspeed: 0.0393s/iter; left time: 614.9592s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771591\n",
      "\tspeed: 0.0170s/iter; left time: 264.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0786864 Vali Loss: 0.0778701 Test Loss: 0.0835060\n",
      "Validation loss decreased (0.077904 --> 0.077870).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0817337\n",
      "\tspeed: 0.0393s/iter; left time: 607.2707s\n",
      "\titers: 200, epoch: 31 | loss: 0.0799501\n",
      "\tspeed: 0.0176s/iter; left time: 269.4728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0787699 Vali Loss: 0.0783857 Test Loss: 0.0838893\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0790439\n",
      "\tspeed: 0.0425s/iter; left time: 646.8010s\n",
      "\titers: 200, epoch: 32 | loss: 0.0774869\n",
      "\tspeed: 0.0202s/iter; left time: 305.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 222 | Train Loss: 0.0786186 Vali Loss: 0.0779820 Test Loss: 0.0836114\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0805306\n",
      "\tspeed: 0.0445s/iter; left time: 667.3080s\n",
      "\titers: 200, epoch: 33 | loss: 0.0801780\n",
      "\tspeed: 0.0233s/iter; left time: 347.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 222 | Train Loss: 0.0785689 Vali Loss: 0.0782035 Test Loss: 0.0835488\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0788253\n",
      "\tspeed: 0.0474s/iter; left time: 699.8895s\n",
      "\titers: 200, epoch: 34 | loss: 0.0753295\n",
      "\tspeed: 0.0188s/iter; left time: 275.8263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 222 | Train Loss: 0.0787260 Vali Loss: 0.0779253 Test Loss: 0.0836682\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768477\n",
      "\tspeed: 0.0414s/iter; left time: 601.9171s\n",
      "\titers: 200, epoch: 35 | loss: 0.0769447\n",
      "\tspeed: 0.0162s/iter; left time: 233.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0785765 Vali Loss: 0.0782844 Test Loss: 0.0838309\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0795754\n",
      "\tspeed: 0.0369s/iter; left time: 529.1381s\n",
      "\titers: 200, epoch: 36 | loss: 0.0797847\n",
      "\tspeed: 0.0203s/iter; left time: 289.3174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0785016 Vali Loss: 0.0780071 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0832342\n",
      "\tspeed: 0.0398s/iter; left time: 561.0689s\n",
      "\titers: 200, epoch: 37 | loss: 0.0774548\n",
      "\tspeed: 0.0178s/iter; left time: 249.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0784543 Vali Loss: 0.0779903 Test Loss: 0.0835282\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802678\n",
      "\tspeed: 0.0400s/iter; left time: 555.3109s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797945\n",
      "\tspeed: 0.0170s/iter; left time: 234.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0783770 Vali Loss: 0.0781965 Test Loss: 0.0838084\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0735248\n",
      "\tspeed: 0.0381s/iter; left time: 520.0045s\n",
      "\titers: 200, epoch: 39 | loss: 0.0799417\n",
      "\tspeed: 0.0173s/iter; left time: 234.9289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0783900 Vali Loss: 0.0778958 Test Loss: 0.0835715\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0789938\n",
      "\tspeed: 0.0385s/iter; left time: 517.6762s\n",
      "\titers: 200, epoch: 40 | loss: 0.0747399\n",
      "\tspeed: 0.0163s/iter; left time: 217.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0784124 Vali Loss: 0.0780216 Test Loss: 0.0836652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018412597477436066, rmse:0.1356930285692215, mae:0.08350596576929092, rse:0.5130699276924133\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2669699\n",
      "\tspeed: 0.0244s/iter; left time: 540.1559s\n",
      "\titers: 200, epoch: 1 | loss: 0.2450630\n",
      "\tspeed: 0.0187s/iter; left time: 412.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.2744923 Vali Loss: 0.1891254 Test Loss: 0.1977536\n",
      "Validation loss decreased (inf --> 0.189125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1374452\n",
      "\tspeed: 0.0379s/iter; left time: 828.2597s\n",
      "\titers: 200, epoch: 2 | loss: 0.1209822\n",
      "\tspeed: 0.0178s/iter; left time: 388.1321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 222 | Train Loss: 0.1514843 Vali Loss: 0.1045871 Test Loss: 0.1098326\n",
      "Validation loss decreased (0.189125 --> 0.104587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1118573\n",
      "\tspeed: 0.0373s/iter; left time: 807.4754s\n",
      "\titers: 200, epoch: 3 | loss: 0.1030534\n",
      "\tspeed: 0.0189s/iter; left time: 408.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.1093698 Vali Loss: 0.0961750 Test Loss: 0.1004811\n",
      "Validation loss decreased (0.104587 --> 0.096175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1103015\n",
      "\tspeed: 0.0392s/iter; left time: 840.6055s\n",
      "\titers: 200, epoch: 4 | loss: 0.0936483\n",
      "\tspeed: 0.0175s/iter; left time: 374.2352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0980030 Vali Loss: 0.0882828 Test Loss: 0.0927319\n",
      "Validation loss decreased (0.096175 --> 0.088283).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0889753\n",
      "\tspeed: 0.0360s/iter; left time: 762.8967s\n",
      "\titers: 200, epoch: 5 | loss: 0.0982663\n",
      "\tspeed: 0.0137s/iter; left time: 289.2362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 222 | Train Loss: 0.0919368 Vali Loss: 0.0855115 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.088283 --> 0.085512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839968\n",
      "\tspeed: 0.0363s/iter; left time: 762.4019s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844622\n",
      "\tspeed: 0.0169s/iter; left time: 353.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0886087 Vali Loss: 0.0842759 Test Loss: 0.0881643\n",
      "Validation loss decreased (0.085512 --> 0.084276).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0870719\n",
      "\tspeed: 0.0383s/iter; left time: 795.8849s\n",
      "\titers: 200, epoch: 7 | loss: 0.0901598\n",
      "\tspeed: 0.0187s/iter; left time: 386.2348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0869783 Vali Loss: 0.0831270 Test Loss: 0.0881475\n",
      "Validation loss decreased (0.084276 --> 0.083127).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0868821\n",
      "\tspeed: 0.0387s/iter; left time: 794.6604s\n",
      "\titers: 200, epoch: 8 | loss: 0.0865162\n",
      "\tspeed: 0.0165s/iter; left time: 336.8896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0854771 Vali Loss: 0.0816712 Test Loss: 0.0865686\n",
      "Validation loss decreased (0.083127 --> 0.081671).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0851794\n",
      "\tspeed: 0.0338s/iter; left time: 686.6107s\n",
      "\titers: 200, epoch: 9 | loss: 0.0889486\n",
      "\tspeed: 0.0136s/iter; left time: 274.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 222 | Train Loss: 0.0842140 Vali Loss: 0.0809032 Test Loss: 0.0862001\n",
      "Validation loss decreased (0.081671 --> 0.080903).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0884752\n",
      "\tspeed: 0.0422s/iter; left time: 849.1534s\n",
      "\titers: 200, epoch: 10 | loss: 0.0834779\n",
      "\tspeed: 0.0182s/iter; left time: 364.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0834075 Vali Loss: 0.0806109 Test Loss: 0.0853274\n",
      "Validation loss decreased (0.080903 --> 0.080611).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0813067\n",
      "\tspeed: 0.0373s/iter; left time: 742.4979s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809828\n",
      "\tspeed: 0.0221s/iter; left time: 436.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 222 | Train Loss: 0.0828738 Vali Loss: 0.0803249 Test Loss: 0.0854242\n",
      "Validation loss decreased (0.080611 --> 0.080325).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787641\n",
      "\tspeed: 0.0421s/iter; left time: 827.5186s\n",
      "\titers: 200, epoch: 12 | loss: 0.0846575\n",
      "\tspeed: 0.0204s/iter; left time: 399.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 222 | Train Loss: 0.0823977 Vali Loss: 0.0802869 Test Loss: 0.0853479\n",
      "Validation loss decreased (0.080325 --> 0.080287).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0806332\n",
      "\tspeed: 0.0392s/iter; left time: 762.4969s\n",
      "\titers: 200, epoch: 13 | loss: 0.0780229\n",
      "\tspeed: 0.0176s/iter; left time: 340.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 222 | Train Loss: 0.0821032 Vali Loss: 0.0796546 Test Loss: 0.0850520\n",
      "Validation loss decreased (0.080287 --> 0.079655).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807278\n",
      "\tspeed: 0.0398s/iter; left time: 765.6458s\n",
      "\titers: 200, epoch: 14 | loss: 0.0801523\n",
      "\tspeed: 0.0212s/iter; left time: 405.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 222 | Train Loss: 0.0814515 Vali Loss: 0.0793224 Test Loss: 0.0846003\n",
      "Validation loss decreased (0.079655 --> 0.079322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0811834\n",
      "\tspeed: 0.0388s/iter; left time: 737.8128s\n",
      "\titers: 200, epoch: 15 | loss: 0.0824905\n",
      "\tspeed: 0.0202s/iter; left time: 381.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0811528 Vali Loss: 0.0791987 Test Loss: 0.0847875\n",
      "Validation loss decreased (0.079322 --> 0.079199).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0812803\n",
      "\tspeed: 0.0381s/iter; left time: 714.8382s\n",
      "\titers: 200, epoch: 16 | loss: 0.0791309\n",
      "\tspeed: 0.0170s/iter; left time: 316.7763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0812663 Vali Loss: 0.0791264 Test Loss: 0.0847761\n",
      "Validation loss decreased (0.079199 --> 0.079126).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814442\n",
      "\tspeed: 0.0350s/iter; left time: 648.6126s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843137\n",
      "\tspeed: 0.0148s/iter; left time: 272.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0805641 Vali Loss: 0.0793165 Test Loss: 0.0850676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781366\n",
      "\tspeed: 0.0423s/iter; left time: 774.7343s\n",
      "\titers: 200, epoch: 18 | loss: 0.0777626\n",
      "\tspeed: 0.0218s/iter; left time: 397.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0801775 Vali Loss: 0.0786415 Test Loss: 0.0847553\n",
      "Validation loss decreased (0.079126 --> 0.078641).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766904\n",
      "\tspeed: 0.0384s/iter; left time: 694.8109s\n",
      "\titers: 200, epoch: 19 | loss: 0.0786663\n",
      "\tspeed: 0.0164s/iter; left time: 294.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.0800585 Vali Loss: 0.0784111 Test Loss: 0.0842944\n",
      "Validation loss decreased (0.078641 --> 0.078411).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0812891\n",
      "\tspeed: 0.0364s/iter; left time: 650.5121s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824140\n",
      "\tspeed: 0.0200s/iter; left time: 356.0203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0798285 Vali Loss: 0.0785157 Test Loss: 0.0841717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0775364\n",
      "\tspeed: 0.0364s/iter; left time: 643.6330s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771284\n",
      "\tspeed: 0.0181s/iter; left time: 317.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0796215 Vali Loss: 0.0784598 Test Loss: 0.0844882\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0826520\n",
      "\tspeed: 0.0387s/iter; left time: 674.5753s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745289\n",
      "\tspeed: 0.0180s/iter; left time: 312.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0794640 Vali Loss: 0.0783014 Test Loss: 0.0844967\n",
      "Validation loss decreased (0.078411 --> 0.078301).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0809165\n",
      "\tspeed: 0.0373s/iter; left time: 642.1949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0799347\n",
      "\tspeed: 0.0135s/iter; left time: 230.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 222 | Train Loss: 0.0792830 Vali Loss: 0.0785589 Test Loss: 0.0841373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0753420\n",
      "\tspeed: 0.0321s/iter; left time: 545.0886s\n",
      "\titers: 200, epoch: 24 | loss: 0.0770513\n",
      "\tspeed: 0.0135s/iter; left time: 227.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 222 | Train Loss: 0.0792857 Vali Loss: 0.0784758 Test Loss: 0.0841427\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0783725\n",
      "\tspeed: 0.0401s/iter; left time: 673.1254s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784349\n",
      "\tspeed: 0.0204s/iter; left time: 339.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0791210 Vali Loss: 0.0780171 Test Loss: 0.0841317\n",
      "Validation loss decreased (0.078301 --> 0.078017).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799472\n",
      "\tspeed: 0.0383s/iter; left time: 633.4782s\n",
      "\titers: 200, epoch: 26 | loss: 0.0803593\n",
      "\tspeed: 0.0181s/iter; left time: 297.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 222 | Train Loss: 0.0792566 Vali Loss: 0.0783194 Test Loss: 0.0843090\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0800453\n",
      "\tspeed: 0.0378s/iter; left time: 616.9650s\n",
      "\titers: 200, epoch: 27 | loss: 0.0855692\n",
      "\tspeed: 0.0191s/iter; left time: 309.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 222 | Train Loss: 0.0790418 Vali Loss: 0.0781827 Test Loss: 0.0844223\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802417\n",
      "\tspeed: 0.0384s/iter; left time: 617.8379s\n",
      "\titers: 200, epoch: 28 | loss: 0.0781306\n",
      "\tspeed: 0.0135s/iter; left time: 215.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 222 | Train Loss: 0.0789394 Vali Loss: 0.0781281 Test Loss: 0.0844924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744723\n",
      "\tspeed: 0.0372s/iter; left time: 591.3120s\n",
      "\titers: 200, epoch: 29 | loss: 0.0800503\n",
      "\tspeed: 0.0194s/iter; left time: 306.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0787147 Vali Loss: 0.0782186 Test Loss: 0.0847710\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0786771\n",
      "\tspeed: 0.0379s/iter; left time: 594.1609s\n",
      "\titers: 200, epoch: 30 | loss: 0.0785042\n",
      "\tspeed: 0.0178s/iter; left time: 276.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 222 | Train Loss: 0.0788852 Vali Loss: 0.0782980 Test Loss: 0.0843329\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0824540\n",
      "\tspeed: 0.0371s/iter; left time: 572.8120s\n",
      "\titers: 200, epoch: 31 | loss: 0.0787745\n",
      "\tspeed: 0.0197s/iter; left time: 302.4883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 222 | Train Loss: 0.0787516 Vali Loss: 0.0781605 Test Loss: 0.0843612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0798231\n",
      "\tspeed: 0.0397s/iter; left time: 604.3505s\n",
      "\titers: 200, epoch: 32 | loss: 0.0795925\n",
      "\tspeed: 0.0173s/iter; left time: 261.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0785447 Vali Loss: 0.0779584 Test Loss: 0.0845215\n",
      "Validation loss decreased (0.078017 --> 0.077958).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0787936\n",
      "\tspeed: 0.0402s/iter; left time: 602.6713s\n",
      "\titers: 200, epoch: 33 | loss: 0.0770558\n",
      "\tspeed: 0.0181s/iter; left time: 270.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 222 | Train Loss: 0.0785042 Vali Loss: 0.0779346 Test Loss: 0.0844570\n",
      "Validation loss decreased (0.077958 --> 0.077935).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0774692\n",
      "\tspeed: 0.0396s/iter; left time: 584.4051s\n",
      "\titers: 200, epoch: 34 | loss: 0.0759537\n",
      "\tspeed: 0.0219s/iter; left time: 320.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 222 | Train Loss: 0.0784329 Vali Loss: 0.0780995 Test Loss: 0.0843573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768622\n",
      "\tspeed: 0.0382s/iter; left time: 555.5305s\n",
      "\titers: 200, epoch: 35 | loss: 0.0767152\n",
      "\tspeed: 0.0178s/iter; left time: 257.0064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 222 | Train Loss: 0.0785559 Vali Loss: 0.0779781 Test Loss: 0.0841425\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0778051\n",
      "\tspeed: 0.0415s/iter; left time: 594.8845s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777113\n",
      "\tspeed: 0.0172s/iter; left time: 245.1256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0784720 Vali Loss: 0.0779585 Test Loss: 0.0843921\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0785430\n",
      "\tspeed: 0.0399s/iter; left time: 562.8869s\n",
      "\titers: 200, epoch: 37 | loss: 0.0810425\n",
      "\tspeed: 0.0162s/iter; left time: 227.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0784679 Vali Loss: 0.0778323 Test Loss: 0.0842875\n",
      "Validation loss decreased (0.077935 --> 0.077832).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802566\n",
      "\tspeed: 0.0383s/iter; left time: 531.7475s\n",
      "\titers: 200, epoch: 38 | loss: 0.0764927\n",
      "\tspeed: 0.0181s/iter; left time: 250.1771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0783907 Vali Loss: 0.0779225 Test Loss: 0.0842849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0792846\n",
      "\tspeed: 0.0334s/iter; left time: 456.1727s\n",
      "\titers: 200, epoch: 39 | loss: 0.0809628\n",
      "\tspeed: 0.0148s/iter; left time: 200.9608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0784432 Vali Loss: 0.0779092 Test Loss: 0.0843623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0783319\n",
      "\tspeed: 0.0432s/iter; left time: 580.5300s\n",
      "\titers: 200, epoch: 40 | loss: 0.0799557\n",
      "\tspeed: 0.0203s/iter; left time: 271.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.0784310 Vali Loss: 0.0777476 Test Loss: 0.0844199\n",
      "Validation loss decreased (0.077832 --> 0.077748).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762456\n",
      "\tspeed: 0.0444s/iter; left time: 586.6659s\n",
      "\titers: 200, epoch: 41 | loss: 0.0742338\n",
      "\tspeed: 0.0194s/iter; left time: 254.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0783518 Vali Loss: 0.0777561 Test Loss: 0.0841875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0770126\n",
      "\tspeed: 0.0389s/iter; left time: 505.7553s\n",
      "\titers: 200, epoch: 42 | loss: 0.0793621\n",
      "\tspeed: 0.0182s/iter; left time: 235.2909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 222 | Train Loss: 0.0783116 Vali Loss: 0.0775457 Test Loss: 0.0842376\n",
      "Validation loss decreased (0.077748 --> 0.077546).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0780495\n",
      "\tspeed: 0.0369s/iter; left time: 470.8740s\n",
      "\titers: 200, epoch: 43 | loss: 0.0755535\n",
      "\tspeed: 0.0163s/iter; left time: 206.6457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 222 | Train Loss: 0.0781984 Vali Loss: 0.0777200 Test Loss: 0.0841385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0757912\n",
      "\tspeed: 0.0373s/iter; left time: 468.3455s\n",
      "\titers: 200, epoch: 44 | loss: 0.0804827\n",
      "\tspeed: 0.0182s/iter; left time: 227.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0785006 Vali Loss: 0.0778034 Test Loss: 0.0842228\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0790154\n",
      "\tspeed: 0.0419s/iter; left time: 516.9221s\n",
      "\titers: 200, epoch: 45 | loss: 0.0779546\n",
      "\tspeed: 0.0171s/iter; left time: 209.2712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 222 | Train Loss: 0.0782630 Vali Loss: 0.0776432 Test Loss: 0.0841934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0848608\n",
      "\tspeed: 0.0376s/iter; left time: 455.5104s\n",
      "\titers: 200, epoch: 46 | loss: 0.0808703\n",
      "\tspeed: 0.0169s/iter; left time: 202.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 222 | Train Loss: 0.0783092 Vali Loss: 0.0777007 Test Loss: 0.0842784\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0782285\n",
      "\tspeed: 0.0434s/iter; left time: 516.5651s\n",
      "\titers: 200, epoch: 47 | loss: 0.0790537\n",
      "\tspeed: 0.0182s/iter; left time: 214.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0781918 Vali Loss: 0.0778294 Test Loss: 0.0842310\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0792304\n",
      "\tspeed: 0.0380s/iter; left time: 443.3235s\n",
      "\titers: 200, epoch: 48 | loss: 0.0792798\n",
      "\tspeed: 0.0171s/iter; left time: 198.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.0782369 Vali Loss: 0.0777886 Test Loss: 0.0842740\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0789824\n",
      "\tspeed: 0.0354s/iter; left time: 405.4661s\n",
      "\titers: 200, epoch: 49 | loss: 0.0772062\n",
      "\tspeed: 0.0170s/iter; left time: 192.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.0784395 Vali Loss: 0.0778968 Test Loss: 0.0843072\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0770739\n",
      "\tspeed: 0.0387s/iter; left time: 434.2562s\n",
      "\titers: 200, epoch: 50 | loss: 0.0764689\n",
      "\tspeed: 0.0169s/iter; left time: 187.4881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 222 | Train Loss: 0.0782838 Vali Loss: 0.0778267 Test Loss: 0.0844131\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815865\n",
      "\tspeed: 0.0372s/iter; left time: 409.7466s\n",
      "\titers: 200, epoch: 51 | loss: 0.0847316\n",
      "\tspeed: 0.0151s/iter; left time: 164.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0783152 Vali Loss: 0.0775835 Test Loss: 0.0842785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0804158\n",
      "\tspeed: 0.0380s/iter; left time: 409.9081s\n",
      "\titers: 200, epoch: 52 | loss: 0.0765600\n",
      "\tspeed: 0.0241s/iter; left time: 257.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.0782747 Vali Loss: 0.0777675 Test Loss: 0.0842551\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018542619422078133, rmse:0.13617128133773804, mae:0.08423762768507004, rse:0.5148782730102539\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:55.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2623744\n",
      "\tspeed: 0.0420s/iter; left time: 927.5870s\n",
      "\titers: 200, epoch: 1 | loss: 0.2450005\n",
      "\tspeed: 0.0138s/iter; left time: 302.7337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 222 | Train Loss: 0.2712762 Vali Loss: 0.1892322 Test Loss: 0.1963542\n",
      "Validation loss decreased (inf --> 0.189232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1408351\n",
      "\tspeed: 0.0331s/iter; left time: 723.7136s\n",
      "\titers: 200, epoch: 2 | loss: 0.1200960\n",
      "\tspeed: 0.0137s/iter; left time: 298.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 222 | Train Loss: 0.1527142 Vali Loss: 0.1074763 Test Loss: 0.1128705\n",
      "Validation loss decreased (0.189232 --> 0.107476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1113417\n",
      "\tspeed: 0.0392s/iter; left time: 849.0988s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039628\n",
      "\tspeed: 0.0153s/iter; left time: 329.7680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.1100681 Vali Loss: 0.0971555 Test Loss: 0.1001091\n",
      "Validation loss decreased (0.107476 --> 0.097156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0994959\n",
      "\tspeed: 0.0329s/iter; left time: 706.0792s\n",
      "\titers: 200, epoch: 4 | loss: 0.0961771\n",
      "\tspeed: 0.0138s/iter; left time: 294.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 222 | Train Loss: 0.0994796 Vali Loss: 0.0918822 Test Loss: 0.0945576\n",
      "Validation loss decreased (0.097156 --> 0.091882).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978309\n",
      "\tspeed: 0.0327s/iter; left time: 693.9270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0923279\n",
      "\tspeed: 0.0139s/iter; left time: 293.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 222 | Train Loss: 0.0947662 Vali Loss: 0.0886997 Test Loss: 0.0922637\n",
      "Validation loss decreased (0.091882 --> 0.088700).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910314\n",
      "\tspeed: 0.0331s/iter; left time: 695.2378s\n",
      "\titers: 200, epoch: 6 | loss: 0.0867660\n",
      "\tspeed: 0.0136s/iter; left time: 283.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 222 | Train Loss: 0.0920840 Vali Loss: 0.0879990 Test Loss: 0.0926584\n",
      "Validation loss decreased (0.088700 --> 0.087999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891643\n",
      "\tspeed: 0.0367s/iter; left time: 761.8285s\n",
      "\titers: 200, epoch: 7 | loss: 0.0895050\n",
      "\tspeed: 0.0169s/iter; left time: 348.4028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 222 | Train Loss: 0.0902035 Vali Loss: 0.0859869 Test Loss: 0.0899814\n",
      "Validation loss decreased (0.087999 --> 0.085987).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0862706\n",
      "\tspeed: 0.0373s/iter; left time: 765.6487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0882515\n",
      "\tspeed: 0.0136s/iter; left time: 278.5631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 222 | Train Loss: 0.0887546 Vali Loss: 0.0849545 Test Loss: 0.0896388\n",
      "Validation loss decreased (0.085987 --> 0.084955).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0883243\n",
      "\tspeed: 0.0370s/iter; left time: 752.9432s\n",
      "\titers: 200, epoch: 9 | loss: 0.0862404\n",
      "\tspeed: 0.0190s/iter; left time: 383.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 222 | Train Loss: 0.0875899 Vali Loss: 0.0852935 Test Loss: 0.0899381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0867116\n",
      "\tspeed: 0.0402s/iter; left time: 807.1928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848586\n",
      "\tspeed: 0.0200s/iter; left time: 399.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 222 | Train Loss: 0.0866538 Vali Loss: 0.0847252 Test Loss: 0.0892747\n",
      "Validation loss decreased (0.084955 --> 0.084725).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0855074\n",
      "\tspeed: 0.0408s/iter; left time: 811.0469s\n",
      "\titers: 200, epoch: 11 | loss: 0.0857905\n",
      "\tspeed: 0.0199s/iter; left time: 393.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 222 | Train Loss: 0.0861807 Vali Loss: 0.0837049 Test Loss: 0.0884712\n",
      "Validation loss decreased (0.084725 --> 0.083705).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0823696\n",
      "\tspeed: 0.0420s/iter; left time: 825.3334s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843925\n",
      "\tspeed: 0.0201s/iter; left time: 392.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0855676 Vali Loss: 0.0834212 Test Loss: 0.0882320\n",
      "Validation loss decreased (0.083705 --> 0.083421).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0824965\n",
      "\tspeed: 0.0409s/iter; left time: 794.2823s\n",
      "\titers: 200, epoch: 13 | loss: 0.0787788\n",
      "\tspeed: 0.0203s/iter; left time: 392.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 222 | Train Loss: 0.0852563 Vali Loss: 0.0835483 Test Loss: 0.0882946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841491\n",
      "\tspeed: 0.0433s/iter; left time: 831.6104s\n",
      "\titers: 200, epoch: 14 | loss: 0.0836439\n",
      "\tspeed: 0.0207s/iter; left time: 396.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 222 | Train Loss: 0.0848209 Vali Loss: 0.0830857 Test Loss: 0.0881342\n",
      "Validation loss decreased (0.083421 --> 0.083086).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0865259\n",
      "\tspeed: 0.0424s/iter; left time: 805.8117s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829420\n",
      "\tspeed: 0.0202s/iter; left time: 380.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 222 | Train Loss: 0.0848062 Vali Loss: 0.0829537 Test Loss: 0.0883071\n",
      "Validation loss decreased (0.083086 --> 0.082954).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0844988\n",
      "\tspeed: 0.0398s/iter; left time: 747.6310s\n",
      "\titers: 200, epoch: 16 | loss: 0.0813226\n",
      "\tspeed: 0.0209s/iter; left time: 389.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 222 | Train Loss: 0.0840173 Vali Loss: 0.0828866 Test Loss: 0.0883264\n",
      "Validation loss decreased (0.082954 --> 0.082887).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0822286\n",
      "\tspeed: 0.0419s/iter; left time: 777.8777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0811582\n",
      "\tspeed: 0.0183s/iter; left time: 338.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0837539 Vali Loss: 0.0824189 Test Loss: 0.0878899\n",
      "Validation loss decreased (0.082887 --> 0.082419).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0801338\n",
      "\tspeed: 0.0395s/iter; left time: 724.6607s\n",
      "\titers: 200, epoch: 18 | loss: 0.0810253\n",
      "\tspeed: 0.0202s/iter; left time: 367.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0836768 Vali Loss: 0.0824808 Test Loss: 0.0882645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841864\n",
      "\tspeed: 0.0432s/iter; left time: 782.1362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0849248\n",
      "\tspeed: 0.0204s/iter; left time: 367.7388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0834017 Vali Loss: 0.0825050 Test Loss: 0.0881532\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811977\n",
      "\tspeed: 0.0413s/iter; left time: 737.8150s\n",
      "\titers: 200, epoch: 20 | loss: 0.0814986\n",
      "\tspeed: 0.0180s/iter; left time: 319.6446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 222 | Train Loss: 0.0831224 Vali Loss: 0.0827331 Test Loss: 0.0884382\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0842526\n",
      "\tspeed: 0.0411s/iter; left time: 726.0060s\n",
      "\titers: 200, epoch: 21 | loss: 0.0844001\n",
      "\tspeed: 0.0204s/iter; left time: 357.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0832062 Vali Loss: 0.0822411 Test Loss: 0.0879636\n",
      "Validation loss decreased (0.082419 --> 0.082241).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0817567\n",
      "\tspeed: 0.0418s/iter; left time: 729.2107s\n",
      "\titers: 200, epoch: 22 | loss: 0.0820697\n",
      "\tspeed: 0.0211s/iter; left time: 365.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0832305 Vali Loss: 0.0823467 Test Loss: 0.0885551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0809216\n",
      "\tspeed: 0.0428s/iter; left time: 737.5679s\n",
      "\titers: 200, epoch: 23 | loss: 0.0813171\n",
      "\tspeed: 0.0214s/iter; left time: 366.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 222 | Train Loss: 0.0828882 Vali Loss: 0.0824147 Test Loss: 0.0881744\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0809080\n",
      "\tspeed: 0.0407s/iter; left time: 690.9896s\n",
      "\titers: 200, epoch: 24 | loss: 0.0853437\n",
      "\tspeed: 0.0202s/iter; left time: 340.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0828422 Vali Loss: 0.0827910 Test Loss: 0.0886205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0824172\n",
      "\tspeed: 0.0418s/iter; left time: 700.3342s\n",
      "\titers: 200, epoch: 25 | loss: 0.0799203\n",
      "\tspeed: 0.0198s/iter; left time: 329.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 222 | Train Loss: 0.0825665 Vali Loss: 0.0826381 Test Loss: 0.0884931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828128\n",
      "\tspeed: 0.0404s/iter; left time: 669.0708s\n",
      "\titers: 200, epoch: 26 | loss: 0.0804897\n",
      "\tspeed: 0.0202s/iter; left time: 332.1335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0826134 Vali Loss: 0.0824440 Test Loss: 0.0884047\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0878159\n",
      "\tspeed: 0.0423s/iter; left time: 690.3725s\n",
      "\titers: 200, epoch: 27 | loss: 0.0820288\n",
      "\tspeed: 0.0227s/iter; left time: 368.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 222 | Train Loss: 0.0825387 Vali Loss: 0.0824503 Test Loss: 0.0886938\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0832498\n",
      "\tspeed: 0.0419s/iter; left time: 674.8907s\n",
      "\titers: 200, epoch: 28 | loss: 0.0824159\n",
      "\tspeed: 0.0135s/iter; left time: 215.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0823991 Vali Loss: 0.0822423 Test Loss: 0.0882074\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0837849\n",
      "\tspeed: 0.0389s/iter; left time: 618.5729s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780446\n",
      "\tspeed: 0.0179s/iter; left time: 282.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 222 | Train Loss: 0.0823763 Vali Loss: 0.0823771 Test Loss: 0.0881678\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0845247\n",
      "\tspeed: 0.0389s/iter; left time: 609.0677s\n",
      "\titers: 200, epoch: 30 | loss: 0.0855861\n",
      "\tspeed: 0.0190s/iter; left time: 295.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 222 | Train Loss: 0.0827045 Vali Loss: 0.0830361 Test Loss: 0.0885761\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0848081\n",
      "\tspeed: 0.0392s/iter; left time: 605.5501s\n",
      "\titers: 200, epoch: 31 | loss: 0.0832928\n",
      "\tspeed: 0.0181s/iter; left time: 278.2020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 222 | Train Loss: 0.0823795 Vali Loss: 0.0821888 Test Loss: 0.0883767\n",
      "Validation loss decreased (0.082241 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0802322\n",
      "\tspeed: 0.0387s/iter; left time: 589.6836s\n",
      "\titers: 200, epoch: 32 | loss: 0.0831175\n",
      "\tspeed: 0.0192s/iter; left time: 290.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0822764 Vali Loss: 0.0824038 Test Loss: 0.0882548\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0830918\n",
      "\tspeed: 0.0385s/iter; left time: 577.3514s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793728\n",
      "\tspeed: 0.0213s/iter; left time: 317.5574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 222 | Train Loss: 0.0821784 Vali Loss: 0.0822476 Test Loss: 0.0882046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0776519\n",
      "\tspeed: 0.0380s/iter; left time: 561.2018s\n",
      "\titers: 200, epoch: 34 | loss: 0.0819596\n",
      "\tspeed: 0.0200s/iter; left time: 294.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0822438 Vali Loss: 0.0821295 Test Loss: 0.0883762\n",
      "Validation loss decreased (0.082189 --> 0.082130).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0787440\n",
      "\tspeed: 0.0426s/iter; left time: 619.3907s\n",
      "\titers: 200, epoch: 35 | loss: 0.0771109\n",
      "\tspeed: 0.0202s/iter; left time: 292.3333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 222 | Train Loss: 0.0823118 Vali Loss: 0.0824794 Test Loss: 0.0887839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0816495\n",
      "\tspeed: 0.0431s/iter; left time: 618.0142s\n",
      "\titers: 200, epoch: 36 | loss: 0.0814413\n",
      "\tspeed: 0.0197s/iter; left time: 280.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0820317 Vali Loss: 0.0820441 Test Loss: 0.0881821\n",
      "Validation loss decreased (0.082130 --> 0.082044).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0828957\n",
      "\tspeed: 0.0441s/iter; left time: 621.9021s\n",
      "\titers: 200, epoch: 37 | loss: 0.0850870\n",
      "\tspeed: 0.0220s/iter; left time: 307.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 222 | Train Loss: 0.0820310 Vali Loss: 0.0821765 Test Loss: 0.0884298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0838884\n",
      "\tspeed: 0.0407s/iter; left time: 565.6554s\n",
      "\titers: 200, epoch: 38 | loss: 0.0814081\n",
      "\tspeed: 0.0186s/iter; left time: 255.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 222 | Train Loss: 0.0820474 Vali Loss: 0.0821589 Test Loss: 0.0885091\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0784536\n",
      "\tspeed: 0.0408s/iter; left time: 556.9536s\n",
      "\titers: 200, epoch: 39 | loss: 0.0867268\n",
      "\tspeed: 0.0198s/iter; left time: 269.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0820567 Vali Loss: 0.0822583 Test Loss: 0.0884373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0830478\n",
      "\tspeed: 0.0404s/iter; left time: 543.3401s\n",
      "\titers: 200, epoch: 40 | loss: 0.0777736\n",
      "\tspeed: 0.0197s/iter; left time: 262.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0819677 Vali Loss: 0.0822046 Test Loss: 0.0884621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0835645\n",
      "\tspeed: 0.0404s/iter; left time: 534.0033s\n",
      "\titers: 200, epoch: 41 | loss: 0.0800434\n",
      "\tspeed: 0.0219s/iter; left time: 287.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 222 | Train Loss: 0.0819560 Vali Loss: 0.0820218 Test Loss: 0.0882482\n",
      "Validation loss decreased (0.082044 --> 0.082022).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845304\n",
      "\tspeed: 0.0390s/iter; left time: 506.7602s\n",
      "\titers: 200, epoch: 42 | loss: 0.0816610\n",
      "\tspeed: 0.0176s/iter; left time: 227.6636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 222 | Train Loss: 0.0820568 Vali Loss: 0.0820582 Test Loss: 0.0882806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0810728\n",
      "\tspeed: 0.0391s/iter; left time: 499.4621s\n",
      "\titers: 200, epoch: 43 | loss: 0.0854628\n",
      "\tspeed: 0.0195s/iter; left time: 247.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0819868 Vali Loss: 0.0821145 Test Loss: 0.0884622\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0822338\n",
      "\tspeed: 0.0376s/iter; left time: 472.6334s\n",
      "\titers: 200, epoch: 44 | loss: 0.0816598\n",
      "\tspeed: 0.0180s/iter; left time: 223.7199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0818978 Vali Loss: 0.0820457 Test Loss: 0.0884021\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0839961\n",
      "\tspeed: 0.0388s/iter; left time: 477.9046s\n",
      "\titers: 200, epoch: 45 | loss: 0.0836015\n",
      "\tspeed: 0.0136s/iter; left time: 166.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0818034 Vali Loss: 0.0821953 Test Loss: 0.0883732\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0802597\n",
      "\tspeed: 0.0447s/iter; left time: 541.2268s\n",
      "\titers: 200, epoch: 46 | loss: 0.0779905\n",
      "\tspeed: 0.0209s/iter; left time: 250.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 222 | Train Loss: 0.0817427 Vali Loss: 0.0819662 Test Loss: 0.0884531\n",
      "Validation loss decreased (0.082022 --> 0.081966).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0824521\n",
      "\tspeed: 0.0405s/iter; left time: 481.9380s\n",
      "\titers: 200, epoch: 47 | loss: 0.0803926\n",
      "\tspeed: 0.0169s/iter; left time: 199.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.0819594 Vali Loss: 0.0825168 Test Loss: 0.0884939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0816119\n",
      "\tspeed: 0.0330s/iter; left time: 384.8888s\n",
      "\titers: 200, epoch: 48 | loss: 0.0852106\n",
      "\tspeed: 0.0135s/iter; left time: 155.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 222 | Train Loss: 0.0820579 Vali Loss: 0.0820884 Test Loss: 0.0883255\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0818182\n",
      "\tspeed: 0.0396s/iter; left time: 453.5298s\n",
      "\titers: 200, epoch: 49 | loss: 0.0817004\n",
      "\tspeed: 0.0187s/iter; left time: 211.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 222 | Train Loss: 0.0819418 Vali Loss: 0.0818370 Test Loss: 0.0881932\n",
      "Validation loss decreased (0.081966 --> 0.081837).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0834935\n",
      "\tspeed: 0.0426s/iter; left time: 478.2772s\n",
      "\titers: 200, epoch: 50 | loss: 0.0805027\n",
      "\tspeed: 0.0213s/iter; left time: 237.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 222 | Train Loss: 0.0818667 Vali Loss: 0.0822212 Test Loss: 0.0882141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0783036\n",
      "\tspeed: 0.0368s/iter; left time: 404.6198s\n",
      "\titers: 200, epoch: 51 | loss: 0.0795352\n",
      "\tspeed: 0.0188s/iter; left time: 205.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0818968 Vali Loss: 0.0819246 Test Loss: 0.0882194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0833366\n",
      "\tspeed: 0.0406s/iter; left time: 437.8112s\n",
      "\titers: 200, epoch: 52 | loss: 0.0854200\n",
      "\tspeed: 0.0226s/iter; left time: 241.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 222 | Train Loss: 0.0817988 Vali Loss: 0.0819509 Test Loss: 0.0882387\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0786324\n",
      "\tspeed: 0.0392s/iter; left time: 413.3095s\n",
      "\titers: 200, epoch: 53 | loss: 0.0790665\n",
      "\tspeed: 0.0202s/iter; left time: 211.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 222 | Train Loss: 0.0818386 Vali Loss: 0.0823388 Test Loss: 0.0882767\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0830407\n",
      "\tspeed: 0.0441s/iter; left time: 455.5770s\n",
      "\titers: 200, epoch: 54 | loss: 0.0790486\n",
      "\tspeed: 0.0244s/iter; left time: 249.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 222 | Train Loss: 0.0818012 Vali Loss: 0.0819960 Test Loss: 0.0884223\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0769131\n",
      "\tspeed: 0.0458s/iter; left time: 463.3877s\n",
      "\titers: 200, epoch: 55 | loss: 0.0849257\n",
      "\tspeed: 0.0211s/iter; left time: 211.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0818655 Vali Loss: 0.0820058 Test Loss: 0.0883152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0862380\n",
      "\tspeed: 0.0400s/iter; left time: 395.4179s\n",
      "\titers: 200, epoch: 56 | loss: 0.0817307\n",
      "\tspeed: 0.0136s/iter; left time: 132.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0820245 Vali Loss: 0.0821021 Test Loss: 0.0881774\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0795083\n",
      "\tspeed: 0.0393s/iter; left time: 379.5099s\n",
      "\titers: 200, epoch: 57 | loss: 0.0812620\n",
      "\tspeed: 0.0200s/iter; left time: 191.8438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 222 | Train Loss: 0.0818150 Vali Loss: 0.0820054 Test Loss: 0.0883177\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0845081\n",
      "\tspeed: 0.0421s/iter; left time: 397.9027s\n",
      "\titers: 200, epoch: 58 | loss: 0.0835808\n",
      "\tspeed: 0.0197s/iter; left time: 184.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 222 | Train Loss: 0.0819062 Vali Loss: 0.0819882 Test Loss: 0.0882302\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0817004\n",
      "\tspeed: 0.0388s/iter; left time: 357.7658s\n",
      "\titers: 200, epoch: 59 | loss: 0.0857204\n",
      "\tspeed: 0.0190s/iter; left time: 173.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 222 | Train Loss: 0.0819953 Vali Loss: 0.0819777 Test Loss: 0.0883877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02009870857000351, rmse:0.1417699158191681, mae:0.08819320052862167, rse:0.53654545545578\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2712563\n",
      "\tspeed: 0.0214s/iter; left time: 471.9183s\n",
      "\titers: 200, epoch: 1 | loss: 0.2490055\n",
      "\tspeed: 0.0251s/iter; left time: 551.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 222 | Train Loss: 0.2747137 Vali Loss: 0.1928143 Test Loss: 0.1985855\n",
      "Validation loss decreased (inf --> 0.192814).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1475603\n",
      "\tspeed: 0.0428s/iter; left time: 935.7272s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184002\n",
      "\tspeed: 0.0216s/iter; left time: 470.0232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 222 | Train Loss: 0.1543333 Vali Loss: 0.1072151 Test Loss: 0.1128805\n",
      "Validation loss decreased (0.192814 --> 0.107215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1093291\n",
      "\tspeed: 0.0390s/iter; left time: 845.5274s\n",
      "\titers: 200, epoch: 3 | loss: 0.1044130\n",
      "\tspeed: 0.0192s/iter; left time: 414.5451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 222 | Train Loss: 0.1114542 Vali Loss: 0.0979469 Test Loss: 0.1012931\n",
      "Validation loss decreased (0.107215 --> 0.097947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1022294\n",
      "\tspeed: 0.0405s/iter; left time: 869.0369s\n",
      "\titers: 200, epoch: 4 | loss: 0.0971455\n",
      "\tspeed: 0.0230s/iter; left time: 490.0793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 222 | Train Loss: 0.1020911 Vali Loss: 0.0929810 Test Loss: 0.0952793\n",
      "Validation loss decreased (0.097947 --> 0.092981).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0972201\n",
      "\tspeed: 0.0411s/iter; left time: 872.6176s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956559\n",
      "\tspeed: 0.0221s/iter; left time: 466.6546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 222 | Train Loss: 0.0962046 Vali Loss: 0.0889489 Test Loss: 0.0927465\n",
      "Validation loss decreased (0.092981 --> 0.088949).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916785\n",
      "\tspeed: 0.0415s/iter; left time: 871.1624s\n",
      "\titers: 200, epoch: 6 | loss: 0.0933037\n",
      "\tspeed: 0.0205s/iter; left time: 427.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 222 | Train Loss: 0.0925845 Vali Loss: 0.0879964 Test Loss: 0.0919507\n",
      "Validation loss decreased (0.088949 --> 0.087996).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896356\n",
      "\tspeed: 0.0372s/iter; left time: 772.5942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882480\n",
      "\tspeed: 0.0152s/iter; left time: 313.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 222 | Train Loss: 0.0903009 Vali Loss: 0.0864873 Test Loss: 0.0906692\n",
      "Validation loss decreased (0.087996 --> 0.086487).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0867063\n",
      "\tspeed: 0.0415s/iter; left time: 853.3271s\n",
      "\titers: 200, epoch: 8 | loss: 0.0857418\n",
      "\tspeed: 0.0203s/iter; left time: 414.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 222 | Train Loss: 0.0887536 Vali Loss: 0.0856702 Test Loss: 0.0896701\n",
      "Validation loss decreased (0.086487 --> 0.085670).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0900326\n",
      "\tspeed: 0.0366s/iter; left time: 744.1792s\n",
      "\titers: 200, epoch: 9 | loss: 0.0843220\n",
      "\tspeed: 0.0186s/iter; left time: 376.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 222 | Train Loss: 0.0874678 Vali Loss: 0.0853976 Test Loss: 0.0898667\n",
      "Validation loss decreased (0.085670 --> 0.085398).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0881722\n",
      "\tspeed: 0.0430s/iter; left time: 863.4492s\n",
      "\titers: 200, epoch: 10 | loss: 0.0830235\n",
      "\tspeed: 0.0202s/iter; left time: 404.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 222 | Train Loss: 0.0865154 Vali Loss: 0.0847643 Test Loss: 0.0892309\n",
      "Validation loss decreased (0.085398 --> 0.084764).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0850319\n",
      "\tspeed: 0.0394s/iter; left time: 784.0469s\n",
      "\titers: 200, epoch: 11 | loss: 0.0851163\n",
      "\tspeed: 0.0143s/iter; left time: 283.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0859890 Vali Loss: 0.0846788 Test Loss: 0.0884777\n",
      "Validation loss decreased (0.084764 --> 0.084679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0867555\n",
      "\tspeed: 0.0417s/iter; left time: 820.0030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0873440\n",
      "\tspeed: 0.0189s/iter; left time: 369.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 222 | Train Loss: 0.0855398 Vali Loss: 0.0846019 Test Loss: 0.0891452\n",
      "Validation loss decreased (0.084679 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0830634\n",
      "\tspeed: 0.0441s/iter; left time: 857.7225s\n",
      "\titers: 200, epoch: 13 | loss: 0.0849355\n",
      "\tspeed: 0.0173s/iter; left time: 334.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0847453 Vali Loss: 0.0845939 Test Loss: 0.0891996\n",
      "Validation loss decreased (0.084602 --> 0.084594).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0888833\n",
      "\tspeed: 0.0418s/iter; left time: 803.0337s\n",
      "\titers: 200, epoch: 14 | loss: 0.0820894\n",
      "\tspeed: 0.0185s/iter; left time: 353.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 222 | Train Loss: 0.0845855 Vali Loss: 0.0839425 Test Loss: 0.0884560\n",
      "Validation loss decreased (0.084594 --> 0.083942).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0871443\n",
      "\tspeed: 0.0409s/iter; left time: 776.3951s\n",
      "\titers: 200, epoch: 15 | loss: 0.0820118\n",
      "\tspeed: 0.0237s/iter; left time: 447.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 222 | Train Loss: 0.0842505 Vali Loss: 0.0837001 Test Loss: 0.0886381\n",
      "Validation loss decreased (0.083942 --> 0.083700).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0873144\n",
      "\tspeed: 0.0434s/iter; left time: 815.4731s\n",
      "\titers: 200, epoch: 16 | loss: 0.0815480\n",
      "\tspeed: 0.0182s/iter; left time: 339.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 222 | Train Loss: 0.0838815 Vali Loss: 0.0839674 Test Loss: 0.0879909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0838181\n",
      "\tspeed: 0.0406s/iter; left time: 753.2408s\n",
      "\titers: 200, epoch: 17 | loss: 0.0831851\n",
      "\tspeed: 0.0171s/iter; left time: 315.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 222 | Train Loss: 0.0837566 Vali Loss: 0.0838716 Test Loss: 0.0885497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0827826\n",
      "\tspeed: 0.0419s/iter; left time: 768.4519s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845723\n",
      "\tspeed: 0.0187s/iter; left time: 340.2529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 222 | Train Loss: 0.0834298 Vali Loss: 0.0836627 Test Loss: 0.0887304\n",
      "Validation loss decreased (0.083700 --> 0.083663).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0812503\n",
      "\tspeed: 0.0402s/iter; left time: 727.5958s\n",
      "\titers: 200, epoch: 19 | loss: 0.0835254\n",
      "\tspeed: 0.0197s/iter; left time: 353.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 222 | Train Loss: 0.0834923 Vali Loss: 0.0836854 Test Loss: 0.0883439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815291\n",
      "\tspeed: 0.0406s/iter; left time: 725.4777s\n",
      "\titers: 200, epoch: 20 | loss: 0.0821135\n",
      "\tspeed: 0.0159s/iter; left time: 282.9839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 222 | Train Loss: 0.0830429 Vali Loss: 0.0838270 Test Loss: 0.0889554\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799186\n",
      "\tspeed: 0.0395s/iter; left time: 697.9261s\n",
      "\titers: 200, epoch: 21 | loss: 0.0854063\n",
      "\tspeed: 0.0173s/iter; left time: 303.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.0828098 Vali Loss: 0.0836667 Test Loss: 0.0883499\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0878938\n",
      "\tspeed: 0.0380s/iter; left time: 663.4156s\n",
      "\titers: 200, epoch: 22 | loss: 0.0862450\n",
      "\tspeed: 0.0207s/iter; left time: 358.3119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 222 | Train Loss: 0.0827896 Vali Loss: 0.0836010 Test Loss: 0.0884958\n",
      "Validation loss decreased (0.083663 --> 0.083601).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0814758\n",
      "\tspeed: 0.0419s/iter; left time: 722.0619s\n",
      "\titers: 200, epoch: 23 | loss: 0.0839890\n",
      "\tspeed: 0.0191s/iter; left time: 326.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 222 | Train Loss: 0.0826417 Vali Loss: 0.0836368 Test Loss: 0.0884014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0784697\n",
      "\tspeed: 0.0447s/iter; left time: 759.4861s\n",
      "\titers: 200, epoch: 24 | loss: 0.0790533\n",
      "\tspeed: 0.0242s/iter; left time: 408.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 222 | Train Loss: 0.0827528 Vali Loss: 0.0829785 Test Loss: 0.0880086\n",
      "Validation loss decreased (0.083601 --> 0.082979).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0845103\n",
      "\tspeed: 0.0436s/iter; left time: 730.5613s\n",
      "\titers: 200, epoch: 25 | loss: 0.0846483\n",
      "\tspeed: 0.0236s/iter; left time: 393.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 222 | Train Loss: 0.0824630 Vali Loss: 0.0838180 Test Loss: 0.0891874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821375\n",
      "\tspeed: 0.0413s/iter; left time: 684.0281s\n",
      "\titers: 200, epoch: 26 | loss: 0.0806116\n",
      "\tspeed: 0.0182s/iter; left time: 299.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 222 | Train Loss: 0.0822775 Vali Loss: 0.0833788 Test Loss: 0.0884062\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0811948\n",
      "\tspeed: 0.0433s/iter; left time: 707.5438s\n",
      "\titers: 200, epoch: 27 | loss: 0.0827033\n",
      "\tspeed: 0.0197s/iter; left time: 320.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 222 | Train Loss: 0.0821459 Vali Loss: 0.0831527 Test Loss: 0.0880050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0815737\n",
      "\tspeed: 0.0365s/iter; left time: 588.1219s\n",
      "\titers: 200, epoch: 28 | loss: 0.0822114\n",
      "\tspeed: 0.0199s/iter; left time: 319.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 222 | Train Loss: 0.0823929 Vali Loss: 0.0835644 Test Loss: 0.0885297\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0823265\n",
      "\tspeed: 0.0391s/iter; left time: 620.8840s\n",
      "\titers: 200, epoch: 29 | loss: 0.0828064\n",
      "\tspeed: 0.0163s/iter; left time: 257.6131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 222 | Train Loss: 0.0821245 Vali Loss: 0.0835258 Test Loss: 0.0883994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0825101\n",
      "\tspeed: 0.0437s/iter; left time: 684.1664s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805133\n",
      "\tspeed: 0.0226s/iter; left time: 351.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 222 | Train Loss: 0.0820209 Vali Loss: 0.0834555 Test Loss: 0.0884562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0806998\n",
      "\tspeed: 0.0404s/iter; left time: 623.9036s\n",
      "\titers: 200, epoch: 31 | loss: 0.0799772\n",
      "\tspeed: 0.0135s/iter; left time: 206.8850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0820380 Vali Loss: 0.0830150 Test Loss: 0.0880995\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0818871\n",
      "\tspeed: 0.0373s/iter; left time: 567.9344s\n",
      "\titers: 200, epoch: 32 | loss: 0.0836088\n",
      "\tspeed: 0.0177s/iter; left time: 267.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 222 | Train Loss: 0.0821489 Vali Loss: 0.0835289 Test Loss: 0.0884418\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0831489\n",
      "\tspeed: 0.0406s/iter; left time: 608.2334s\n",
      "\titers: 200, epoch: 33 | loss: 0.0810823\n",
      "\tspeed: 0.0192s/iter; left time: 286.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 222 | Train Loss: 0.0818812 Vali Loss: 0.0830940 Test Loss: 0.0881459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0825568\n",
      "\tspeed: 0.0400s/iter; left time: 590.9784s\n",
      "\titers: 200, epoch: 34 | loss: 0.0790253\n",
      "\tspeed: 0.0189s/iter; left time: 277.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 222 | Train Loss: 0.0821900 Vali Loss: 0.0837752 Test Loss: 0.0887844\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019392775371670723, rmse:0.13925795257091522, mae:0.08800852298736572, rse:0.5270386338233948\n",
      "Intermediate time for IT and pred_len 168: 00h:09m:24.60s\n",
      "Intermediate time for IT: 00h:32m:25.42s\n",
      "Total time: 02h:21m:42.70s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.0673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0216  0.1470  0.0909\n",
       "        96             0.0402  0.2003  0.1316\n",
       "        168            0.0429  0.2070  0.1383\n",
       "ES      24             0.0112  0.1059  0.0673\n",
       "        96             0.0218  0.1474  0.0986\n",
       "        168            0.0262  0.1613  0.1086\n",
       "FR      24             0.0107  0.1033  0.0588\n",
       "        96             0.0205  0.1431  0.0836\n",
       "        168            0.0229  0.1513  0.0891\n",
       "GB      24             0.0269  0.1640  0.1050\n",
       "        96             0.0434  0.2083  0.1431\n",
       "        168            0.0457  0.2139  0.1494\n",
       "IT      24             0.0105  0.1026  0.0602\n",
       "        96             0.0187  0.1367  0.0834\n",
       "        168            0.0201  0.1418  0.0880"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin_512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1540070\n",
      "\tspeed: 0.0682s/iter; left time: 1513.0206s\n",
      "\titers: 200, epoch: 1 | loss: 0.1399671\n",
      "\tspeed: 0.0396s/iter; left time: 875.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.1535374 Vali Loss: 0.1520032 Test Loss: 0.1628620\n",
      "Validation loss decreased (inf --> 0.152003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0945533\n",
      "\tspeed: 0.0738s/iter; left time: 1621.5854s\n",
      "\titers: 200, epoch: 2 | loss: 0.0801202\n",
      "\tspeed: 0.0393s/iter; left time: 858.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0983999 Vali Loss: 0.0966843 Test Loss: 0.0982382\n",
      "Validation loss decreased (0.152003 --> 0.096684).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0761902\n",
      "\tspeed: 0.0738s/iter; left time: 1606.0167s\n",
      "\titers: 200, epoch: 3 | loss: 0.0756312\n",
      "\tspeed: 0.0397s/iter; left time: 859.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0803869 Vali Loss: 0.0919775 Test Loss: 0.0941401\n",
      "Validation loss decreased (0.096684 --> 0.091978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827611\n",
      "\tspeed: 0.0738s/iter; left time: 1588.3208s\n",
      "\titers: 200, epoch: 4 | loss: 0.0745360\n",
      "\tspeed: 0.0393s/iter; left time: 842.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0768801 Vali Loss: 0.0898522 Test Loss: 0.0916621\n",
      "Validation loss decreased (0.091978 --> 0.089852).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0750114\n",
      "\tspeed: 0.0745s/iter; left time: 1586.9739s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757578\n",
      "\tspeed: 0.0396s/iter; left time: 840.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0749955 Vali Loss: 0.0887784 Test Loss: 0.0907531\n",
      "Validation loss decreased (0.089852 --> 0.088778).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0704827\n",
      "\tspeed: 0.0739s/iter; left time: 1558.7845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802003\n",
      "\tspeed: 0.0394s/iter; left time: 827.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0737706 Vali Loss: 0.0884229 Test Loss: 0.0903026\n",
      "Validation loss decreased (0.088778 --> 0.088423).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0703720\n",
      "\tspeed: 0.0734s/iter; left time: 1530.7978s\n",
      "\titers: 200, epoch: 7 | loss: 0.0752982\n",
      "\tspeed: 0.0397s/iter; left time: 824.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0728895 Vali Loss: 0.0884783 Test Loss: 0.0904812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0714368\n",
      "\tspeed: 0.0732s/iter; left time: 1511.7299s\n",
      "\titers: 200, epoch: 8 | loss: 0.0780095\n",
      "\tspeed: 0.0393s/iter; left time: 807.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0723454 Vali Loss: 0.0879506 Test Loss: 0.0896100\n",
      "Validation loss decreased (0.088423 --> 0.087951).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731446\n",
      "\tspeed: 0.0738s/iter; left time: 1507.5893s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719422\n",
      "\tspeed: 0.0396s/iter; left time: 805.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0717695 Vali Loss: 0.0878297 Test Loss: 0.0898020\n",
      "Validation loss decreased (0.087951 --> 0.087830).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0711289\n",
      "\tspeed: 0.0737s/iter; left time: 1488.4937s\n",
      "\titers: 200, epoch: 10 | loss: 0.0765802\n",
      "\tspeed: 0.0390s/iter; left time: 783.4490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0713679 Vali Loss: 0.0876375 Test Loss: 0.0898624\n",
      "Validation loss decreased (0.087830 --> 0.087638).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0663756\n",
      "\tspeed: 0.0735s/iter; left time: 1468.0396s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691783\n",
      "\tspeed: 0.0400s/iter; left time: 795.2587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 223 | Train Loss: 0.0709750 Vali Loss: 0.0872272 Test Loss: 0.0893647\n",
      "Validation loss decreased (0.087638 --> 0.087227).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0709993\n",
      "\tspeed: 0.0731s/iter; left time: 1443.1039s\n",
      "\titers: 200, epoch: 12 | loss: 0.0715705\n",
      "\tspeed: 0.0393s/iter; left time: 772.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0705905 Vali Loss: 0.0876522 Test Loss: 0.0895438\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0695625\n",
      "\tspeed: 0.0731s/iter; left time: 1427.6730s\n",
      "\titers: 200, epoch: 13 | loss: 0.0708215\n",
      "\tspeed: 0.0394s/iter; left time: 765.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0703840 Vali Loss: 0.0872865 Test Loss: 0.0894072\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695714\n",
      "\tspeed: 0.0731s/iter; left time: 1411.3237s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717605\n",
      "\tspeed: 0.0392s/iter; left time: 751.9262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0700742 Vali Loss: 0.0875291 Test Loss: 0.0894345\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0716382\n",
      "\tspeed: 0.0726s/iter; left time: 1385.7260s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705205\n",
      "\tspeed: 0.0392s/iter; left time: 744.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0697654 Vali Loss: 0.0875876 Test Loss: 0.0895487\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0702533\n",
      "\tspeed: 0.0729s/iter; left time: 1374.0730s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751965\n",
      "\tspeed: 0.0393s/iter; left time: 737.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0695786 Vali Loss: 0.0874853 Test Loss: 0.0896701\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0719358\n",
      "\tspeed: 0.0734s/iter; left time: 1367.6883s\n",
      "\titers: 200, epoch: 17 | loss: 0.0673930\n",
      "\tspeed: 0.0395s/iter; left time: 731.1883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0693594 Vali Loss: 0.0874779 Test Loss: 0.0893710\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0671811\n",
      "\tspeed: 0.0730s/iter; left time: 1344.5356s\n",
      "\titers: 200, epoch: 18 | loss: 0.0669464\n",
      "\tspeed: 0.0395s/iter; left time: 722.6299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0692546 Vali Loss: 0.0874369 Test Loss: 0.0895819\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0696596\n",
      "\tspeed: 0.0736s/iter; left time: 1338.0350s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723202\n",
      "\tspeed: 0.0394s/iter; left time: 712.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0690475 Vali Loss: 0.0875139 Test Loss: 0.0896322\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0703168\n",
      "\tspeed: 0.0728s/iter; left time: 1308.5046s\n",
      "\titers: 200, epoch: 20 | loss: 0.0635600\n",
      "\tspeed: 0.0393s/iter; left time: 702.2069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0689665 Vali Loss: 0.0873956 Test Loss: 0.0893301\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0691639\n",
      "\tspeed: 0.0729s/iter; left time: 1293.6182s\n",
      "\titers: 200, epoch: 21 | loss: 0.0701297\n",
      "\tspeed: 0.0392s/iter; left time: 691.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0688408 Vali Loss: 0.0876105 Test Loss: 0.0897749\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021089807152748108, rmse:0.14522330462932587, mae:0.08936472982168198, rse:0.5125131011009216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1592548\n",
      "\tspeed: 0.0415s/iter; left time: 920.9142s\n",
      "\titers: 200, epoch: 1 | loss: 0.1390639\n",
      "\tspeed: 0.0394s/iter; left time: 869.8449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.1540130 Vali Loss: 0.1532656 Test Loss: 0.1637412\n",
      "Validation loss decreased (inf --> 0.153266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0949316\n",
      "\tspeed: 0.0753s/iter; left time: 1653.8558s\n",
      "\titers: 200, epoch: 2 | loss: 0.0798822\n",
      "\tspeed: 0.0395s/iter; left time: 863.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0993247 Vali Loss: 0.0980056 Test Loss: 0.0991047\n",
      "Validation loss decreased (0.153266 --> 0.098006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0861318\n",
      "\tspeed: 0.0741s/iter; left time: 1611.7689s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792707\n",
      "\tspeed: 0.0395s/iter; left time: 855.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0809582 Vali Loss: 0.0917781 Test Loss: 0.0942827\n",
      "Validation loss decreased (0.098006 --> 0.091778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0756787\n",
      "\tspeed: 0.0749s/iter; left time: 1613.8142s\n",
      "\titers: 200, epoch: 4 | loss: 0.0796184\n",
      "\tspeed: 0.0397s/iter; left time: 850.5442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.0772868 Vali Loss: 0.0899476 Test Loss: 0.0923501\n",
      "Validation loss decreased (0.091778 --> 0.089948).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0766317\n",
      "\tspeed: 0.0795s/iter; left time: 1693.9858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787369\n",
      "\tspeed: 0.0412s/iter; left time: 874.6546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0751880 Vali Loss: 0.0891346 Test Loss: 0.0912587\n",
      "Validation loss decreased (0.089948 --> 0.089135).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0678988\n",
      "\tspeed: 0.0792s/iter; left time: 1670.4055s\n",
      "\titers: 200, epoch: 6 | loss: 0.0737279\n",
      "\tspeed: 0.0408s/iter; left time: 855.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0739857 Vali Loss: 0.0886733 Test Loss: 0.0910355\n",
      "Validation loss decreased (0.089135 --> 0.088673).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783062\n",
      "\tspeed: 0.0769s/iter; left time: 1603.7090s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773654\n",
      "\tspeed: 0.0392s/iter; left time: 812.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 223 | Train Loss: 0.0731408 Vali Loss: 0.0878661 Test Loss: 0.0906288\n",
      "Validation loss decreased (0.088673 --> 0.087866).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726752\n",
      "\tspeed: 0.0776s/iter; left time: 1602.3296s\n",
      "\titers: 200, epoch: 8 | loss: 0.0692866\n",
      "\tspeed: 0.0399s/iter; left time: 819.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0723848 Vali Loss: 0.0876358 Test Loss: 0.0900650\n",
      "Validation loss decreased (0.087866 --> 0.087636).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0688828\n",
      "\tspeed: 0.0746s/iter; left time: 1523.8248s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753372\n",
      "\tspeed: 0.0397s/iter; left time: 806.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 223 | Train Loss: 0.0718418 Vali Loss: 0.0871986 Test Loss: 0.0901422\n",
      "Validation loss decreased (0.087636 --> 0.087199).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698159\n",
      "\tspeed: 0.0742s/iter; left time: 1498.2292s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749876\n",
      "\tspeed: 0.0394s/iter; left time: 791.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0714432 Vali Loss: 0.0875067 Test Loss: 0.0903057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714020\n",
      "\tspeed: 0.0729s/iter; left time: 1456.6831s\n",
      "\titers: 200, epoch: 11 | loss: 0.0704673\n",
      "\tspeed: 0.0392s/iter; left time: 778.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0709839 Vali Loss: 0.0872032 Test Loss: 0.0901335\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0682913\n",
      "\tspeed: 0.0736s/iter; left time: 1453.1577s\n",
      "\titers: 200, epoch: 12 | loss: 0.0698308\n",
      "\tspeed: 0.0404s/iter; left time: 793.5483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0707336 Vali Loss: 0.0870073 Test Loss: 0.0897848\n",
      "Validation loss decreased (0.087199 --> 0.087007).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0675830\n",
      "\tspeed: 0.0745s/iter; left time: 1455.5370s\n",
      "\titers: 200, epoch: 13 | loss: 0.0722683\n",
      "\tspeed: 0.0392s/iter; left time: 762.2963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0703472 Vali Loss: 0.0874077 Test Loss: 0.0899746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707077\n",
      "\tspeed: 0.0743s/iter; left time: 1434.6298s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726146\n",
      "\tspeed: 0.0393s/iter; left time: 753.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0700877 Vali Loss: 0.0871070 Test Loss: 0.0900448\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0750981\n",
      "\tspeed: 0.0767s/iter; left time: 1464.2881s\n",
      "\titers: 200, epoch: 15 | loss: 0.0712058\n",
      "\tspeed: 0.0401s/iter; left time: 760.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0699153 Vali Loss: 0.0871613 Test Loss: 0.0899834\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0685468\n",
      "\tspeed: 0.0736s/iter; left time: 1387.7715s\n",
      "\titers: 200, epoch: 16 | loss: 0.0695068\n",
      "\tspeed: 0.0392s/iter; left time: 734.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0696994 Vali Loss: 0.0870462 Test Loss: 0.0899903\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0674618\n",
      "\tspeed: 0.0735s/iter; left time: 1370.0828s\n",
      "\titers: 200, epoch: 17 | loss: 0.0693320\n",
      "\tspeed: 0.0394s/iter; left time: 730.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0694627 Vali Loss: 0.0870356 Test Loss: 0.0898084\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0668953\n",
      "\tspeed: 0.0737s/iter; left time: 1357.1073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0709489\n",
      "\tspeed: 0.0394s/iter; left time: 721.8132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0693186 Vali Loss: 0.0870681 Test Loss: 0.0899144\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0727419\n",
      "\tspeed: 0.0739s/iter; left time: 1344.2735s\n",
      "\titers: 200, epoch: 19 | loss: 0.0712517\n",
      "\tspeed: 0.0392s/iter; left time: 709.4483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0691367 Vali Loss: 0.0872595 Test Loss: 0.0900782\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0715295\n",
      "\tspeed: 0.0735s/iter; left time: 1320.3287s\n",
      "\titers: 200, epoch: 20 | loss: 0.0712320\n",
      "\tspeed: 0.0393s/iter; left time: 701.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0690746 Vali Loss: 0.0869953 Test Loss: 0.0899402\n",
      "Validation loss decreased (0.087007 --> 0.086995).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651725\n",
      "\tspeed: 0.0742s/iter; left time: 1316.4065s\n",
      "\titers: 200, epoch: 21 | loss: 0.0694971\n",
      "\tspeed: 0.0389s/iter; left time: 685.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 223 | Train Loss: 0.0689198 Vali Loss: 0.0872683 Test Loss: 0.0901109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0678065\n",
      "\tspeed: 0.0734s/iter; left time: 1285.7012s\n",
      "\titers: 200, epoch: 22 | loss: 0.0765335\n",
      "\tspeed: 0.0392s/iter; left time: 682.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0687780 Vali Loss: 0.0869619 Test Loss: 0.0899195\n",
      "Validation loss decreased (0.086995 --> 0.086962).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0678848\n",
      "\tspeed: 0.0752s/iter; left time: 1300.9009s\n",
      "\titers: 200, epoch: 23 | loss: 0.0687558\n",
      "\tspeed: 0.0394s/iter; left time: 676.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0687458 Vali Loss: 0.0870782 Test Loss: 0.0901198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0689096\n",
      "\tspeed: 0.0740s/iter; left time: 1262.9620s\n",
      "\titers: 200, epoch: 24 | loss: 0.0632926\n",
      "\tspeed: 0.0396s/iter; left time: 672.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 223 | Train Loss: 0.0686266 Vali Loss: 0.0868974 Test Loss: 0.0899454\n",
      "Validation loss decreased (0.086962 --> 0.086897).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0690079\n",
      "\tspeed: 0.0743s/iter; left time: 1251.7148s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721449\n",
      "\tspeed: 0.0395s/iter; left time: 661.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0685004 Vali Loss: 0.0871989 Test Loss: 0.0900799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0687096\n",
      "\tspeed: 0.0737s/iter; left time: 1225.7210s\n",
      "\titers: 200, epoch: 26 | loss: 0.0710688\n",
      "\tspeed: 0.0392s/iter; left time: 647.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0684957 Vali Loss: 0.0871168 Test Loss: 0.0899808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0642295\n",
      "\tspeed: 0.0735s/iter; left time: 1205.5229s\n",
      "\titers: 200, epoch: 27 | loss: 0.0659218\n",
      "\tspeed: 0.0394s/iter; left time: 642.7608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0683640 Vali Loss: 0.0870550 Test Loss: 0.0899583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0642235\n",
      "\tspeed: 0.0746s/iter; left time: 1207.6054s\n",
      "\titers: 200, epoch: 28 | loss: 0.0690017\n",
      "\tspeed: 0.0400s/iter; left time: 643.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 223 | Train Loss: 0.0683829 Vali Loss: 0.0871987 Test Loss: 0.0901412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0705739\n",
      "\tspeed: 0.0773s/iter; left time: 1234.1577s\n",
      "\titers: 200, epoch: 29 | loss: 0.0647701\n",
      "\tspeed: 0.0406s/iter; left time: 644.0997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0683098 Vali Loss: 0.0873242 Test Loss: 0.0901052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0681651\n",
      "\tspeed: 0.0742s/iter; left time: 1168.1975s\n",
      "\titers: 200, epoch: 30 | loss: 0.0676674\n",
      "\tspeed: 0.0393s/iter; left time: 614.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0682895 Vali Loss: 0.0871748 Test Loss: 0.0900059\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0673058\n",
      "\tspeed: 0.0731s/iter; left time: 1134.1918s\n",
      "\titers: 200, epoch: 31 | loss: 0.0664348\n",
      "\tspeed: 0.0393s/iter; left time: 605.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0682102 Vali Loss: 0.0870394 Test Loss: 0.0901751\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0660020\n",
      "\tspeed: 0.0739s/iter; left time: 1130.3651s\n",
      "\titers: 200, epoch: 32 | loss: 0.0637015\n",
      "\tspeed: 0.0400s/iter; left time: 607.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 223 | Train Loss: 0.0682256 Vali Loss: 0.0870955 Test Loss: 0.0900244\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0724259\n",
      "\tspeed: 0.0738s/iter; left time: 1111.8520s\n",
      "\titers: 200, epoch: 33 | loss: 0.0720216\n",
      "\tspeed: 0.0392s/iter; left time: 586.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0681541 Vali Loss: 0.0870745 Test Loss: 0.0900343\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0680007\n",
      "\tspeed: 0.0750s/iter; left time: 1113.8362s\n",
      "\titers: 200, epoch: 34 | loss: 0.0696984\n",
      "\tspeed: 0.0392s/iter; left time: 578.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0681028 Vali Loss: 0.0871005 Test Loss: 0.0900277\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02139110304415226, rmse:0.14625698328018188, mae:0.08994536846876144, rse:0.5161610841751099\n",
      "Intermediate time for DE and pred_len 24: 00h:10m:38.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600669\n",
      "\tspeed: 0.0680s/iter; left time: 1503.7225s\n",
      "\titers: 200, epoch: 1 | loss: 0.1527673\n",
      "\tspeed: 0.0398s/iter; left time: 875.0232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1611702 Vali Loss: 0.1621645 Test Loss: 0.1750328\n",
      "Validation loss decreased (inf --> 0.162165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156927\n",
      "\tspeed: 0.0764s/iter; left time: 1670.9997s\n",
      "\titers: 200, epoch: 2 | loss: 0.1021599\n",
      "\tspeed: 0.0403s/iter; left time: 877.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1205411 Vali Loss: 0.1230662 Test Loss: 0.1297388\n",
      "Validation loss decreased (0.162165 --> 0.123066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1009320\n",
      "\tspeed: 0.0752s/iter; left time: 1628.4722s\n",
      "\titers: 200, epoch: 3 | loss: 0.1045488\n",
      "\tspeed: 0.0398s/iter; left time: 858.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1062302 Vali Loss: 0.1199998 Test Loss: 0.1273548\n",
      "Validation loss decreased (0.123066 --> 0.120000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045803\n",
      "\tspeed: 0.0755s/iter; left time: 1619.1510s\n",
      "\titers: 200, epoch: 4 | loss: 0.1029762\n",
      "\tspeed: 0.0402s/iter; left time: 857.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1030366 Vali Loss: 0.1189446 Test Loss: 0.1263045\n",
      "Validation loss decreased (0.120000 --> 0.118945).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036077\n",
      "\tspeed: 0.0770s/iter; left time: 1633.8494s\n",
      "\titers: 200, epoch: 5 | loss: 0.1049879\n",
      "\tspeed: 0.0398s/iter; left time: 840.2776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1012221 Vali Loss: 0.1186936 Test Loss: 0.1251391\n",
      "Validation loss decreased (0.118945 --> 0.118694).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1007111\n",
      "\tspeed: 0.0769s/iter; left time: 1615.1526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0951548\n",
      "\tspeed: 0.0405s/iter; left time: 846.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.0998083 Vali Loss: 0.1190142 Test Loss: 0.1252121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0942722\n",
      "\tspeed: 0.0777s/iter; left time: 1613.9195s\n",
      "\titers: 200, epoch: 7 | loss: 0.1007469\n",
      "\tspeed: 0.0417s/iter; left time: 861.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0985169 Vali Loss: 0.1187003 Test Loss: 0.1249588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0996086\n",
      "\tspeed: 0.0743s/iter; left time: 1527.2152s\n",
      "\titers: 200, epoch: 8 | loss: 0.0962064\n",
      "\tspeed: 0.0399s/iter; left time: 814.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.0972846 Vali Loss: 0.1195242 Test Loss: 0.1259775\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0946268\n",
      "\tspeed: 0.0768s/iter; left time: 1560.0477s\n",
      "\titers: 200, epoch: 9 | loss: 0.0944993\n",
      "\tspeed: 0.0418s/iter; left time: 845.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0961611 Vali Loss: 0.1196051 Test Loss: 0.1262500\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0949965\n",
      "\tspeed: 0.0767s/iter; left time: 1540.9548s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985169\n",
      "\tspeed: 0.0417s/iter; left time: 833.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.0950249 Vali Loss: 0.1201942 Test Loss: 0.1268933\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0943173\n",
      "\tspeed: 0.0765s/iter; left time: 1520.2123s\n",
      "\titers: 200, epoch: 11 | loss: 0.0888833\n",
      "\tspeed: 0.0398s/iter; left time: 787.9282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0939013 Vali Loss: 0.1201605 Test Loss: 0.1275077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0947640\n",
      "\tspeed: 0.0771s/iter; left time: 1516.2026s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940488\n",
      "\tspeed: 0.0406s/iter; left time: 795.0462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0928736 Vali Loss: 0.1207160 Test Loss: 0.1283039\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872432\n",
      "\tspeed: 0.0763s/iter; left time: 1483.1805s\n",
      "\titers: 200, epoch: 13 | loss: 0.0938069\n",
      "\tspeed: 0.0403s/iter; left time: 779.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.0918952 Vali Loss: 0.1211996 Test Loss: 0.1288645\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0912930\n",
      "\tspeed: 0.0767s/iter; left time: 1473.1480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0899064\n",
      "\tspeed: 0.0404s/iter; left time: 773.0789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.0910675 Vali Loss: 0.1213230 Test Loss: 0.1302743\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0948955\n",
      "\tspeed: 0.0750s/iter; left time: 1424.0803s\n",
      "\titers: 200, epoch: 15 | loss: 0.0847715\n",
      "\tspeed: 0.0396s/iter; left time: 748.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.0904130 Vali Loss: 0.1214363 Test Loss: 0.1296028\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03564053028821945, rmse:0.18878699839115143, mae:0.12513910233974457, rse:0.6685329079627991\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1585158\n",
      "\tspeed: 0.0436s/iter; left time: 962.6003s\n",
      "\titers: 200, epoch: 1 | loss: 0.1524044\n",
      "\tspeed: 0.0405s/iter; left time: 891.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1610517 Vali Loss: 0.1623402 Test Loss: 0.1751056\n",
      "Validation loss decreased (inf --> 0.162340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1197549\n",
      "\tspeed: 0.0788s/iter; left time: 1724.1082s\n",
      "\titers: 200, epoch: 2 | loss: 0.1077989\n",
      "\tspeed: 0.0423s/iter; left time: 921.9596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.1204545 Vali Loss: 0.1228454 Test Loss: 0.1303715\n",
      "Validation loss decreased (0.162340 --> 0.122845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1086880\n",
      "\tspeed: 0.0781s/iter; left time: 1690.7934s\n",
      "\titers: 200, epoch: 3 | loss: 0.1087148\n",
      "\tspeed: 0.0401s/iter; left time: 865.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1062672 Vali Loss: 0.1192858 Test Loss: 0.1270949\n",
      "Validation loss decreased (0.122845 --> 0.119286).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068478\n",
      "\tspeed: 0.0795s/iter; left time: 1704.3755s\n",
      "\titers: 200, epoch: 4 | loss: 0.0937039\n",
      "\tspeed: 0.0406s/iter; left time: 866.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1030713 Vali Loss: 0.1185084 Test Loss: 0.1258031\n",
      "Validation loss decreased (0.119286 --> 0.118508).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005776\n",
      "\tspeed: 0.0782s/iter; left time: 1659.6993s\n",
      "\titers: 200, epoch: 5 | loss: 0.0998916\n",
      "\tspeed: 0.0409s/iter; left time: 864.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1013403 Vali Loss: 0.1183625 Test Loss: 0.1256153\n",
      "Validation loss decreased (0.118508 --> 0.118363).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1000169\n",
      "\tspeed: 0.0779s/iter; left time: 1635.3777s\n",
      "\titers: 200, epoch: 6 | loss: 0.0984202\n",
      "\tspeed: 0.0405s/iter; left time: 846.6629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.0998020 Vali Loss: 0.1180264 Test Loss: 0.1255330\n",
      "Validation loss decreased (0.118363 --> 0.118026).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014176\n",
      "\tspeed: 0.0787s/iter; left time: 1634.0812s\n",
      "\titers: 200, epoch: 7 | loss: 0.0947941\n",
      "\tspeed: 0.0412s/iter; left time: 850.6048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0984298 Vali Loss: 0.1186043 Test Loss: 0.1261357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0947239\n",
      "\tspeed: 0.0783s/iter; left time: 1608.9292s\n",
      "\titers: 200, epoch: 8 | loss: 0.0987961\n",
      "\tspeed: 0.0414s/iter; left time: 847.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.0969922 Vali Loss: 0.1188005 Test Loss: 0.1267570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0956844\n",
      "\tspeed: 0.0770s/iter; left time: 1565.8176s\n",
      "\titers: 200, epoch: 9 | loss: 0.0946037\n",
      "\tspeed: 0.0406s/iter; left time: 821.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.0958029 Vali Loss: 0.1186884 Test Loss: 0.1261335\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0925317\n",
      "\tspeed: 0.0786s/iter; left time: 1580.1544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947608\n",
      "\tspeed: 0.0411s/iter; left time: 821.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0944651 Vali Loss: 0.1192054 Test Loss: 0.1269687\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0914042\n",
      "\tspeed: 0.0758s/iter; left time: 1506.1422s\n",
      "\titers: 200, epoch: 11 | loss: 0.0934613\n",
      "\tspeed: 0.0406s/iter; left time: 803.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0933464 Vali Loss: 0.1195102 Test Loss: 0.1280126\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0993447\n",
      "\tspeed: 0.0770s/iter; left time: 1512.9925s\n",
      "\titers: 200, epoch: 12 | loss: 0.0977269\n",
      "\tspeed: 0.0403s/iter; left time: 788.8996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0923186 Vali Loss: 0.1199271 Test Loss: 0.1276711\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0880250\n",
      "\tspeed: 0.0779s/iter; left time: 1514.3929s\n",
      "\titers: 200, epoch: 13 | loss: 0.0930575\n",
      "\tspeed: 0.0422s/iter; left time: 816.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.0914104 Vali Loss: 0.1206686 Test Loss: 0.1277122\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0912447\n",
      "\tspeed: 0.0777s/iter; left time: 1492.0540s\n",
      "\titers: 200, epoch: 14 | loss: 0.0931837\n",
      "\tspeed: 0.0414s/iter; left time: 791.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.0906323 Vali Loss: 0.1208091 Test Loss: 0.1288277\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0940887\n",
      "\tspeed: 0.0775s/iter; left time: 1472.4761s\n",
      "\titers: 200, epoch: 15 | loss: 0.0872629\n",
      "\tspeed: 0.0410s/iter; left time: 774.6838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0898379 Vali Loss: 0.1214956 Test Loss: 0.1297098\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0906460\n",
      "\tspeed: 0.0770s/iter; left time: 1445.7022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0921967\n",
      "\tspeed: 0.0403s/iter; left time: 751.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.0893114 Vali Loss: 0.1218835 Test Loss: 0.1290730\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.035144589841365814, rmse:0.18746890127658844, mae:0.12553302943706512, rse:0.663865327835083\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:19.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1637948\n",
      "\tspeed: 0.0683s/iter; left time: 1510.0175s\n",
      "\titers: 200, epoch: 1 | loss: 0.1558273\n",
      "\tspeed: 0.0401s/iter; left time: 882.8915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1622484 Vali Loss: 0.1636669 Test Loss: 0.1774525\n",
      "Validation loss decreased (inf --> 0.163667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1249573\n",
      "\tspeed: 0.0788s/iter; left time: 1723.0806s\n",
      "\titers: 200, epoch: 2 | loss: 0.1134416\n",
      "\tspeed: 0.0418s/iter; left time: 910.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1245685 Vali Loss: 0.1267606 Test Loss: 0.1353316\n",
      "Validation loss decreased (0.163667 --> 0.126761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139607\n",
      "\tspeed: 0.0788s/iter; left time: 1707.1060s\n",
      "\titers: 200, epoch: 3 | loss: 0.1124243\n",
      "\tspeed: 0.0408s/iter; left time: 880.5385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1115572 Vali Loss: 0.1236479 Test Loss: 0.1326398\n",
      "Validation loss decreased (0.126761 --> 0.123648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040074\n",
      "\tspeed: 0.0799s/iter; left time: 1711.8536s\n",
      "\titers: 200, epoch: 4 | loss: 0.1049048\n",
      "\tspeed: 0.0409s/iter; left time: 872.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1086400 Vali Loss: 0.1225734 Test Loss: 0.1323809\n",
      "Validation loss decreased (0.123648 --> 0.122573).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1034284\n",
      "\tspeed: 0.0789s/iter; left time: 1674.3579s\n",
      "\titers: 200, epoch: 5 | loss: 0.1017302\n",
      "\tspeed: 0.0405s/iter; left time: 854.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1066127 Vali Loss: 0.1225914 Test Loss: 0.1321557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1031749\n",
      "\tspeed: 0.0758s/iter; left time: 1590.9584s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042629\n",
      "\tspeed: 0.0401s/iter; left time: 837.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1045670 Vali Loss: 0.1225011 Test Loss: 0.1323627\n",
      "Validation loss decreased (0.122573 --> 0.122501).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1010065\n",
      "\tspeed: 0.0763s/iter; left time: 1585.4442s\n",
      "\titers: 200, epoch: 7 | loss: 0.1014691\n",
      "\tspeed: 0.0405s/iter; left time: 836.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1026140 Vali Loss: 0.1219549 Test Loss: 0.1336804\n",
      "Validation loss decreased (0.122501 --> 0.121955).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998419\n",
      "\tspeed: 0.0786s/iter; left time: 1615.4701s\n",
      "\titers: 200, epoch: 8 | loss: 0.0962954\n",
      "\tspeed: 0.0402s/iter; left time: 821.9132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1009039 Vali Loss: 0.1222688 Test Loss: 0.1343412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0978708\n",
      "\tspeed: 0.0803s/iter; left time: 1631.7334s\n",
      "\titers: 200, epoch: 9 | loss: 0.0966941\n",
      "\tspeed: 0.0413s/iter; left time: 835.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.0993450 Vali Loss: 0.1233286 Test Loss: 0.1352878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0956978\n",
      "\tspeed: 0.0760s/iter; left time: 1528.4255s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998351\n",
      "\tspeed: 0.0405s/iter; left time: 809.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.0979509 Vali Loss: 0.1236695 Test Loss: 0.1353929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1006201\n",
      "\tspeed: 0.0755s/iter; left time: 1501.3466s\n",
      "\titers: 200, epoch: 11 | loss: 0.0961271\n",
      "\tspeed: 0.0404s/iter; left time: 799.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.0967615 Vali Loss: 0.1239721 Test Loss: 0.1361289\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0960294\n",
      "\tspeed: 0.0746s/iter; left time: 1466.3961s\n",
      "\titers: 200, epoch: 12 | loss: 0.0977076\n",
      "\tspeed: 0.0403s/iter; left time: 788.5322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0956423 Vali Loss: 0.1243947 Test Loss: 0.1360776\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0998066\n",
      "\tspeed: 0.0751s/iter; left time: 1459.9454s\n",
      "\titers: 200, epoch: 13 | loss: 0.0910464\n",
      "\tspeed: 0.0401s/iter; left time: 775.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 222 | Train Loss: 0.0946886 Vali Loss: 0.1252855 Test Loss: 0.1368607\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967988\n",
      "\tspeed: 0.0754s/iter; left time: 1448.3745s\n",
      "\titers: 200, epoch: 14 | loss: 0.0936563\n",
      "\tspeed: 0.0405s/iter; left time: 774.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.0938332 Vali Loss: 0.1249425 Test Loss: 0.1372831\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0942873\n",
      "\tspeed: 0.0752s/iter; left time: 1428.4053s\n",
      "\titers: 200, epoch: 15 | loss: 0.0892866\n",
      "\tspeed: 0.0403s/iter; left time: 760.4539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.0930495 Vali Loss: 0.1255569 Test Loss: 0.1380603\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0922364\n",
      "\tspeed: 0.0748s/iter; left time: 1403.7542s\n",
      "\titers: 200, epoch: 16 | loss: 0.0925183\n",
      "\tspeed: 0.0404s/iter; left time: 754.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.0925319 Vali Loss: 0.1259017 Test Loss: 0.1376587\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0930251\n",
      "\tspeed: 0.0773s/iter; left time: 1434.6880s\n",
      "\titers: 200, epoch: 17 | loss: 0.0930177\n",
      "\tspeed: 0.0406s/iter; left time: 749.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.0919379 Vali Loss: 0.1258813 Test Loss: 0.1382186\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03840918093919754, rmse:0.19598260521888733, mae:0.13368038833141327, rse:0.6941861510276794\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1589826\n",
      "\tspeed: 0.0428s/iter; left time: 946.9097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1600245\n",
      "\tspeed: 0.0404s/iter; left time: 888.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1628138 Vali Loss: 0.1642195 Test Loss: 0.1779769\n",
      "Validation loss decreased (inf --> 0.164220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1231840\n",
      "\tspeed: 0.0771s/iter; left time: 1685.9928s\n",
      "\titers: 200, epoch: 2 | loss: 0.1197779\n",
      "\tspeed: 0.0404s/iter; left time: 878.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1254261 Vali Loss: 0.1268570 Test Loss: 0.1356405\n",
      "Validation loss decreased (0.164220 --> 0.126857).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1180012\n",
      "\tspeed: 0.0768s/iter; left time: 1664.0592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048214\n",
      "\tspeed: 0.0401s/iter; left time: 865.1136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 222 | Train Loss: 0.1118843 Vali Loss: 0.1233901 Test Loss: 0.1329493\n",
      "Validation loss decreased (0.126857 --> 0.123390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1022953\n",
      "\tspeed: 0.0766s/iter; left time: 1642.2383s\n",
      "\titers: 200, epoch: 4 | loss: 0.1081269\n",
      "\tspeed: 0.0400s/iter; left time: 853.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1087229 Vali Loss: 0.1224606 Test Loss: 0.1320337\n",
      "Validation loss decreased (0.123390 --> 0.122461).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1104084\n",
      "\tspeed: 0.0785s/iter; left time: 1665.8815s\n",
      "\titers: 200, epoch: 5 | loss: 0.1079825\n",
      "\tspeed: 0.0403s/iter; left time: 849.9804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1065371 Vali Loss: 0.1219001 Test Loss: 0.1320212\n",
      "Validation loss decreased (0.122461 --> 0.121900).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1033093\n",
      "\tspeed: 0.0770s/iter; left time: 1617.1488s\n",
      "\titers: 200, epoch: 6 | loss: 0.1002939\n",
      "\tspeed: 0.0401s/iter; left time: 838.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.1045883 Vali Loss: 0.1220449 Test Loss: 0.1325750\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1022260\n",
      "\tspeed: 0.0768s/iter; left time: 1594.0720s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031185\n",
      "\tspeed: 0.0401s/iter; left time: 829.5483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1026898 Vali Loss: 0.1224644 Test Loss: 0.1322432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016527\n",
      "\tspeed: 0.0761s/iter; left time: 1563.1718s\n",
      "\titers: 200, epoch: 8 | loss: 0.0993714\n",
      "\tspeed: 0.0405s/iter; left time: 827.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1007898 Vali Loss: 0.1226913 Test Loss: 0.1339313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0998640\n",
      "\tspeed: 0.0763s/iter; left time: 1550.5193s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001434\n",
      "\tspeed: 0.0402s/iter; left time: 813.1632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.0989265 Vali Loss: 0.1232066 Test Loss: 0.1346138\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0946698\n",
      "\tspeed: 0.0764s/iter; left time: 1536.6650s\n",
      "\titers: 200, epoch: 10 | loss: 0.0994346\n",
      "\tspeed: 0.0400s/iter; left time: 800.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.0973122 Vali Loss: 0.1235026 Test Loss: 0.1345903\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0928850\n",
      "\tspeed: 0.0768s/iter; left time: 1526.9758s\n",
      "\titers: 200, epoch: 11 | loss: 0.0987797\n",
      "\tspeed: 0.0404s/iter; left time: 799.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.0959640 Vali Loss: 0.1240801 Test Loss: 0.1351399\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0921602\n",
      "\tspeed: 0.0766s/iter; left time: 1506.5559s\n",
      "\titers: 200, epoch: 12 | loss: 0.0950019\n",
      "\tspeed: 0.0405s/iter; left time: 791.7764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0947946 Vali Loss: 0.1246165 Test Loss: 0.1354302\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0968398\n",
      "\tspeed: 0.0777s/iter; left time: 1510.9294s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915866\n",
      "\tspeed: 0.0418s/iter; left time: 807.4137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.0938127 Vali Loss: 0.1240539 Test Loss: 0.1357256\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0919161\n",
      "\tspeed: 0.0758s/iter; left time: 1455.6502s\n",
      "\titers: 200, epoch: 14 | loss: 0.0942523\n",
      "\tspeed: 0.0402s/iter; left time: 767.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.0929461 Vali Loss: 0.1242172 Test Loss: 0.1358479\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0934670\n",
      "\tspeed: 0.0757s/iter; left time: 1437.7464s\n",
      "\titers: 200, epoch: 15 | loss: 0.0899981\n",
      "\tspeed: 0.0400s/iter; left time: 755.7287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.0922789 Vali Loss: 0.1248387 Test Loss: 0.1364546\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.037806104868650436, rmse:0.1944379210472107, mae:0.13202132284641266, rse:0.6887147426605225\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:30.56s\n",
      "Intermediate time for DE: 00h:23m:28.79s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1432123\n",
      "\tspeed: 0.0681s/iter; left time: 1512.3956s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282094\n",
      "\tspeed: 0.0398s/iter; left time: 878.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.1396746 Vali Loss: 0.1393305 Test Loss: 0.1622373\n",
      "Validation loss decreased (inf --> 0.139330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0951777\n",
      "\tspeed: 0.0742s/iter; left time: 1630.7966s\n",
      "\titers: 200, epoch: 2 | loss: 0.0778341\n",
      "\tspeed: 0.0393s/iter; left time: 859.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0947363 Vali Loss: 0.0933725 Test Loss: 0.1051049\n",
      "Validation loss decreased (0.139330 --> 0.093373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0783852\n",
      "\tspeed: 0.0753s/iter; left time: 1637.2258s\n",
      "\titers: 200, epoch: 3 | loss: 0.0741457\n",
      "\tspeed: 0.0401s/iter; left time: 868.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0796153 Vali Loss: 0.0909919 Test Loss: 0.1027080\n",
      "Validation loss decreased (0.093373 --> 0.090992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0793956\n",
      "\tspeed: 0.0783s/iter; left time: 1685.2003s\n",
      "\titers: 200, epoch: 4 | loss: 0.0776062\n",
      "\tspeed: 0.0394s/iter; left time: 845.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0773601 Vali Loss: 0.0904026 Test Loss: 0.1022681\n",
      "Validation loss decreased (0.090992 --> 0.090403).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0745519\n",
      "\tspeed: 0.0742s/iter; left time: 1580.4181s\n",
      "\titers: 200, epoch: 5 | loss: 0.0764645\n",
      "\tspeed: 0.0393s/iter; left time: 833.2299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0761149 Vali Loss: 0.0897204 Test Loss: 0.1014479\n",
      "Validation loss decreased (0.090403 --> 0.089720).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752737\n",
      "\tspeed: 0.0757s/iter; left time: 1595.2531s\n",
      "\titers: 200, epoch: 6 | loss: 0.0807177\n",
      "\tspeed: 0.0401s/iter; left time: 842.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0752766 Vali Loss: 0.0888971 Test Loss: 0.1019252\n",
      "Validation loss decreased (0.089720 --> 0.088897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0710548\n",
      "\tspeed: 0.0743s/iter; left time: 1550.1364s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746819\n",
      "\tspeed: 0.0397s/iter; left time: 825.3059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0746119 Vali Loss: 0.0893179 Test Loss: 0.1016962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0712430\n",
      "\tspeed: 0.0759s/iter; left time: 1566.9014s\n",
      "\titers: 200, epoch: 8 | loss: 0.0736699\n",
      "\tspeed: 0.0413s/iter; left time: 847.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0740003 Vali Loss: 0.0887310 Test Loss: 0.1019839\n",
      "Validation loss decreased (0.088897 --> 0.088731).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734583\n",
      "\tspeed: 0.0747s/iter; left time: 1525.5114s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759790\n",
      "\tspeed: 0.0392s/iter; left time: 797.4232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0736072 Vali Loss: 0.0884793 Test Loss: 0.1018404\n",
      "Validation loss decreased (0.088731 --> 0.088479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0762913\n",
      "\tspeed: 0.0737s/iter; left time: 1487.9060s\n",
      "\titers: 200, epoch: 10 | loss: 0.0752624\n",
      "\tspeed: 0.0392s/iter; left time: 788.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0732726 Vali Loss: 0.0883747 Test Loss: 0.1016981\n",
      "Validation loss decreased (0.088479 --> 0.088375).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739641\n",
      "\tspeed: 0.0745s/iter; left time: 1487.8242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0800824\n",
      "\tspeed: 0.0394s/iter; left time: 783.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 223 | Train Loss: 0.0729142 Vali Loss: 0.0884058 Test Loss: 0.1018832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0730774\n",
      "\tspeed: 0.0740s/iter; left time: 1460.5303s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722421\n",
      "\tspeed: 0.0396s/iter; left time: 777.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 223 | Train Loss: 0.0726127 Vali Loss: 0.0881956 Test Loss: 0.1017841\n",
      "Validation loss decreased (0.088375 --> 0.088196).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0685261\n",
      "\tspeed: 0.0754s/iter; left time: 1472.5873s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687956\n",
      "\tspeed: 0.0393s/iter; left time: 763.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0723763 Vali Loss: 0.0881572 Test Loss: 0.1017773\n",
      "Validation loss decreased (0.088196 --> 0.088157).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771289\n",
      "\tspeed: 0.0749s/iter; left time: 1445.9927s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723521\n",
      "\tspeed: 0.0398s/iter; left time: 764.8880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0720819 Vali Loss: 0.0879894 Test Loss: 0.1018722\n",
      "Validation loss decreased (0.088157 --> 0.087989).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0715121\n",
      "\tspeed: 0.0744s/iter; left time: 1419.7271s\n",
      "\titers: 200, epoch: 15 | loss: 0.0745759\n",
      "\tspeed: 0.0392s/iter; left time: 744.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0718524 Vali Loss: 0.0881718 Test Loss: 0.1020897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0731282\n",
      "\tspeed: 0.0725s/iter; left time: 1367.4923s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744459\n",
      "\tspeed: 0.0394s/iter; left time: 739.4598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0716612 Vali Loss: 0.0883592 Test Loss: 0.1022563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0693578\n",
      "\tspeed: 0.0733s/iter; left time: 1365.6634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0707198\n",
      "\tspeed: 0.0394s/iter; left time: 731.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0714756 Vali Loss: 0.0882376 Test Loss: 0.1017597\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713619\n",
      "\tspeed: 0.0731s/iter; left time: 1345.8097s\n",
      "\titers: 200, epoch: 18 | loss: 0.0734985\n",
      "\tspeed: 0.0395s/iter; left time: 723.9853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0714082 Vali Loss: 0.0883376 Test Loss: 0.1021778\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0751653\n",
      "\tspeed: 0.0739s/iter; left time: 1344.4790s\n",
      "\titers: 200, epoch: 19 | loss: 0.0753849\n",
      "\tspeed: 0.0402s/iter; left time: 727.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0712462 Vali Loss: 0.0880648 Test Loss: 0.1020453\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0679944\n",
      "\tspeed: 0.0731s/iter; left time: 1312.8161s\n",
      "\titers: 200, epoch: 20 | loss: 0.0726969\n",
      "\tspeed: 0.0398s/iter; left time: 711.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0710828 Vali Loss: 0.0882135 Test Loss: 0.1021130\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699968\n",
      "\tspeed: 0.0738s/iter; left time: 1308.5221s\n",
      "\titers: 200, epoch: 21 | loss: 0.0764337\n",
      "\tspeed: 0.0401s/iter; left time: 706.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0709943 Vali Loss: 0.0881673 Test Loss: 0.1021165\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0671451\n",
      "\tspeed: 0.0733s/iter; left time: 1284.6844s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705989\n",
      "\tspeed: 0.0395s/iter; left time: 687.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0708585 Vali Loss: 0.0881698 Test Loss: 0.1020419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0700505\n",
      "\tspeed: 0.0732s/iter; left time: 1266.4978s\n",
      "\titers: 200, epoch: 23 | loss: 0.0745684\n",
      "\tspeed: 0.0394s/iter; left time: 678.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0707959 Vali Loss: 0.0881616 Test Loss: 0.1024151\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0690730\n",
      "\tspeed: 0.0730s/iter; left time: 1245.4811s\n",
      "\titers: 200, epoch: 24 | loss: 0.0712544\n",
      "\tspeed: 0.0390s/iter; left time: 662.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0707517 Vali Loss: 0.0881807 Test Loss: 0.1019920\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02565113641321659, rmse:0.16015972197055817, mae:0.10187219828367233, rse:0.5525056719779968\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1476764\n",
      "\tspeed: 0.0422s/iter; left time: 937.6935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349923\n",
      "\tspeed: 0.0401s/iter; left time: 886.6712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.1402989 Vali Loss: 0.1396245 Test Loss: 0.1621065\n",
      "Validation loss decreased (inf --> 0.139625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0961650\n",
      "\tspeed: 0.0763s/iter; left time: 1677.7422s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827597\n",
      "\tspeed: 0.0392s/iter; left time: 857.0744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0954318 Vali Loss: 0.0943644 Test Loss: 0.1065690\n",
      "Validation loss decreased (0.139625 --> 0.094364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845987\n",
      "\tspeed: 0.0749s/iter; left time: 1628.3897s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792703\n",
      "\tspeed: 0.0397s/iter; left time: 860.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0799388 Vali Loss: 0.0911665 Test Loss: 0.1031031\n",
      "Validation loss decreased (0.094364 --> 0.091167).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0772284\n",
      "\tspeed: 0.0741s/iter; left time: 1596.1812s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765794\n",
      "\tspeed: 0.0394s/iter; left time: 844.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0776169 Vali Loss: 0.0903608 Test Loss: 0.1030993\n",
      "Validation loss decreased (0.091167 --> 0.090361).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0747140\n",
      "\tspeed: 0.0766s/iter; left time: 1632.5948s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721048\n",
      "\tspeed: 0.0415s/iter; left time: 880.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0762570 Vali Loss: 0.0900963 Test Loss: 0.1027058\n",
      "Validation loss decreased (0.090361 --> 0.090096).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0697034\n",
      "\tspeed: 0.0759s/iter; left time: 1599.5231s\n",
      "\titers: 200, epoch: 6 | loss: 0.0743171\n",
      "\tspeed: 0.0394s/iter; left time: 826.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0753807 Vali Loss: 0.0897229 Test Loss: 0.1022076\n",
      "Validation loss decreased (0.090096 --> 0.089723).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0747862\n",
      "\tspeed: 0.0759s/iter; left time: 1583.5758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743631\n",
      "\tspeed: 0.0400s/iter; left time: 830.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 223 | Train Loss: 0.0747150 Vali Loss: 0.0891738 Test Loss: 0.1027199\n",
      "Validation loss decreased (0.089723 --> 0.089174).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750424\n",
      "\tspeed: 0.0748s/iter; left time: 1543.2777s\n",
      "\titers: 200, epoch: 8 | loss: 0.0677717\n",
      "\tspeed: 0.0394s/iter; left time: 809.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0741094 Vali Loss: 0.0889366 Test Loss: 0.1020847\n",
      "Validation loss decreased (0.089174 --> 0.088937).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711122\n",
      "\tspeed: 0.0744s/iter; left time: 1518.4853s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760797\n",
      "\tspeed: 0.0397s/iter; left time: 806.1133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0737450 Vali Loss: 0.0886982 Test Loss: 0.1020859\n",
      "Validation loss decreased (0.088937 --> 0.088698).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793462\n",
      "\tspeed: 0.0754s/iter; left time: 1523.1549s\n",
      "\titers: 200, epoch: 10 | loss: 0.0691939\n",
      "\tspeed: 0.0397s/iter; left time: 797.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 223 | Train Loss: 0.0733139 Vali Loss: 0.0886391 Test Loss: 0.1024255\n",
      "Validation loss decreased (0.088698 --> 0.088639).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746733\n",
      "\tspeed: 0.0745s/iter; left time: 1488.8025s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676955\n",
      "\tspeed: 0.0396s/iter; left time: 786.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0730556 Vali Loss: 0.0886227 Test Loss: 0.1025077\n",
      "Validation loss decreased (0.088639 --> 0.088623).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752938\n",
      "\tspeed: 0.0746s/iter; left time: 1472.6832s\n",
      "\titers: 200, epoch: 12 | loss: 0.0737555\n",
      "\tspeed: 0.0398s/iter; left time: 782.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 223 | Train Loss: 0.0727082 Vali Loss: 0.0886729 Test Loss: 0.1018626\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0706257\n",
      "\tspeed: 0.0730s/iter; left time: 1424.9115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0750554\n",
      "\tspeed: 0.0393s/iter; left time: 763.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0724606 Vali Loss: 0.0885971 Test Loss: 0.1019840\n",
      "Validation loss decreased (0.088623 --> 0.088597).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687880\n",
      "\tspeed: 0.0767s/iter; left time: 1480.0116s\n",
      "\titers: 200, epoch: 14 | loss: 0.0700276\n",
      "\tspeed: 0.0401s/iter; left time: 769.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.0721414 Vali Loss: 0.0884503 Test Loss: 0.1021581\n",
      "Validation loss decreased (0.088597 --> 0.088450).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0736492\n",
      "\tspeed: 0.0769s/iter; left time: 1466.5547s\n",
      "\titers: 200, epoch: 15 | loss: 0.0704719\n",
      "\tspeed: 0.0405s/iter; left time: 768.0249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0720265 Vali Loss: 0.0885820 Test Loss: 0.1025253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0738495\n",
      "\tspeed: 0.0759s/iter; left time: 1431.5196s\n",
      "\titers: 200, epoch: 16 | loss: 0.0767625\n",
      "\tspeed: 0.0392s/iter; left time: 736.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0718210 Vali Loss: 0.0884989 Test Loss: 0.1024746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754377\n",
      "\tspeed: 0.0749s/iter; left time: 1395.6908s\n",
      "\titers: 200, epoch: 17 | loss: 0.0739776\n",
      "\tspeed: 0.0394s/iter; left time: 729.3888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0716716 Vali Loss: 0.0883125 Test Loss: 0.1023251\n",
      "Validation loss decreased (0.088450 --> 0.088313).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0675483\n",
      "\tspeed: 0.0737s/iter; left time: 1356.2080s\n",
      "\titers: 200, epoch: 18 | loss: 0.0695482\n",
      "\tspeed: 0.0396s/iter; left time: 725.5010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0714921 Vali Loss: 0.0883892 Test Loss: 0.1023845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734640\n",
      "\tspeed: 0.0743s/iter; left time: 1351.0172s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759828\n",
      "\tspeed: 0.0396s/iter; left time: 716.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0714164 Vali Loss: 0.0884977 Test Loss: 0.1024617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0726497\n",
      "\tspeed: 0.0735s/iter; left time: 1319.6149s\n",
      "\titers: 200, epoch: 20 | loss: 0.0697834\n",
      "\tspeed: 0.0396s/iter; left time: 707.8944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0712118 Vali Loss: 0.0884449 Test Loss: 0.1026849\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0770420\n",
      "\tspeed: 0.0734s/iter; left time: 1302.2758s\n",
      "\titers: 200, epoch: 21 | loss: 0.0688247\n",
      "\tspeed: 0.0393s/iter; left time: 692.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0711189 Vali Loss: 0.0885552 Test Loss: 0.1027026\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706759\n",
      "\tspeed: 0.0738s/iter; left time: 1292.2056s\n",
      "\titers: 200, epoch: 22 | loss: 0.0718844\n",
      "\tspeed: 0.0394s/iter; left time: 685.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0709853 Vali Loss: 0.0884013 Test Loss: 0.1025447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0689843\n",
      "\tspeed: 0.0740s/iter; left time: 1279.1615s\n",
      "\titers: 200, epoch: 23 | loss: 0.0712601\n",
      "\tspeed: 0.0394s/iter; left time: 677.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0709491 Vali Loss: 0.0883186 Test Loss: 0.1025997\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754551\n",
      "\tspeed: 0.0738s/iter; left time: 1259.5500s\n",
      "\titers: 200, epoch: 24 | loss: 0.0697886\n",
      "\tspeed: 0.0395s/iter; left time: 670.1626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0708395 Vali Loss: 0.0884907 Test Loss: 0.1025862\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0726331\n",
      "\tspeed: 0.0738s/iter; left time: 1243.2132s\n",
      "\titers: 200, epoch: 25 | loss: 0.0686854\n",
      "\tspeed: 0.0394s/iter; left time: 660.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0707865 Vali Loss: 0.0884841 Test Loss: 0.1026404\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0718038\n",
      "\tspeed: 0.0733s/iter; left time: 1219.3221s\n",
      "\titers: 200, epoch: 26 | loss: 0.0727287\n",
      "\tspeed: 0.0395s/iter; left time: 652.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0707095 Vali Loss: 0.0885339 Test Loss: 0.1027211\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0693274\n",
      "\tspeed: 0.0735s/iter; left time: 1205.3366s\n",
      "\titers: 200, epoch: 27 | loss: 0.0715145\n",
      "\tspeed: 0.0400s/iter; left time: 651.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 223 | Train Loss: 0.0706148 Vali Loss: 0.0884355 Test Loss: 0.1027226\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02584649994969368, rmse:0.16076846420764923, mae:0.10232508182525635, rse:0.5546056032180786\n",
      "Intermediate time for GB and pred_len 24: 00h:09m:55.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1448770\n",
      "\tspeed: 0.0646s/iter; left time: 1428.2043s\n",
      "\titers: 200, epoch: 1 | loss: 0.1391558\n",
      "\tspeed: 0.0399s/iter; left time: 878.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1461433 Vali Loss: 0.1489475 Test Loss: 0.1750351\n",
      "Validation loss decreased (inf --> 0.148948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1129167\n",
      "\tspeed: 0.0743s/iter; left time: 1625.9622s\n",
      "\titers: 200, epoch: 2 | loss: 0.1005386\n",
      "\tspeed: 0.0402s/iter; left time: 876.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1149174 Vali Loss: 0.1181251 Test Loss: 0.1386594\n",
      "Validation loss decreased (0.148948 --> 0.118125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1031710\n",
      "\tspeed: 0.0750s/iter; left time: 1624.2604s\n",
      "\titers: 200, epoch: 3 | loss: 0.0991206\n",
      "\tspeed: 0.0399s/iter; left time: 860.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1030428 Vali Loss: 0.1163868 Test Loss: 0.1391145\n",
      "Validation loss decreased (0.118125 --> 0.116387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1017639\n",
      "\tspeed: 0.0749s/iter; left time: 1606.0809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0966288\n",
      "\tspeed: 0.0398s/iter; left time: 848.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.1005856 Vali Loss: 0.1154555 Test Loss: 0.1396553\n",
      "Validation loss decreased (0.116387 --> 0.115455).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0986010\n",
      "\tspeed: 0.0780s/iter; left time: 1655.5014s\n",
      "\titers: 200, epoch: 5 | loss: 0.0993348\n",
      "\tspeed: 0.0398s/iter; left time: 839.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 222 | Train Loss: 0.0989079 Vali Loss: 0.1151601 Test Loss: 0.1395628\n",
      "Validation loss decreased (0.115455 --> 0.115160).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0977102\n",
      "\tspeed: 0.0751s/iter; left time: 1575.8009s\n",
      "\titers: 200, epoch: 6 | loss: 0.0929132\n",
      "\tspeed: 0.0404s/iter; left time: 844.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.0974407 Vali Loss: 0.1150006 Test Loss: 0.1408491\n",
      "Validation loss decreased (0.115160 --> 0.115001).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0972369\n",
      "\tspeed: 0.0746s/iter; left time: 1550.2803s\n",
      "\titers: 200, epoch: 7 | loss: 0.0952241\n",
      "\tspeed: 0.0397s/iter; left time: 819.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 222 | Train Loss: 0.0960830 Vali Loss: 0.1150026 Test Loss: 0.1420797\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0966173\n",
      "\tspeed: 0.0750s/iter; left time: 1540.1470s\n",
      "\titers: 200, epoch: 8 | loss: 0.0978146\n",
      "\tspeed: 0.0398s/iter; left time: 813.1007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0945581 Vali Loss: 0.1154890 Test Loss: 0.1433707\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0947365\n",
      "\tspeed: 0.0753s/iter; left time: 1530.7339s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956987\n",
      "\tspeed: 0.0404s/iter; left time: 816.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0932267 Vali Loss: 0.1159981 Test Loss: 0.1441094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0913042\n",
      "\tspeed: 0.0775s/iter; left time: 1558.4959s\n",
      "\titers: 200, epoch: 10 | loss: 0.0945083\n",
      "\tspeed: 0.0416s/iter; left time: 831.3504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0919541 Vali Loss: 0.1169385 Test Loss: 0.1447693\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0881115\n",
      "\tspeed: 0.0762s/iter; left time: 1515.5240s\n",
      "\titers: 200, epoch: 11 | loss: 0.0860742\n",
      "\tspeed: 0.0421s/iter; left time: 832.6392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.0908833 Vali Loss: 0.1169766 Test Loss: 0.1452072\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0900455\n",
      "\tspeed: 0.0759s/iter; left time: 1492.3029s\n",
      "\titers: 200, epoch: 12 | loss: 0.0879424\n",
      "\tspeed: 0.0396s/iter; left time: 774.1412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0899094 Vali Loss: 0.1175685 Test Loss: 0.1465373\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0900775\n",
      "\tspeed: 0.0758s/iter; left time: 1472.6220s\n",
      "\titers: 200, epoch: 13 | loss: 0.0881789\n",
      "\tspeed: 0.0398s/iter; left time: 769.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.0890129 Vali Loss: 0.1175455 Test Loss: 0.1461928\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0918403\n",
      "\tspeed: 0.0743s/iter; left time: 1427.0030s\n",
      "\titers: 200, epoch: 14 | loss: 0.0882268\n",
      "\tspeed: 0.0427s/iter; left time: 816.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.0882180 Vali Loss: 0.1181878 Test Loss: 0.1468957\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0878203\n",
      "\tspeed: 0.0776s/iter; left time: 1473.0462s\n",
      "\titers: 200, epoch: 15 | loss: 0.0855482\n",
      "\tspeed: 0.0414s/iter; left time: 781.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 222 | Train Loss: 0.0875866 Vali Loss: 0.1178044 Test Loss: 0.1468874\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0895169\n",
      "\tspeed: 0.0763s/iter; left time: 1431.3289s\n",
      "\titers: 200, epoch: 16 | loss: 0.0866271\n",
      "\tspeed: 0.0410s/iter; left time: 765.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0870003 Vali Loss: 0.1183708 Test Loss: 0.1478115\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04272288829088211, rmse:0.20669515430927277, mae:0.1408490687608719, rse:0.7147806882858276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1452505\n",
      "\tspeed: 0.0450s/iter; left time: 995.5819s\n",
      "\titers: 200, epoch: 1 | loss: 0.1358394\n",
      "\tspeed: 0.0419s/iter; left time: 922.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1460599 Vali Loss: 0.1490447 Test Loss: 0.1755829\n",
      "Validation loss decreased (inf --> 0.149045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1111758\n",
      "\tspeed: 0.0787s/iter; left time: 1721.5571s\n",
      "\titers: 200, epoch: 2 | loss: 0.1078050\n",
      "\tspeed: 0.0395s/iter; left time: 860.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1142795 Vali Loss: 0.1184007 Test Loss: 0.1384943\n",
      "Validation loss decreased (0.149045 --> 0.118401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1104529\n",
      "\tspeed: 0.0771s/iter; left time: 1669.1044s\n",
      "\titers: 200, epoch: 3 | loss: 0.0956960\n",
      "\tspeed: 0.0437s/iter; left time: 941.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1032646 Vali Loss: 0.1167335 Test Loss: 0.1390334\n",
      "Validation loss decreased (0.118401 --> 0.116734).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985594\n",
      "\tspeed: 0.0780s/iter; left time: 1671.6785s\n",
      "\titers: 200, epoch: 4 | loss: 0.1047949\n",
      "\tspeed: 0.0421s/iter; left time: 897.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1008587 Vali Loss: 0.1162034 Test Loss: 0.1399632\n",
      "Validation loss decreased (0.116734 --> 0.116203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0997820\n",
      "\tspeed: 0.0778s/iter; left time: 1651.1195s\n",
      "\titers: 200, epoch: 5 | loss: 0.0988003\n",
      "\tspeed: 0.0403s/iter; left time: 850.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.0990523 Vali Loss: 0.1157914 Test Loss: 0.1405771\n",
      "Validation loss decreased (0.116203 --> 0.115791).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0963227\n",
      "\tspeed: 0.0785s/iter; left time: 1647.1290s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899580\n",
      "\tspeed: 0.0440s/iter; left time: 918.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 222 | Train Loss: 0.0975493 Vali Loss: 0.1157855 Test Loss: 0.1417909\n",
      "Validation loss decreased (0.115791 --> 0.115786).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0939520\n",
      "\tspeed: 0.0782s/iter; left time: 1624.5536s\n",
      "\titers: 200, epoch: 7 | loss: 0.0955321\n",
      "\tspeed: 0.0416s/iter; left time: 860.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.0961790 Vali Loss: 0.1162200 Test Loss: 0.1418881\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0915225\n",
      "\tspeed: 0.0772s/iter; left time: 1585.7606s\n",
      "\titers: 200, epoch: 8 | loss: 0.0920904\n",
      "\tspeed: 0.0413s/iter; left time: 844.3054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.0948722 Vali Loss: 0.1163465 Test Loss: 0.1429089\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0904512\n",
      "\tspeed: 0.0764s/iter; left time: 1552.7451s\n",
      "\titers: 200, epoch: 9 | loss: 0.0953194\n",
      "\tspeed: 0.0414s/iter; left time: 837.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.0936528 Vali Loss: 0.1165900 Test Loss: 0.1430539\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0912163\n",
      "\tspeed: 0.0748s/iter; left time: 1504.0667s\n",
      "\titers: 200, epoch: 10 | loss: 0.0912644\n",
      "\tspeed: 0.0399s/iter; left time: 798.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.0924361 Vali Loss: 0.1168186 Test Loss: 0.1447790\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0932130\n",
      "\tspeed: 0.0765s/iter; left time: 1520.5300s\n",
      "\titers: 200, epoch: 11 | loss: 0.0933815\n",
      "\tspeed: 0.0424s/iter; left time: 839.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.0913405 Vali Loss: 0.1174285 Test Loss: 0.1456824\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0878613\n",
      "\tspeed: 0.0768s/iter; left time: 1509.9397s\n",
      "\titers: 200, epoch: 12 | loss: 0.0905434\n",
      "\tspeed: 0.0412s/iter; left time: 806.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.0903512 Vali Loss: 0.1168011 Test Loss: 0.1445681\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858454\n",
      "\tspeed: 0.0770s/iter; left time: 1496.6251s\n",
      "\titers: 200, epoch: 13 | loss: 0.0926529\n",
      "\tspeed: 0.0428s/iter; left time: 827.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0894801 Vali Loss: 0.1173903 Test Loss: 0.1454006\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0911617\n",
      "\tspeed: 0.0743s/iter; left time: 1428.4493s\n",
      "\titers: 200, epoch: 14 | loss: 0.0879622\n",
      "\tspeed: 0.0412s/iter; left time: 787.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0888077 Vali Loss: 0.1179283 Test Loss: 0.1466755\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0878413\n",
      "\tspeed: 0.0757s/iter; left time: 1437.4771s\n",
      "\titers: 200, epoch: 15 | loss: 0.0873785\n",
      "\tspeed: 0.0409s/iter; left time: 773.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.0880661 Vali Loss: 0.1178823 Test Loss: 0.1468932\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0907289\n",
      "\tspeed: 0.0772s/iter; left time: 1449.5771s\n",
      "\titers: 200, epoch: 16 | loss: 0.0862359\n",
      "\tspeed: 0.0413s/iter; left time: 771.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0875528 Vali Loss: 0.1178571 Test Loss: 0.1464821\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0432744100689888, rmse:0.2080250233411789, mae:0.1417909562587738, rse:0.7193795442581177\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:28.51s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1482841\n",
      "\tspeed: 0.0658s/iter; left time: 1454.0269s\n",
      "\titers: 200, epoch: 1 | loss: 0.1397689\n",
      "\tspeed: 0.0403s/iter; left time: 885.9841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1470762 Vali Loss: 0.1508166 Test Loss: 0.1776926\n",
      "Validation loss decreased (inf --> 0.150817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1174704\n",
      "\tspeed: 0.0763s/iter; left time: 1669.5534s\n",
      "\titers: 200, epoch: 2 | loss: 0.1069854\n",
      "\tspeed: 0.0402s/iter; left time: 876.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1179822 Vali Loss: 0.1228416 Test Loss: 0.1439932\n",
      "Validation loss decreased (0.150817 --> 0.122842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1048739\n",
      "\tspeed: 0.0754s/iter; left time: 1632.3192s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061292\n",
      "\tspeed: 0.0398s/iter; left time: 858.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1073072 Vali Loss: 0.1203709 Test Loss: 0.1446353\n",
      "Validation loss decreased (0.122842 --> 0.120371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1021432\n",
      "\tspeed: 0.0754s/iter; left time: 1615.4150s\n",
      "\titers: 200, epoch: 4 | loss: 0.1027313\n",
      "\tspeed: 0.0403s/iter; left time: 860.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1049311 Vali Loss: 0.1196160 Test Loss: 0.1451954\n",
      "Validation loss decreased (0.120371 --> 0.119616).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994091\n",
      "\tspeed: 0.0750s/iter; left time: 1590.9817s\n",
      "\titers: 200, epoch: 5 | loss: 0.1021254\n",
      "\tspeed: 0.0400s/iter; left time: 845.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1029629 Vali Loss: 0.1198071 Test Loss: 0.1461911\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021269\n",
      "\tspeed: 0.0735s/iter; left time: 1543.7957s\n",
      "\titers: 200, epoch: 6 | loss: 0.0982703\n",
      "\tspeed: 0.0402s/iter; left time: 839.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1009105 Vali Loss: 0.1200600 Test Loss: 0.1466856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0949556\n",
      "\tspeed: 0.0746s/iter; left time: 1548.5908s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973987\n",
      "\tspeed: 0.0402s/iter; left time: 830.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.0988333 Vali Loss: 0.1213073 Test Loss: 0.1475052\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985887\n",
      "\tspeed: 0.0742s/iter; left time: 1524.9694s\n",
      "\titers: 200, epoch: 8 | loss: 0.0900519\n",
      "\tspeed: 0.0401s/iter; left time: 819.2889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.0969457 Vali Loss: 0.1222926 Test Loss: 0.1491201\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0937475\n",
      "\tspeed: 0.0742s/iter; left time: 1507.7110s\n",
      "\titers: 200, epoch: 9 | loss: 0.0953897\n",
      "\tspeed: 0.0403s/iter; left time: 815.8883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.0952411 Vali Loss: 0.1225819 Test Loss: 0.1495869\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920122\n",
      "\tspeed: 0.0748s/iter; left time: 1504.0428s\n",
      "\titers: 200, epoch: 10 | loss: 0.0924476\n",
      "\tspeed: 0.0403s/iter; left time: 806.6465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0937649 Vali Loss: 0.1232245 Test Loss: 0.1508904\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937805\n",
      "\tspeed: 0.0742s/iter; left time: 1474.9772s\n",
      "\titers: 200, epoch: 11 | loss: 0.0938792\n",
      "\tspeed: 0.0404s/iter; left time: 799.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0925031 Vali Loss: 0.1232682 Test Loss: 0.1517894\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0932997\n",
      "\tspeed: 0.0741s/iter; left time: 1457.0195s\n",
      "\titers: 200, epoch: 12 | loss: 0.0912576\n",
      "\tspeed: 0.0402s/iter; left time: 785.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.0913503 Vali Loss: 0.1231844 Test Loss: 0.1526500\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908530\n",
      "\tspeed: 0.0742s/iter; left time: 1441.7143s\n",
      "\titers: 200, epoch: 13 | loss: 0.0882442\n",
      "\tspeed: 0.0405s/iter; left time: 783.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.0904965 Vali Loss: 0.1236009 Test Loss: 0.1532194\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0890870\n",
      "\tspeed: 0.0743s/iter; left time: 1427.7848s\n",
      "\titers: 200, epoch: 14 | loss: 0.0891327\n",
      "\tspeed: 0.0403s/iter; left time: 770.3714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.0896928 Vali Loss: 0.1240712 Test Loss: 0.1544316\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043500062078237534, rmse:0.20856668055057526, mae:0.1451953798532486, rse:0.7231306433677673\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1505878\n",
      "\tspeed: 0.0424s/iter; left time: 936.0034s\n",
      "\titers: 200, epoch: 1 | loss: 0.1377010\n",
      "\tspeed: 0.0404s/iter; left time: 888.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1471375 Vali Loss: 0.1506498 Test Loss: 0.1775536\n",
      "Validation loss decreased (inf --> 0.150650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1150922\n",
      "\tspeed: 0.0772s/iter; left time: 1689.2384s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108951\n",
      "\tspeed: 0.0402s/iter; left time: 875.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1182516 Vali Loss: 0.1227923 Test Loss: 0.1446636\n",
      "Validation loss decreased (0.150650 --> 0.122792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135347\n",
      "\tspeed: 0.0785s/iter; left time: 1699.7504s\n",
      "\titers: 200, epoch: 3 | loss: 0.1016342\n",
      "\tspeed: 0.0402s/iter; left time: 866.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1073212 Vali Loss: 0.1199218 Test Loss: 0.1451758\n",
      "Validation loss decreased (0.122792 --> 0.119922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1003288\n",
      "\tspeed: 0.0769s/iter; left time: 1649.3932s\n",
      "\titers: 200, epoch: 4 | loss: 0.1081735\n",
      "\tspeed: 0.0400s/iter; left time: 854.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1047437 Vali Loss: 0.1196900 Test Loss: 0.1470098\n",
      "Validation loss decreased (0.119922 --> 0.119690).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1025281\n",
      "\tspeed: 0.0778s/iter; left time: 1650.2593s\n",
      "\titers: 200, epoch: 5 | loss: 0.1050308\n",
      "\tspeed: 0.0403s/iter; left time: 851.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1027642 Vali Loss: 0.1201891 Test Loss: 0.1480005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036502\n",
      "\tspeed: 0.0773s/iter; left time: 1622.9788s\n",
      "\titers: 200, epoch: 6 | loss: 0.0979115\n",
      "\tspeed: 0.0404s/iter; left time: 844.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1010635 Vali Loss: 0.1207508 Test Loss: 0.1497401\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0978446\n",
      "\tspeed: 0.0765s/iter; left time: 1588.5756s\n",
      "\titers: 200, epoch: 7 | loss: 0.0981048\n",
      "\tspeed: 0.0402s/iter; left time: 830.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.0993270 Vali Loss: 0.1215502 Test Loss: 0.1503176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0999971\n",
      "\tspeed: 0.0766s/iter; left time: 1574.7140s\n",
      "\titers: 200, epoch: 8 | loss: 0.0969827\n",
      "\tspeed: 0.0405s/iter; left time: 827.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.0977830 Vali Loss: 0.1218885 Test Loss: 0.1505485\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0937268\n",
      "\tspeed: 0.0767s/iter; left time: 1558.3768s\n",
      "\titers: 200, epoch: 9 | loss: 0.0952368\n",
      "\tspeed: 0.0403s/iter; left time: 814.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.0961900 Vali Loss: 0.1224056 Test Loss: 0.1507414\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0967686\n",
      "\tspeed: 0.0764s/iter; left time: 1536.3067s\n",
      "\titers: 200, epoch: 10 | loss: 0.0948266\n",
      "\tspeed: 0.0404s/iter; left time: 807.1705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.0947822 Vali Loss: 0.1227211 Test Loss: 0.1505685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0924086\n",
      "\tspeed: 0.0765s/iter; left time: 1521.7864s\n",
      "\titers: 200, epoch: 11 | loss: 0.0888181\n",
      "\tspeed: 0.0403s/iter; left time: 798.0666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.0935379 Vali Loss: 0.1234265 Test Loss: 0.1516659\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0922789\n",
      "\tspeed: 0.0766s/iter; left time: 1506.3299s\n",
      "\titers: 200, epoch: 12 | loss: 0.0946511\n",
      "\tspeed: 0.0404s/iter; left time: 789.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.0924092 Vali Loss: 0.1239032 Test Loss: 0.1518357\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0894871\n",
      "\tspeed: 0.0774s/iter; left time: 1503.6552s\n",
      "\titers: 200, epoch: 13 | loss: 0.0941193\n",
      "\tspeed: 0.0404s/iter; left time: 781.9770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.0914030 Vali Loss: 0.1234637 Test Loss: 0.1518494\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0906198\n",
      "\tspeed: 0.0766s/iter; left time: 1471.9949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0923201\n",
      "\tspeed: 0.0404s/iter; left time: 771.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.0904459 Vali Loss: 0.1241936 Test Loss: 0.1527707\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04482467845082283, rmse:0.2117183953523636, mae:0.1470097154378891, rse:0.7340580821037292\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:39.96s\n",
      "Intermediate time for GB: 00h:22m:03.51s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1591950\n",
      "\tspeed: 0.0545s/iter; left time: 1210.0467s\n",
      "\titers: 200, epoch: 1 | loss: 0.1430429\n",
      "\tspeed: 0.0278s/iter; left time: 615.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.1604571 Vali Loss: 0.1448400 Test Loss: 0.1753013\n",
      "Validation loss decreased (inf --> 0.144840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0777640\n",
      "\tspeed: 0.0517s/iter; left time: 1136.6810s\n",
      "\titers: 200, epoch: 2 | loss: 0.0700862\n",
      "\tspeed: 0.0260s/iter; left time: 567.8435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0837115 Vali Loss: 0.0639677 Test Loss: 0.0723990\n",
      "Validation loss decreased (0.144840 --> 0.063968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0614089\n",
      "\tspeed: 0.0524s/iter; left time: 1139.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.0569645\n",
      "\tspeed: 0.0259s/iter; left time: 561.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0641778 Vali Loss: 0.0602029 Test Loss: 0.0677163\n",
      "Validation loss decreased (0.063968 --> 0.060203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0643705\n",
      "\tspeed: 0.0529s/iter; left time: 1139.9804s\n",
      "\titers: 200, epoch: 4 | loss: 0.0579398\n",
      "\tspeed: 0.0258s/iter; left time: 553.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0606680 Vali Loss: 0.0586843 Test Loss: 0.0659136\n",
      "Validation loss decreased (0.060203 --> 0.058684).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0559417\n",
      "\tspeed: 0.0538s/iter; left time: 1147.3908s\n",
      "\titers: 200, epoch: 5 | loss: 0.0551922\n",
      "\tspeed: 0.0262s/iter; left time: 555.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0585276 Vali Loss: 0.0574389 Test Loss: 0.0643924\n",
      "Validation loss decreased (0.058684 --> 0.057439).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579328\n",
      "\tspeed: 0.0638s/iter; left time: 1345.2079s\n",
      "\titers: 200, epoch: 6 | loss: 0.0590771\n",
      "\tspeed: 0.0332s/iter; left time: 697.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0572236 Vali Loss: 0.0565885 Test Loss: 0.0638592\n",
      "Validation loss decreased (0.057439 --> 0.056588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581754\n",
      "\tspeed: 0.0582s/iter; left time: 1214.7324s\n",
      "\titers: 200, epoch: 7 | loss: 0.0525846\n",
      "\tspeed: 0.0256s/iter; left time: 532.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0562868 Vali Loss: 0.0559713 Test Loss: 0.0630468\n",
      "Validation loss decreased (0.056588 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0521842\n",
      "\tspeed: 0.0516s/iter; left time: 1065.7843s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560654\n",
      "\tspeed: 0.0278s/iter; left time: 570.2131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0556004 Vali Loss: 0.0557309 Test Loss: 0.0628824\n",
      "Validation loss decreased (0.055971 --> 0.055731).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551004\n",
      "\tspeed: 0.0531s/iter; left time: 1083.1562s\n",
      "\titers: 200, epoch: 9 | loss: 0.0585422\n",
      "\tspeed: 0.0288s/iter; left time: 586.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0551100 Vali Loss: 0.0553242 Test Loss: 0.0624345\n",
      "Validation loss decreased (0.055731 --> 0.055324).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536915\n",
      "\tspeed: 0.0517s/iter; left time: 1044.4029s\n",
      "\titers: 200, epoch: 10 | loss: 0.0532309\n",
      "\tspeed: 0.0255s/iter; left time: 512.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0546438 Vali Loss: 0.0548357 Test Loss: 0.0621107\n",
      "Validation loss decreased (0.055324 --> 0.054836).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0564749\n",
      "\tspeed: 0.0531s/iter; left time: 1059.5330s\n",
      "\titers: 200, epoch: 11 | loss: 0.0545265\n",
      "\tspeed: 0.0266s/iter; left time: 528.8746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0542482 Vali Loss: 0.0548346 Test Loss: 0.0619634\n",
      "Validation loss decreased (0.054836 --> 0.054835).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0559002\n",
      "\tspeed: 0.0536s/iter; left time: 1057.6124s\n",
      "\titers: 200, epoch: 12 | loss: 0.0544986\n",
      "\tspeed: 0.0294s/iter; left time: 577.1728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.0540311 Vali Loss: 0.0546138 Test Loss: 0.0617312\n",
      "Validation loss decreased (0.054835 --> 0.054614).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0538645\n",
      "\tspeed: 0.0520s/iter; left time: 1015.6295s\n",
      "\titers: 200, epoch: 13 | loss: 0.0510065\n",
      "\tspeed: 0.0257s/iter; left time: 499.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0536946 Vali Loss: 0.0544339 Test Loss: 0.0616052\n",
      "Validation loss decreased (0.054614 --> 0.054434).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0526822\n",
      "\tspeed: 0.0533s/iter; left time: 1029.4242s\n",
      "\titers: 200, epoch: 14 | loss: 0.0521037\n",
      "\tspeed: 0.0307s/iter; left time: 589.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 223 | Train Loss: 0.0534395 Vali Loss: 0.0543097 Test Loss: 0.0615806\n",
      "Validation loss decreased (0.054434 --> 0.054310).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0499752\n",
      "\tspeed: 0.0636s/iter; left time: 1212.7902s\n",
      "\titers: 200, epoch: 15 | loss: 0.0534603\n",
      "\tspeed: 0.0267s/iter; left time: 506.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.0532916 Vali Loss: 0.0541679 Test Loss: 0.0612994\n",
      "Validation loss decreased (0.054310 --> 0.054168).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0524868\n",
      "\tspeed: 0.0537s/iter; left time: 1012.8667s\n",
      "\titers: 200, epoch: 16 | loss: 0.0544519\n",
      "\tspeed: 0.0290s/iter; left time: 544.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.0530808 Vali Loss: 0.0541953 Test Loss: 0.0611973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0509620\n",
      "\tspeed: 0.0573s/iter; left time: 1067.3880s\n",
      "\titers: 200, epoch: 17 | loss: 0.0520801\n",
      "\tspeed: 0.0297s/iter; left time: 549.6644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0529144 Vali Loss: 0.0541215 Test Loss: 0.0611514\n",
      "Validation loss decreased (0.054168 --> 0.054122).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0527096\n",
      "\tspeed: 0.0537s/iter; left time: 987.9616s\n",
      "\titers: 200, epoch: 18 | loss: 0.0508821\n",
      "\tspeed: 0.0276s/iter; left time: 505.5678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 223 | Train Loss: 0.0528036 Vali Loss: 0.0538762 Test Loss: 0.0609142\n",
      "Validation loss decreased (0.054122 --> 0.053876).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0551066\n",
      "\tspeed: 0.0543s/iter; left time: 987.8720s\n",
      "\titers: 200, epoch: 19 | loss: 0.0530871\n",
      "\tspeed: 0.0259s/iter; left time: 468.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0526812 Vali Loss: 0.0539105 Test Loss: 0.0608605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0517950\n",
      "\tspeed: 0.0509s/iter; left time: 913.5548s\n",
      "\titers: 200, epoch: 20 | loss: 0.0560987\n",
      "\tspeed: 0.0259s/iter; left time: 463.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.0525361 Vali Loss: 0.0539579 Test Loss: 0.0610352\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0494585\n",
      "\tspeed: 0.0571s/iter; left time: 1012.1493s\n",
      "\titers: 200, epoch: 21 | loss: 0.0537858\n",
      "\tspeed: 0.0287s/iter; left time: 507.1159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.0524161 Vali Loss: 0.0537177 Test Loss: 0.0607885\n",
      "Validation loss decreased (0.053876 --> 0.053718).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0536114\n",
      "\tspeed: 0.0524s/iter; left time: 918.5818s\n",
      "\titers: 200, epoch: 22 | loss: 0.0533266\n",
      "\tspeed: 0.0263s/iter; left time: 458.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523640 Vali Loss: 0.0537453 Test Loss: 0.0607046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511124\n",
      "\tspeed: 0.0520s/iter; left time: 899.9241s\n",
      "\titers: 200, epoch: 23 | loss: 0.0542669\n",
      "\tspeed: 0.0258s/iter; left time: 442.9024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0522465 Vali Loss: 0.0536764 Test Loss: 0.0606734\n",
      "Validation loss decreased (0.053718 --> 0.053676).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0517858\n",
      "\tspeed: 0.0517s/iter; left time: 881.8763s\n",
      "\titers: 200, epoch: 24 | loss: 0.0503288\n",
      "\tspeed: 0.0253s/iter; left time: 430.1823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0521952 Vali Loss: 0.0536841 Test Loss: 0.0608055\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0538896\n",
      "\tspeed: 0.0516s/iter; left time: 868.8908s\n",
      "\titers: 200, epoch: 25 | loss: 0.0515745\n",
      "\tspeed: 0.0279s/iter; left time: 468.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0521067 Vali Loss: 0.0537868 Test Loss: 0.0608817\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513572\n",
      "\tspeed: 0.0515s/iter; left time: 856.3430s\n",
      "\titers: 200, epoch: 26 | loss: 0.0516374\n",
      "\tspeed: 0.0255s/iter; left time: 421.9638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0521153 Vali Loss: 0.0535669 Test Loss: 0.0605754\n",
      "Validation loss decreased (0.053676 --> 0.053567).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0536967\n",
      "\tspeed: 0.0550s/iter; left time: 902.6638s\n",
      "\titers: 200, epoch: 27 | loss: 0.0541706\n",
      "\tspeed: 0.0259s/iter; left time: 422.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0520743 Vali Loss: 0.0534772 Test Loss: 0.0605626\n",
      "Validation loss decreased (0.053567 --> 0.053477).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0499714\n",
      "\tspeed: 0.0526s/iter; left time: 851.2329s\n",
      "\titers: 200, epoch: 28 | loss: 0.0536211\n",
      "\tspeed: 0.0257s/iter; left time: 413.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 223 | Train Loss: 0.0519987 Vali Loss: 0.0535234 Test Loss: 0.0606292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0499966\n",
      "\tspeed: 0.0537s/iter; left time: 856.7914s\n",
      "\titers: 200, epoch: 29 | loss: 0.0506326\n",
      "\tspeed: 0.0304s/iter; left time: 482.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.0519353 Vali Loss: 0.0535601 Test Loss: 0.0606231\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0536309\n",
      "\tspeed: 0.0557s/iter; left time: 875.6387s\n",
      "\titers: 200, epoch: 30 | loss: 0.0511401\n",
      "\tspeed: 0.0300s/iter; left time: 468.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0518532 Vali Loss: 0.0535791 Test Loss: 0.0605956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509653\n",
      "\tspeed: 0.0546s/iter; left time: 846.8313s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515538\n",
      "\tspeed: 0.0261s/iter; left time: 402.5190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0519370 Vali Loss: 0.0534824 Test Loss: 0.0605677\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0492794\n",
      "\tspeed: 0.0507s/iter; left time: 775.1771s\n",
      "\titers: 200, epoch: 32 | loss: 0.0536051\n",
      "\tspeed: 0.0274s/iter; left time: 415.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0518176 Vali Loss: 0.0535533 Test Loss: 0.0605655\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0479570\n",
      "\tspeed: 0.0526s/iter; left time: 792.1651s\n",
      "\titers: 200, epoch: 33 | loss: 0.0510792\n",
      "\tspeed: 0.0254s/iter; left time: 380.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0518565 Vali Loss: 0.0534751 Test Loss: 0.0604863\n",
      "Validation loss decreased (0.053477 --> 0.053475).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525191\n",
      "\tspeed: 0.0510s/iter; left time: 756.3132s\n",
      "\titers: 200, epoch: 34 | loss: 0.0521635\n",
      "\tspeed: 0.0284s/iter; left time: 418.2048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0517660 Vali Loss: 0.0534538 Test Loss: 0.0604829\n",
      "Validation loss decreased (0.053475 --> 0.053454).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548505\n",
      "\tspeed: 0.0537s/iter; left time: 784.9289s\n",
      "\titers: 200, epoch: 35 | loss: 0.0505060\n",
      "\tspeed: 0.0336s/iter; left time: 487.3608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0517281 Vali Loss: 0.0535447 Test Loss: 0.0605600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0522625\n",
      "\tspeed: 0.0529s/iter; left time: 762.0454s\n",
      "\titers: 200, epoch: 36 | loss: 0.0510154\n",
      "\tspeed: 0.0281s/iter; left time: 401.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0516890 Vali Loss: 0.0534124 Test Loss: 0.0604643\n",
      "Validation loss decreased (0.053454 --> 0.053412).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0512337\n",
      "\tspeed: 0.0547s/iter; left time: 775.8969s\n",
      "\titers: 200, epoch: 37 | loss: 0.0518844\n",
      "\tspeed: 0.0281s/iter; left time: 395.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0517376 Vali Loss: 0.0534127 Test Loss: 0.0604158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0507275\n",
      "\tspeed: 0.0551s/iter; left time: 768.2096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0509054\n",
      "\tspeed: 0.0280s/iter; left time: 387.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.0517193 Vali Loss: 0.0534516 Test Loss: 0.0604710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0523548\n",
      "\tspeed: 0.0610s/iter; left time: 837.7010s\n",
      "\titers: 200, epoch: 39 | loss: 0.0560175\n",
      "\tspeed: 0.0358s/iter; left time: 488.4676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0516888 Vali Loss: 0.0535326 Test Loss: 0.0605434\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0531359\n",
      "\tspeed: 0.0675s/iter; left time: 911.1723s\n",
      "\titers: 200, epoch: 40 | loss: 0.0515987\n",
      "\tspeed: 0.0360s/iter; left time: 482.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0517721 Vali Loss: 0.0534444 Test Loss: 0.0604911\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535719\n",
      "\tspeed: 0.0613s/iter; left time: 813.9421s\n",
      "\titers: 200, epoch: 41 | loss: 0.0509647\n",
      "\tspeed: 0.0312s/iter; left time: 411.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 223 | Train Loss: 0.0516733 Vali Loss: 0.0534503 Test Loss: 0.0604908\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536277\n",
      "\tspeed: 0.0518s/iter; left time: 676.5295s\n",
      "\titers: 200, epoch: 42 | loss: 0.0523862\n",
      "\tspeed: 0.0264s/iter; left time: 342.2740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.0516713 Vali Loss: 0.0532678 Test Loss: 0.0603086\n",
      "Validation loss decreased (0.053412 --> 0.053268).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0507392\n",
      "\tspeed: 0.0510s/iter; left time: 654.8863s\n",
      "\titers: 200, epoch: 43 | loss: 0.0479830\n",
      "\tspeed: 0.0254s/iter; left time: 323.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.0517091 Vali Loss: 0.0533908 Test Loss: 0.0603975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0487357\n",
      "\tspeed: 0.0644s/iter; left time: 811.7216s\n",
      "\titers: 200, epoch: 44 | loss: 0.0540242\n",
      "\tspeed: 0.0278s/iter; left time: 348.1715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 223 | Train Loss: 0.0516839 Vali Loss: 0.0534146 Test Loss: 0.0604446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0502951\n",
      "\tspeed: 0.0589s/iter; left time: 730.0457s\n",
      "\titers: 200, epoch: 45 | loss: 0.0501663\n",
      "\tspeed: 0.0347s/iter; left time: 426.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 223 | Train Loss: 0.0516685 Vali Loss: 0.0533534 Test Loss: 0.0604324\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0530896\n",
      "\tspeed: 0.0629s/iter; left time: 765.1338s\n",
      "\titers: 200, epoch: 46 | loss: 0.0488839\n",
      "\tspeed: 0.0348s/iter; left time: 419.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0516372 Vali Loss: 0.0534069 Test Loss: 0.0604357\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0494408\n",
      "\tspeed: 0.0615s/iter; left time: 734.6159s\n",
      "\titers: 200, epoch: 47 | loss: 0.0506241\n",
      "\tspeed: 0.0303s/iter; left time: 358.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 223 | Train Loss: 0.0516417 Vali Loss: 0.0533729 Test Loss: 0.0604247\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520000\n",
      "\tspeed: 0.0522s/iter; left time: 612.1419s\n",
      "\titers: 200, epoch: 48 | loss: 0.0519543\n",
      "\tspeed: 0.0255s/iter; left time: 296.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0516180 Vali Loss: 0.0534349 Test Loss: 0.0604148\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0481528\n",
      "\tspeed: 0.0576s/iter; left time: 662.0994s\n",
      "\titers: 200, epoch: 49 | loss: 0.0500238\n",
      "\tspeed: 0.0265s/iter; left time: 302.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 223 | Train Loss: 0.0516122 Vali Loss: 0.0533787 Test Loss: 0.0603859\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0530817\n",
      "\tspeed: 0.0558s/iter; left time: 628.6047s\n",
      "\titers: 200, epoch: 50 | loss: 0.0503520\n",
      "\tspeed: 0.0283s/iter; left time: 316.1263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 223 | Train Loss: 0.0516792 Vali Loss: 0.0534124 Test Loss: 0.0605012\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525285\n",
      "\tspeed: 0.0545s/iter; left time: 602.7079s\n",
      "\titers: 200, epoch: 51 | loss: 0.0487366\n",
      "\tspeed: 0.0296s/iter; left time: 324.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0516575 Vali Loss: 0.0533693 Test Loss: 0.0604784\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0488180\n",
      "\tspeed: 0.0519s/iter; left time: 561.4916s\n",
      "\titers: 200, epoch: 52 | loss: 0.0538134\n",
      "\tspeed: 0.0261s/iter; left time: 279.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0515561 Vali Loss: 0.0533345 Test Loss: 0.0603428\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009913623332977295, rmse:0.09956718236207962, mae:0.06030861660838127, rse:0.29301416873931885\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1604137\n",
      "\tspeed: 0.0318s/iter; left time: 705.3098s\n",
      "\titers: 200, epoch: 1 | loss: 0.1431300\n",
      "\tspeed: 0.0309s/iter; left time: 682.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.1608639 Vali Loss: 0.1446697 Test Loss: 0.1752043\n",
      "Validation loss decreased (inf --> 0.144670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0772732\n",
      "\tspeed: 0.0544s/iter; left time: 1194.7218s\n",
      "\titers: 200, epoch: 2 | loss: 0.0699654\n",
      "\tspeed: 0.0300s/iter; left time: 655.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0850132 Vali Loss: 0.0645239 Test Loss: 0.0730585\n",
      "Validation loss decreased (0.144670 --> 0.064524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0684940\n",
      "\tspeed: 0.0734s/iter; left time: 1595.8253s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625822\n",
      "\tspeed: 0.0433s/iter; left time: 938.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0646027 Vali Loss: 0.0607286 Test Loss: 0.0683715\n",
      "Validation loss decreased (0.064524 --> 0.060729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0622036\n",
      "\tspeed: 0.0710s/iter; left time: 1529.5222s\n",
      "\titers: 200, epoch: 4 | loss: 0.0619112\n",
      "\tspeed: 0.0338s/iter; left time: 724.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 223 | Train Loss: 0.0607060 Vali Loss: 0.0586058 Test Loss: 0.0657358\n",
      "Validation loss decreased (0.060729 --> 0.058606).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0555675\n",
      "\tspeed: 0.0573s/iter; left time: 1221.6345s\n",
      "\titers: 200, epoch: 5 | loss: 0.0598611\n",
      "\tspeed: 0.0334s/iter; left time: 707.5512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 223 | Train Loss: 0.0586319 Vali Loss: 0.0573033 Test Loss: 0.0644244\n",
      "Validation loss decreased (0.058606 --> 0.057303).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0587663\n",
      "\tspeed: 0.0680s/iter; left time: 1434.3497s\n",
      "\titers: 200, epoch: 6 | loss: 0.0561303\n",
      "\tspeed: 0.0365s/iter; left time: 766.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 223 | Train Loss: 0.0571902 Vali Loss: 0.0568653 Test Loss: 0.0639605\n",
      "Validation loss decreased (0.057303 --> 0.056865).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0536839\n",
      "\tspeed: 0.0676s/iter; left time: 1411.0226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523881\n",
      "\tspeed: 0.0376s/iter; left time: 780.5993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 223 | Train Loss: 0.0562810 Vali Loss: 0.0564382 Test Loss: 0.0635311\n",
      "Validation loss decreased (0.056865 --> 0.056438).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0561908\n",
      "\tspeed: 0.0671s/iter; left time: 1384.2389s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562126\n",
      "\tspeed: 0.0351s/iter; left time: 720.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0556503 Vali Loss: 0.0559325 Test Loss: 0.0632426\n",
      "Validation loss decreased (0.056438 --> 0.055933).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0537052\n",
      "\tspeed: 0.0640s/iter; left time: 1305.8010s\n",
      "\titers: 200, epoch: 9 | loss: 0.0588657\n",
      "\tspeed: 0.0377s/iter; left time: 765.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 223 | Train Loss: 0.0550537 Vali Loss: 0.0554563 Test Loss: 0.0627188\n",
      "Validation loss decreased (0.055933 --> 0.055456).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0545774\n",
      "\tspeed: 0.0625s/iter; left time: 1261.9939s\n",
      "\titers: 200, epoch: 10 | loss: 0.0575977\n",
      "\tspeed: 0.0343s/iter; left time: 689.3665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0546660 Vali Loss: 0.0554688 Test Loss: 0.0624138\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0548789\n",
      "\tspeed: 0.0639s/iter; left time: 1277.1444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0523331\n",
      "\tspeed: 0.0374s/iter; left time: 743.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 223 | Train Loss: 0.0543137 Vali Loss: 0.0548839 Test Loss: 0.0619350\n",
      "Validation loss decreased (0.055456 --> 0.054884).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0554015\n",
      "\tspeed: 0.0675s/iter; left time: 1332.3119s\n",
      "\titers: 200, epoch: 12 | loss: 0.0531209\n",
      "\tspeed: 0.0348s/iter; left time: 682.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0539099 Vali Loss: 0.0546235 Test Loss: 0.0616393\n",
      "Validation loss decreased (0.054884 --> 0.054623).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552619\n",
      "\tspeed: 0.0692s/iter; left time: 1350.7872s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543976\n",
      "\tspeed: 0.0349s/iter; left time: 677.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 223 | Train Loss: 0.0536210 Vali Loss: 0.0548047 Test Loss: 0.0619099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0544875\n",
      "\tspeed: 0.0644s/iter; left time: 1242.1708s\n",
      "\titers: 200, epoch: 14 | loss: 0.0570824\n",
      "\tspeed: 0.0365s/iter; left time: 701.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0534210 Vali Loss: 0.0545738 Test Loss: 0.0618205\n",
      "Validation loss decreased (0.054623 --> 0.054574).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531555\n",
      "\tspeed: 0.0654s/iter; left time: 1247.2688s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540878\n",
      "\tspeed: 0.0367s/iter; left time: 696.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 223 | Train Loss: 0.0532119 Vali Loss: 0.0544894 Test Loss: 0.0614814\n",
      "Validation loss decreased (0.054574 --> 0.054489).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0510076\n",
      "\tspeed: 0.0594s/iter; left time: 1119.9979s\n",
      "\titers: 200, epoch: 16 | loss: 0.0520986\n",
      "\tspeed: 0.0256s/iter; left time: 480.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0531215 Vali Loss: 0.0543029 Test Loss: 0.0614236\n",
      "Validation loss decreased (0.054489 --> 0.054303).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0530209\n",
      "\tspeed: 0.0587s/iter; left time: 1093.7136s\n",
      "\titers: 200, epoch: 17 | loss: 0.0516927\n",
      "\tspeed: 0.0405s/iter; left time: 750.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 223 | Train Loss: 0.0529309 Vali Loss: 0.0540506 Test Loss: 0.0610606\n",
      "Validation loss decreased (0.054303 --> 0.054051).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0522986\n",
      "\tspeed: 0.0693s/iter; left time: 1276.5129s\n",
      "\titers: 200, epoch: 18 | loss: 0.0506528\n",
      "\tspeed: 0.0404s/iter; left time: 740.1584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 223 | Train Loss: 0.0527436 Vali Loss: 0.0541046 Test Loss: 0.0610915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0507173\n",
      "\tspeed: 0.0675s/iter; left time: 1227.2389s\n",
      "\titers: 200, epoch: 19 | loss: 0.0509806\n",
      "\tspeed: 0.0412s/iter; left time: 745.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0525813 Vali Loss: 0.0540537 Test Loss: 0.0609676\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0504979\n",
      "\tspeed: 0.0736s/iter; left time: 1321.4219s\n",
      "\titers: 200, epoch: 20 | loss: 0.0526390\n",
      "\tspeed: 0.0438s/iter; left time: 782.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0525487 Vali Loss: 0.0541442 Test Loss: 0.0610385\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536256\n",
      "\tspeed: 0.0692s/iter; left time: 1227.8157s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514705\n",
      "\tspeed: 0.0395s/iter; left time: 696.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0524742 Vali Loss: 0.0540221 Test Loss: 0.0610091\n",
      "Validation loss decreased (0.054051 --> 0.054022).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0527169\n",
      "\tspeed: 0.0664s/iter; left time: 1163.5013s\n",
      "\titers: 200, epoch: 22 | loss: 0.0540511\n",
      "\tspeed: 0.0356s/iter; left time: 620.6479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 223 | Train Loss: 0.0523348 Vali Loss: 0.0540492 Test Loss: 0.0609953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543577\n",
      "\tspeed: 0.0651s/iter; left time: 1125.3981s\n",
      "\titers: 200, epoch: 23 | loss: 0.0539596\n",
      "\tspeed: 0.0372s/iter; left time: 639.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 223 | Train Loss: 0.0522726 Vali Loss: 0.0537599 Test Loss: 0.0608534\n",
      "Validation loss decreased (0.054022 --> 0.053760).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0515213\n",
      "\tspeed: 0.0622s/iter; left time: 1062.1386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0504264\n",
      "\tspeed: 0.0383s/iter; left time: 649.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 223 | Train Loss: 0.0522272 Vali Loss: 0.0538369 Test Loss: 0.0607637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0501550\n",
      "\tspeed: 0.0676s/iter; left time: 1138.6926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0520095\n",
      "\tspeed: 0.0349s/iter; left time: 584.0483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 223 | Train Loss: 0.0521344 Vali Loss: 0.0538388 Test Loss: 0.0607488\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0485351\n",
      "\tspeed: 0.0647s/iter; left time: 1076.2089s\n",
      "\titers: 200, epoch: 26 | loss: 0.0529710\n",
      "\tspeed: 0.0342s/iter; left time: 565.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0520890 Vali Loss: 0.0538396 Test Loss: 0.0607870\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0521177\n",
      "\tspeed: 0.0662s/iter; left time: 1086.1901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0504517\n",
      "\tspeed: 0.0345s/iter; left time: 562.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 223 | Train Loss: 0.0520010 Vali Loss: 0.0537806 Test Loss: 0.0607850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0503137\n",
      "\tspeed: 0.0638s/iter; left time: 1031.9792s\n",
      "\titers: 200, epoch: 28 | loss: 0.0526623\n",
      "\tspeed: 0.0356s/iter; left time: 571.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0520151 Vali Loss: 0.0537499 Test Loss: 0.0607426\n",
      "Validation loss decreased (0.053760 --> 0.053750).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0527664\n",
      "\tspeed: 0.0678s/iter; left time: 1081.6981s\n",
      "\titers: 200, epoch: 29 | loss: 0.0523059\n",
      "\tspeed: 0.0344s/iter; left time: 545.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 223 | Train Loss: 0.0519719 Vali Loss: 0.0539094 Test Loss: 0.0608818\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0576007\n",
      "\tspeed: 0.0642s/iter; left time: 1010.5828s\n",
      "\titers: 200, epoch: 30 | loss: 0.0511110\n",
      "\tspeed: 0.0320s/iter; left time: 500.9206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0519244 Vali Loss: 0.0536938 Test Loss: 0.0605566\n",
      "Validation loss decreased (0.053750 --> 0.053694).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0545073\n",
      "\tspeed: 0.0671s/iter; left time: 1040.6816s\n",
      "\titers: 200, epoch: 31 | loss: 0.0533006\n",
      "\tspeed: 0.0371s/iter; left time: 572.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0518731 Vali Loss: 0.0536479 Test Loss: 0.0605731\n",
      "Validation loss decreased (0.053694 --> 0.053648).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0517761\n",
      "\tspeed: 0.0675s/iter; left time: 1031.3285s\n",
      "\titers: 200, epoch: 32 | loss: 0.0491689\n",
      "\tspeed: 0.0360s/iter; left time: 546.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 223 | Train Loss: 0.0518927 Vali Loss: 0.0536186 Test Loss: 0.0604948\n",
      "Validation loss decreased (0.053648 --> 0.053619).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0480916\n",
      "\tspeed: 0.0677s/iter; left time: 1019.4108s\n",
      "\titers: 200, epoch: 33 | loss: 0.0514715\n",
      "\tspeed: 0.0364s/iter; left time: 545.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 223 | Train Loss: 0.0518329 Vali Loss: 0.0536679 Test Loss: 0.0605904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0518080\n",
      "\tspeed: 0.0667s/iter; left time: 990.3767s\n",
      "\titers: 200, epoch: 34 | loss: 0.0495422\n",
      "\tspeed: 0.0366s/iter; left time: 538.8514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.0518524 Vali Loss: 0.0535361 Test Loss: 0.0605083\n",
      "Validation loss decreased (0.053619 --> 0.053536).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0544271\n",
      "\tspeed: 0.0661s/iter; left time: 966.2012s\n",
      "\titers: 200, epoch: 35 | loss: 0.0500351\n",
      "\tspeed: 0.0357s/iter; left time: 517.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 223 | Train Loss: 0.0517801 Vali Loss: 0.0535704 Test Loss: 0.0604085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0502896\n",
      "\tspeed: 0.0630s/iter; left time: 907.2846s\n",
      "\titers: 200, epoch: 36 | loss: 0.0515446\n",
      "\tspeed: 0.0365s/iter; left time: 522.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 223 | Train Loss: 0.0518409 Vali Loss: 0.0535978 Test Loss: 0.0605081\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519810\n",
      "\tspeed: 0.0583s/iter; left time: 825.8108s\n",
      "\titers: 200, epoch: 37 | loss: 0.0533939\n",
      "\tspeed: 0.0272s/iter; left time: 382.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0518093 Vali Loss: 0.0536257 Test Loss: 0.0605028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0521263\n",
      "\tspeed: 0.0517s/iter; left time: 721.7000s\n",
      "\titers: 200, epoch: 38 | loss: 0.0509750\n",
      "\tspeed: 0.0274s/iter; left time: 378.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0518248 Vali Loss: 0.0535466 Test Loss: 0.0604702\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0522126\n",
      "\tspeed: 0.0641s/iter; left time: 880.3615s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543932\n",
      "\tspeed: 0.0372s/iter; left time: 506.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 223 | Train Loss: 0.0516749 Vali Loss: 0.0535119 Test Loss: 0.0604347\n",
      "Validation loss decreased (0.053536 --> 0.053512).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0526889\n",
      "\tspeed: 0.0655s/iter; left time: 884.0551s\n",
      "\titers: 200, epoch: 40 | loss: 0.0488163\n",
      "\tspeed: 0.0330s/iter; left time: 442.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0517006 Vali Loss: 0.0536032 Test Loss: 0.0605546\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0514153\n",
      "\tspeed: 0.0659s/iter; left time: 874.7108s\n",
      "\titers: 200, epoch: 41 | loss: 0.0525598\n",
      "\tspeed: 0.0382s/iter; left time: 503.7058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 223 | Train Loss: 0.0517537 Vali Loss: 0.0536751 Test Loss: 0.0606105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0507352\n",
      "\tspeed: 0.0682s/iter; left time: 891.1473s\n",
      "\titers: 200, epoch: 42 | loss: 0.0522080\n",
      "\tspeed: 0.0379s/iter; left time: 491.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 223 | Train Loss: 0.0517001 Vali Loss: 0.0535443 Test Loss: 0.0604759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0513964\n",
      "\tspeed: 0.0644s/iter; left time: 826.3249s\n",
      "\titers: 200, epoch: 43 | loss: 0.0519295\n",
      "\tspeed: 0.0262s/iter; left time: 333.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 223 | Train Loss: 0.0517503 Vali Loss: 0.0535401 Test Loss: 0.0603964\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0505552\n",
      "\tspeed: 0.0518s/iter; left time: 653.4379s\n",
      "\titers: 200, epoch: 44 | loss: 0.0506604\n",
      "\tspeed: 0.0253s/iter; left time: 316.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0516771 Vali Loss: 0.0536111 Test Loss: 0.0605173\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0544548\n",
      "\tspeed: 0.0610s/iter; left time: 755.4683s\n",
      "\titers: 200, epoch: 45 | loss: 0.0545269\n",
      "\tspeed: 0.0304s/iter; left time: 373.2954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 223 | Train Loss: 0.0516439 Vali Loss: 0.0534504 Test Loss: 0.0603519\n",
      "Validation loss decreased (0.053512 --> 0.053450).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0504720\n",
      "\tspeed: 0.0576s/iter; left time: 700.5370s\n",
      "\titers: 200, epoch: 46 | loss: 0.0524037\n",
      "\tspeed: 0.0256s/iter; left time: 308.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0516680 Vali Loss: 0.0535099 Test Loss: 0.0603301\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0473322\n",
      "\tspeed: 0.0585s/iter; left time: 698.3285s\n",
      "\titers: 200, epoch: 47 | loss: 0.0535025\n",
      "\tspeed: 0.0286s/iter; left time: 338.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0516626 Vali Loss: 0.0535633 Test Loss: 0.0604063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0487419\n",
      "\tspeed: 0.0579s/iter; left time: 678.1235s\n",
      "\titers: 200, epoch: 48 | loss: 0.0537909\n",
      "\tspeed: 0.0255s/iter; left time: 296.8831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0516300 Vali Loss: 0.0535114 Test Loss: 0.0604054\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0524193\n",
      "\tspeed: 0.0516s/iter; left time: 593.6681s\n",
      "\titers: 200, epoch: 49 | loss: 0.0501292\n",
      "\tspeed: 0.0257s/iter; left time: 292.4646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0516288 Vali Loss: 0.0535658 Test Loss: 0.0604450\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0526715\n",
      "\tspeed: 0.0549s/iter; left time: 619.3103s\n",
      "\titers: 200, epoch: 50 | loss: 0.0509765\n",
      "\tspeed: 0.0331s/iter; left time: 370.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 223 | Train Loss: 0.0516107 Vali Loss: 0.0535959 Test Loss: 0.0604820\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0505561\n",
      "\tspeed: 0.0592s/iter; left time: 654.5299s\n",
      "\titers: 200, epoch: 51 | loss: 0.0542747\n",
      "\tspeed: 0.0306s/iter; left time: 334.8812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0516511 Vali Loss: 0.0534766 Test Loss: 0.0603646\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0493037\n",
      "\tspeed: 0.0578s/iter; left time: 625.5922s\n",
      "\titers: 200, epoch: 52 | loss: 0.0543585\n",
      "\tspeed: 0.0294s/iter; left time: 314.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0515550 Vali Loss: 0.0535274 Test Loss: 0.0603362\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0550840\n",
      "\tspeed: 0.0561s/iter; left time: 594.6730s\n",
      "\titers: 200, epoch: 53 | loss: 0.0506019\n",
      "\tspeed: 0.0272s/iter; left time: 285.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0516710 Vali Loss: 0.0535192 Test Loss: 0.0604906\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0513142\n",
      "\tspeed: 0.0524s/iter; left time: 543.7154s\n",
      "\titers: 200, epoch: 54 | loss: 0.0533336\n",
      "\tspeed: 0.0311s/iter; left time: 319.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0516079 Vali Loss: 0.0536206 Test Loss: 0.0605233\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0522167\n",
      "\tspeed: 0.0649s/iter; left time: 659.5942s\n",
      "\titers: 200, epoch: 55 | loss: 0.0526224\n",
      "\tspeed: 0.0367s/iter; left time: 368.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 223 | Train Loss: 0.0516601 Vali Loss: 0.0535210 Test Loss: 0.0604077\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009903013706207275, rmse:0.09951388835906982, mae:0.06035187467932701, rse:0.2928573191165924\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:20.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1622237\n",
      "\tspeed: 0.0536s/iter; left time: 1184.1935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1552807\n",
      "\tspeed: 0.0258s/iter; left time: 567.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.1664880 Vali Loss: 0.1528369 Test Loss: 0.1853393\n",
      "Validation loss decreased (inf --> 0.152837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0952171\n",
      "\tspeed: 0.0530s/iter; left time: 1159.1407s\n",
      "\titers: 200, epoch: 2 | loss: 0.0800278\n",
      "\tspeed: 0.0267s/iter; left time: 580.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0993263 Vali Loss: 0.0832190 Test Loss: 0.0965046\n",
      "Validation loss decreased (0.152837 --> 0.083219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0828655\n",
      "\tspeed: 0.0536s/iter; left time: 1161.2710s\n",
      "\titers: 200, epoch: 3 | loss: 0.0799404\n",
      "\tspeed: 0.0339s/iter; left time: 730.9576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 222 | Train Loss: 0.0833639 Vali Loss: 0.0804485 Test Loss: 0.0934786\n",
      "Validation loss decreased (0.083219 --> 0.080448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0802655\n",
      "\tspeed: 0.0635s/iter; left time: 1361.8573s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785479\n",
      "\tspeed: 0.0336s/iter; left time: 715.9589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 222 | Train Loss: 0.0803158 Vali Loss: 0.0793463 Test Loss: 0.0918768\n",
      "Validation loss decreased (0.080448 --> 0.079346).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784103\n",
      "\tspeed: 0.0759s/iter; left time: 1609.6758s\n",
      "\titers: 200, epoch: 5 | loss: 0.0770508\n",
      "\tspeed: 0.0358s/iter; left time: 755.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 222 | Train Loss: 0.0782849 Vali Loss: 0.0784977 Test Loss: 0.0905443\n",
      "Validation loss decreased (0.079346 --> 0.078498).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733393\n",
      "\tspeed: 0.0569s/iter; left time: 1193.5142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0767892\n",
      "\tspeed: 0.0263s/iter; left time: 548.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0769913 Vali Loss: 0.0781446 Test Loss: 0.0900204\n",
      "Validation loss decreased (0.078498 --> 0.078145).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756378\n",
      "\tspeed: 0.0617s/iter; left time: 1281.1742s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794970\n",
      "\tspeed: 0.0320s/iter; left time: 662.3646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 222 | Train Loss: 0.0760258 Vali Loss: 0.0776737 Test Loss: 0.0894566\n",
      "Validation loss decreased (0.078145 --> 0.077674).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0784064\n",
      "\tspeed: 0.0670s/iter; left time: 1377.5216s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751719\n",
      "\tspeed: 0.0335s/iter; left time: 685.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 222 | Train Loss: 0.0752120 Vali Loss: 0.0771767 Test Loss: 0.0889030\n",
      "Validation loss decreased (0.077674 --> 0.077177).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0706340\n",
      "\tspeed: 0.0693s/iter; left time: 1407.8165s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758572\n",
      "\tspeed: 0.0358s/iter; left time: 723.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 222 | Train Loss: 0.0744788 Vali Loss: 0.0774488 Test Loss: 0.0892087\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0722433\n",
      "\tspeed: 0.0667s/iter; left time: 1339.9667s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749272\n",
      "\tspeed: 0.0359s/iter; left time: 718.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 222 | Train Loss: 0.0739328 Vali Loss: 0.0770640 Test Loss: 0.0887003\n",
      "Validation loss decreased (0.077177 --> 0.077064).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747228\n",
      "\tspeed: 0.0693s/iter; left time: 1378.5095s\n",
      "\titers: 200, epoch: 11 | loss: 0.0709141\n",
      "\tspeed: 0.0381s/iter; left time: 753.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 222 | Train Loss: 0.0733438 Vali Loss: 0.0770103 Test Loss: 0.0887684\n",
      "Validation loss decreased (0.077064 --> 0.077010).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0742489\n",
      "\tspeed: 0.0628s/iter; left time: 1235.4123s\n",
      "\titers: 200, epoch: 12 | loss: 0.0752503\n",
      "\tspeed: 0.0354s/iter; left time: 692.7611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0728946 Vali Loss: 0.0770081 Test Loss: 0.0883811\n",
      "Validation loss decreased (0.077010 --> 0.077008).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0739451\n",
      "\tspeed: 0.0666s/iter; left time: 1294.1063s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723983\n",
      "\tspeed: 0.0334s/iter; left time: 646.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0724343 Vali Loss: 0.0770708 Test Loss: 0.0883359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689736\n",
      "\tspeed: 0.0593s/iter; left time: 1140.3326s\n",
      "\titers: 200, epoch: 14 | loss: 0.0733272\n",
      "\tspeed: 0.0382s/iter; left time: 731.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0720972 Vali Loss: 0.0771475 Test Loss: 0.0882571\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717556\n",
      "\tspeed: 0.0632s/iter; left time: 1200.7171s\n",
      "\titers: 200, epoch: 15 | loss: 0.0717736\n",
      "\tspeed: 0.0353s/iter; left time: 666.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0717808 Vali Loss: 0.0773379 Test Loss: 0.0885696\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0690121\n",
      "\tspeed: 0.0665s/iter; left time: 1247.8377s\n",
      "\titers: 200, epoch: 16 | loss: 0.0717874\n",
      "\tspeed: 0.0356s/iter; left time: 664.7901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 222 | Train Loss: 0.0714794 Vali Loss: 0.0773337 Test Loss: 0.0884711\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704059\n",
      "\tspeed: 0.0654s/iter; left time: 1213.7316s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705279\n",
      "\tspeed: 0.0401s/iter; left time: 740.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 222 | Train Loss: 0.0712225 Vali Loss: 0.0774065 Test Loss: 0.0883728\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739785\n",
      "\tspeed: 0.0646s/iter; left time: 1183.2638s\n",
      "\titers: 200, epoch: 18 | loss: 0.0697217\n",
      "\tspeed: 0.0384s/iter; left time: 699.1041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 222 | Train Loss: 0.0709869 Vali Loss: 0.0772678 Test Loss: 0.0883072\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0714012\n",
      "\tspeed: 0.0647s/iter; left time: 1171.3269s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705960\n",
      "\tspeed: 0.0380s/iter; left time: 684.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 222 | Train Loss: 0.0707900 Vali Loss: 0.0773846 Test Loss: 0.0883412\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0702209\n",
      "\tspeed: 0.0648s/iter; left time: 1159.5003s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730629\n",
      "\tspeed: 0.0328s/iter; left time: 582.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 222 | Train Loss: 0.0705700 Vali Loss: 0.0772145 Test Loss: 0.0879646\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711013\n",
      "\tspeed: 0.0639s/iter; left time: 1129.2740s\n",
      "\titers: 200, epoch: 21 | loss: 0.0691173\n",
      "\tspeed: 0.0334s/iter; left time: 586.8010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0703986 Vali Loss: 0.0775031 Test Loss: 0.0883663\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0688931\n",
      "\tspeed: 0.0647s/iter; left time: 1128.3345s\n",
      "\titers: 200, epoch: 22 | loss: 0.0706317\n",
      "\tspeed: 0.0322s/iter; left time: 557.8438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0703043 Vali Loss: 0.0772153 Test Loss: 0.0881736\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018716780468821526, rmse:0.13680928945541382, mae:0.0883810892701149, rse:0.40190449357032776\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1656220\n",
      "\tspeed: 0.0412s/iter; left time: 910.0327s\n",
      "\titers: 200, epoch: 1 | loss: 0.1555886\n",
      "\tspeed: 0.0397s/iter; left time: 872.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 222 | Train Loss: 0.1660161 Vali Loss: 0.1514914 Test Loss: 0.1832681\n",
      "Validation loss decreased (inf --> 0.151491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0905172\n",
      "\tspeed: 0.0655s/iter; left time: 1433.3049s\n",
      "\titers: 200, epoch: 2 | loss: 0.0859304\n",
      "\tspeed: 0.0372s/iter; left time: 809.9503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 222 | Train Loss: 0.0982952 Vali Loss: 0.0832025 Test Loss: 0.0968010\n",
      "Validation loss decreased (0.151491 --> 0.083202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0834926\n",
      "\tspeed: 0.0643s/iter; left time: 1391.5197s\n",
      "\titers: 200, epoch: 3 | loss: 0.0816848\n",
      "\tspeed: 0.0261s/iter; left time: 561.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0832057 Vali Loss: 0.0809875 Test Loss: 0.0938288\n",
      "Validation loss decreased (0.083202 --> 0.080987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787856\n",
      "\tspeed: 0.0702s/iter; left time: 1504.4402s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802192\n",
      "\tspeed: 0.0454s/iter; left time: 967.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 222 | Train Loss: 0.0800812 Vali Loss: 0.0793317 Test Loss: 0.0921384\n",
      "Validation loss decreased (0.080987 --> 0.079332).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764875\n",
      "\tspeed: 0.0661s/iter; left time: 1401.4759s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787724\n",
      "\tspeed: 0.0288s/iter; left time: 608.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 222 | Train Loss: 0.0782201 Vali Loss: 0.0784535 Test Loss: 0.0909055\n",
      "Validation loss decreased (0.079332 --> 0.078454).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0772114\n",
      "\tspeed: 0.0658s/iter; left time: 1381.1008s\n",
      "\titers: 200, epoch: 6 | loss: 0.0785410\n",
      "\tspeed: 0.0384s/iter; left time: 803.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 222 | Train Loss: 0.0770628 Vali Loss: 0.0779655 Test Loss: 0.0903950\n",
      "Validation loss decreased (0.078454 --> 0.077965).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739681\n",
      "\tspeed: 0.0709s/iter; left time: 1473.2073s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776922\n",
      "\tspeed: 0.0340s/iter; left time: 703.1270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 222 | Train Loss: 0.0761627 Vali Loss: 0.0774716 Test Loss: 0.0894739\n",
      "Validation loss decreased (0.077965 --> 0.077472).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0748946\n",
      "\tspeed: 0.0684s/iter; left time: 1405.5781s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778357\n",
      "\tspeed: 0.0313s/iter; left time: 639.8376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 222 | Train Loss: 0.0754208 Vali Loss: 0.0775267 Test Loss: 0.0895507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0737765\n",
      "\tspeed: 0.0710s/iter; left time: 1442.9471s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785762\n",
      "\tspeed: 0.0300s/iter; left time: 607.3166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0747555 Vali Loss: 0.0770632 Test Loss: 0.0893147\n",
      "Validation loss decreased (0.077472 --> 0.077063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0764496\n",
      "\tspeed: 0.0663s/iter; left time: 1332.6911s\n",
      "\titers: 200, epoch: 10 | loss: 0.0746830\n",
      "\tspeed: 0.0397s/iter; left time: 793.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 222 | Train Loss: 0.0741952 Vali Loss: 0.0769906 Test Loss: 0.0888720\n",
      "Validation loss decreased (0.077063 --> 0.076991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0724794\n",
      "\tspeed: 0.0696s/iter; left time: 1382.8042s\n",
      "\titers: 200, epoch: 11 | loss: 0.0691871\n",
      "\tspeed: 0.0374s/iter; left time: 740.0839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 222 | Train Loss: 0.0736192 Vali Loss: 0.0772075 Test Loss: 0.0890573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0751627\n",
      "\tspeed: 0.0692s/iter; left time: 1360.1016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699785\n",
      "\tspeed: 0.0331s/iter; left time: 646.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 222 | Train Loss: 0.0731209 Vali Loss: 0.0769782 Test Loss: 0.0886720\n",
      "Validation loss decreased (0.076991 --> 0.076978).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0723917\n",
      "\tspeed: 0.0677s/iter; left time: 1315.0739s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719570\n",
      "\tspeed: 0.0398s/iter; left time: 769.3960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 222 | Train Loss: 0.0727734 Vali Loss: 0.0769678 Test Loss: 0.0887840\n",
      "Validation loss decreased (0.076978 --> 0.076968).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735875\n",
      "\tspeed: 0.0568s/iter; left time: 1090.8557s\n",
      "\titers: 200, epoch: 14 | loss: 0.0699578\n",
      "\tspeed: 0.0281s/iter; left time: 537.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0724100 Vali Loss: 0.0769890 Test Loss: 0.0885755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0710374\n",
      "\tspeed: 0.0536s/iter; left time: 1018.6814s\n",
      "\titers: 200, epoch: 15 | loss: 0.0730089\n",
      "\tspeed: 0.0350s/iter; left time: 660.9397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 222 | Train Loss: 0.0720043 Vali Loss: 0.0771782 Test Loss: 0.0885044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683901\n",
      "\tspeed: 0.0668s/iter; left time: 1253.2269s\n",
      "\titers: 200, epoch: 16 | loss: 0.0687507\n",
      "\tspeed: 0.0379s/iter; left time: 707.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 222 | Train Loss: 0.0716457 Vali Loss: 0.0769015 Test Loss: 0.0881144\n",
      "Validation loss decreased (0.076968 --> 0.076902).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0723266\n",
      "\tspeed: 0.0655s/iter; left time: 1215.4844s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701378\n",
      "\tspeed: 0.0378s/iter; left time: 698.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 222 | Train Loss: 0.0714350 Vali Loss: 0.0768894 Test Loss: 0.0880680\n",
      "Validation loss decreased (0.076902 --> 0.076889).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0714156\n",
      "\tspeed: 0.0685s/iter; left time: 1256.2919s\n",
      "\titers: 200, epoch: 18 | loss: 0.0664640\n",
      "\tspeed: 0.0365s/iter; left time: 665.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 222 | Train Loss: 0.0711744 Vali Loss: 0.0770964 Test Loss: 0.0881573\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0687729\n",
      "\tspeed: 0.0665s/iter; left time: 1203.7411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0666778\n",
      "\tspeed: 0.0374s/iter; left time: 673.3914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 222 | Train Loss: 0.0709974 Vali Loss: 0.0771362 Test Loss: 0.0883717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0697861\n",
      "\tspeed: 0.0586s/iter; left time: 1048.0549s\n",
      "\titers: 200, epoch: 20 | loss: 0.0716461\n",
      "\tspeed: 0.0305s/iter; left time: 542.2492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0708288 Vali Loss: 0.0772473 Test Loss: 0.0880336\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0721146\n",
      "\tspeed: 0.0611s/iter; left time: 1079.8322s\n",
      "\titers: 200, epoch: 21 | loss: 0.0733861\n",
      "\tspeed: 0.0353s/iter; left time: 619.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0705951 Vali Loss: 0.0772201 Test Loss: 0.0879106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0692881\n",
      "\tspeed: 0.0678s/iter; left time: 1182.2981s\n",
      "\titers: 200, epoch: 22 | loss: 0.0659724\n",
      "\tspeed: 0.0376s/iter; left time: 652.1432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 222 | Train Loss: 0.0704391 Vali Loss: 0.0772816 Test Loss: 0.0881077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0696533\n",
      "\tspeed: 0.0577s/iter; left time: 993.2998s\n",
      "\titers: 200, epoch: 23 | loss: 0.0679224\n",
      "\tspeed: 0.0277s/iter; left time: 474.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.0702977 Vali Loss: 0.0772594 Test Loss: 0.0882301\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0660354\n",
      "\tspeed: 0.0678s/iter; left time: 1151.4934s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685650\n",
      "\tspeed: 0.0354s/iter; left time: 597.7696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 222 | Train Loss: 0.0701566 Vali Loss: 0.0771192 Test Loss: 0.0879790\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0704551\n",
      "\tspeed: 0.0631s/iter; left time: 1058.5990s\n",
      "\titers: 200, epoch: 25 | loss: 0.0669987\n",
      "\tspeed: 0.0351s/iter; left time: 585.6864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0700105 Vali Loss: 0.0773953 Test Loss: 0.0880814\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0688160\n",
      "\tspeed: 0.0676s/iter; left time: 1119.0546s\n",
      "\titers: 200, epoch: 26 | loss: 0.0712942\n",
      "\tspeed: 0.0389s/iter; left time: 639.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 222 | Train Loss: 0.0698863 Vali Loss: 0.0773792 Test Loss: 0.0879830\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677379\n",
      "\tspeed: 0.0680s/iter; left time: 1110.2304s\n",
      "\titers: 200, epoch: 27 | loss: 0.0688420\n",
      "\tspeed: 0.0376s/iter; left time: 610.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 222 | Train Loss: 0.0698373 Vali Loss: 0.0773966 Test Loss: 0.0879976\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018628498539328575, rmse:0.1364862620830536, mae:0.08806803822517395, rse:0.40095552802085876\n",
      "Intermediate time for ES and pred_len 96: 00h:08m:20.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1667172\n",
      "\tspeed: 0.0552s/iter; left time: 1220.6149s\n",
      "\titers: 200, epoch: 1 | loss: 0.1536697\n",
      "\tspeed: 0.0274s/iter; left time: 602.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.1667698 Vali Loss: 0.1555198 Test Loss: 0.1867086\n",
      "Validation loss decreased (inf --> 0.155520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0991840\n",
      "\tspeed: 0.0623s/iter; left time: 1364.1173s\n",
      "\titers: 200, epoch: 2 | loss: 0.0904490\n",
      "\tspeed: 0.0310s/iter; left time: 674.9193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 222 | Train Loss: 0.1023045 Vali Loss: 0.0883571 Test Loss: 0.1026201\n",
      "Validation loss decreased (0.155520 --> 0.088357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0852566\n",
      "\tspeed: 0.0602s/iter; left time: 1304.4075s\n",
      "\titers: 200, epoch: 3 | loss: 0.0899479\n",
      "\tspeed: 0.0280s/iter; left time: 604.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0876371 Vali Loss: 0.0861908 Test Loss: 0.1001199\n",
      "Validation loss decreased (0.088357 --> 0.086191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0866420\n",
      "\tspeed: 0.0657s/iter; left time: 1409.2194s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839753\n",
      "\tspeed: 0.0357s/iter; left time: 761.3358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 222 | Train Loss: 0.0848534 Vali Loss: 0.0848617 Test Loss: 0.0979498\n",
      "Validation loss decreased (0.086191 --> 0.084862).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815515\n",
      "\tspeed: 0.0609s/iter; left time: 1292.3184s\n",
      "\titers: 200, epoch: 5 | loss: 0.0821665\n",
      "\tspeed: 0.0293s/iter; left time: 619.0380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 222 | Train Loss: 0.0831524 Vali Loss: 0.0840774 Test Loss: 0.0967102\n",
      "Validation loss decreased (0.084862 --> 0.084077).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816573\n",
      "\tspeed: 0.0575s/iter; left time: 1207.8233s\n",
      "\titers: 200, epoch: 6 | loss: 0.0814491\n",
      "\tspeed: 0.0267s/iter; left time: 558.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0820276 Vali Loss: 0.0837123 Test Loss: 0.0960241\n",
      "Validation loss decreased (0.084077 --> 0.083712).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792192\n",
      "\tspeed: 0.0586s/iter; left time: 1216.0859s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831278\n",
      "\tspeed: 0.0331s/iter; left time: 684.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 222 | Train Loss: 0.0811314 Vali Loss: 0.0834576 Test Loss: 0.0960972\n",
      "Validation loss decreased (0.083712 --> 0.083458).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0796208\n",
      "\tspeed: 0.0647s/iter; left time: 1328.3732s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806814\n",
      "\tspeed: 0.0301s/iter; left time: 615.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 222 | Train Loss: 0.0802573 Vali Loss: 0.0830220 Test Loss: 0.0954392\n",
      "Validation loss decreased (0.083458 --> 0.083022).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808112\n",
      "\tspeed: 0.0553s/iter; left time: 1123.0465s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778156\n",
      "\tspeed: 0.0286s/iter; left time: 578.8028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0794692 Vali Loss: 0.0825667 Test Loss: 0.0948723\n",
      "Validation loss decreased (0.083022 --> 0.082567).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0765933\n",
      "\tspeed: 0.0647s/iter; left time: 1299.8096s\n",
      "\titers: 200, epoch: 10 | loss: 0.0799552\n",
      "\tspeed: 0.0357s/iter; left time: 713.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 222 | Train Loss: 0.0787534 Vali Loss: 0.0829924 Test Loss: 0.0953556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0777095\n",
      "\tspeed: 0.0650s/iter; left time: 1292.5402s\n",
      "\titers: 200, epoch: 11 | loss: 0.0800485\n",
      "\tspeed: 0.0390s/iter; left time: 771.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 222 | Train Loss: 0.0780211 Vali Loss: 0.0823126 Test Loss: 0.0951677\n",
      "Validation loss decreased (0.082567 --> 0.082313).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0800414\n",
      "\tspeed: 0.0697s/iter; left time: 1369.2970s\n",
      "\titers: 200, epoch: 12 | loss: 0.0824459\n",
      "\tspeed: 0.0319s/iter; left time: 624.3102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0774122 Vali Loss: 0.0827821 Test Loss: 0.0951796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763938\n",
      "\tspeed: 0.0634s/iter; left time: 1232.3955s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729557\n",
      "\tspeed: 0.0353s/iter; left time: 682.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 222 | Train Loss: 0.0769091 Vali Loss: 0.0832343 Test Loss: 0.0953470\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795303\n",
      "\tspeed: 0.0579s/iter; left time: 1112.1727s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762575\n",
      "\tspeed: 0.0282s/iter; left time: 539.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 222 | Train Loss: 0.0764272 Vali Loss: 0.0831960 Test Loss: 0.0958590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0779220\n",
      "\tspeed: 0.0623s/iter; left time: 1182.4182s\n",
      "\titers: 200, epoch: 15 | loss: 0.0743586\n",
      "\tspeed: 0.0284s/iter; left time: 536.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 222 | Train Loss: 0.0759978 Vali Loss: 0.0832602 Test Loss: 0.0960988\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0753150\n",
      "\tspeed: 0.0574s/iter; left time: 1077.7629s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744865\n",
      "\tspeed: 0.0379s/iter; left time: 707.4219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0755878 Vali Loss: 0.0834599 Test Loss: 0.0960339\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748832\n",
      "\tspeed: 0.0669s/iter; left time: 1240.4314s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759960\n",
      "\tspeed: 0.0375s/iter; left time: 692.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 222 | Train Loss: 0.0752210 Vali Loss: 0.0834334 Test Loss: 0.0962290\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756022\n",
      "\tspeed: 0.0667s/iter; left time: 1221.7151s\n",
      "\titers: 200, epoch: 18 | loss: 0.0739933\n",
      "\tspeed: 0.0375s/iter; left time: 683.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 222 | Train Loss: 0.0748861 Vali Loss: 0.0835302 Test Loss: 0.0964667\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730945\n",
      "\tspeed: 0.0625s/iter; left time: 1130.9809s\n",
      "\titers: 200, epoch: 19 | loss: 0.0748410\n",
      "\tspeed: 0.0325s/iter; left time: 585.5471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 222 | Train Loss: 0.0746826 Vali Loss: 0.0833939 Test Loss: 0.0963619\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0772223\n",
      "\tspeed: 0.0665s/iter; left time: 1189.2741s\n",
      "\titers: 200, epoch: 20 | loss: 0.0748088\n",
      "\tspeed: 0.0311s/iter; left time: 552.4180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 222 | Train Loss: 0.0744102 Vali Loss: 0.0835283 Test Loss: 0.0962982\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0765162\n",
      "\tspeed: 0.0628s/iter; left time: 1108.9107s\n",
      "\titers: 200, epoch: 21 | loss: 0.0756740\n",
      "\tspeed: 0.0372s/iter; left time: 654.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 222 | Train Loss: 0.0742003 Vali Loss: 0.0838472 Test Loss: 0.0966690\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021149104461073875, rmse:0.14542731642723083, mae:0.09516771137714386, rse:0.4272523820400238\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1664377\n",
      "\tspeed: 0.0363s/iter; left time: 803.3459s\n",
      "\titers: 200, epoch: 1 | loss: 0.1513519\n",
      "\tspeed: 0.0359s/iter; left time: 790.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.1676767 Vali Loss: 0.1554711 Test Loss: 0.1863854\n",
      "Validation loss decreased (inf --> 0.155471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0968717\n",
      "\tspeed: 0.0647s/iter; left time: 1414.5771s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898460\n",
      "\tspeed: 0.0288s/iter; left time: 627.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 222 | Train Loss: 0.1027922 Vali Loss: 0.0887035 Test Loss: 0.1030273\n",
      "Validation loss decreased (0.155471 --> 0.088704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0901642\n",
      "\tspeed: 0.0598s/iter; left time: 1295.6163s\n",
      "\titers: 200, epoch: 3 | loss: 0.0857756\n",
      "\tspeed: 0.0407s/iter; left time: 876.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 222 | Train Loss: 0.0880740 Vali Loss: 0.0862094 Test Loss: 0.0994508\n",
      "Validation loss decreased (0.088704 --> 0.086209).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814247\n",
      "\tspeed: 0.0671s/iter; left time: 1439.0419s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831857\n",
      "\tspeed: 0.0376s/iter; left time: 801.4723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 222 | Train Loss: 0.0850540 Vali Loss: 0.0846036 Test Loss: 0.0973046\n",
      "Validation loss decreased (0.086209 --> 0.084604).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844628\n",
      "\tspeed: 0.0665s/iter; left time: 1409.7341s\n",
      "\titers: 200, epoch: 5 | loss: 0.0840128\n",
      "\tspeed: 0.0352s/iter; left time: 742.9711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0831540 Vali Loss: 0.0838599 Test Loss: 0.0966601\n",
      "Validation loss decreased (0.084604 --> 0.083860).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0823022\n",
      "\tspeed: 0.0668s/iter; left time: 1402.7807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834867\n",
      "\tspeed: 0.0386s/iter; left time: 806.1947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 222 | Train Loss: 0.0818759 Vali Loss: 0.0833183 Test Loss: 0.0960490\n",
      "Validation loss decreased (0.083860 --> 0.083318).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0805004\n",
      "\tspeed: 0.0645s/iter; left time: 1339.9947s\n",
      "\titers: 200, epoch: 7 | loss: 0.0791536\n",
      "\tspeed: 0.0319s/iter; left time: 660.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 222 | Train Loss: 0.0808216 Vali Loss: 0.0834087 Test Loss: 0.0960379\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782366\n",
      "\tspeed: 0.0663s/iter; left time: 1362.8576s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799921\n",
      "\tspeed: 0.0368s/iter; left time: 753.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 222 | Train Loss: 0.0798288 Vali Loss: 0.0836683 Test Loss: 0.0957463\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791614\n",
      "\tspeed: 0.0701s/iter; left time: 1425.6895s\n",
      "\titers: 200, epoch: 9 | loss: 0.0787054\n",
      "\tspeed: 0.0400s/iter; left time: 808.0796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.0789983 Vali Loss: 0.0838509 Test Loss: 0.0958226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0780901\n",
      "\tspeed: 0.0684s/iter; left time: 1374.8583s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783641\n",
      "\tspeed: 0.0358s/iter; left time: 716.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 222 | Train Loss: 0.0782063 Vali Loss: 0.0839863 Test Loss: 0.0960033\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0820689\n",
      "\tspeed: 0.0644s/iter; left time: 1280.0860s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760825\n",
      "\tspeed: 0.0406s/iter; left time: 803.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 222 | Train Loss: 0.0775632 Vali Loss: 0.0841423 Test Loss: 0.0958371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0772989\n",
      "\tspeed: 0.0692s/iter; left time: 1360.0264s\n",
      "\titers: 200, epoch: 12 | loss: 0.0770915\n",
      "\tspeed: 0.0336s/iter; left time: 657.9870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 222 | Train Loss: 0.0770076 Vali Loss: 0.0844045 Test Loss: 0.0961919\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0771320\n",
      "\tspeed: 0.0683s/iter; left time: 1328.4923s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759175\n",
      "\tspeed: 0.0344s/iter; left time: 665.6084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 222 | Train Loss: 0.0764637 Vali Loss: 0.0848842 Test Loss: 0.0961703\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0766726\n",
      "\tspeed: 0.0684s/iter; left time: 1314.4442s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747900\n",
      "\tspeed: 0.0431s/iter; left time: 822.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0759371 Vali Loss: 0.0849438 Test Loss: 0.0963353\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787375\n",
      "\tspeed: 0.0670s/iter; left time: 1273.4800s\n",
      "\titers: 200, epoch: 15 | loss: 0.0755112\n",
      "\tspeed: 0.0320s/iter; left time: 604.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 222 | Train Loss: 0.0755669 Vali Loss: 0.0850392 Test Loss: 0.0962709\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0729638\n",
      "\tspeed: 0.0680s/iter; left time: 1276.1416s\n",
      "\titers: 200, epoch: 16 | loss: 0.0759397\n",
      "\tspeed: 0.0293s/iter; left time: 547.5417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 222 | Train Loss: 0.0751992 Vali Loss: 0.0850821 Test Loss: 0.0964342\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021182619035243988, rmse:0.14554250240325928, mae:0.096049003303051, rse:0.4275907576084137\n",
      "Intermediate time for ES and pred_len 168: 00h:06m:15.69s\n",
      "Intermediate time for ES: 00h:30m:57.12s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1140872\n",
      "\tspeed: 0.0540s/iter; left time: 1199.8653s\n",
      "\titers: 200, epoch: 1 | loss: 0.1055382\n",
      "\tspeed: 0.0256s/iter; left time: 565.4553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1169740 Vali Loss: 0.1183264 Test Loss: 0.1319762\n",
      "Validation loss decreased (inf --> 0.118326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0585090\n",
      "\tspeed: 0.0511s/iter; left time: 1123.2045s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524967\n",
      "\tspeed: 0.0256s/iter; left time: 559.5772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0641247 Vali Loss: 0.0598206 Test Loss: 0.0626129\n",
      "Validation loss decreased (0.118326 --> 0.059821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0477323\n",
      "\tspeed: 0.0512s/iter; left time: 1113.4934s\n",
      "\titers: 200, epoch: 3 | loss: 0.0421955\n",
      "\tspeed: 0.0256s/iter; left time: 553.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0489894 Vali Loss: 0.0570222 Test Loss: 0.0597966\n",
      "Validation loss decreased (0.059821 --> 0.057022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0502533\n",
      "\tspeed: 0.0508s/iter; left time: 1093.7587s\n",
      "\titers: 200, epoch: 4 | loss: 0.0442259\n",
      "\tspeed: 0.0255s/iter; left time: 547.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0465537 Vali Loss: 0.0558177 Test Loss: 0.0586961\n",
      "Validation loss decreased (0.057022 --> 0.055818).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0447592\n",
      "\tspeed: 0.0524s/iter; left time: 1116.1174s\n",
      "\titers: 200, epoch: 5 | loss: 0.0480808\n",
      "\tspeed: 0.0263s/iter; left time: 557.1351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0449755 Vali Loss: 0.0543699 Test Loss: 0.0578095\n",
      "Validation loss decreased (0.055818 --> 0.054370).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0450183\n",
      "\tspeed: 0.0517s/iter; left time: 1090.3434s\n",
      "\titers: 200, epoch: 6 | loss: 0.0456242\n",
      "\tspeed: 0.0256s/iter; left time: 536.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0440491 Vali Loss: 0.0537871 Test Loss: 0.0569668\n",
      "Validation loss decreased (0.054370 --> 0.053787).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0423694\n",
      "\tspeed: 0.0516s/iter; left time: 1077.5422s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456653\n",
      "\tspeed: 0.0306s/iter; left time: 634.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0432643 Vali Loss: 0.0535342 Test Loss: 0.0568439\n",
      "Validation loss decreased (0.053787 --> 0.053534).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0415514\n",
      "\tspeed: 0.0508s/iter; left time: 1048.4094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0410998\n",
      "\tspeed: 0.0257s/iter; left time: 528.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0427699 Vali Loss: 0.0532761 Test Loss: 0.0567382\n",
      "Validation loss decreased (0.053534 --> 0.053276).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0453478\n",
      "\tspeed: 0.0557s/iter; left time: 1136.8226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443312\n",
      "\tspeed: 0.0262s/iter; left time: 532.1524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0423547 Vali Loss: 0.0529748 Test Loss: 0.0564367\n",
      "Validation loss decreased (0.053276 --> 0.052975).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0430013\n",
      "\tspeed: 0.0542s/iter; left time: 1094.4829s\n",
      "\titers: 200, epoch: 10 | loss: 0.0425285\n",
      "\tspeed: 0.0253s/iter; left time: 509.2492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0420066 Vali Loss: 0.0525059 Test Loss: 0.0561239\n",
      "Validation loss decreased (0.052975 --> 0.052506).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0413049\n",
      "\tspeed: 0.0513s/iter; left time: 1024.7067s\n",
      "\titers: 200, epoch: 11 | loss: 0.0402861\n",
      "\tspeed: 0.0259s/iter; left time: 515.0357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0417292 Vali Loss: 0.0525886 Test Loss: 0.0561171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0395130\n",
      "\tspeed: 0.0537s/iter; left time: 1060.0620s\n",
      "\titers: 200, epoch: 12 | loss: 0.0439444\n",
      "\tspeed: 0.0259s/iter; left time: 509.8252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0414576 Vali Loss: 0.0525107 Test Loss: 0.0558513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0413571\n",
      "\tspeed: 0.0504s/iter; left time: 983.8101s\n",
      "\titers: 200, epoch: 13 | loss: 0.0383228\n",
      "\tspeed: 0.0286s/iter; left time: 554.8789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0412399 Vali Loss: 0.0522327 Test Loss: 0.0559637\n",
      "Validation loss decreased (0.052506 --> 0.052233).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0402878\n",
      "\tspeed: 0.0572s/iter; left time: 1103.5860s\n",
      "\titers: 200, epoch: 14 | loss: 0.0371367\n",
      "\tspeed: 0.0303s/iter; left time: 582.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 223 | Train Loss: 0.0410573 Vali Loss: 0.0523137 Test Loss: 0.0558821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0406556\n",
      "\tspeed: 0.0547s/iter; left time: 1043.9527s\n",
      "\titers: 200, epoch: 15 | loss: 0.0415717\n",
      "\tspeed: 0.0281s/iter; left time: 533.1780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 223 | Train Loss: 0.0408860 Vali Loss: 0.0522481 Test Loss: 0.0560163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0402413\n",
      "\tspeed: 0.0546s/iter; left time: 1029.2324s\n",
      "\titers: 200, epoch: 16 | loss: 0.0400484\n",
      "\tspeed: 0.0271s/iter; left time: 508.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0407475 Vali Loss: 0.0522860 Test Loss: 0.0558234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0401683\n",
      "\tspeed: 0.0605s/iter; left time: 1126.8620s\n",
      "\titers: 200, epoch: 17 | loss: 0.0437474\n",
      "\tspeed: 0.0301s/iter; left time: 558.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.0405954 Vali Loss: 0.0521562 Test Loss: 0.0556722\n",
      "Validation loss decreased (0.052233 --> 0.052156).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0408250\n",
      "\tspeed: 0.0558s/iter; left time: 1026.6880s\n",
      "\titers: 200, epoch: 18 | loss: 0.0392674\n",
      "\tspeed: 0.0268s/iter; left time: 489.9236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0405210 Vali Loss: 0.0521421 Test Loss: 0.0558911\n",
      "Validation loss decreased (0.052156 --> 0.052142).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0411964\n",
      "\tspeed: 0.0516s/iter; left time: 937.7580s\n",
      "\titers: 200, epoch: 19 | loss: 0.0436633\n",
      "\tspeed: 0.0259s/iter; left time: 468.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0404109 Vali Loss: 0.0521563 Test Loss: 0.0556668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0390184\n",
      "\tspeed: 0.0628s/iter; left time: 1127.8895s\n",
      "\titers: 200, epoch: 20 | loss: 0.0397153\n",
      "\tspeed: 0.0379s/iter; left time: 677.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 223 | Train Loss: 0.0403161 Vali Loss: 0.0520465 Test Loss: 0.0556355\n",
      "Validation loss decreased (0.052142 --> 0.052046).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0397949\n",
      "\tspeed: 0.0691s/iter; left time: 1226.5397s\n",
      "\titers: 200, epoch: 21 | loss: 0.0426896\n",
      "\tspeed: 0.0401s/iter; left time: 706.5736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0402796 Vali Loss: 0.0520280 Test Loss: 0.0557359\n",
      "Validation loss decreased (0.052046 --> 0.052028).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0397166\n",
      "\tspeed: 0.0604s/iter; left time: 1057.9884s\n",
      "\titers: 200, epoch: 22 | loss: 0.0380174\n",
      "\tspeed: 0.0317s/iter; left time: 552.5125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.0401656 Vali Loss: 0.0520701 Test Loss: 0.0556204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0443866\n",
      "\tspeed: 0.0527s/iter; left time: 911.7040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0421690\n",
      "\tspeed: 0.0258s/iter; left time: 443.7070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0401030 Vali Loss: 0.0520472 Test Loss: 0.0557340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0395614\n",
      "\tspeed: 0.0532s/iter; left time: 907.5431s\n",
      "\titers: 200, epoch: 24 | loss: 0.0389571\n",
      "\tspeed: 0.0305s/iter; left time: 518.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 223 | Train Loss: 0.0400681 Vali Loss: 0.0519396 Test Loss: 0.0555869\n",
      "Validation loss decreased (0.052028 --> 0.051940).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0416265\n",
      "\tspeed: 0.0533s/iter; left time: 898.1833s\n",
      "\titers: 200, epoch: 25 | loss: 0.0403194\n",
      "\tspeed: 0.0306s/iter; left time: 512.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0399590 Vali Loss: 0.0519754 Test Loss: 0.0557054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0398572\n",
      "\tspeed: 0.0622s/iter; left time: 1033.9746s\n",
      "\titers: 200, epoch: 26 | loss: 0.0412667\n",
      "\tspeed: 0.0392s/iter; left time: 648.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 223 | Train Loss: 0.0399254 Vali Loss: 0.0519261 Test Loss: 0.0555977\n",
      "Validation loss decreased (0.051940 --> 0.051926).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0432502\n",
      "\tspeed: 0.0585s/iter; left time: 958.9274s\n",
      "\titers: 200, epoch: 27 | loss: 0.0406726\n",
      "\tspeed: 0.0260s/iter; left time: 423.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0399007 Vali Loss: 0.0518692 Test Loss: 0.0556088\n",
      "Validation loss decreased (0.051926 --> 0.051869).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0386496\n",
      "\tspeed: 0.0537s/iter; left time: 868.1481s\n",
      "\titers: 200, epoch: 28 | loss: 0.0393012\n",
      "\tspeed: 0.0287s/iter; left time: 462.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0399026 Vali Loss: 0.0519179 Test Loss: 0.0556006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0399515\n",
      "\tspeed: 0.0593s/iter; left time: 945.4799s\n",
      "\titers: 200, epoch: 29 | loss: 0.0371560\n",
      "\tspeed: 0.0299s/iter; left time: 474.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0398341 Vali Loss: 0.0518811 Test Loss: 0.0554868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0424017\n",
      "\tspeed: 0.0507s/iter; left time: 797.6891s\n",
      "\titers: 200, epoch: 30 | loss: 0.0418225\n",
      "\tspeed: 0.0261s/iter; left time: 407.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.0398197 Vali Loss: 0.0518277 Test Loss: 0.0555114\n",
      "Validation loss decreased (0.051869 --> 0.051828).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0409460\n",
      "\tspeed: 0.0532s/iter; left time: 824.5338s\n",
      "\titers: 200, epoch: 31 | loss: 0.0386783\n",
      "\tspeed: 0.0278s/iter; left time: 427.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0397842 Vali Loss: 0.0518128 Test Loss: 0.0555074\n",
      "Validation loss decreased (0.051828 --> 0.051813).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0376600\n",
      "\tspeed: 0.0526s/iter; left time: 803.5391s\n",
      "\titers: 200, epoch: 32 | loss: 0.0418769\n",
      "\tspeed: 0.0256s/iter; left time: 388.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0397508 Vali Loss: 0.0519186 Test Loss: 0.0556834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0399474\n",
      "\tspeed: 0.0513s/iter; left time: 772.6690s\n",
      "\titers: 200, epoch: 33 | loss: 0.0382622\n",
      "\tspeed: 0.0256s/iter; left time: 383.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0397641 Vali Loss: 0.0519161 Test Loss: 0.0556035\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0405266\n",
      "\tspeed: 0.0501s/iter; left time: 743.7973s\n",
      "\titers: 200, epoch: 34 | loss: 0.0407878\n",
      "\tspeed: 0.0256s/iter; left time: 377.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0397053 Vali Loss: 0.0519603 Test Loss: 0.0555645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0405657\n",
      "\tspeed: 0.0529s/iter; left time: 773.2533s\n",
      "\titers: 200, epoch: 35 | loss: 0.0371235\n",
      "\tspeed: 0.0282s/iter; left time: 409.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0396990 Vali Loss: 0.0519316 Test Loss: 0.0556261\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0390754\n",
      "\tspeed: 0.0557s/iter; left time: 802.5640s\n",
      "\titers: 200, epoch: 36 | loss: 0.0397889\n",
      "\tspeed: 0.0271s/iter; left time: 387.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0396818 Vali Loss: 0.0518233 Test Loss: 0.0555336\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0416521\n",
      "\tspeed: 0.0612s/iter; left time: 866.8181s\n",
      "\titers: 200, epoch: 37 | loss: 0.0417674\n",
      "\tspeed: 0.0325s/iter; left time: 457.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0396595 Vali Loss: 0.0519470 Test Loss: 0.0556143\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0399431\n",
      "\tspeed: 0.0624s/iter; left time: 870.5504s\n",
      "\titers: 200, epoch: 38 | loss: 0.0405230\n",
      "\tspeed: 0.0345s/iter; left time: 477.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0396327 Vali Loss: 0.0519122 Test Loss: 0.0555291\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0400016\n",
      "\tspeed: 0.0605s/iter; left time: 830.9424s\n",
      "\titers: 200, epoch: 39 | loss: 0.0430805\n",
      "\tspeed: 0.0260s/iter; left time: 354.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 223 | Train Loss: 0.0396404 Vali Loss: 0.0517961 Test Loss: 0.0555071\n",
      "Validation loss decreased (0.051813 --> 0.051796).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0430878\n",
      "\tspeed: 0.0577s/iter; left time: 779.8378s\n",
      "\titers: 200, epoch: 40 | loss: 0.0407361\n",
      "\tspeed: 0.0263s/iter; left time: 352.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.0396136 Vali Loss: 0.0518378 Test Loss: 0.0555239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0395740\n",
      "\tspeed: 0.0553s/iter; left time: 734.9857s\n",
      "\titers: 200, epoch: 41 | loss: 0.0375407\n",
      "\tspeed: 0.0265s/iter; left time: 349.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.0396253 Vali Loss: 0.0518491 Test Loss: 0.0555658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0417149\n",
      "\tspeed: 0.0560s/iter; left time: 730.6952s\n",
      "\titers: 200, epoch: 42 | loss: 0.0392544\n",
      "\tspeed: 0.0282s/iter; left time: 365.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.0395969 Vali Loss: 0.0518761 Test Loss: 0.0555099\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0373820\n",
      "\tspeed: 0.0618s/iter; left time: 793.7193s\n",
      "\titers: 200, epoch: 43 | loss: 0.0403155\n",
      "\tspeed: 0.0256s/iter; left time: 326.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0395650 Vali Loss: 0.0518275 Test Loss: 0.0555100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0386273\n",
      "\tspeed: 0.0508s/iter; left time: 640.4814s\n",
      "\titers: 200, epoch: 44 | loss: 0.0428330\n",
      "\tspeed: 0.0257s/iter; left time: 321.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0395723 Vali Loss: 0.0518688 Test Loss: 0.0555439\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0384653\n",
      "\tspeed: 0.0502s/iter; left time: 621.4847s\n",
      "\titers: 200, epoch: 45 | loss: 0.0384220\n",
      "\tspeed: 0.0256s/iter; left time: 314.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0395831 Vali Loss: 0.0518329 Test Loss: 0.0555704\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0385408\n",
      "\tspeed: 0.0579s/iter; left time: 704.2461s\n",
      "\titers: 200, epoch: 46 | loss: 0.0380344\n",
      "\tspeed: 0.0335s/iter; left time: 404.6855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0395354 Vali Loss: 0.0518282 Test Loss: 0.0554941\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0390652\n",
      "\tspeed: 0.0637s/iter; left time: 760.2368s\n",
      "\titers: 200, epoch: 47 | loss: 0.0388284\n",
      "\tspeed: 0.0315s/iter; left time: 373.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 223 | Train Loss: 0.0395766 Vali Loss: 0.0518387 Test Loss: 0.0555403\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0399073\n",
      "\tspeed: 0.0520s/iter; left time: 609.3807s\n",
      "\titers: 200, epoch: 48 | loss: 0.0395991\n",
      "\tspeed: 0.0261s/iter; left time: 303.3624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0396104 Vali Loss: 0.0518062 Test Loss: 0.0555174\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0381132\n",
      "\tspeed: 0.0603s/iter; left time: 692.8965s\n",
      "\titers: 200, epoch: 49 | loss: 0.0380972\n",
      "\tspeed: 0.0344s/iter; left time: 392.5290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0396000 Vali Loss: 0.0518392 Test Loss: 0.0555258\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010068420320749283, rmse:0.10034152120351791, mae:0.055507078766822815, rse:0.38711482286453247\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1132582\n",
      "\tspeed: 0.0276s/iter; left time: 613.4841s\n",
      "\titers: 200, epoch: 1 | loss: 0.1022840\n",
      "\tspeed: 0.0255s/iter; left time: 563.3261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.1161418 Vali Loss: 0.1172169 Test Loss: 0.1304740\n",
      "Validation loss decreased (inf --> 0.117217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0585198\n",
      "\tspeed: 0.0551s/iter; left time: 1210.9590s\n",
      "\titers: 200, epoch: 2 | loss: 0.0538354\n",
      "\tspeed: 0.0289s/iter; left time: 632.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0644673 Vali Loss: 0.0602254 Test Loss: 0.0633617\n",
      "Validation loss decreased (0.117217 --> 0.060225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0487929\n",
      "\tspeed: 0.0527s/iter; left time: 1147.5686s\n",
      "\titers: 200, epoch: 3 | loss: 0.0476235\n",
      "\tspeed: 0.0255s/iter; left time: 552.1397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0492049 Vali Loss: 0.0567866 Test Loss: 0.0600417\n",
      "Validation loss decreased (0.060225 --> 0.056787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0475634\n",
      "\tspeed: 0.0569s/iter; left time: 1225.8290s\n",
      "\titers: 200, epoch: 4 | loss: 0.0435478\n",
      "\tspeed: 0.0268s/iter; left time: 573.5998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.0466075 Vali Loss: 0.0556213 Test Loss: 0.0587383\n",
      "Validation loss decreased (0.056787 --> 0.055621).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0432293\n",
      "\tspeed: 0.0584s/iter; left time: 1243.9101s\n",
      "\titers: 200, epoch: 5 | loss: 0.0454266\n",
      "\tspeed: 0.0298s/iter; left time: 632.8074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 223 | Train Loss: 0.0450911 Vali Loss: 0.0545516 Test Loss: 0.0580917\n",
      "Validation loss decreased (0.055621 --> 0.054552).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0474033\n",
      "\tspeed: 0.0597s/iter; left time: 1258.3276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0443257\n",
      "\tspeed: 0.0364s/iter; left time: 764.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0440594 Vali Loss: 0.0540765 Test Loss: 0.0573940\n",
      "Validation loss decreased (0.054552 --> 0.054077).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0411622\n",
      "\tspeed: 0.0570s/iter; left time: 1189.6463s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448081\n",
      "\tspeed: 0.0286s/iter; left time: 594.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0434055 Vali Loss: 0.0534542 Test Loss: 0.0567106\n",
      "Validation loss decreased (0.054077 --> 0.053454).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0425200\n",
      "\tspeed: 0.0520s/iter; left time: 1072.6754s\n",
      "\titers: 200, epoch: 8 | loss: 0.0405488\n",
      "\tspeed: 0.0256s/iter; left time: 525.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0428772 Vali Loss: 0.0532168 Test Loss: 0.0564695\n",
      "Validation loss decreased (0.053454 --> 0.053217).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0422284\n",
      "\tspeed: 0.0513s/iter; left time: 1047.7869s\n",
      "\titers: 200, epoch: 9 | loss: 0.0416472\n",
      "\tspeed: 0.0256s/iter; left time: 520.1560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0424359 Vali Loss: 0.0529702 Test Loss: 0.0565663\n",
      "Validation loss decreased (0.053217 --> 0.052970).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0434575\n",
      "\tspeed: 0.0558s/iter; left time: 1126.9870s\n",
      "\titers: 200, epoch: 10 | loss: 0.0444072\n",
      "\tspeed: 0.0256s/iter; left time: 513.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0420795 Vali Loss: 0.0528026 Test Loss: 0.0563766\n",
      "Validation loss decreased (0.052970 --> 0.052803).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0423735\n",
      "\tspeed: 0.0553s/iter; left time: 1105.0444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0430981\n",
      "\tspeed: 0.0256s/iter; left time: 509.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0418046 Vali Loss: 0.0526436 Test Loss: 0.0562440\n",
      "Validation loss decreased (0.052803 --> 0.052644).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0409851\n",
      "\tspeed: 0.0609s/iter; left time: 1203.0872s\n",
      "\titers: 200, epoch: 12 | loss: 0.0403020\n",
      "\tspeed: 0.0328s/iter; left time: 644.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0415196 Vali Loss: 0.0524243 Test Loss: 0.0560301\n",
      "Validation loss decreased (0.052644 --> 0.052424).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406806\n",
      "\tspeed: 0.0594s/iter; left time: 1159.2682s\n",
      "\titers: 200, epoch: 13 | loss: 0.0416546\n",
      "\tspeed: 0.0331s/iter; left time: 642.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 223 | Train Loss: 0.0413594 Vali Loss: 0.0523351 Test Loss: 0.0561979\n",
      "Validation loss decreased (0.052424 --> 0.052335).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0394528\n",
      "\tspeed: 0.0598s/iter; left time: 1153.9689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441767\n",
      "\tspeed: 0.0285s/iter; left time: 547.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 223 | Train Loss: 0.0411418 Vali Loss: 0.0523557 Test Loss: 0.0561198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0403130\n",
      "\tspeed: 0.0516s/iter; left time: 983.9553s\n",
      "\titers: 200, epoch: 15 | loss: 0.0400382\n",
      "\tspeed: 0.0256s/iter; left time: 486.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0409817 Vali Loss: 0.0521395 Test Loss: 0.0559229\n",
      "Validation loss decreased (0.052335 --> 0.052140).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0378590\n",
      "\tspeed: 0.0555s/iter; left time: 1045.6044s\n",
      "\titers: 200, epoch: 16 | loss: 0.0390551\n",
      "\tspeed: 0.0283s/iter; left time: 530.1087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 223 | Train Loss: 0.0408630 Vali Loss: 0.0522169 Test Loss: 0.0561647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0398826\n",
      "\tspeed: 0.0535s/iter; left time: 997.4003s\n",
      "\titers: 200, epoch: 17 | loss: 0.0408820\n",
      "\tspeed: 0.0309s/iter; left time: 572.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0407675 Vali Loss: 0.0522220 Test Loss: 0.0559406\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0409182\n",
      "\tspeed: 0.0578s/iter; left time: 1063.4697s\n",
      "\titers: 200, epoch: 18 | loss: 0.0396893\n",
      "\tspeed: 0.0303s/iter; left time: 555.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0405944 Vali Loss: 0.0521644 Test Loss: 0.0559545\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0402278\n",
      "\tspeed: 0.0511s/iter; left time: 929.9366s\n",
      "\titers: 200, epoch: 19 | loss: 0.0414021\n",
      "\tspeed: 0.0269s/iter; left time: 487.3301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0405438 Vali Loss: 0.0522536 Test Loss: 0.0562000\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0381580\n",
      "\tspeed: 0.0554s/iter; left time: 994.6353s\n",
      "\titers: 200, epoch: 20 | loss: 0.0443796\n",
      "\tspeed: 0.0263s/iter; left time: 470.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0404696 Vali Loss: 0.0520336 Test Loss: 0.0558095\n",
      "Validation loss decreased (0.052140 --> 0.052034).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0442392\n",
      "\tspeed: 0.0563s/iter; left time: 998.6711s\n",
      "\titers: 200, epoch: 21 | loss: 0.0412392\n",
      "\tspeed: 0.0269s/iter; left time: 475.2372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0403127 Vali Loss: 0.0519236 Test Loss: 0.0557161\n",
      "Validation loss decreased (0.052034 --> 0.051924).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0394321\n",
      "\tspeed: 0.0578s/iter; left time: 1011.9149s\n",
      "\titers: 200, epoch: 22 | loss: 0.0414123\n",
      "\tspeed: 0.0332s/iter; left time: 578.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 223 | Train Loss: 0.0403150 Vali Loss: 0.0519666 Test Loss: 0.0558106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0370747\n",
      "\tspeed: 0.0531s/iter; left time: 919.0953s\n",
      "\titers: 200, epoch: 23 | loss: 0.0420724\n",
      "\tspeed: 0.0256s/iter; left time: 439.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0402726 Vali Loss: 0.0519463 Test Loss: 0.0557027\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0377280\n",
      "\tspeed: 0.0592s/iter; left time: 1010.8380s\n",
      "\titers: 200, epoch: 24 | loss: 0.0405853\n",
      "\tspeed: 0.0290s/iter; left time: 492.5456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 223 | Train Loss: 0.0402162 Vali Loss: 0.0518627 Test Loss: 0.0556858\n",
      "Validation loss decreased (0.051924 --> 0.051863).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0378446\n",
      "\tspeed: 0.0522s/iter; left time: 879.3053s\n",
      "\titers: 200, epoch: 25 | loss: 0.0350149\n",
      "\tspeed: 0.0261s/iter; left time: 437.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 223 | Train Loss: 0.0401477 Vali Loss: 0.0518912 Test Loss: 0.0556811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0399225\n",
      "\tspeed: 0.0554s/iter; left time: 920.9663s\n",
      "\titers: 200, epoch: 26 | loss: 0.0374044\n",
      "\tspeed: 0.0281s/iter; left time: 464.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0400767 Vali Loss: 0.0518856 Test Loss: 0.0557268\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0383372\n",
      "\tspeed: 0.0652s/iter; left time: 1068.8188s\n",
      "\titers: 200, epoch: 27 | loss: 0.0363667\n",
      "\tspeed: 0.0374s/iter; left time: 609.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 223 | Train Loss: 0.0400095 Vali Loss: 0.0519391 Test Loss: 0.0558019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0393215\n",
      "\tspeed: 0.0582s/iter; left time: 941.0210s\n",
      "\titers: 200, epoch: 28 | loss: 0.0394170\n",
      "\tspeed: 0.0284s/iter; left time: 457.0781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0400020 Vali Loss: 0.0519477 Test Loss: 0.0558768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0397043\n",
      "\tspeed: 0.0516s/iter; left time: 822.9771s\n",
      "\titers: 200, epoch: 29 | loss: 0.0432118\n",
      "\tspeed: 0.0255s/iter; left time: 405.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0400001 Vali Loss: 0.0517876 Test Loss: 0.0556565\n",
      "Validation loss decreased (0.051863 --> 0.051788).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0420416\n",
      "\tspeed: 0.0627s/iter; left time: 987.0801s\n",
      "\titers: 200, epoch: 30 | loss: 0.0392087\n",
      "\tspeed: 0.0305s/iter; left time: 476.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 223 | Train Loss: 0.0399818 Vali Loss: 0.0518045 Test Loss: 0.0556866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0378915\n",
      "\tspeed: 0.0616s/iter; left time: 955.7089s\n",
      "\titers: 200, epoch: 31 | loss: 0.0394377\n",
      "\tspeed: 0.0304s/iter; left time: 468.9998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.0399130 Vali Loss: 0.0518236 Test Loss: 0.0556944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0421110\n",
      "\tspeed: 0.0570s/iter; left time: 871.9828s\n",
      "\titers: 200, epoch: 32 | loss: 0.0402363\n",
      "\tspeed: 0.0325s/iter; left time: 494.0605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 223 | Train Loss: 0.0398693 Vali Loss: 0.0518930 Test Loss: 0.0557051\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0436207\n",
      "\tspeed: 0.0619s/iter; left time: 932.6848s\n",
      "\titers: 200, epoch: 33 | loss: 0.0400281\n",
      "\tspeed: 0.0332s/iter; left time: 496.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0398992 Vali Loss: 0.0518610 Test Loss: 0.0557349\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0385314\n",
      "\tspeed: 0.0543s/iter; left time: 805.6161s\n",
      "\titers: 200, epoch: 34 | loss: 0.0429763\n",
      "\tspeed: 0.0266s/iter; left time: 391.5450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0397999 Vali Loss: 0.0517849 Test Loss: 0.0556883\n",
      "Validation loss decreased (0.051788 --> 0.051785).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0394144\n",
      "\tspeed: 0.0514s/iter; left time: 751.3656s\n",
      "\titers: 200, epoch: 35 | loss: 0.0384348\n",
      "\tspeed: 0.0283s/iter; left time: 411.2056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0398395 Vali Loss: 0.0517656 Test Loss: 0.0556700\n",
      "Validation loss decreased (0.051785 --> 0.051766).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0441906\n",
      "\tspeed: 0.0654s/iter; left time: 941.1407s\n",
      "\titers: 200, epoch: 36 | loss: 0.0392311\n",
      "\tspeed: 0.0346s/iter; left time: 495.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0398278 Vali Loss: 0.0518087 Test Loss: 0.0557225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0394461\n",
      "\tspeed: 0.0635s/iter; left time: 899.4914s\n",
      "\titers: 200, epoch: 37 | loss: 0.0410081\n",
      "\tspeed: 0.0318s/iter; left time: 447.7279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0398349 Vali Loss: 0.0517508 Test Loss: 0.0556718\n",
      "Validation loss decreased (0.051766 --> 0.051751).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0394862\n",
      "\tspeed: 0.0542s/iter; left time: 756.7741s\n",
      "\titers: 200, epoch: 38 | loss: 0.0379735\n",
      "\tspeed: 0.0294s/iter; left time: 406.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0398120 Vali Loss: 0.0517128 Test Loss: 0.0556148\n",
      "Validation loss decreased (0.051751 --> 0.051713).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0390199\n",
      "\tspeed: 0.0540s/iter; left time: 740.6660s\n",
      "\titers: 200, epoch: 39 | loss: 0.0422409\n",
      "\tspeed: 0.0267s/iter; left time: 364.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0397517 Vali Loss: 0.0517856 Test Loss: 0.0556702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0393341\n",
      "\tspeed: 0.0574s/iter; left time: 774.9537s\n",
      "\titers: 200, epoch: 40 | loss: 0.0398550\n",
      "\tspeed: 0.0303s/iter; left time: 406.6394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 223 | Train Loss: 0.0397702 Vali Loss: 0.0518023 Test Loss: 0.0556725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0386982\n",
      "\tspeed: 0.0521s/iter; left time: 692.4671s\n",
      "\titers: 200, epoch: 41 | loss: 0.0388395\n",
      "\tspeed: 0.0300s/iter; left time: 395.8581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0398026 Vali Loss: 0.0517655 Test Loss: 0.0556758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0388383\n",
      "\tspeed: 0.0515s/iter; left time: 672.0617s\n",
      "\titers: 200, epoch: 42 | loss: 0.0402277\n",
      "\tspeed: 0.0254s/iter; left time: 329.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0397475 Vali Loss: 0.0517927 Test Loss: 0.0556826\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0361455\n",
      "\tspeed: 0.0516s/iter; left time: 662.7628s\n",
      "\titers: 200, epoch: 43 | loss: 0.0377763\n",
      "\tspeed: 0.0262s/iter; left time: 333.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0397214 Vali Loss: 0.0517581 Test Loss: 0.0556980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0396060\n",
      "\tspeed: 0.0559s/iter; left time: 704.3838s\n",
      "\titers: 200, epoch: 44 | loss: 0.0380247\n",
      "\tspeed: 0.0348s/iter; left time: 435.4101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 223 | Train Loss: 0.0397499 Vali Loss: 0.0517743 Test Loss: 0.0557063\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0458198\n",
      "\tspeed: 0.0642s/iter; left time: 795.0778s\n",
      "\titers: 200, epoch: 45 | loss: 0.0401654\n",
      "\tspeed: 0.0365s/iter; left time: 449.0981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 223 | Train Loss: 0.0397515 Vali Loss: 0.0517196 Test Loss: 0.0556628\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0406211\n",
      "\tspeed: 0.0634s/iter; left time: 770.8420s\n",
      "\titers: 200, epoch: 46 | loss: 0.0394608\n",
      "\tspeed: 0.0304s/iter; left time: 367.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 223 | Train Loss: 0.0397229 Vali Loss: 0.0517849 Test Loss: 0.0556319\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393395\n",
      "\tspeed: 0.0536s/iter; left time: 640.0161s\n",
      "\titers: 200, epoch: 47 | loss: 0.0370213\n",
      "\tspeed: 0.0294s/iter; left time: 347.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0397171 Vali Loss: 0.0517463 Test Loss: 0.0556441\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0363969\n",
      "\tspeed: 0.0611s/iter; left time: 716.3410s\n",
      "\titers: 200, epoch: 48 | loss: 0.0399633\n",
      "\tspeed: 0.0336s/iter; left time: 390.5750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.0396869 Vali Loss: 0.0517929 Test Loss: 0.0556742\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010068424977362156, rmse:0.1003415435552597, mae:0.055614762008190155, rse:0.38711491227149963\n",
      "Intermediate time for FR and pred_len 24: 00h:13m:56.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1218110\n",
      "\tspeed: 0.0543s/iter; left time: 1200.2908s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137544\n",
      "\tspeed: 0.0263s/iter; left time: 579.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.1224695 Vali Loss: 0.1255808 Test Loss: 0.1406451\n",
      "Validation loss decreased (inf --> 0.125581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0732613\n",
      "\tspeed: 0.0566s/iter; left time: 1237.9003s\n",
      "\titers: 200, epoch: 2 | loss: 0.0629769\n",
      "\tspeed: 0.0279s/iter; left time: 607.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0764721 Vali Loss: 0.0765375 Test Loss: 0.0843603\n",
      "Validation loss decreased (0.125581 --> 0.076538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0626130\n",
      "\tspeed: 0.0563s/iter; left time: 1218.4135s\n",
      "\titers: 200, epoch: 3 | loss: 0.0620434\n",
      "\tspeed: 0.0268s/iter; left time: 577.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 222 | Train Loss: 0.0635961 Vali Loss: 0.0739032 Test Loss: 0.0823538\n",
      "Validation loss decreased (0.076538 --> 0.073903).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0589487\n",
      "\tspeed: 0.0538s/iter; left time: 1154.1285s\n",
      "\titers: 200, epoch: 4 | loss: 0.0592938\n",
      "\tspeed: 0.0268s/iter; left time: 572.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0610566 Vali Loss: 0.0730475 Test Loss: 0.0817051\n",
      "Validation loss decreased (0.073903 --> 0.073048).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600801\n",
      "\tspeed: 0.0533s/iter; left time: 1130.1240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0598252\n",
      "\tspeed: 0.0274s/iter; left time: 578.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0595624 Vali Loss: 0.0719791 Test Loss: 0.0804170\n",
      "Validation loss decreased (0.073048 --> 0.071979).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568739\n",
      "\tspeed: 0.0650s/iter; left time: 1363.7298s\n",
      "\titers: 200, epoch: 6 | loss: 0.0549373\n",
      "\tspeed: 0.0352s/iter; left time: 736.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 222 | Train Loss: 0.0585994 Vali Loss: 0.0717396 Test Loss: 0.0801455\n",
      "Validation loss decreased (0.071979 --> 0.071740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0579307\n",
      "\tspeed: 0.0551s/iter; left time: 1143.5399s\n",
      "\titers: 200, epoch: 7 | loss: 0.0577383\n",
      "\tspeed: 0.0287s/iter; left time: 592.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0578489 Vali Loss: 0.0716063 Test Loss: 0.0804583\n",
      "Validation loss decreased (0.071740 --> 0.071606).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599716\n",
      "\tspeed: 0.0712s/iter; left time: 1463.4507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0574920\n",
      "\tspeed: 0.0382s/iter; left time: 782.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 222 | Train Loss: 0.0572437 Vali Loss: 0.0714968 Test Loss: 0.0802611\n",
      "Validation loss decreased (0.071606 --> 0.071497).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546870\n",
      "\tspeed: 0.0666s/iter; left time: 1353.4128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0564790\n",
      "\tspeed: 0.0364s/iter; left time: 736.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 222 | Train Loss: 0.0567020 Vali Loss: 0.0715490 Test Loss: 0.0804176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0561256\n",
      "\tspeed: 0.0663s/iter; left time: 1333.7128s\n",
      "\titers: 200, epoch: 10 | loss: 0.0582485\n",
      "\tspeed: 0.0347s/iter; left time: 694.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 222 | Train Loss: 0.0562384 Vali Loss: 0.0716411 Test Loss: 0.0808098\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0566050\n",
      "\tspeed: 0.0603s/iter; left time: 1198.9244s\n",
      "\titers: 200, epoch: 11 | loss: 0.0527454\n",
      "\tspeed: 0.0339s/iter; left time: 670.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 222 | Train Loss: 0.0558264 Vali Loss: 0.0717166 Test Loss: 0.0808106\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0565046\n",
      "\tspeed: 0.0629s/iter; left time: 1235.9549s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571343\n",
      "\tspeed: 0.0365s/iter; left time: 713.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 222 | Train Loss: 0.0554664 Vali Loss: 0.0716104 Test Loss: 0.0808155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0534686\n",
      "\tspeed: 0.0650s/iter; left time: 1262.5679s\n",
      "\titers: 200, epoch: 13 | loss: 0.0560080\n",
      "\tspeed: 0.0348s/iter; left time: 672.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 222 | Train Loss: 0.0551084 Vali Loss: 0.0717066 Test Loss: 0.0808741\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560629\n",
      "\tspeed: 0.0563s/iter; left time: 1081.6013s\n",
      "\titers: 200, epoch: 14 | loss: 0.0566833\n",
      "\tspeed: 0.0262s/iter; left time: 501.7400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0547990 Vali Loss: 0.0718297 Test Loss: 0.0809084\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0565253\n",
      "\tspeed: 0.0597s/iter; left time: 1133.2824s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540411\n",
      "\tspeed: 0.0352s/iter; left time: 665.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 222 | Train Loss: 0.0545360 Vali Loss: 0.0719537 Test Loss: 0.0807955\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574836\n",
      "\tspeed: 0.0670s/iter; left time: 1258.3732s\n",
      "\titers: 200, epoch: 16 | loss: 0.0550019\n",
      "\tspeed: 0.0345s/iter; left time: 643.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 222 | Train Loss: 0.0542379 Vali Loss: 0.0718396 Test Loss: 0.0810291\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0547287\n",
      "\tspeed: 0.0668s/iter; left time: 1238.8829s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582256\n",
      "\tspeed: 0.0384s/iter; left time: 709.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 222 | Train Loss: 0.0540318 Vali Loss: 0.0721772 Test Loss: 0.0814868\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0530501\n",
      "\tspeed: 0.0642s/iter; left time: 1176.4423s\n",
      "\titers: 200, epoch: 18 | loss: 0.0536336\n",
      "\tspeed: 0.0369s/iter; left time: 672.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 222 | Train Loss: 0.0537833 Vali Loss: 0.0720254 Test Loss: 0.0813267\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018443172797560692, rmse:0.1358056366443634, mae:0.08026110380887985, rse:0.5253323316574097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1246816\n",
      "\tspeed: 0.0323s/iter; left time: 714.6482s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083415\n",
      "\tspeed: 0.0382s/iter; left time: 840.2121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 222 | Train Loss: 0.1208576 Vali Loss: 0.1250309 Test Loss: 0.1399231\n",
      "Validation loss decreased (inf --> 0.125031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707581\n",
      "\tspeed: 0.0698s/iter; left time: 1527.2412s\n",
      "\titers: 200, epoch: 2 | loss: 0.0676964\n",
      "\tspeed: 0.0383s/iter; left time: 835.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 222 | Train Loss: 0.0755458 Vali Loss: 0.0763404 Test Loss: 0.0844156\n",
      "Validation loss decreased (0.125031 --> 0.076340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0626083\n",
      "\tspeed: 0.0656s/iter; left time: 1421.6335s\n",
      "\titers: 200, epoch: 3 | loss: 0.0610911\n",
      "\tspeed: 0.0354s/iter; left time: 763.9699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 222 | Train Loss: 0.0636499 Vali Loss: 0.0736971 Test Loss: 0.0824052\n",
      "Validation loss decreased (0.076340 --> 0.073697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0626939\n",
      "\tspeed: 0.0702s/iter; left time: 1505.5704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0574194\n",
      "\tspeed: 0.0356s/iter; left time: 759.2536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 222 | Train Loss: 0.0610933 Vali Loss: 0.0726728 Test Loss: 0.0814737\n",
      "Validation loss decreased (0.073697 --> 0.072673).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620710\n",
      "\tspeed: 0.0655s/iter; left time: 1389.3757s\n",
      "\titers: 200, epoch: 5 | loss: 0.0601563\n",
      "\tspeed: 0.0402s/iter; left time: 848.8582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 222 | Train Loss: 0.0596398 Vali Loss: 0.0723173 Test Loss: 0.0810761\n",
      "Validation loss decreased (0.072673 --> 0.072317).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594851\n",
      "\tspeed: 0.0686s/iter; left time: 1439.8091s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588357\n",
      "\tspeed: 0.0381s/iter; left time: 795.7122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 222 | Train Loss: 0.0587047 Vali Loss: 0.0719135 Test Loss: 0.0805775\n",
      "Validation loss decreased (0.072317 --> 0.071914).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0547667\n",
      "\tspeed: 0.0617s/iter; left time: 1281.6529s\n",
      "\titers: 200, epoch: 7 | loss: 0.0588855\n",
      "\tspeed: 0.0354s/iter; left time: 731.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 222 | Train Loss: 0.0580425 Vali Loss: 0.0717449 Test Loss: 0.0804237\n",
      "Validation loss decreased (0.071914 --> 0.071745).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0559218\n",
      "\tspeed: 0.0676s/iter; left time: 1388.2836s\n",
      "\titers: 200, epoch: 8 | loss: 0.0587478\n",
      "\tspeed: 0.0365s/iter; left time: 745.9718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 222 | Train Loss: 0.0573750 Vali Loss: 0.0720185 Test Loss: 0.0807697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0574036\n",
      "\tspeed: 0.0674s/iter; left time: 1368.9895s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579369\n",
      "\tspeed: 0.0355s/iter; left time: 717.2066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 222 | Train Loss: 0.0568755 Vali Loss: 0.0718540 Test Loss: 0.0807775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529149\n",
      "\tspeed: 0.0680s/iter; left time: 1366.8527s\n",
      "\titers: 200, epoch: 10 | loss: 0.0574327\n",
      "\tspeed: 0.0365s/iter; left time: 731.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 222 | Train Loss: 0.0564229 Vali Loss: 0.0719503 Test Loss: 0.0809164\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0546500\n",
      "\tspeed: 0.0603s/iter; left time: 1199.3747s\n",
      "\titers: 200, epoch: 11 | loss: 0.0563277\n",
      "\tspeed: 0.0331s/iter; left time: 654.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 222 | Train Loss: 0.0559679 Vali Loss: 0.0718429 Test Loss: 0.0806213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0607247\n",
      "\tspeed: 0.0664s/iter; left time: 1304.8005s\n",
      "\titers: 200, epoch: 12 | loss: 0.0570613\n",
      "\tspeed: 0.0372s/iter; left time: 728.4791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 222 | Train Loss: 0.0556233 Vali Loss: 0.0717238 Test Loss: 0.0808648\n",
      "Validation loss decreased (0.071745 --> 0.071724).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556148\n",
      "\tspeed: 0.0627s/iter; left time: 1217.8318s\n",
      "\titers: 200, epoch: 13 | loss: 0.0545006\n",
      "\tspeed: 0.0350s/iter; left time: 676.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 222 | Train Loss: 0.0553136 Vali Loss: 0.0718773 Test Loss: 0.0808091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0571416\n",
      "\tspeed: 0.0593s/iter; left time: 1139.5261s\n",
      "\titers: 200, epoch: 14 | loss: 0.0547242\n",
      "\tspeed: 0.0259s/iter; left time: 495.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0549295 Vali Loss: 0.0720428 Test Loss: 0.0810508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0561872\n",
      "\tspeed: 0.0633s/iter; left time: 1202.9499s\n",
      "\titers: 200, epoch: 15 | loss: 0.0523929\n",
      "\tspeed: 0.0371s/iter; left time: 701.2527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 222 | Train Loss: 0.0546951 Vali Loss: 0.0721112 Test Loss: 0.0814885\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0539860\n",
      "\tspeed: 0.0671s/iter; left time: 1258.8822s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561582\n",
      "\tspeed: 0.0339s/iter; left time: 633.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 222 | Train Loss: 0.0544064 Vali Loss: 0.0720556 Test Loss: 0.0812824\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0556941\n",
      "\tspeed: 0.0674s/iter; left time: 1249.6840s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528033\n",
      "\tspeed: 0.0357s/iter; left time: 658.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 222 | Train Loss: 0.0541754 Vali Loss: 0.0719461 Test Loss: 0.0811439\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0512479\n",
      "\tspeed: 0.0550s/iter; left time: 1008.3677s\n",
      "\titers: 200, epoch: 18 | loss: 0.0556756\n",
      "\tspeed: 0.0259s/iter; left time: 471.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 222 | Train Loss: 0.0539673 Vali Loss: 0.0720825 Test Loss: 0.0813842\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529617\n",
      "\tspeed: 0.0623s/iter; left time: 1127.8357s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589110\n",
      "\tspeed: 0.0276s/iter; left time: 496.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 222 | Train Loss: 0.0537682 Vali Loss: 0.0721191 Test Loss: 0.0815389\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0530473\n",
      "\tspeed: 0.0540s/iter; left time: 964.8651s\n",
      "\titers: 200, epoch: 20 | loss: 0.0524342\n",
      "\tspeed: 0.0367s/iter; left time: 653.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 222 | Train Loss: 0.0535894 Vali Loss: 0.0719286 Test Loss: 0.0811005\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0520260\n",
      "\tspeed: 0.0635s/iter; left time: 1121.4379s\n",
      "\titers: 200, epoch: 21 | loss: 0.0523385\n",
      "\tspeed: 0.0308s/iter; left time: 541.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 222 | Train Loss: 0.0534064 Vali Loss: 0.0721837 Test Loss: 0.0814508\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0546495\n",
      "\tspeed: 0.0680s/iter; left time: 1186.3745s\n",
      "\titers: 200, epoch: 22 | loss: 0.0498412\n",
      "\tspeed: 0.0442s/iter; left time: 767.0321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0533119 Vali Loss: 0.0722265 Test Loss: 0.0815963\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018584182485938072, rmse:0.13632380962371826, mae:0.0808648020029068, rse:0.5273367166519165\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:40.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1241037\n",
      "\tspeed: 0.0547s/iter; left time: 1209.5305s\n",
      "\titers: 200, epoch: 1 | loss: 0.1148480\n",
      "\tspeed: 0.0264s/iter; left time: 581.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.1233226 Vali Loss: 0.1280907 Test Loss: 0.1417627\n",
      "Validation loss decreased (inf --> 0.128091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0762033\n",
      "\tspeed: 0.0587s/iter; left time: 1283.3462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0660794\n",
      "\tspeed: 0.0301s/iter; left time: 656.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 222 | Train Loss: 0.0792840 Vali Loss: 0.0804045 Test Loss: 0.0875624\n",
      "Validation loss decreased (0.128091 --> 0.080405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0685591\n",
      "\tspeed: 0.0558s/iter; left time: 1208.6553s\n",
      "\titers: 200, epoch: 3 | loss: 0.0683600\n",
      "\tspeed: 0.0303s/iter; left time: 652.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0674569 Vali Loss: 0.0777807 Test Loss: 0.0861774\n",
      "Validation loss decreased (0.080405 --> 0.077781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0601392\n",
      "\tspeed: 0.0593s/iter; left time: 1271.5151s\n",
      "\titers: 200, epoch: 4 | loss: 0.0608068\n",
      "\tspeed: 0.0303s/iter; left time: 646.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 222 | Train Loss: 0.0649505 Vali Loss: 0.0766171 Test Loss: 0.0853603\n",
      "Validation loss decreased (0.077781 --> 0.076617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0603957\n",
      "\tspeed: 0.0634s/iter; left time: 1344.9485s\n",
      "\titers: 200, epoch: 5 | loss: 0.0650201\n",
      "\tspeed: 0.0346s/iter; left time: 730.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 222 | Train Loss: 0.0635107 Vali Loss: 0.0764300 Test Loss: 0.0851777\n",
      "Validation loss decreased (0.076617 --> 0.076430).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637357\n",
      "\tspeed: 0.0577s/iter; left time: 1211.1256s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619895\n",
      "\tspeed: 0.0263s/iter; left time: 549.0307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.0624784 Vali Loss: 0.0765892 Test Loss: 0.0853962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594628\n",
      "\tspeed: 0.0662s/iter; left time: 1375.7045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0616477\n",
      "\tspeed: 0.0387s/iter; left time: 798.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 222 | Train Loss: 0.0616294 Vali Loss: 0.0757560 Test Loss: 0.0842478\n",
      "Validation loss decreased (0.076430 --> 0.075756).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0615715\n",
      "\tspeed: 0.0553s/iter; left time: 1135.7621s\n",
      "\titers: 200, epoch: 8 | loss: 0.0592556\n",
      "\tspeed: 0.0262s/iter; left time: 534.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 222 | Train Loss: 0.0608564 Vali Loss: 0.0754588 Test Loss: 0.0848377\n",
      "Validation loss decreased (0.075756 --> 0.075459).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0557141\n",
      "\tspeed: 0.0568s/iter; left time: 1154.6372s\n",
      "\titers: 200, epoch: 9 | loss: 0.0596301\n",
      "\tspeed: 0.0300s/iter; left time: 606.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 222 | Train Loss: 0.0601670 Vali Loss: 0.0760837 Test Loss: 0.0850899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0575630\n",
      "\tspeed: 0.0656s/iter; left time: 1319.7173s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610277\n",
      "\tspeed: 0.0347s/iter; left time: 693.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 222 | Train Loss: 0.0594669 Vali Loss: 0.0762974 Test Loss: 0.0856869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0581777\n",
      "\tspeed: 0.0658s/iter; left time: 1307.5520s\n",
      "\titers: 200, epoch: 11 | loss: 0.0626729\n",
      "\tspeed: 0.0386s/iter; left time: 763.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 222 | Train Loss: 0.0589573 Vali Loss: 0.0762021 Test Loss: 0.0856056\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0572700\n",
      "\tspeed: 0.0670s/iter; left time: 1317.3079s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594733\n",
      "\tspeed: 0.0326s/iter; left time: 637.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0584877 Vali Loss: 0.0765176 Test Loss: 0.0859598\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0599858\n",
      "\tspeed: 0.0596s/iter; left time: 1159.3862s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555707\n",
      "\tspeed: 0.0287s/iter; left time: 555.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0580689 Vali Loss: 0.0766434 Test Loss: 0.0858079\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577650\n",
      "\tspeed: 0.0590s/iter; left time: 1134.5932s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560344\n",
      "\tspeed: 0.0351s/iter; left time: 670.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 222 | Train Loss: 0.0577026 Vali Loss: 0.0765224 Test Loss: 0.0860210\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582381\n",
      "\tspeed: 0.0643s/iter; left time: 1220.8244s\n",
      "\titers: 200, epoch: 15 | loss: 0.0560290\n",
      "\tspeed: 0.0381s/iter; left time: 720.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 222 | Train Loss: 0.0573487 Vali Loss: 0.0766813 Test Loss: 0.0860490\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0590813\n",
      "\tspeed: 0.0678s/iter; left time: 1272.0910s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580636\n",
      "\tspeed: 0.0383s/iter; left time: 714.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 222 | Train Loss: 0.0570629 Vali Loss: 0.0767765 Test Loss: 0.0864700\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0529347\n",
      "\tspeed: 0.0698s/iter; left time: 1293.9457s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565189\n",
      "\tspeed: 0.0409s/iter; left time: 754.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.0568093 Vali Loss: 0.0769049 Test Loss: 0.0865274\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0588267\n",
      "\tspeed: 0.0738s/iter; left time: 1352.8751s\n",
      "\titers: 200, epoch: 18 | loss: 0.0537624\n",
      "\tspeed: 0.0415s/iter; left time: 756.7895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.0565839 Vali Loss: 0.0770290 Test Loss: 0.0864557\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02002469077706337, rmse:0.14150862395763397, mae:0.0848376527428627, rse:0.548076331615448\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1211106\n",
      "\tspeed: 0.0435s/iter; left time: 961.5476s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141630\n",
      "\tspeed: 0.0456s/iter; left time: 1003.3212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 222 | Train Loss: 0.1233040 Vali Loss: 0.1278187 Test Loss: 0.1413660\n",
      "Validation loss decreased (inf --> 0.127819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0776612\n",
      "\tspeed: 0.0731s/iter; left time: 1598.9506s\n",
      "\titers: 200, epoch: 2 | loss: 0.0677784\n",
      "\tspeed: 0.0431s/iter; left time: 938.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.0793558 Vali Loss: 0.0804367 Test Loss: 0.0882609\n",
      "Validation loss decreased (0.127819 --> 0.080437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0627224\n",
      "\tspeed: 0.0772s/iter; left time: 1672.8785s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644695\n",
      "\tspeed: 0.0414s/iter; left time: 891.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 222 | Train Loss: 0.0676661 Vali Loss: 0.0780619 Test Loss: 0.0869329\n",
      "Validation loss decreased (0.080437 --> 0.078062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0698833\n",
      "\tspeed: 0.0751s/iter; left time: 1610.5666s\n",
      "\titers: 200, epoch: 4 | loss: 0.0630467\n",
      "\tspeed: 0.0435s/iter; left time: 928.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 222 | Train Loss: 0.0652914 Vali Loss: 0.0769144 Test Loss: 0.0860841\n",
      "Validation loss decreased (0.078062 --> 0.076914).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0638102\n",
      "\tspeed: 0.0786s/iter; left time: 1666.4487s\n",
      "\titers: 200, epoch: 5 | loss: 0.0607556\n",
      "\tspeed: 0.0458s/iter; left time: 966.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.32s\n",
      "Steps: 222 | Train Loss: 0.0637370 Vali Loss: 0.0764480 Test Loss: 0.0854253\n",
      "Validation loss decreased (0.076914 --> 0.076448).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0654437\n",
      "\tspeed: 0.0798s/iter; left time: 1674.1769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0597387\n",
      "\tspeed: 0.0448s/iter; left time: 936.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 222 | Train Loss: 0.0626930 Vali Loss: 0.0762568 Test Loss: 0.0852670\n",
      "Validation loss decreased (0.076448 --> 0.076257).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597281\n",
      "\tspeed: 0.0614s/iter; left time: 1274.9118s\n",
      "\titers: 200, epoch: 7 | loss: 0.0596455\n",
      "\tspeed: 0.0262s/iter; left time: 540.5406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0618288 Vali Loss: 0.0762865 Test Loss: 0.0851046\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591842\n",
      "\tspeed: 0.0642s/iter; left time: 1319.0185s\n",
      "\titers: 200, epoch: 8 | loss: 0.0601916\n",
      "\tspeed: 0.0373s/iter; left time: 761.8080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 222 | Train Loss: 0.0611151 Vali Loss: 0.0759843 Test Loss: 0.0851297\n",
      "Validation loss decreased (0.076257 --> 0.075984).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0585901\n",
      "\tspeed: 0.0680s/iter; left time: 1382.7456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0630196\n",
      "\tspeed: 0.0363s/iter; left time: 734.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 222 | Train Loss: 0.0604606 Vali Loss: 0.0764274 Test Loss: 0.0859740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0559151\n",
      "\tspeed: 0.0658s/iter; left time: 1322.3825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0601008\n",
      "\tspeed: 0.0366s/iter; left time: 732.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 222 | Train Loss: 0.0597636 Vali Loss: 0.0763115 Test Loss: 0.0857018\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0591346\n",
      "\tspeed: 0.0678s/iter; left time: 1347.4067s\n",
      "\titers: 200, epoch: 11 | loss: 0.0628320\n",
      "\tspeed: 0.0358s/iter; left time: 708.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 222 | Train Loss: 0.0591661 Vali Loss: 0.0764910 Test Loss: 0.0863002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0576984\n",
      "\tspeed: 0.0639s/iter; left time: 1255.3155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0599851\n",
      "\tspeed: 0.0353s/iter; left time: 690.7118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 222 | Train Loss: 0.0586572 Vali Loss: 0.0764147 Test Loss: 0.0863816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575535\n",
      "\tspeed: 0.0658s/iter; left time: 1278.7535s\n",
      "\titers: 200, epoch: 13 | loss: 0.0593046\n",
      "\tspeed: 0.0381s/iter; left time: 736.5613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 222 | Train Loss: 0.0582304 Vali Loss: 0.0766653 Test Loss: 0.0868239\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0582185\n",
      "\tspeed: 0.0645s/iter; left time: 1238.5754s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563004\n",
      "\tspeed: 0.0351s/iter; left time: 670.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 222 | Train Loss: 0.0578545 Vali Loss: 0.0768394 Test Loss: 0.0868249\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0576839\n",
      "\tspeed: 0.0681s/iter; left time: 1292.8387s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595528\n",
      "\tspeed: 0.0368s/iter; left time: 695.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 222 | Train Loss: 0.0574750 Vali Loss: 0.0768500 Test Loss: 0.0867932\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0561916\n",
      "\tspeed: 0.0661s/iter; left time: 1241.2417s\n",
      "\titers: 200, epoch: 16 | loss: 0.0564733\n",
      "\tspeed: 0.0366s/iter; left time: 683.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 222 | Train Loss: 0.0571824 Vali Loss: 0.0771773 Test Loss: 0.0871585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0573052\n",
      "\tspeed: 0.0563s/iter; left time: 1043.7449s\n",
      "\titers: 200, epoch: 17 | loss: 0.0556849\n",
      "\tspeed: 0.0269s/iter; left time: 497.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0568881 Vali Loss: 0.0771205 Test Loss: 0.0871868\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0576346\n",
      "\tspeed: 0.0621s/iter; left time: 1137.9308s\n",
      "\titers: 200, epoch: 18 | loss: 0.0556212\n",
      "\tspeed: 0.0342s/iter; left time: 624.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 222 | Train Loss: 0.0566388 Vali Loss: 0.0771398 Test Loss: 0.0873813\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020080003887414932, rmse:0.14170393347740173, mae:0.08512969315052032, rse:0.5488327145576477\n",
      "Intermediate time for FR and pred_len 168: 00h:06m:17.03s\n",
      "Intermediate time for FR: 00h:26m:53.79s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1666982\n",
      "\tspeed: 0.0537s/iter; left time: 1192.4171s\n",
      "\titers: 200, epoch: 1 | loss: 0.1524902\n",
      "\tspeed: 0.0266s/iter; left time: 586.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.1706979 Vali Loss: 0.1437861 Test Loss: 0.1501406\n",
      "Validation loss decreased (inf --> 0.143786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0817006\n",
      "\tspeed: 0.0524s/iter; left time: 1151.4816s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682279\n",
      "\tspeed: 0.0256s/iter; left time: 559.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0888713 Vali Loss: 0.0640438 Test Loss: 0.0672689\n",
      "Validation loss decreased (0.143786 --> 0.064044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619602\n",
      "\tspeed: 0.0511s/iter; left time: 1112.4195s\n",
      "\titers: 200, epoch: 3 | loss: 0.0613660\n",
      "\tspeed: 0.0256s/iter; left time: 554.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0651459 Vali Loss: 0.0600841 Test Loss: 0.0636509\n",
      "Validation loss decreased (0.064044 --> 0.060084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0605855\n",
      "\tspeed: 0.0535s/iter; left time: 1151.2566s\n",
      "\titers: 200, epoch: 4 | loss: 0.0596265\n",
      "\tspeed: 0.0262s/iter; left time: 560.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0614747 Vali Loss: 0.0587187 Test Loss: 0.0623024\n",
      "Validation loss decreased (0.060084 --> 0.058719).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0572405\n",
      "\tspeed: 0.0512s/iter; left time: 1090.7559s\n",
      "\titers: 200, epoch: 5 | loss: 0.0620339\n",
      "\tspeed: 0.0257s/iter; left time: 544.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0594598 Vali Loss: 0.0573285 Test Loss: 0.0608757\n",
      "Validation loss decreased (0.058719 --> 0.057329).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0585060\n",
      "\tspeed: 0.0536s/iter; left time: 1129.2794s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583370\n",
      "\tspeed: 0.0292s/iter; left time: 613.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0579862 Vali Loss: 0.0566960 Test Loss: 0.0601647\n",
      "Validation loss decreased (0.057329 --> 0.056696).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0565500\n",
      "\tspeed: 0.0638s/iter; left time: 1330.5363s\n",
      "\titers: 200, epoch: 7 | loss: 0.0527307\n",
      "\tspeed: 0.0369s/iter; left time: 765.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 223 | Train Loss: 0.0570756 Vali Loss: 0.0560964 Test Loss: 0.0595184\n",
      "Validation loss decreased (0.056696 --> 0.056096).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574529\n",
      "\tspeed: 0.0562s/iter; left time: 1160.5621s\n",
      "\titers: 200, epoch: 8 | loss: 0.0541416\n",
      "\tspeed: 0.0258s/iter; left time: 529.0118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0564438 Vali Loss: 0.0558872 Test Loss: 0.0593208\n",
      "Validation loss decreased (0.056096 --> 0.055887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0540634\n",
      "\tspeed: 0.0532s/iter; left time: 1086.0817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0553400\n",
      "\tspeed: 0.0296s/iter; left time: 600.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0558557 Vali Loss: 0.0559345 Test Loss: 0.0593015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577445\n",
      "\tspeed: 0.0556s/iter; left time: 1122.8714s\n",
      "\titers: 200, epoch: 10 | loss: 0.0541575\n",
      "\tspeed: 0.0272s/iter; left time: 545.7482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0555122 Vali Loss: 0.0555371 Test Loss: 0.0589136\n",
      "Validation loss decreased (0.055887 --> 0.055537).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0530706\n",
      "\tspeed: 0.0511s/iter; left time: 1019.7527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0535309\n",
      "\tspeed: 0.0256s/iter; left time: 508.8373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0550372 Vali Loss: 0.0554847 Test Loss: 0.0588560\n",
      "Validation loss decreased (0.055537 --> 0.055485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0530517\n",
      "\tspeed: 0.0514s/iter; left time: 1015.1513s\n",
      "\titers: 200, epoch: 12 | loss: 0.0572278\n",
      "\tspeed: 0.0256s/iter; left time: 502.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0548496 Vali Loss: 0.0554011 Test Loss: 0.0586271\n",
      "Validation loss decreased (0.055485 --> 0.055401).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0518475\n",
      "\tspeed: 0.0646s/iter; left time: 1261.9174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0540882\n",
      "\tspeed: 0.0378s/iter; left time: 734.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0545897 Vali Loss: 0.0554994 Test Loss: 0.0587791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0553361\n",
      "\tspeed: 0.0644s/iter; left time: 1242.9173s\n",
      "\titers: 200, epoch: 14 | loss: 0.0549809\n",
      "\tspeed: 0.0345s/iter; left time: 662.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 223 | Train Loss: 0.0543167 Vali Loss: 0.0554123 Test Loss: 0.0587761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0543077\n",
      "\tspeed: 0.0537s/iter; left time: 1024.6590s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540728\n",
      "\tspeed: 0.0255s/iter; left time: 483.8213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0541432 Vali Loss: 0.0550529 Test Loss: 0.0583971\n",
      "Validation loss decreased (0.055401 --> 0.055053).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545898\n",
      "\tspeed: 0.0509s/iter; left time: 959.8674s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538074\n",
      "\tspeed: 0.0256s/iter; left time: 480.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0539847 Vali Loss: 0.0550526 Test Loss: 0.0583285\n",
      "Validation loss decreased (0.055053 --> 0.055053).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0565738\n",
      "\tspeed: 0.0537s/iter; left time: 1001.1918s\n",
      "\titers: 200, epoch: 17 | loss: 0.0526358\n",
      "\tspeed: 0.0263s/iter; left time: 487.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0537607 Vali Loss: 0.0551651 Test Loss: 0.0584169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0522349\n",
      "\tspeed: 0.0637s/iter; left time: 1172.3450s\n",
      "\titers: 200, epoch: 18 | loss: 0.0548351\n",
      "\tspeed: 0.0386s/iter; left time: 707.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 223 | Train Loss: 0.0536412 Vali Loss: 0.0551288 Test Loss: 0.0583160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0533593\n",
      "\tspeed: 0.0563s/iter; left time: 1023.5250s\n",
      "\titers: 200, epoch: 19 | loss: 0.0548181\n",
      "\tspeed: 0.0256s/iter; left time: 462.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0535270 Vali Loss: 0.0549872 Test Loss: 0.0581665\n",
      "Validation loss decreased (0.055053 --> 0.054987).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0492180\n",
      "\tspeed: 0.0524s/iter; left time: 940.6268s\n",
      "\titers: 200, epoch: 20 | loss: 0.0545013\n",
      "\tspeed: 0.0299s/iter; left time: 534.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0533950 Vali Loss: 0.0549432 Test Loss: 0.0581925\n",
      "Validation loss decreased (0.054987 --> 0.054943).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0558018\n",
      "\tspeed: 0.0557s/iter; left time: 988.3324s\n",
      "\titers: 200, epoch: 21 | loss: 0.0508116\n",
      "\tspeed: 0.0294s/iter; left time: 518.9661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0533227 Vali Loss: 0.0548927 Test Loss: 0.0582207\n",
      "Validation loss decreased (0.054943 --> 0.054893).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0501408\n",
      "\tspeed: 0.0545s/iter; left time: 954.9061s\n",
      "\titers: 200, epoch: 22 | loss: 0.0509246\n",
      "\tspeed: 0.0264s/iter; left time: 459.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0532347 Vali Loss: 0.0549273 Test Loss: 0.0581536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0518457\n",
      "\tspeed: 0.0508s/iter; left time: 877.9070s\n",
      "\titers: 200, epoch: 23 | loss: 0.0551974\n",
      "\tspeed: 0.0257s/iter; left time: 441.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0531476 Vali Loss: 0.0549596 Test Loss: 0.0582653\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0517124\n",
      "\tspeed: 0.0539s/iter; left time: 920.6487s\n",
      "\titers: 200, epoch: 24 | loss: 0.0546799\n",
      "\tspeed: 0.0318s/iter; left time: 539.6778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 223 | Train Loss: 0.0531133 Vali Loss: 0.0549095 Test Loss: 0.0581461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0567966\n",
      "\tspeed: 0.0520s/iter; left time: 875.5268s\n",
      "\titers: 200, epoch: 25 | loss: 0.0564677\n",
      "\tspeed: 0.0265s/iter; left time: 443.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0530779 Vali Loss: 0.0551300 Test Loss: 0.0583300\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0489806\n",
      "\tspeed: 0.0530s/iter; left time: 881.2318s\n",
      "\titers: 200, epoch: 26 | loss: 0.0562983\n",
      "\tspeed: 0.0260s/iter; left time: 430.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0530137 Vali Loss: 0.0548149 Test Loss: 0.0580493\n",
      "Validation loss decreased (0.054893 --> 0.054815).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0494470\n",
      "\tspeed: 0.0637s/iter; left time: 1045.5631s\n",
      "\titers: 200, epoch: 27 | loss: 0.0559439\n",
      "\tspeed: 0.0365s/iter; left time: 594.6476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0529471 Vali Loss: 0.0547978 Test Loss: 0.0580087\n",
      "Validation loss decreased (0.054815 --> 0.054798).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0534833\n",
      "\tspeed: 0.0658s/iter; left time: 1064.1587s\n",
      "\titers: 200, epoch: 28 | loss: 0.0497755\n",
      "\tspeed: 0.0271s/iter; left time: 436.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 223 | Train Loss: 0.0528988 Vali Loss: 0.0547767 Test Loss: 0.0580791\n",
      "Validation loss decreased (0.054798 --> 0.054777).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0546162\n",
      "\tspeed: 0.0634s/iter; left time: 1011.9516s\n",
      "\titers: 200, epoch: 29 | loss: 0.0482364\n",
      "\tspeed: 0.0316s/iter; left time: 501.6822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0527976 Vali Loss: 0.0548390 Test Loss: 0.0580498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0514056\n",
      "\tspeed: 0.0542s/iter; left time: 852.7247s\n",
      "\titers: 200, epoch: 30 | loss: 0.0515832\n",
      "\tspeed: 0.0256s/iter; left time: 399.5038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.0528217 Vali Loss: 0.0547835 Test Loss: 0.0580094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0502742\n",
      "\tspeed: 0.0530s/iter; left time: 822.3993s\n",
      "\titers: 200, epoch: 31 | loss: 0.0523818\n",
      "\tspeed: 0.0275s/iter; left time: 424.2228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0527453 Vali Loss: 0.0547558 Test Loss: 0.0580604\n",
      "Validation loss decreased (0.054777 --> 0.054756).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0551462\n",
      "\tspeed: 0.0527s/iter; left time: 804.9609s\n",
      "\titers: 200, epoch: 32 | loss: 0.0529665\n",
      "\tspeed: 0.0270s/iter; left time: 410.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0527182 Vali Loss: 0.0547712 Test Loss: 0.0580111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0499785\n",
      "\tspeed: 0.0536s/iter; left time: 806.9022s\n",
      "\titers: 200, epoch: 33 | loss: 0.0543638\n",
      "\tspeed: 0.0284s/iter; left time: 425.2872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0527430 Vali Loss: 0.0547353 Test Loss: 0.0580659\n",
      "Validation loss decreased (0.054756 --> 0.054735).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0520477\n",
      "\tspeed: 0.0642s/iter; left time: 952.8710s\n",
      "\titers: 200, epoch: 34 | loss: 0.0533128\n",
      "\tspeed: 0.0351s/iter; left time: 516.8807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 223 | Train Loss: 0.0526974 Vali Loss: 0.0548603 Test Loss: 0.0580869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0546946\n",
      "\tspeed: 0.0610s/iter; left time: 891.1993s\n",
      "\titers: 200, epoch: 35 | loss: 0.0555447\n",
      "\tspeed: 0.0305s/iter; left time: 443.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 223 | Train Loss: 0.0527207 Vali Loss: 0.0547957 Test Loss: 0.0580329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0546721\n",
      "\tspeed: 0.0530s/iter; left time: 762.5423s\n",
      "\titers: 200, epoch: 36 | loss: 0.0519910\n",
      "\tspeed: 0.0269s/iter; left time: 383.8601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526500 Vali Loss: 0.0546964 Test Loss: 0.0579776\n",
      "Validation loss decreased (0.054735 --> 0.054696).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0523512\n",
      "\tspeed: 0.0522s/iter; left time: 739.2459s\n",
      "\titers: 200, epoch: 37 | loss: 0.0546747\n",
      "\tspeed: 0.0308s/iter; left time: 433.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.0526666 Vali Loss: 0.0547396 Test Loss: 0.0580337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0534836\n",
      "\tspeed: 0.0571s/iter; left time: 796.8454s\n",
      "\titers: 200, epoch: 38 | loss: 0.0539312\n",
      "\tspeed: 0.0298s/iter; left time: 413.3393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 223 | Train Loss: 0.0526087 Vali Loss: 0.0547107 Test Loss: 0.0579508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0531438\n",
      "\tspeed: 0.0550s/iter; left time: 755.1517s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516568\n",
      "\tspeed: 0.0260s/iter; left time: 353.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0525765 Vali Loss: 0.0547066 Test Loss: 0.0579552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0501385\n",
      "\tspeed: 0.0542s/iter; left time: 731.8527s\n",
      "\titers: 200, epoch: 40 | loss: 0.0550164\n",
      "\tspeed: 0.0300s/iter; left time: 402.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 223 | Train Loss: 0.0526171 Vali Loss: 0.0547018 Test Loss: 0.0579779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0544265\n",
      "\tspeed: 0.0521s/iter; left time: 691.3120s\n",
      "\titers: 200, epoch: 41 | loss: 0.0530413\n",
      "\tspeed: 0.0255s/iter; left time: 336.3198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0526425 Vali Loss: 0.0548637 Test Loss: 0.0580630\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0581276\n",
      "\tspeed: 0.0528s/iter; left time: 689.0106s\n",
      "\titers: 200, epoch: 42 | loss: 0.0542533\n",
      "\tspeed: 0.0294s/iter; left time: 380.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 223 | Train Loss: 0.0526240 Vali Loss: 0.0545914 Test Loss: 0.0579419\n",
      "Validation loss decreased (0.054696 --> 0.054591).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0501260\n",
      "\tspeed: 0.0592s/iter; left time: 759.9117s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514073\n",
      "\tspeed: 0.0316s/iter; left time: 402.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 223 | Train Loss: 0.0525766 Vali Loss: 0.0546661 Test Loss: 0.0579404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0511218\n",
      "\tspeed: 0.0556s/iter; left time: 700.8090s\n",
      "\titers: 200, epoch: 44 | loss: 0.0513954\n",
      "\tspeed: 0.0340s/iter; left time: 424.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.0525506 Vali Loss: 0.0547464 Test Loss: 0.0579979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0550311\n",
      "\tspeed: 0.0516s/iter; left time: 638.8772s\n",
      "\titers: 200, epoch: 45 | loss: 0.0524600\n",
      "\tspeed: 0.0255s/iter; left time: 313.8474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0525694 Vali Loss: 0.0546932 Test Loss: 0.0579794\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0520596\n",
      "\tspeed: 0.0508s/iter; left time: 618.6137s\n",
      "\titers: 200, epoch: 46 | loss: 0.0550357\n",
      "\tspeed: 0.0256s/iter; left time: 308.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0525442 Vali Loss: 0.0547253 Test Loss: 0.0580185\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0501307\n",
      "\tspeed: 0.0580s/iter; left time: 692.9136s\n",
      "\titers: 200, epoch: 47 | loss: 0.0500038\n",
      "\tspeed: 0.0303s/iter; left time: 359.0026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.0525085 Vali Loss: 0.0546025 Test Loss: 0.0579274\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547399\n",
      "\tspeed: 0.0550s/iter; left time: 644.4166s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521640\n",
      "\tspeed: 0.0296s/iter; left time: 344.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 223 | Train Loss: 0.0525072 Vali Loss: 0.0547481 Test Loss: 0.0580055\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0533656\n",
      "\tspeed: 0.0516s/iter; left time: 593.1480s\n",
      "\titers: 200, epoch: 49 | loss: 0.0526697\n",
      "\tspeed: 0.0301s/iter; left time: 343.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0525101 Vali Loss: 0.0547132 Test Loss: 0.0579663\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0524444\n",
      "\tspeed: 0.0614s/iter; left time: 692.7391s\n",
      "\titers: 200, epoch: 50 | loss: 0.0541497\n",
      "\tspeed: 0.0358s/iter; left time: 399.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 223 | Train Loss: 0.0525236 Vali Loss: 0.0546434 Test Loss: 0.0579386\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0464345\n",
      "\tspeed: 0.0606s/iter; left time: 669.6749s\n",
      "\titers: 200, epoch: 51 | loss: 0.0519780\n",
      "\tspeed: 0.0349s/iter; left time: 382.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0525358 Vali Loss: 0.0545811 Test Loss: 0.0579175\n",
      "Validation loss decreased (0.054591 --> 0.054581).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0507083\n",
      "\tspeed: 0.0715s/iter; left time: 774.2597s\n",
      "\titers: 200, epoch: 52 | loss: 0.0507224\n",
      "\tspeed: 0.0345s/iter; left time: 369.9197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 223 | Train Loss: 0.0525005 Vali Loss: 0.0546294 Test Loss: 0.0579562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0555608\n",
      "\tspeed: 0.0665s/iter; left time: 704.7322s\n",
      "\titers: 200, epoch: 53 | loss: 0.0539058\n",
      "\tspeed: 0.0388s/iter; left time: 407.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 223 | Train Loss: 0.0525331 Vali Loss: 0.0547650 Test Loss: 0.0579651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0555326\n",
      "\tspeed: 0.0580s/iter; left time: 601.8408s\n",
      "\titers: 200, epoch: 54 | loss: 0.0529416\n",
      "\tspeed: 0.0344s/iter; left time: 354.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 223 | Train Loss: 0.0525299 Vali Loss: 0.0547366 Test Loss: 0.0579888\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0554902\n",
      "\tspeed: 0.0682s/iter; left time: 692.3936s\n",
      "\titers: 200, epoch: 55 | loss: 0.0497450\n",
      "\tspeed: 0.0333s/iter; left time: 335.1448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0525846 Vali Loss: 0.0546924 Test Loss: 0.0579730\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0506876\n",
      "\tspeed: 0.0647s/iter; left time: 642.4373s\n",
      "\titers: 200, epoch: 56 | loss: 0.0533410\n",
      "\tspeed: 0.0409s/iter; left time: 402.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0524580 Vali Loss: 0.0548295 Test Loss: 0.0580311\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0510804\n",
      "\tspeed: 0.0655s/iter; left time: 636.0833s\n",
      "\titers: 200, epoch: 57 | loss: 0.0535187\n",
      "\tspeed: 0.0344s/iter; left time: 330.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 223 | Train Loss: 0.0525392 Vali Loss: 0.0547690 Test Loss: 0.0580002\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0540871\n",
      "\tspeed: 0.0630s/iter; left time: 597.8020s\n",
      "\titers: 200, epoch: 58 | loss: 0.0543129\n",
      "\tspeed: 0.0373s/iter; left time: 350.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 223 | Train Loss: 0.0525163 Vali Loss: 0.0546344 Test Loss: 0.0579469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0516760\n",
      "\tspeed: 0.0549s/iter; left time: 508.9583s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519528\n",
      "\tspeed: 0.0255s/iter; left time: 234.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0525056 Vali Loss: 0.0545595 Test Loss: 0.0579188\n",
      "Validation loss decreased (0.054581 --> 0.054560).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0523415\n",
      "\tspeed: 0.0568s/iter; left time: 513.3200s\n",
      "\titers: 200, epoch: 60 | loss: 0.0520616\n",
      "\tspeed: 0.0284s/iter; left time: 253.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.0524824 Vali Loss: 0.0547237 Test Loss: 0.0579836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0531614\n",
      "\tspeed: 0.0617s/iter; left time: 543.8582s\n",
      "\titers: 200, epoch: 61 | loss: 0.0547406\n",
      "\tspeed: 0.0368s/iter; left time: 320.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 223 | Train Loss: 0.0524624 Vali Loss: 0.0546745 Test Loss: 0.0579907\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0529115\n",
      "\tspeed: 0.0593s/iter; left time: 509.4711s\n",
      "\titers: 200, epoch: 62 | loss: 0.0531791\n",
      "\tspeed: 0.0306s/iter; left time: 260.0371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.0524776 Vali Loss: 0.0546848 Test Loss: 0.0579330\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0515253\n",
      "\tspeed: 0.0531s/iter; left time: 444.7232s\n",
      "\titers: 200, epoch: 63 | loss: 0.0534103\n",
      "\tspeed: 0.0317s/iter; left time: 262.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 223 | Train Loss: 0.0525408 Vali Loss: 0.0545999 Test Loss: 0.0579410\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0565064\n",
      "\tspeed: 0.0721s/iter; left time: 587.8824s\n",
      "\titers: 200, epoch: 64 | loss: 0.0506969\n",
      "\tspeed: 0.0326s/iter; left time: 262.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 223 | Train Loss: 0.0525418 Vali Loss: 0.0547950 Test Loss: 0.0580204\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0504207\n",
      "\tspeed: 0.0612s/iter; left time: 484.9500s\n",
      "\titers: 200, epoch: 65 | loss: 0.0530848\n",
      "\tspeed: 0.0340s/iter; left time: 266.4050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0524676 Vali Loss: 0.0547150 Test Loss: 0.0580030\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0514719\n",
      "\tspeed: 0.0629s/iter; left time: 484.5306s\n",
      "\titers: 200, epoch: 66 | loss: 0.0492261\n",
      "\tspeed: 0.0337s/iter; left time: 256.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0524502 Vali Loss: 0.0545987 Test Loss: 0.0579090\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0516307\n",
      "\tspeed: 0.0663s/iter; left time: 496.3855s\n",
      "\titers: 200, epoch: 67 | loss: 0.0514829\n",
      "\tspeed: 0.0381s/iter; left time: 281.5548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0524721 Vali Loss: 0.0548259 Test Loss: 0.0580225\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0499627\n",
      "\tspeed: 0.0630s/iter; left time: 457.0629s\n",
      "\titers: 200, epoch: 68 | loss: 0.0548370\n",
      "\tspeed: 0.0350s/iter; left time: 250.4056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0525168 Vali Loss: 0.0547533 Test Loss: 0.0580104\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0559433\n",
      "\tspeed: 0.0666s/iter; left time: 468.9681s\n",
      "\titers: 200, epoch: 69 | loss: 0.0541268\n",
      "\tspeed: 0.0355s/iter; left time: 246.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 223 | Train Loss: 0.0525076 Vali Loss: 0.0547383 Test Loss: 0.0579478\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01025902759283781, rmse:0.1012868583202362, mae:0.05791882798075676, rse:0.3827131688594818\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1717055\n",
      "\tspeed: 0.0431s/iter; left time: 956.3206s\n",
      "\titers: 200, epoch: 1 | loss: 0.1485900\n",
      "\tspeed: 0.0386s/iter; left time: 852.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.1694800 Vali Loss: 0.1432156 Test Loss: 0.1494051\n",
      "Validation loss decreased (inf --> 0.143216).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0800900\n",
      "\tspeed: 0.0607s/iter; left time: 1334.1382s\n",
      "\titers: 200, epoch: 2 | loss: 0.0652701\n",
      "\tspeed: 0.0344s/iter; left time: 753.6618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 223 | Train Loss: 0.0887126 Vali Loss: 0.0645617 Test Loss: 0.0677362\n",
      "Validation loss decreased (0.143216 --> 0.064562).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0604678\n",
      "\tspeed: 0.0601s/iter; left time: 1307.8057s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644708\n",
      "\tspeed: 0.0337s/iter; left time: 729.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 223 | Train Loss: 0.0656220 Vali Loss: 0.0604746 Test Loss: 0.0641593\n",
      "Validation loss decreased (0.064562 --> 0.060475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0632558\n",
      "\tspeed: 0.0598s/iter; left time: 1287.1360s\n",
      "\titers: 200, epoch: 4 | loss: 0.0605759\n",
      "\tspeed: 0.0288s/iter; left time: 617.2228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 223 | Train Loss: 0.0619164 Vali Loss: 0.0586349 Test Loss: 0.0620526\n",
      "Validation loss decreased (0.060475 --> 0.058635).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597222\n",
      "\tspeed: 0.0604s/iter; left time: 1287.5646s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541384\n",
      "\tspeed: 0.0296s/iter; left time: 628.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 223 | Train Loss: 0.0597221 Vali Loss: 0.0574436 Test Loss: 0.0611999\n",
      "Validation loss decreased (0.058635 --> 0.057444).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0570956\n",
      "\tspeed: 0.0544s/iter; left time: 1147.7576s\n",
      "\titers: 200, epoch: 6 | loss: 0.0554852\n",
      "\tspeed: 0.0290s/iter; left time: 608.1334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.0581979 Vali Loss: 0.0565788 Test Loss: 0.0601522\n",
      "Validation loss decreased (0.057444 --> 0.056579).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556648\n",
      "\tspeed: 0.0638s/iter; left time: 1330.0545s\n",
      "\titers: 200, epoch: 7 | loss: 0.0562354\n",
      "\tspeed: 0.0361s/iter; left time: 750.1313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 223 | Train Loss: 0.0571618 Vali Loss: 0.0564649 Test Loss: 0.0598806\n",
      "Validation loss decreased (0.056579 --> 0.056465).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552746\n",
      "\tspeed: 0.0683s/iter; left time: 1409.9957s\n",
      "\titers: 200, epoch: 8 | loss: 0.0526850\n",
      "\tspeed: 0.0375s/iter; left time: 769.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 223 | Train Loss: 0.0565136 Vali Loss: 0.0560664 Test Loss: 0.0594139\n",
      "Validation loss decreased (0.056465 --> 0.056066).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0548525\n",
      "\tspeed: 0.0580s/iter; left time: 1183.8783s\n",
      "\titers: 200, epoch: 9 | loss: 0.0606097\n",
      "\tspeed: 0.0356s/iter; left time: 722.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0559144 Vali Loss: 0.0557678 Test Loss: 0.0592723\n",
      "Validation loss decreased (0.056066 --> 0.055768).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0538730\n",
      "\tspeed: 0.0657s/iter; left time: 1326.9631s\n",
      "\titers: 200, epoch: 10 | loss: 0.0538046\n",
      "\tspeed: 0.0379s/iter; left time: 761.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 223 | Train Loss: 0.0554533 Vali Loss: 0.0556055 Test Loss: 0.0589054\n",
      "Validation loss decreased (0.055768 --> 0.055606).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0543101\n",
      "\tspeed: 0.0690s/iter; left time: 1378.7496s\n",
      "\titers: 200, epoch: 11 | loss: 0.0538343\n",
      "\tspeed: 0.0381s/iter; left time: 756.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0551544 Vali Loss: 0.0553383 Test Loss: 0.0586907\n",
      "Validation loss decreased (0.055606 --> 0.055338).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0570344\n",
      "\tspeed: 0.0696s/iter; left time: 1373.9194s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549232\n",
      "\tspeed: 0.0368s/iter; left time: 722.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 223 | Train Loss: 0.0548662 Vali Loss: 0.0552696 Test Loss: 0.0586818\n",
      "Validation loss decreased (0.055338 --> 0.055270).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0568361\n",
      "\tspeed: 0.0618s/iter; left time: 1206.6511s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570971\n",
      "\tspeed: 0.0344s/iter; left time: 668.2568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0545810 Vali Loss: 0.0552236 Test Loss: 0.0584599\n",
      "Validation loss decreased (0.055270 --> 0.055224).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0553691\n",
      "\tspeed: 0.0693s/iter; left time: 1336.8370s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576549\n",
      "\tspeed: 0.0346s/iter; left time: 664.3746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 223 | Train Loss: 0.0543912 Vali Loss: 0.0553458 Test Loss: 0.0586480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0476412\n",
      "\tspeed: 0.0602s/iter; left time: 1149.3128s\n",
      "\titers: 200, epoch: 15 | loss: 0.0502024\n",
      "\tspeed: 0.0327s/iter; left time: 620.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 223 | Train Loss: 0.0542477 Vali Loss: 0.0551760 Test Loss: 0.0584437\n",
      "Validation loss decreased (0.055224 --> 0.055176).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0561399\n",
      "\tspeed: 0.0612s/iter; left time: 1153.7490s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552849\n",
      "\tspeed: 0.0377s/iter; left time: 707.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0540715 Vali Loss: 0.0551691 Test Loss: 0.0584590\n",
      "Validation loss decreased (0.055176 --> 0.055169).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0519873\n",
      "\tspeed: 0.0742s/iter; left time: 1381.8849s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539741\n",
      "\tspeed: 0.0436s/iter; left time: 808.7041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0538644 Vali Loss: 0.0551667 Test Loss: 0.0584794\n",
      "Validation loss decreased (0.055169 --> 0.055167).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0516626\n",
      "\tspeed: 0.0635s/iter; left time: 1169.8805s\n",
      "\titers: 200, epoch: 18 | loss: 0.0526086\n",
      "\tspeed: 0.0323s/iter; left time: 590.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 223 | Train Loss: 0.0537904 Vali Loss: 0.0549835 Test Loss: 0.0583495\n",
      "Validation loss decreased (0.055167 --> 0.054983).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0511259\n",
      "\tspeed: 0.0704s/iter; left time: 1281.0805s\n",
      "\titers: 200, epoch: 19 | loss: 0.0562319\n",
      "\tspeed: 0.0367s/iter; left time: 664.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0536661 Vali Loss: 0.0549177 Test Loss: 0.0581896\n",
      "Validation loss decreased (0.054983 --> 0.054918).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545675\n",
      "\tspeed: 0.0728s/iter; left time: 1308.4282s\n",
      "\titers: 200, epoch: 20 | loss: 0.0539949\n",
      "\tspeed: 0.0430s/iter; left time: 767.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 223 | Train Loss: 0.0535756 Vali Loss: 0.0548477 Test Loss: 0.0581735\n",
      "Validation loss decreased (0.054918 --> 0.054848).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0537066\n",
      "\tspeed: 0.0579s/iter; left time: 1027.7424s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538169\n",
      "\tspeed: 0.0347s/iter; left time: 612.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0534312 Vali Loss: 0.0548435 Test Loss: 0.0582042\n",
      "Validation loss decreased (0.054848 --> 0.054843).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0522837\n",
      "\tspeed: 0.0581s/iter; left time: 1018.3296s\n",
      "\titers: 200, epoch: 22 | loss: 0.0557033\n",
      "\tspeed: 0.0280s/iter; left time: 487.5051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 223 | Train Loss: 0.0532931 Vali Loss: 0.0547245 Test Loss: 0.0581448\n",
      "Validation loss decreased (0.054843 --> 0.054725).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0576742\n",
      "\tspeed: 0.0543s/iter; left time: 938.8636s\n",
      "\titers: 200, epoch: 23 | loss: 0.0500989\n",
      "\tspeed: 0.0256s/iter; left time: 439.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0532740 Vali Loss: 0.0547992 Test Loss: 0.0582190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522139\n",
      "\tspeed: 0.0650s/iter; left time: 1110.2742s\n",
      "\titers: 200, epoch: 24 | loss: 0.0536052\n",
      "\tspeed: 0.0343s/iter; left time: 581.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 223 | Train Loss: 0.0532633 Vali Loss: 0.0549433 Test Loss: 0.0582131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0579043\n",
      "\tspeed: 0.0567s/iter; left time: 954.7607s\n",
      "\titers: 200, epoch: 25 | loss: 0.0497379\n",
      "\tspeed: 0.0255s/iter; left time: 427.2193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0531428 Vali Loss: 0.0548065 Test Loss: 0.0581853\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0517811\n",
      "\tspeed: 0.0653s/iter; left time: 1085.5913s\n",
      "\titers: 200, epoch: 26 | loss: 0.0504412\n",
      "\tspeed: 0.0372s/iter; left time: 615.2879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 223 | Train Loss: 0.0530603 Vali Loss: 0.0547106 Test Loss: 0.0581130\n",
      "Validation loss decreased (0.054725 --> 0.054711).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0512030\n",
      "\tspeed: 0.0722s/iter; left time: 1183.5509s\n",
      "\titers: 200, epoch: 27 | loss: 0.0524151\n",
      "\tspeed: 0.0408s/iter; left time: 665.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0530323 Vali Loss: 0.0548623 Test Loss: 0.0581327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0486823\n",
      "\tspeed: 0.0607s/iter; left time: 982.7780s\n",
      "\titers: 200, epoch: 28 | loss: 0.0545269\n",
      "\tspeed: 0.0369s/iter; left time: 593.3598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0529944 Vali Loss: 0.0548541 Test Loss: 0.0580871\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0527006\n",
      "\tspeed: 0.0666s/iter; left time: 1063.3918s\n",
      "\titers: 200, epoch: 29 | loss: 0.0519911\n",
      "\tspeed: 0.0378s/iter; left time: 599.7918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0529725 Vali Loss: 0.0547857 Test Loss: 0.0580574\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0487736\n",
      "\tspeed: 0.0656s/iter; left time: 1031.6147s\n",
      "\titers: 200, epoch: 30 | loss: 0.0496971\n",
      "\tspeed: 0.0351s/iter; left time: 548.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 223 | Train Loss: 0.0529192 Vali Loss: 0.0547220 Test Loss: 0.0580357\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0498929\n",
      "\tspeed: 0.0660s/iter; left time: 1024.4246s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548316\n",
      "\tspeed: 0.0406s/iter; left time: 625.2080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0529226 Vali Loss: 0.0546385 Test Loss: 0.0580350\n",
      "Validation loss decreased (0.054711 --> 0.054639).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0522808\n",
      "\tspeed: 0.0627s/iter; left time: 958.4684s\n",
      "\titers: 200, epoch: 32 | loss: 0.0524090\n",
      "\tspeed: 0.0348s/iter; left time: 528.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0528818 Vali Loss: 0.0547373 Test Loss: 0.0580063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0555934\n",
      "\tspeed: 0.0657s/iter; left time: 989.7719s\n",
      "\titers: 200, epoch: 33 | loss: 0.0524223\n",
      "\tspeed: 0.0379s/iter; left time: 567.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 223 | Train Loss: 0.0527969 Vali Loss: 0.0547712 Test Loss: 0.0580695\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0530666\n",
      "\tspeed: 0.0631s/iter; left time: 936.2650s\n",
      "\titers: 200, epoch: 34 | loss: 0.0534333\n",
      "\tspeed: 0.0406s/iter; left time: 598.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0528341 Vali Loss: 0.0545481 Test Loss: 0.0579661\n",
      "Validation loss decreased (0.054639 --> 0.054548).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0508608\n",
      "\tspeed: 0.0614s/iter; left time: 898.2306s\n",
      "\titers: 200, epoch: 35 | loss: 0.0533513\n",
      "\tspeed: 0.0317s/iter; left time: 460.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 223 | Train Loss: 0.0528034 Vali Loss: 0.0548026 Test Loss: 0.0580415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506763\n",
      "\tspeed: 0.0561s/iter; left time: 807.6322s\n",
      "\titers: 200, epoch: 36 | loss: 0.0545389\n",
      "\tspeed: 0.0307s/iter; left time: 439.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0527592 Vali Loss: 0.0546879 Test Loss: 0.0579734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532354\n",
      "\tspeed: 0.0569s/iter; left time: 805.8729s\n",
      "\titers: 200, epoch: 37 | loss: 0.0475882\n",
      "\tspeed: 0.0337s/iter; left time: 474.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 223 | Train Loss: 0.0527585 Vali Loss: 0.0545990 Test Loss: 0.0579895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0492560\n",
      "\tspeed: 0.0676s/iter; left time: 942.4496s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547863\n",
      "\tspeed: 0.0382s/iter; left time: 529.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 223 | Train Loss: 0.0527005 Vali Loss: 0.0547151 Test Loss: 0.0580167\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0529479\n",
      "\tspeed: 0.0677s/iter; left time: 929.0067s\n",
      "\titers: 200, epoch: 39 | loss: 0.0559588\n",
      "\tspeed: 0.0440s/iter; left time: 598.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0527668 Vali Loss: 0.0546051 Test Loss: 0.0579585\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0625522\n",
      "\tspeed: 0.0746s/iter; left time: 1007.0483s\n",
      "\titers: 200, epoch: 40 | loss: 0.0530506\n",
      "\tspeed: 0.0420s/iter; left time: 562.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 223 | Train Loss: 0.0527141 Vali Loss: 0.0548181 Test Loss: 0.0580725\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0520604\n",
      "\tspeed: 0.0759s/iter; left time: 1007.3834s\n",
      "\titers: 200, epoch: 41 | loss: 0.0528591\n",
      "\tspeed: 0.0445s/iter; left time: 586.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 223 | Train Loss: 0.0526937 Vali Loss: 0.0547285 Test Loss: 0.0580406\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0511337\n",
      "\tspeed: 0.0686s/iter; left time: 896.0461s\n",
      "\titers: 200, epoch: 42 | loss: 0.0517501\n",
      "\tspeed: 0.0399s/iter; left time: 517.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 223 | Train Loss: 0.0526962 Vali Loss: 0.0546777 Test Loss: 0.0580159\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0509948\n",
      "\tspeed: 0.0706s/iter; left time: 906.7343s\n",
      "\titers: 200, epoch: 43 | loss: 0.0474578\n",
      "\tspeed: 0.0418s/iter; left time: 532.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0526581 Vali Loss: 0.0546536 Test Loss: 0.0579394\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0559133\n",
      "\tspeed: 0.0644s/iter; left time: 811.8352s\n",
      "\titers: 200, epoch: 44 | loss: 0.0531031\n",
      "\tspeed: 0.0387s/iter; left time: 484.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0526986 Vali Loss: 0.0545789 Test Loss: 0.0579516\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010280443355441093, rmse:0.10139252245426178, mae:0.05796615406870842, rse:0.3831124007701874\n",
      "Intermediate time for IT and pred_len 24: 00h:17m:42.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1753753\n",
      "\tspeed: 0.0552s/iter; left time: 1219.8630s\n",
      "\titers: 200, epoch: 1 | loss: 0.1597836\n",
      "\tspeed: 0.0262s/iter; left time: 576.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.1770754 Vali Loss: 0.1512438 Test Loss: 0.1575890\n",
      "Validation loss decreased (inf --> 0.151244).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962438\n",
      "\tspeed: 0.0527s/iter; left time: 1153.1335s\n",
      "\titers: 200, epoch: 2 | loss: 0.0865009\n",
      "\tspeed: 0.0260s/iter; left time: 567.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.1048786 Vali Loss: 0.0829470 Test Loss: 0.0876575\n",
      "Validation loss decreased (0.151244 --> 0.082947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0846580\n",
      "\tspeed: 0.0578s/iter; left time: 1252.0634s\n",
      "\titers: 200, epoch: 3 | loss: 0.0808921\n",
      "\tspeed: 0.0270s/iter; left time: 581.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0848865 Vali Loss: 0.0799442 Test Loss: 0.0854384\n",
      "Validation loss decreased (0.082947 --> 0.079944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0817334\n",
      "\tspeed: 0.0632s/iter; left time: 1354.9045s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765876\n",
      "\tspeed: 0.0385s/iter; left time: 822.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 222 | Train Loss: 0.0815939 Vali Loss: 0.0778942 Test Loss: 0.0838772\n",
      "Validation loss decreased (0.079944 --> 0.077894).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798482\n",
      "\tspeed: 0.0639s/iter; left time: 1355.3491s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791696\n",
      "\tspeed: 0.0261s/iter; left time: 550.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0790166 Vali Loss: 0.0768422 Test Loss: 0.0823236\n",
      "Validation loss decreased (0.077894 --> 0.076842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791217\n",
      "\tspeed: 0.0658s/iter; left time: 1380.3927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776306\n",
      "\tspeed: 0.0340s/iter; left time: 709.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 222 | Train Loss: 0.0773240 Vali Loss: 0.0764858 Test Loss: 0.0820255\n",
      "Validation loss decreased (0.076842 --> 0.076486).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0786264\n",
      "\tspeed: 0.0666s/iter; left time: 1383.5579s\n",
      "\titers: 200, epoch: 7 | loss: 0.0730719\n",
      "\tspeed: 0.0388s/iter; left time: 801.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 222 | Train Loss: 0.0760060 Vali Loss: 0.0759890 Test Loss: 0.0811493\n",
      "Validation loss decreased (0.076486 --> 0.075989).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0750706\n",
      "\tspeed: 0.0669s/iter; left time: 1374.9882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747649\n",
      "\tspeed: 0.0364s/iter; left time: 743.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 222 | Train Loss: 0.0749959 Vali Loss: 0.0762141 Test Loss: 0.0816415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728345\n",
      "\tspeed: 0.0609s/iter; left time: 1237.8490s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740707\n",
      "\tspeed: 0.0306s/iter; left time: 619.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 222 | Train Loss: 0.0741578 Vali Loss: 0.0760008 Test Loss: 0.0813336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0722821\n",
      "\tspeed: 0.0549s/iter; left time: 1104.4161s\n",
      "\titers: 200, epoch: 10 | loss: 0.0710991\n",
      "\tspeed: 0.0263s/iter; left time: 525.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0734327 Vali Loss: 0.0765087 Test Loss: 0.0815486\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733486\n",
      "\tspeed: 0.0605s/iter; left time: 1203.3616s\n",
      "\titers: 200, epoch: 11 | loss: 0.0727560\n",
      "\tspeed: 0.0337s/iter; left time: 666.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 222 | Train Loss: 0.0727645 Vali Loss: 0.0767150 Test Loss: 0.0817584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775183\n",
      "\tspeed: 0.0667s/iter; left time: 1311.1221s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711688\n",
      "\tspeed: 0.0370s/iter; left time: 724.2062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 222 | Train Loss: 0.0720898 Vali Loss: 0.0767015 Test Loss: 0.0817770\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0713079\n",
      "\tspeed: 0.0603s/iter; left time: 1171.4591s\n",
      "\titers: 200, epoch: 13 | loss: 0.0734862\n",
      "\tspeed: 0.0274s/iter; left time: 529.6352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0715275 Vali Loss: 0.0772910 Test Loss: 0.0817738\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0678677\n",
      "\tspeed: 0.0542s/iter; left time: 1041.2099s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718624\n",
      "\tspeed: 0.0288s/iter; left time: 550.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0709772 Vali Loss: 0.0774553 Test Loss: 0.0817281\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0739586\n",
      "\tspeed: 0.0531s/iter; left time: 1008.9168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0703668\n",
      "\tspeed: 0.0309s/iter; left time: 582.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 222 | Train Loss: 0.0705512 Vali Loss: 0.0778418 Test Loss: 0.0820561\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0714521\n",
      "\tspeed: 0.0616s/iter; left time: 1156.3125s\n",
      "\titers: 200, epoch: 16 | loss: 0.0696031\n",
      "\tspeed: 0.0349s/iter; left time: 651.2369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 222 | Train Loss: 0.0701489 Vali Loss: 0.0778801 Test Loss: 0.0819220\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0682226\n",
      "\tspeed: 0.0653s/iter; left time: 1211.9413s\n",
      "\titers: 200, epoch: 17 | loss: 0.0747022\n",
      "\tspeed: 0.0344s/iter; left time: 634.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 222 | Train Loss: 0.0698124 Vali Loss: 0.0781645 Test Loss: 0.0820324\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017812455072999, rmse:0.1334633082151413, mae:0.08114922791719437, rse:0.5046391487121582\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1773208\n",
      "\tspeed: 0.0408s/iter; left time: 901.0041s\n",
      "\titers: 200, epoch: 1 | loss: 0.1558906\n",
      "\tspeed: 0.0373s/iter; left time: 819.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 222 | Train Loss: 0.1763523 Vali Loss: 0.1511220 Test Loss: 0.1572856\n",
      "Validation loss decreased (inf --> 0.151122).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0980407\n",
      "\tspeed: 0.0676s/iter; left time: 1479.5368s\n",
      "\titers: 200, epoch: 2 | loss: 0.0889126\n",
      "\tspeed: 0.0369s/iter; left time: 803.3869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 222 | Train Loss: 0.1039425 Vali Loss: 0.0829438 Test Loss: 0.0875296\n",
      "Validation loss decreased (0.151122 --> 0.082944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853809\n",
      "\tspeed: 0.0676s/iter; left time: 1463.1708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0784334\n",
      "\tspeed: 0.0372s/iter; left time: 802.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 222 | Train Loss: 0.0842616 Vali Loss: 0.0792221 Test Loss: 0.0844351\n",
      "Validation loss decreased (0.082944 --> 0.079222).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771087\n",
      "\tspeed: 0.0664s/iter; left time: 1422.9932s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817255\n",
      "\tspeed: 0.0377s/iter; left time: 804.4330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 222 | Train Loss: 0.0808215 Vali Loss: 0.0774983 Test Loss: 0.0830073\n",
      "Validation loss decreased (0.079222 --> 0.077498).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813322\n",
      "\tspeed: 0.0683s/iter; left time: 1449.5735s\n",
      "\titers: 200, epoch: 5 | loss: 0.0738560\n",
      "\tspeed: 0.0385s/iter; left time: 812.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 222 | Train Loss: 0.0787056 Vali Loss: 0.0766442 Test Loss: 0.0824317\n",
      "Validation loss decreased (0.077498 --> 0.076644).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778125\n",
      "\tspeed: 0.0668s/iter; left time: 1402.4094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0770522\n",
      "\tspeed: 0.0377s/iter; left time: 786.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 222 | Train Loss: 0.0770934 Vali Loss: 0.0764735 Test Loss: 0.0819570\n",
      "Validation loss decreased (0.076644 --> 0.076474).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746206\n",
      "\tspeed: 0.0687s/iter; left time: 1427.6029s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786247\n",
      "\tspeed: 0.0388s/iter; left time: 802.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 222 | Train Loss: 0.0758894 Vali Loss: 0.0763782 Test Loss: 0.0818798\n",
      "Validation loss decreased (0.076474 --> 0.076378).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0717489\n",
      "\tspeed: 0.0667s/iter; left time: 1370.0232s\n",
      "\titers: 200, epoch: 8 | loss: 0.0746726\n",
      "\tspeed: 0.0326s/iter; left time: 666.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 222 | Train Loss: 0.0749253 Vali Loss: 0.0762732 Test Loss: 0.0815395\n",
      "Validation loss decreased (0.076378 --> 0.076273).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0719149\n",
      "\tspeed: 0.0659s/iter; left time: 1338.5159s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758827\n",
      "\tspeed: 0.0388s/iter; left time: 785.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 222 | Train Loss: 0.0740149 Vali Loss: 0.0763326 Test Loss: 0.0814742\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727618\n",
      "\tspeed: 0.0660s/iter; left time: 1327.7759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730981\n",
      "\tspeed: 0.0309s/iter; left time: 618.0660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 222 | Train Loss: 0.0733248 Vali Loss: 0.0764891 Test Loss: 0.0814293\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0700514\n",
      "\tspeed: 0.0550s/iter; left time: 1093.4406s\n",
      "\titers: 200, epoch: 11 | loss: 0.0743186\n",
      "\tspeed: 0.0265s/iter; left time: 524.0954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0726949 Vali Loss: 0.0767204 Test Loss: 0.0814186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715227\n",
      "\tspeed: 0.0599s/iter; left time: 1177.7082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768301\n",
      "\tspeed: 0.0298s/iter; left time: 582.7862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 222 | Train Loss: 0.0721287 Vali Loss: 0.0770972 Test Loss: 0.0816332\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0735277\n",
      "\tspeed: 0.0751s/iter; left time: 1460.0068s\n",
      "\titers: 200, epoch: 13 | loss: 0.0721622\n",
      "\tspeed: 0.0424s/iter; left time: 820.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 222 | Train Loss: 0.0717176 Vali Loss: 0.0773682 Test Loss: 0.0816756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709131\n",
      "\tspeed: 0.0654s/iter; left time: 1257.5519s\n",
      "\titers: 200, epoch: 14 | loss: 0.0706134\n",
      "\tspeed: 0.0358s/iter; left time: 685.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 222 | Train Loss: 0.0711887 Vali Loss: 0.0775855 Test Loss: 0.0815979\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747834\n",
      "\tspeed: 0.0684s/iter; left time: 1298.4260s\n",
      "\titers: 200, epoch: 15 | loss: 0.0674817\n",
      "\tspeed: 0.0371s/iter; left time: 701.2418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 222 | Train Loss: 0.0707596 Vali Loss: 0.0779160 Test Loss: 0.0817807\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0725159\n",
      "\tspeed: 0.0676s/iter; left time: 1269.2882s\n",
      "\titers: 200, epoch: 16 | loss: 0.0686077\n",
      "\tspeed: 0.0374s/iter; left time: 698.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 222 | Train Loss: 0.0704023 Vali Loss: 0.0775829 Test Loss: 0.0815774\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669803\n",
      "\tspeed: 0.0678s/iter; left time: 1257.0186s\n",
      "\titers: 200, epoch: 17 | loss: 0.0680389\n",
      "\tspeed: 0.0358s/iter; left time: 659.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 222 | Train Loss: 0.0700630 Vali Loss: 0.0778274 Test Loss: 0.0815452\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0694918\n",
      "\tspeed: 0.0648s/iter; left time: 1186.6846s\n",
      "\titers: 200, epoch: 18 | loss: 0.0633145\n",
      "\tspeed: 0.0328s/iter; left time: 597.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 222 | Train Loss: 0.0697879 Vali Loss: 0.0779532 Test Loss: 0.0816427\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017936011776328087, rmse:0.1339253932237625, mae:0.08153951913118362, rse:0.5063863396644592\n",
      "Intermediate time for IT and pred_len 96: 00h:05m:53.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1746441\n",
      "\tspeed: 0.0533s/iter; left time: 1177.1499s\n",
      "\titers: 200, epoch: 1 | loss: 0.1623820\n",
      "\tspeed: 0.0262s/iter; left time: 575.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.1769348 Vali Loss: 0.1530277 Test Loss: 0.1581604\n",
      "Validation loss decreased (inf --> 0.153028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0977790\n",
      "\tspeed: 0.0539s/iter; left time: 1178.8052s\n",
      "\titers: 200, epoch: 2 | loss: 0.0896204\n",
      "\tspeed: 0.0279s/iter; left time: 608.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1070378 Vali Loss: 0.0876295 Test Loss: 0.0913102\n",
      "Validation loss decreased (0.153028 --> 0.087630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0893668\n",
      "\tspeed: 0.0556s/iter; left time: 1203.7149s\n",
      "\titers: 200, epoch: 3 | loss: 0.0882290\n",
      "\tspeed: 0.0287s/iter; left time: 619.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0885672 Vali Loss: 0.0844256 Test Loss: 0.0888829\n",
      "Validation loss decreased (0.087630 --> 0.084426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810407\n",
      "\tspeed: 0.0639s/iter; left time: 1370.0263s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823974\n",
      "\tspeed: 0.0300s/iter; left time: 640.1919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 222 | Train Loss: 0.0853079 Vali Loss: 0.0828841 Test Loss: 0.0873432\n",
      "Validation loss decreased (0.084426 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824699\n",
      "\tspeed: 0.0689s/iter; left time: 1461.4176s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824210\n",
      "\tspeed: 0.0345s/iter; left time: 727.7949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 222 | Train Loss: 0.0828610 Vali Loss: 0.0820326 Test Loss: 0.0865175\n",
      "Validation loss decreased (0.082884 --> 0.082033).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808103\n",
      "\tspeed: 0.0550s/iter; left time: 1154.4087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0819920\n",
      "\tspeed: 0.0287s/iter; left time: 599.7695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0810905 Vali Loss: 0.0823983 Test Loss: 0.0865624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774601\n",
      "\tspeed: 0.0569s/iter; left time: 1181.6753s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793055\n",
      "\tspeed: 0.0313s/iter; left time: 647.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 222 | Train Loss: 0.0796942 Vali Loss: 0.0813570 Test Loss: 0.0856480\n",
      "Validation loss decreased (0.082033 --> 0.081357).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0793816\n",
      "\tspeed: 0.0622s/iter; left time: 1278.0614s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795963\n",
      "\tspeed: 0.0306s/iter; left time: 624.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 222 | Train Loss: 0.0784713 Vali Loss: 0.0819944 Test Loss: 0.0859151\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774097\n",
      "\tspeed: 0.0549s/iter; left time: 1114.8781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0754623\n",
      "\tspeed: 0.0393s/iter; left time: 795.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 222 | Train Loss: 0.0775678 Vali Loss: 0.0823195 Test Loss: 0.0860887\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0756980\n",
      "\tspeed: 0.0705s/iter; left time: 1416.7076s\n",
      "\titers: 200, epoch: 10 | loss: 0.0815355\n",
      "\tspeed: 0.0417s/iter; left time: 834.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0766957 Vali Loss: 0.0826027 Test Loss: 0.0862339\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0758496\n",
      "\tspeed: 0.0608s/iter; left time: 1208.7602s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798348\n",
      "\tspeed: 0.0271s/iter; left time: 536.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0759971 Vali Loss: 0.0829828 Test Loss: 0.0865636\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0750832\n",
      "\tspeed: 0.0539s/iter; left time: 1058.9540s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751934\n",
      "\tspeed: 0.0291s/iter; left time: 568.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0753702 Vali Loss: 0.0832622 Test Loss: 0.0865737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749402\n",
      "\tspeed: 0.0580s/iter; left time: 1128.3133s\n",
      "\titers: 200, epoch: 13 | loss: 0.0745562\n",
      "\tspeed: 0.0283s/iter; left time: 547.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0748471 Vali Loss: 0.0831328 Test Loss: 0.0869340\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0753028\n",
      "\tspeed: 0.0555s/iter; left time: 1066.9826s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738721\n",
      "\tspeed: 0.0310s/iter; left time: 593.2240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 222 | Train Loss: 0.0743249 Vali Loss: 0.0833801 Test Loss: 0.0867358\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770546\n",
      "\tspeed: 0.0585s/iter; left time: 1111.3089s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728228\n",
      "\tspeed: 0.0286s/iter; left time: 540.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 222 | Train Loss: 0.0738036 Vali Loss: 0.0836629 Test Loss: 0.0870581\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0750396\n",
      "\tspeed: 0.0538s/iter; left time: 1010.3591s\n",
      "\titers: 200, epoch: 16 | loss: 0.0712230\n",
      "\tspeed: 0.0316s/iter; left time: 590.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 222 | Train Loss: 0.0734640 Vali Loss: 0.0842369 Test Loss: 0.0872311\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685776\n",
      "\tspeed: 0.0529s/iter; left time: 982.0416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0755227\n",
      "\tspeed: 0.0294s/iter; left time: 542.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0730282 Vali Loss: 0.0843911 Test Loss: 0.0870329\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019195787608623505, rmse:0.1385488659143448, mae:0.08564791828393936, rse:0.5243549942970276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1766461\n",
      "\tspeed: 0.0319s/iter; left time: 705.3870s\n",
      "\titers: 200, epoch: 1 | loss: 0.1639915\n",
      "\tspeed: 0.0360s/iter; left time: 791.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 222 | Train Loss: 0.1777718 Vali Loss: 0.1537944 Test Loss: 0.1588953\n",
      "Validation loss decreased (inf --> 0.153794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964910\n",
      "\tspeed: 0.0602s/iter; left time: 1316.7613s\n",
      "\titers: 200, epoch: 2 | loss: 0.0939204\n",
      "\tspeed: 0.0286s/iter; left time: 623.5538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 222 | Train Loss: 0.1079121 Vali Loss: 0.0876971 Test Loss: 0.0913077\n",
      "Validation loss decreased (0.153794 --> 0.087697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0879141\n",
      "\tspeed: 0.0587s/iter; left time: 1272.2767s\n",
      "\titers: 200, epoch: 3 | loss: 0.0861323\n",
      "\tspeed: 0.0306s/iter; left time: 659.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 222 | Train Loss: 0.0890562 Vali Loss: 0.0846068 Test Loss: 0.0890268\n",
      "Validation loss decreased (0.087697 --> 0.084607).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0823426\n",
      "\tspeed: 0.0590s/iter; left time: 1265.4409s\n",
      "\titers: 200, epoch: 4 | loss: 0.0840869\n",
      "\tspeed: 0.0280s/iter; left time: 597.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 222 | Train Loss: 0.0855099 Vali Loss: 0.0827726 Test Loss: 0.0874128\n",
      "Validation loss decreased (0.084607 --> 0.082773).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838870\n",
      "\tspeed: 0.0611s/iter; left time: 1296.8795s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818214\n",
      "\tspeed: 0.0301s/iter; left time: 636.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 222 | Train Loss: 0.0828737 Vali Loss: 0.0819302 Test Loss: 0.0866863\n",
      "Validation loss decreased (0.082773 --> 0.081930).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0820208\n",
      "\tspeed: 0.0551s/iter; left time: 1156.8390s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789016\n",
      "\tspeed: 0.0310s/iter; left time: 648.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 222 | Train Loss: 0.0810420 Vali Loss: 0.0822482 Test Loss: 0.0865955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789057\n",
      "\tspeed: 0.0574s/iter; left time: 1191.5550s\n",
      "\titers: 200, epoch: 7 | loss: 0.0778392\n",
      "\tspeed: 0.0283s/iter; left time: 584.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0795969 Vali Loss: 0.0821025 Test Loss: 0.0864432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776914\n",
      "\tspeed: 0.0553s/iter; left time: 1136.6068s\n",
      "\titers: 200, epoch: 8 | loss: 0.0754920\n",
      "\tspeed: 0.0307s/iter; left time: 626.8995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 222 | Train Loss: 0.0784678 Vali Loss: 0.0822381 Test Loss: 0.0867110\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804203\n",
      "\tspeed: 0.0578s/iter; left time: 1174.7282s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759517\n",
      "\tspeed: 0.0316s/iter; left time: 638.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 222 | Train Loss: 0.0774946 Vali Loss: 0.0823136 Test Loss: 0.0868279\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0773902\n",
      "\tspeed: 0.0548s/iter; left time: 1101.3313s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741224\n",
      "\tspeed: 0.0303s/iter; left time: 606.9917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0767099 Vali Loss: 0.0826392 Test Loss: 0.0867382\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0716539\n",
      "\tspeed: 0.0605s/iter; left time: 1203.2579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777369\n",
      "\tspeed: 0.0298s/iter; left time: 588.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 222 | Train Loss: 0.0759476 Vali Loss: 0.0827535 Test Loss: 0.0876155\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0746529\n",
      "\tspeed: 0.0578s/iter; left time: 1135.3744s\n",
      "\titers: 200, epoch: 12 | loss: 0.0734295\n",
      "\tspeed: 0.0276s/iter; left time: 540.1038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0752825 Vali Loss: 0.0832321 Test Loss: 0.0872469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0741085\n",
      "\tspeed: 0.0575s/iter; left time: 1118.4058s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751979\n",
      "\tspeed: 0.0277s/iter; left time: 535.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0746078 Vali Loss: 0.0832993 Test Loss: 0.0874019\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0728345\n",
      "\tspeed: 0.0548s/iter; left time: 1052.0480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0742365\n",
      "\tspeed: 0.0306s/iter; left time: 584.9025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0740953 Vali Loss: 0.0835588 Test Loss: 0.0878907\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738477\n",
      "\tspeed: 0.0566s/iter; left time: 1075.7745s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711205\n",
      "\tspeed: 0.0295s/iter; left time: 558.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 222 | Train Loss: 0.0735669 Vali Loss: 0.0837083 Test Loss: 0.0879271\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01931203529238701, rmse:0.13896775245666504, mae:0.08668635040521622, rse:0.5259403586387634\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:56.11s\n",
      "Intermediate time for IT: 00h:28m:32.26s\n",
      "Total time: 02h:11m:55.49s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.0656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.2081</td>\n",
       "      <td>0.1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.0596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0215  0.1467  0.0906\n",
       "        96              0.0390  0.1973  0.1300\n",
       "        168             0.0417  0.2040  0.1369\n",
       "ES      24              0.0109  0.1043  0.0656\n",
       "        96              0.0210  0.1447  0.0960\n",
       "        168             0.0249  0.1574  0.1054\n",
       "FR      24              0.0105  0.1025  0.0580\n",
       "        96              0.0200  0.1413  0.0828\n",
       "        168             0.0222  0.1489  0.0881\n",
       "GB      24              0.0266  0.1631  0.1042\n",
       "        96              0.0433  0.2081  0.1427\n",
       "        168             0.0454  0.2129  0.1486\n",
       "IT      24              0.0105  0.1023  0.0596\n",
       "        96              0.0185  0.1359  0.0829\n",
       "        168             0.0199  0.1411  0.0876"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TS Decomposition + No RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3076945\n",
      "\tspeed: 0.0665s/iter; left time: 1476.1580s\n",
      "\titers: 200, epoch: 1 | loss: 0.2789010\n",
      "\tspeed: 0.0394s/iter; left time: 870.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.3081932 Vali Loss: 0.2482915 Test Loss: 0.2519065\n",
      "Validation loss decreased (inf --> 0.248292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1638562\n",
      "\tspeed: 0.0733s/iter; left time: 1609.9406s\n",
      "\titers: 200, epoch: 2 | loss: 0.1406918\n",
      "\tspeed: 0.0392s/iter; left time: 857.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.1783940 Vali Loss: 0.1542408 Test Loss: 0.1613330\n",
      "Validation loss decreased (0.248292 --> 0.154241).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1342908\n",
      "\tspeed: 0.0737s/iter; left time: 1603.4695s\n",
      "\titers: 200, epoch: 3 | loss: 0.1246183\n",
      "\tspeed: 0.0392s/iter; left time: 847.9981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.1342221 Vali Loss: 0.1371294 Test Loss: 0.1435677\n",
      "Validation loss decreased (0.154241 --> 0.137129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1158175\n",
      "\tspeed: 0.0729s/iter; left time: 1569.6479s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 4 | loss: 0.1030280\n",
      "\tspeed: 0.0390s/iter; left time: 836.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.1121669 Vali Loss: 0.1111415 Test Loss: 0.1145016\n",
      "Validation loss decreased (0.137129 --> 0.111141).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0967089\n",
      "\tspeed: 0.0738s/iter; left time: 1573.0784s\n",
      "\titers: 200, epoch: 5 | loss: 0.1009373\n",
      "\tspeed: 0.0394s/iter; left time: 835.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0992470 Vali Loss: 0.1072604 Test Loss: 0.1109597\n",
      "Validation loss decreased (0.111141 --> 0.107260).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0936083\n",
      "\tspeed: 0.0734s/iter; left time: 1548.1120s\n",
      "\titers: 200, epoch: 6 | loss: 0.0996717\n",
      "\tspeed: 0.0391s/iter; left time: 819.5171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0947712 Vali Loss: 0.1034362 Test Loss: 0.1067774\n",
      "Validation loss decreased (0.107260 --> 0.103436).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899060\n",
      "\tspeed: 0.0738s/iter; left time: 1538.8707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0921599\n",
      "\tspeed: 0.0394s/iter; left time: 819.0332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0921763 Vali Loss: 0.1015805 Test Loss: 0.1051502\n",
      "Validation loss decreased (0.103436 --> 0.101581).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0878173\n",
      "\tspeed: 0.0760s/iter; left time: 1568.2402s\n",
      "\titers: 200, epoch: 8 | loss: 0.0912416\n",
      "\tspeed: 0.0414s/iter; left time: 849.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0899490 Vali Loss: 0.1002820 Test Loss: 0.1034811\n",
      "Validation loss decreased (0.101581 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0924185\n",
      "\tspeed: 0.0769s/iter; left time: 1569.4510s\n",
      "\titers: 200, epoch: 9 | loss: 0.0872299\n",
      "\tspeed: 0.0408s/iter; left time: 829.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0882781 Vali Loss: 0.0981101 Test Loss: 0.1019481\n",
      "Validation loss decreased (0.100282 --> 0.098110).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0864746\n",
      "\tspeed: 0.0770s/iter; left time: 1554.2792s\n",
      "\titers: 200, epoch: 10 | loss: 0.0893587\n",
      "\tspeed: 0.0408s/iter; left time: 819.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0866424 Vali Loss: 0.0969345 Test Loss: 0.1007025\n",
      "Validation loss decreased (0.098110 --> 0.096935).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822373\n",
      "\tspeed: 0.0789s/iter; left time: 1576.0852s\n",
      "\titers: 200, epoch: 11 | loss: 0.0831705\n",
      "\tspeed: 0.0411s/iter; left time: 817.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0853453 Vali Loss: 0.0962126 Test Loss: 0.0996499\n",
      "Validation loss decreased (0.096935 --> 0.096213).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834884\n",
      "\tspeed: 0.0783s/iter; left time: 1546.4460s\n",
      "\titers: 200, epoch: 12 | loss: 0.0840631\n",
      "\tspeed: 0.0406s/iter; left time: 797.1436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0844050 Vali Loss: 0.0954370 Test Loss: 0.0990020\n",
      "Validation loss decreased (0.096213 --> 0.095437).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0834387\n",
      "\tspeed: 0.0757s/iter; left time: 1478.3708s\n",
      "\titers: 200, epoch: 13 | loss: 0.0845602\n",
      "\tspeed: 0.0391s/iter; left time: 759.7812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0834294 Vali Loss: 0.0951177 Test Loss: 0.0991242\n",
      "Validation loss decreased (0.095437 --> 0.095118).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0806244\n",
      "\tspeed: 0.0774s/iter; left time: 1493.6404s\n",
      "\titers: 200, epoch: 14 | loss: 0.0852740\n",
      "\tspeed: 0.0439s/iter; left time: 843.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.0826854 Vali Loss: 0.0945826 Test Loss: 0.0985009\n",
      "Validation loss decreased (0.095118 --> 0.094583).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0833009\n",
      "\tspeed: 0.0849s/iter; left time: 1619.0075s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817942\n",
      "\tspeed: 0.0459s/iter; left time: 870.2585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.73s\n",
      "Steps: 223 | Train Loss: 0.0819931 Vali Loss: 0.0943775 Test Loss: 0.0985279\n",
      "Validation loss decreased (0.094583 --> 0.094377).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0838617\n",
      "\tspeed: 0.0837s/iter; left time: 1579.1788s\n",
      "\titers: 200, epoch: 16 | loss: 0.0872094\n",
      "\tspeed: 0.0468s/iter; left time: 876.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 223 | Train Loss: 0.0813460 Vali Loss: 0.0938232 Test Loss: 0.0977513\n",
      "Validation loss decreased (0.094377 --> 0.093823).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0830839\n",
      "\tspeed: 0.0845s/iter; left time: 1574.3128s\n",
      "\titers: 200, epoch: 17 | loss: 0.0782543\n",
      "\tspeed: 0.0470s/iter; left time: 871.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.79s\n",
      "Steps: 223 | Train Loss: 0.0810979 Vali Loss: 0.0935347 Test Loss: 0.0971676\n",
      "Validation loss decreased (0.093823 --> 0.093535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787568\n",
      "\tspeed: 0.0834s/iter; left time: 1535.2800s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783755\n",
      "\tspeed: 0.0453s/iter; left time: 829.8073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.37s\n",
      "Steps: 223 | Train Loss: 0.0808378 Vali Loss: 0.0939313 Test Loss: 0.0980014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0821436\n",
      "\tspeed: 0.0761s/iter; left time: 1384.7830s\n",
      "\titers: 200, epoch: 19 | loss: 0.0835161\n",
      "\tspeed: 0.0404s/iter; left time: 731.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0804628 Vali Loss: 0.0933557 Test Loss: 0.0972996\n",
      "Validation loss decreased (0.093535 --> 0.093356).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0800974\n",
      "\tspeed: 0.0772s/iter; left time: 1387.3731s\n",
      "\titers: 200, epoch: 20 | loss: 0.0740406\n",
      "\tspeed: 0.0408s/iter; left time: 728.9138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0799425 Vali Loss: 0.0934522 Test Loss: 0.0973672\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0792220\n",
      "\tspeed: 0.0761s/iter; left time: 1349.5828s\n",
      "\titers: 200, epoch: 21 | loss: 0.0800557\n",
      "\tspeed: 0.0412s/iter; left time: 727.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0797299 Vali Loss: 0.0933082 Test Loss: 0.0972592\n",
      "Validation loss decreased (0.093356 --> 0.093308).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0809140\n",
      "\tspeed: 0.0764s/iter; left time: 1338.5985s\n",
      "\titers: 200, epoch: 22 | loss: 0.0791628\n",
      "\tspeed: 0.0407s/iter; left time: 708.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0794363 Vali Loss: 0.0933283 Test Loss: 0.0973159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0774002\n",
      "\tspeed: 0.0756s/iter; left time: 1307.6260s\n",
      "\titers: 200, epoch: 23 | loss: 0.0816682\n",
      "\tspeed: 0.0408s/iter; left time: 700.8851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0793459 Vali Loss: 0.0929844 Test Loss: 0.0971298\n",
      "Validation loss decreased (0.093308 --> 0.092984).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741662\n",
      "\tspeed: 0.0770s/iter; left time: 1314.6384s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829684\n",
      "\tspeed: 0.0403s/iter; left time: 684.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0792077 Vali Loss: 0.0927484 Test Loss: 0.0969628\n",
      "Validation loss decreased (0.092984 --> 0.092748).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0867628\n",
      "\tspeed: 0.0753s/iter; left time: 1268.8026s\n",
      "\titers: 200, epoch: 25 | loss: 0.0741284\n",
      "\tspeed: 0.0405s/iter; left time: 678.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0791248 Vali Loss: 0.0928454 Test Loss: 0.0967692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0782138\n",
      "\tspeed: 0.0751s/iter; left time: 1249.2401s\n",
      "\titers: 200, epoch: 26 | loss: 0.0735188\n",
      "\tspeed: 0.0403s/iter; left time: 666.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0787920 Vali Loss: 0.0927851 Test Loss: 0.0969393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0798206\n",
      "\tspeed: 0.0747s/iter; left time: 1225.7390s\n",
      "\titers: 200, epoch: 27 | loss: 0.0872458\n",
      "\tspeed: 0.0408s/iter; left time: 664.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0787958 Vali Loss: 0.0925486 Test Loss: 0.0966334\n",
      "Validation loss decreased (0.092748 --> 0.092549).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0817417\n",
      "\tspeed: 0.0761s/iter; left time: 1231.6031s\n",
      "\titers: 200, epoch: 28 | loss: 0.0782959\n",
      "\tspeed: 0.0402s/iter; left time: 645.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0787491 Vali Loss: 0.0928219 Test Loss: 0.0971367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0802352\n",
      "\tspeed: 0.0750s/iter; left time: 1197.2598s\n",
      "\titers: 200, epoch: 29 | loss: 0.0785250\n",
      "\tspeed: 0.0409s/iter; left time: 648.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0785215 Vali Loss: 0.0926309 Test Loss: 0.0967417\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0814905\n",
      "\tspeed: 0.0761s/iter; left time: 1198.0700s\n",
      "\titers: 200, epoch: 30 | loss: 0.0731403\n",
      "\tspeed: 0.0413s/iter; left time: 645.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0784639 Vali Loss: 0.0927780 Test Loss: 0.0971439\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0822051\n",
      "\tspeed: 0.0767s/iter; left time: 1190.4452s\n",
      "\titers: 200, epoch: 31 | loss: 0.0811925\n",
      "\tspeed: 0.0407s/iter; left time: 627.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0784981 Vali Loss: 0.0925181 Test Loss: 0.0968074\n",
      "Validation loss decreased (0.092549 --> 0.092518).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0717718\n",
      "\tspeed: 0.0772s/iter; left time: 1180.3759s\n",
      "\titers: 200, epoch: 32 | loss: 0.0772513\n",
      "\tspeed: 0.0407s/iter; left time: 618.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0783310 Vali Loss: 0.0925629 Test Loss: 0.0969097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0855694\n",
      "\tspeed: 0.0757s/iter; left time: 1140.4648s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741483\n",
      "\tspeed: 0.0405s/iter; left time: 605.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0783244 Vali Loss: 0.0923620 Test Loss: 0.0965614\n",
      "Validation loss decreased (0.092518 --> 0.092362).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0794027\n",
      "\tspeed: 0.0764s/iter; left time: 1134.4362s\n",
      "\titers: 200, epoch: 34 | loss: 0.0773778\n",
      "\tspeed: 0.0402s/iter; left time: 593.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0782929 Vali Loss: 0.0928259 Test Loss: 0.0969210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0777795\n",
      "\tspeed: 0.0767s/iter; left time: 1121.8727s\n",
      "\titers: 200, epoch: 35 | loss: 0.0764658\n",
      "\tspeed: 0.0406s/iter; left time: 589.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0782185 Vali Loss: 0.0925045 Test Loss: 0.0968241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0797379\n",
      "\tspeed: 0.0757s/iter; left time: 1090.3176s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777661\n",
      "\tspeed: 0.0410s/iter; left time: 586.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0781731 Vali Loss: 0.0923674 Test Loss: 0.0966517\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0780007\n",
      "\tspeed: 0.0757s/iter; left time: 1073.0543s\n",
      "\titers: 200, epoch: 37 | loss: 0.0781868\n",
      "\tspeed: 0.0414s/iter; left time: 582.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0780824 Vali Loss: 0.0923932 Test Loss: 0.0966902\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0734213\n",
      "\tspeed: 0.0755s/iter; left time: 1052.5524s\n",
      "\titers: 200, epoch: 38 | loss: 0.0756392\n",
      "\tspeed: 0.0406s/iter; left time: 562.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0780712 Vali Loss: 0.0924156 Test Loss: 0.0966256\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0770620\n",
      "\tspeed: 0.0762s/iter; left time: 1046.0585s\n",
      "\titers: 200, epoch: 39 | loss: 0.0803570\n",
      "\tspeed: 0.0402s/iter; left time: 547.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0780136 Vali Loss: 0.0923058 Test Loss: 0.0965526\n",
      "Validation loss decreased (0.092362 --> 0.092306).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0774509\n",
      "\tspeed: 0.0742s/iter; left time: 1002.1328s\n",
      "\titers: 200, epoch: 40 | loss: 0.0810045\n",
      "\tspeed: 0.0391s/iter; left time: 524.7492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0779856 Vali Loss: 0.0924603 Test Loss: 0.0966418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0778279\n",
      "\tspeed: 0.0749s/iter; left time: 995.1430s\n",
      "\titers: 200, epoch: 41 | loss: 0.0776937\n",
      "\tspeed: 0.0392s/iter; left time: 516.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0779421 Vali Loss: 0.0923239 Test Loss: 0.0965320\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0820208\n",
      "\tspeed: 0.0786s/iter; left time: 1026.5353s\n",
      "\titers: 200, epoch: 42 | loss: 0.0765325\n",
      "\tspeed: 0.0462s/iter; left time: 598.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:10.40s\n",
      "Steps: 223 | Train Loss: 0.0779369 Vali Loss: 0.0923302 Test Loss: 0.0968036\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0791285\n",
      "\tspeed: 0.0807s/iter; left time: 1036.0137s\n",
      "\titers: 200, epoch: 43 | loss: 0.0834686\n",
      "\tspeed: 0.0448s/iter; left time: 569.9776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 223 | Train Loss: 0.0779536 Vali Loss: 0.0922453 Test Loss: 0.0965889\n",
      "Validation loss decreased (0.092306 --> 0.092245).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0751408\n",
      "\tspeed: 0.0773s/iter; left time: 974.6920s\n",
      "\titers: 200, epoch: 44 | loss: 0.0807966\n",
      "\tspeed: 0.0401s/iter; left time: 501.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0779461 Vali Loss: 0.0924632 Test Loss: 0.0969329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0755493\n",
      "\tspeed: 0.0741s/iter; left time: 917.9656s\n",
      "\titers: 200, epoch: 45 | loss: 0.0721917\n",
      "\tspeed: 0.0393s/iter; left time: 483.4798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0779119 Vali Loss: 0.0923642 Test Loss: 0.0967281\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0808332\n",
      "\tspeed: 0.0722s/iter; left time: 878.8876s\n",
      "\titers: 200, epoch: 46 | loss: 0.0798107\n",
      "\tspeed: 0.0390s/iter; left time: 471.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0778964 Vali Loss: 0.0924356 Test Loss: 0.0967914\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0764894\n",
      "\tspeed: 0.0733s/iter; left time: 875.6441s\n",
      "\titers: 200, epoch: 47 | loss: 0.0773816\n",
      "\tspeed: 0.0475s/iter; left time: 563.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:10.13s\n",
      "Steps: 223 | Train Loss: 0.0778870 Vali Loss: 0.0923888 Test Loss: 0.0966391\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0809204\n",
      "\tspeed: 0.0771s/iter; left time: 903.2798s\n",
      "\titers: 200, epoch: 48 | loss: 0.0763166\n",
      "\tspeed: 0.0405s/iter; left time: 470.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.0778385 Vali Loss: 0.0921897 Test Loss: 0.0964735\n",
      "Validation loss decreased (0.092245 --> 0.092190).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0811581\n",
      "\tspeed: 0.0774s/iter; left time: 890.0441s\n",
      "\titers: 200, epoch: 49 | loss: 0.0779913\n",
      "\tspeed: 0.0455s/iter; left time: 519.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0778552 Vali Loss: 0.0925256 Test Loss: 0.0967690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0767454\n",
      "\tspeed: 0.0727s/iter; left time: 820.1169s\n",
      "\titers: 200, epoch: 50 | loss: 0.0724514\n",
      "\tspeed: 0.0391s/iter; left time: 436.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 223 | Train Loss: 0.0778307 Vali Loss: 0.0923734 Test Loss: 0.0965792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0745569\n",
      "\tspeed: 0.0720s/iter; left time: 795.8986s\n",
      "\titers: 200, epoch: 51 | loss: 0.0779254\n",
      "\tspeed: 0.0392s/iter; left time: 429.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0778081 Vali Loss: 0.0922338 Test Loss: 0.0965786\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0834289\n",
      "\tspeed: 0.0724s/iter; left time: 784.1021s\n",
      "\titers: 200, epoch: 52 | loss: 0.0796882\n",
      "\tspeed: 0.0391s/iter; left time: 418.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0777583 Vali Loss: 0.0922315 Test Loss: 0.0966221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0812875\n",
      "\tspeed: 0.0725s/iter; left time: 768.6018s\n",
      "\titers: 200, epoch: 53 | loss: 0.0820242\n",
      "\tspeed: 0.0390s/iter; left time: 409.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 223 | Train Loss: 0.0778734 Vali Loss: 0.0924355 Test Loss: 0.0966151\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0758207\n",
      "\tspeed: 0.0724s/iter; left time: 751.4594s\n",
      "\titers: 200, epoch: 54 | loss: 0.0810523\n",
      "\tspeed: 0.0390s/iter; left time: 401.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0777694 Vali Loss: 0.0922804 Test Loss: 0.0966932\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0780737\n",
      "\tspeed: 0.0727s/iter; left time: 738.8396s\n",
      "\titers: 200, epoch: 55 | loss: 0.0778689\n",
      "\tspeed: 0.0392s/iter; left time: 393.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0777638 Vali Loss: 0.0923522 Test Loss: 0.0966050\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0776581\n",
      "\tspeed: 0.0747s/iter; left time: 742.1829s\n",
      "\titers: 200, epoch: 56 | loss: 0.0764012\n",
      "\tspeed: 0.0403s/iter; left time: 395.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0777802 Vali Loss: 0.0923108 Test Loss: 0.0965767\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0735616\n",
      "\tspeed: 0.0760s/iter; left time: 738.4512s\n",
      "\titers: 200, epoch: 57 | loss: 0.0824235\n",
      "\tspeed: 0.0418s/iter; left time: 401.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0777518 Vali Loss: 0.0922178 Test Loss: 0.0964429\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0784202\n",
      "\tspeed: 0.0754s/iter; left time: 715.2553s\n",
      "\titers: 200, epoch: 58 | loss: 0.0722737\n",
      "\tspeed: 0.0394s/iter; left time: 370.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0777917 Vali Loss: 0.0922924 Test Loss: 0.0966354\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02334590256214142, rmse:0.15279366075992584, mae:0.09647348523139954, rse:0.5392299890518188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3080146\n",
      "\tspeed: 0.0500s/iter; left time: 1110.6833s\n",
      "\titers: 200, epoch: 1 | loss: 0.2790629\n",
      "\tspeed: 0.0463s/iter; left time: 1023.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.69s\n",
      "Steps: 223 | Train Loss: 0.3084028 Vali Loss: 0.2552087 Test Loss: 0.2576425\n",
      "Validation loss decreased (inf --> 0.255209).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1677393\n",
      "\tspeed: 0.0768s/iter; left time: 1687.9408s\n",
      "\titers: 200, epoch: 2 | loss: 0.1420872\n",
      "\tspeed: 0.0391s/iter; left time: 854.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.1784006 Vali Loss: 0.1509992 Test Loss: 0.1576872\n",
      "Validation loss decreased (0.255209 --> 0.150999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1325056\n",
      "\tspeed: 0.0739s/iter; left time: 1607.9889s\n",
      "\titers: 200, epoch: 3 | loss: 0.1217743\n",
      "\tspeed: 0.0395s/iter; left time: 855.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.1300604 Vali Loss: 0.1280405 Test Loss: 0.1321596\n",
      "Validation loss decreased (0.150999 --> 0.128040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1109877\n",
      "\tspeed: 0.0776s/iter; left time: 1670.5325s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007124\n",
      "\tspeed: 0.0392s/iter; left time: 840.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.1096980 Vali Loss: 0.1120514 Test Loss: 0.1159602\n",
      "Validation loss decreased (0.128040 --> 0.112051).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1006160\n",
      "\tspeed: 0.0753s/iter; left time: 1603.6100s\n",
      "\titers: 200, epoch: 5 | loss: 0.1080253\n",
      "\tspeed: 0.0395s/iter; left time: 837.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0996368 Vali Loss: 0.1088984 Test Loss: 0.1125383\n",
      "Validation loss decreased (0.112051 --> 0.108898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0896810\n",
      "\tspeed: 0.0747s/iter; left time: 1574.4301s\n",
      "\titers: 200, epoch: 6 | loss: 0.0973714\n",
      "\tspeed: 0.0392s/iter; left time: 823.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0954706 Vali Loss: 0.1039079 Test Loss: 0.1076654\n",
      "Validation loss decreased (0.108898 --> 0.103908).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0965368\n",
      "\tspeed: 0.0743s/iter; left time: 1550.9857s\n",
      "\titers: 200, epoch: 7 | loss: 0.0902605\n",
      "\tspeed: 0.0395s/iter; left time: 820.6043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0925215 Vali Loss: 0.1011803 Test Loss: 0.1049975\n",
      "Validation loss decreased (0.103908 --> 0.101180).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0916805\n",
      "\tspeed: 0.0745s/iter; left time: 1538.3986s\n",
      "\titers: 200, epoch: 8 | loss: 0.0879794\n",
      "\tspeed: 0.0392s/iter; left time: 804.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0902541 Vali Loss: 0.1009981 Test Loss: 0.1043894\n",
      "Validation loss decreased (0.101180 --> 0.100998).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0902119\n",
      "\tspeed: 0.0740s/iter; left time: 1510.4717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0833331\n",
      "\tspeed: 0.0392s/iter; left time: 797.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0882565 Vali Loss: 0.0986715 Test Loss: 0.1023076\n",
      "Validation loss decreased (0.100998 --> 0.098672).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0855064\n",
      "\tspeed: 0.0742s/iter; left time: 1497.7476s\n",
      "\titers: 200, epoch: 10 | loss: 0.0865379\n",
      "\tspeed: 0.0391s/iter; left time: 784.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0867844 Vali Loss: 0.0977712 Test Loss: 0.1004318\n",
      "Validation loss decreased (0.098672 --> 0.097771).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844632\n",
      "\tspeed: 0.0739s/iter; left time: 1475.7404s\n",
      "\titers: 200, epoch: 11 | loss: 0.0873359\n",
      "\tspeed: 0.0390s/iter; left time: 775.2123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0855056 Vali Loss: 0.0963926 Test Loss: 0.0997817\n",
      "Validation loss decreased (0.097771 --> 0.096393).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0823638\n",
      "\tspeed: 0.0732s/iter; left time: 1445.2488s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788203\n",
      "\tspeed: 0.0391s/iter; left time: 767.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0846003 Vali Loss: 0.0957724 Test Loss: 0.0987216\n",
      "Validation loss decreased (0.096393 --> 0.095772).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0926298\n",
      "\tspeed: 0.0738s/iter; left time: 1440.8495s\n",
      "\titers: 200, epoch: 13 | loss: 0.0865053\n",
      "\tspeed: 0.0391s/iter; left time: 758.9190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0841369 Vali Loss: 0.0969220 Test Loss: 0.0998623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797163\n",
      "\tspeed: 0.0728s/iter; left time: 1405.0334s\n",
      "\titers: 200, epoch: 14 | loss: 0.0825148\n",
      "\tspeed: 0.0392s/iter; left time: 752.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0832278 Vali Loss: 0.0955287 Test Loss: 0.0990572\n",
      "Validation loss decreased (0.095772 --> 0.095529).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0817549\n",
      "\tspeed: 0.0743s/iter; left time: 1417.3951s\n",
      "\titers: 200, epoch: 15 | loss: 0.0797019\n",
      "\tspeed: 0.0392s/iter; left time: 744.8001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0824789 Vali Loss: 0.0947996 Test Loss: 0.0977689\n",
      "Validation loss decreased (0.095529 --> 0.094800).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0835267\n",
      "\tspeed: 0.0762s/iter; left time: 1436.5955s\n",
      "\titers: 200, epoch: 16 | loss: 0.0805989\n",
      "\tspeed: 0.0405s/iter; left time: 758.7904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0819614 Vali Loss: 0.0952756 Test Loss: 0.0980850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807216\n",
      "\tspeed: 0.0741s/iter; left time: 1380.6613s\n",
      "\titers: 200, epoch: 17 | loss: 0.0737224\n",
      "\tspeed: 0.0404s/iter; left time: 747.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0813871 Vali Loss: 0.0943735 Test Loss: 0.0973355\n",
      "Validation loss decreased (0.094800 --> 0.094374).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0776923\n",
      "\tspeed: 0.0765s/iter; left time: 1407.7506s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760688\n",
      "\tspeed: 0.0394s/iter; left time: 721.3102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0810636 Vali Loss: 0.0939164 Test Loss: 0.0970127\n",
      "Validation loss decreased (0.094374 --> 0.093916).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0790848\n",
      "\tspeed: 0.0749s/iter; left time: 1362.8892s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797037\n",
      "\tspeed: 0.0394s/iter; left time: 712.3314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0806580 Vali Loss: 0.0937746 Test Loss: 0.0971683\n",
      "Validation loss decreased (0.093916 --> 0.093775).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0769669\n",
      "\tspeed: 0.0756s/iter; left time: 1358.9396s\n",
      "\titers: 200, epoch: 20 | loss: 0.0806015\n",
      "\tspeed: 0.0391s/iter; left time: 698.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0803610 Vali Loss: 0.0936393 Test Loss: 0.0967445\n",
      "Validation loss decreased (0.093775 --> 0.093639).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0865185\n",
      "\tspeed: 0.0738s/iter; left time: 1308.5329s\n",
      "\titers: 200, epoch: 21 | loss: 0.0791970\n",
      "\tspeed: 0.0391s/iter; left time: 689.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0800923 Vali Loss: 0.0933013 Test Loss: 0.0964508\n",
      "Validation loss decreased (0.093639 --> 0.093301).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0744280\n",
      "\tspeed: 0.0741s/iter; left time: 1298.4324s\n",
      "\titers: 200, epoch: 22 | loss: 0.0752589\n",
      "\tspeed: 0.0403s/iter; left time: 702.8134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0798378 Vali Loss: 0.0927765 Test Loss: 0.0962400\n",
      "Validation loss decreased (0.093301 --> 0.092777).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0829736\n",
      "\tspeed: 0.0743s/iter; left time: 1285.6214s\n",
      "\titers: 200, epoch: 23 | loss: 0.0808691\n",
      "\tspeed: 0.0396s/iter; left time: 680.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0796212 Vali Loss: 0.0927674 Test Loss: 0.0962314\n",
      "Validation loss decreased (0.092777 --> 0.092767).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0780895\n",
      "\tspeed: 0.0756s/iter; left time: 1290.1728s\n",
      "\titers: 200, epoch: 24 | loss: 0.0788399\n",
      "\tspeed: 0.0402s/iter; left time: 682.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 223 | Train Loss: 0.0794670 Vali Loss: 0.0931241 Test Loss: 0.0962116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0766795\n",
      "\tspeed: 0.0762s/iter; left time: 1283.1852s\n",
      "\titers: 200, epoch: 25 | loss: 0.0773863\n",
      "\tspeed: 0.0409s/iter; left time: 685.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0791355 Vali Loss: 0.0929981 Test Loss: 0.0961276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0788309\n",
      "\tspeed: 0.0790s/iter; left time: 1312.8230s\n",
      "\titers: 200, epoch: 26 | loss: 0.0764069\n",
      "\tspeed: 0.0471s/iter; left time: 778.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 223 | Train Loss: 0.0789527 Vali Loss: 0.0927166 Test Loss: 0.0960036\n",
      "Validation loss decreased (0.092767 --> 0.092717).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0823304\n",
      "\tspeed: 0.0786s/iter; left time: 1290.0253s\n",
      "\titers: 200, epoch: 27 | loss: 0.0809646\n",
      "\tspeed: 0.0401s/iter; left time: 653.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0789914 Vali Loss: 0.0926665 Test Loss: 0.0960555\n",
      "Validation loss decreased (0.092717 --> 0.092666).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0837875\n",
      "\tspeed: 0.0758s/iter; left time: 1226.5375s\n",
      "\titers: 200, epoch: 28 | loss: 0.0840536\n",
      "\tspeed: 0.0396s/iter; left time: 637.0517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.0787988 Vali Loss: 0.0928089 Test Loss: 0.0958647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0794112\n",
      "\tspeed: 0.0730s/iter; left time: 1165.2008s\n",
      "\titers: 200, epoch: 29 | loss: 0.0764613\n",
      "\tspeed: 0.0398s/iter; left time: 630.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0786049 Vali Loss: 0.0928564 Test Loss: 0.0960063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0793030\n",
      "\tspeed: 0.0737s/iter; left time: 1160.2005s\n",
      "\titers: 200, epoch: 30 | loss: 0.0833101\n",
      "\tspeed: 0.0393s/iter; left time: 614.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0785641 Vali Loss: 0.0925156 Test Loss: 0.0957019\n",
      "Validation loss decreased (0.092666 --> 0.092516).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0762745\n",
      "\tspeed: 0.0773s/iter; left time: 1199.1402s\n",
      "\titers: 200, epoch: 31 | loss: 0.0750749\n",
      "\tspeed: 0.0391s/iter; left time: 601.8272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0784951 Vali Loss: 0.0924452 Test Loss: 0.0959329\n",
      "Validation loss decreased (0.092516 --> 0.092445).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0769495\n",
      "\tspeed: 0.0739s/iter; left time: 1129.2589s\n",
      "\titers: 200, epoch: 32 | loss: 0.0840974\n",
      "\tspeed: 0.0392s/iter; left time: 596.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0784416 Vali Loss: 0.0923208 Test Loss: 0.0955615\n",
      "Validation loss decreased (0.092445 --> 0.092321).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764445\n",
      "\tspeed: 0.0757s/iter; left time: 1140.1213s\n",
      "\titers: 200, epoch: 33 | loss: 0.0782920\n",
      "\tspeed: 0.0391s/iter; left time: 584.8576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0782592 Vali Loss: 0.0923433 Test Loss: 0.0955601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0756650\n",
      "\tspeed: 0.0732s/iter; left time: 1085.7816s\n",
      "\titers: 200, epoch: 34 | loss: 0.0755153\n",
      "\tspeed: 0.0393s/iter; left time: 579.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0782110 Vali Loss: 0.0921713 Test Loss: 0.0956170\n",
      "Validation loss decreased (0.092321 --> 0.092171).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0841382\n",
      "\tspeed: 0.0748s/iter; left time: 1093.4037s\n",
      "\titers: 200, epoch: 35 | loss: 0.0768102\n",
      "\tspeed: 0.0390s/iter; left time: 566.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0782156 Vali Loss: 0.0924025 Test Loss: 0.0956031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0851820\n",
      "\tspeed: 0.0736s/iter; left time: 1059.2539s\n",
      "\titers: 200, epoch: 36 | loss: 0.0799777\n",
      "\tspeed: 0.0390s/iter; left time: 558.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0781929 Vali Loss: 0.0921672 Test Loss: 0.0955251\n",
      "Validation loss decreased (0.092171 --> 0.092167).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0841853\n",
      "\tspeed: 0.0740s/iter; left time: 1048.4798s\n",
      "\titers: 200, epoch: 37 | loss: 0.0794772\n",
      "\tspeed: 0.0391s/iter; left time: 549.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0781041 Vali Loss: 0.0922006 Test Loss: 0.0955454\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0796745\n",
      "\tspeed: 0.0741s/iter; left time: 1033.7806s\n",
      "\titers: 200, epoch: 38 | loss: 0.0781508\n",
      "\tspeed: 0.0390s/iter; left time: 540.5248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0780662 Vali Loss: 0.0922398 Test Loss: 0.0955416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0735128\n",
      "\tspeed: 0.0730s/iter; left time: 1001.4700s\n",
      "\titers: 200, epoch: 39 | loss: 0.0834485\n",
      "\tspeed: 0.0391s/iter; left time: 532.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0780141 Vali Loss: 0.0927878 Test Loss: 0.0958959\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0801430\n",
      "\tspeed: 0.0750s/iter; left time: 1013.0354s\n",
      "\titers: 200, epoch: 40 | loss: 0.0794963\n",
      "\tspeed: 0.0391s/iter; left time: 523.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0779085 Vali Loss: 0.0924477 Test Loss: 0.0956182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0770263\n",
      "\tspeed: 0.0762s/iter; left time: 1012.4933s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781991\n",
      "\tspeed: 0.0394s/iter; left time: 519.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0779320 Vali Loss: 0.0921180 Test Loss: 0.0954626\n",
      "Validation loss decreased (0.092167 --> 0.092118).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0769638\n",
      "\tspeed: 0.0744s/iter; left time: 971.0242s\n",
      "\titers: 200, epoch: 42 | loss: 0.0789724\n",
      "\tspeed: 0.0393s/iter; left time: 508.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0779793 Vali Loss: 0.0922716 Test Loss: 0.0954883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0812305\n",
      "\tspeed: 0.0735s/iter; left time: 943.3920s\n",
      "\titers: 200, epoch: 43 | loss: 0.0741097\n",
      "\tspeed: 0.0388s/iter; left time: 493.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0778346 Vali Loss: 0.0921406 Test Loss: 0.0954489\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0820441\n",
      "\tspeed: 0.0781s/iter; left time: 984.4091s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757079\n",
      "\tspeed: 0.0403s/iter; left time: 503.7645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0779381 Vali Loss: 0.0922703 Test Loss: 0.0955384\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0748204\n",
      "\tspeed: 0.0770s/iter; left time: 953.3957s\n",
      "\titers: 200, epoch: 45 | loss: 0.0802502\n",
      "\tspeed: 0.0405s/iter; left time: 497.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0778225 Vali Loss: 0.0921974 Test Loss: 0.0954675\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0775723\n",
      "\tspeed: 0.0754s/iter; left time: 917.6007s\n",
      "\titers: 200, epoch: 46 | loss: 0.0803550\n",
      "\tspeed: 0.0391s/iter; left time: 471.3124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0777630 Vali Loss: 0.0923739 Test Loss: 0.0955280\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738334\n",
      "\tspeed: 0.0735s/iter; left time: 877.4226s\n",
      "\titers: 200, epoch: 47 | loss: 0.0807630\n",
      "\tspeed: 0.0390s/iter; left time: 461.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0778314 Vali Loss: 0.0921926 Test Loss: 0.0954609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0776202\n",
      "\tspeed: 0.0737s/iter; left time: 863.5685s\n",
      "\titers: 200, epoch: 48 | loss: 0.0780999\n",
      "\tspeed: 0.0399s/iter; left time: 464.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0777588 Vali Loss: 0.0921641 Test Loss: 0.0954303\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0756521\n",
      "\tspeed: 0.0735s/iter; left time: 845.3987s\n",
      "\titers: 200, epoch: 49 | loss: 0.0774185\n",
      "\tspeed: 0.0403s/iter; left time: 459.2397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0777934 Vali Loss: 0.0922037 Test Loss: 0.0954729\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0779799\n",
      "\tspeed: 0.0749s/iter; left time: 843.8661s\n",
      "\titers: 200, epoch: 50 | loss: 0.0762182\n",
      "\tspeed: 0.0390s/iter; left time: 435.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0779052 Vali Loss: 0.0920197 Test Loss: 0.0953666\n",
      "Validation loss decreased (0.092118 --> 0.092020).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0789795\n",
      "\tspeed: 0.0738s/iter; left time: 815.0805s\n",
      "\titers: 200, epoch: 51 | loss: 0.0786915\n",
      "\tspeed: 0.0392s/iter; left time: 428.9614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0777551 Vali Loss: 0.0921362 Test Loss: 0.0954248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0741192\n",
      "\tspeed: 0.0743s/iter; left time: 804.2702s\n",
      "\titers: 200, epoch: 52 | loss: 0.0745338\n",
      "\tspeed: 0.0391s/iter; left time: 419.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0777958 Vali Loss: 0.0923793 Test Loss: 0.0956235\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0759238\n",
      "\tspeed: 0.0729s/iter; left time: 772.9391s\n",
      "\titers: 200, epoch: 53 | loss: 0.0786863\n",
      "\tspeed: 0.0390s/iter; left time: 409.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0778536 Vali Loss: 0.0920218 Test Loss: 0.0954029\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0800610\n",
      "\tspeed: 0.0731s/iter; left time: 758.6015s\n",
      "\titers: 200, epoch: 54 | loss: 0.0803818\n",
      "\tspeed: 0.0390s/iter; left time: 401.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0777592 Vali Loss: 0.0920335 Test Loss: 0.0953722\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0795559\n",
      "\tspeed: 0.0732s/iter; left time: 743.5163s\n",
      "\titers: 200, epoch: 55 | loss: 0.0768455\n",
      "\tspeed: 0.0390s/iter; left time: 392.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0776835 Vali Loss: 0.0921948 Test Loss: 0.0954427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0820324\n",
      "\tspeed: 0.0734s/iter; left time: 729.1788s\n",
      "\titers: 200, epoch: 56 | loss: 0.0798198\n",
      "\tspeed: 0.0394s/iter; left time: 387.6004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0777403 Vali Loss: 0.0921130 Test Loss: 0.0953942\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0766282\n",
      "\tspeed: 0.0731s/iter; left time: 709.9482s\n",
      "\titers: 200, epoch: 57 | loss: 0.0756723\n",
      "\tspeed: 0.0390s/iter; left time: 375.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0777368 Vali Loss: 0.0920077 Test Loss: 0.0953932\n",
      "Validation loss decreased (0.092020 --> 0.092008).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0772319\n",
      "\tspeed: 0.0732s/iter; left time: 694.2536s\n",
      "\titers: 200, epoch: 58 | loss: 0.0796352\n",
      "\tspeed: 0.0393s/iter; left time: 369.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0776890 Vali Loss: 0.0919944 Test Loss: 0.0953804\n",
      "Validation loss decreased (0.092008 --> 0.091994).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0740148\n",
      "\tspeed: 0.0742s/iter; left time: 687.5602s\n",
      "\titers: 200, epoch: 59 | loss: 0.0759659\n",
      "\tspeed: 0.0392s/iter; left time: 359.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0777411 Vali Loss: 0.0921390 Test Loss: 0.0953781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0818398\n",
      "\tspeed: 0.0730s/iter; left time: 660.4509s\n",
      "\titers: 200, epoch: 60 | loss: 0.0758929\n",
      "\tspeed: 0.0399s/iter; left time: 356.7008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 223 | Train Loss: 0.0777213 Vali Loss: 0.0921134 Test Loss: 0.0953995\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0787978\n",
      "\tspeed: 0.0735s/iter; left time: 648.2145s\n",
      "\titers: 200, epoch: 61 | loss: 0.0736430\n",
      "\tspeed: 0.0390s/iter; left time: 340.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0776988 Vali Loss: 0.0920566 Test Loss: 0.0953496\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0786709\n",
      "\tspeed: 0.0756s/iter; left time: 650.1284s\n",
      "\titers: 200, epoch: 62 | loss: 0.0797383\n",
      "\tspeed: 0.0394s/iter; left time: 334.8849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0778061 Vali Loss: 0.0921145 Test Loss: 0.0953476\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0745407\n",
      "\tspeed: 0.0742s/iter; left time: 621.3464s\n",
      "\titers: 200, epoch: 63 | loss: 0.0743975\n",
      "\tspeed: 0.0392s/iter; left time: 324.0244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0777066 Vali Loss: 0.0919489 Test Loss: 0.0953291\n",
      "Validation loss decreased (0.091994 --> 0.091949).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0782335\n",
      "\tspeed: 0.0740s/iter; left time: 603.4668s\n",
      "\titers: 200, epoch: 64 | loss: 0.0795110\n",
      "\tspeed: 0.0392s/iter; left time: 315.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0776654 Vali Loss: 0.0921476 Test Loss: 0.0954668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0785309\n",
      "\tspeed: 0.0768s/iter; left time: 609.3251s\n",
      "\titers: 200, epoch: 65 | loss: 0.0760095\n",
      "\tspeed: 0.0428s/iter; left time: 334.8433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0777798 Vali Loss: 0.0920429 Test Loss: 0.0953792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0804728\n",
      "\tspeed: 0.0806s/iter; left time: 621.2499s\n",
      "\titers: 200, epoch: 66 | loss: 0.0771747\n",
      "\tspeed: 0.0457s/iter; left time: 347.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 223 | Train Loss: 0.0777001 Vali Loss: 0.0921167 Test Loss: 0.0953689\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0776581\n",
      "\tspeed: 0.0788s/iter; left time: 589.5024s\n",
      "\titers: 200, epoch: 67 | loss: 0.0777184\n",
      "\tspeed: 0.0405s/iter; left time: 298.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0776996 Vali Loss: 0.0922016 Test Loss: 0.0954574\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0778340\n",
      "\tspeed: 0.0763s/iter; left time: 554.2581s\n",
      "\titers: 200, epoch: 68 | loss: 0.0764293\n",
      "\tspeed: 0.0400s/iter; left time: 286.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0777238 Vali Loss: 0.0919908 Test Loss: 0.0953882\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0808484\n",
      "\tspeed: 0.0744s/iter; left time: 523.6256s\n",
      "\titers: 200, epoch: 69 | loss: 0.0757904\n",
      "\tspeed: 0.0391s/iter; left time: 271.0337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0777165 Vali Loss: 0.0920778 Test Loss: 0.0954327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0771801\n",
      "\tspeed: 0.0733s/iter; left time: 499.6473s\n",
      "\titers: 200, epoch: 70 | loss: 0.0775205\n",
      "\tspeed: 0.0390s/iter; left time: 261.7207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0777433 Vali Loss: 0.0921650 Test Loss: 0.0953689\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0796836\n",
      "\tspeed: 0.0727s/iter; left time: 479.4130s\n",
      "\titers: 200, epoch: 71 | loss: 0.0771724\n",
      "\tspeed: 0.0391s/iter; left time: 253.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0776903 Vali Loss: 0.0920136 Test Loss: 0.0953416\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0787829\n",
      "\tspeed: 0.0732s/iter; left time: 466.2414s\n",
      "\titers: 200, epoch: 72 | loss: 0.0768651\n",
      "\tspeed: 0.0391s/iter; left time: 244.8712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0776141 Vali Loss: 0.0920991 Test Loss: 0.0953835\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0818861\n",
      "\tspeed: 0.0763s/iter; left time: 468.6475s\n",
      "\titers: 200, epoch: 73 | loss: 0.0798026\n",
      "\tspeed: 0.0404s/iter; left time: 244.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0777147 Vali Loss: 0.0921051 Test Loss: 0.0953637\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023010335862636566, rmse:0.15169158577919006, mae:0.09532910585403442, rse:0.5353406071662903\n",
      "Intermediate time for DE and pred_len 24: 00h:25m:28.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3120088\n",
      "\tspeed: 0.0671s/iter; left time: 1483.6236s\n",
      "\titers: 200, epoch: 1 | loss: 0.2828692\n",
      "\tspeed: 0.0397s/iter; left time: 874.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.3178178 Vali Loss: 0.2487531 Test Loss: 0.2517730\n",
      "Validation loss decreased (inf --> 0.248753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1684796\n",
      "\tspeed: 0.0756s/iter; left time: 1653.9623s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542087\n",
      "\tspeed: 0.0399s/iter; left time: 868.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1837635 Vali Loss: 0.1655682 Test Loss: 0.1778153\n",
      "Validation loss decreased (0.248753 --> 0.165568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1446750\n",
      "\tspeed: 0.0748s/iter; left time: 1619.2698s\n",
      "\titers: 200, epoch: 3 | loss: 0.1430892\n",
      "\tspeed: 0.0398s/iter; left time: 858.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.1481483 Vali Loss: 0.1533378 Test Loss: 0.1634749\n",
      "Validation loss decreased (0.165568 --> 0.153338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1358662\n",
      "\tspeed: 0.0762s/iter; left time: 1634.2187s\n",
      "\titers: 200, epoch: 4 | loss: 0.1234534\n",
      "\tspeed: 0.0398s/iter; left time: 849.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1317288 Vali Loss: 0.1358286 Test Loss: 0.1459284\n",
      "Validation loss decreased (0.153338 --> 0.135829).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1224981\n",
      "\tspeed: 0.0763s/iter; left time: 1617.6578s\n",
      "\titers: 200, epoch: 5 | loss: 0.1201754\n",
      "\tspeed: 0.0398s/iter; left time: 840.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1191641 Vali Loss: 0.1289537 Test Loss: 0.1392416\n",
      "Validation loss decreased (0.135829 --> 0.128954).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1155574\n",
      "\tspeed: 0.0749s/iter; left time: 1571.8663s\n",
      "\titers: 200, epoch: 6 | loss: 0.1102712\n",
      "\tspeed: 0.0400s/iter; left time: 836.3269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1140824 Vali Loss: 0.1289373 Test Loss: 0.1385676\n",
      "Validation loss decreased (0.128954 --> 0.128937).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1073093\n",
      "\tspeed: 0.0752s/iter; left time: 1561.2815s\n",
      "\titers: 200, epoch: 7 | loss: 0.1130515\n",
      "\tspeed: 0.0399s/iter; left time: 823.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1113036 Vali Loss: 0.1294855 Test Loss: 0.1364959\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1107221\n",
      "\tspeed: 0.0733s/iter; left time: 1505.5170s\n",
      "\titers: 200, epoch: 8 | loss: 0.1083395\n",
      "\tspeed: 0.0395s/iter; left time: 807.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 222 | Train Loss: 0.1094456 Vali Loss: 0.1247737 Test Loss: 0.1334840\n",
      "Validation loss decreased (0.128937 --> 0.124774).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1037984\n",
      "\tspeed: 0.0765s/iter; left time: 1555.3624s\n",
      "\titers: 200, epoch: 9 | loss: 0.1052197\n",
      "\tspeed: 0.0405s/iter; left time: 818.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1081960 Vali Loss: 0.1265113 Test Loss: 0.1353848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1083823\n",
      "\tspeed: 0.0744s/iter; left time: 1495.5990s\n",
      "\titers: 200, epoch: 10 | loss: 0.1116988\n",
      "\tspeed: 0.0398s/iter; left time: 796.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 222 | Train Loss: 0.1073544 Vali Loss: 0.1270837 Test Loss: 0.1350410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1082432\n",
      "\tspeed: 0.0738s/iter; left time: 1467.5069s\n",
      "\titers: 200, epoch: 11 | loss: 0.1020968\n",
      "\tspeed: 0.0396s/iter; left time: 783.0714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1063997 Vali Loss: 0.1269610 Test Loss: 0.1373861\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1057096\n",
      "\tspeed: 0.0733s/iter; left time: 1441.4523s\n",
      "\titers: 200, epoch: 12 | loss: 0.1047711\n",
      "\tspeed: 0.0394s/iter; left time: 771.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 222 | Train Loss: 0.1056055 Vali Loss: 0.1277318 Test Loss: 0.1368269\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004436\n",
      "\tspeed: 0.0729s/iter; left time: 1416.5464s\n",
      "\titers: 200, epoch: 13 | loss: 0.1054419\n",
      "\tspeed: 0.0394s/iter; left time: 761.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 222 | Train Loss: 0.1050366 Vali Loss: 0.1255320 Test Loss: 0.1357212\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1015482\n",
      "\tspeed: 0.0743s/iter; left time: 1427.8147s\n",
      "\titers: 200, epoch: 14 | loss: 0.1040763\n",
      "\tspeed: 0.0406s/iter; left time: 776.1155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1046945 Vali Loss: 0.1261239 Test Loss: 0.1376357\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1088467\n",
      "\tspeed: 0.0741s/iter; left time: 1406.5842s\n",
      "\titers: 200, epoch: 15 | loss: 0.1004357\n",
      "\tspeed: 0.0397s/iter; left time: 750.4796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1042188 Vali Loss: 0.1267985 Test Loss: 0.1382032\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1060328\n",
      "\tspeed: 0.0738s/iter; left time: 1386.1891s\n",
      "\titers: 200, epoch: 16 | loss: 0.1010256\n",
      "\tspeed: 0.0399s/iter; left time: 744.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.1037233 Vali Loss: 0.1250563 Test Loss: 0.1376710\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1039131\n",
      "\tspeed: 0.0760s/iter; left time: 1410.6051s\n",
      "\titers: 200, epoch: 17 | loss: 0.1055680\n",
      "\tspeed: 0.0409s/iter; left time: 755.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1033258 Vali Loss: 0.1260079 Test Loss: 0.1391000\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1008970\n",
      "\tspeed: 0.0751s/iter; left time: 1375.4804s\n",
      "\titers: 200, epoch: 18 | loss: 0.1085616\n",
      "\tspeed: 0.0402s/iter; left time: 732.2536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1031264 Vali Loss: 0.1252104 Test Loss: 0.1390329\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03951077163219452, rmse:0.19877316057682037, mae:0.13348399102687836, rse:0.7038959860801697\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3196181\n",
      "\tspeed: 0.0439s/iter; left time: 970.6078s\n",
      "\titers: 200, epoch: 1 | loss: 0.2781796\n",
      "\tspeed: 0.0409s/iter; left time: 900.4942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.3190983 Vali Loss: 0.2498070 Test Loss: 0.2514441\n",
      "Validation loss decreased (inf --> 0.249807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704350\n",
      "\tspeed: 0.0784s/iter; left time: 1715.2152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1564649\n",
      "\tspeed: 0.0404s/iter; left time: 880.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1857044 Vali Loss: 0.1682590 Test Loss: 0.1800749\n",
      "Validation loss decreased (0.249807 --> 0.168259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1494730\n",
      "\tspeed: 0.0781s/iter; left time: 1691.7725s\n",
      "\titers: 200, epoch: 3 | loss: 0.1399132\n",
      "\tspeed: 0.0408s/iter; left time: 878.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1501206 Vali Loss: 0.1510731 Test Loss: 0.1642591\n",
      "Validation loss decreased (0.168259 --> 0.151073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1408409\n",
      "\tspeed: 0.0810s/iter; left time: 1736.9473s\n",
      "\titers: 200, epoch: 4 | loss: 0.1297565\n",
      "\tspeed: 0.0422s/iter; left time: 900.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 222 | Train Loss: 0.1372262 Vali Loss: 0.1418353 Test Loss: 0.1542032\n",
      "Validation loss decreased (0.151073 --> 0.141835).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1199374\n",
      "\tspeed: 0.0786s/iter; left time: 1668.1800s\n",
      "\titers: 200, epoch: 5 | loss: 0.1194826\n",
      "\tspeed: 0.0405s/iter; left time: 855.2450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1206887 Vali Loss: 0.1322426 Test Loss: 0.1425354\n",
      "Validation loss decreased (0.141835 --> 0.132243).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1144986\n",
      "\tspeed: 0.0781s/iter; left time: 1640.1661s\n",
      "\titers: 200, epoch: 6 | loss: 0.1144773\n",
      "\tspeed: 0.0406s/iter; left time: 848.3984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1144043 Vali Loss: 0.1276644 Test Loss: 0.1390462\n",
      "Validation loss decreased (0.132243 --> 0.127664).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1088416\n",
      "\tspeed: 0.0791s/iter; left time: 1642.8457s\n",
      "\titers: 200, epoch: 7 | loss: 0.1138161\n",
      "\tspeed: 0.0405s/iter; left time: 836.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1116612 Vali Loss: 0.1257650 Test Loss: 0.1381584\n",
      "Validation loss decreased (0.127664 --> 0.125765).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1064970\n",
      "\tspeed: 0.0769s/iter; left time: 1579.8398s\n",
      "\titers: 200, epoch: 8 | loss: 0.1091189\n",
      "\tspeed: 0.0395s/iter; left time: 806.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1097431 Vali Loss: 0.1269665 Test Loss: 0.1401706\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1134989\n",
      "\tspeed: 0.0753s/iter; left time: 1529.6744s\n",
      "\titers: 200, epoch: 9 | loss: 0.1129395\n",
      "\tspeed: 0.0399s/iter; left time: 806.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1085271 Vali Loss: 0.1246775 Test Loss: 0.1382992\n",
      "Validation loss decreased (0.125765 --> 0.124678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043600\n",
      "\tspeed: 0.0760s/iter; left time: 1528.0103s\n",
      "\titers: 200, epoch: 10 | loss: 0.1108025\n",
      "\tspeed: 0.0396s/iter; left time: 791.5526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 222 | Train Loss: 0.1071712 Vali Loss: 0.1241837 Test Loss: 0.1373796\n",
      "Validation loss decreased (0.124678 --> 0.124184).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068431\n",
      "\tspeed: 0.0762s/iter; left time: 1514.9085s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089996\n",
      "\tspeed: 0.0421s/iter; left time: 832.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1064188 Vali Loss: 0.1246435 Test Loss: 0.1392694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1109306\n",
      "\tspeed: 0.0746s/iter; left time: 1467.1309s\n",
      "\titers: 200, epoch: 12 | loss: 0.1041144\n",
      "\tspeed: 0.0395s/iter; left time: 771.7012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1055690 Vali Loss: 0.1237220 Test Loss: 0.1373448\n",
      "Validation loss decreased (0.124184 --> 0.123722).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1062315\n",
      "\tspeed: 0.0775s/iter; left time: 1506.9007s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071509\n",
      "\tspeed: 0.0409s/iter; left time: 791.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1050550 Vali Loss: 0.1269125 Test Loss: 0.1404346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1052811\n",
      "\tspeed: 0.0780s/iter; left time: 1498.8454s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998257\n",
      "\tspeed: 0.0408s/iter; left time: 779.1004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1044519 Vali Loss: 0.1238702 Test Loss: 0.1380830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1036485\n",
      "\tspeed: 0.0767s/iter; left time: 1455.8887s\n",
      "\titers: 200, epoch: 15 | loss: 0.1024580\n",
      "\tspeed: 0.0396s/iter; left time: 747.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1038695 Vali Loss: 0.1235085 Test Loss: 0.1368241\n",
      "Validation loss decreased (0.123722 --> 0.123508).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0980099\n",
      "\tspeed: 0.0778s/iter; left time: 1460.0214s\n",
      "\titers: 200, epoch: 16 | loss: 0.0975179\n",
      "\tspeed: 0.0412s/iter; left time: 769.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1034269 Vali Loss: 0.1240259 Test Loss: 0.1393351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1019813\n",
      "\tspeed: 0.0773s/iter; left time: 1433.6043s\n",
      "\titers: 200, epoch: 17 | loss: 0.1034273\n",
      "\tspeed: 0.0407s/iter; left time: 750.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1030063 Vali Loss: 0.1235911 Test Loss: 0.1384237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0988285\n",
      "\tspeed: 0.0771s/iter; left time: 1413.4803s\n",
      "\titers: 200, epoch: 18 | loss: 0.1079141\n",
      "\tspeed: 0.0406s/iter; left time: 740.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1026656 Vali Loss: 0.1236588 Test Loss: 0.1382035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0983084\n",
      "\tspeed: 0.0755s/iter; left time: 1367.4192s\n",
      "\titers: 200, epoch: 19 | loss: 0.1093846\n",
      "\tspeed: 0.0408s/iter; left time: 735.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1025215 Vali Loss: 0.1238350 Test Loss: 0.1390599\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1046274\n",
      "\tspeed: 0.0842s/iter; left time: 1506.4838s\n",
      "\titers: 200, epoch: 20 | loss: 0.1027091\n",
      "\tspeed: 0.0471s/iter; left time: 836.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.89s\n",
      "Steps: 222 | Train Loss: 0.1023637 Vali Loss: 0.1229947 Test Loss: 0.1373743\n",
      "Validation loss decreased (0.123508 --> 0.122995).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1011196\n",
      "\tspeed: 0.0796s/iter; left time: 1406.0143s\n",
      "\titers: 200, epoch: 21 | loss: 0.1021279\n",
      "\tspeed: 0.0406s/iter; left time: 712.3921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1019171 Vali Loss: 0.1235510 Test Loss: 0.1387734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1006793\n",
      "\tspeed: 0.0768s/iter; left time: 1339.0753s\n",
      "\titers: 200, epoch: 22 | loss: 0.0976110\n",
      "\tspeed: 0.0410s/iter; left time: 711.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1015931 Vali Loss: 0.1237752 Test Loss: 0.1394017\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0991917\n",
      "\tspeed: 0.0771s/iter; left time: 1327.8695s\n",
      "\titers: 200, epoch: 23 | loss: 0.1012041\n",
      "\tspeed: 0.0407s/iter; left time: 696.8799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1015213 Vali Loss: 0.1237825 Test Loss: 0.1391756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1008084\n",
      "\tspeed: 0.0771s/iter; left time: 1310.5149s\n",
      "\titers: 200, epoch: 24 | loss: 0.1030595\n",
      "\tspeed: 0.0404s/iter; left time: 682.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1012570 Vali Loss: 0.1235957 Test Loss: 0.1386071\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0978132\n",
      "\tspeed: 0.0782s/iter; left time: 1310.8661s\n",
      "\titers: 200, epoch: 25 | loss: 0.0998615\n",
      "\tspeed: 0.0404s/iter; left time: 674.2988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1011324 Vali Loss: 0.1234459 Test Loss: 0.1383376\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1041884\n",
      "\tspeed: 0.0779s/iter; left time: 1289.4507s\n",
      "\titers: 200, epoch: 26 | loss: 0.0976797\n",
      "\tspeed: 0.0406s/iter; left time: 667.5932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1009737 Vali Loss: 0.1236557 Test Loss: 0.1385072\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1013719\n",
      "\tspeed: 0.0776s/iter; left time: 1266.9281s\n",
      "\titers: 200, epoch: 27 | loss: 0.0994971\n",
      "\tspeed: 0.0408s/iter; left time: 662.3004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1008846 Vali Loss: 0.1234540 Test Loss: 0.1386208\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1029933\n",
      "\tspeed: 0.0771s/iter; left time: 1242.3284s\n",
      "\titers: 200, epoch: 28 | loss: 0.1025555\n",
      "\tspeed: 0.0410s/iter; left time: 657.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1007393 Vali Loss: 0.1236892 Test Loss: 0.1395062\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0992379\n",
      "\tspeed: 0.0764s/iter; left time: 1213.0779s\n",
      "\titers: 200, epoch: 29 | loss: 0.1044127\n",
      "\tspeed: 0.0427s/iter; left time: 674.4539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1006494 Vali Loss: 0.1237306 Test Loss: 0.1395274\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1022635\n",
      "\tspeed: 0.0845s/iter; left time: 1323.3602s\n",
      "\titers: 200, epoch: 30 | loss: 0.0965984\n",
      "\tspeed: 0.0470s/iter; left time: 731.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:10.76s\n",
      "Steps: 222 | Train Loss: 0.1005594 Vali Loss: 0.1237423 Test Loss: 0.1394334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044695574790239334, rmse:0.21141327917575836, mae:0.13737419247627258, rse:0.7486571669578552\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:37.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3160385\n",
      "\tspeed: 0.0662s/iter; left time: 1463.4326s\n",
      "\titers: 200, epoch: 1 | loss: 0.2852874\n",
      "\tspeed: 0.0400s/iter; left time: 879.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.3150296 Vali Loss: 0.2459897 Test Loss: 0.2499872\n",
      "Validation loss decreased (inf --> 0.245990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1794195\n",
      "\tspeed: 0.0750s/iter; left time: 1641.5752s\n",
      "\titers: 200, epoch: 2 | loss: 0.1582432\n",
      "\tspeed: 0.0400s/iter; left time: 871.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1834127 Vali Loss: 0.1671697 Test Loss: 0.1793368\n",
      "Validation loss decreased (0.245990 --> 0.167170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1509220\n",
      "\tspeed: 0.0762s/iter; left time: 1649.2361s\n",
      "\titers: 200, epoch: 3 | loss: 0.1450536\n",
      "\tspeed: 0.0401s/iter; left time: 863.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1501372 Vali Loss: 0.1525110 Test Loss: 0.1645670\n",
      "Validation loss decreased (0.167170 --> 0.152511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1289448\n",
      "\tspeed: 0.0767s/iter; left time: 1643.6820s\n",
      "\titers: 200, epoch: 4 | loss: 0.1234911\n",
      "\tspeed: 0.0408s/iter; left time: 870.0094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1330118 Vali Loss: 0.1407652 Test Loss: 0.1521861\n",
      "Validation loss decreased (0.152511 --> 0.140765).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1203124\n",
      "\tspeed: 0.0798s/iter; left time: 1692.6862s\n",
      "\titers: 200, epoch: 5 | loss: 0.1190618\n",
      "\tspeed: 0.0411s/iter; left time: 867.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1233455 Vali Loss: 0.1364807 Test Loss: 0.1491483\n",
      "Validation loss decreased (0.140765 --> 0.136481).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1168736\n",
      "\tspeed: 0.0782s/iter; left time: 1640.5020s\n",
      "\titers: 200, epoch: 6 | loss: 0.1186200\n",
      "\tspeed: 0.0404s/iter; left time: 844.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1193331 Vali Loss: 0.1371163 Test Loss: 0.1464587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1140976\n",
      "\tspeed: 0.0767s/iter; left time: 1593.9357s\n",
      "\titers: 200, epoch: 7 | loss: 0.1163201\n",
      "\tspeed: 0.0408s/iter; left time: 842.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1166404 Vali Loss: 0.1322793 Test Loss: 0.1430868\n",
      "Validation loss decreased (0.136481 --> 0.132279).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1142260\n",
      "\tspeed: 0.0788s/iter; left time: 1619.2348s\n",
      "\titers: 200, epoch: 8 | loss: 0.1112217\n",
      "\tspeed: 0.0425s/iter; left time: 869.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.1152146 Vali Loss: 0.1346572 Test Loss: 0.1430740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1107220\n",
      "\tspeed: 0.0769s/iter; left time: 1563.5358s\n",
      "\titers: 200, epoch: 9 | loss: 0.1102567\n",
      "\tspeed: 0.0405s/iter; left time: 819.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1136390 Vali Loss: 0.1349594 Test Loss: 0.1436609\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1115613\n",
      "\tspeed: 0.0771s/iter; left time: 1550.8270s\n",
      "\titers: 200, epoch: 10 | loss: 0.1142841\n",
      "\tspeed: 0.0420s/iter; left time: 839.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.1124932 Vali Loss: 0.1337960 Test Loss: 0.1440065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1145137\n",
      "\tspeed: 0.0756s/iter; left time: 1503.8995s\n",
      "\titers: 200, epoch: 11 | loss: 0.1135386\n",
      "\tspeed: 0.0403s/iter; left time: 796.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1114009 Vali Loss: 0.1328952 Test Loss: 0.1435874\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1118057\n",
      "\tspeed: 0.0757s/iter; left time: 1487.2970s\n",
      "\titers: 200, epoch: 12 | loss: 0.1128443\n",
      "\tspeed: 0.0398s/iter; left time: 778.9951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.1105021 Vali Loss: 0.1314874 Test Loss: 0.1427216\n",
      "Validation loss decreased (0.132279 --> 0.131487).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1146282\n",
      "\tspeed: 0.0770s/iter; left time: 1496.4968s\n",
      "\titers: 200, epoch: 13 | loss: 0.1072921\n",
      "\tspeed: 0.0396s/iter; left time: 765.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1101488 Vali Loss: 0.1318278 Test Loss: 0.1439553\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1116444\n",
      "\tspeed: 0.0759s/iter; left time: 1458.1877s\n",
      "\titers: 200, epoch: 14 | loss: 0.1087587\n",
      "\tspeed: 0.0409s/iter; left time: 782.5124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1095756 Vali Loss: 0.1298258 Test Loss: 0.1418812\n",
      "Validation loss decreased (0.131487 --> 0.129826).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1105963\n",
      "\tspeed: 0.0786s/iter; left time: 1492.6653s\n",
      "\titers: 200, epoch: 15 | loss: 0.1070820\n",
      "\tspeed: 0.0407s/iter; left time: 768.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1088665 Vali Loss: 0.1294969 Test Loss: 0.1415620\n",
      "Validation loss decreased (0.129826 --> 0.129497).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076548\n",
      "\tspeed: 0.0789s/iter; left time: 1481.0509s\n",
      "\titers: 200, epoch: 16 | loss: 0.1073347\n",
      "\tspeed: 0.0414s/iter; left time: 772.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1082460 Vali Loss: 0.1303927 Test Loss: 0.1423751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1092361\n",
      "\tspeed: 0.0768s/iter; left time: 1425.2949s\n",
      "\titers: 200, epoch: 17 | loss: 0.1093917\n",
      "\tspeed: 0.0419s/iter; left time: 773.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1080450 Vali Loss: 0.1298912 Test Loss: 0.1420830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1105295\n",
      "\tspeed: 0.0781s/iter; left time: 1430.9530s\n",
      "\titers: 200, epoch: 18 | loss: 0.1018491\n",
      "\tspeed: 0.0414s/iter; left time: 755.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1077800 Vali Loss: 0.1302249 Test Loss: 0.1432978\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1099272\n",
      "\tspeed: 0.0785s/iter; left time: 1420.3686s\n",
      "\titers: 200, epoch: 19 | loss: 0.1049790\n",
      "\tspeed: 0.0420s/iter; left time: 755.6299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1072463 Vali Loss: 0.1305036 Test Loss: 0.1428536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1084905\n",
      "\tspeed: 0.0769s/iter; left time: 1375.4679s\n",
      "\titers: 200, epoch: 20 | loss: 0.1098540\n",
      "\tspeed: 0.0411s/iter; left time: 731.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1070976 Vali Loss: 0.1294234 Test Loss: 0.1430379\n",
      "Validation loss decreased (0.129497 --> 0.129423).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1050014\n",
      "\tspeed: 0.0781s/iter; left time: 1379.1143s\n",
      "\titers: 200, epoch: 21 | loss: 0.1094897\n",
      "\tspeed: 0.0405s/iter; left time: 710.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1067640 Vali Loss: 0.1298082 Test Loss: 0.1438436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0998618\n",
      "\tspeed: 0.0761s/iter; left time: 1327.5938s\n",
      "\titers: 200, epoch: 22 | loss: 0.1085929\n",
      "\tspeed: 0.0405s/iter; left time: 701.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1065350 Vali Loss: 0.1299801 Test Loss: 0.1437604\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1055508\n",
      "\tspeed: 0.0778s/iter; left time: 1339.5027s\n",
      "\titers: 200, epoch: 23 | loss: 0.1050243\n",
      "\tspeed: 0.0404s/iter; left time: 692.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1063968 Vali Loss: 0.1302681 Test Loss: 0.1442521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1080379\n",
      "\tspeed: 0.0763s/iter; left time: 1296.2466s\n",
      "\titers: 200, epoch: 24 | loss: 0.1065259\n",
      "\tspeed: 0.0409s/iter; left time: 691.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1062325 Vali Loss: 0.1296166 Test Loss: 0.1445673\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1107330\n",
      "\tspeed: 0.0777s/iter; left time: 1304.0975s\n",
      "\titers: 200, epoch: 25 | loss: 0.1042513\n",
      "\tspeed: 0.0412s/iter; left time: 686.6923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1059568 Vali Loss: 0.1307608 Test Loss: 0.1459942\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1039019\n",
      "\tspeed: 0.0774s/iter; left time: 1281.8574s\n",
      "\titers: 200, epoch: 26 | loss: 0.1060900\n",
      "\tspeed: 0.0407s/iter; left time: 670.2094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1057834 Vali Loss: 0.1303077 Test Loss: 0.1442277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1048598\n",
      "\tspeed: 0.0759s/iter; left time: 1239.4934s\n",
      "\titers: 200, epoch: 27 | loss: 0.1066823\n",
      "\tspeed: 0.0414s/iter; left time: 671.8696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1056601 Vali Loss: 0.1300836 Test Loss: 0.1439911\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1041795\n",
      "\tspeed: 0.0780s/iter; left time: 1256.5321s\n",
      "\titers: 200, epoch: 28 | loss: 0.1044775\n",
      "\tspeed: 0.0402s/iter; left time: 643.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1054679 Vali Loss: 0.1298668 Test Loss: 0.1449594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1034368\n",
      "\tspeed: 0.0750s/iter; left time: 1190.9459s\n",
      "\titers: 200, epoch: 29 | loss: 0.0959986\n",
      "\tspeed: 0.0403s/iter; left time: 636.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 222 | Train Loss: 0.1054535 Vali Loss: 0.1300879 Test Loss: 0.1443095\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1000299\n",
      "\tspeed: 0.0761s/iter; left time: 1191.8782s\n",
      "\titers: 200, epoch: 30 | loss: 0.1036485\n",
      "\tspeed: 0.0397s/iter; left time: 618.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1053133 Vali Loss: 0.1301018 Test Loss: 0.1451761\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04699910432100296, rmse:0.2167927622795105, mae:0.14303791522979736, rse:0.7678974270820618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3134314\n",
      "\tspeed: 0.0433s/iter; left time: 957.3622s\n",
      "\titers: 200, epoch: 1 | loss: 0.2848532\n",
      "\tspeed: 0.0406s/iter; left time: 893.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.3182058 Vali Loss: 0.2471261 Test Loss: 0.2510278\n",
      "Validation loss decreased (inf --> 0.247126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1725518\n",
      "\tspeed: 0.0791s/iter; left time: 1729.6997s\n",
      "\titers: 200, epoch: 2 | loss: 0.1595807\n",
      "\tspeed: 0.0427s/iter; left time: 930.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1847319 Vali Loss: 0.1659123 Test Loss: 0.1796440\n",
      "Validation loss decreased (0.247126 --> 0.165912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1479641\n",
      "\tspeed: 0.0784s/iter; left time: 1698.8299s\n",
      "\titers: 200, epoch: 3 | loss: 0.1434374\n",
      "\tspeed: 0.0406s/iter; left time: 875.4965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1488526 Vali Loss: 0.1478806 Test Loss: 0.1602009\n",
      "Validation loss decreased (0.165912 --> 0.147881).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1283762\n",
      "\tspeed: 0.0774s/iter; left time: 1659.3878s\n",
      "\titers: 200, epoch: 4 | loss: 0.1234551\n",
      "\tspeed: 0.0409s/iter; left time: 873.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1319872 Vali Loss: 0.1415304 Test Loss: 0.1526927\n",
      "Validation loss decreased (0.147881 --> 0.141530).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1217633\n",
      "\tspeed: 0.0786s/iter; left time: 1667.3252s\n",
      "\titers: 200, epoch: 5 | loss: 0.1218934\n",
      "\tspeed: 0.0398s/iter; left time: 840.2682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1241210 Vali Loss: 0.1371667 Test Loss: 0.1484579\n",
      "Validation loss decreased (0.141530 --> 0.137167).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1200382\n",
      "\tspeed: 0.0785s/iter; left time: 1647.8762s\n",
      "\titers: 200, epoch: 6 | loss: 0.1204477\n",
      "\tspeed: 0.0412s/iter; left time: 860.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1201034 Vali Loss: 0.1342497 Test Loss: 0.1444621\n",
      "Validation loss decreased (0.137167 --> 0.134250).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1134561\n",
      "\tspeed: 0.0784s/iter; left time: 1629.1457s\n",
      "\titers: 200, epoch: 7 | loss: 0.1206576\n",
      "\tspeed: 0.0417s/iter; left time: 861.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1172729 Vali Loss: 0.1348342 Test Loss: 0.1469767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1157297\n",
      "\tspeed: 0.0775s/iter; left time: 1593.3951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1118097\n",
      "\tspeed: 0.0412s/iter; left time: 842.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1157046 Vali Loss: 0.1346547 Test Loss: 0.1471184\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1152952\n",
      "\tspeed: 0.0809s/iter; left time: 1645.0206s\n",
      "\titers: 200, epoch: 9 | loss: 0.1150558\n",
      "\tspeed: 0.0414s/iter; left time: 836.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1138273 Vali Loss: 0.1341886 Test Loss: 0.1473801\n",
      "Validation loss decreased (0.134250 --> 0.134189).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1177783\n",
      "\tspeed: 0.0793s/iter; left time: 1593.3917s\n",
      "\titers: 200, epoch: 10 | loss: 0.1105330\n",
      "\tspeed: 0.0399s/iter; left time: 797.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.1127190 Vali Loss: 0.1322618 Test Loss: 0.1459188\n",
      "Validation loss decreased (0.134189 --> 0.132262).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1074785\n",
      "\tspeed: 0.0803s/iter; left time: 1596.7035s\n",
      "\titers: 200, epoch: 11 | loss: 0.1117938\n",
      "\tspeed: 0.0418s/iter; left time: 825.9790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1115987 Vali Loss: 0.1308876 Test Loss: 0.1448717\n",
      "Validation loss decreased (0.132262 --> 0.130888).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1077681\n",
      "\tspeed: 0.0780s/iter; left time: 1533.6091s\n",
      "\titers: 200, epoch: 12 | loss: 0.1056866\n",
      "\tspeed: 0.0408s/iter; left time: 798.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1106472 Vali Loss: 0.1305142 Test Loss: 0.1442067\n",
      "Validation loss decreased (0.130888 --> 0.130514).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1041864\n",
      "\tspeed: 0.0798s/iter; left time: 1550.4200s\n",
      "\titers: 200, epoch: 13 | loss: 0.1073992\n",
      "\tspeed: 0.0406s/iter; left time: 785.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1099900 Vali Loss: 0.1327355 Test Loss: 0.1475619\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1155894\n",
      "\tspeed: 0.0776s/iter; left time: 1491.4455s\n",
      "\titers: 200, epoch: 14 | loss: 0.1091723\n",
      "\tspeed: 0.0408s/iter; left time: 779.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1091139 Vali Loss: 0.1320471 Test Loss: 0.1462544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1055505\n",
      "\tspeed: 0.0767s/iter; left time: 1456.7232s\n",
      "\titers: 200, epoch: 15 | loss: 0.1130039\n",
      "\tspeed: 0.0400s/iter; left time: 754.8072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.1084717 Vali Loss: 0.1310398 Test Loss: 0.1438026\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1042067\n",
      "\tspeed: 0.0771s/iter; left time: 1446.3156s\n",
      "\titers: 200, epoch: 16 | loss: 0.0997970\n",
      "\tspeed: 0.0412s/iter; left time: 768.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1080408 Vali Loss: 0.1311243 Test Loss: 0.1438619\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1098455\n",
      "\tspeed: 0.0765s/iter; left time: 1418.8179s\n",
      "\titers: 200, epoch: 17 | loss: 0.1037619\n",
      "\tspeed: 0.0403s/iter; left time: 743.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1079397 Vali Loss: 0.1319663 Test Loss: 0.1447473\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1071015\n",
      "\tspeed: 0.0775s/iter; left time: 1421.0174s\n",
      "\titers: 200, epoch: 18 | loss: 0.1101864\n",
      "\tspeed: 0.0399s/iter; left time: 727.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1072515 Vali Loss: 0.1322952 Test Loss: 0.1471865\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1061305\n",
      "\tspeed: 0.0769s/iter; left time: 1392.3785s\n",
      "\titers: 200, epoch: 19 | loss: 0.1040870\n",
      "\tspeed: 0.0399s/iter; left time: 718.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1069052 Vali Loss: 0.1308526 Test Loss: 0.1446468\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1091669\n",
      "\tspeed: 0.0771s/iter; left time: 1379.2524s\n",
      "\titers: 200, epoch: 20 | loss: 0.1074627\n",
      "\tspeed: 0.0400s/iter; left time: 710.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1064139 Vali Loss: 0.1318033 Test Loss: 0.1465521\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1108413\n",
      "\tspeed: 0.0773s/iter; left time: 1364.7536s\n",
      "\titers: 200, epoch: 21 | loss: 0.1060411\n",
      "\tspeed: 0.0400s/iter; left time: 702.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1061974 Vali Loss: 0.1309398 Test Loss: 0.1447262\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1073828\n",
      "\tspeed: 0.0761s/iter; left time: 1326.6623s\n",
      "\titers: 200, epoch: 22 | loss: 0.1102774\n",
      "\tspeed: 0.0398s/iter; left time: 690.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 222 | Train Loss: 0.1058840 Vali Loss: 0.1305068 Test Loss: 0.1446483\n",
      "Validation loss decreased (0.130514 --> 0.130507).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1096206\n",
      "\tspeed: 0.0782s/iter; left time: 1347.0117s\n",
      "\titers: 200, epoch: 23 | loss: 0.1060370\n",
      "\tspeed: 0.0400s/iter; left time: 685.3608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.1056253 Vali Loss: 0.1307428 Test Loss: 0.1447878\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1066529\n",
      "\tspeed: 0.0761s/iter; left time: 1293.8580s\n",
      "\titers: 200, epoch: 24 | loss: 0.1095800\n",
      "\tspeed: 0.0398s/iter; left time: 673.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1053386 Vali Loss: 0.1312687 Test Loss: 0.1454325\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1034412\n",
      "\tspeed: 0.0763s/iter; left time: 1279.0610s\n",
      "\titers: 200, epoch: 25 | loss: 0.1082877\n",
      "\tspeed: 0.0398s/iter; left time: 663.0548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1053188 Vali Loss: 0.1309672 Test Loss: 0.1450019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1063517\n",
      "\tspeed: 0.0765s/iter; left time: 1266.2401s\n",
      "\titers: 200, epoch: 26 | loss: 0.1030888\n",
      "\tspeed: 0.0399s/iter; left time: 656.7736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1050740 Vali Loss: 0.1309214 Test Loss: 0.1463749\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1022401\n",
      "\tspeed: 0.0765s/iter; left time: 1248.7990s\n",
      "\titers: 200, epoch: 27 | loss: 0.1065170\n",
      "\tspeed: 0.0400s/iter; left time: 648.6027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1048471 Vali Loss: 0.1308488 Test Loss: 0.1453600\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1037174\n",
      "\tspeed: 0.0757s/iter; left time: 1219.3252s\n",
      "\titers: 200, epoch: 28 | loss: 0.1042717\n",
      "\tspeed: 0.0399s/iter; left time: 638.6398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1047511 Vali Loss: 0.1309701 Test Loss: 0.1455828\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1021071\n",
      "\tspeed: 0.0772s/iter; left time: 1226.7973s\n",
      "\titers: 200, epoch: 29 | loss: 0.1095787\n",
      "\tspeed: 0.0404s/iter; left time: 638.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1045022 Vali Loss: 0.1314244 Test Loss: 0.1463719\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1075136\n",
      "\tspeed: 0.0778s/iter; left time: 1219.0706s\n",
      "\titers: 200, epoch: 30 | loss: 0.1082052\n",
      "\tspeed: 0.0407s/iter; left time: 633.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1044788 Vali Loss: 0.1309789 Test Loss: 0.1461553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1018802\n",
      "\tspeed: 0.0766s/iter; left time: 1182.3101s\n",
      "\titers: 200, epoch: 31 | loss: 0.1046902\n",
      "\tspeed: 0.0400s/iter; left time: 613.7674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1043047 Vali Loss: 0.1302619 Test Loss: 0.1439088\n",
      "Validation loss decreased (0.130507 --> 0.130262).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1064198\n",
      "\tspeed: 0.0818s/iter; left time: 1245.1604s\n",
      "\titers: 200, epoch: 32 | loss: 0.1020201\n",
      "\tspeed: 0.0403s/iter; left time: 608.7371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1043226 Vali Loss: 0.1313447 Test Loss: 0.1463797\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1040244\n",
      "\tspeed: 0.0767s/iter; left time: 1150.9636s\n",
      "\titers: 200, epoch: 33 | loss: 0.1053780\n",
      "\tspeed: 0.0399s/iter; left time: 594.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1042472 Vali Loss: 0.1315507 Test Loss: 0.1462973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1053478\n",
      "\tspeed: 0.0781s/iter; left time: 1153.9868s\n",
      "\titers: 200, epoch: 34 | loss: 0.1041543\n",
      "\tspeed: 0.0413s/iter; left time: 606.0733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.1040630 Vali Loss: 0.1307516 Test Loss: 0.1457314\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1082480\n",
      "\tspeed: 0.0782s/iter; left time: 1137.6368s\n",
      "\titers: 200, epoch: 35 | loss: 0.1034435\n",
      "\tspeed: 0.0399s/iter; left time: 576.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1039880 Vali Loss: 0.1310570 Test Loss: 0.1458926\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1037588\n",
      "\tspeed: 0.0765s/iter; left time: 1095.8649s\n",
      "\titers: 200, epoch: 36 | loss: 0.1025304\n",
      "\tspeed: 0.0399s/iter; left time: 568.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1039073 Vali Loss: 0.1312822 Test Loss: 0.1467291\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1054882\n",
      "\tspeed: 0.0769s/iter; left time: 1085.2235s\n",
      "\titers: 200, epoch: 37 | loss: 0.1046328\n",
      "\tspeed: 0.0401s/iter; left time: 561.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1040142 Vali Loss: 0.1309390 Test Loss: 0.1461090\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1049726\n",
      "\tspeed: 0.0785s/iter; left time: 1090.0453s\n",
      "\titers: 200, epoch: 38 | loss: 0.1036366\n",
      "\tspeed: 0.0460s/iter; left time: 634.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 222 | Train Loss: 0.1038193 Vali Loss: 0.1314593 Test Loss: 0.1464235\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1029386\n",
      "\tspeed: 0.0769s/iter; left time: 1050.7881s\n",
      "\titers: 200, epoch: 39 | loss: 0.1060454\n",
      "\tspeed: 0.0402s/iter; left time: 544.8812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1038140 Vali Loss: 0.1311432 Test Loss: 0.1459764\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1014578\n",
      "\tspeed: 0.0769s/iter; left time: 1033.1096s\n",
      "\titers: 200, epoch: 40 | loss: 0.1029208\n",
      "\tspeed: 0.0399s/iter; left time: 532.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 222 | Train Loss: 0.1037164 Vali Loss: 0.1309557 Test Loss: 0.1460410\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1061487\n",
      "\tspeed: 0.0763s/iter; left time: 1008.4474s\n",
      "\titers: 200, epoch: 41 | loss: 0.0976441\n",
      "\tspeed: 0.0399s/iter; left time: 523.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1036925 Vali Loss: 0.1313838 Test Loss: 0.1462523\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048019107431173325, rmse:0.21913263201713562, mae:0.14390885829925537, rse:0.7761853933334351\n",
      "Intermediate time for DE and pred_len 168: 00h:14m:14.10s\n",
      "Intermediate time for DE: 00h:49m:20.48s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3172464\n",
      "\tspeed: 0.0676s/iter; left time: 1499.6810s\n",
      "\titers: 200, epoch: 1 | loss: 0.2911912\n",
      "\tspeed: 0.0394s/iter; left time: 869.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.3194493 Vali Loss: 0.2587424 Test Loss: 0.2758079\n",
      "Validation loss decreased (inf --> 0.258742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1538503\n",
      "\tspeed: 0.0749s/iter; left time: 1646.9232s\n",
      "\titers: 200, epoch: 2 | loss: 0.1359521\n",
      "\tspeed: 0.0393s/iter; left time: 859.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.1728916 Vali Loss: 0.1372509 Test Loss: 0.1586481\n",
      "Validation loss decreased (0.258742 --> 0.137251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1302016\n",
      "\tspeed: 0.0744s/iter; left time: 1618.3397s\n",
      "\titers: 200, epoch: 3 | loss: 0.1173900\n",
      "\tspeed: 0.0393s/iter; left time: 851.3176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.1245386 Vali Loss: 0.1272233 Test Loss: 0.1435134\n",
      "Validation loss decreased (0.137251 --> 0.127223).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1166042\n",
      "\tspeed: 0.0737s/iter; left time: 1587.6580s\n",
      "\titers: 200, epoch: 4 | loss: 0.1130571\n",
      "\tspeed: 0.0394s/iter; left time: 844.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.1166201 Vali Loss: 0.1202792 Test Loss: 0.1355263\n",
      "Validation loss decreased (0.127223 --> 0.120279).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032065\n",
      "\tspeed: 0.0738s/iter; left time: 1572.8525s\n",
      "\titers: 200, epoch: 5 | loss: 0.1010945\n",
      "\tspeed: 0.0390s/iter; left time: 828.0760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.1043898 Vali Loss: 0.1043322 Test Loss: 0.1201680\n",
      "Validation loss decreased (0.120279 --> 0.104332).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982173\n",
      "\tspeed: 0.0765s/iter; left time: 1613.3667s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993224\n",
      "\tspeed: 0.0397s/iter; left time: 832.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0966554 Vali Loss: 0.1014294 Test Loss: 0.1163308\n",
      "Validation loss decreased (0.104332 --> 0.101429).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0918209\n",
      "\tspeed: 0.0742s/iter; left time: 1548.9568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0940941\n",
      "\tspeed: 0.0391s/iter; left time: 812.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0939420 Vali Loss: 0.1011624 Test Loss: 0.1163465\n",
      "Validation loss decreased (0.101429 --> 0.101162).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0889259\n",
      "\tspeed: 0.0735s/iter; left time: 1517.8116s\n",
      "\titers: 200, epoch: 8 | loss: 0.0898564\n",
      "\tspeed: 0.0390s/iter; left time: 801.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0922313 Vali Loss: 0.1001768 Test Loss: 0.1154227\n",
      "Validation loss decreased (0.101162 --> 0.100177).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0934184\n",
      "\tspeed: 0.0759s/iter; left time: 1548.9833s\n",
      "\titers: 200, epoch: 9 | loss: 0.0902843\n",
      "\tspeed: 0.0400s/iter; left time: 813.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0914160 Vali Loss: 0.0994237 Test Loss: 0.1145260\n",
      "Validation loss decreased (0.100177 --> 0.099424).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0934615\n",
      "\tspeed: 0.0764s/iter; left time: 1543.3806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0931610\n",
      "\tspeed: 0.0393s/iter; left time: 789.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0903588 Vali Loss: 0.0988806 Test Loss: 0.1134765\n",
      "Validation loss decreased (0.099424 --> 0.098881).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0917882\n",
      "\tspeed: 0.0781s/iter; left time: 1560.2347s\n",
      "\titers: 200, epoch: 11 | loss: 0.0972192\n",
      "\tspeed: 0.0403s/iter; left time: 800.0261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0890516 Vali Loss: 0.0987060 Test Loss: 0.1134306\n",
      "Validation loss decreased (0.098881 --> 0.098706).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0888321\n",
      "\tspeed: 0.0782s/iter; left time: 1544.1384s\n",
      "\titers: 200, epoch: 12 | loss: 0.0896715\n",
      "\tspeed: 0.0392s/iter; left time: 770.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0883189 Vali Loss: 0.0983071 Test Loss: 0.1134429\n",
      "Validation loss decreased (0.098706 --> 0.098307).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0865293\n",
      "\tspeed: 0.0763s/iter; left time: 1488.9501s\n",
      "\titers: 200, epoch: 13 | loss: 0.0834839\n",
      "\tspeed: 0.0392s/iter; left time: 761.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0873309 Vali Loss: 0.0978332 Test Loss: 0.1129300\n",
      "Validation loss decreased (0.098307 --> 0.097833).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0916800\n",
      "\tspeed: 0.0730s/iter; left time: 1409.6141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0892457\n",
      "\tspeed: 0.0392s/iter; left time: 753.2440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0866597 Vali Loss: 0.0968086 Test Loss: 0.1122556\n",
      "Validation loss decreased (0.097833 --> 0.096809).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0867429\n",
      "\tspeed: 0.0736s/iter; left time: 1404.1031s\n",
      "\titers: 200, epoch: 15 | loss: 0.0846711\n",
      "\tspeed: 0.0390s/iter; left time: 740.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 223 | Train Loss: 0.0857993 Vali Loss: 0.0965055 Test Loss: 0.1120551\n",
      "Validation loss decreased (0.096809 --> 0.096505).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0878152\n",
      "\tspeed: 0.0739s/iter; left time: 1393.3193s\n",
      "\titers: 200, epoch: 16 | loss: 0.0843875\n",
      "\tspeed: 0.0391s/iter; left time: 734.0823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0850914 Vali Loss: 0.0958131 Test Loss: 0.1115721\n",
      "Validation loss decreased (0.096505 --> 0.095813).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0818610\n",
      "\tspeed: 0.0734s/iter; left time: 1368.5459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0821096\n",
      "\tspeed: 0.0389s/iter; left time: 721.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0843256 Vali Loss: 0.0960370 Test Loss: 0.1116688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0835144\n",
      "\tspeed: 0.0736s/iter; left time: 1354.6001s\n",
      "\titers: 200, epoch: 18 | loss: 0.0845849\n",
      "\tspeed: 0.0392s/iter; left time: 717.9534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0836739 Vali Loss: 0.0963231 Test Loss: 0.1118983\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0853580\n",
      "\tspeed: 0.0729s/iter; left time: 1325.4477s\n",
      "\titers: 200, epoch: 19 | loss: 0.0846943\n",
      "\tspeed: 0.0392s/iter; left time: 709.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0832169 Vali Loss: 0.0951216 Test Loss: 0.1111098\n",
      "Validation loss decreased (0.095813 --> 0.095122).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0799565\n",
      "\tspeed: 0.0762s/iter; left time: 1369.1735s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820763\n",
      "\tspeed: 0.0409s/iter; left time: 729.8916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0826018 Vali Loss: 0.0958598 Test Loss: 0.1114897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0783941\n",
      "\tspeed: 0.0760s/iter; left time: 1347.7161s\n",
      "\titers: 200, epoch: 21 | loss: 0.0869042\n",
      "\tspeed: 0.0409s/iter; left time: 721.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0822438 Vali Loss: 0.0943711 Test Loss: 0.1098465\n",
      "Validation loss decreased (0.095122 --> 0.094371).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0791188\n",
      "\tspeed: 0.0748s/iter; left time: 1310.4481s\n",
      "\titers: 200, epoch: 22 | loss: 0.0813810\n",
      "\tspeed: 0.0392s/iter; left time: 683.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0816026 Vali Loss: 0.0940653 Test Loss: 0.1096369\n",
      "Validation loss decreased (0.094371 --> 0.094065).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0779078\n",
      "\tspeed: 0.0727s/iter; left time: 1257.3737s\n",
      "\titers: 200, epoch: 23 | loss: 0.0853700\n",
      "\tspeed: 0.0391s/iter; left time: 673.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 223 | Train Loss: 0.0813716 Vali Loss: 0.0938074 Test Loss: 0.1096288\n",
      "Validation loss decreased (0.094065 --> 0.093807).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0782516\n",
      "\tspeed: 0.0752s/iter; left time: 1284.6129s\n",
      "\titers: 200, epoch: 24 | loss: 0.0811806\n",
      "\tspeed: 0.0391s/iter; left time: 663.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0811679 Vali Loss: 0.0936584 Test Loss: 0.1093691\n",
      "Validation loss decreased (0.093807 --> 0.093658).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0819161\n",
      "\tspeed: 0.0731s/iter; left time: 1231.2488s\n",
      "\titers: 200, epoch: 25 | loss: 0.0838251\n",
      "\tspeed: 0.0393s/iter; left time: 657.8029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0808082 Vali Loss: 0.0941157 Test Loss: 0.1099126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799747\n",
      "\tspeed: 0.0738s/iter; left time: 1226.6529s\n",
      "\titers: 200, epoch: 26 | loss: 0.0805894\n",
      "\tspeed: 0.0389s/iter; left time: 643.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0806198 Vali Loss: 0.0941157 Test Loss: 0.1096665\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0856202\n",
      "\tspeed: 0.0747s/iter; left time: 1226.0753s\n",
      "\titers: 200, epoch: 27 | loss: 0.0803079\n",
      "\tspeed: 0.0390s/iter; left time: 636.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 223 | Train Loss: 0.0804526 Vali Loss: 0.0937368 Test Loss: 0.1094536\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0807653\n",
      "\tspeed: 0.0723s/iter; left time: 1169.8638s\n",
      "\titers: 200, epoch: 28 | loss: 0.0799502\n",
      "\tspeed: 0.0393s/iter; left time: 631.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 223 | Train Loss: 0.0802650 Vali Loss: 0.0934301 Test Loss: 0.1091270\n",
      "Validation loss decreased (0.093658 --> 0.093430).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0800759\n",
      "\tspeed: 0.0761s/iter; left time: 1213.9003s\n",
      "\titers: 200, epoch: 29 | loss: 0.0799424\n",
      "\tspeed: 0.0404s/iter; left time: 640.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0801347 Vali Loss: 0.0942976 Test Loss: 0.1099886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0831368\n",
      "\tspeed: 0.0732s/iter; left time: 1151.8733s\n",
      "\titers: 200, epoch: 30 | loss: 0.0778237\n",
      "\tspeed: 0.0390s/iter; left time: 609.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0799265 Vali Loss: 0.0939335 Test Loss: 0.1097265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0832254\n",
      "\tspeed: 0.0724s/iter; left time: 1123.1400s\n",
      "\titers: 200, epoch: 31 | loss: 0.0835412\n",
      "\tspeed: 0.0391s/iter; left time: 601.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0798050 Vali Loss: 0.0936035 Test Loss: 0.1094722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0787123\n",
      "\tspeed: 0.0732s/iter; left time: 1119.5431s\n",
      "\titers: 200, epoch: 32 | loss: 0.0793114\n",
      "\tspeed: 0.0390s/iter; left time: 592.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0797785 Vali Loss: 0.0937579 Test Loss: 0.1094872\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0769385\n",
      "\tspeed: 0.0752s/iter; left time: 1132.8555s\n",
      "\titers: 200, epoch: 33 | loss: 0.0800261\n",
      "\tspeed: 0.0402s/iter; left time: 601.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0796030 Vali Loss: 0.0936869 Test Loss: 0.1094288\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0803549\n",
      "\tspeed: 0.0744s/iter; left time: 1104.7923s\n",
      "\titers: 200, epoch: 34 | loss: 0.0828094\n",
      "\tspeed: 0.0390s/iter; left time: 574.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0795832 Vali Loss: 0.0934813 Test Loss: 0.1091498\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0803263\n",
      "\tspeed: 0.0723s/iter; left time: 1056.3673s\n",
      "\titers: 200, epoch: 35 | loss: 0.0806136\n",
      "\tspeed: 0.0389s/iter; left time: 565.3985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.89s\n",
      "Steps: 223 | Train Loss: 0.0795048 Vali Loss: 0.0934156 Test Loss: 0.1091697\n",
      "Validation loss decreased (0.093430 --> 0.093416).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0764026\n",
      "\tspeed: 0.0744s/iter; left time: 1071.4413s\n",
      "\titers: 200, epoch: 36 | loss: 0.0802646\n",
      "\tspeed: 0.0393s/iter; left time: 561.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0795049 Vali Loss: 0.0939936 Test Loss: 0.1098373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0760821\n",
      "\tspeed: 0.0745s/iter; left time: 1055.9233s\n",
      "\titers: 200, epoch: 37 | loss: 0.0781312\n",
      "\tspeed: 0.0392s/iter; left time: 550.9936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0793955 Vali Loss: 0.0933989 Test Loss: 0.1092416\n",
      "Validation loss decreased (0.093416 --> 0.093399).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0815993\n",
      "\tspeed: 0.0733s/iter; left time: 1022.7812s\n",
      "\titers: 200, epoch: 38 | loss: 0.0795853\n",
      "\tspeed: 0.0391s/iter; left time: 541.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0793427 Vali Loss: 0.0934979 Test Loss: 0.1092675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0750512\n",
      "\tspeed: 0.0738s/iter; left time: 1013.7025s\n",
      "\titers: 200, epoch: 39 | loss: 0.0810659\n",
      "\tspeed: 0.0391s/iter; left time: 532.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0792515 Vali Loss: 0.0935287 Test Loss: 0.1093181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0811673\n",
      "\tspeed: 0.0723s/iter; left time: 976.9965s\n",
      "\titers: 200, epoch: 40 | loss: 0.0777437\n",
      "\tspeed: 0.0390s/iter; left time: 522.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 223 | Train Loss: 0.0792520 Vali Loss: 0.0934786 Test Loss: 0.1093450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0761597\n",
      "\tspeed: 0.0727s/iter; left time: 965.6611s\n",
      "\titers: 200, epoch: 41 | loss: 0.0770124\n",
      "\tspeed: 0.0390s/iter; left time: 514.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0792213 Vali Loss: 0.0933879 Test Loss: 0.1092263\n",
      "Validation loss decreased (0.093399 --> 0.093388).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0766376\n",
      "\tspeed: 0.0728s/iter; left time: 950.3926s\n",
      "\titers: 200, epoch: 42 | loss: 0.0752908\n",
      "\tspeed: 0.0390s/iter; left time: 504.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0792565 Vali Loss: 0.0934861 Test Loss: 0.1093184\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0848864\n",
      "\tspeed: 0.0725s/iter; left time: 930.5492s\n",
      "\titers: 200, epoch: 43 | loss: 0.0768185\n",
      "\tspeed: 0.0391s/iter; left time: 497.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0791340 Vali Loss: 0.0936205 Test Loss: 0.1095328\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0781693\n",
      "\tspeed: 0.0735s/iter; left time: 926.8615s\n",
      "\titers: 200, epoch: 44 | loss: 0.0808844\n",
      "\tspeed: 0.0392s/iter; left time: 490.7917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0791611 Vali Loss: 0.0934488 Test Loss: 0.1093401\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0774045\n",
      "\tspeed: 0.0746s/iter; left time: 924.1568s\n",
      "\titers: 200, epoch: 45 | loss: 0.0804046\n",
      "\tspeed: 0.0394s/iter; left time: 483.9683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 223 | Train Loss: 0.0791099 Vali Loss: 0.0935124 Test Loss: 0.1093599\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0760984\n",
      "\tspeed: 0.0739s/iter; left time: 898.5359s\n",
      "\titers: 200, epoch: 46 | loss: 0.0787687\n",
      "\tspeed: 0.0400s/iter; left time: 482.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0791031 Vali Loss: 0.0933472 Test Loss: 0.1093151\n",
      "Validation loss decreased (0.093388 --> 0.093347).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0792218\n",
      "\tspeed: 0.0731s/iter; left time: 872.6989s\n",
      "\titers: 200, epoch: 47 | loss: 0.0767578\n",
      "\tspeed: 0.0390s/iter; left time: 462.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 223 | Train Loss: 0.0790349 Vali Loss: 0.0933852 Test Loss: 0.1093465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0787772\n",
      "\tspeed: 0.0729s/iter; left time: 854.4992s\n",
      "\titers: 200, epoch: 48 | loss: 0.0787515\n",
      "\tspeed: 0.0391s/iter; left time: 454.8568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0790202 Vali Loss: 0.0931344 Test Loss: 0.1090922\n",
      "Validation loss decreased (0.093347 --> 0.093134).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0805069\n",
      "\tspeed: 0.0738s/iter; left time: 848.9384s\n",
      "\titers: 200, epoch: 49 | loss: 0.0751215\n",
      "\tspeed: 0.0393s/iter; left time: 448.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0790612 Vali Loss: 0.0934987 Test Loss: 0.1094157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0781916\n",
      "\tspeed: 0.0729s/iter; left time: 821.5856s\n",
      "\titers: 200, epoch: 50 | loss: 0.0799954\n",
      "\tspeed: 0.0393s/iter; left time: 439.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0790132 Vali Loss: 0.0932961 Test Loss: 0.1092081\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0795931\n",
      "\tspeed: 0.0733s/iter; left time: 809.6803s\n",
      "\titers: 200, epoch: 51 | loss: 0.0802871\n",
      "\tspeed: 0.0393s/iter; left time: 430.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0789916 Vali Loss: 0.0933160 Test Loss: 0.1092240\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0810160\n",
      "\tspeed: 0.0739s/iter; left time: 799.9559s\n",
      "\titers: 200, epoch: 52 | loss: 0.0768484\n",
      "\tspeed: 0.0390s/iter; left time: 418.0210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0789591 Vali Loss: 0.0933751 Test Loss: 0.1093103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0831498\n",
      "\tspeed: 0.0735s/iter; left time: 779.0867s\n",
      "\titers: 200, epoch: 53 | loss: 0.0803323\n",
      "\tspeed: 0.0393s/iter; left time: 412.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0789418 Vali Loss: 0.0932822 Test Loss: 0.1092033\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0828484\n",
      "\tspeed: 0.0742s/iter; left time: 770.8604s\n",
      "\titers: 200, epoch: 54 | loss: 0.0804241\n",
      "\tspeed: 0.0396s/iter; left time: 406.8089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0789706 Vali Loss: 0.0935555 Test Loss: 0.1094234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0813449\n",
      "\tspeed: 0.0735s/iter; left time: 747.0870s\n",
      "\titers: 200, epoch: 55 | loss: 0.0752153\n",
      "\tspeed: 0.0395s/iter; left time: 397.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0790029 Vali Loss: 0.0933569 Test Loss: 0.1092687\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0776829\n",
      "\tspeed: 0.0750s/iter; left time: 745.5508s\n",
      "\titers: 200, epoch: 56 | loss: 0.0823706\n",
      "\tspeed: 0.0409s/iter; left time: 402.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0789384 Vali Loss: 0.0934252 Test Loss: 0.1094050\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0739111\n",
      "\tspeed: 0.0740s/iter; left time: 719.1517s\n",
      "\titers: 200, epoch: 57 | loss: 0.0792411\n",
      "\tspeed: 0.0390s/iter; left time: 375.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 223 | Train Loss: 0.0789430 Vali Loss: 0.0934668 Test Loss: 0.1093465\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0813686\n",
      "\tspeed: 0.0723s/iter; left time: 685.7429s\n",
      "\titers: 200, epoch: 58 | loss: 0.0761071\n",
      "\tspeed: 0.0390s/iter; left time: 366.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0790032 Vali Loss: 0.0933475 Test Loss: 0.1093047\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028262613341212273, rmse:0.16811488568782806, mae:0.10909226536750793, rse:0.5799486637115479\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3152337\n",
      "\tspeed: 0.0414s/iter; left time: 918.4515s\n",
      "\titers: 200, epoch: 1 | loss: 0.2973524\n",
      "\tspeed: 0.0394s/iter; left time: 869.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.3197845 Vali Loss: 0.2687608 Test Loss: 0.2834947\n",
      "Validation loss decreased (inf --> 0.268761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1589351\n",
      "\tspeed: 0.0743s/iter; left time: 1633.2843s\n",
      "\titers: 200, epoch: 2 | loss: 0.1267627\n",
      "\tspeed: 0.0389s/iter; left time: 851.4811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.1725961 Vali Loss: 0.1313205 Test Loss: 0.1502493\n",
      "Validation loss decreased (0.268761 --> 0.131320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1261153\n",
      "\tspeed: 0.0730s/iter; left time: 1588.2826s\n",
      "\titers: 200, epoch: 3 | loss: 0.1220909\n",
      "\tspeed: 0.0389s/iter; left time: 842.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.1222524 Vali Loss: 0.1250087 Test Loss: 0.1402612\n",
      "Validation loss decreased (0.131320 --> 0.125009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1160693\n",
      "\tspeed: 0.0752s/iter; left time: 1618.5083s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133885\n",
      "\tspeed: 0.0396s/iter; left time: 848.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1147958 Vali Loss: 0.1193044 Test Loss: 0.1351525\n",
      "Validation loss decreased (0.125009 --> 0.119304).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1061113\n",
      "\tspeed: 0.0757s/iter; left time: 1613.1250s\n",
      "\titers: 200, epoch: 5 | loss: 0.1096740\n",
      "\tspeed: 0.0397s/iter; left time: 841.5766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 223 | Train Loss: 0.1058027 Vali Loss: 0.1059470 Test Loss: 0.1228735\n",
      "Validation loss decreased (0.119304 --> 0.105947).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0971246\n",
      "\tspeed: 0.0736s/iter; left time: 1551.2387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0980050\n",
      "\tspeed: 0.0391s/iter; left time: 819.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 223 | Train Loss: 0.0966957 Vali Loss: 0.1030668 Test Loss: 0.1235337\n",
      "Validation loss decreased (0.105947 --> 0.103067).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0954455\n",
      "\tspeed: 0.0741s/iter; left time: 1545.2884s\n",
      "\titers: 200, epoch: 7 | loss: 0.0996417\n",
      "\tspeed: 0.0394s/iter; left time: 817.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0932134 Vali Loss: 0.1037001 Test Loss: 0.1274340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847216\n",
      "\tspeed: 0.0728s/iter; left time: 1502.0689s\n",
      "\titers: 200, epoch: 8 | loss: 0.0884954\n",
      "\tspeed: 0.0388s/iter; left time: 796.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 223 | Train Loss: 0.0910087 Vali Loss: 0.0995608 Test Loss: 0.1205517\n",
      "Validation loss decreased (0.103067 --> 0.099561).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0857954\n",
      "\tspeed: 0.0738s/iter; left time: 1506.1039s\n",
      "\titers: 200, epoch: 9 | loss: 0.0832545\n",
      "\tspeed: 0.0392s/iter; left time: 796.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0895559 Vali Loss: 0.0977951 Test Loss: 0.1167396\n",
      "Validation loss decreased (0.099561 --> 0.097795).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0892041\n",
      "\tspeed: 0.0754s/iter; left time: 1522.9472s\n",
      "\titers: 200, epoch: 10 | loss: 0.0894414\n",
      "\tspeed: 0.0394s/iter; left time: 790.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 223 | Train Loss: 0.0880285 Vali Loss: 0.0977838 Test Loss: 0.1170046\n",
      "Validation loss decreased (0.097795 --> 0.097784).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0868241\n",
      "\tspeed: 0.0740s/iter; left time: 1478.0804s\n",
      "\titers: 200, epoch: 11 | loss: 0.0920000\n",
      "\tspeed: 0.0392s/iter; left time: 778.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.98s\n",
      "Steps: 223 | Train Loss: 0.0870819 Vali Loss: 0.0983632 Test Loss: 0.1169128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0907766\n",
      "\tspeed: 0.0732s/iter; left time: 1445.8318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0871369\n",
      "\tspeed: 0.0392s/iter; left time: 770.0307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0861046 Vali Loss: 0.0968459 Test Loss: 0.1145203\n",
      "Validation loss decreased (0.097784 --> 0.096846).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0863632\n",
      "\tspeed: 0.0744s/iter; left time: 1451.9070s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813789\n",
      "\tspeed: 0.0391s/iter; left time: 758.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0854617 Vali Loss: 0.0968392 Test Loss: 0.1150885\n",
      "Validation loss decreased (0.096846 --> 0.096839).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0856046\n",
      "\tspeed: 0.0772s/iter; left time: 1489.1981s\n",
      "\titers: 200, epoch: 14 | loss: 0.0866667\n",
      "\tspeed: 0.0408s/iter; left time: 783.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0846725 Vali Loss: 0.0959266 Test Loss: 0.1151211\n",
      "Validation loss decreased (0.096839 --> 0.095927).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0823660\n",
      "\tspeed: 0.0792s/iter; left time: 1510.8014s\n",
      "\titers: 200, epoch: 15 | loss: 0.0828971\n",
      "\tspeed: 0.0396s/iter; left time: 750.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0841895 Vali Loss: 0.0977687 Test Loss: 0.1171922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0842434\n",
      "\tspeed: 0.0731s/iter; left time: 1378.3402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0799332\n",
      "\tspeed: 0.0391s/iter; left time: 732.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0836290 Vali Loss: 0.0959968 Test Loss: 0.1144735\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0845898\n",
      "\tspeed: 0.0733s/iter; left time: 1366.6216s\n",
      "\titers: 200, epoch: 17 | loss: 0.0747472\n",
      "\tspeed: 0.0389s/iter; left time: 721.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 223 | Train Loss: 0.0832586 Vali Loss: 0.0957950 Test Loss: 0.1139647\n",
      "Validation loss decreased (0.095927 --> 0.095795).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0831702\n",
      "\tspeed: 0.0739s/iter; left time: 1360.3351s\n",
      "\titers: 200, epoch: 18 | loss: 0.0797844\n",
      "\tspeed: 0.0394s/iter; left time: 720.6597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 223 | Train Loss: 0.0829173 Vali Loss: 0.0960802 Test Loss: 0.1141547\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0823347\n",
      "\tspeed: 0.0746s/iter; left time: 1356.6568s\n",
      "\titers: 200, epoch: 19 | loss: 0.0876996\n",
      "\tspeed: 0.0406s/iter; left time: 734.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0823195 Vali Loss: 0.0948106 Test Loss: 0.1144260\n",
      "Validation loss decreased (0.095795 --> 0.094811).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0781347\n",
      "\tspeed: 0.0777s/iter; left time: 1396.1016s\n",
      "\titers: 200, epoch: 20 | loss: 0.0849104\n",
      "\tspeed: 0.0391s/iter; left time: 698.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0819734 Vali Loss: 0.0958080 Test Loss: 0.1140718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0870852\n",
      "\tspeed: 0.0728s/iter; left time: 1291.6280s\n",
      "\titers: 200, epoch: 21 | loss: 0.0811779\n",
      "\tspeed: 0.0390s/iter; left time: 687.9363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0818338 Vali Loss: 0.0952628 Test Loss: 0.1133878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798166\n",
      "\tspeed: 0.0758s/iter; left time: 1328.4814s\n",
      "\titers: 200, epoch: 22 | loss: 0.0787404\n",
      "\tspeed: 0.0403s/iter; left time: 701.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0815713 Vali Loss: 0.0948281 Test Loss: 0.1139235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0885847\n",
      "\tspeed: 0.0785s/iter; left time: 1357.8663s\n",
      "\titers: 200, epoch: 23 | loss: 0.0904214\n",
      "\tspeed: 0.0405s/iter; left time: 695.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0814057 Vali Loss: 0.0949516 Test Loss: 0.1153004\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0818874\n",
      "\tspeed: 0.0733s/iter; left time: 1251.8293s\n",
      "\titers: 200, epoch: 24 | loss: 0.0796843\n",
      "\tspeed: 0.0391s/iter; left time: 663.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 223 | Train Loss: 0.0812753 Vali Loss: 0.0961543 Test Loss: 0.1144374\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0834633\n",
      "\tspeed: 0.0745s/iter; left time: 1255.4170s\n",
      "\titers: 200, epoch: 25 | loss: 0.0815073\n",
      "\tspeed: 0.0392s/iter; left time: 656.6160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0807696 Vali Loss: 0.0949621 Test Loss: 0.1145962\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0831048\n",
      "\tspeed: 0.0729s/iter; left time: 1211.6138s\n",
      "\titers: 200, epoch: 26 | loss: 0.0759411\n",
      "\tspeed: 0.0390s/iter; left time: 643.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 223 | Train Loss: 0.0806898 Vali Loss: 0.0942770 Test Loss: 0.1142329\n",
      "Validation loss decreased (0.094811 --> 0.094277).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0870466\n",
      "\tspeed: 0.0762s/iter; left time: 1249.6486s\n",
      "\titers: 200, epoch: 27 | loss: 0.0820244\n",
      "\tspeed: 0.0392s/iter; left time: 639.8890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 223 | Train Loss: 0.0806569 Vali Loss: 0.0940645 Test Loss: 0.1138593\n",
      "Validation loss decreased (0.094277 --> 0.094064).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0781775\n",
      "\tspeed: 0.0792s/iter; left time: 1280.9131s\n",
      "\titers: 200, epoch: 28 | loss: 0.0759656\n",
      "\tspeed: 0.0391s/iter; left time: 629.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 223 | Train Loss: 0.0803957 Vali Loss: 0.0951529 Test Loss: 0.1144848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0792237\n",
      "\tspeed: 0.0730s/iter; left time: 1164.7515s\n",
      "\titers: 200, epoch: 29 | loss: 0.0761054\n",
      "\tspeed: 0.0390s/iter; left time: 618.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0802765 Vali Loss: 0.0942080 Test Loss: 0.1135837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0845778\n",
      "\tspeed: 0.0750s/iter; left time: 1179.7404s\n",
      "\titers: 200, epoch: 30 | loss: 0.0783369\n",
      "\tspeed: 0.0406s/iter; left time: 634.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0800947 Vali Loss: 0.0943491 Test Loss: 0.1134229\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0769998\n",
      "\tspeed: 0.0744s/iter; left time: 1154.5742s\n",
      "\titers: 200, epoch: 31 | loss: 0.0786080\n",
      "\tspeed: 0.0392s/iter; left time: 604.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0800320 Vali Loss: 0.0945585 Test Loss: 0.1140245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776055\n",
      "\tspeed: 0.0736s/iter; left time: 1125.8332s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818883\n",
      "\tspeed: 0.0393s/iter; left time: 597.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 223 | Train Loss: 0.0800339 Vali Loss: 0.0942017 Test Loss: 0.1130949\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0800974\n",
      "\tspeed: 0.0762s/iter; left time: 1147.6686s\n",
      "\titers: 200, epoch: 33 | loss: 0.0812481\n",
      "\tspeed: 0.0400s/iter; left time: 599.2416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0798320 Vali Loss: 0.0939775 Test Loss: 0.1132630\n",
      "Validation loss decreased (0.094064 --> 0.093978).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0766838\n",
      "\tspeed: 0.0745s/iter; left time: 1105.1463s\n",
      "\titers: 200, epoch: 34 | loss: 0.0740111\n",
      "\tspeed: 0.0390s/iter; left time: 574.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0797738 Vali Loss: 0.0943604 Test Loss: 0.1136052\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0830077\n",
      "\tspeed: 0.0730s/iter; left time: 1066.9610s\n",
      "\titers: 200, epoch: 35 | loss: 0.0824818\n",
      "\tspeed: 0.0389s/iter; left time: 565.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 223 | Train Loss: 0.0798089 Vali Loss: 0.0944594 Test Loss: 0.1137439\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0872541\n",
      "\tspeed: 0.0731s/iter; left time: 1052.6186s\n",
      "\titers: 200, epoch: 36 | loss: 0.0760861\n",
      "\tspeed: 0.0392s/iter; left time: 559.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0798148 Vali Loss: 0.0939036 Test Loss: 0.1135664\n",
      "Validation loss decreased (0.093978 --> 0.093904).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0811955\n",
      "\tspeed: 0.0739s/iter; left time: 1047.4646s\n",
      "\titers: 200, epoch: 37 | loss: 0.0787264\n",
      "\tspeed: 0.0392s/iter; left time: 551.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0796481 Vali Loss: 0.0945417 Test Loss: 0.1142473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0776881\n",
      "\tspeed: 0.0724s/iter; left time: 1009.7150s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763719\n",
      "\tspeed: 0.0390s/iter; left time: 540.0513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0796229 Vali Loss: 0.0941590 Test Loss: 0.1139253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0774488\n",
      "\tspeed: 0.0743s/iter; left time: 1019.7849s\n",
      "\titers: 200, epoch: 39 | loss: 0.0806588\n",
      "\tspeed: 0.0391s/iter; left time: 532.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 223 | Train Loss: 0.0796028 Vali Loss: 0.0946571 Test Loss: 0.1140927\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0768404\n",
      "\tspeed: 0.0759s/iter; left time: 1025.0272s\n",
      "\titers: 200, epoch: 40 | loss: 0.0783197\n",
      "\tspeed: 0.0390s/iter; left time: 522.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 223 | Train Loss: 0.0795507 Vali Loss: 0.0945957 Test Loss: 0.1138433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762477\n",
      "\tspeed: 0.0741s/iter; left time: 983.9292s\n",
      "\titers: 200, epoch: 41 | loss: 0.0875751\n",
      "\tspeed: 0.0393s/iter; left time: 517.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 223 | Train Loss: 0.0795227 Vali Loss: 0.0940673 Test Loss: 0.1139168\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0820829\n",
      "\tspeed: 0.0732s/iter; left time: 955.3894s\n",
      "\titers: 200, epoch: 42 | loss: 0.0790311\n",
      "\tspeed: 0.0391s/iter; left time: 506.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 223 | Train Loss: 0.0794662 Vali Loss: 0.0944147 Test Loss: 0.1139332\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0813896\n",
      "\tspeed: 0.0730s/iter; left time: 937.4814s\n",
      "\titers: 200, epoch: 43 | loss: 0.0768588\n",
      "\tspeed: 0.0390s/iter; left time: 497.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0794370 Vali Loss: 0.0943117 Test Loss: 0.1140595\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0833894\n",
      "\tspeed: 0.0729s/iter; left time: 920.0295s\n",
      "\titers: 200, epoch: 44 | loss: 0.0827605\n",
      "\tspeed: 0.0390s/iter; left time: 487.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 223 | Train Loss: 0.0794707 Vali Loss: 0.0944747 Test Loss: 0.1141188\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0767844\n",
      "\tspeed: 0.0728s/iter; left time: 901.3142s\n",
      "\titers: 200, epoch: 45 | loss: 0.0778661\n",
      "\tspeed: 0.0389s/iter; left time: 477.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 223 | Train Loss: 0.0794291 Vali Loss: 0.0942808 Test Loss: 0.1137876\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0803389\n",
      "\tspeed: 0.0735s/iter; left time: 894.4501s\n",
      "\titers: 200, epoch: 46 | loss: 0.0791902\n",
      "\tspeed: 0.0391s/iter; left time: 471.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 223 | Train Loss: 0.0793713 Vali Loss: 0.0941704 Test Loss: 0.1136382\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03251860290765762, rmse:0.18032915890216827, mae:0.11356636881828308, rse:0.6220844388008118\n",
      "Intermediate time for GB and pred_len 24: 00h:19m:54.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3217376\n",
      "\tspeed: 0.0683s/iter; left time: 1508.8407s\n",
      "\titers: 200, epoch: 1 | loss: 0.2982069\n",
      "\tspeed: 0.0398s/iter; left time: 875.0294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.3274105 Vali Loss: 0.2618922 Test Loss: 0.2784771\n",
      "Validation loss decreased (inf --> 0.261892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1633827\n",
      "\tspeed: 0.0777s/iter; left time: 1700.8496s\n",
      "\titers: 200, epoch: 2 | loss: 0.1447607\n",
      "\tspeed: 0.0397s/iter; left time: 863.9126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.1768533 Vali Loss: 0.1512649 Test Loss: 0.1780071\n",
      "Validation loss decreased (0.261892 --> 0.151265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1393235\n",
      "\tspeed: 0.0788s/iter; left time: 1706.4075s\n",
      "\titers: 200, epoch: 3 | loss: 0.1354606\n",
      "\tspeed: 0.0430s/iter; left time: 927.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 222 | Train Loss: 0.1389243 Vali Loss: 0.1470216 Test Loss: 0.1710418\n",
      "Validation loss decreased (0.151265 --> 0.147022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1351276\n",
      "\tspeed: 0.0850s/iter; left time: 1821.1795s\n",
      "\titers: 200, epoch: 4 | loss: 0.1301573\n",
      "\tspeed: 0.0455s/iter; left time: 971.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.51s\n",
      "Steps: 222 | Train Loss: 0.1335075 Vali Loss: 0.1447949 Test Loss: 0.1672248\n",
      "Validation loss decreased (0.147022 --> 0.144795).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1304946\n",
      "\tspeed: 0.0861s/iter; left time: 1825.6167s\n",
      "\titers: 200, epoch: 5 | loss: 0.1290485\n",
      "\tspeed: 0.0454s/iter; left time: 959.2954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 222 | Train Loss: 0.1292483 Vali Loss: 0.1423071 Test Loss: 0.1667214\n",
      "Validation loss decreased (0.144795 --> 0.142307).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1214378\n",
      "\tspeed: 0.0783s/iter; left time: 1643.8533s\n",
      "\titers: 200, epoch: 6 | loss: 0.1125386\n",
      "\tspeed: 0.0399s/iter; left time: 833.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1214053 Vali Loss: 0.1313087 Test Loss: 0.1576876\n",
      "Validation loss decreased (0.142307 --> 0.131309).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1135019\n",
      "\tspeed: 0.0746s/iter; left time: 1548.6862s\n",
      "\titers: 200, epoch: 7 | loss: 0.1092401\n",
      "\tspeed: 0.0397s/iter; left time: 819.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1117896 Vali Loss: 0.1285096 Test Loss: 0.1557290\n",
      "Validation loss decreased (0.131309 --> 0.128510).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1095802\n",
      "\tspeed: 0.0766s/iter; left time: 1574.2496s\n",
      "\titers: 200, epoch: 8 | loss: 0.1078750\n",
      "\tspeed: 0.0398s/iter; left time: 813.3814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1088160 Vali Loss: 0.1276692 Test Loss: 0.1571908\n",
      "Validation loss decreased (0.128510 --> 0.127669).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 0.0783s/iter; left time: 1592.3058s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085969\n",
      "\tspeed: 0.0400s/iter; left time: 807.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1070815 Vali Loss: 0.1260921 Test Loss: 0.1537202\n",
      "Validation loss decreased (0.127669 --> 0.126092).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048988\n",
      "\tspeed: 0.0761s/iter; left time: 1528.8860s\n",
      "\titers: 200, epoch: 10 | loss: 0.1106407\n",
      "\tspeed: 0.0395s/iter; left time: 790.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 222 | Train Loss: 0.1059881 Vali Loss: 0.1250069 Test Loss: 0.1527264\n",
      "Validation loss decreased (0.126092 --> 0.125007).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044631\n",
      "\tspeed: 0.0754s/iter; left time: 1498.0968s\n",
      "\titers: 200, epoch: 11 | loss: 0.1003991\n",
      "\tspeed: 0.0398s/iter; left time: 787.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1050156 Vali Loss: 0.1243849 Test Loss: 0.1524866\n",
      "Validation loss decreased (0.125007 --> 0.124385).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1047489\n",
      "\tspeed: 0.0746s/iter; left time: 1467.2454s\n",
      "\titers: 200, epoch: 12 | loss: 0.1012925\n",
      "\tspeed: 0.0395s/iter; left time: 772.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 222 | Train Loss: 0.1040857 Vali Loss: 0.1245374 Test Loss: 0.1532443\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1015333\n",
      "\tspeed: 0.0736s/iter; left time: 1431.0421s\n",
      "\titers: 200, epoch: 13 | loss: 0.1017910\n",
      "\tspeed: 0.0396s/iter; left time: 765.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 222 | Train Loss: 0.1033052 Vali Loss: 0.1234626 Test Loss: 0.1520102\n",
      "Validation loss decreased (0.124385 --> 0.123463).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1054955\n",
      "\tspeed: 0.0750s/iter; left time: 1440.5890s\n",
      "\titers: 200, epoch: 14 | loss: 0.1033810\n",
      "\tspeed: 0.0396s/iter; left time: 756.1501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1032123 Vali Loss: 0.1239472 Test Loss: 0.1532694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1023274\n",
      "\tspeed: 0.0739s/iter; left time: 1403.8327s\n",
      "\titers: 200, epoch: 15 | loss: 0.1026284\n",
      "\tspeed: 0.0397s/iter; left time: 749.4639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1025742 Vali Loss: 0.1243167 Test Loss: 0.1535156\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1035890\n",
      "\tspeed: 0.0730s/iter; left time: 1369.6230s\n",
      "\titers: 200, epoch: 16 | loss: 0.1019068\n",
      "\tspeed: 0.0394s/iter; left time: 736.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 222 | Train Loss: 0.1020369 Vali Loss: 0.1231679 Test Loss: 0.1524179\n",
      "Validation loss decreased (0.123463 --> 0.123168).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0990148\n",
      "\tspeed: 0.0751s/iter; left time: 1392.1294s\n",
      "\titers: 200, epoch: 17 | loss: 0.1048523\n",
      "\tspeed: 0.0394s/iter; left time: 726.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1017176 Vali Loss: 0.1236288 Test Loss: 0.1528180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1005020\n",
      "\tspeed: 0.0735s/iter; left time: 1347.6743s\n",
      "\titers: 200, epoch: 18 | loss: 0.1050622\n",
      "\tspeed: 0.0395s/iter; left time: 719.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1015725 Vali Loss: 0.1237218 Test Loss: 0.1524753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0999184\n",
      "\tspeed: 0.0736s/iter; left time: 1332.6549s\n",
      "\titers: 200, epoch: 19 | loss: 0.1010016\n",
      "\tspeed: 0.0397s/iter; left time: 715.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1011854 Vali Loss: 0.1231171 Test Loss: 0.1521045\n",
      "Validation loss decreased (0.123168 --> 0.123117).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0985555\n",
      "\tspeed: 0.0771s/iter; left time: 1379.6108s\n",
      "\titers: 200, epoch: 20 | loss: 0.0986160\n",
      "\tspeed: 0.0395s/iter; left time: 703.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1009383 Vali Loss: 0.1228593 Test Loss: 0.1520738\n",
      "Validation loss decreased (0.123117 --> 0.122859).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1024683\n",
      "\tspeed: 0.0756s/iter; left time: 1335.4998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0982553\n",
      "\tspeed: 0.0394s/iter; left time: 692.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.1011594 Vali Loss: 0.1241158 Test Loss: 0.1533372\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1028093\n",
      "\tspeed: 0.0741s/iter; left time: 1292.7029s\n",
      "\titers: 200, epoch: 22 | loss: 0.0980430\n",
      "\tspeed: 0.0395s/iter; left time: 685.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 222 | Train Loss: 0.1006839 Vali Loss: 0.1224363 Test Loss: 0.1516130\n",
      "Validation loss decreased (0.122859 --> 0.122436).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1016103\n",
      "\tspeed: 0.0769s/iter; left time: 1323.3232s\n",
      "\titers: 200, epoch: 23 | loss: 0.1004545\n",
      "\tspeed: 0.0397s/iter; left time: 679.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.1004453 Vali Loss: 0.1227657 Test Loss: 0.1518043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0990420\n",
      "\tspeed: 0.0747s/iter; left time: 1269.4901s\n",
      "\titers: 200, epoch: 24 | loss: 0.0958816\n",
      "\tspeed: 0.0395s/iter; left time: 666.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1004015 Vali Loss: 0.1225666 Test Loss: 0.1519237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1013644\n",
      "\tspeed: 0.0764s/iter; left time: 1281.1461s\n",
      "\titers: 200, epoch: 25 | loss: 0.1027201\n",
      "\tspeed: 0.0413s/iter; left time: 688.2240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1001803 Vali Loss: 0.1217237 Test Loss: 0.1510783\n",
      "Validation loss decreased (0.122436 --> 0.121724).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1042161\n",
      "\tspeed: 0.0768s/iter; left time: 1270.7065s\n",
      "\titers: 200, epoch: 26 | loss: 0.1021532\n",
      "\tspeed: 0.0405s/iter; left time: 666.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1002852 Vali Loss: 0.1221485 Test Loss: 0.1517561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1023746\n",
      "\tspeed: 0.0760s/iter; left time: 1241.5092s\n",
      "\titers: 200, epoch: 27 | loss: 0.0985764\n",
      "\tspeed: 0.0395s/iter; left time: 640.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.0999001 Vali Loss: 0.1220671 Test Loss: 0.1513993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0976589\n",
      "\tspeed: 0.0738s/iter; left time: 1188.0766s\n",
      "\titers: 200, epoch: 28 | loss: 0.0986520\n",
      "\tspeed: 0.0396s/iter; left time: 634.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.0999433 Vali Loss: 0.1223907 Test Loss: 0.1517628\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0965463\n",
      "\tspeed: 0.0745s/iter; left time: 1183.2696s\n",
      "\titers: 200, epoch: 29 | loss: 0.1030524\n",
      "\tspeed: 0.0406s/iter; left time: 640.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.0998131 Vali Loss: 0.1220926 Test Loss: 0.1515409\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0947942\n",
      "\tspeed: 0.0735s/iter; left time: 1150.9010s\n",
      "\titers: 200, epoch: 30 | loss: 0.0956699\n",
      "\tspeed: 0.0397s/iter; left time: 617.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.0996482 Vali Loss: 0.1219731 Test Loss: 0.1510697\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1024522\n",
      "\tspeed: 0.0765s/iter; left time: 1180.8410s\n",
      "\titers: 200, epoch: 31 | loss: 0.1011491\n",
      "\tspeed: 0.0420s/iter; left time: 643.5570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.0996326 Vali Loss: 0.1222006 Test Loss: 0.1513456\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1018146\n",
      "\tspeed: 0.0767s/iter; left time: 1166.8365s\n",
      "\titers: 200, epoch: 32 | loss: 0.0995213\n",
      "\tspeed: 0.0406s/iter; left time: 613.7957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.0996255 Vali Loss: 0.1221258 Test Loss: 0.1514370\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1034442\n",
      "\tspeed: 0.0753s/iter; left time: 1129.8705s\n",
      "\titers: 200, epoch: 33 | loss: 0.0994347\n",
      "\tspeed: 0.0395s/iter; left time: 588.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 222 | Train Loss: 0.0995515 Vali Loss: 0.1224203 Test Loss: 0.1516310\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0991438\n",
      "\tspeed: 0.0771s/iter; left time: 1138.7748s\n",
      "\titers: 200, epoch: 34 | loss: 0.1016581\n",
      "\tspeed: 0.0416s/iter; left time: 610.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0995065 Vali Loss: 0.1218914 Test Loss: 0.1511413\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1023173\n",
      "\tspeed: 0.0752s/iter; left time: 1094.3186s\n",
      "\titers: 200, epoch: 35 | loss: 0.0958684\n",
      "\tspeed: 0.0396s/iter; left time: 572.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.0994605 Vali Loss: 0.1220177 Test Loss: 0.1512924\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04932384938001633, rmse:0.2220897376537323, mae:0.15107817947864532, rse:0.7680172324180603\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3205367\n",
      "\tspeed: 0.0433s/iter; left time: 956.2465s\n",
      "\titers: 200, epoch: 1 | loss: 0.2993930\n",
      "\tspeed: 0.0403s/iter; left time: 886.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.3288122 Vali Loss: 0.2653092 Test Loss: 0.2814672\n",
      "Validation loss decreased (inf --> 0.265309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1592050\n",
      "\tspeed: 0.0764s/iter; left time: 1670.6177s\n",
      "\titers: 200, epoch: 2 | loss: 0.1507115\n",
      "\tspeed: 0.0398s/iter; left time: 866.5104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 222 | Train Loss: 0.1781052 Vali Loss: 0.1510592 Test Loss: 0.1779951\n",
      "Validation loss decreased (0.265309 --> 0.151059).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1407541\n",
      "\tspeed: 0.0776s/iter; left time: 1681.1339s\n",
      "\titers: 200, epoch: 3 | loss: 0.1408559\n",
      "\tspeed: 0.0398s/iter; left time: 858.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1383450 Vali Loss: 0.1464192 Test Loss: 0.1715667\n",
      "Validation loss decreased (0.151059 --> 0.146419).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1340961\n",
      "\tspeed: 0.0767s/iter; left time: 1643.2764s\n",
      "\titers: 200, epoch: 4 | loss: 0.1309501\n",
      "\tspeed: 0.0394s/iter; left time: 841.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 222 | Train Loss: 0.1328854 Vali Loss: 0.1427267 Test Loss: 0.1697866\n",
      "Validation loss decreased (0.146419 --> 0.142727).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1251872\n",
      "\tspeed: 0.0781s/iter; left time: 1657.2495s\n",
      "\titers: 200, epoch: 5 | loss: 0.1156499\n",
      "\tspeed: 0.0408s/iter; left time: 861.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1220893 Vali Loss: 0.1282275 Test Loss: 0.1562178\n",
      "Validation loss decreased (0.142727 --> 0.128227).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1106281\n",
      "\tspeed: 0.0792s/iter; left time: 1663.1293s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151507\n",
      "\tspeed: 0.0393s/iter; left time: 821.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.1144547 Vali Loss: 0.1278555 Test Loss: 0.1560998\n",
      "Validation loss decreased (0.128227 --> 0.127855).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1085991\n",
      "\tspeed: 0.0758s/iter; left time: 1574.7541s\n",
      "\titers: 200, epoch: 7 | loss: 0.1182067\n",
      "\tspeed: 0.0394s/iter; left time: 814.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.1121452 Vali Loss: 0.1273494 Test Loss: 0.1558812\n",
      "Validation loss decreased (0.127855 --> 0.127349).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1104857\n",
      "\tspeed: 0.0759s/iter; left time: 1559.3890s\n",
      "\titers: 200, epoch: 8 | loss: 0.1137383\n",
      "\tspeed: 0.0399s/iter; left time: 816.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 222 | Train Loss: 0.1097270 Vali Loss: 0.1277002 Test Loss: 0.1572934\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1125096\n",
      "\tspeed: 0.0753s/iter; left time: 1531.2535s\n",
      "\titers: 200, epoch: 9 | loss: 0.1056971\n",
      "\tspeed: 0.0397s/iter; left time: 802.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 222 | Train Loss: 0.1083762 Vali Loss: 0.1254351 Test Loss: 0.1541674\n",
      "Validation loss decreased (0.127349 --> 0.125435).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1075710\n",
      "\tspeed: 0.0756s/iter; left time: 1519.4111s\n",
      "\titers: 200, epoch: 10 | loss: 0.1079484\n",
      "\tspeed: 0.0397s/iter; left time: 793.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 222 | Train Loss: 0.1068392 Vali Loss: 0.1260585 Test Loss: 0.1548593\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1080515\n",
      "\tspeed: 0.0745s/iter; left time: 1480.7201s\n",
      "\titers: 200, epoch: 11 | loss: 0.1037759\n",
      "\tspeed: 0.0396s/iter; left time: 783.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1054636 Vali Loss: 0.1259887 Test Loss: 0.1555129\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1007005\n",
      "\tspeed: 0.0750s/iter; left time: 1475.0066s\n",
      "\titers: 200, epoch: 12 | loss: 0.1066272\n",
      "\tspeed: 0.0395s/iter; left time: 773.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.1045956 Vali Loss: 0.1250016 Test Loss: 0.1545256\n",
      "Validation loss decreased (0.125435 --> 0.125002).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016216\n",
      "\tspeed: 0.0755s/iter; left time: 1468.2263s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018066\n",
      "\tspeed: 0.0393s/iter; left time: 760.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1033218 Vali Loss: 0.1234521 Test Loss: 0.1535910\n",
      "Validation loss decreased (0.125002 --> 0.123452).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1016151\n",
      "\tspeed: 0.0753s/iter; left time: 1446.9069s\n",
      "\titers: 200, epoch: 14 | loss: 0.1082145\n",
      "\tspeed: 0.0394s/iter; left time: 752.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 222 | Train Loss: 0.1027141 Vali Loss: 0.1257066 Test Loss: 0.1565625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1019971\n",
      "\tspeed: 0.0742s/iter; left time: 1409.3168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0997956\n",
      "\tspeed: 0.0395s/iter; left time: 745.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 222 | Train Loss: 0.1019858 Vali Loss: 0.1238644 Test Loss: 0.1542823\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0989707\n",
      "\tspeed: 0.0766s/iter; left time: 1438.2732s\n",
      "\titers: 200, epoch: 16 | loss: 0.0989271\n",
      "\tspeed: 0.0396s/iter; left time: 739.1278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1017883 Vali Loss: 0.1237297 Test Loss: 0.1541183\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003020\n",
      "\tspeed: 0.0743s/iter; left time: 1377.7706s\n",
      "\titers: 200, epoch: 17 | loss: 0.1002619\n",
      "\tspeed: 0.0395s/iter; left time: 729.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.1013125 Vali Loss: 0.1234292 Test Loss: 0.1544753\n",
      "Validation loss decreased (0.123452 --> 0.123429).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1073956\n",
      "\tspeed: 0.0761s/iter; left time: 1394.7155s\n",
      "\titers: 200, epoch: 18 | loss: 0.1011103\n",
      "\tspeed: 0.0395s/iter; left time: 719.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 222 | Train Loss: 0.1008890 Vali Loss: 0.1235606 Test Loss: 0.1552757\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0971683\n",
      "\tspeed: 0.0755s/iter; left time: 1366.5410s\n",
      "\titers: 200, epoch: 19 | loss: 0.1011195\n",
      "\tspeed: 0.0395s/iter; left time: 710.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 222 | Train Loss: 0.1004885 Vali Loss: 0.1235760 Test Loss: 0.1546686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1005251\n",
      "\tspeed: 0.0748s/iter; left time: 1336.7638s\n",
      "\titers: 200, epoch: 20 | loss: 0.0968408\n",
      "\tspeed: 0.0393s/iter; left time: 699.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 222 | Train Loss: 0.1003295 Vali Loss: 0.1234892 Test Loss: 0.1544831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1012071\n",
      "\tspeed: 0.0762s/iter; left time: 1345.8483s\n",
      "\titers: 200, epoch: 21 | loss: 0.0998529\n",
      "\tspeed: 0.0404s/iter; left time: 708.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.0999859 Vali Loss: 0.1226737 Test Loss: 0.1547249\n",
      "Validation loss decreased (0.123429 --> 0.122674).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1001535\n",
      "\tspeed: 0.0803s/iter; left time: 1400.8092s\n",
      "\titers: 200, epoch: 22 | loss: 0.0996899\n",
      "\tspeed: 0.0405s/iter; left time: 702.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.0997348 Vali Loss: 0.1229523 Test Loss: 0.1542149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0973762\n",
      "\tspeed: 0.0746s/iter; left time: 1285.0849s\n",
      "\titers: 200, epoch: 23 | loss: 0.0993675\n",
      "\tspeed: 0.0400s/iter; left time: 685.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 222 | Train Loss: 0.0995970 Vali Loss: 0.1233414 Test Loss: 0.1557722\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1007252\n",
      "\tspeed: 0.0746s/iter; left time: 1268.6612s\n",
      "\titers: 200, epoch: 24 | loss: 0.0977427\n",
      "\tspeed: 0.0395s/iter; left time: 666.9678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.0993020 Vali Loss: 0.1232815 Test Loss: 0.1552410\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1021678\n",
      "\tspeed: 0.0785s/iter; left time: 1316.2747s\n",
      "\titers: 200, epoch: 25 | loss: 0.0998680\n",
      "\tspeed: 0.0407s/iter; left time: 678.9017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.0991860 Vali Loss: 0.1240731 Test Loss: 0.1566739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1009754\n",
      "\tspeed: 0.0787s/iter; left time: 1303.2718s\n",
      "\titers: 200, epoch: 26 | loss: 0.1025553\n",
      "\tspeed: 0.0408s/iter; left time: 670.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.0989259 Vali Loss: 0.1230823 Test Loss: 0.1562157\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1026580\n",
      "\tspeed: 0.0754s/iter; left time: 1231.2647s\n",
      "\titers: 200, epoch: 27 | loss: 0.1023101\n",
      "\tspeed: 0.0395s/iter; left time: 640.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 222 | Train Loss: 0.0989654 Vali Loss: 0.1234102 Test Loss: 0.1554434\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0962875\n",
      "\tspeed: 0.0744s/iter; left time: 1197.9427s\n",
      "\titers: 200, epoch: 28 | loss: 0.0992430\n",
      "\tspeed: 0.0394s/iter; left time: 631.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.02s\n",
      "Steps: 222 | Train Loss: 0.0987520 Vali Loss: 0.1248423 Test Loss: 0.1579324\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1011395\n",
      "\tspeed: 0.0747s/iter; left time: 1185.9080s\n",
      "\titers: 200, epoch: 29 | loss: 0.0993801\n",
      "\tspeed: 0.0394s/iter; left time: 622.3223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 222 | Train Loss: 0.0987238 Vali Loss: 0.1235099 Test Loss: 0.1554286\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0993785\n",
      "\tspeed: 0.0764s/iter; left time: 1196.8853s\n",
      "\titers: 200, epoch: 30 | loss: 0.0988964\n",
      "\tspeed: 0.0407s/iter; left time: 632.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.0985488 Vali Loss: 0.1239956 Test Loss: 0.1562031\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0968063\n",
      "\tspeed: 0.0758s/iter; left time: 1170.0147s\n",
      "\titers: 200, epoch: 31 | loss: 0.1024606\n",
      "\tspeed: 0.0398s/iter; left time: 610.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.0984983 Vali Loss: 0.1242049 Test Loss: 0.1565552\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.055670250207185745, rmse:0.2359454333782196, mae:0.1547248363494873, rse:0.8159322142601013\n",
      "Intermediate time for GB and pred_len 96: 00h:13m:00.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3236534\n",
      "\tspeed: 0.0663s/iter; left time: 1466.2415s\n",
      "\titers: 200, epoch: 1 | loss: 0.2981193\n",
      "\tspeed: 0.0398s/iter; left time: 876.0408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.3245735 Vali Loss: 0.2592341 Test Loss: 0.2752581\n",
      "Validation loss decreased (inf --> 0.259234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1735482\n",
      "\tspeed: 0.0752s/iter; left time: 1644.2270s\n",
      "\titers: 200, epoch: 2 | loss: 0.1456811\n",
      "\tspeed: 0.0401s/iter; left time: 874.0804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1754483 Vali Loss: 0.1542883 Test Loss: 0.1830197\n",
      "Validation loss decreased (0.259234 --> 0.154288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377501\n",
      "\tspeed: 0.0759s/iter; left time: 1643.6501s\n",
      "\titers: 200, epoch: 3 | loss: 0.1368370\n",
      "\tspeed: 0.0403s/iter; left time: 867.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1420209 Vali Loss: 0.1486775 Test Loss: 0.1749032\n",
      "Validation loss decreased (0.154288 --> 0.148677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1329237\n",
      "\tspeed: 0.0752s/iter; left time: 1612.4518s\n",
      "\titers: 200, epoch: 4 | loss: 0.1341758\n",
      "\tspeed: 0.0400s/iter; left time: 853.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1363051 Vali Loss: 0.1474613 Test Loss: 0.1726164\n",
      "Validation loss decreased (0.148677 --> 0.147461).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1281781\n",
      "\tspeed: 0.0757s/iter; left time: 1605.6210s\n",
      "\titers: 200, epoch: 5 | loss: 0.1256892\n",
      "\tspeed: 0.0403s/iter; left time: 850.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1314340 Vali Loss: 0.1420843 Test Loss: 0.1695757\n",
      "Validation loss decreased (0.147461 --> 0.142084).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1204902\n",
      "\tspeed: 0.0755s/iter; left time: 1584.7697s\n",
      "\titers: 200, epoch: 6 | loss: 0.1173962\n",
      "\tspeed: 0.0406s/iter; left time: 847.3838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1199288 Vali Loss: 0.1346977 Test Loss: 0.1638184\n",
      "Validation loss decreased (0.142084 --> 0.134698).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1109685\n",
      "\tspeed: 0.0764s/iter; left time: 1586.3660s\n",
      "\titers: 200, epoch: 7 | loss: 0.1133085\n",
      "\tspeed: 0.0398s/iter; left time: 822.4614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 222 | Train Loss: 0.1146735 Vali Loss: 0.1325585 Test Loss: 0.1609875\n",
      "Validation loss decreased (0.134698 --> 0.132558).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1153665\n",
      "\tspeed: 0.0772s/iter; left time: 1586.3059s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070992\n",
      "\tspeed: 0.0405s/iter; left time: 828.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1129270 Vali Loss: 0.1327892 Test Loss: 0.1631939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1070763\n",
      "\tspeed: 0.0760s/iter; left time: 1544.3308s\n",
      "\titers: 200, epoch: 9 | loss: 0.1135721\n",
      "\tspeed: 0.0407s/iter; left time: 822.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1117262 Vali Loss: 0.1302690 Test Loss: 0.1606625\n",
      "Validation loss decreased (0.132558 --> 0.130269).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1082812\n",
      "\tspeed: 0.0778s/iter; left time: 1564.2153s\n",
      "\titers: 200, epoch: 10 | loss: 0.1138330\n",
      "\tspeed: 0.0405s/iter; left time: 809.3613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1101445 Vali Loss: 0.1325863 Test Loss: 0.1649617\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1099389\n",
      "\tspeed: 0.0760s/iter; left time: 1510.8750s\n",
      "\titers: 200, epoch: 11 | loss: 0.1125380\n",
      "\tspeed: 0.0401s/iter; left time: 794.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1095128 Vali Loss: 0.1315609 Test Loss: 0.1638011\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1108927\n",
      "\tspeed: 0.0745s/iter; left time: 1464.3521s\n",
      "\titers: 200, epoch: 12 | loss: 0.1098884\n",
      "\tspeed: 0.0400s/iter; left time: 782.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1084663 Vali Loss: 0.1301256 Test Loss: 0.1629055\n",
      "Validation loss decreased (0.130269 --> 0.130126).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1080241\n",
      "\tspeed: 0.0757s/iter; left time: 1470.4839s\n",
      "\titers: 200, epoch: 13 | loss: 0.1056928\n",
      "\tspeed: 0.0398s/iter; left time: 770.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1084438 Vali Loss: 0.1291452 Test Loss: 0.1625235\n",
      "Validation loss decreased (0.130126 --> 0.129145).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1057676\n",
      "\tspeed: 0.0765s/iter; left time: 1469.1092s\n",
      "\titers: 200, epoch: 14 | loss: 0.1080685\n",
      "\tspeed: 0.0403s/iter; left time: 770.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1075485 Vali Loss: 0.1286182 Test Loss: 0.1620963\n",
      "Validation loss decreased (0.129145 --> 0.128618).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1070695\n",
      "\tspeed: 0.0763s/iter; left time: 1449.1181s\n",
      "\titers: 200, epoch: 15 | loss: 0.1012314\n",
      "\tspeed: 0.0406s/iter; left time: 766.2164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1072054 Vali Loss: 0.1293575 Test Loss: 0.1632479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067102\n",
      "\tspeed: 0.0753s/iter; left time: 1413.2755s\n",
      "\titers: 200, epoch: 16 | loss: 0.1080663\n",
      "\tspeed: 0.0401s/iter; left time: 749.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.16s\n",
      "Steps: 222 | Train Loss: 0.1065857 Vali Loss: 0.1285912 Test Loss: 0.1630339\n",
      "Validation loss decreased (0.128618 --> 0.128591).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1069796\n",
      "\tspeed: 0.0744s/iter; left time: 1380.2429s\n",
      "\titers: 200, epoch: 17 | loss: 0.1028393\n",
      "\tspeed: 0.0400s/iter; left time: 737.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1064183 Vali Loss: 0.1309483 Test Loss: 0.1657725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1075046\n",
      "\tspeed: 0.0766s/iter; left time: 1403.0386s\n",
      "\titers: 200, epoch: 18 | loss: 0.1044096\n",
      "\tspeed: 0.0405s/iter; left time: 738.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1062172 Vali Loss: 0.1281644 Test Loss: 0.1631783\n",
      "Validation loss decreased (0.128591 --> 0.128164).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1040390\n",
      "\tspeed: 0.0801s/iter; left time: 1450.1533s\n",
      "\titers: 200, epoch: 19 | loss: 0.1056306\n",
      "\tspeed: 0.0407s/iter; left time: 731.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1057120 Vali Loss: 0.1283571 Test Loss: 0.1641231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1048495\n",
      "\tspeed: 0.0773s/iter; left time: 1382.0940s\n",
      "\titers: 200, epoch: 20 | loss: 0.1099688\n",
      "\tspeed: 0.0410s/iter; left time: 729.0452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1053098 Vali Loss: 0.1288163 Test Loss: 0.1642105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1041746\n",
      "\tspeed: 0.0772s/iter; left time: 1363.1317s\n",
      "\titers: 200, epoch: 21 | loss: 0.1070938\n",
      "\tspeed: 0.0413s/iter; left time: 724.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.1052107 Vali Loss: 0.1291365 Test Loss: 0.1650924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1006791\n",
      "\tspeed: 0.0771s/iter; left time: 1344.6430s\n",
      "\titers: 200, epoch: 22 | loss: 0.1044459\n",
      "\tspeed: 0.0402s/iter; left time: 696.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1053243 Vali Loss: 0.1291589 Test Loss: 0.1648050\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1020182\n",
      "\tspeed: 0.0748s/iter; left time: 1287.1899s\n",
      "\titers: 200, epoch: 23 | loss: 0.1064328\n",
      "\tspeed: 0.0401s/iter; left time: 685.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 222 | Train Loss: 0.1048322 Vali Loss: 0.1285892 Test Loss: 0.1648510\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1038583\n",
      "\tspeed: 0.0748s/iter; left time: 1270.7248s\n",
      "\titers: 200, epoch: 24 | loss: 0.1035260\n",
      "\tspeed: 0.0412s/iter; left time: 696.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1047885 Vali Loss: 0.1272460 Test Loss: 0.1626241\n",
      "Validation loss decreased (0.128164 --> 0.127246).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1079026\n",
      "\tspeed: 0.0780s/iter; left time: 1308.8758s\n",
      "\titers: 200, epoch: 25 | loss: 0.1019117\n",
      "\tspeed: 0.0460s/iter; left time: 766.2864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 222 | Train Loss: 0.1045991 Vali Loss: 0.1277280 Test Loss: 0.1635064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1045134\n",
      "\tspeed: 0.0802s/iter; left time: 1327.4243s\n",
      "\titers: 200, epoch: 26 | loss: 0.1047147\n",
      "\tspeed: 0.0471s/iter; left time: 775.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 222 | Train Loss: 0.1042714 Vali Loss: 0.1279325 Test Loss: 0.1637198\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1067095\n",
      "\tspeed: 0.0848s/iter; left time: 1384.4570s\n",
      "\titers: 200, epoch: 27 | loss: 0.1041547\n",
      "\tspeed: 0.0490s/iter; left time: 795.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 222 | Train Loss: 0.1043255 Vali Loss: 0.1277409 Test Loss: 0.1628625\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1046916\n",
      "\tspeed: 0.0756s/iter; left time: 1217.5388s\n",
      "\titers: 200, epoch: 28 | loss: 0.1046082\n",
      "\tspeed: 0.0484s/iter; left time: 775.1178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 222 | Train Loss: 0.1041690 Vali Loss: 0.1272924 Test Loss: 0.1626493\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1019194\n",
      "\tspeed: 0.0807s/iter; left time: 1282.0411s\n",
      "\titers: 200, epoch: 29 | loss: 0.1023435\n",
      "\tspeed: 0.0444s/iter; left time: 700.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 222 | Train Loss: 0.1041787 Vali Loss: 0.1273057 Test Loss: 0.1626872\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1007342\n",
      "\tspeed: 0.0754s/iter; left time: 1181.1115s\n",
      "\titers: 200, epoch: 30 | loss: 0.1032458\n",
      "\tspeed: 0.0449s/iter; left time: 698.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 222 | Train Loss: 0.1040491 Vali Loss: 0.1275127 Test Loss: 0.1627417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1056645\n",
      "\tspeed: 0.0852s/iter; left time: 1316.0755s\n",
      "\titers: 200, epoch: 31 | loss: 0.1037444\n",
      "\tspeed: 0.0453s/iter; left time: 695.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 222 | Train Loss: 0.1039567 Vali Loss: 0.1275295 Test Loss: 0.1626227\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1057333\n",
      "\tspeed: 0.0855s/iter; left time: 1300.5366s\n",
      "\titers: 200, epoch: 32 | loss: 0.1066126\n",
      "\tspeed: 0.0418s/iter; left time: 632.2297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 222 | Train Loss: 0.1037022 Vali Loss: 0.1273606 Test Loss: 0.1624194\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0997827\n",
      "\tspeed: 0.0744s/iter; left time: 1115.2230s\n",
      "\titers: 200, epoch: 33 | loss: 0.1019148\n",
      "\tspeed: 0.0416s/iter; left time: 619.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1039257 Vali Loss: 0.1272434 Test Loss: 0.1623695\n",
      "Validation loss decreased (0.127246 --> 0.127243).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1062913\n",
      "\tspeed: 0.0853s/iter; left time: 1259.9406s\n",
      "\titers: 200, epoch: 34 | loss: 0.1035735\n",
      "\tspeed: 0.0479s/iter; left time: 702.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 222 | Train Loss: 0.1037256 Vali Loss: 0.1274325 Test Loss: 0.1629388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1042971\n",
      "\tspeed: 0.0788s/iter; left time: 1147.3886s\n",
      "\titers: 200, epoch: 35 | loss: 0.1068872\n",
      "\tspeed: 0.0478s/iter; left time: 691.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.35s\n",
      "Steps: 222 | Train Loss: 0.1037740 Vali Loss: 0.1271311 Test Loss: 0.1625467\n",
      "Validation loss decreased (0.127243 --> 0.127131).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1020918\n",
      "\tspeed: 0.0828s/iter; left time: 1186.8935s\n",
      "\titers: 200, epoch: 36 | loss: 0.1029330\n",
      "\tspeed: 0.0405s/iter; left time: 575.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1036417 Vali Loss: 0.1274657 Test Loss: 0.1624565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1031540\n",
      "\tspeed: 0.0760s/iter; left time: 1072.1914s\n",
      "\titers: 200, epoch: 37 | loss: 0.1020886\n",
      "\tspeed: 0.0406s/iter; left time: 568.1137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1035977 Vali Loss: 0.1271770 Test Loss: 0.1624425\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1047826\n",
      "\tspeed: 0.0767s/iter; left time: 1064.4918s\n",
      "\titers: 200, epoch: 38 | loss: 0.1025815\n",
      "\tspeed: 0.0412s/iter; left time: 568.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1036564 Vali Loss: 0.1274125 Test Loss: 0.1627168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1040224\n",
      "\tspeed: 0.0752s/iter; left time: 1027.5868s\n",
      "\titers: 200, epoch: 39 | loss: 0.1039523\n",
      "\tspeed: 0.0407s/iter; left time: 552.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1035766 Vali Loss: 0.1273344 Test Loss: 0.1625159\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1021726\n",
      "\tspeed: 0.0763s/iter; left time: 1025.8987s\n",
      "\titers: 200, epoch: 40 | loss: 0.1052653\n",
      "\tspeed: 0.0410s/iter; left time: 546.9146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1034784 Vali Loss: 0.1269406 Test Loss: 0.1620459\n",
      "Validation loss decreased (0.127131 --> 0.126941).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1039605\n",
      "\tspeed: 0.0840s/iter; left time: 1110.3887s\n",
      "\titers: 200, epoch: 41 | loss: 0.1029856\n",
      "\tspeed: 0.0404s/iter; left time: 530.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1035826 Vali Loss: 0.1273570 Test Loss: 0.1625697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0994091\n",
      "\tspeed: 0.0766s/iter; left time: 995.0781s\n",
      "\titers: 200, epoch: 42 | loss: 0.1026017\n",
      "\tspeed: 0.0409s/iter; left time: 527.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1035173 Vali Loss: 0.1270976 Test Loss: 0.1621464\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1011737\n",
      "\tspeed: 0.0742s/iter; left time: 948.4397s\n",
      "\titers: 200, epoch: 43 | loss: 0.1026250\n",
      "\tspeed: 0.0398s/iter; left time: 504.5094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 222 | Train Loss: 0.1035488 Vali Loss: 0.1275003 Test Loss: 0.1625611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1004847\n",
      "\tspeed: 0.0740s/iter; left time: 929.4266s\n",
      "\titers: 200, epoch: 44 | loss: 0.1003934\n",
      "\tspeed: 0.0399s/iter; left time: 497.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 222 | Train Loss: 0.1034382 Vali Loss: 0.1269662 Test Loss: 0.1620208\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1013571\n",
      "\tspeed: 0.0772s/iter; left time: 951.8840s\n",
      "\titers: 200, epoch: 45 | loss: 0.1027323\n",
      "\tspeed: 0.0410s/iter; left time: 501.1848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1033411 Vali Loss: 0.1269793 Test Loss: 0.1620144\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1020972\n",
      "\tspeed: 0.0764s/iter; left time: 925.3784s\n",
      "\titers: 200, epoch: 46 | loss: 0.1020693\n",
      "\tspeed: 0.0407s/iter; left time: 488.7212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1033498 Vali Loss: 0.1270498 Test Loss: 0.1623211\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0989460\n",
      "\tspeed: 0.0763s/iter; left time: 906.6523s\n",
      "\titers: 200, epoch: 47 | loss: 0.0985041\n",
      "\tspeed: 0.0405s/iter; left time: 477.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1033509 Vali Loss: 0.1268168 Test Loss: 0.1617513\n",
      "Validation loss decreased (0.126941 --> 0.126817).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1021581\n",
      "\tspeed: 0.0768s/iter; left time: 895.9054s\n",
      "\titers: 200, epoch: 48 | loss: 0.1022976\n",
      "\tspeed: 0.0397s/iter; left time: 459.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 222 | Train Loss: 0.1034565 Vali Loss: 0.1268669 Test Loss: 0.1618938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1037157\n",
      "\tspeed: 0.0802s/iter; left time: 918.0175s\n",
      "\titers: 200, epoch: 49 | loss: 0.1081199\n",
      "\tspeed: 0.0448s/iter; left time: 508.4573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 222 | Train Loss: 0.1032974 Vali Loss: 0.1272314 Test Loss: 0.1622982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1020134\n",
      "\tspeed: 0.0851s/iter; left time: 955.3528s\n",
      "\titers: 200, epoch: 50 | loss: 0.1014621\n",
      "\tspeed: 0.0479s/iter; left time: 532.5862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:11.00s\n",
      "Steps: 222 | Train Loss: 0.1034376 Vali Loss: 0.1272885 Test Loss: 0.1623900\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0995292\n",
      "\tspeed: 0.0858s/iter; left time: 943.8576s\n",
      "\titers: 200, epoch: 51 | loss: 0.1033338\n",
      "\tspeed: 0.0471s/iter; left time: 512.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:10.84s\n",
      "Steps: 222 | Train Loss: 0.1032386 Vali Loss: 0.1271809 Test Loss: 0.1623913\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1049516\n",
      "\tspeed: 0.0796s/iter; left time: 858.5292s\n",
      "\titers: 200, epoch: 52 | loss: 0.1047133\n",
      "\tspeed: 0.0405s/iter; left time: 432.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1032129 Vali Loss: 0.1272299 Test Loss: 0.1622519\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1009005\n",
      "\tspeed: 0.0754s/iter; left time: 796.0176s\n",
      "\titers: 200, epoch: 53 | loss: 0.1046428\n",
      "\tspeed: 0.0441s/iter; left time: 461.3104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1032294 Vali Loss: 0.1267982 Test Loss: 0.1618062\n",
      "Validation loss decreased (0.126817 --> 0.126798).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1042711\n",
      "\tspeed: 0.0870s/iter; left time: 899.0778s\n",
      "\titers: 200, epoch: 54 | loss: 0.1064279\n",
      "\tspeed: 0.0456s/iter; left time: 466.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 222 | Train Loss: 0.1032861 Vali Loss: 0.1269991 Test Loss: 0.1620583\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1067240\n",
      "\tspeed: 0.0775s/iter; left time: 783.4971s\n",
      "\titers: 200, epoch: 55 | loss: 0.1017149\n",
      "\tspeed: 0.0406s/iter; left time: 406.9399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1033548 Vali Loss: 0.1270972 Test Loss: 0.1621754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1029388\n",
      "\tspeed: 0.0765s/iter; left time: 756.7359s\n",
      "\titers: 200, epoch: 56 | loss: 0.1000297\n",
      "\tspeed: 0.0405s/iter; left time: 396.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1033499 Vali Loss: 0.1269938 Test Loss: 0.1619611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1031238\n",
      "\tspeed: 0.0772s/iter; left time: 746.7338s\n",
      "\titers: 200, epoch: 57 | loss: 0.0988405\n",
      "\tspeed: 0.0405s/iter; left time: 387.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1032727 Vali Loss: 0.1267992 Test Loss: 0.1618129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0998224\n",
      "\tspeed: 0.0780s/iter; left time: 737.0244s\n",
      "\titers: 200, epoch: 58 | loss: 0.0999755\n",
      "\tspeed: 0.0407s/iter; left time: 380.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1034038 Vali Loss: 0.1270086 Test Loss: 0.1621325\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1055498\n",
      "\tspeed: 0.0777s/iter; left time: 716.3235s\n",
      "\titers: 200, epoch: 59 | loss: 0.1077452\n",
      "\tspeed: 0.0405s/iter; left time: 369.8978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1034128 Vali Loss: 0.1269924 Test Loss: 0.1621580\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.1024208\n",
      "\tspeed: 0.0763s/iter; left time: 686.9795s\n",
      "\titers: 200, epoch: 60 | loss: 0.1046938\n",
      "\tspeed: 0.0419s/iter; left time: 373.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1032326 Vali Loss: 0.1269242 Test Loss: 0.1618266\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.1022625\n",
      "\tspeed: 0.0766s/iter; left time: 672.3767s\n",
      "\titers: 200, epoch: 61 | loss: 0.1035189\n",
      "\tspeed: 0.0405s/iter; left time: 351.6826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1032530 Vali Loss: 0.1270162 Test Loss: 0.1621781\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1056367\n",
      "\tspeed: 0.0758s/iter; left time: 649.0842s\n",
      "\titers: 200, epoch: 62 | loss: 0.1039050\n",
      "\tspeed: 0.0440s/iter; left time: 371.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.1033406 Vali Loss: 0.1268280 Test Loss: 0.1618026\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.1029105\n",
      "\tspeed: 0.0783s/iter; left time: 652.8298s\n",
      "\titers: 200, epoch: 63 | loss: 0.1035236\n",
      "\tspeed: 0.0405s/iter; left time: 333.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.1032716 Vali Loss: 0.1271025 Test Loss: 0.1622232\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05710963159799576, rmse:0.23897621035575867, mae:0.1618061363697052, rse:0.8285648822784424\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3219199\n",
      "\tspeed: 0.0484s/iter; left time: 1069.0488s\n",
      "\titers: 200, epoch: 1 | loss: 0.2916265\n",
      "\tspeed: 0.0439s/iter; left time: 965.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 222 | Train Loss: 0.3282858 Vali Loss: 0.2608060 Test Loss: 0.2762555\n",
      "Validation loss decreased (inf --> 0.260806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1576269\n",
      "\tspeed: 0.0761s/iter; left time: 1664.4348s\n",
      "\titers: 200, epoch: 2 | loss: 0.1484030\n",
      "\tspeed: 0.0403s/iter; left time: 877.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 222 | Train Loss: 0.1756300 Vali Loss: 0.1533782 Test Loss: 0.1807553\n",
      "Validation loss decreased (0.260806 --> 0.153378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1413908\n",
      "\tspeed: 0.0767s/iter; left time: 1661.4426s\n",
      "\titers: 200, epoch: 3 | loss: 0.1362349\n",
      "\tspeed: 0.0404s/iter; left time: 871.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1406058 Vali Loss: 0.1479542 Test Loss: 0.1736340\n",
      "Validation loss decreased (0.153378 --> 0.147954).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1342915\n",
      "\tspeed: 0.0784s/iter; left time: 1680.7150s\n",
      "\titers: 200, epoch: 4 | loss: 0.1196750\n",
      "\tspeed: 0.0401s/iter; left time: 855.1895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1307592 Vali Loss: 0.1393507 Test Loss: 0.1673925\n",
      "Validation loss decreased (0.147954 --> 0.139351).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1210423\n",
      "\tspeed: 0.0761s/iter; left time: 1615.3554s\n",
      "\titers: 200, epoch: 5 | loss: 0.1170768\n",
      "\tspeed: 0.0400s/iter; left time: 844.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.13s\n",
      "Steps: 222 | Train Loss: 0.1193673 Vali Loss: 0.1345476 Test Loss: 0.1625245\n",
      "Validation loss decreased (0.139351 --> 0.134548).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1176646\n",
      "\tspeed: 0.0799s/iter; left time: 1677.4267s\n",
      "\titers: 200, epoch: 6 | loss: 0.1167118\n",
      "\tspeed: 0.0400s/iter; left time: 835.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1161794 Vali Loss: 0.1321900 Test Loss: 0.1594687\n",
      "Validation loss decreased (0.134548 --> 0.132190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1089467\n",
      "\tspeed: 0.0772s/iter; left time: 1603.2066s\n",
      "\titers: 200, epoch: 7 | loss: 0.1093940\n",
      "\tspeed: 0.0404s/iter; left time: 835.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1133620 Vali Loss: 0.1351487 Test Loss: 0.1611924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1129942\n",
      "\tspeed: 0.0793s/iter; left time: 1628.7926s\n",
      "\titers: 200, epoch: 8 | loss: 0.1085530\n",
      "\tspeed: 0.0405s/iter; left time: 829.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1126534 Vali Loss: 0.1322651 Test Loss: 0.1609574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1149745\n",
      "\tspeed: 0.0801s/iter; left time: 1628.1107s\n",
      "\titers: 200, epoch: 9 | loss: 0.1129378\n",
      "\tspeed: 0.0453s/iter; left time: 916.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 222 | Train Loss: 0.1109881 Vali Loss: 0.1305646 Test Loss: 0.1586560\n",
      "Validation loss decreased (0.132190 --> 0.130565).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1137617\n",
      "\tspeed: 0.0864s/iter; left time: 1737.8815s\n",
      "\titers: 200, epoch: 10 | loss: 0.1057054\n",
      "\tspeed: 0.0469s/iter; left time: 938.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.59s\n",
      "Steps: 222 | Train Loss: 0.1104195 Vali Loss: 0.1319910 Test Loss: 0.1605259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1066176\n",
      "\tspeed: 0.0843s/iter; left time: 1675.8108s\n",
      "\titers: 200, epoch: 11 | loss: 0.1127811\n",
      "\tspeed: 0.0462s/iter; left time: 913.8770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 222 | Train Loss: 0.1096023 Vali Loss: 0.1307945 Test Loss: 0.1592043\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1072674\n",
      "\tspeed: 0.0811s/iter; left time: 1594.7284s\n",
      "\titers: 200, epoch: 12 | loss: 0.1085254\n",
      "\tspeed: 0.0412s/iter; left time: 804.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.1089283 Vali Loss: 0.1298151 Test Loss: 0.1604999\n",
      "Validation loss decreased (0.130565 --> 0.129815).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1067790\n",
      "\tspeed: 0.0817s/iter; left time: 1587.7831s\n",
      "\titers: 200, epoch: 13 | loss: 0.1122403\n",
      "\tspeed: 0.0408s/iter; left time: 789.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.1091143 Vali Loss: 0.1292847 Test Loss: 0.1600400\n",
      "Validation loss decreased (0.129815 --> 0.129285).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1105896\n",
      "\tspeed: 0.0798s/iter; left time: 1532.9963s\n",
      "\titers: 200, epoch: 14 | loss: 0.1041419\n",
      "\tspeed: 0.0406s/iter; left time: 775.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1081229 Vali Loss: 0.1291538 Test Loss: 0.1618443\n",
      "Validation loss decreased (0.129285 --> 0.129154).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1111876\n",
      "\tspeed: 0.0806s/iter; left time: 1531.7619s\n",
      "\titers: 200, epoch: 15 | loss: 0.1056613\n",
      "\tspeed: 0.0424s/iter; left time: 801.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 222 | Train Loss: 0.1078221 Vali Loss: 0.1297333 Test Loss: 0.1620228\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1064280\n",
      "\tspeed: 0.0894s/iter; left time: 1677.8775s\n",
      "\titers: 200, epoch: 16 | loss: 0.1107809\n",
      "\tspeed: 0.0463s/iter; left time: 864.3761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.82s\n",
      "Steps: 222 | Train Loss: 0.1072072 Vali Loss: 0.1279415 Test Loss: 0.1598456\n",
      "Validation loss decreased (0.129154 --> 0.127942).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1136331\n",
      "\tspeed: 0.0811s/iter; left time: 1503.8550s\n",
      "\titers: 200, epoch: 17 | loss: 0.1067872\n",
      "\tspeed: 0.0430s/iter; left time: 793.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 222 | Train Loss: 0.1068737 Vali Loss: 0.1285816 Test Loss: 0.1628912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1077157\n",
      "\tspeed: 0.0866s/iter; left time: 1587.9233s\n",
      "\titers: 200, epoch: 18 | loss: 0.1038371\n",
      "\tspeed: 0.0451s/iter; left time: 822.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 222 | Train Loss: 0.1067213 Vali Loss: 0.1283897 Test Loss: 0.1623055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1048123\n",
      "\tspeed: 0.0804s/iter; left time: 1455.9936s\n",
      "\titers: 200, epoch: 19 | loss: 0.1031843\n",
      "\tspeed: 0.0401s/iter; left time: 721.6138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1061359 Vali Loss: 0.1274038 Test Loss: 0.1614610\n",
      "Validation loss decreased (0.127942 --> 0.127404).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1099020\n",
      "\tspeed: 0.0808s/iter; left time: 1445.3624s\n",
      "\titers: 200, epoch: 20 | loss: 0.1093214\n",
      "\tspeed: 0.0398s/iter; left time: 708.0719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1061012 Vali Loss: 0.1288515 Test Loss: 0.1626655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1076769\n",
      "\tspeed: 0.0809s/iter; left time: 1429.6212s\n",
      "\titers: 200, epoch: 21 | loss: 0.1049856\n",
      "\tspeed: 0.0402s/iter; left time: 706.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1056886 Vali Loss: 0.1267701 Test Loss: 0.1603732\n",
      "Validation loss decreased (0.127404 --> 0.126770).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1064424\n",
      "\tspeed: 0.0824s/iter; left time: 1436.3010s\n",
      "\titers: 200, epoch: 22 | loss: 0.1040733\n",
      "\tspeed: 0.0411s/iter; left time: 712.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1056943 Vali Loss: 0.1277091 Test Loss: 0.1628526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1050361\n",
      "\tspeed: 0.0790s/iter; left time: 1360.6977s\n",
      "\titers: 200, epoch: 23 | loss: 0.1069129\n",
      "\tspeed: 0.0402s/iter; left time: 688.6091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1054308 Vali Loss: 0.1269352 Test Loss: 0.1621846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1020579\n",
      "\tspeed: 0.0791s/iter; left time: 1343.7755s\n",
      "\titers: 200, epoch: 24 | loss: 0.1044557\n",
      "\tspeed: 0.0409s/iter; left time: 690.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.1054784 Vali Loss: 0.1283045 Test Loss: 0.1636601\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1029710\n",
      "\tspeed: 0.0793s/iter; left time: 1330.3628s\n",
      "\titers: 200, epoch: 25 | loss: 0.1049899\n",
      "\tspeed: 0.0411s/iter; left time: 684.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.1051379 Vali Loss: 0.1277046 Test Loss: 0.1628990\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1005564\n",
      "\tspeed: 0.0792s/iter; left time: 1311.0512s\n",
      "\titers: 200, epoch: 26 | loss: 0.1067139\n",
      "\tspeed: 0.0407s/iter; left time: 670.2288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1048260 Vali Loss: 0.1275966 Test Loss: 0.1629403\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1071336\n",
      "\tspeed: 0.0793s/iter; left time: 1294.0750s\n",
      "\titers: 200, epoch: 27 | loss: 0.1076232\n",
      "\tspeed: 0.0458s/iter; left time: 743.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 222 | Train Loss: 0.1048855 Vali Loss: 0.1271490 Test Loss: 0.1625602\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1038777\n",
      "\tspeed: 0.0856s/iter; left time: 1378.6125s\n",
      "\titers: 200, epoch: 28 | loss: 0.1059700\n",
      "\tspeed: 0.0427s/iter; left time: 684.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 222 | Train Loss: 0.1048629 Vali Loss: 0.1274397 Test Loss: 0.1627459\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1042370\n",
      "\tspeed: 0.0785s/iter; left time: 1247.1492s\n",
      "\titers: 200, epoch: 29 | loss: 0.1071369\n",
      "\tspeed: 0.0403s/iter; left time: 636.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1046844 Vali Loss: 0.1267944 Test Loss: 0.1617181\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1072554\n",
      "\tspeed: 0.0785s/iter; left time: 1229.0503s\n",
      "\titers: 200, epoch: 30 | loss: 0.1027702\n",
      "\tspeed: 0.0408s/iter; left time: 635.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1046432 Vali Loss: 0.1268881 Test Loss: 0.1623149\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1043801\n",
      "\tspeed: 0.0792s/iter; left time: 1222.7815s\n",
      "\titers: 200, epoch: 31 | loss: 0.1089537\n",
      "\tspeed: 0.0411s/iter; left time: 630.9190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1044928 Vali Loss: 0.1270307 Test Loss: 0.1632277\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05701729282736778, rmse:0.23878294229507446, mae:0.16037322580814362, rse:0.8278947472572327\n",
      "Intermediate time for GB and pred_len 168: 00h:19m:11.89s\n",
      "Intermediate time for GB: 00h:52m:07.85s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3115171\n",
      "\tspeed: 0.0525s/iter; left time: 1165.5375s\n",
      "\titers: 200, epoch: 1 | loss: 0.2880824\n",
      "\tspeed: 0.0255s/iter; left time: 563.8861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.3143839 Vali Loss: 0.2351798 Test Loss: 0.2490981\n",
      "Validation loss decreased (inf --> 0.235180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1796710\n",
      "\tspeed: 0.0502s/iter; left time: 1103.0422s\n",
      "\titers: 200, epoch: 2 | loss: 0.1296046\n",
      "\tspeed: 0.0252s/iter; left time: 551.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.1807251 Vali Loss: 0.0991966 Test Loss: 0.1313138\n",
      "Validation loss decreased (0.235180 --> 0.099197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099171\n",
      "\tspeed: 0.0511s/iter; left time: 1111.4458s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975334\n",
      "\tspeed: 0.0255s/iter; left time: 552.9839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.1096505 Vali Loss: 0.0946902 Test Loss: 0.1326759\n",
      "Validation loss decreased (0.099197 --> 0.094690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0967731\n",
      "\tspeed: 0.0586s/iter; left time: 1260.9391s\n",
      "\titers: 200, epoch: 4 | loss: 0.0889089\n",
      "\tspeed: 0.0264s/iter; left time: 565.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 223 | Train Loss: 0.0943914 Vali Loss: 0.0841959 Test Loss: 0.1216624\n",
      "Validation loss decreased (0.094690 --> 0.084196).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829330\n",
      "\tspeed: 0.0576s/iter; left time: 1228.2480s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775494\n",
      "\tspeed: 0.0256s/iter; left time: 542.2357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 223 | Train Loss: 0.0853964 Vali Loss: 0.0809458 Test Loss: 0.1174575\n",
      "Validation loss decreased (0.084196 --> 0.080946).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835489\n",
      "\tspeed: 0.0524s/iter; left time: 1105.5230s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792435\n",
      "\tspeed: 0.0255s/iter; left time: 535.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0797116 Vali Loss: 0.0761679 Test Loss: 0.1138628\n",
      "Validation loss decreased (0.080946 --> 0.076168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0767640\n",
      "\tspeed: 0.0504s/iter; left time: 1051.1526s\n",
      "\titers: 200, epoch: 7 | loss: 0.0710465\n",
      "\tspeed: 0.0263s/iter; left time: 546.1487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0759259 Vali Loss: 0.0773044 Test Loss: 0.1169276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0713401\n",
      "\tspeed: 0.0494s/iter; left time: 1019.1400s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751493\n",
      "\tspeed: 0.0302s/iter; left time: 619.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 223 | Train Loss: 0.0738228 Vali Loss: 0.0745264 Test Loss: 0.1134771\n",
      "Validation loss decreased (0.076168 --> 0.074526).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774654\n",
      "\tspeed: 0.0530s/iter; left time: 1082.5609s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740248\n",
      "\tspeed: 0.0253s/iter; left time: 513.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0721675 Vali Loss: 0.0706301 Test Loss: 0.1078245\n",
      "Validation loss decreased (0.074526 --> 0.070630).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0805506\n",
      "\tspeed: 0.0505s/iter; left time: 1020.6199s\n",
      "\titers: 200, epoch: 10 | loss: 0.0710080\n",
      "\tspeed: 0.0254s/iter; left time: 510.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0710263 Vali Loss: 0.0701402 Test Loss: 0.1070002\n",
      "Validation loss decreased (0.070630 --> 0.070140).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712441\n",
      "\tspeed: 0.0498s/iter; left time: 994.7366s\n",
      "\titers: 200, epoch: 11 | loss: 0.0690842\n",
      "\tspeed: 0.0253s/iter; left time: 502.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0694088 Vali Loss: 0.0689434 Test Loss: 0.1052890\n",
      "Validation loss decreased (0.070140 --> 0.068943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716634\n",
      "\tspeed: 0.0539s/iter; left time: 1065.2203s\n",
      "\titers: 200, epoch: 12 | loss: 0.0669682\n",
      "\tspeed: 0.0304s/iter; left time: 596.5564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0686227 Vali Loss: 0.0691073 Test Loss: 0.1032993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0673451\n",
      "\tspeed: 0.0622s/iter; left time: 1214.1044s\n",
      "\titers: 200, epoch: 13 | loss: 0.0683151\n",
      "\tspeed: 0.0325s/iter; left time: 630.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0680458 Vali Loss: 0.0675273 Test Loss: 0.1039349\n",
      "Validation loss decreased (0.068943 --> 0.067527).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652825\n",
      "\tspeed: 0.0530s/iter; left time: 1022.8774s\n",
      "\titers: 200, epoch: 14 | loss: 0.0628644\n",
      "\tspeed: 0.0264s/iter; left time: 506.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0674227 Vali Loss: 0.0671743 Test Loss: 0.1023247\n",
      "Validation loss decreased (0.067527 --> 0.067174).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0616812\n",
      "\tspeed: 0.0507s/iter; left time: 967.2985s\n",
      "\titers: 200, epoch: 15 | loss: 0.0693523\n",
      "\tspeed: 0.0253s/iter; left time: 480.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0664551 Vali Loss: 0.0684299 Test Loss: 0.1042997\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0644902\n",
      "\tspeed: 0.0563s/iter; left time: 1061.5213s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676209\n",
      "\tspeed: 0.0285s/iter; left time: 534.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 223 | Train Loss: 0.0660602 Vali Loss: 0.0660850 Test Loss: 0.1023967\n",
      "Validation loss decreased (0.067174 --> 0.066085).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0672716\n",
      "\tspeed: 0.0551s/iter; left time: 1027.1806s\n",
      "\titers: 200, epoch: 17 | loss: 0.0643907\n",
      "\tspeed: 0.0261s/iter; left time: 483.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0654299 Vali Loss: 0.0666651 Test Loss: 0.1018439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0639353\n",
      "\tspeed: 0.0534s/iter; left time: 982.3298s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592492\n",
      "\tspeed: 0.0262s/iter; left time: 479.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0658197 Vali Loss: 0.0659764 Test Loss: 0.1009903\n",
      "Validation loss decreased (0.066085 --> 0.065976).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668463\n",
      "\tspeed: 0.0615s/iter; left time: 1118.1970s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674174\n",
      "\tspeed: 0.0303s/iter; left time: 547.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 223 | Train Loss: 0.0651498 Vali Loss: 0.0663798 Test Loss: 0.1016597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0635013\n",
      "\tspeed: 0.0647s/iter; left time: 1162.1521s\n",
      "\titers: 200, epoch: 20 | loss: 0.0671774\n",
      "\tspeed: 0.0335s/iter; left time: 599.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0646807 Vali Loss: 0.0652175 Test Loss: 0.1009260\n",
      "Validation loss decreased (0.065976 --> 0.065218).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0607012\n",
      "\tspeed: 0.0622s/iter; left time: 1102.9550s\n",
      "\titers: 200, epoch: 21 | loss: 0.0650992\n",
      "\tspeed: 0.0290s/iter; left time: 511.5359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 223 | Train Loss: 0.0641179 Vali Loss: 0.0648428 Test Loss: 0.1009107\n",
      "Validation loss decreased (0.065218 --> 0.064843).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0610474\n",
      "\tspeed: 0.0648s/iter; left time: 1134.5871s\n",
      "\titers: 200, epoch: 22 | loss: 0.0650357\n",
      "\tspeed: 0.0338s/iter; left time: 588.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0640069 Vali Loss: 0.0647188 Test Loss: 0.1011875\n",
      "Validation loss decreased (0.064843 --> 0.064719).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0614457\n",
      "\tspeed: 0.0533s/iter; left time: 922.5733s\n",
      "\titers: 200, epoch: 23 | loss: 0.0670610\n",
      "\tspeed: 0.0257s/iter; left time: 442.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0640793 Vali Loss: 0.0657229 Test Loss: 0.1011220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0619800\n",
      "\tspeed: 0.0551s/iter; left time: 939.9734s\n",
      "\titers: 200, epoch: 24 | loss: 0.0625510\n",
      "\tspeed: 0.0332s/iter; left time: 564.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 223 | Train Loss: 0.0637003 Vali Loss: 0.0649644 Test Loss: 0.1037946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0630417\n",
      "\tspeed: 0.0532s/iter; left time: 896.2902s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646923\n",
      "\tspeed: 0.0311s/iter; left time: 521.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0633564 Vali Loss: 0.0646941 Test Loss: 0.1002939\n",
      "Validation loss decreased (0.064719 --> 0.064694).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0629422\n",
      "\tspeed: 0.0527s/iter; left time: 876.1106s\n",
      "\titers: 200, epoch: 26 | loss: 0.0633350\n",
      "\tspeed: 0.0275s/iter; left time: 454.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0630587 Vali Loss: 0.0636250 Test Loss: 0.0998673\n",
      "Validation loss decreased (0.064694 --> 0.063625).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0636925\n",
      "\tspeed: 0.0514s/iter; left time: 843.3645s\n",
      "\titers: 200, epoch: 27 | loss: 0.0637900\n",
      "\tspeed: 0.0264s/iter; left time: 430.1127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0632786 Vali Loss: 0.0637099 Test Loss: 0.1002663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0639087\n",
      "\tspeed: 0.0514s/iter; left time: 832.0001s\n",
      "\titers: 200, epoch: 28 | loss: 0.0668686\n",
      "\tspeed: 0.0253s/iter; left time: 406.9075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0629415 Vali Loss: 0.0636809 Test Loss: 0.0993859\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596752\n",
      "\tspeed: 0.0491s/iter; left time: 783.5493s\n",
      "\titers: 200, epoch: 29 | loss: 0.0625523\n",
      "\tspeed: 0.0253s/iter; left time: 400.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0631238 Vali Loss: 0.0637909 Test Loss: 0.0995719\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0662444\n",
      "\tspeed: 0.0516s/iter; left time: 811.6074s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606233\n",
      "\tspeed: 0.0265s/iter; left time: 414.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0630985 Vali Loss: 0.0637063 Test Loss: 0.0998604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0611188\n",
      "\tspeed: 0.0531s/iter; left time: 823.2470s\n",
      "\titers: 200, epoch: 31 | loss: 0.0615757\n",
      "\tspeed: 0.0285s/iter; left time: 439.5417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0628123 Vali Loss: 0.0630970 Test Loss: 0.0985296\n",
      "Validation loss decreased (0.063625 --> 0.063097).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0599085\n",
      "\tspeed: 0.0561s/iter; left time: 857.9988s\n",
      "\titers: 200, epoch: 32 | loss: 0.0619325\n",
      "\tspeed: 0.0367s/iter; left time: 556.6943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0626171 Vali Loss: 0.0633582 Test Loss: 0.0999710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0590025\n",
      "\tspeed: 0.0563s/iter; left time: 847.4680s\n",
      "\titers: 200, epoch: 33 | loss: 0.0623721\n",
      "\tspeed: 0.0255s/iter; left time: 382.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0624677 Vali Loss: 0.0641703 Test Loss: 0.1002103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0645642\n",
      "\tspeed: 0.0508s/iter; left time: 754.4722s\n",
      "\titers: 200, epoch: 34 | loss: 0.0650208\n",
      "\tspeed: 0.0255s/iter; left time: 376.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0627143 Vali Loss: 0.0630594 Test Loss: 0.0980995\n",
      "Validation loss decreased (0.063097 --> 0.063059).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0650986\n",
      "\tspeed: 0.0543s/iter; left time: 793.7204s\n",
      "\titers: 200, epoch: 35 | loss: 0.0616681\n",
      "\tspeed: 0.0260s/iter; left time: 377.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0623243 Vali Loss: 0.0629922 Test Loss: 0.0984345\n",
      "Validation loss decreased (0.063059 --> 0.062992).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610814\n",
      "\tspeed: 0.0548s/iter; left time: 789.2754s\n",
      "\titers: 200, epoch: 36 | loss: 0.0613006\n",
      "\tspeed: 0.0252s/iter; left time: 360.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0623845 Vali Loss: 0.0630976 Test Loss: 0.0987953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0617679\n",
      "\tspeed: 0.0581s/iter; left time: 823.0756s\n",
      "\titers: 200, epoch: 37 | loss: 0.0624125\n",
      "\tspeed: 0.0376s/iter; left time: 529.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 223 | Train Loss: 0.0623172 Vali Loss: 0.0625196 Test Loss: 0.0982977\n",
      "Validation loss decreased (0.062992 --> 0.062520).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0617082\n",
      "\tspeed: 0.0536s/iter; left time: 748.2916s\n",
      "\titers: 200, epoch: 38 | loss: 0.0627187\n",
      "\tspeed: 0.0252s/iter; left time: 349.6241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0623510 Vali Loss: 0.0626276 Test Loss: 0.0980209\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0616402\n",
      "\tspeed: 0.0521s/iter; left time: 715.0430s\n",
      "\titers: 200, epoch: 39 | loss: 0.0646291\n",
      "\tspeed: 0.0336s/iter; left time: 458.5483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 223 | Train Loss: 0.0622662 Vali Loss: 0.0630252 Test Loss: 0.0990028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0618073\n",
      "\tspeed: 0.0507s/iter; left time: 684.8305s\n",
      "\titers: 200, epoch: 40 | loss: 0.0622323\n",
      "\tspeed: 0.0253s/iter; left time: 338.8046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0621098 Vali Loss: 0.0628508 Test Loss: 0.0989007\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0634673\n",
      "\tspeed: 0.0497s/iter; left time: 659.8885s\n",
      "\titers: 200, epoch: 41 | loss: 0.0603102\n",
      "\tspeed: 0.0252s/iter; left time: 332.6799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0621895 Vali Loss: 0.0628399 Test Loss: 0.0986511\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0639547\n",
      "\tspeed: 0.0514s/iter; left time: 671.1170s\n",
      "\titers: 200, epoch: 42 | loss: 0.0609568\n",
      "\tspeed: 0.0255s/iter; left time: 330.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0621274 Vali Loss: 0.0630174 Test Loss: 0.0989828\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0624392\n",
      "\tspeed: 0.0500s/iter; left time: 641.6003s\n",
      "\titers: 200, epoch: 43 | loss: 0.0614904\n",
      "\tspeed: 0.0252s/iter; left time: 321.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0629409 Vali Loss: 0.0635590 Test Loss: 0.0991788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0575654\n",
      "\tspeed: 0.0581s/iter; left time: 732.6023s\n",
      "\titers: 200, epoch: 44 | loss: 0.0639528\n",
      "\tspeed: 0.0270s/iter; left time: 337.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0620955 Vali Loss: 0.0630856 Test Loss: 0.0982748\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0632257\n",
      "\tspeed: 0.0616s/iter; left time: 762.7014s\n",
      "\titers: 200, epoch: 45 | loss: 0.0603562\n",
      "\tspeed: 0.0311s/iter; left time: 381.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 223 | Train Loss: 0.0622111 Vali Loss: 0.0629373 Test Loss: 0.0984318\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0649840\n",
      "\tspeed: 0.0516s/iter; left time: 627.6156s\n",
      "\titers: 200, epoch: 46 | loss: 0.0578174\n",
      "\tspeed: 0.0253s/iter; left time: 305.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0619493 Vali Loss: 0.0627788 Test Loss: 0.0984461\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0603537\n",
      "\tspeed: 0.0549s/iter; left time: 655.1375s\n",
      "\titers: 200, epoch: 47 | loss: 0.0605504\n",
      "\tspeed: 0.0257s/iter; left time: 303.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0621357 Vali Loss: 0.0625544 Test Loss: 0.0978829\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02906438522040844, rmse:0.17048279941082, mae:0.09829769283533096, rse:0.5017102360725403\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3095878\n",
      "\tspeed: 0.0282s/iter; left time: 625.9907s\n",
      "\titers: 200, epoch: 1 | loss: 0.2846880\n",
      "\tspeed: 0.0267s/iter; left time: 589.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.3149515 Vali Loss: 0.2382882 Test Loss: 0.2535693\n",
      "Validation loss decreased (inf --> 0.238288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1843008\n",
      "\tspeed: 0.0525s/iter; left time: 1152.7762s\n",
      "\titers: 200, epoch: 2 | loss: 0.1378197\n",
      "\tspeed: 0.0299s/iter; left time: 653.1159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.1838962 Vali Loss: 0.1047806 Test Loss: 0.1330730\n",
      "Validation loss decreased (0.238288 --> 0.104781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1103168\n",
      "\tspeed: 0.0571s/iter; left time: 1242.3420s\n",
      "\titers: 200, epoch: 3 | loss: 0.1015223\n",
      "\tspeed: 0.0345s/iter; left time: 746.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 223 | Train Loss: 0.1126171 Vali Loss: 0.0905170 Test Loss: 0.1279801\n",
      "Validation loss decreased (0.104781 --> 0.090517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919622\n",
      "\tspeed: 0.0634s/iter; left time: 1365.8374s\n",
      "\titers: 200, epoch: 4 | loss: 0.0899467\n",
      "\tspeed: 0.0326s/iter; left time: 698.4569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 223 | Train Loss: 0.0948411 Vali Loss: 0.0870812 Test Loss: 0.1231878\n",
      "Validation loss decreased (0.090517 --> 0.087081).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878488\n",
      "\tspeed: 0.0518s/iter; left time: 1104.8221s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811246\n",
      "\tspeed: 0.0319s/iter; left time: 677.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.0857307 Vali Loss: 0.0799312 Test Loss: 0.1179006\n",
      "Validation loss decreased (0.087081 --> 0.079931).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800256\n",
      "\tspeed: 0.0670s/iter; left time: 1412.8515s\n",
      "\titers: 200, epoch: 6 | loss: 0.0785767\n",
      "\tspeed: 0.0372s/iter; left time: 780.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0795904 Vali Loss: 0.0786093 Test Loss: 0.1165936\n",
      "Validation loss decreased (0.079931 --> 0.078609).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763542\n",
      "\tspeed: 0.0547s/iter; left time: 1141.3207s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759258\n",
      "\tspeed: 0.0323s/iter; left time: 671.0353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0754933 Vali Loss: 0.0756442 Test Loss: 0.1116529\n",
      "Validation loss decreased (0.078609 --> 0.075644).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752721\n",
      "\tspeed: 0.0665s/iter; left time: 1372.3782s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721395\n",
      "\tspeed: 0.0345s/iter; left time: 707.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 223 | Train Loss: 0.0727108 Vali Loss: 0.0725603 Test Loss: 0.1116315\n",
      "Validation loss decreased (0.075644 --> 0.072560).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758435\n",
      "\tspeed: 0.0511s/iter; left time: 1044.0557s\n",
      "\titers: 200, epoch: 9 | loss: 0.0791225\n",
      "\tspeed: 0.0255s/iter; left time: 517.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0715852 Vali Loss: 0.0727205 Test Loss: 0.1120276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0674759\n",
      "\tspeed: 0.0617s/iter; left time: 1246.9734s\n",
      "\titers: 200, epoch: 10 | loss: 0.0731568\n",
      "\tspeed: 0.0351s/iter; left time: 705.5101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 223 | Train Loss: 0.0706978 Vali Loss: 0.0707596 Test Loss: 0.1097052\n",
      "Validation loss decreased (0.072560 --> 0.070760).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714541\n",
      "\tspeed: 0.0601s/iter; left time: 1199.2612s\n",
      "\titers: 200, epoch: 11 | loss: 0.0678328\n",
      "\tspeed: 0.0273s/iter; left time: 541.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0689856 Vali Loss: 0.0697025 Test Loss: 0.1100525\n",
      "Validation loss decreased (0.070760 --> 0.069702).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0640860\n",
      "\tspeed: 0.0650s/iter; left time: 1282.7737s\n",
      "\titers: 200, epoch: 12 | loss: 0.0655003\n",
      "\tspeed: 0.0376s/iter; left time: 738.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0690159 Vali Loss: 0.0687588 Test Loss: 0.1068962\n",
      "Validation loss decreased (0.069702 --> 0.068759).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0670020\n",
      "\tspeed: 0.0565s/iter; left time: 1103.0713s\n",
      "\titers: 200, epoch: 13 | loss: 0.0688646\n",
      "\tspeed: 0.0255s/iter; left time: 496.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0672134 Vali Loss: 0.0689301 Test Loss: 0.1075063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0651034\n",
      "\tspeed: 0.0510s/iter; left time: 983.7461s\n",
      "\titers: 200, epoch: 14 | loss: 0.0691159\n",
      "\tspeed: 0.0252s/iter; left time: 484.7507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0666673 Vali Loss: 0.0694196 Test Loss: 0.1064784\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0623778\n",
      "\tspeed: 0.0513s/iter; left time: 979.6663s\n",
      "\titers: 200, epoch: 15 | loss: 0.0674270\n",
      "\tspeed: 0.0255s/iter; left time: 483.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0660632 Vali Loss: 0.0696463 Test Loss: 0.1083936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0664181\n",
      "\tspeed: 0.0576s/iter; left time: 1085.8458s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630234\n",
      "\tspeed: 0.0315s/iter; left time: 590.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 223 | Train Loss: 0.0659692 Vali Loss: 0.0667357 Test Loss: 0.1056346\n",
      "Validation loss decreased (0.068759 --> 0.066736).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0664413\n",
      "\tspeed: 0.0558s/iter; left time: 1040.0315s\n",
      "\titers: 200, epoch: 17 | loss: 0.0663331\n",
      "\tspeed: 0.0268s/iter; left time: 496.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0651848 Vali Loss: 0.0663038 Test Loss: 0.1051308\n",
      "Validation loss decreased (0.066736 --> 0.066304).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0647536\n",
      "\tspeed: 0.0559s/iter; left time: 1028.3598s\n",
      "\titers: 200, epoch: 18 | loss: 0.0672801\n",
      "\tspeed: 0.0286s/iter; left time: 523.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 223 | Train Loss: 0.0648823 Vali Loss: 0.0664386 Test Loss: 0.1055327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0637928\n",
      "\tspeed: 0.0524s/iter; left time: 953.7675s\n",
      "\titers: 200, epoch: 19 | loss: 0.0666910\n",
      "\tspeed: 0.0253s/iter; left time: 457.7309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0646910 Vali Loss: 0.0656113 Test Loss: 0.1049190\n",
      "Validation loss decreased (0.066304 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0642296\n",
      "\tspeed: 0.0534s/iter; left time: 959.6368s\n",
      "\titers: 200, epoch: 20 | loss: 0.0650020\n",
      "\tspeed: 0.0296s/iter; left time: 527.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 223 | Train Loss: 0.0643549 Vali Loss: 0.0659371 Test Loss: 0.1052411\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0636495\n",
      "\tspeed: 0.0575s/iter; left time: 1020.4282s\n",
      "\titers: 200, epoch: 21 | loss: 0.0621389\n",
      "\tspeed: 0.0298s/iter; left time: 526.1554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.0639638 Vali Loss: 0.0656817 Test Loss: 0.1049081\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0643470\n",
      "\tspeed: 0.0630s/iter; left time: 1103.0342s\n",
      "\titers: 200, epoch: 22 | loss: 0.0625110\n",
      "\tspeed: 0.0339s/iter; left time: 590.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0643106 Vali Loss: 0.0655123 Test Loss: 0.1046392\n",
      "Validation loss decreased (0.065611 --> 0.065512).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0634944\n",
      "\tspeed: 0.0543s/iter; left time: 938.6191s\n",
      "\titers: 200, epoch: 23 | loss: 0.0614964\n",
      "\tspeed: 0.0253s/iter; left time: 435.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0636988 Vali Loss: 0.0648778 Test Loss: 0.1025614\n",
      "Validation loss decreased (0.065512 --> 0.064878).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0617971\n",
      "\tspeed: 0.0561s/iter; left time: 958.4793s\n",
      "\titers: 200, epoch: 24 | loss: 0.0599708\n",
      "\tspeed: 0.0261s/iter; left time: 442.5567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0636706 Vali Loss: 0.0658749 Test Loss: 0.1044991\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0626105\n",
      "\tspeed: 0.0625s/iter; left time: 1052.7828s\n",
      "\titers: 200, epoch: 25 | loss: 0.0615660\n",
      "\tspeed: 0.0371s/iter; left time: 620.7709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 223 | Train Loss: 0.0632289 Vali Loss: 0.0645083 Test Loss: 0.1023642\n",
      "Validation loss decreased (0.064878 --> 0.064508).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0645861\n",
      "\tspeed: 0.0609s/iter; left time: 1012.8281s\n",
      "\titers: 200, epoch: 26 | loss: 0.0599332\n",
      "\tspeed: 0.0254s/iter; left time: 419.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0629630 Vali Loss: 0.0647196 Test Loss: 0.1022966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0656169\n",
      "\tspeed: 0.0501s/iter; left time: 821.5655s\n",
      "\titers: 200, epoch: 27 | loss: 0.0628372\n",
      "\tspeed: 0.0253s/iter; left time: 412.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0630329 Vali Loss: 0.0648018 Test Loss: 0.1027350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662400\n",
      "\tspeed: 0.0500s/iter; left time: 808.9678s\n",
      "\titers: 200, epoch: 28 | loss: 0.0637680\n",
      "\tspeed: 0.0254s/iter; left time: 407.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0629094 Vali Loss: 0.0646690 Test Loss: 0.1030339\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0623322\n",
      "\tspeed: 0.0501s/iter; left time: 798.7054s\n",
      "\titers: 200, epoch: 29 | loss: 0.0629570\n",
      "\tspeed: 0.0253s/iter; left time: 401.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0628110 Vali Loss: 0.0644566 Test Loss: 0.1030254\n",
      "Validation loss decreased (0.064508 --> 0.064457).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0589954\n",
      "\tspeed: 0.0634s/iter; left time: 997.6417s\n",
      "\titers: 200, epoch: 30 | loss: 0.0622966\n",
      "\tspeed: 0.0372s/iter; left time: 581.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 223 | Train Loss: 0.0626180 Vali Loss: 0.0651320 Test Loss: 0.1034185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0586849\n",
      "\tspeed: 0.0682s/iter; left time: 1057.8399s\n",
      "\titers: 200, epoch: 31 | loss: 0.0635693\n",
      "\tspeed: 0.0337s/iter; left time: 519.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 223 | Train Loss: 0.0625818 Vali Loss: 0.0647801 Test Loss: 0.1029215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628516\n",
      "\tspeed: 0.0526s/iter; left time: 804.0043s\n",
      "\titers: 200, epoch: 32 | loss: 0.0620919\n",
      "\tspeed: 0.0256s/iter; left time: 388.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0624514 Vali Loss: 0.0645339 Test Loss: 0.1029721\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0593516\n",
      "\tspeed: 0.0506s/iter; left time: 762.7600s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641283\n",
      "\tspeed: 0.0253s/iter; left time: 379.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0623991 Vali Loss: 0.0642009 Test Loss: 0.1022982\n",
      "Validation loss decreased (0.064457 --> 0.064201).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0646105\n",
      "\tspeed: 0.0568s/iter; left time: 842.4933s\n",
      "\titers: 200, epoch: 34 | loss: 0.0613008\n",
      "\tspeed: 0.0293s/iter; left time: 432.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 223 | Train Loss: 0.0625449 Vali Loss: 0.0651878 Test Loss: 0.1033512\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0659105\n",
      "\tspeed: 0.0551s/iter; left time: 805.3975s\n",
      "\titers: 200, epoch: 35 | loss: 0.0613998\n",
      "\tspeed: 0.0260s/iter; left time: 376.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0623078 Vali Loss: 0.0642447 Test Loss: 0.1024594\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0646801\n",
      "\tspeed: 0.0529s/iter; left time: 761.2991s\n",
      "\titers: 200, epoch: 36 | loss: 0.0661081\n",
      "\tspeed: 0.0256s/iter; left time: 365.8272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0623851 Vali Loss: 0.0641456 Test Loss: 0.1020538\n",
      "Validation loss decreased (0.064201 --> 0.064146).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0604092\n",
      "\tspeed: 0.0545s/iter; left time: 773.0185s\n",
      "\titers: 200, epoch: 37 | loss: 0.0590896\n",
      "\tspeed: 0.0268s/iter; left time: 376.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0620639 Vali Loss: 0.0641972 Test Loss: 0.1020894\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0601404\n",
      "\tspeed: 0.0539s/iter; left time: 751.9873s\n",
      "\titers: 200, epoch: 38 | loss: 0.0636847\n",
      "\tspeed: 0.0291s/iter; left time: 403.4781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 223 | Train Loss: 0.0620519 Vali Loss: 0.0642620 Test Loss: 0.1021246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0617320\n",
      "\tspeed: 0.0529s/iter; left time: 726.3793s\n",
      "\titers: 200, epoch: 39 | loss: 0.0602076\n",
      "\tspeed: 0.0254s/iter; left time: 345.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0621565 Vali Loss: 0.0642978 Test Loss: 0.1026060\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0602017\n",
      "\tspeed: 0.0512s/iter; left time: 691.7531s\n",
      "\titers: 200, epoch: 40 | loss: 0.0618844\n",
      "\tspeed: 0.0257s/iter; left time: 344.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.0620823 Vali Loss: 0.0640083 Test Loss: 0.1018651\n",
      "Validation loss decreased (0.064146 --> 0.064008).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0607183\n",
      "\tspeed: 0.0613s/iter; left time: 814.3781s\n",
      "\titers: 200, epoch: 41 | loss: 0.0624867\n",
      "\tspeed: 0.0388s/iter; left time: 511.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 223 | Train Loss: 0.0619868 Vali Loss: 0.0642335 Test Loss: 0.1026854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0619669\n",
      "\tspeed: 0.0603s/iter; left time: 787.2762s\n",
      "\titers: 200, epoch: 42 | loss: 0.0623490\n",
      "\tspeed: 0.0312s/iter; left time: 404.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 223 | Train Loss: 0.0620501 Vali Loss: 0.0638719 Test Loss: 0.1018439\n",
      "Validation loss decreased (0.064008 --> 0.063872).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0670535\n",
      "\tspeed: 0.0576s/iter; left time: 739.8168s\n",
      "\titers: 200, epoch: 43 | loss: 0.0630262\n",
      "\tspeed: 0.0308s/iter; left time: 391.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 223 | Train Loss: 0.0621233 Vali Loss: 0.0643988 Test Loss: 0.1027786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0630138\n",
      "\tspeed: 0.0567s/iter; left time: 715.0669s\n",
      "\titers: 200, epoch: 44 | loss: 0.0677117\n",
      "\tspeed: 0.0349s/iter; left time: 436.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 223 | Train Loss: 0.0620335 Vali Loss: 0.0640041 Test Loss: 0.1019148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0635344\n",
      "\tspeed: 0.0522s/iter; left time: 646.4224s\n",
      "\titers: 200, epoch: 45 | loss: 0.0588775\n",
      "\tspeed: 0.0278s/iter; left time: 341.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0620346 Vali Loss: 0.0640785 Test Loss: 0.1017932\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609881\n",
      "\tspeed: 0.0569s/iter; left time: 692.7576s\n",
      "\titers: 200, epoch: 46 | loss: 0.0626459\n",
      "\tspeed: 0.0310s/iter; left time: 373.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 223 | Train Loss: 0.0618815 Vali Loss: 0.0641125 Test Loss: 0.1021436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0600697\n",
      "\tspeed: 0.0549s/iter; left time: 655.3900s\n",
      "\titers: 200, epoch: 47 | loss: 0.0648041\n",
      "\tspeed: 0.0255s/iter; left time: 301.7709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0619033 Vali Loss: 0.0643325 Test Loss: 0.1027013\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0629921\n",
      "\tspeed: 0.0505s/iter; left time: 591.5241s\n",
      "\titers: 200, epoch: 48 | loss: 0.0617698\n",
      "\tspeed: 0.0252s/iter; left time: 293.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0618658 Vali Loss: 0.0639103 Test Loss: 0.1020392\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0588582\n",
      "\tspeed: 0.0522s/iter; left time: 599.9222s\n",
      "\titers: 200, epoch: 49 | loss: 0.0586269\n",
      "\tspeed: 0.0273s/iter; left time: 311.1080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0617974 Vali Loss: 0.0640440 Test Loss: 0.1023898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0619602\n",
      "\tspeed: 0.0509s/iter; left time: 573.5485s\n",
      "\titers: 200, epoch: 50 | loss: 0.0637882\n",
      "\tspeed: 0.0252s/iter; left time: 281.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0617129 Vali Loss: 0.0637848 Test Loss: 0.1019275\n",
      "Validation loss decreased (0.063872 --> 0.063785).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0629580\n",
      "\tspeed: 0.0589s/iter; left time: 651.2930s\n",
      "\titers: 200, epoch: 51 | loss: 0.0617654\n",
      "\tspeed: 0.0263s/iter; left time: 288.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 223 | Train Loss: 0.0618098 Vali Loss: 0.0640143 Test Loss: 0.1020329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0585091\n",
      "\tspeed: 0.0566s/iter; left time: 613.2590s\n",
      "\titers: 200, epoch: 52 | loss: 0.0629951\n",
      "\tspeed: 0.0281s/iter; left time: 301.1300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 223 | Train Loss: 0.0620232 Vali Loss: 0.0640034 Test Loss: 0.1020468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0577174\n",
      "\tspeed: 0.0531s/iter; left time: 562.6674s\n",
      "\titers: 200, epoch: 53 | loss: 0.0622370\n",
      "\tspeed: 0.0287s/iter; left time: 301.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0617491 Vali Loss: 0.0641319 Test Loss: 0.1022911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0613763\n",
      "\tspeed: 0.0510s/iter; left time: 529.7316s\n",
      "\titers: 200, epoch: 54 | loss: 0.0595834\n",
      "\tspeed: 0.0254s/iter; left time: 261.2731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 223 | Train Loss: 0.0618343 Vali Loss: 0.0644657 Test Loss: 0.1029476\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0606672\n",
      "\tspeed: 0.0559s/iter; left time: 567.6763s\n",
      "\titers: 200, epoch: 55 | loss: 0.0618241\n",
      "\tspeed: 0.0291s/iter; left time: 292.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 223 | Train Loss: 0.0618929 Vali Loss: 0.0642209 Test Loss: 0.1024468\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0609516\n",
      "\tspeed: 0.0524s/iter; left time: 520.2492s\n",
      "\titers: 200, epoch: 56 | loss: 0.0645796\n",
      "\tspeed: 0.0253s/iter; left time: 248.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0617286 Vali Loss: 0.0640785 Test Loss: 0.1021305\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0595435\n",
      "\tspeed: 0.0502s/iter; left time: 487.3489s\n",
      "\titers: 200, epoch: 57 | loss: 0.0649209\n",
      "\tspeed: 0.0253s/iter; left time: 243.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0618574 Vali Loss: 0.0641882 Test Loss: 0.1023234\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0653501\n",
      "\tspeed: 0.0622s/iter; left time: 590.5843s\n",
      "\titers: 200, epoch: 58 | loss: 0.0613151\n",
      "\tspeed: 0.0384s/iter; left time: 360.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 223 | Train Loss: 0.0618218 Vali Loss: 0.0639913 Test Loss: 0.1021550\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0604626\n",
      "\tspeed: 0.0659s/iter; left time: 610.3893s\n",
      "\titers: 200, epoch: 59 | loss: 0.0637192\n",
      "\tspeed: 0.0319s/iter; left time: 292.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0617459 Vali Loss: 0.0641744 Test Loss: 0.1023887\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0622743\n",
      "\tspeed: 0.0657s/iter; left time: 594.0138s\n",
      "\titers: 200, epoch: 60 | loss: 0.0604341\n",
      "\tspeed: 0.0361s/iter; left time: 322.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 223 | Train Loss: 0.0619015 Vali Loss: 0.0640619 Test Loss: 0.1019936\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.032928965985774994, rmse:0.18146340548992157, mae:0.1019275113940239, rse:0.5340248346328735\n",
      "Intermediate time for ES and pred_len 24: 00h:15m:11.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3147144\n",
      "\tspeed: 0.0506s/iter; left time: 1118.7917s\n",
      "\titers: 200, epoch: 1 | loss: 0.2925049\n",
      "\tspeed: 0.0259s/iter; left time: 570.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.3229047 Vali Loss: 0.2346041 Test Loss: 0.2518649\n",
      "Validation loss decreased (inf --> 0.234604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1552963\n",
      "\tspeed: 0.0537s/iter; left time: 1174.5975s\n",
      "\titers: 200, epoch: 2 | loss: 0.1211096\n",
      "\tspeed: 0.0290s/iter; left time: 632.2915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1671492 Vali Loss: 0.1110602 Test Loss: 0.1478291\n",
      "Validation loss decreased (0.234604 --> 0.111060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164386\n",
      "\tspeed: 0.0573s/iter; left time: 1240.4697s\n",
      "\titers: 200, epoch: 3 | loss: 0.1119621\n",
      "\tspeed: 0.0295s/iter; left time: 635.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 222 | Train Loss: 0.1146475 Vali Loss: 0.1073987 Test Loss: 0.1478716\n",
      "Validation loss decreased (0.111060 --> 0.107399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032833\n",
      "\tspeed: 0.0543s/iter; left time: 1163.9478s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009923\n",
      "\tspeed: 0.0268s/iter; left time: 571.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.1030029 Vali Loss: 0.1003884 Test Loss: 0.1412654\n",
      "Validation loss decreased (0.107399 --> 0.100388).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0954587\n",
      "\tspeed: 0.0539s/iter; left time: 1144.2138s\n",
      "\titers: 200, epoch: 5 | loss: 0.0962565\n",
      "\tspeed: 0.0261s/iter; left time: 551.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 222 | Train Loss: 0.0967893 Vali Loss: 0.0971172 Test Loss: 0.1377830\n",
      "Validation loss decreased (0.100388 --> 0.097117).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0903452\n",
      "\tspeed: 0.0515s/iter; left time: 1081.9439s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906657\n",
      "\tspeed: 0.0268s/iter; left time: 559.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0936582 Vali Loss: 0.0939101 Test Loss: 0.1363251\n",
      "Validation loss decreased (0.097117 --> 0.093910).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0918095\n",
      "\tspeed: 0.0522s/iter; left time: 1084.1001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0964305\n",
      "\tspeed: 0.0275s/iter; left time: 568.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0907185 Vali Loss: 0.0936447 Test Loss: 0.1374800\n",
      "Validation loss decreased (0.093910 --> 0.093645).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0910271\n",
      "\tspeed: 0.0522s/iter; left time: 1072.1805s\n",
      "\titers: 200, epoch: 8 | loss: 0.0866849\n",
      "\tspeed: 0.0258s/iter; left time: 527.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.0888777 Vali Loss: 0.0896958 Test Loss: 0.1312113\n",
      "Validation loss decreased (0.093645 --> 0.089696).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0848824\n",
      "\tspeed: 0.0530s/iter; left time: 1076.2463s\n",
      "\titers: 200, epoch: 9 | loss: 0.0855493\n",
      "\tspeed: 0.0260s/iter; left time: 525.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 222 | Train Loss: 0.0875627 Vali Loss: 0.0869981 Test Loss: 0.1295556\n",
      "Validation loss decreased (0.089696 --> 0.086998).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0843736\n",
      "\tspeed: 0.0513s/iter; left time: 1031.3458s\n",
      "\titers: 200, epoch: 10 | loss: 0.0897565\n",
      "\tspeed: 0.0258s/iter; left time: 515.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.0861446 Vali Loss: 0.0884001 Test Loss: 0.1309070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0866483\n",
      "\tspeed: 0.0519s/iter; left time: 1031.6928s\n",
      "\titers: 200, epoch: 11 | loss: 0.0819987\n",
      "\tspeed: 0.0302s/iter; left time: 597.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0855203 Vali Loss: 0.0878138 Test Loss: 0.1286195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839683\n",
      "\tspeed: 0.0531s/iter; left time: 1044.2122s\n",
      "\titers: 200, epoch: 12 | loss: 0.0873688\n",
      "\tspeed: 0.0263s/iter; left time: 514.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0852414 Vali Loss: 0.0858418 Test Loss: 0.1268850\n",
      "Validation loss decreased (0.086998 --> 0.085842).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858119\n",
      "\tspeed: 0.0517s/iter; left time: 1005.3490s\n",
      "\titers: 200, epoch: 13 | loss: 0.0832708\n",
      "\tspeed: 0.0258s/iter; left time: 498.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.0842663 Vali Loss: 0.0877689 Test Loss: 0.1296467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0802648\n",
      "\tspeed: 0.0529s/iter; left time: 1016.5755s\n",
      "\titers: 200, epoch: 14 | loss: 0.0827321\n",
      "\tspeed: 0.0272s/iter; left time: 519.2164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0838558 Vali Loss: 0.0881953 Test Loss: 0.1267008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0872370\n",
      "\tspeed: 0.0518s/iter; left time: 982.8927s\n",
      "\titers: 200, epoch: 15 | loss: 0.0858869\n",
      "\tspeed: 0.0258s/iter; left time: 487.0524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 222 | Train Loss: 0.0842359 Vali Loss: 0.0871689 Test Loss: 0.1293593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0799319\n",
      "\tspeed: 0.0525s/iter; left time: 985.0533s\n",
      "\titers: 200, epoch: 16 | loss: 0.0849701\n",
      "\tspeed: 0.0293s/iter; left time: 547.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0831073 Vali Loss: 0.0856804 Test Loss: 0.1255846\n",
      "Validation loss decreased (0.085842 --> 0.085680).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0806165\n",
      "\tspeed: 0.0544s/iter; left time: 1008.7977s\n",
      "\titers: 200, epoch: 17 | loss: 0.0817643\n",
      "\tspeed: 0.0262s/iter; left time: 482.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 222 | Train Loss: 0.0832091 Vali Loss: 0.0855700 Test Loss: 0.1275130\n",
      "Validation loss decreased (0.085680 --> 0.085570).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0841565\n",
      "\tspeed: 0.0511s/iter; left time: 937.0676s\n",
      "\titers: 200, epoch: 18 | loss: 0.0794272\n",
      "\tspeed: 0.0258s/iter; left time: 470.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.0822500 Vali Loss: 0.0857329 Test Loss: 0.1248757\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0837666\n",
      "\tspeed: 0.0499s/iter; left time: 902.8464s\n",
      "\titers: 200, epoch: 19 | loss: 0.0838962\n",
      "\tspeed: 0.0261s/iter; left time: 469.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.0820560 Vali Loss: 0.0855009 Test Loss: 0.1276632\n",
      "Validation loss decreased (0.085570 --> 0.085501).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806025\n",
      "\tspeed: 0.0533s/iter; left time: 954.0461s\n",
      "\titers: 200, epoch: 20 | loss: 0.0830378\n",
      "\tspeed: 0.0305s/iter; left time: 542.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 222 | Train Loss: 0.0815742 Vali Loss: 0.0851702 Test Loss: 0.1256440\n",
      "Validation loss decreased (0.085501 --> 0.085170).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0797350\n",
      "\tspeed: 0.0574s/iter; left time: 1014.0133s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823162\n",
      "\tspeed: 0.0299s/iter; left time: 524.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0818243 Vali Loss: 0.0847368 Test Loss: 0.1272609\n",
      "Validation loss decreased (0.085170 --> 0.084737).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0804891\n",
      "\tspeed: 0.0524s/iter; left time: 914.1517s\n",
      "\titers: 200, epoch: 22 | loss: 0.0819062\n",
      "\tspeed: 0.0278s/iter; left time: 481.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0813939 Vali Loss: 0.0853985 Test Loss: 0.1267670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0816699\n",
      "\tspeed: 0.0522s/iter; left time: 898.5325s\n",
      "\titers: 200, epoch: 23 | loss: 0.0776531\n",
      "\tspeed: 0.0321s/iter; left time: 549.7912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 222 | Train Loss: 0.0815781 Vali Loss: 0.0841971 Test Loss: 0.1261182\n",
      "Validation loss decreased (0.084737 --> 0.084197).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0820762\n",
      "\tspeed: 0.0523s/iter; left time: 888.1041s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773915\n",
      "\tspeed: 0.0265s/iter; left time: 448.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0810857 Vali Loss: 0.0843296 Test Loss: 0.1273272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0809451\n",
      "\tspeed: 0.0524s/iter; left time: 878.4318s\n",
      "\titers: 200, epoch: 25 | loss: 0.0818676\n",
      "\tspeed: 0.0259s/iter; left time: 432.5094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0809346 Vali Loss: 0.0854437 Test Loss: 0.1285678\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0845236\n",
      "\tspeed: 0.0526s/iter; left time: 870.2334s\n",
      "\titers: 200, epoch: 26 | loss: 0.0827319\n",
      "\tspeed: 0.0280s/iter; left time: 460.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0807819 Vali Loss: 0.0845679 Test Loss: 0.1268232\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0823765\n",
      "\tspeed: 0.0514s/iter; left time: 839.6246s\n",
      "\titers: 200, epoch: 27 | loss: 0.0806511\n",
      "\tspeed: 0.0300s/iter; left time: 486.1277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0810077 Vali Loss: 0.0845672 Test Loss: 0.1260933\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0770651\n",
      "\tspeed: 0.0521s/iter; left time: 839.8446s\n",
      "\titers: 200, epoch: 28 | loss: 0.0817216\n",
      "\tspeed: 0.0281s/iter; left time: 450.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0805071 Vali Loss: 0.0847881 Test Loss: 0.1277687\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0812074\n",
      "\tspeed: 0.0513s/iter; left time: 814.6511s\n",
      "\titers: 200, epoch: 29 | loss: 0.0808156\n",
      "\tspeed: 0.0308s/iter; left time: 485.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 222 | Train Loss: 0.0805530 Vali Loss: 0.0840625 Test Loss: 0.1270644\n",
      "Validation loss decreased (0.084197 --> 0.084063).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0776299\n",
      "\tspeed: 0.0560s/iter; left time: 877.0118s\n",
      "\titers: 200, epoch: 30 | loss: 0.0778471\n",
      "\tspeed: 0.0276s/iter; left time: 429.1950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0804039 Vali Loss: 0.0845094 Test Loss: 0.1272635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807393\n",
      "\tspeed: 0.0594s/iter; left time: 917.9660s\n",
      "\titers: 200, epoch: 31 | loss: 0.0762016\n",
      "\tspeed: 0.0264s/iter; left time: 405.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0804234 Vali Loss: 0.0842582 Test Loss: 0.1268570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0788464\n",
      "\tspeed: 0.0514s/iter; left time: 781.5095s\n",
      "\titers: 200, epoch: 32 | loss: 0.0814512\n",
      "\tspeed: 0.0258s/iter; left time: 389.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 222 | Train Loss: 0.0803919 Vali Loss: 0.0842488 Test Loss: 0.1268193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0808462\n",
      "\tspeed: 0.0573s/iter; left time: 859.1867s\n",
      "\titers: 200, epoch: 33 | loss: 0.0800650\n",
      "\tspeed: 0.0277s/iter; left time: 411.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 222 | Train Loss: 0.0800392 Vali Loss: 0.0839568 Test Loss: 0.1268096\n",
      "Validation loss decreased (0.084063 --> 0.083957).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0813101\n",
      "\tspeed: 0.0530s/iter; left time: 782.9671s\n",
      "\titers: 200, epoch: 34 | loss: 0.0858657\n",
      "\tspeed: 0.0295s/iter; left time: 433.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0800681 Vali Loss: 0.0845444 Test Loss: 0.1273314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0798160\n",
      "\tspeed: 0.0573s/iter; left time: 833.4869s\n",
      "\titers: 200, epoch: 35 | loss: 0.0825624\n",
      "\tspeed: 0.0264s/iter; left time: 381.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0802181 Vali Loss: 0.0837327 Test Loss: 0.1259956\n",
      "Validation loss decreased (0.083957 --> 0.083733).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0789562\n",
      "\tspeed: 0.0528s/iter; left time: 757.3356s\n",
      "\titers: 200, epoch: 36 | loss: 0.0805244\n",
      "\tspeed: 0.0259s/iter; left time: 368.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.0799615 Vali Loss: 0.0845624 Test Loss: 0.1275047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0831004\n",
      "\tspeed: 0.0526s/iter; left time: 742.3953s\n",
      "\titers: 200, epoch: 37 | loss: 0.0802114\n",
      "\tspeed: 0.0284s/iter; left time: 397.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0800447 Vali Loss: 0.0841669 Test Loss: 0.1267800\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0804705\n",
      "\tspeed: 0.0509s/iter; left time: 706.9451s\n",
      "\titers: 200, epoch: 38 | loss: 0.0782143\n",
      "\tspeed: 0.0259s/iter; left time: 356.5367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0799718 Vali Loss: 0.0836434 Test Loss: 0.1263771\n",
      "Validation loss decreased (0.083733 --> 0.083643).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0811858\n",
      "\tspeed: 0.0556s/iter; left time: 759.8070s\n",
      "\titers: 200, epoch: 39 | loss: 0.0790170\n",
      "\tspeed: 0.0270s/iter; left time: 365.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0798839 Vali Loss: 0.0839752 Test Loss: 0.1270642\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0788038\n",
      "\tspeed: 0.0543s/iter; left time: 729.3821s\n",
      "\titers: 200, epoch: 40 | loss: 0.0798554\n",
      "\tspeed: 0.0266s/iter; left time: 354.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0802005 Vali Loss: 0.0837913 Test Loss: 0.1266331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0786112\n",
      "\tspeed: 0.0517s/iter; left time: 682.8798s\n",
      "\titers: 200, epoch: 41 | loss: 0.0789183\n",
      "\tspeed: 0.0329s/iter; left time: 431.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 222 | Train Loss: 0.0797981 Vali Loss: 0.0837880 Test Loss: 0.1268152\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0781712\n",
      "\tspeed: 0.0549s/iter; left time: 714.2062s\n",
      "\titers: 200, epoch: 42 | loss: 0.0819774\n",
      "\tspeed: 0.0308s/iter; left time: 397.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 222 | Train Loss: 0.0798018 Vali Loss: 0.0837896 Test Loss: 0.1271350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0799049\n",
      "\tspeed: 0.0531s/iter; left time: 678.1094s\n",
      "\titers: 200, epoch: 43 | loss: 0.0801999\n",
      "\tspeed: 0.0268s/iter; left time: 339.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.0799342 Vali Loss: 0.0839139 Test Loss: 0.1264891\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0828093\n",
      "\tspeed: 0.0536s/iter; left time: 672.5967s\n",
      "\titers: 200, epoch: 44 | loss: 0.0812048\n",
      "\tspeed: 0.0304s/iter; left time: 378.6484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0797609 Vali Loss: 0.0839898 Test Loss: 0.1268618\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0828152\n",
      "\tspeed: 0.0528s/iter; left time: 650.7907s\n",
      "\titers: 200, epoch: 45 | loss: 0.0787516\n",
      "\tspeed: 0.0280s/iter; left time: 342.6526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.0797723 Vali Loss: 0.0836721 Test Loss: 0.1261226\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0806987\n",
      "\tspeed: 0.0531s/iter; left time: 643.4618s\n",
      "\titers: 200, epoch: 46 | loss: 0.0800966\n",
      "\tspeed: 0.0264s/iter; left time: 316.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0797689 Vali Loss: 0.0840444 Test Loss: 0.1267351\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0791417\n",
      "\tspeed: 0.0600s/iter; left time: 713.7216s\n",
      "\titers: 200, epoch: 47 | loss: 0.0785033\n",
      "\tspeed: 0.0283s/iter; left time: 333.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 222 | Train Loss: 0.0796246 Vali Loss: 0.0835991 Test Loss: 0.1263401\n",
      "Validation loss decreased (0.083643 --> 0.083599).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0808136\n",
      "\tspeed: 0.0513s/iter; left time: 598.9443s\n",
      "\titers: 200, epoch: 48 | loss: 0.0766873\n",
      "\tspeed: 0.0258s/iter; left time: 297.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.0797899 Vali Loss: 0.0834704 Test Loss: 0.1263111\n",
      "Validation loss decreased (0.083599 --> 0.083470).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0803966\n",
      "\tspeed: 0.0523s/iter; left time: 598.3663s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801051\n",
      "\tspeed: 0.0263s/iter; left time: 298.2800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 222 | Train Loss: 0.0797105 Vali Loss: 0.0834076 Test Loss: 0.1260195\n",
      "Validation loss decreased (0.083470 --> 0.083408).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0805158\n",
      "\tspeed: 0.0588s/iter; left time: 660.0481s\n",
      "\titers: 200, epoch: 50 | loss: 0.0790699\n",
      "\tspeed: 0.0303s/iter; left time: 337.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 222 | Train Loss: 0.0796255 Vali Loss: 0.0834769 Test Loss: 0.1261945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0814191\n",
      "\tspeed: 0.0575s/iter; left time: 632.2825s\n",
      "\titers: 200, epoch: 51 | loss: 0.0806363\n",
      "\tspeed: 0.0302s/iter; left time: 329.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 222 | Train Loss: 0.0795828 Vali Loss: 0.0833282 Test Loss: 0.1265159\n",
      "Validation loss decreased (0.083408 --> 0.083328).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0780337\n",
      "\tspeed: 0.0593s/iter; left time: 638.6661s\n",
      "\titers: 200, epoch: 52 | loss: 0.0797252\n",
      "\tspeed: 0.0257s/iter; left time: 274.8420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0798460 Vali Loss: 0.0840704 Test Loss: 0.1270625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0840050\n",
      "\tspeed: 0.0517s/iter; left time: 545.6285s\n",
      "\titers: 200, epoch: 53 | loss: 0.0785592\n",
      "\tspeed: 0.0271s/iter; left time: 283.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0796591 Vali Loss: 0.0837892 Test Loss: 0.1264517\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0813148\n",
      "\tspeed: 0.0537s/iter; left time: 555.4107s\n",
      "\titers: 200, epoch: 54 | loss: 0.0787035\n",
      "\tspeed: 0.0259s/iter; left time: 264.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0796568 Vali Loss: 0.0834680 Test Loss: 0.1262538\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0814416\n",
      "\tspeed: 0.0544s/iter; left time: 550.1668s\n",
      "\titers: 200, epoch: 55 | loss: 0.0801050\n",
      "\tspeed: 0.0316s/iter; left time: 316.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 222 | Train Loss: 0.0795421 Vali Loss: 0.0835235 Test Loss: 0.1266008\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0787414\n",
      "\tspeed: 0.0585s/iter; left time: 578.8855s\n",
      "\titers: 200, epoch: 56 | loss: 0.0789879\n",
      "\tspeed: 0.0315s/iter; left time: 308.4581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 222 | Train Loss: 0.0797317 Vali Loss: 0.0836352 Test Loss: 0.1266329\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0797672\n",
      "\tspeed: 0.0540s/iter; left time: 522.5271s\n",
      "\titers: 200, epoch: 57 | loss: 0.0810083\n",
      "\tspeed: 0.0308s/iter; left time: 294.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0796932 Vali Loss: 0.0832805 Test Loss: 0.1264449\n",
      "Validation loss decreased (0.083328 --> 0.083280).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0760169\n",
      "\tspeed: 0.0519s/iter; left time: 489.9648s\n",
      "\titers: 200, epoch: 58 | loss: 0.0813728\n",
      "\tspeed: 0.0294s/iter; left time: 274.4056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0796088 Vali Loss: 0.0838469 Test Loss: 0.1267040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0788409\n",
      "\tspeed: 0.0508s/iter; left time: 468.7382s\n",
      "\titers: 200, epoch: 59 | loss: 0.0804135\n",
      "\tspeed: 0.0335s/iter; left time: 305.8835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 222 | Train Loss: 0.0795634 Vali Loss: 0.0838044 Test Loss: 0.1269941\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0783219\n",
      "\tspeed: 0.0654s/iter; left time: 589.1869s\n",
      "\titers: 200, epoch: 60 | loss: 0.0841002\n",
      "\tspeed: 0.0284s/iter; left time: 252.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 222 | Train Loss: 0.0796183 Vali Loss: 0.0838897 Test Loss: 0.1267204\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0775512\n",
      "\tspeed: 0.0634s/iter; left time: 556.3048s\n",
      "\titers: 200, epoch: 61 | loss: 0.0815161\n",
      "\tspeed: 0.0307s/iter; left time: 266.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 222 | Train Loss: 0.0797751 Vali Loss: 0.0837657 Test Loss: 0.1268313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0789304\n",
      "\tspeed: 0.0538s/iter; left time: 460.2193s\n",
      "\titers: 200, epoch: 62 | loss: 0.0806428\n",
      "\tspeed: 0.0301s/iter; left time: 254.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 222 | Train Loss: 0.0797962 Vali Loss: 0.0837555 Test Loss: 0.1266953\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0824143\n",
      "\tspeed: 0.0620s/iter; left time: 517.2783s\n",
      "\titers: 200, epoch: 63 | loss: 0.0783244\n",
      "\tspeed: 0.0388s/iter; left time: 319.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 222 | Train Loss: 0.0797104 Vali Loss: 0.0837145 Test Loss: 0.1266875\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0772666\n",
      "\tspeed: 0.0603s/iter; left time: 489.3886s\n",
      "\titers: 200, epoch: 64 | loss: 0.0793409\n",
      "\tspeed: 0.0342s/iter; left time: 274.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 222 | Train Loss: 0.0796188 Vali Loss: 0.0832771 Test Loss: 0.1262297\n",
      "Validation loss decreased (0.083280 --> 0.083277).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0809730\n",
      "\tspeed: 0.0568s/iter; left time: 448.1755s\n",
      "\titers: 200, epoch: 65 | loss: 0.0801059\n",
      "\tspeed: 0.0280s/iter; left time: 218.2879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0796872 Vali Loss: 0.0837495 Test Loss: 0.1269260\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0809179\n",
      "\tspeed: 0.0518s/iter; left time: 397.7083s\n",
      "\titers: 200, epoch: 66 | loss: 0.0784104\n",
      "\tspeed: 0.0290s/iter; left time: 219.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.0795468 Vali Loss: 0.0838777 Test Loss: 0.1269372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0782233\n",
      "\tspeed: 0.0523s/iter; left time: 389.8203s\n",
      "\titers: 200, epoch: 67 | loss: 0.0799672\n",
      "\tspeed: 0.0285s/iter; left time: 209.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0795998 Vali Loss: 0.0834554 Test Loss: 0.1266113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0811003\n",
      "\tspeed: 0.0532s/iter; left time: 384.4446s\n",
      "\titers: 200, epoch: 68 | loss: 0.0768890\n",
      "\tspeed: 0.0284s/iter; left time: 202.1263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0795308 Vali Loss: 0.0838681 Test Loss: 0.1267072\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0808652\n",
      "\tspeed: 0.0590s/iter; left time: 413.1546s\n",
      "\titers: 200, epoch: 69 | loss: 0.0773047\n",
      "\tspeed: 0.0295s/iter; left time: 203.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 222 | Train Loss: 0.0797469 Vali Loss: 0.0836857 Test Loss: 0.1267984\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0814931\n",
      "\tspeed: 0.0521s/iter; left time: 353.1724s\n",
      "\titers: 200, epoch: 70 | loss: 0.0806888\n",
      "\tspeed: 0.0326s/iter; left time: 217.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0795766 Vali Loss: 0.0834152 Test Loss: 0.1265499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0793127\n",
      "\tspeed: 0.0565s/iter; left time: 370.4135s\n",
      "\titers: 200, epoch: 71 | loss: 0.0795124\n",
      "\tspeed: 0.0271s/iter; left time: 175.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0797065 Vali Loss: 0.0836492 Test Loss: 0.1266932\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0804654\n",
      "\tspeed: 0.0621s/iter; left time: 393.5140s\n",
      "\titers: 200, epoch: 72 | loss: 0.0777024\n",
      "\tspeed: 0.0397s/iter; left time: 247.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 222 | Train Loss: 0.0795684 Vali Loss: 0.0837382 Test Loss: 0.1267288\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0782249\n",
      "\tspeed: 0.0655s/iter; left time: 400.5556s\n",
      "\titers: 200, epoch: 73 | loss: 0.0794195\n",
      "\tspeed: 0.0377s/iter; left time: 227.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 222 | Train Loss: 0.0795603 Vali Loss: 0.0838102 Test Loss: 0.1267575\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0813729\n",
      "\tspeed: 0.0641s/iter; left time: 378.0421s\n",
      "\titers: 200, epoch: 74 | loss: 0.0786692\n",
      "\tspeed: 0.0329s/iter; left time: 190.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 222 | Train Loss: 0.0794573 Vali Loss: 0.0836709 Test Loss: 0.1266025\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111006110906601, rmse:0.20275616645812988, mae:0.12622971832752228, rse:0.5956366062164307\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3174569\n",
      "\tspeed: 0.0414s/iter; left time: 915.3982s\n",
      "\titers: 200, epoch: 1 | loss: 0.2874222\n",
      "\tspeed: 0.0332s/iter; left time: 729.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 222 | Train Loss: 0.3200442 Vali Loss: 0.2401257 Test Loss: 0.2517047\n",
      "Validation loss decreased (inf --> 0.240126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520367\n",
      "\tspeed: 0.0620s/iter; left time: 1355.6377s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273854\n",
      "\tspeed: 0.0279s/iter; left time: 606.7683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 222 | Train Loss: 0.1663707 Vali Loss: 0.1111739 Test Loss: 0.1514155\n",
      "Validation loss decreased (0.240126 --> 0.111174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139742\n",
      "\tspeed: 0.0611s/iter; left time: 1322.4532s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096063\n",
      "\tspeed: 0.0282s/iter; left time: 608.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 222 | Train Loss: 0.1149485 Vali Loss: 0.1040322 Test Loss: 0.1489903\n",
      "Validation loss decreased (0.111174 --> 0.104032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1043336\n",
      "\tspeed: 0.0724s/iter; left time: 1551.4241s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003359\n",
      "\tspeed: 0.0290s/iter; left time: 619.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 222 | Train Loss: 0.1034319 Vali Loss: 0.1016531 Test Loss: 0.1473366\n",
      "Validation loss decreased (0.104032 --> 0.101653).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0917278\n",
      "\tspeed: 0.0520s/iter; left time: 1102.5629s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893141\n",
      "\tspeed: 0.0259s/iter; left time: 547.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0963177 Vali Loss: 0.0941593 Test Loss: 0.1412795\n",
      "Validation loss decreased (0.101653 --> 0.094159).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0923875\n",
      "\tspeed: 0.0669s/iter; left time: 1405.0974s\n",
      "\titers: 200, epoch: 6 | loss: 0.0910395\n",
      "\tspeed: 0.0272s/iter; left time: 568.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 222 | Train Loss: 0.0922865 Vali Loss: 0.0903410 Test Loss: 0.1363947\n",
      "Validation loss decreased (0.094159 --> 0.090341).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0934827\n",
      "\tspeed: 0.0657s/iter; left time: 1363.5034s\n",
      "\titers: 200, epoch: 7 | loss: 0.0894494\n",
      "\tspeed: 0.0396s/iter; left time: 818.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 222 | Train Loss: 0.0903477 Vali Loss: 0.0889590 Test Loss: 0.1351245\n",
      "Validation loss decreased (0.090341 --> 0.088959).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0891881\n",
      "\tspeed: 0.0689s/iter; left time: 1416.1012s\n",
      "\titers: 200, epoch: 8 | loss: 0.0858067\n",
      "\tspeed: 0.0369s/iter; left time: 753.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 222 | Train Loss: 0.0891087 Vali Loss: 0.0881565 Test Loss: 0.1346339\n",
      "Validation loss decreased (0.088959 --> 0.088156).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0931924\n",
      "\tspeed: 0.0653s/iter; left time: 1326.5419s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847007\n",
      "\tspeed: 0.0379s/iter; left time: 767.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 222 | Train Loss: 0.0870853 Vali Loss: 0.0870163 Test Loss: 0.1314254\n",
      "Validation loss decreased (0.088156 --> 0.087016).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865444\n",
      "\tspeed: 0.0707s/iter; left time: 1421.3547s\n",
      "\titers: 200, epoch: 10 | loss: 0.0868875\n",
      "\tspeed: 0.0350s/iter; left time: 699.7988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 222 | Train Loss: 0.0864941 Vali Loss: 0.0867136 Test Loss: 0.1312937\n",
      "Validation loss decreased (0.087016 --> 0.086714).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0879679\n",
      "\tspeed: 0.0652s/iter; left time: 1296.7337s\n",
      "\titers: 200, epoch: 11 | loss: 0.0835632\n",
      "\tspeed: 0.0332s/iter; left time: 657.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 222 | Train Loss: 0.0852561 Vali Loss: 0.0857169 Test Loss: 0.1296604\n",
      "Validation loss decreased (0.086714 --> 0.085717).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0832732\n",
      "\tspeed: 0.0685s/iter; left time: 1345.9141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0896635\n",
      "\tspeed: 0.0412s/iter; left time: 806.5568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.0848608 Vali Loss: 0.0854348 Test Loss: 0.1307113\n",
      "Validation loss decreased (0.085717 --> 0.085435).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0844016\n",
      "\tspeed: 0.0609s/iter; left time: 1184.2072s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800547\n",
      "\tspeed: 0.0381s/iter; left time: 737.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 222 | Train Loss: 0.0840051 Vali Loss: 0.0850748 Test Loss: 0.1283702\n",
      "Validation loss decreased (0.085435 --> 0.085075).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0843181\n",
      "\tspeed: 0.0627s/iter; left time: 1204.7657s\n",
      "\titers: 200, epoch: 14 | loss: 0.0888538\n",
      "\tspeed: 0.0374s/iter; left time: 715.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 222 | Train Loss: 0.0836061 Vali Loss: 0.0844848 Test Loss: 0.1264425\n",
      "Validation loss decreased (0.085075 --> 0.084485).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0833333\n",
      "\tspeed: 0.0709s/iter; left time: 1346.8626s\n",
      "\titers: 200, epoch: 15 | loss: 0.0808878\n",
      "\tspeed: 0.0381s/iter; left time: 720.3174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.86s\n",
      "Steps: 222 | Train Loss: 0.0825280 Vali Loss: 0.0848763 Test Loss: 0.1277237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0840514\n",
      "\tspeed: 0.0687s/iter; left time: 1288.7196s\n",
      "\titers: 200, epoch: 16 | loss: 0.0815270\n",
      "\tspeed: 0.0419s/iter; left time: 782.4158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.0822666 Vali Loss: 0.0856214 Test Loss: 0.1280824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0864338\n",
      "\tspeed: 0.0659s/iter; left time: 1222.1559s\n",
      "\titers: 200, epoch: 17 | loss: 0.0808191\n",
      "\tspeed: 0.0419s/iter; left time: 772.4947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 222 | Train Loss: 0.0820803 Vali Loss: 0.0837292 Test Loss: 0.1242595\n",
      "Validation loss decreased (0.084485 --> 0.083729).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773598\n",
      "\tspeed: 0.0675s/iter; left time: 1236.4018s\n",
      "\titers: 200, epoch: 18 | loss: 0.0802323\n",
      "\tspeed: 0.0397s/iter; left time: 723.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 222 | Train Loss: 0.0818475 Vali Loss: 0.0837921 Test Loss: 0.1254752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0826434\n",
      "\tspeed: 0.0654s/iter; left time: 1184.9616s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797695\n",
      "\tspeed: 0.0393s/iter; left time: 708.3171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 222 | Train Loss: 0.0816632 Vali Loss: 0.0836134 Test Loss: 0.1255648\n",
      "Validation loss decreased (0.083729 --> 0.083613).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0817181\n",
      "\tspeed: 0.0655s/iter; left time: 1171.4449s\n",
      "\titers: 200, epoch: 20 | loss: 0.0775445\n",
      "\tspeed: 0.0284s/iter; left time: 505.1861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 222 | Train Loss: 0.0811057 Vali Loss: 0.0838256 Test Loss: 0.1260239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0806698\n",
      "\tspeed: 0.0542s/iter; left time: 957.0289s\n",
      "\titers: 200, epoch: 21 | loss: 0.0808875\n",
      "\tspeed: 0.0308s/iter; left time: 541.2674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0808358 Vali Loss: 0.0849322 Test Loss: 0.1275872\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0797668\n",
      "\tspeed: 0.0654s/iter; left time: 1140.5787s\n",
      "\titers: 200, epoch: 22 | loss: 0.0799021\n",
      "\tspeed: 0.0273s/iter; left time: 473.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 222 | Train Loss: 0.0807036 Vali Loss: 0.0833376 Test Loss: 0.1247943\n",
      "Validation loss decreased (0.083613 --> 0.083338).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0894037\n",
      "\tspeed: 0.0619s/iter; left time: 1066.3047s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779009\n",
      "\tspeed: 0.0378s/iter; left time: 647.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 222 | Train Loss: 0.0807531 Vali Loss: 0.0837554 Test Loss: 0.1260827\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0829525\n",
      "\tspeed: 0.0669s/iter; left time: 1137.3036s\n",
      "\titers: 200, epoch: 24 | loss: 0.0778028\n",
      "\tspeed: 0.0399s/iter; left time: 673.7982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 222 | Train Loss: 0.0803515 Vali Loss: 0.0828490 Test Loss: 0.1241593\n",
      "Validation loss decreased (0.083338 --> 0.082849).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785776\n",
      "\tspeed: 0.0641s/iter; left time: 1075.3038s\n",
      "\titers: 200, epoch: 25 | loss: 0.0831678\n",
      "\tspeed: 0.0354s/iter; left time: 590.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0804239 Vali Loss: 0.0830504 Test Loss: 0.1246540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0837921\n",
      "\tspeed: 0.0524s/iter; left time: 867.4951s\n",
      "\titers: 200, epoch: 26 | loss: 0.0871833\n",
      "\tspeed: 0.0305s/iter; left time: 501.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0800594 Vali Loss: 0.0845414 Test Loss: 0.1258090\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0790721\n",
      "\tspeed: 0.0631s/iter; left time: 1029.6349s\n",
      "\titers: 200, epoch: 27 | loss: 0.0821162\n",
      "\tspeed: 0.0349s/iter; left time: 565.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 222 | Train Loss: 0.0799198 Vali Loss: 0.0835470 Test Loss: 0.1264690\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0793398\n",
      "\tspeed: 0.0544s/iter; left time: 876.8279s\n",
      "\titers: 200, epoch: 28 | loss: 0.0788075\n",
      "\tspeed: 0.0263s/iter; left time: 420.8196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0797541 Vali Loss: 0.0830917 Test Loss: 0.1247235\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0780371\n",
      "\tspeed: 0.0528s/iter; left time: 839.1044s\n",
      "\titers: 200, epoch: 29 | loss: 0.0840782\n",
      "\tspeed: 0.0259s/iter; left time: 408.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0798338 Vali Loss: 0.0826083 Test Loss: 0.1235515\n",
      "Validation loss decreased (0.082849 --> 0.082608).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0769194\n",
      "\tspeed: 0.0538s/iter; left time: 843.0790s\n",
      "\titers: 200, epoch: 30 | loss: 0.0786123\n",
      "\tspeed: 0.0292s/iter; left time: 454.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0797325 Vali Loss: 0.0831518 Test Loss: 0.1256355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0817805\n",
      "\tspeed: 0.0592s/iter; left time: 913.5894s\n",
      "\titers: 200, epoch: 31 | loss: 0.0762106\n",
      "\tspeed: 0.0376s/iter; left time: 576.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 222 | Train Loss: 0.0797899 Vali Loss: 0.0835523 Test Loss: 0.1259773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0787341\n",
      "\tspeed: 0.0565s/iter; left time: 860.2805s\n",
      "\titers: 200, epoch: 32 | loss: 0.0794706\n",
      "\tspeed: 0.0339s/iter; left time: 512.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 222 | Train Loss: 0.0795503 Vali Loss: 0.0825128 Test Loss: 0.1236622\n",
      "Validation loss decreased (0.082608 --> 0.082513).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0835309\n",
      "\tspeed: 0.0656s/iter; left time: 984.3353s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795717\n",
      "\tspeed: 0.0259s/iter; left time: 386.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.0794180 Vali Loss: 0.0828143 Test Loss: 0.1254973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0837062\n",
      "\tspeed: 0.0610s/iter; left time: 901.5715s\n",
      "\titers: 200, epoch: 34 | loss: 0.0783705\n",
      "\tspeed: 0.0302s/iter; left time: 443.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 222 | Train Loss: 0.0794414 Vali Loss: 0.0829059 Test Loss: 0.1250226\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0794153\n",
      "\tspeed: 0.0521s/iter; left time: 757.6619s\n",
      "\titers: 200, epoch: 35 | loss: 0.0792470\n",
      "\tspeed: 0.0262s/iter; left time: 379.2331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0793219 Vali Loss: 0.0830143 Test Loss: 0.1257929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0856731\n",
      "\tspeed: 0.0618s/iter; left time: 886.3484s\n",
      "\titers: 200, epoch: 36 | loss: 0.0753285\n",
      "\tspeed: 0.0341s/iter; left time: 485.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 222 | Train Loss: 0.0794596 Vali Loss: 0.0828143 Test Loss: 0.1248862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0776481\n",
      "\tspeed: 0.0605s/iter; left time: 853.7715s\n",
      "\titers: 200, epoch: 37 | loss: 0.0796337\n",
      "\tspeed: 0.0349s/iter; left time: 488.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 222 | Train Loss: 0.0792571 Vali Loss: 0.0827366 Test Loss: 0.1250576\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0767227\n",
      "\tspeed: 0.0598s/iter; left time: 830.5538s\n",
      "\titers: 200, epoch: 38 | loss: 0.0755412\n",
      "\tspeed: 0.0378s/iter; left time: 521.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 222 | Train Loss: 0.0792529 Vali Loss: 0.0824611 Test Loss: 0.1246656\n",
      "Validation loss decreased (0.082513 --> 0.082461).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0774095\n",
      "\tspeed: 0.0715s/iter; left time: 976.5857s\n",
      "\titers: 200, epoch: 39 | loss: 0.0806491\n",
      "\tspeed: 0.0344s/iter; left time: 466.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 222 | Train Loss: 0.0792086 Vali Loss: 0.0825560 Test Loss: 0.1247143\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0786739\n",
      "\tspeed: 0.0640s/iter; left time: 860.4439s\n",
      "\titers: 200, epoch: 40 | loss: 0.0810359\n",
      "\tspeed: 0.0410s/iter; left time: 547.5429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 222 | Train Loss: 0.0790025 Vali Loss: 0.0824978 Test Loss: 0.1245880\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0829056\n",
      "\tspeed: 0.0635s/iter; left time: 839.4041s\n",
      "\titers: 200, epoch: 41 | loss: 0.0805995\n",
      "\tspeed: 0.0375s/iter; left time: 491.6616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 222 | Train Loss: 0.0791235 Vali Loss: 0.0826835 Test Loss: 0.1252108\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0811421\n",
      "\tspeed: 0.0689s/iter; left time: 896.1420s\n",
      "\titers: 200, epoch: 42 | loss: 0.0764460\n",
      "\tspeed: 0.0379s/iter; left time: 488.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 222 | Train Loss: 0.0791304 Vali Loss: 0.0824444 Test Loss: 0.1238777\n",
      "Validation loss decreased (0.082461 --> 0.082444).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0793065\n",
      "\tspeed: 0.0705s/iter; left time: 900.8610s\n",
      "\titers: 200, epoch: 43 | loss: 0.0813277\n",
      "\tspeed: 0.0426s/iter; left time: 540.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.0793404 Vali Loss: 0.0826978 Test Loss: 0.1246895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0754223\n",
      "\tspeed: 0.0688s/iter; left time: 863.5471s\n",
      "\titers: 200, epoch: 44 | loss: 0.1029262\n",
      "\tspeed: 0.0384s/iter; left time: 478.4725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 222 | Train Loss: 0.0792035 Vali Loss: 0.0829559 Test Loss: 0.1256068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0791424\n",
      "\tspeed: 0.0674s/iter; left time: 831.0428s\n",
      "\titers: 200, epoch: 45 | loss: 0.0801032\n",
      "\tspeed: 0.0390s/iter; left time: 477.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 222 | Train Loss: 0.0790393 Vali Loss: 0.0826597 Test Loss: 0.1250457\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0786388\n",
      "\tspeed: 0.0644s/iter; left time: 779.6948s\n",
      "\titers: 200, epoch: 46 | loss: 0.0760357\n",
      "\tspeed: 0.0394s/iter; left time: 473.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 222 | Train Loss: 0.0789564 Vali Loss: 0.0828346 Test Loss: 0.1254029\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0828830\n",
      "\tspeed: 0.0656s/iter; left time: 780.0225s\n",
      "\titers: 200, epoch: 47 | loss: 0.0779614\n",
      "\tspeed: 0.0354s/iter; left time: 417.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 222 | Train Loss: 0.0791000 Vali Loss: 0.0825642 Test Loss: 0.1251130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0768354\n",
      "\tspeed: 0.0550s/iter; left time: 641.7545s\n",
      "\titers: 200, epoch: 48 | loss: 0.0804250\n",
      "\tspeed: 0.0289s/iter; left time: 334.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0789242 Vali Loss: 0.0827186 Test Loss: 0.1255382\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0772356\n",
      "\tspeed: 0.0555s/iter; left time: 635.2874s\n",
      "\titers: 200, epoch: 49 | loss: 0.0783990\n",
      "\tspeed: 0.0287s/iter; left time: 325.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0790139 Vali Loss: 0.0828094 Test Loss: 0.1254260\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0768522\n",
      "\tspeed: 0.0520s/iter; left time: 583.1847s\n",
      "\titers: 200, epoch: 50 | loss: 0.0756860\n",
      "\tspeed: 0.0333s/iter; left time: 370.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 222 | Train Loss: 0.0790950 Vali Loss: 0.0825744 Test Loss: 0.1247045\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0800510\n",
      "\tspeed: 0.0668s/iter; left time: 734.5248s\n",
      "\titers: 200, epoch: 51 | loss: 0.0829478\n",
      "\tspeed: 0.0387s/iter; left time: 422.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 222 | Train Loss: 0.0789340 Vali Loss: 0.0826142 Test Loss: 0.1244303\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0766461\n",
      "\tspeed: 0.0551s/iter; left time: 593.5502s\n",
      "\titers: 200, epoch: 52 | loss: 0.0807740\n",
      "\tspeed: 0.0281s/iter; left time: 300.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0790252 Vali Loss: 0.0826740 Test Loss: 0.1251621\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038151029497385025, rmse:0.1953228861093521, mae:0.12387765198945999, rse:0.5737998485565186\n",
      "Intermediate time for ES and pred_len 96: 00h:18m:53.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3149875\n",
      "\tspeed: 0.0541s/iter; left time: 1195.2305s\n",
      "\titers: 200, epoch: 1 | loss: 0.2934698\n",
      "\tspeed: 0.0262s/iter; left time: 577.3115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.3207283 Vali Loss: 0.2330227 Test Loss: 0.2502821\n",
      "Validation loss decreased (inf --> 0.233023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1485554\n",
      "\tspeed: 0.0558s/iter; left time: 1219.9124s\n",
      "\titers: 200, epoch: 2 | loss: 0.1259702\n",
      "\tspeed: 0.0263s/iter; left time: 572.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.1613443 Vali Loss: 0.1147424 Test Loss: 0.1563727\n",
      "Validation loss decreased (0.233023 --> 0.114742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1119445\n",
      "\tspeed: 0.0663s/iter; left time: 1435.9791s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091200\n",
      "\tspeed: 0.0279s/iter; left time: 602.2527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 222 | Train Loss: 0.1148151 Vali Loss: 0.1073551 Test Loss: 0.1597529\n",
      "Validation loss decreased (0.114742 --> 0.107355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1039577\n",
      "\tspeed: 0.0617s/iter; left time: 1321.8983s\n",
      "\titers: 200, epoch: 4 | loss: 0.1022624\n",
      "\tspeed: 0.0267s/iter; left time: 570.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 222 | Train Loss: 0.1036175 Vali Loss: 0.1026362 Test Loss: 0.1545071\n",
      "Validation loss decreased (0.107355 --> 0.102636).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994654\n",
      "\tspeed: 0.0561s/iter; left time: 1189.2768s\n",
      "\titers: 200, epoch: 5 | loss: 0.0964081\n",
      "\tspeed: 0.0273s/iter; left time: 577.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 222 | Train Loss: 0.0992591 Vali Loss: 0.0997009 Test Loss: 0.1484649\n",
      "Validation loss decreased (0.102636 --> 0.099701).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0969398\n",
      "\tspeed: 0.0542s/iter; left time: 1136.7674s\n",
      "\titers: 200, epoch: 6 | loss: 0.0945241\n",
      "\tspeed: 0.0271s/iter; left time: 567.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0963511 Vali Loss: 0.0990823 Test Loss: 0.1457873\n",
      "Validation loss decreased (0.099701 --> 0.099082).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0924518\n",
      "\tspeed: 0.0537s/iter; left time: 1116.2606s\n",
      "\titers: 200, epoch: 7 | loss: 0.0966128\n",
      "\tspeed: 0.0265s/iter; left time: 547.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0938290 Vali Loss: 0.0968640 Test Loss: 0.1434163\n",
      "Validation loss decreased (0.099082 --> 0.096864).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0913162\n",
      "\tspeed: 0.0586s/iter; left time: 1204.8667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0925816\n",
      "\tspeed: 0.0295s/iter; left time: 603.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 222 | Train Loss: 0.0925198 Vali Loss: 0.0951076 Test Loss: 0.1413796\n",
      "Validation loss decreased (0.096864 --> 0.095108).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919790\n",
      "\tspeed: 0.0641s/iter; left time: 1303.8137s\n",
      "\titers: 200, epoch: 9 | loss: 0.0891102\n",
      "\tspeed: 0.0290s/iter; left time: 586.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 222 | Train Loss: 0.0915998 Vali Loss: 0.0964071 Test Loss: 0.1406248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0898396\n",
      "\tspeed: 0.0637s/iter; left time: 1281.5656s\n",
      "\titers: 200, epoch: 10 | loss: 0.0897508\n",
      "\tspeed: 0.0269s/iter; left time: 537.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 222 | Train Loss: 0.0900308 Vali Loss: 0.0958512 Test Loss: 0.1423330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0868174\n",
      "\tspeed: 0.0632s/iter; left time: 1255.5369s\n",
      "\titers: 200, epoch: 11 | loss: 0.0902316\n",
      "\tspeed: 0.0378s/iter; left time: 747.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 222 | Train Loss: 0.0894251 Vali Loss: 0.0952252 Test Loss: 0.1417195\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0892916\n",
      "\tspeed: 0.0579s/iter; left time: 1139.2370s\n",
      "\titers: 200, epoch: 12 | loss: 0.0921318\n",
      "\tspeed: 0.0274s/iter; left time: 535.8240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0889050 Vali Loss: 0.0963712 Test Loss: 0.1411144\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0874595\n",
      "\tspeed: 0.0598s/iter; left time: 1163.0758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0906750\n",
      "\tspeed: 0.0316s/iter; left time: 610.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 222 | Train Loss: 0.0890217 Vali Loss: 0.0931928 Test Loss: 0.1404610\n",
      "Validation loss decreased (0.095108 --> 0.093193).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0891063\n",
      "\tspeed: 0.0596s/iter; left time: 1145.2780s\n",
      "\titers: 200, epoch: 14 | loss: 0.0901814\n",
      "\tspeed: 0.0289s/iter; left time: 551.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0878871 Vali Loss: 0.0926603 Test Loss: 0.1391353\n",
      "Validation loss decreased (0.093193 --> 0.092660).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0899263\n",
      "\tspeed: 0.0543s/iter; left time: 1031.4221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0864345\n",
      "\tspeed: 0.0259s/iter; left time: 489.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 222 | Train Loss: 0.0871981 Vali Loss: 0.0919294 Test Loss: 0.1377450\n",
      "Validation loss decreased (0.092660 --> 0.091929).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0889200\n",
      "\tspeed: 0.0537s/iter; left time: 1008.2816s\n",
      "\titers: 200, epoch: 16 | loss: 0.0900103\n",
      "\tspeed: 0.0270s/iter; left time: 503.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0869719 Vali Loss: 0.0914697 Test Loss: 0.1365180\n",
      "Validation loss decreased (0.091929 --> 0.091470).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0857338\n",
      "\tspeed: 0.0556s/iter; left time: 1031.9147s\n",
      "\titers: 200, epoch: 17 | loss: 0.0865352\n",
      "\tspeed: 0.0263s/iter; left time: 485.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 222 | Train Loss: 0.0861970 Vali Loss: 0.0912797 Test Loss: 0.1371784\n",
      "Validation loss decreased (0.091470 --> 0.091280).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0865391\n",
      "\tspeed: 0.0524s/iter; left time: 961.1146s\n",
      "\titers: 200, epoch: 18 | loss: 0.0844980\n",
      "\tspeed: 0.0292s/iter; left time: 531.9554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0859053 Vali Loss: 0.0928910 Test Loss: 0.1391152\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0848804\n",
      "\tspeed: 0.0520s/iter; left time: 941.8023s\n",
      "\titers: 200, epoch: 19 | loss: 0.0859172\n",
      "\tspeed: 0.0259s/iter; left time: 466.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.0856187 Vali Loss: 0.0906086 Test Loss: 0.1379921\n",
      "Validation loss decreased (0.091280 --> 0.090609).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0879309\n",
      "\tspeed: 0.0539s/iter; left time: 963.6125s\n",
      "\titers: 200, epoch: 20 | loss: 0.0888831\n",
      "\tspeed: 0.0261s/iter; left time: 464.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0856539 Vali Loss: 0.0924114 Test Loss: 0.1383345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0882337\n",
      "\tspeed: 0.0560s/iter; left time: 988.8484s\n",
      "\titers: 200, epoch: 21 | loss: 0.0856722\n",
      "\tspeed: 0.0298s/iter; left time: 523.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 222 | Train Loss: 0.0852096 Vali Loss: 0.0906821 Test Loss: 0.1379102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0823965\n",
      "\tspeed: 0.0540s/iter; left time: 940.9094s\n",
      "\titers: 200, epoch: 22 | loss: 0.0808241\n",
      "\tspeed: 0.0278s/iter; left time: 481.7309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0853662 Vali Loss: 0.0914925 Test Loss: 0.1389603\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0887572\n",
      "\tspeed: 0.0535s/iter; left time: 920.6220s\n",
      "\titers: 200, epoch: 23 | loss: 0.0859834\n",
      "\tspeed: 0.0260s/iter; left time: 444.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.0849094 Vali Loss: 0.0913021 Test Loss: 0.1393445\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0858398\n",
      "\tspeed: 0.0546s/iter; left time: 927.4700s\n",
      "\titers: 200, epoch: 24 | loss: 0.0860321\n",
      "\tspeed: 0.0294s/iter; left time: 497.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0846493 Vali Loss: 0.0910656 Test Loss: 0.1396734\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0814625\n",
      "\tspeed: 0.0590s/iter; left time: 989.0875s\n",
      "\titers: 200, epoch: 25 | loss: 0.0842008\n",
      "\tspeed: 0.0277s/iter; left time: 462.4020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0845985 Vali Loss: 0.0911614 Test Loss: 0.1398549\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0854630\n",
      "\tspeed: 0.0544s/iter; left time: 900.3628s\n",
      "\titers: 200, epoch: 26 | loss: 0.0845272\n",
      "\tspeed: 0.0330s/iter; left time: 542.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 222 | Train Loss: 0.0843580 Vali Loss: 0.0896477 Test Loss: 0.1388284\n",
      "Validation loss decreased (0.090609 --> 0.089648).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0844114\n",
      "\tspeed: 0.0545s/iter; left time: 890.6296s\n",
      "\titers: 200, epoch: 27 | loss: 0.0870713\n",
      "\tspeed: 0.0260s/iter; left time: 421.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 222 | Train Loss: 0.0841733 Vali Loss: 0.0895319 Test Loss: 0.1372795\n",
      "Validation loss decreased (0.089648 --> 0.089532).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0859846\n",
      "\tspeed: 0.0530s/iter; left time: 853.9477s\n",
      "\titers: 200, epoch: 28 | loss: 0.0851450\n",
      "\tspeed: 0.0261s/iter; left time: 417.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 222 | Train Loss: 0.0842229 Vali Loss: 0.0903495 Test Loss: 0.1385197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0851272\n",
      "\tspeed: 0.0516s/iter; left time: 819.2990s\n",
      "\titers: 200, epoch: 29 | loss: 0.0825511\n",
      "\tspeed: 0.0281s/iter; left time: 442.8117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0841715 Vali Loss: 0.0900538 Test Loss: 0.1380837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0827544\n",
      "\tspeed: 0.0772s/iter; left time: 1209.8478s\n",
      "\titers: 200, epoch: 30 | loss: 0.0808625\n",
      "\tspeed: 0.0273s/iter; left time: 425.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 222 | Train Loss: 0.0841362 Vali Loss: 0.0899130 Test Loss: 0.1384506\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0846131\n",
      "\tspeed: 0.0531s/iter; left time: 820.3629s\n",
      "\titers: 200, epoch: 31 | loss: 0.0828555\n",
      "\tspeed: 0.0259s/iter; left time: 398.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 222 | Train Loss: 0.0840806 Vali Loss: 0.0897111 Test Loss: 0.1380569\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0868603\n",
      "\tspeed: 0.0526s/iter; left time: 800.0198s\n",
      "\titers: 200, epoch: 32 | loss: 0.0857596\n",
      "\tspeed: 0.0259s/iter; left time: 391.6482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 222 | Train Loss: 0.0837738 Vali Loss: 0.0892564 Test Loss: 0.1381384\n",
      "Validation loss decreased (0.089532 --> 0.089256).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0799966\n",
      "\tspeed: 0.0553s/iter; left time: 829.1211s\n",
      "\titers: 200, epoch: 33 | loss: 0.0841802\n",
      "\tspeed: 0.0259s/iter; left time: 385.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 222 | Train Loss: 0.0837494 Vali Loss: 0.0896674 Test Loss: 0.1382743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0833812\n",
      "\tspeed: 0.0520s/iter; left time: 767.5919s\n",
      "\titers: 200, epoch: 34 | loss: 0.0868029\n",
      "\tspeed: 0.0268s/iter; left time: 392.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 222 | Train Loss: 0.0839848 Vali Loss: 0.0898647 Test Loss: 0.1387579\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0808280\n",
      "\tspeed: 0.0516s/iter; left time: 751.2153s\n",
      "\titers: 200, epoch: 35 | loss: 0.0847114\n",
      "\tspeed: 0.0259s/iter; left time: 374.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0834621 Vali Loss: 0.0894771 Test Loss: 0.1385000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0817441\n",
      "\tspeed: 0.0515s/iter; left time: 738.6223s\n",
      "\titers: 200, epoch: 36 | loss: 0.0874269\n",
      "\tspeed: 0.0261s/iter; left time: 371.2954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0837592 Vali Loss: 0.0907142 Test Loss: 0.1390617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815843\n",
      "\tspeed: 0.0515s/iter; left time: 726.0645s\n",
      "\titers: 200, epoch: 37 | loss: 0.0823556\n",
      "\tspeed: 0.0266s/iter; left time: 372.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 222 | Train Loss: 0.0835522 Vali Loss: 0.0896209 Test Loss: 0.1385122\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0828336\n",
      "\tspeed: 0.0513s/iter; left time: 712.5798s\n",
      "\titers: 200, epoch: 38 | loss: 0.0870446\n",
      "\tspeed: 0.0266s/iter; left time: 366.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 222 | Train Loss: 0.0836036 Vali Loss: 0.0894116 Test Loss: 0.1382480\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0822937\n",
      "\tspeed: 0.0518s/iter; left time: 707.7421s\n",
      "\titers: 200, epoch: 39 | loss: 0.0822853\n",
      "\tspeed: 0.0258s/iter; left time: 350.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 222 | Train Loss: 0.0833390 Vali Loss: 0.0896169 Test Loss: 0.1388514\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0826771\n",
      "\tspeed: 0.0514s/iter; left time: 691.3235s\n",
      "\titers: 200, epoch: 40 | loss: 0.0825236\n",
      "\tspeed: 0.0264s/iter; left time: 351.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.0834483 Vali Loss: 0.0904663 Test Loss: 0.1404166\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0837196\n",
      "\tspeed: 0.0518s/iter; left time: 684.8762s\n",
      "\titers: 200, epoch: 41 | loss: 0.0828424\n",
      "\tspeed: 0.0260s/iter; left time: 340.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 222 | Train Loss: 0.0833131 Vali Loss: 0.0896370 Test Loss: 0.1391788\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0831819\n",
      "\tspeed: 0.0542s/iter; left time: 704.1044s\n",
      "\titers: 200, epoch: 42 | loss: 0.0848298\n",
      "\tspeed: 0.0439s/iter; left time: 565.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 222 | Train Loss: 0.0833206 Vali Loss: 0.0896517 Test Loss: 0.1393112\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.050083622336387634, rmse:0.22379370033740997, mae:0.13813841342926025, rse:0.6574857831001282\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3181153\n",
      "\tspeed: 0.0884s/iter; left time: 1953.6610s\n",
      "\titers: 200, epoch: 1 | loss: 0.2908432\n",
      "\tspeed: 0.0844s/iter; left time: 1856.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.13s\n",
      "Steps: 222 | Train Loss: 0.3237807 Vali Loss: 0.2346110 Test Loss: 0.2487616\n",
      "Validation loss decreased (inf --> 0.234611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1481942\n",
      "\tspeed: 0.2640s/iter; left time: 5776.6877s\n",
      "\titers: 200, epoch: 2 | loss: 0.1269623\n",
      "\tspeed: 0.0847s/iter; left time: 1845.2966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.47s\n",
      "Steps: 222 | Train Loss: 0.1646678 Vali Loss: 0.1136355 Test Loss: 0.1512818\n",
      "Validation loss decreased (0.234611 --> 0.113636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1180176\n",
      "\tspeed: 0.2546s/iter; left time: 5513.4942s\n",
      "\titers: 200, epoch: 3 | loss: 0.1115586\n",
      "\tspeed: 0.0829s/iter; left time: 1787.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:19.05s\n",
      "Steps: 222 | Train Loss: 0.1166311 Vali Loss: 0.1076858 Test Loss: 0.1500086\n",
      "Validation loss decreased (0.113636 --> 0.107686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1057549\n",
      "\tspeed: 0.2551s/iter; left time: 5467.9396s\n",
      "\titers: 200, epoch: 4 | loss: 0.0998994\n",
      "\tspeed: 0.0835s/iter; left time: 1781.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:19.11s\n",
      "Steps: 222 | Train Loss: 0.1047921 Vali Loss: 0.1137724 Test Loss: 0.1661510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0998108\n",
      "\tspeed: 0.2477s/iter; left time: 5254.2742s\n",
      "\titers: 200, epoch: 5 | loss: 0.1004925\n",
      "\tspeed: 0.0886s/iter; left time: 1869.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.84s\n",
      "Steps: 222 | Train Loss: 0.0986910 Vali Loss: 0.0993711 Test Loss: 0.1536352\n",
      "Validation loss decreased (0.107686 --> 0.099371).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0952950\n",
      "\tspeed: 0.2581s/iter; left time: 5418.2777s\n",
      "\titers: 200, epoch: 6 | loss: 0.1265844\n",
      "\tspeed: 0.0876s/iter; left time: 1830.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.86s\n",
      "Steps: 222 | Train Loss: 0.0960982 Vali Loss: 0.1072776 Test Loss: 0.1552569\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0935072\n",
      "\tspeed: 0.2571s/iter; left time: 5338.8053s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915683\n",
      "\tspeed: 0.0890s/iter; left time: 1838.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:20.21s\n",
      "Steps: 222 | Train Loss: 0.0935473 Vali Loss: 0.0944410 Test Loss: 0.1431582\n",
      "Validation loss decreased (0.099371 --> 0.094441).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0919732\n",
      "\tspeed: 0.2663s/iter; left time: 5471.3724s\n",
      "\titers: 200, epoch: 8 | loss: 0.0881575\n",
      "\tspeed: 0.0894s/iter; left time: 1828.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:19.94s\n",
      "Steps: 222 | Train Loss: 0.0912227 Vali Loss: 0.0933138 Test Loss: 0.1434893\n",
      "Validation loss decreased (0.094441 --> 0.093314).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0937219\n",
      "\tspeed: 0.2549s/iter; left time: 5181.5740s\n",
      "\titers: 200, epoch: 9 | loss: 0.0888551\n",
      "\tspeed: 0.0877s/iter; left time: 1772.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:19.67s\n",
      "Steps: 222 | Train Loss: 0.0900392 Vali Loss: 0.0933109 Test Loss: 0.1408889\n",
      "Validation loss decreased (0.093314 --> 0.093311).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0925525\n",
      "\tspeed: 0.2469s/iter; left time: 4963.9681s\n",
      "\titers: 200, epoch: 10 | loss: 0.0941726\n",
      "\tspeed: 0.0868s/iter; left time: 1735.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:19.45s\n",
      "Steps: 222 | Train Loss: 0.0900909 Vali Loss: 0.0948680 Test Loss: 0.1393135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0900671\n",
      "\tspeed: 0.2442s/iter; left time: 4854.9998s\n",
      "\titers: 200, epoch: 11 | loss: 0.0894361\n",
      "\tspeed: 0.0845s/iter; left time: 1671.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:19.34s\n",
      "Steps: 222 | Train Loss: 0.0894925 Vali Loss: 0.0920531 Test Loss: 0.1395034\n",
      "Validation loss decreased (0.093311 --> 0.092053).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0848322\n",
      "\tspeed: 0.2405s/iter; left time: 4728.5528s\n",
      "\titers: 200, epoch: 12 | loss: 0.0895905\n",
      "\tspeed: 0.0881s/iter; left time: 1723.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:19.71s\n",
      "Steps: 222 | Train Loss: 0.0883529 Vali Loss: 0.0910270 Test Loss: 0.1380486\n",
      "Validation loss decreased (0.092053 --> 0.091027).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0854379\n",
      "\tspeed: 0.2590s/iter; left time: 5034.2168s\n",
      "\titers: 200, epoch: 13 | loss: 0.0844422\n",
      "\tspeed: 0.0866s/iter; left time: 1673.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:19.96s\n",
      "Steps: 222 | Train Loss: 0.0876274 Vali Loss: 0.0905179 Test Loss: 0.1362549\n",
      "Validation loss decreased (0.091027 --> 0.090518).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0851443\n",
      "\tspeed: 0.2482s/iter; left time: 4769.9343s\n",
      "\titers: 200, epoch: 14 | loss: 0.0841287\n",
      "\tspeed: 0.0861s/iter; left time: 1645.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:19.37s\n",
      "Steps: 222 | Train Loss: 0.0870819 Vali Loss: 0.0894211 Test Loss: 0.1348815\n",
      "Validation loss decreased (0.090518 --> 0.089421).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0851897\n",
      "\tspeed: 0.2338s/iter; left time: 4440.6078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877644\n",
      "\tspeed: 0.0832s/iter; left time: 1571.5570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:19.15s\n",
      "Steps: 222 | Train Loss: 0.0865850 Vali Loss: 0.0897265 Test Loss: 0.1368692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0876066\n",
      "\tspeed: 0.2482s/iter; left time: 4659.3067s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844284\n",
      "\tspeed: 0.0859s/iter; left time: 1604.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.77s\n",
      "Steps: 222 | Train Loss: 0.0865626 Vali Loss: 0.0904795 Test Loss: 0.1380317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0836445\n",
      "\tspeed: 0.2459s/iter; left time: 4562.0576s\n",
      "\titers: 200, epoch: 17 | loss: 0.0885673\n",
      "\tspeed: 0.0853s/iter; left time: 1573.5824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:19.25s\n",
      "Steps: 222 | Train Loss: 0.0858048 Vali Loss: 0.0888841 Test Loss: 0.1367745\n",
      "Validation loss decreased (0.089421 --> 0.088884).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0855581\n",
      "\tspeed: 0.2481s/iter; left time: 4547.6938s\n",
      "\titers: 200, epoch: 18 | loss: 0.0847229\n",
      "\tspeed: 0.0882s/iter; left time: 1608.4343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:19.80s\n",
      "Steps: 222 | Train Loss: 0.0856663 Vali Loss: 0.0892088 Test Loss: 0.1363592\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0848636\n",
      "\tspeed: 0.2455s/iter; left time: 4444.4398s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834534\n",
      "\tspeed: 0.0891s/iter; left time: 1603.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:19.63s\n",
      "Steps: 222 | Train Loss: 0.0854393 Vali Loss: 0.0904177 Test Loss: 0.1396060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0876939\n",
      "\tspeed: 0.2627s/iter; left time: 4697.4624s\n",
      "\titers: 200, epoch: 20 | loss: 0.0844571\n",
      "\tspeed: 0.0754s/iter; left time: 1340.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0854203 Vali Loss: 0.0889176 Test Loss: 0.1358021\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0866354\n",
      "\tspeed: 0.2244s/iter; left time: 3962.4693s\n",
      "\titers: 200, epoch: 21 | loss: 0.0842018\n",
      "\tspeed: 0.0761s/iter; left time: 1336.5962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0850818 Vali Loss: 0.0880363 Test Loss: 0.1339612\n",
      "Validation loss decreased (0.088884 --> 0.088036).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856950\n",
      "\tspeed: 0.2251s/iter; left time: 3924.7927s\n",
      "\titers: 200, epoch: 22 | loss: 0.0820366\n",
      "\tspeed: 0.0757s/iter; left time: 1312.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:17.43s\n",
      "Steps: 222 | Train Loss: 0.0847716 Vali Loss: 0.0880819 Test Loss: 0.1344969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0833623\n",
      "\tspeed: 0.2155s/iter; left time: 3709.9489s\n",
      "\titers: 200, epoch: 23 | loss: 0.0885934\n",
      "\tspeed: 0.0829s/iter; left time: 1419.4544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0846385 Vali Loss: 0.0882519 Test Loss: 0.1347591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0847479\n",
      "\tspeed: 0.2285s/iter; left time: 3883.7220s\n",
      "\titers: 200, epoch: 24 | loss: 0.0809866\n",
      "\tspeed: 0.0737s/iter; left time: 1244.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:17.47s\n",
      "Steps: 222 | Train Loss: 0.0843916 Vali Loss: 0.0883709 Test Loss: 0.1347584\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0873677\n",
      "\tspeed: 0.2270s/iter; left time: 3808.0003s\n",
      "\titers: 200, epoch: 25 | loss: 0.0833890\n",
      "\tspeed: 0.0753s/iter; left time: 1255.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:17.30s\n",
      "Steps: 222 | Train Loss: 0.0843128 Vali Loss: 0.0879038 Test Loss: 0.1331528\n",
      "Validation loss decreased (0.088036 --> 0.087904).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0856610\n",
      "\tspeed: 0.2270s/iter; left time: 3756.4257s\n",
      "\titers: 200, epoch: 26 | loss: 0.0878330\n",
      "\tspeed: 0.0769s/iter; left time: 1264.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:17.71s\n",
      "Steps: 222 | Train Loss: 0.0840296 Vali Loss: 0.0882877 Test Loss: 0.1355279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0853046\n",
      "\tspeed: 0.2221s/iter; left time: 3627.2273s\n",
      "\titers: 200, epoch: 27 | loss: 0.0846256\n",
      "\tspeed: 0.0767s/iter; left time: 1244.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.65s\n",
      "Steps: 222 | Train Loss: 0.0839308 Vali Loss: 0.0873830 Test Loss: 0.1323245\n",
      "Validation loss decreased (0.087904 --> 0.087383).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0860023\n",
      "\tspeed: 0.2323s/iter; left time: 3740.9560s\n",
      "\titers: 200, epoch: 28 | loss: 0.0852530\n",
      "\tspeed: 0.0772s/iter; left time: 1235.7784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:17.90s\n",
      "Steps: 222 | Train Loss: 0.0841338 Vali Loss: 0.0882819 Test Loss: 0.1358431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0864434\n",
      "\tspeed: 0.2282s/iter; left time: 3625.5778s\n",
      "\titers: 200, epoch: 29 | loss: 0.0795368\n",
      "\tspeed: 0.0775s/iter; left time: 1222.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:17.75s\n",
      "Steps: 222 | Train Loss: 0.0839885 Vali Loss: 0.0885131 Test Loss: 0.1356549\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0859490\n",
      "\tspeed: 0.2367s/iter; left time: 3706.8195s\n",
      "\titers: 200, epoch: 30 | loss: 0.0843210\n",
      "\tspeed: 0.0800s/iter; left time: 1245.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.37s\n",
      "Steps: 222 | Train Loss: 0.0838221 Vali Loss: 0.0876965 Test Loss: 0.1337219\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808490\n",
      "\tspeed: 0.2339s/iter; left time: 3612.1207s\n",
      "\titers: 200, epoch: 31 | loss: 0.0828531\n",
      "\tspeed: 0.0816s/iter; left time: 1251.7212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0840041 Vali Loss: 0.0875076 Test Loss: 0.1326170\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0841783\n",
      "\tspeed: 0.2373s/iter; left time: 3611.0215s\n",
      "\titers: 200, epoch: 32 | loss: 0.0865266\n",
      "\tspeed: 0.0824s/iter; left time: 1245.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.74s\n",
      "Steps: 222 | Train Loss: 0.0836112 Vali Loss: 0.0884350 Test Loss: 0.1353031\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0840218\n",
      "\tspeed: 0.2379s/iter; left time: 3567.4570s\n",
      "\titers: 200, epoch: 33 | loss: 0.0837441\n",
      "\tspeed: 0.0826s/iter; left time: 1230.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.96s\n",
      "Steps: 222 | Train Loss: 0.0836764 Vali Loss: 0.0872989 Test Loss: 0.1326383\n",
      "Validation loss decreased (0.087383 --> 0.087299).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0805858\n",
      "\tspeed: 0.2422s/iter; left time: 3578.0137s\n",
      "\titers: 200, epoch: 34 | loss: 0.0867160\n",
      "\tspeed: 0.0813s/iter; left time: 1193.3775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.44s\n",
      "Steps: 222 | Train Loss: 0.0834269 Vali Loss: 0.0884190 Test Loss: 0.1354959\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0819976\n",
      "\tspeed: 0.2360s/iter; left time: 3433.9575s\n",
      "\titers: 200, epoch: 35 | loss: 0.0849478\n",
      "\tspeed: 0.0840s/iter; left time: 1214.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.98s\n",
      "Steps: 222 | Train Loss: 0.0835585 Vali Loss: 0.0873145 Test Loss: 0.1324766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823738\n",
      "\tspeed: 0.2392s/iter; left time: 3428.6685s\n",
      "\titers: 200, epoch: 36 | loss: 0.0817804\n",
      "\tspeed: 0.0823s/iter; left time: 1171.6488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.80s\n",
      "Steps: 222 | Train Loss: 0.0834425 Vali Loss: 0.0878824 Test Loss: 0.1344615\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0832224\n",
      "\tspeed: 0.2332s/iter; left time: 3290.2691s\n",
      "\titers: 200, epoch: 37 | loss: 0.0863478\n",
      "\tspeed: 0.0814s/iter; left time: 1139.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 222 | Train Loss: 0.0833335 Vali Loss: 0.0874824 Test Loss: 0.1333707\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0850325\n",
      "\tspeed: 0.2331s/iter; left time: 3236.6474s\n",
      "\titers: 200, epoch: 38 | loss: 0.0844169\n",
      "\tspeed: 0.0831s/iter; left time: 1145.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:18.84s\n",
      "Steps: 222 | Train Loss: 0.0833410 Vali Loss: 0.0872331 Test Loss: 0.1329378\n",
      "Validation loss decreased (0.087299 --> 0.087233).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0824161\n",
      "\tspeed: 0.2338s/iter; left time: 3195.3672s\n",
      "\titers: 200, epoch: 39 | loss: 0.0810515\n",
      "\tspeed: 0.0859s/iter; left time: 1164.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:19.46s\n",
      "Steps: 222 | Train Loss: 0.0833001 Vali Loss: 0.0873334 Test Loss: 0.1326835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0860663\n",
      "\tspeed: 0.2371s/iter; left time: 3187.5297s\n",
      "\titers: 200, epoch: 40 | loss: 0.0839439\n",
      "\tspeed: 0.0840s/iter; left time: 1120.2767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:18.95s\n",
      "Steps: 222 | Train Loss: 0.0832782 Vali Loss: 0.0874267 Test Loss: 0.1337718\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0789073\n",
      "\tspeed: 0.2297s/iter; left time: 3036.5920s\n",
      "\titers: 200, epoch: 41 | loss: 0.0821170\n",
      "\tspeed: 0.0829s/iter; left time: 1087.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:19.04s\n",
      "Steps: 222 | Train Loss: 0.0831964 Vali Loss: 0.0878609 Test Loss: 0.1343196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0870401\n",
      "\tspeed: 0.2381s/iter; left time: 3095.4267s\n",
      "\titers: 200, epoch: 42 | loss: 0.0804817\n",
      "\tspeed: 0.0848s/iter; left time: 1093.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:19.15s\n",
      "Steps: 222 | Train Loss: 0.0831930 Vali Loss: 0.0871274 Test Loss: 0.1326035\n",
      "Validation loss decreased (0.087233 --> 0.087127).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0835666\n",
      "\tspeed: 0.2453s/iter; left time: 3134.5370s\n",
      "\titers: 200, epoch: 43 | loss: 0.0811648\n",
      "\tspeed: 0.0848s/iter; left time: 1075.0094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:19.38s\n",
      "Steps: 222 | Train Loss: 0.0830796 Vali Loss: 0.0874757 Test Loss: 0.1335251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0836164\n",
      "\tspeed: 0.2453s/iter; left time: 3080.1521s\n",
      "\titers: 200, epoch: 44 | loss: 0.0835920\n",
      "\tspeed: 0.0851s/iter; left time: 1059.6112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:19.31s\n",
      "Steps: 222 | Train Loss: 0.0831270 Vali Loss: 0.0875249 Test Loss: 0.1334444\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0826038\n",
      "\tspeed: 0.2430s/iter; left time: 2997.1367s\n",
      "\titers: 200, epoch: 45 | loss: 0.0841515\n",
      "\tspeed: 0.0831s/iter; left time: 1017.1008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.95s\n",
      "Steps: 222 | Train Loss: 0.0831909 Vali Loss: 0.0873264 Test Loss: 0.1331538\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0838422\n",
      "\tspeed: 0.2436s/iter; left time: 2950.1739s\n",
      "\titers: 200, epoch: 46 | loss: 0.0795021\n",
      "\tspeed: 0.0842s/iter; left time: 1011.3609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:19.22s\n",
      "Steps: 222 | Train Loss: 0.0830527 Vali Loss: 0.0871764 Test Loss: 0.1324024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0794638\n",
      "\tspeed: 0.2535s/iter; left time: 3013.4437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0827410\n",
      "\tspeed: 0.0852s/iter; left time: 1004.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:19.62s\n",
      "Steps: 222 | Train Loss: 0.0831401 Vali Loss: 0.0877040 Test Loss: 0.1342804\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0839580\n",
      "\tspeed: 0.2480s/iter; left time: 2893.0947s\n",
      "\titers: 200, epoch: 48 | loss: 0.0822726\n",
      "\tspeed: 0.0846s/iter; left time: 978.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:19.21s\n",
      "Steps: 222 | Train Loss: 0.0830658 Vali Loss: 0.0872083 Test Loss: 0.1327254\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0827884\n",
      "\tspeed: 0.2473s/iter; left time: 2829.8871s\n",
      "\titers: 200, epoch: 49 | loss: 0.0857314\n",
      "\tspeed: 0.0844s/iter; left time: 957.1381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:19.17s\n",
      "Steps: 222 | Train Loss: 0.0829857 Vali Loss: 0.0874284 Test Loss: 0.1333181\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0815416\n",
      "\tspeed: 0.2449s/iter; left time: 2748.4282s\n",
      "\titers: 200, epoch: 50 | loss: 0.0826032\n",
      "\tspeed: 0.0860s/iter; left time: 957.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:19.30s\n",
      "Steps: 222 | Train Loss: 0.0830679 Vali Loss: 0.0870814 Test Loss: 0.1322614\n",
      "Validation loss decreased (0.087127 --> 0.087081).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0808961\n",
      "\tspeed: 0.2454s/iter; left time: 2699.2679s\n",
      "\titers: 200, epoch: 51 | loss: 0.0833313\n",
      "\tspeed: 0.0859s/iter; left time: 936.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:19.51s\n",
      "Steps: 222 | Train Loss: 0.0829899 Vali Loss: 0.0873382 Test Loss: 0.1328771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0846273\n",
      "\tspeed: 0.2481s/iter; left time: 2673.9743s\n",
      "\titers: 200, epoch: 52 | loss: 0.0840759\n",
      "\tspeed: 0.0853s/iter; left time: 911.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:19.40s\n",
      "Steps: 222 | Train Loss: 0.0831449 Vali Loss: 0.0870875 Test Loss: 0.1323837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0851423\n",
      "\tspeed: 0.2437s/iter; left time: 2572.8641s\n",
      "\titers: 200, epoch: 53 | loss: 0.0815358\n",
      "\tspeed: 0.0852s/iter; left time: 891.3855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:19.26s\n",
      "Steps: 222 | Train Loss: 0.0828970 Vali Loss: 0.0871621 Test Loss: 0.1327168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0817293\n",
      "\tspeed: 0.2489s/iter; left time: 2572.8303s\n",
      "\titers: 200, epoch: 54 | loss: 0.0823241\n",
      "\tspeed: 0.0834s/iter; left time: 853.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 222 | Train Loss: 0.0828710 Vali Loss: 0.0871841 Test Loss: 0.1326640\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0801776\n",
      "\tspeed: 0.2490s/iter; left time: 2518.5895s\n",
      "\titers: 200, epoch: 55 | loss: 0.0785742\n",
      "\tspeed: 0.0844s/iter; left time: 845.5347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:19.15s\n",
      "Steps: 222 | Train Loss: 0.0830113 Vali Loss: 0.0871063 Test Loss: 0.1328487\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0830133\n",
      "\tspeed: 0.2441s/iter; left time: 2414.1455s\n",
      "\titers: 200, epoch: 56 | loss: 0.0821016\n",
      "\tspeed: 0.0845s/iter; left time: 827.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:19.12s\n",
      "Steps: 222 | Train Loss: 0.0830884 Vali Loss: 0.0870180 Test Loss: 0.1317738\n",
      "Validation loss decreased (0.087081 --> 0.087018).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0815017\n",
      "\tspeed: 0.2355s/iter; left time: 2276.7389s\n",
      "\titers: 200, epoch: 57 | loss: 0.0818871\n",
      "\tspeed: 0.0840s/iter; left time: 803.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:18.90s\n",
      "Steps: 222 | Train Loss: 0.0829921 Vali Loss: 0.0874952 Test Loss: 0.1334562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0800838\n",
      "\tspeed: 0.2465s/iter; left time: 2329.0129s\n",
      "\titers: 200, epoch: 58 | loss: 0.0802353\n",
      "\tspeed: 0.0816s/iter; left time: 762.8078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:18.86s\n",
      "Steps: 222 | Train Loss: 0.0833282 Vali Loss: 0.0873506 Test Loss: 0.1331623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0833622\n",
      "\tspeed: 0.2399s/iter; left time: 2212.6575s\n",
      "\titers: 200, epoch: 59 | loss: 0.0790680\n",
      "\tspeed: 0.0833s/iter; left time: 759.9588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:19.24s\n",
      "Steps: 222 | Train Loss: 0.0830511 Vali Loss: 0.0873754 Test Loss: 0.1330397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0819512\n",
      "\tspeed: 0.2434s/iter; left time: 2191.6622s\n",
      "\titers: 200, epoch: 60 | loss: 0.0839351\n",
      "\tspeed: 0.0827s/iter; left time: 736.4877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:18.76s\n",
      "Steps: 222 | Train Loss: 0.0829204 Vali Loss: 0.0871372 Test Loss: 0.1325173\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0825650\n",
      "\tspeed: 0.2393s/iter; left time: 2101.4255s\n",
      "\titers: 200, epoch: 61 | loss: 0.0841407\n",
      "\tspeed: 0.0842s/iter; left time: 731.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:18.94s\n",
      "Steps: 222 | Train Loss: 0.0831984 Vali Loss: 0.0876740 Test Loss: 0.1336304\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0848692\n",
      "\tspeed: 0.2419s/iter; left time: 2070.7684s\n",
      "\titers: 200, epoch: 62 | loss: 0.0811387\n",
      "\tspeed: 0.0834s/iter; left time: 705.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:18.94s\n",
      "Steps: 222 | Train Loss: 0.0829256 Vali Loss: 0.0869855 Test Loss: 0.1324427\n",
      "Validation loss decreased (0.087018 --> 0.086985).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0807236\n",
      "\tspeed: 0.2397s/iter; left time: 1998.4881s\n",
      "\titers: 200, epoch: 63 | loss: 0.0839715\n",
      "\tspeed: 0.0834s/iter; left time: 687.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:18.91s\n",
      "Steps: 222 | Train Loss: 0.0840017 Vali Loss: 0.0872401 Test Loss: 0.1328288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0840662\n",
      "\tspeed: 0.2440s/iter; left time: 1980.0588s\n",
      "\titers: 200, epoch: 64 | loss: 0.0814487\n",
      "\tspeed: 0.0808s/iter; left time: 647.8794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0830301 Vali Loss: 0.0874077 Test Loss: 0.1331177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0852366\n",
      "\tspeed: 0.2435s/iter; left time: 1922.3279s\n",
      "\titers: 200, epoch: 65 | loss: 0.0878065\n",
      "\tspeed: 0.0824s/iter; left time: 641.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:18.89s\n",
      "Steps: 222 | Train Loss: 0.0829329 Vali Loss: 0.0875846 Test Loss: 0.1335388\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0826515\n",
      "\tspeed: 0.2410s/iter; left time: 1848.6330s\n",
      "\titers: 200, epoch: 66 | loss: 0.0855218\n",
      "\tspeed: 0.0840s/iter; left time: 635.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:18.91s\n",
      "Steps: 222 | Train Loss: 0.0833548 Vali Loss: 0.0877195 Test Loss: 0.1341210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0827173\n",
      "\tspeed: 0.2384s/iter; left time: 1775.5156s\n",
      "\titers: 200, epoch: 67 | loss: 0.0806148\n",
      "\tspeed: 0.0821s/iter; left time: 603.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0829735 Vali Loss: 0.0873378 Test Loss: 0.1333719\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0791283\n",
      "\tspeed: 0.2397s/iter; left time: 1732.1119s\n",
      "\titers: 200, epoch: 68 | loss: 0.0838164\n",
      "\tspeed: 0.0848s/iter; left time: 604.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:19.19s\n",
      "Steps: 222 | Train Loss: 0.0829677 Vali Loss: 0.0874819 Test Loss: 0.1332354\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0830312\n",
      "\tspeed: 0.2350s/iter; left time: 1646.2734s\n",
      "\titers: 200, epoch: 69 | loss: 0.0801882\n",
      "\tspeed: 0.0808s/iter; left time: 558.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.0830101 Vali Loss: 0.0871733 Test Loss: 0.1320888\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0822263\n",
      "\tspeed: 0.2363s/iter; left time: 1602.5984s\n",
      "\titers: 200, epoch: 70 | loss: 0.0820833\n",
      "\tspeed: 0.0844s/iter; left time: 563.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:18.92s\n",
      "Steps: 222 | Train Loss: 0.0830275 Vali Loss: 0.0872230 Test Loss: 0.1325817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0830849\n",
      "\tspeed: 0.2436s/iter; left time: 1598.4476s\n",
      "\titers: 200, epoch: 71 | loss: 0.0860324\n",
      "\tspeed: 0.0871s/iter; left time: 562.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:19.16s\n",
      "Steps: 222 | Train Loss: 0.0829951 Vali Loss: 0.0872997 Test Loss: 0.1325963\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0813553\n",
      "\tspeed: 0.2428s/iter; left time: 1538.8148s\n",
      "\titers: 200, epoch: 72 | loss: 0.0821610\n",
      "\tspeed: 0.0813s/iter; left time: 507.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0832160 Vali Loss: 0.0875694 Test Loss: 0.1336513\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04653661325573921, rmse:0.21572346985340118, mae:0.13244275748729706, rse:0.6337761282920837\n",
      "Intermediate time for ES and pred_len 168: 00h:45m:24.85s\n",
      "Intermediate time for ES: 01h:19m:29.94s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2828788\n",
      "\tspeed: 0.0966s/iter; left time: 2145.3400s\n",
      "\titers: 200, epoch: 1 | loss: 0.2437136\n",
      "\tspeed: 0.0683s/iter; left time: 1509.7545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.92s\n",
      "Steps: 223 | Train Loss: 0.2837180 Vali Loss: 0.2025528 Test Loss: 0.2080802\n",
      "Validation loss decreased (inf --> 0.202553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1686376\n",
      "\tspeed: 0.1461s/iter; left time: 3210.5455s\n",
      "\titers: 200, epoch: 2 | loss: 0.1266646\n",
      "\tspeed: 0.0696s/iter; left time: 1522.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1673479 Vali Loss: 0.1295527 Test Loss: 0.1519311\n",
      "Validation loss decreased (0.202553 --> 0.129553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1080618\n",
      "\tspeed: 0.1488s/iter; left time: 3236.9429s\n",
      "\titers: 200, epoch: 3 | loss: 0.0909165\n",
      "\tspeed: 0.0664s/iter; left time: 1437.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 223 | Train Loss: 0.1080026 Vali Loss: 0.0944639 Test Loss: 0.1082993\n",
      "Validation loss decreased (0.129553 --> 0.094464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0869093\n",
      "\tspeed: 0.1488s/iter; left time: 3204.8760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0708620\n",
      "\tspeed: 0.0673s/iter; left time: 1442.4424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 223 | Train Loss: 0.0811177 Vali Loss: 0.0770427 Test Loss: 0.0867743\n",
      "Validation loss decreased (0.094464 --> 0.077043).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679235\n",
      "\tspeed: 0.1513s/iter; left time: 3223.9445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0703295\n",
      "\tspeed: 0.0675s/iter; left time: 1431.2907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0687047 Vali Loss: 0.0696698 Test Loss: 0.0768566\n",
      "Validation loss decreased (0.077043 --> 0.069670).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0623873\n",
      "\tspeed: 0.1511s/iter; left time: 3186.4665s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627164\n",
      "\tspeed: 0.0683s/iter; left time: 1432.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.0626935 Vali Loss: 0.0672146 Test Loss: 0.0737432\n",
      "Validation loss decreased (0.069670 --> 0.067215).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585631\n",
      "\tspeed: 0.1524s/iter; left time: 3179.8938s\n",
      "\titers: 200, epoch: 7 | loss: 0.0633108\n",
      "\tspeed: 0.0691s/iter; left time: 1435.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 223 | Train Loss: 0.0600569 Vali Loss: 0.0645218 Test Loss: 0.0714450\n",
      "Validation loss decreased (0.067215 --> 0.064522).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0557721\n",
      "\tspeed: 0.1493s/iter; left time: 3081.1124s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542722\n",
      "\tspeed: 0.0683s/iter; left time: 1403.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0580943 Vali Loss: 0.0625661 Test Loss: 0.0691818\n",
      "Validation loss decreased (0.064522 --> 0.062566).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0587338\n",
      "\tspeed: 0.1470s/iter; left time: 3001.6322s\n",
      "\titers: 200, epoch: 9 | loss: 0.0566891\n",
      "\tspeed: 0.0675s/iter; left time: 1370.6480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 223 | Train Loss: 0.0570818 Vali Loss: 0.0653189 Test Loss: 0.0715130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0562397\n",
      "\tspeed: 0.1572s/iter; left time: 3174.5577s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559129\n",
      "\tspeed: 0.0743s/iter; left time: 1493.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.59s\n",
      "Steps: 223 | Train Loss: 0.0554649 Vali Loss: 0.0620180 Test Loss: 0.0689081\n",
      "Validation loss decreased (0.062566 --> 0.062018).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0558411\n",
      "\tspeed: 0.1638s/iter; left time: 3272.0908s\n",
      "\titers: 200, epoch: 11 | loss: 0.0504240\n",
      "\tspeed: 0.0688s/iter; left time: 1367.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.16s\n",
      "Steps: 223 | Train Loss: 0.0548454 Vali Loss: 0.0618429 Test Loss: 0.0685487\n",
      "Validation loss decreased (0.062018 --> 0.061843).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0530113\n",
      "\tspeed: 0.1485s/iter; left time: 2933.2498s\n",
      "\titers: 200, epoch: 12 | loss: 0.0554107\n",
      "\tspeed: 0.0690s/iter; left time: 1355.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 223 | Train Loss: 0.0541529 Vali Loss: 0.0607527 Test Loss: 0.0668162\n",
      "Validation loss decreased (0.061843 --> 0.060753).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559148\n",
      "\tspeed: 0.1497s/iter; left time: 2923.6160s\n",
      "\titers: 200, epoch: 13 | loss: 0.0513095\n",
      "\tspeed: 0.0690s/iter; left time: 1339.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.0539329 Vali Loss: 0.0604366 Test Loss: 0.0666289\n",
      "Validation loss decreased (0.060753 --> 0.060437).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0516774\n",
      "\tspeed: 0.1502s/iter; left time: 2899.6612s\n",
      "\titers: 200, epoch: 14 | loss: 0.0490398\n",
      "\tspeed: 0.0692s/iter; left time: 1328.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.94s\n",
      "Steps: 223 | Train Loss: 0.0533398 Vali Loss: 0.0614119 Test Loss: 0.0676202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0528224\n",
      "\tspeed: 0.1552s/iter; left time: 2960.8807s\n",
      "\titers: 200, epoch: 15 | loss: 0.0518462\n",
      "\tspeed: 0.0680s/iter; left time: 1290.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:16.01s\n",
      "Steps: 223 | Train Loss: 0.0526649 Vali Loss: 0.0598233 Test Loss: 0.0655937\n",
      "Validation loss decreased (0.060437 --> 0.059823).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0508829\n",
      "\tspeed: 0.1652s/iter; left time: 3114.9921s\n",
      "\titers: 200, epoch: 16 | loss: 0.0535198\n",
      "\tspeed: 0.0684s/iter; left time: 1282.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.86s\n",
      "Steps: 223 | Train Loss: 0.0522849 Vali Loss: 0.0595741 Test Loss: 0.0656710\n",
      "Validation loss decreased (0.059823 --> 0.059574).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513684\n",
      "\tspeed: 0.1511s/iter; left time: 2816.0948s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532046\n",
      "\tspeed: 0.0703s/iter; left time: 1302.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 223 | Train Loss: 0.0522383 Vali Loss: 0.0598465 Test Loss: 0.0660389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0513407\n",
      "\tspeed: 0.1503s/iter; left time: 2766.9647s\n",
      "\titers: 200, epoch: 18 | loss: 0.0528799\n",
      "\tspeed: 0.0702s/iter; left time: 1284.5534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.98s\n",
      "Steps: 223 | Train Loss: 0.0519505 Vali Loss: 0.0609218 Test Loss: 0.0665658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0509499\n",
      "\tspeed: 0.1526s/iter; left time: 2775.0719s\n",
      "\titers: 200, epoch: 19 | loss: 0.0528819\n",
      "\tspeed: 0.0689s/iter; left time: 1246.5730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 223 | Train Loss: 0.0518262 Vali Loss: 0.0589856 Test Loss: 0.0649928\n",
      "Validation loss decreased (0.059574 --> 0.058986).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0501960\n",
      "\tspeed: 0.1548s/iter; left time: 2781.0682s\n",
      "\titers: 200, epoch: 20 | loss: 0.0497564\n",
      "\tspeed: 0.0707s/iter; left time: 1262.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 223 | Train Loss: 0.0514431 Vali Loss: 0.0589191 Test Loss: 0.0649223\n",
      "Validation loss decreased (0.058986 --> 0.058919).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0502469\n",
      "\tspeed: 0.1510s/iter; left time: 2678.1721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0539150\n",
      "\tspeed: 0.0692s/iter; left time: 1220.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 223 | Train Loss: 0.0512955 Vali Loss: 0.0588420 Test Loss: 0.0647146\n",
      "Validation loss decreased (0.058919 --> 0.058842).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0514413\n",
      "\tspeed: 0.1548s/iter; left time: 2711.7420s\n",
      "\titers: 200, epoch: 22 | loss: 0.0506372\n",
      "\tspeed: 0.0678s/iter; left time: 1181.5267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:16.07s\n",
      "Steps: 223 | Train Loss: 0.0510955 Vali Loss: 0.0594373 Test Loss: 0.0655300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0551648\n",
      "\tspeed: 0.1527s/iter; left time: 2640.1447s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531998\n",
      "\tspeed: 0.0692s/iter; left time: 1190.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 223 | Train Loss: 0.0509061 Vali Loss: 0.0588389 Test Loss: 0.0644467\n",
      "Validation loss decreased (0.058842 --> 0.058839).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0523015\n",
      "\tspeed: 0.1568s/iter; left time: 2676.6122s\n",
      "\titers: 200, epoch: 24 | loss: 0.0483427\n",
      "\tspeed: 0.0703s/iter; left time: 1193.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 223 | Train Loss: 0.0508291 Vali Loss: 0.0585164 Test Loss: 0.0645202\n",
      "Validation loss decreased (0.058839 --> 0.058516).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0527910\n",
      "\tspeed: 0.1575s/iter; left time: 2653.1322s\n",
      "\titers: 200, epoch: 25 | loss: 0.0525988\n",
      "\tspeed: 0.0726s/iter; left time: 1216.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 223 | Train Loss: 0.0508029 Vali Loss: 0.0586363 Test Loss: 0.0643557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0534954\n",
      "\tspeed: 0.1522s/iter; left time: 2529.7412s\n",
      "\titers: 200, epoch: 26 | loss: 0.0533771\n",
      "\tspeed: 0.0700s/iter; left time: 1156.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:16.03s\n",
      "Steps: 223 | Train Loss: 0.0506707 Vali Loss: 0.0586305 Test Loss: 0.0647778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0525613\n",
      "\tspeed: 0.1534s/iter; left time: 2516.8911s\n",
      "\titers: 200, epoch: 27 | loss: 0.0503731\n",
      "\tspeed: 0.0724s/iter; left time: 1181.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:16.33s\n",
      "Steps: 223 | Train Loss: 0.0505554 Vali Loss: 0.0582939 Test Loss: 0.0643018\n",
      "Validation loss decreased (0.058516 --> 0.058294).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0506064\n",
      "\tspeed: 0.1560s/iter; left time: 2523.8617s\n",
      "\titers: 200, epoch: 28 | loss: 0.0492523\n",
      "\tspeed: 0.0716s/iter; left time: 1152.0333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:16.42s\n",
      "Steps: 223 | Train Loss: 0.0503551 Vali Loss: 0.0588362 Test Loss: 0.0650539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0492361\n",
      "\tspeed: 0.1557s/iter; left time: 2484.3377s\n",
      "\titers: 200, epoch: 29 | loss: 0.0485700\n",
      "\tspeed: 0.0730s/iter; left time: 1158.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:16.75s\n",
      "Steps: 223 | Train Loss: 0.0503810 Vali Loss: 0.0583515 Test Loss: 0.0641915\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0549046\n",
      "\tspeed: 0.1604s/iter; left time: 2523.1215s\n",
      "\titers: 200, epoch: 30 | loss: 0.0522134\n",
      "\tspeed: 0.0724s/iter; left time: 1131.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:16.84s\n",
      "Steps: 223 | Train Loss: 0.0502538 Vali Loss: 0.0599024 Test Loss: 0.0653761\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0505050\n",
      "\tspeed: 0.1633s/iter; left time: 2532.9316s\n",
      "\titers: 200, epoch: 31 | loss: 0.0519006\n",
      "\tspeed: 0.0756s/iter; left time: 1165.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:17.19s\n",
      "Steps: 223 | Train Loss: 0.0502400 Vali Loss: 0.0582784 Test Loss: 0.0641736\n",
      "Validation loss decreased (0.058294 --> 0.058278).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0474981\n",
      "\tspeed: 0.1675s/iter; left time: 2561.2342s\n",
      "\titers: 200, epoch: 32 | loss: 0.0522959\n",
      "\tspeed: 0.0739s/iter; left time: 1122.0371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 223 | Train Loss: 0.0501486 Vali Loss: 0.0583313 Test Loss: 0.0641860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0497762\n",
      "\tspeed: 0.1646s/iter; left time: 2479.9133s\n",
      "\titers: 200, epoch: 33 | loss: 0.0482114\n",
      "\tspeed: 0.0761s/iter; left time: 1139.4100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:17.29s\n",
      "Steps: 223 | Train Loss: 0.0499977 Vali Loss: 0.0584331 Test Loss: 0.0641088\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525409\n",
      "\tspeed: 0.1616s/iter; left time: 2398.3991s\n",
      "\titers: 200, epoch: 34 | loss: 0.0501980\n",
      "\tspeed: 0.0747s/iter; left time: 1101.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 223 | Train Loss: 0.0500957 Vali Loss: 0.0583082 Test Loss: 0.0639644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0499385\n",
      "\tspeed: 0.1620s/iter; left time: 2368.0225s\n",
      "\titers: 200, epoch: 35 | loss: 0.0471079\n",
      "\tspeed: 0.0764s/iter; left time: 1108.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:17.34s\n",
      "Steps: 223 | Train Loss: 0.0499424 Vali Loss: 0.0581979 Test Loss: 0.0639626\n",
      "Validation loss decreased (0.058278 --> 0.058198).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0509089\n",
      "\tspeed: 0.1631s/iter; left time: 2348.1910s\n",
      "\titers: 200, epoch: 36 | loss: 0.0496509\n",
      "\tspeed: 0.0753s/iter; left time: 1076.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:17.12s\n",
      "Steps: 223 | Train Loss: 0.0499227 Vali Loss: 0.0580915 Test Loss: 0.0640359\n",
      "Validation loss decreased (0.058198 --> 0.058092).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0515159\n",
      "\tspeed: 0.1662s/iter; left time: 2355.1136s\n",
      "\titers: 200, epoch: 37 | loss: 0.0526967\n",
      "\tspeed: 0.0758s/iter; left time: 1066.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:17.36s\n",
      "Steps: 223 | Train Loss: 0.0499270 Vali Loss: 0.0581878 Test Loss: 0.0640753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0480199\n",
      "\tspeed: 0.1636s/iter; left time: 2281.7735s\n",
      "\titers: 200, epoch: 38 | loss: 0.0511516\n",
      "\tspeed: 0.0755s/iter; left time: 1046.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:17.11s\n",
      "Steps: 223 | Train Loss: 0.0498744 Vali Loss: 0.0581401 Test Loss: 0.0640007\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0495438\n",
      "\tspeed: 0.1627s/iter; left time: 2233.5565s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528563\n",
      "\tspeed: 0.0773s/iter; left time: 1052.8268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:17.24s\n",
      "Steps: 223 | Train Loss: 0.0497603 Vali Loss: 0.0581317 Test Loss: 0.0640220\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0512163\n",
      "\tspeed: 0.1623s/iter; left time: 2192.1523s\n",
      "\titers: 200, epoch: 40 | loss: 0.0524048\n",
      "\tspeed: 0.0749s/iter; left time: 1003.8207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 223 | Train Loss: 0.0498229 Vali Loss: 0.0581836 Test Loss: 0.0639885\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0487834\n",
      "\tspeed: 0.1616s/iter; left time: 2145.6972s\n",
      "\titers: 200, epoch: 41 | loss: 0.0456459\n",
      "\tspeed: 0.0743s/iter; left time: 979.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 223 | Train Loss: 0.0497658 Vali Loss: 0.0580611 Test Loss: 0.0639018\n",
      "Validation loss decreased (0.058092 --> 0.058061).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0522386\n",
      "\tspeed: 0.1693s/iter; left time: 2211.0121s\n",
      "\titers: 200, epoch: 42 | loss: 0.0494738\n",
      "\tspeed: 0.0847s/iter; left time: 1097.2499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 223 | Train Loss: 0.0496871 Vali Loss: 0.0580055 Test Loss: 0.0639366\n",
      "Validation loss decreased (0.058061 --> 0.058005).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0486762\n",
      "\tspeed: 0.1775s/iter; left time: 2278.5283s\n",
      "\titers: 200, epoch: 43 | loss: 0.0515852\n",
      "\tspeed: 0.0811s/iter; left time: 1033.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.53s\n",
      "Steps: 223 | Train Loss: 0.0497967 Vali Loss: 0.0579855 Test Loss: 0.0639271\n",
      "Validation loss decreased (0.058005 --> 0.057986).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0465257\n",
      "\tspeed: 0.1736s/iter; left time: 2189.9729s\n",
      "\titers: 200, epoch: 44 | loss: 0.0539892\n",
      "\tspeed: 0.0777s/iter; left time: 971.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0498699 Vali Loss: 0.0579828 Test Loss: 0.0638156\n",
      "Validation loss decreased (0.057986 --> 0.057983).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0486124\n",
      "\tspeed: 0.1749s/iter; left time: 2167.1716s\n",
      "\titers: 200, epoch: 45 | loss: 0.0481620\n",
      "\tspeed: 0.0787s/iter; left time: 967.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0497553 Vali Loss: 0.0580263 Test Loss: 0.0638639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0511678\n",
      "\tspeed: 0.1670s/iter; left time: 2031.6147s\n",
      "\titers: 200, epoch: 46 | loss: 0.0484396\n",
      "\tspeed: 0.0768s/iter; left time: 926.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:17.61s\n",
      "Steps: 223 | Train Loss: 0.0497213 Vali Loss: 0.0579032 Test Loss: 0.0639849\n",
      "Validation loss decreased (0.057983 --> 0.057903).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0475906\n",
      "\tspeed: 0.1664s/iter; left time: 1987.8320s\n",
      "\titers: 200, epoch: 47 | loss: 0.0520929\n",
      "\tspeed: 0.0777s/iter; left time: 919.7374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:17.89s\n",
      "Steps: 223 | Train Loss: 0.0497306 Vali Loss: 0.0579705 Test Loss: 0.0639318\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0501741\n",
      "\tspeed: 0.1701s/iter; left time: 1993.0982s\n",
      "\titers: 200, epoch: 48 | loss: 0.0498039\n",
      "\tspeed: 0.0786s/iter; left time: 912.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:17.97s\n",
      "Steps: 223 | Train Loss: 0.0497341 Vali Loss: 0.0579804 Test Loss: 0.0638072\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0494548\n",
      "\tspeed: 0.1682s/iter; left time: 1933.6979s\n",
      "\titers: 200, epoch: 49 | loss: 0.0485717\n",
      "\tspeed: 0.0766s/iter; left time: 872.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:17.64s\n",
      "Steps: 223 | Train Loss: 0.0497206 Vali Loss: 0.0579633 Test Loss: 0.0637432\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0507115\n",
      "\tspeed: 0.1662s/iter; left time: 1873.9124s\n",
      "\titers: 200, epoch: 50 | loss: 0.0478464\n",
      "\tspeed: 0.0777s/iter; left time: 868.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:17.62s\n",
      "Steps: 223 | Train Loss: 0.0496050 Vali Loss: 0.0580187 Test Loss: 0.0638746\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0503432\n",
      "\tspeed: 0.1703s/iter; left time: 1881.5749s\n",
      "\titers: 200, epoch: 51 | loss: 0.0482400\n",
      "\tspeed: 0.0767s/iter; left time: 839.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0496026 Vali Loss: 0.0578983 Test Loss: 0.0639598\n",
      "Validation loss decreased (0.057903 --> 0.057898).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0530060\n",
      "\tspeed: 0.1688s/iter; left time: 1828.0861s\n",
      "\titers: 200, epoch: 52 | loss: 0.0474543\n",
      "\tspeed: 0.0784s/iter; left time: 841.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:17.73s\n",
      "Steps: 223 | Train Loss: 0.0495388 Vali Loss: 0.0578965 Test Loss: 0.0639028\n",
      "Validation loss decreased (0.057898 --> 0.057896).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0532143\n",
      "\tspeed: 0.1699s/iter; left time: 1802.1397s\n",
      "\titers: 200, epoch: 53 | loss: 0.0495643\n",
      "\tspeed: 0.0783s/iter; left time: 822.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:17.90s\n",
      "Steps: 223 | Train Loss: 0.0495300 Vali Loss: 0.0579893 Test Loss: 0.0637743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0514539\n",
      "\tspeed: 0.1663s/iter; left time: 1726.7649s\n",
      "\titers: 200, epoch: 54 | loss: 0.0487289\n",
      "\tspeed: 0.0769s/iter; left time: 790.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:17.55s\n",
      "Steps: 223 | Train Loss: 0.0495767 Vali Loss: 0.0579832 Test Loss: 0.0639462\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0490304\n",
      "\tspeed: 0.1651s/iter; left time: 1676.9804s\n",
      "\titers: 200, epoch: 55 | loss: 0.0485974\n",
      "\tspeed: 0.0772s/iter; left time: 776.3994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:17.68s\n",
      "Steps: 223 | Train Loss: 0.0495676 Vali Loss: 0.0579684 Test Loss: 0.0639201\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0515207\n",
      "\tspeed: 0.1630s/iter; left time: 1619.1081s\n",
      "\titers: 200, epoch: 56 | loss: 0.0525868\n",
      "\tspeed: 0.0762s/iter; left time: 749.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:17.38s\n",
      "Steps: 223 | Train Loss: 0.0495745 Vali Loss: 0.0581349 Test Loss: 0.0639460\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0487749\n",
      "\tspeed: 0.1675s/iter; left time: 1626.5735s\n",
      "\titers: 200, epoch: 57 | loss: 0.0505745\n",
      "\tspeed: 0.0786s/iter; left time: 755.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:17.70s\n",
      "Steps: 223 | Train Loss: 0.0495602 Vali Loss: 0.0581718 Test Loss: 0.0639829\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0519050\n",
      "\tspeed: 0.1627s/iter; left time: 1543.8382s\n",
      "\titers: 200, epoch: 58 | loss: 0.0474512\n",
      "\tspeed: 0.0749s/iter; left time: 703.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:17.12s\n",
      "Steps: 223 | Train Loss: 0.0495687 Vali Loss: 0.0580050 Test Loss: 0.0639098\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0490051\n",
      "\tspeed: 0.1634s/iter; left time: 1514.5891s\n",
      "\titers: 200, epoch: 59 | loss: 0.0502170\n",
      "\tspeed: 0.0763s/iter; left time: 699.8142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:17.33s\n",
      "Steps: 223 | Train Loss: 0.0495362 Vali Loss: 0.0580077 Test Loss: 0.0638145\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0473861\n",
      "\tspeed: 0.1653s/iter; left time: 1494.6560s\n",
      "\titers: 200, epoch: 60 | loss: 0.0504264\n",
      "\tspeed: 0.0763s/iter; left time: 682.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:17.47s\n",
      "Steps: 223 | Train Loss: 0.0495430 Vali Loss: 0.0579263 Test Loss: 0.0639119\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0489060\n",
      "\tspeed: 0.1652s/iter; left time: 1456.8111s\n",
      "\titers: 200, epoch: 61 | loss: 0.0468738\n",
      "\tspeed: 0.0749s/iter; left time: 653.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:17.35s\n",
      "Steps: 223 | Train Loss: 0.0496028 Vali Loss: 0.0578953 Test Loss: 0.0638676\n",
      "Validation loss decreased (0.057896 --> 0.057895).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0502880\n",
      "\tspeed: 0.1610s/iter; left time: 1384.0319s\n",
      "\titers: 200, epoch: 62 | loss: 0.0524167\n",
      "\tspeed: 0.0771s/iter; left time: 655.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 223 | Train Loss: 0.0495506 Vali Loss: 0.0579389 Test Loss: 0.0638221\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0494202\n",
      "\tspeed: 0.1634s/iter; left time: 1368.6387s\n",
      "\titers: 200, epoch: 63 | loss: 0.0498640\n",
      "\tspeed: 0.0762s/iter; left time: 630.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:17.37s\n",
      "Steps: 223 | Train Loss: 0.0496471 Vali Loss: 0.0581017 Test Loss: 0.0640110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0484178\n",
      "\tspeed: 0.1616s/iter; left time: 1317.7090s\n",
      "\titers: 200, epoch: 64 | loss: 0.0526438\n",
      "\tspeed: 0.0733s/iter; left time: 589.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 223 | Train Loss: 0.0495332 Vali Loss: 0.0580086 Test Loss: 0.0638289\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0507073\n",
      "\tspeed: 0.1636s/iter; left time: 1297.1019s\n",
      "\titers: 200, epoch: 65 | loss: 0.0517477\n",
      "\tspeed: 0.0765s/iter; left time: 599.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:17.25s\n",
      "Steps: 223 | Train Loss: 0.0495867 Vali Loss: 0.0579901 Test Loss: 0.0638819\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0492522\n",
      "\tspeed: 0.1623s/iter; left time: 1250.8046s\n",
      "\titers: 200, epoch: 66 | loss: 0.0500161\n",
      "\tspeed: 0.0751s/iter; left time: 571.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:17.21s\n",
      "Steps: 223 | Train Loss: 0.0495739 Vali Loss: 0.0578278 Test Loss: 0.0638604\n",
      "Validation loss decreased (0.057895 --> 0.057828).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0535236\n",
      "\tspeed: 0.1645s/iter; left time: 1231.2862s\n",
      "\titers: 200, epoch: 67 | loss: 0.0487632\n",
      "\tspeed: 0.0727s/iter; left time: 536.7421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:16.98s\n",
      "Steps: 223 | Train Loss: 0.0495085 Vali Loss: 0.0579350 Test Loss: 0.0638509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0492562\n",
      "\tspeed: 0.1616s/iter; left time: 1173.5579s\n",
      "\titers: 200, epoch: 68 | loss: 0.0526231\n",
      "\tspeed: 0.0762s/iter; left time: 545.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:17.36s\n",
      "Steps: 223 | Train Loss: 0.0495075 Vali Loss: 0.0578424 Test Loss: 0.0638246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0533621\n",
      "\tspeed: 0.1663s/iter; left time: 1170.4005s\n",
      "\titers: 200, epoch: 69 | loss: 0.0520198\n",
      "\tspeed: 0.0739s/iter; left time: 512.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:17.48s\n",
      "Steps: 223 | Train Loss: 0.0495003 Vali Loss: 0.0579257 Test Loss: 0.0638312\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0495660\n",
      "\tspeed: 0.1625s/iter; left time: 1107.3477s\n",
      "\titers: 200, epoch: 70 | loss: 0.0489646\n",
      "\tspeed: 0.0731s/iter; left time: 491.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:16.85s\n",
      "Steps: 223 | Train Loss: 0.0495810 Vali Loss: 0.0579508 Test Loss: 0.0638814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0506874\n",
      "\tspeed: 0.1610s/iter; left time: 1060.9500s\n",
      "\titers: 200, epoch: 71 | loss: 0.0477193\n",
      "\tspeed: 0.0736s/iter; left time: 477.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:16.90s\n",
      "Steps: 223 | Train Loss: 0.0495968 Vali Loss: 0.0578537 Test Loss: 0.0638997\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0499876\n",
      "\tspeed: 0.1622s/iter; left time: 1032.7148s\n",
      "\titers: 200, epoch: 72 | loss: 0.0489400\n",
      "\tspeed: 0.0756s/iter; left time: 473.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:17.21s\n",
      "Steps: 223 | Train Loss: 0.0494948 Vali Loss: 0.0579187 Test Loss: 0.0638216\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0475729\n",
      "\tspeed: 0.1619s/iter; left time: 994.7420s\n",
      "\titers: 200, epoch: 73 | loss: 0.0479499\n",
      "\tspeed: 0.0744s/iter; left time: 449.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:16.94s\n",
      "Steps: 223 | Train Loss: 0.0494927 Vali Loss: 0.0578359 Test Loss: 0.0637880\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0502341\n",
      "\tspeed: 0.1620s/iter; left time: 959.5449s\n",
      "\titers: 200, epoch: 74 | loss: 0.0490378\n",
      "\tspeed: 0.0740s/iter; left time: 430.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:17.04s\n",
      "Steps: 223 | Train Loss: 0.0495155 Vali Loss: 0.0579903 Test Loss: 0.0639296\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0496189\n",
      "\tspeed: 0.1604s/iter; left time: 914.0846s\n",
      "\titers: 200, epoch: 75 | loss: 0.0492870\n",
      "\tspeed: 0.0751s/iter; left time: 420.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:17.07s\n",
      "Steps: 223 | Train Loss: 0.0494897 Vali Loss: 0.0579235 Test Loss: 0.0638473\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0496947\n",
      "\tspeed: 0.1615s/iter; left time: 884.3531s\n",
      "\titers: 200, epoch: 76 | loss: 0.0494388\n",
      "\tspeed: 0.0738s/iter; left time: 396.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:17.19s\n",
      "Steps: 223 | Train Loss: 0.0496155 Vali Loss: 0.0579117 Test Loss: 0.0638364\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011898575350642204, rmse:0.10908059030771255, mae:0.06386039406061172, rse:0.4208298623561859\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2828164\n",
      "\tspeed: 0.0781s/iter; left time: 1733.7221s\n",
      "\titers: 200, epoch: 1 | loss: 0.2472405\n",
      "\tspeed: 0.0759s/iter; left time: 1678.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:17.15s\n",
      "Steps: 223 | Train Loss: 0.2875768 Vali Loss: 0.2047670 Test Loss: 0.2090477\n",
      "Validation loss decreased (inf --> 0.204767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1735363\n",
      "\tspeed: 0.1649s/iter; left time: 3623.9076s\n",
      "\titers: 200, epoch: 2 | loss: 0.1343435\n",
      "\tspeed: 0.0758s/iter; left time: 1658.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.28s\n",
      "Steps: 223 | Train Loss: 0.1714466 Vali Loss: 0.1294951 Test Loss: 0.1529826\n",
      "Validation loss decreased (0.204767 --> 0.129495).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135385\n",
      "\tspeed: 0.1636s/iter; left time: 3558.9331s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924409\n",
      "\tspeed: 0.0746s/iter; left time: 1616.0462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.08s\n",
      "Steps: 223 | Train Loss: 0.1068394 Vali Loss: 0.0961636 Test Loss: 0.1081751\n",
      "Validation loss decreased (0.129495 --> 0.096164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774882\n",
      "\tspeed: 0.1636s/iter; left time: 3522.1220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714796\n",
      "\tspeed: 0.0738s/iter; left time: 1582.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 223 | Train Loss: 0.0811721 Vali Loss: 0.0769064 Test Loss: 0.0859565\n",
      "Validation loss decreased (0.096164 --> 0.076906).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0719130\n",
      "\tspeed: 0.1659s/iter; left time: 3534.0985s\n",
      "\titers: 200, epoch: 5 | loss: 0.0656092\n",
      "\tspeed: 0.0739s/iter; left time: 1567.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.14s\n",
      "Steps: 223 | Train Loss: 0.0686620 Vali Loss: 0.0708951 Test Loss: 0.0792277\n",
      "Validation loss decreased (0.076906 --> 0.070895).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0706517\n",
      "\tspeed: 0.1643s/iter; left time: 3464.0824s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627004\n",
      "\tspeed: 0.0752s/iter; left time: 1579.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.24s\n",
      "Steps: 223 | Train Loss: 0.0626684 Vali Loss: 0.0663768 Test Loss: 0.0737693\n",
      "Validation loss decreased (0.070895 --> 0.066377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595170\n",
      "\tspeed: 0.1648s/iter; left time: 3438.9002s\n",
      "\titers: 200, epoch: 7 | loss: 0.0629300\n",
      "\tspeed: 0.0743s/iter; left time: 1541.8282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.93s\n",
      "Steps: 223 | Train Loss: 0.0597131 Vali Loss: 0.0707945 Test Loss: 0.0770117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0622103\n",
      "\tspeed: 0.1636s/iter; left time: 3376.0382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0547197\n",
      "\tspeed: 0.0743s/iter; left time: 1526.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:17.23s\n",
      "Steps: 223 | Train Loss: 0.0577328 Vali Loss: 0.0637909 Test Loss: 0.0716382\n",
      "Validation loss decreased (0.066377 --> 0.063791).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0595534\n",
      "\tspeed: 0.1603s/iter; left time: 3273.7303s\n",
      "\titers: 200, epoch: 9 | loss: 0.0546079\n",
      "\tspeed: 0.0760s/iter; left time: 1544.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 223 | Train Loss: 0.0563569 Vali Loss: 0.0618478 Test Loss: 0.0691103\n",
      "Validation loss decreased (0.063791 --> 0.061848).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0558740\n",
      "\tspeed: 0.1639s/iter; left time: 3309.7571s\n",
      "\titers: 200, epoch: 10 | loss: 0.0561576\n",
      "\tspeed: 0.0752s/iter; left time: 1510.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.00s\n",
      "Steps: 223 | Train Loss: 0.0549810 Vali Loss: 0.0613248 Test Loss: 0.0692294\n",
      "Validation loss decreased (0.061848 --> 0.061325).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0547265\n",
      "\tspeed: 0.1656s/iter; left time: 3307.2278s\n",
      "\titers: 200, epoch: 11 | loss: 0.0539381\n",
      "\tspeed: 0.0742s/iter; left time: 1474.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:17.20s\n",
      "Steps: 223 | Train Loss: 0.0541260 Vali Loss: 0.0612770 Test Loss: 0.0679474\n",
      "Validation loss decreased (0.061325 --> 0.061277).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0501873\n",
      "\tspeed: 0.1618s/iter; left time: 3194.9233s\n",
      "\titers: 200, epoch: 12 | loss: 0.0541616\n",
      "\tspeed: 0.0755s/iter; left time: 1482.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.08s\n",
      "Steps: 223 | Train Loss: 0.0537823 Vali Loss: 0.0616499 Test Loss: 0.0684076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0519635\n",
      "\tspeed: 0.1633s/iter; left time: 3187.5429s\n",
      "\titers: 200, epoch: 13 | loss: 0.0521477\n",
      "\tspeed: 0.0729s/iter; left time: 1415.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:16.82s\n",
      "Steps: 223 | Train Loss: 0.0530952 Vali Loss: 0.0601393 Test Loss: 0.0673633\n",
      "Validation loss decreased (0.061277 --> 0.060139).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0508347\n",
      "\tspeed: 0.1609s/iter; left time: 3105.2876s\n",
      "\titers: 200, epoch: 14 | loss: 0.0531934\n",
      "\tspeed: 0.0722s/iter; left time: 1386.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:16.69s\n",
      "Steps: 223 | Train Loss: 0.0531130 Vali Loss: 0.0598451 Test Loss: 0.0658136\n",
      "Validation loss decreased (0.060139 --> 0.059845).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521539\n",
      "\tspeed: 0.1611s/iter; left time: 3073.7989s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532904\n",
      "\tspeed: 0.0749s/iter; left time: 1420.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:17.03s\n",
      "Steps: 223 | Train Loss: 0.0520958 Vali Loss: 0.0596601 Test Loss: 0.0655564\n",
      "Validation loss decreased (0.059845 --> 0.059660).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0490224\n",
      "\tspeed: 0.1600s/iter; left time: 3016.0868s\n",
      "\titers: 200, epoch: 16 | loss: 0.0496755\n",
      "\tspeed: 0.0734s/iter; left time: 1377.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:16.73s\n",
      "Steps: 223 | Train Loss: 0.0520223 Vali Loss: 0.0591880 Test Loss: 0.0651278\n",
      "Validation loss decreased (0.059660 --> 0.059188).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0520728\n",
      "\tspeed: 0.1589s/iter; left time: 2960.8490s\n",
      "\titers: 200, epoch: 17 | loss: 0.0491760\n",
      "\tspeed: 0.0727s/iter; left time: 1346.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:16.57s\n",
      "Steps: 223 | Train Loss: 0.0514397 Vali Loss: 0.0592969 Test Loss: 0.0654543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0576769\n",
      "\tspeed: 0.1592s/iter; left time: 2930.7603s\n",
      "\titers: 200, epoch: 18 | loss: 0.0523924\n",
      "\tspeed: 0.0728s/iter; left time: 1332.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.96s\n",
      "Steps: 223 | Train Loss: 0.0513855 Vali Loss: 0.0620079 Test Loss: 0.0671246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0528836\n",
      "\tspeed: 0.1588s/iter; left time: 2888.7594s\n",
      "\titers: 200, epoch: 19 | loss: 0.0524819\n",
      "\tspeed: 0.0746s/iter; left time: 1349.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:16.76s\n",
      "Steps: 223 | Train Loss: 0.0513175 Vali Loss: 0.0603368 Test Loss: 0.0656929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0515281\n",
      "\tspeed: 0.1597s/iter; left time: 2869.3072s\n",
      "\titers: 200, epoch: 20 | loss: 0.0487048\n",
      "\tspeed: 0.0717s/iter; left time: 1281.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:16.63s\n",
      "Steps: 223 | Train Loss: 0.0510895 Vali Loss: 0.0586617 Test Loss: 0.0644004\n",
      "Validation loss decreased (0.059188 --> 0.058662).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0483302\n",
      "\tspeed: 0.1622s/iter; left time: 2877.1492s\n",
      "\titers: 200, epoch: 21 | loss: 0.0532133\n",
      "\tspeed: 0.0717s/iter; left time: 1265.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:16.80s\n",
      "Steps: 223 | Train Loss: 0.0508791 Vali Loss: 0.0587126 Test Loss: 0.0644493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0497920\n",
      "\tspeed: 0.1604s/iter; left time: 2809.1626s\n",
      "\titers: 200, epoch: 22 | loss: 0.0516976\n",
      "\tspeed: 0.0720s/iter; left time: 1253.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:16.65s\n",
      "Steps: 223 | Train Loss: 0.0506050 Vali Loss: 0.0586068 Test Loss: 0.0641174\n",
      "Validation loss decreased (0.058662 --> 0.058607).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0521214\n",
      "\tspeed: 0.1584s/iter; left time: 2738.9580s\n",
      "\titers: 200, epoch: 23 | loss: 0.0572686\n",
      "\tspeed: 0.0725s/iter; left time: 1247.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:16.54s\n",
      "Steps: 223 | Train Loss: 0.0509831 Vali Loss: 0.0586825 Test Loss: 0.0642385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0498578\n",
      "\tspeed: 0.1586s/iter; left time: 2708.4138s\n",
      "\titers: 200, epoch: 24 | loss: 0.0506752\n",
      "\tspeed: 0.0718s/iter; left time: 1219.1338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:16.59s\n",
      "Steps: 223 | Train Loss: 0.0504889 Vali Loss: 0.0586428 Test Loss: 0.0639987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0535546\n",
      "\tspeed: 0.1586s/iter; left time: 2672.1667s\n",
      "\titers: 200, epoch: 25 | loss: 0.0516117\n",
      "\tspeed: 0.0735s/iter; left time: 1231.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:16.60s\n",
      "Steps: 223 | Train Loss: 0.0503280 Vali Loss: 0.0587352 Test Loss: 0.0642798\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0534375\n",
      "\tspeed: 0.1576s/iter; left time: 2620.2285s\n",
      "\titers: 200, epoch: 26 | loss: 0.0525467\n",
      "\tspeed: 0.0705s/iter; left time: 1164.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:16.51s\n",
      "Steps: 223 | Train Loss: 0.0503603 Vali Loss: 0.0590428 Test Loss: 0.0644085\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0465135\n",
      "\tspeed: 0.1596s/iter; left time: 2618.5846s\n",
      "\titers: 200, epoch: 27 | loss: 0.0538803\n",
      "\tspeed: 0.0754s/iter; left time: 1229.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:16.77s\n",
      "Steps: 223 | Train Loss: 0.0501223 Vali Loss: 0.0584743 Test Loss: 0.0639411\n",
      "Validation loss decreased (0.058607 --> 0.058474).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0498343\n",
      "\tspeed: 0.1588s/iter; left time: 2569.1886s\n",
      "\titers: 200, epoch: 28 | loss: 0.0487973\n",
      "\tspeed: 0.0729s/iter; left time: 1172.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:16.56s\n",
      "Steps: 223 | Train Loss: 0.0500228 Vali Loss: 0.0583596 Test Loss: 0.0639725\n",
      "Validation loss decreased (0.058474 --> 0.058360).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0465820\n",
      "\tspeed: 0.1623s/iter; left time: 2589.6005s\n",
      "\titers: 200, epoch: 29 | loss: 0.0507199\n",
      "\tspeed: 0.0746s/iter; left time: 1183.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:16.92s\n",
      "Steps: 223 | Train Loss: 0.0500272 Vali Loss: 0.0584326 Test Loss: 0.0639009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0479375\n",
      "\tspeed: 0.1604s/iter; left time: 2524.2455s\n",
      "\titers: 200, epoch: 30 | loss: 0.0510449\n",
      "\tspeed: 0.0736s/iter; left time: 1150.1908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 223 | Train Loss: 0.0497792 Vali Loss: 0.0582136 Test Loss: 0.0635221\n",
      "Validation loss decreased (0.058360 --> 0.058214).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0512649\n",
      "\tspeed: 0.1625s/iter; left time: 2520.5672s\n",
      "\titers: 200, epoch: 31 | loss: 0.0536658\n",
      "\tspeed: 0.0704s/iter; left time: 1085.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:16.52s\n",
      "Steps: 223 | Train Loss: 0.0498167 Vali Loss: 0.0581222 Test Loss: 0.0637642\n",
      "Validation loss decreased (0.058214 --> 0.058122).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510707\n",
      "\tspeed: 0.1510s/iter; left time: 2308.0947s\n",
      "\titers: 200, epoch: 32 | loss: 0.0519969\n",
      "\tspeed: 0.0704s/iter; left time: 1068.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:16.07s\n",
      "Steps: 223 | Train Loss: 0.0498787 Vali Loss: 0.0585834 Test Loss: 0.0638173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0538387\n",
      "\tspeed: 0.1551s/iter; left time: 2336.3240s\n",
      "\titers: 200, epoch: 33 | loss: 0.0551568\n",
      "\tspeed: 0.0697s/iter; left time: 1043.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:16.15s\n",
      "Steps: 223 | Train Loss: 0.0496733 Vali Loss: 0.0588851 Test Loss: 0.0639534\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0490317\n",
      "\tspeed: 0.1521s/iter; left time: 2257.2128s\n",
      "\titers: 200, epoch: 34 | loss: 0.0473784\n",
      "\tspeed: 0.0686s/iter; left time: 1011.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:16.09s\n",
      "Steps: 223 | Train Loss: 0.0497128 Vali Loss: 0.0580527 Test Loss: 0.0635702\n",
      "Validation loss decreased (0.058122 --> 0.058053).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0477961\n",
      "\tspeed: 0.1553s/iter; left time: 2269.9917s\n",
      "\titers: 200, epoch: 35 | loss: 0.0501709\n",
      "\tspeed: 0.0720s/iter; left time: 1045.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:16.35s\n",
      "Steps: 223 | Train Loss: 0.0495988 Vali Loss: 0.0581476 Test Loss: 0.0634917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0532380\n",
      "\tspeed: 0.1551s/iter; left time: 2233.4197s\n",
      "\titers: 200, epoch: 36 | loss: 0.0473652\n",
      "\tspeed: 0.0684s/iter; left time: 977.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 223 | Train Loss: 0.0496035 Vali Loss: 0.0586342 Test Loss: 0.0637329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0485422\n",
      "\tspeed: 0.1537s/iter; left time: 2178.7203s\n",
      "\titers: 200, epoch: 37 | loss: 0.0455604\n",
      "\tspeed: 0.0712s/iter; left time: 1001.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:16.11s\n",
      "Steps: 223 | Train Loss: 0.0496808 Vali Loss: 0.0583717 Test Loss: 0.0637693\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0529093\n",
      "\tspeed: 0.1526s/iter; left time: 2129.1064s\n",
      "\titers: 200, epoch: 38 | loss: 0.0531113\n",
      "\tspeed: 0.0745s/iter; left time: 1031.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:16.83s\n",
      "Steps: 223 | Train Loss: 0.0495448 Vali Loss: 0.0583062 Test Loss: 0.0636310\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0494073\n",
      "\tspeed: 0.1595s/iter; left time: 2188.8173s\n",
      "\titers: 200, epoch: 39 | loss: 0.0476449\n",
      "\tspeed: 0.0751s/iter; left time: 1023.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:17.04s\n",
      "Steps: 223 | Train Loss: 0.0495484 Vali Loss: 0.0579671 Test Loss: 0.0633808\n",
      "Validation loss decreased (0.058053 --> 0.057967).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0511956\n",
      "\tspeed: 0.1564s/iter; left time: 2112.1380s\n",
      "\titers: 200, epoch: 40 | loss: 0.0471591\n",
      "\tspeed: 0.0711s/iter; left time: 953.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:16.19s\n",
      "Steps: 223 | Train Loss: 0.0494276 Vali Loss: 0.0581304 Test Loss: 0.0634968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0522939\n",
      "\tspeed: 0.1538s/iter; left time: 2043.1729s\n",
      "\titers: 200, epoch: 41 | loss: 0.0498335\n",
      "\tspeed: 0.0721s/iter; left time: 950.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:16.34s\n",
      "Steps: 223 | Train Loss: 0.0495961 Vali Loss: 0.0582137 Test Loss: 0.0636996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0507112\n",
      "\tspeed: 0.1549s/iter; left time: 2022.0350s\n",
      "\titers: 200, epoch: 42 | loss: 0.0505646\n",
      "\tspeed: 0.0717s/iter; left time: 928.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:16.25s\n",
      "Steps: 223 | Train Loss: 0.0493856 Vali Loss: 0.0579522 Test Loss: 0.0635362\n",
      "Validation loss decreased (0.057967 --> 0.057952).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0562049\n",
      "\tspeed: 0.1581s/iter; left time: 2028.5815s\n",
      "\titers: 200, epoch: 43 | loss: 0.0474430\n",
      "\tspeed: 0.0711s/iter; left time: 906.0847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:16.47s\n",
      "Steps: 223 | Train Loss: 0.0494186 Vali Loss: 0.0580614 Test Loss: 0.0634415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0492905\n",
      "\tspeed: 0.1575s/iter; left time: 1986.9048s\n",
      "\titers: 200, epoch: 44 | loss: 0.0499367\n",
      "\tspeed: 0.0740s/iter; left time: 925.7434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:16.83s\n",
      "Steps: 223 | Train Loss: 0.0494644 Vali Loss: 0.0580952 Test Loss: 0.0635091\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0482889\n",
      "\tspeed: 0.1566s/iter; left time: 1940.1034s\n",
      "\titers: 200, epoch: 45 | loss: 0.0496999\n",
      "\tspeed: 0.0694s/iter; left time: 852.6685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:16.33s\n",
      "Steps: 223 | Train Loss: 0.0493969 Vali Loss: 0.0579238 Test Loss: 0.0632849\n",
      "Validation loss decreased (0.057952 --> 0.057924).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0492359\n",
      "\tspeed: 0.1579s/iter; left time: 1920.6866s\n",
      "\titers: 200, epoch: 46 | loss: 0.0482824\n",
      "\tspeed: 0.0722s/iter; left time: 871.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:16.64s\n",
      "Steps: 223 | Train Loss: 0.0492682 Vali Loss: 0.0579593 Test Loss: 0.0633963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0553752\n",
      "\tspeed: 0.1548s/iter; left time: 1848.4307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0451511\n",
      "\tspeed: 0.0715s/iter; left time: 846.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:16.34s\n",
      "Steps: 223 | Train Loss: 0.0493744 Vali Loss: 0.0580040 Test Loss: 0.0632274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0501630\n",
      "\tspeed: 0.1536s/iter; left time: 1799.7928s\n",
      "\titers: 200, epoch: 48 | loss: 0.0494250\n",
      "\tspeed: 0.0712s/iter; left time: 827.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:16.37s\n",
      "Steps: 223 | Train Loss: 0.0493211 Vali Loss: 0.0580396 Test Loss: 0.0633411\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0529085\n",
      "\tspeed: 0.1554s/iter; left time: 1786.1195s\n",
      "\titers: 200, epoch: 49 | loss: 0.0471556\n",
      "\tspeed: 0.0718s/iter; left time: 817.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:16.36s\n",
      "Steps: 223 | Train Loss: 0.0493269 Vali Loss: 0.0580385 Test Loss: 0.0633722\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0486015\n",
      "\tspeed: 0.1546s/iter; left time: 1743.3375s\n",
      "\titers: 200, epoch: 50 | loss: 0.0526589\n",
      "\tspeed: 0.0713s/iter; left time: 796.5293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:16.27s\n",
      "Steps: 223 | Train Loss: 0.0494011 Vali Loss: 0.0579858 Test Loss: 0.0633229\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0512149\n",
      "\tspeed: 0.1504s/iter; left time: 1662.3665s\n",
      "\titers: 200, epoch: 51 | loss: 0.0501257\n",
      "\tspeed: 0.0710s/iter; left time: 777.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:16.14s\n",
      "Steps: 223 | Train Loss: 0.0493392 Vali Loss: 0.0580367 Test Loss: 0.0634605\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0487781\n",
      "\tspeed: 0.1527s/iter; left time: 1653.1876s\n",
      "\titers: 200, epoch: 52 | loss: 0.0489938\n",
      "\tspeed: 0.0710s/iter; left time: 762.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:16.30s\n",
      "Steps: 223 | Train Loss: 0.0494290 Vali Loss: 0.0582654 Test Loss: 0.0635235\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0485045\n",
      "\tspeed: 0.1520s/iter; left time: 1611.6611s\n",
      "\titers: 200, epoch: 53 | loss: 0.0497875\n",
      "\tspeed: 0.0705s/iter; left time: 740.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:16.20s\n",
      "Steps: 223 | Train Loss: 0.0493384 Vali Loss: 0.0580103 Test Loss: 0.0632931\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0507777\n",
      "\tspeed: 0.1550s/iter; left time: 1609.1129s\n",
      "\titers: 200, epoch: 54 | loss: 0.0517692\n",
      "\tspeed: 0.0707s/iter; left time: 726.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:16.33s\n",
      "Steps: 223 | Train Loss: 0.0493122 Vali Loss: 0.0579950 Test Loss: 0.0633246\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0501293\n",
      "\tspeed: 0.1523s/iter; left time: 1547.0078s\n",
      "\titers: 200, epoch: 55 | loss: 0.0546685\n",
      "\tspeed: 0.0697s/iter; left time: 700.6127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.94s\n",
      "Steps: 223 | Train Loss: 0.0492113 Vali Loss: 0.0579659 Test Loss: 0.0632678\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01167220901697874, rmse:0.10803800076246262, mae:0.06328491121530533, rse:0.4168075919151306\n",
      "Intermediate time for FR and pred_len 24: 00h:51m:08.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2879077\n",
      "\tspeed: 0.1098s/iter; left time: 2426.7399s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536774\n",
      "\tspeed: 0.0866s/iter; left time: 1905.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.56s\n",
      "Steps: 222 | Train Loss: 0.2945667 Vali Loss: 0.1999623 Test Loss: 0.2042363\n",
      "Validation loss decreased (inf --> 0.199962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1517449\n",
      "\tspeed: 0.2638s/iter; left time: 5770.6677s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126845\n",
      "\tspeed: 0.0859s/iter; left time: 1870.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.41s\n",
      "Steps: 222 | Train Loss: 0.1530619 Vali Loss: 0.1144468 Test Loss: 0.1329957\n",
      "Validation loss decreased (0.199962 --> 0.114447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0986583\n",
      "\tspeed: 0.2552s/iter; left time: 5526.0172s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901116\n",
      "\tspeed: 0.0850s/iter; left time: 1832.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:19.31s\n",
      "Steps: 222 | Train Loss: 0.0982979 Vali Loss: 0.1058146 Test Loss: 0.1244993\n",
      "Validation loss decreased (0.114447 --> 0.105815).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859649\n",
      "\tspeed: 0.2547s/iter; left time: 5459.4613s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809683\n",
      "\tspeed: 0.0849s/iter; left time: 1812.2033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:19.21s\n",
      "Steps: 222 | Train Loss: 0.0850114 Vali Loss: 0.0983728 Test Loss: 0.1163349\n",
      "Validation loss decreased (0.105815 --> 0.098373).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0792870\n",
      "\tspeed: 0.2563s/iter; left time: 5436.4884s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783465\n",
      "\tspeed: 0.0866s/iter; left time: 1827.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 222 | Train Loss: 0.0787314 Vali Loss: 0.0924403 Test Loss: 0.1093581\n",
      "Validation loss decreased (0.098373 --> 0.092440).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0724203\n",
      "\tspeed: 0.2551s/iter; left time: 5355.2512s\n",
      "\titers: 200, epoch: 6 | loss: 0.0687408\n",
      "\tspeed: 0.0842s/iter; left time: 1759.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.23s\n",
      "Steps: 222 | Train Loss: 0.0742491 Vali Loss: 0.0907336 Test Loss: 0.1093434\n",
      "Validation loss decreased (0.092440 --> 0.090734).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0711499\n",
      "\tspeed: 0.2485s/iter; left time: 5160.9370s\n",
      "\titers: 200, epoch: 7 | loss: 0.0710708\n",
      "\tspeed: 0.0852s/iter; left time: 1760.5694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:19.48s\n",
      "Steps: 222 | Train Loss: 0.0724132 Vali Loss: 0.0903843 Test Loss: 0.1059529\n",
      "Validation loss decreased (0.090734 --> 0.090384).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724414\n",
      "\tspeed: 0.2405s/iter; left time: 4942.2156s\n",
      "\titers: 200, epoch: 8 | loss: 0.0719910\n",
      "\tspeed: 0.0829s/iter; left time: 1694.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.92s\n",
      "Steps: 222 | Train Loss: 0.0707222 Vali Loss: 0.0889377 Test Loss: 0.1062376\n",
      "Validation loss decreased (0.090384 --> 0.088938).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0693138\n",
      "\tspeed: 0.2475s/iter; left time: 5029.7507s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727626\n",
      "\tspeed: 0.0821s/iter; left time: 1661.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.89s\n",
      "Steps: 222 | Train Loss: 0.0695257 Vali Loss: 0.0863636 Test Loss: 0.1037186\n",
      "Validation loss decreased (0.088938 --> 0.086364).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667829\n",
      "\tspeed: 0.2513s/iter; left time: 5050.9853s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720462\n",
      "\tspeed: 0.0851s/iter; left time: 1701.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 222 | Train Loss: 0.0682772 Vali Loss: 0.0854409 Test Loss: 0.1014704\n",
      "Validation loss decreased (0.086364 --> 0.085441).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664678\n",
      "\tspeed: 0.2485s/iter; left time: 4939.9551s\n",
      "\titers: 200, epoch: 11 | loss: 0.0645685\n",
      "\tspeed: 0.0836s/iter; left time: 1653.5932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:19.08s\n",
      "Steps: 222 | Train Loss: 0.0675065 Vali Loss: 0.0842289 Test Loss: 0.1000871\n",
      "Validation loss decreased (0.085441 --> 0.084229).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683544\n",
      "\tspeed: 0.2493s/iter; left time: 4901.5911s\n",
      "\titers: 200, epoch: 12 | loss: 0.0679531\n",
      "\tspeed: 0.0842s/iter; left time: 1647.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:19.38s\n",
      "Steps: 222 | Train Loss: 0.0667692 Vali Loss: 0.0843801 Test Loss: 0.0999205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0639349\n",
      "\tspeed: 0.2496s/iter; left time: 4851.7061s\n",
      "\titers: 200, epoch: 13 | loss: 0.0661275\n",
      "\tspeed: 0.0844s/iter; left time: 1631.5322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:19.28s\n",
      "Steps: 222 | Train Loss: 0.0665508 Vali Loss: 0.0831838 Test Loss: 0.0993018\n",
      "Validation loss decreased (0.084229 --> 0.083184).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0654968\n",
      "\tspeed: 0.2516s/iter; left time: 4834.6595s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667286\n",
      "\tspeed: 0.0844s/iter; left time: 1614.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:19.36s\n",
      "Steps: 222 | Train Loss: 0.0661709 Vali Loss: 0.0834952 Test Loss: 0.0989341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0673839\n",
      "\tspeed: 0.2545s/iter; left time: 4833.0254s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644995\n",
      "\tspeed: 0.0860s/iter; left time: 1624.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:19.69s\n",
      "Steps: 222 | Train Loss: 0.0660211 Vali Loss: 0.0832899 Test Loss: 0.0984953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0665912\n",
      "\tspeed: 0.2501s/iter; left time: 4695.0924s\n",
      "\titers: 200, epoch: 16 | loss: 0.0643072\n",
      "\tspeed: 0.0848s/iter; left time: 1582.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.27s\n",
      "Steps: 222 | Train Loss: 0.0653587 Vali Loss: 0.0835787 Test Loss: 0.0986860\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0651170\n",
      "\tspeed: 0.2498s/iter; left time: 4634.1000s\n",
      "\titers: 200, epoch: 17 | loss: 0.0672310\n",
      "\tspeed: 0.0854s/iter; left time: 1574.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:19.29s\n",
      "Steps: 222 | Train Loss: 0.0649874 Vali Loss: 0.0817120 Test Loss: 0.0971271\n",
      "Validation loss decreased (0.083184 --> 0.081712).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0646221\n",
      "\tspeed: 0.2513s/iter; left time: 4605.5399s\n",
      "\titers: 200, epoch: 18 | loss: 0.0646976\n",
      "\tspeed: 0.0856s/iter; left time: 1560.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:19.36s\n",
      "Steps: 222 | Train Loss: 0.0656343 Vali Loss: 0.0824961 Test Loss: 0.0985582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0649461\n",
      "\tspeed: 0.2535s/iter; left time: 4589.3802s\n",
      "\titers: 200, epoch: 19 | loss: 0.0673964\n",
      "\tspeed: 0.0836s/iter; left time: 1505.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:19.37s\n",
      "Steps: 222 | Train Loss: 0.0647440 Vali Loss: 0.0816682 Test Loss: 0.0975457\n",
      "Validation loss decreased (0.081712 --> 0.081668).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0595958\n",
      "\tspeed: 0.2428s/iter; left time: 4341.3624s\n",
      "\titers: 200, epoch: 20 | loss: 0.0686415\n",
      "\tspeed: 0.0852s/iter; left time: 1514.4431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:19.31s\n",
      "Steps: 222 | Train Loss: 0.0646993 Vali Loss: 0.0813476 Test Loss: 0.0971504\n",
      "Validation loss decreased (0.081668 --> 0.081348).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0634930\n",
      "\tspeed: 0.2543s/iter; left time: 4492.0493s\n",
      "\titers: 200, epoch: 21 | loss: 0.0674322\n",
      "\tspeed: 0.0850s/iter; left time: 1492.0228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:19.33s\n",
      "Steps: 222 | Train Loss: 0.0646301 Vali Loss: 0.0811480 Test Loss: 0.0973621\n",
      "Validation loss decreased (0.081348 --> 0.081148).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0632882\n",
      "\tspeed: 0.2508s/iter; left time: 4373.8126s\n",
      "\titers: 200, epoch: 22 | loss: 0.0634241\n",
      "\tspeed: 0.0842s/iter; left time: 1459.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:19.19s\n",
      "Steps: 222 | Train Loss: 0.0643982 Vali Loss: 0.0808697 Test Loss: 0.0968169\n",
      "Validation loss decreased (0.081148 --> 0.080870).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0646736\n",
      "\tspeed: 0.2491s/iter; left time: 4289.5998s\n",
      "\titers: 200, epoch: 23 | loss: 0.0621610\n",
      "\tspeed: 0.0867s/iter; left time: 1483.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:19.43s\n",
      "Steps: 222 | Train Loss: 0.0639984 Vali Loss: 0.0807103 Test Loss: 0.0965630\n",
      "Validation loss decreased (0.080870 --> 0.080710).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0634157\n",
      "\tspeed: 0.2525s/iter; left time: 4292.0850s\n",
      "\titers: 200, epoch: 24 | loss: 0.0622353\n",
      "\tspeed: 0.0862s/iter; left time: 1455.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 222 | Train Loss: 0.0637827 Vali Loss: 0.0809653 Test Loss: 0.0965855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0649769\n",
      "\tspeed: 0.2415s/iter; left time: 4050.6289s\n",
      "\titers: 200, epoch: 25 | loss: 0.0649977\n",
      "\tspeed: 0.0849s/iter; left time: 1414.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:19.43s\n",
      "Steps: 222 | Train Loss: 0.0637167 Vali Loss: 0.0807689 Test Loss: 0.0968552\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0650866\n",
      "\tspeed: 0.2391s/iter; left time: 3958.1199s\n",
      "\titers: 200, epoch: 26 | loss: 0.0649061\n",
      "\tspeed: 0.0859s/iter; left time: 1412.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:19.18s\n",
      "Steps: 222 | Train Loss: 0.0637211 Vali Loss: 0.0803797 Test Loss: 0.0965875\n",
      "Validation loss decreased (0.080710 --> 0.080380).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680842\n",
      "\tspeed: 0.2479s/iter; left time: 4047.6930s\n",
      "\titers: 200, epoch: 27 | loss: 0.0622084\n",
      "\tspeed: 0.0864s/iter; left time: 1402.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:19.49s\n",
      "Steps: 222 | Train Loss: 0.0635259 Vali Loss: 0.0804601 Test Loss: 0.0964582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0623048\n",
      "\tspeed: 0.2448s/iter; left time: 3942.4400s\n",
      "\titers: 200, epoch: 28 | loss: 0.0651492\n",
      "\tspeed: 0.0858s/iter; left time: 1374.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:19.27s\n",
      "Steps: 222 | Train Loss: 0.0635082 Vali Loss: 0.0800556 Test Loss: 0.0965651\n",
      "Validation loss decreased (0.080380 --> 0.080056).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0660916\n",
      "\tspeed: 0.2536s/iter; left time: 4028.9946s\n",
      "\titers: 200, epoch: 29 | loss: 0.0665524\n",
      "\tspeed: 0.0844s/iter; left time: 1332.2836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:19.04s\n",
      "Steps: 222 | Train Loss: 0.0635274 Vali Loss: 0.0805412 Test Loss: 0.0966226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0637945\n",
      "\tspeed: 0.2502s/iter; left time: 3919.3982s\n",
      "\titers: 200, epoch: 30 | loss: 0.0648117\n",
      "\tspeed: 0.0846s/iter; left time: 1317.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:19.10s\n",
      "Steps: 222 | Train Loss: 0.0633962 Vali Loss: 0.0805329 Test Loss: 0.0972186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0612445\n",
      "\tspeed: 0.2417s/iter; left time: 3732.3902s\n",
      "\titers: 200, epoch: 31 | loss: 0.0629811\n",
      "\tspeed: 0.0861s/iter; left time: 1320.6767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:19.23s\n",
      "Steps: 222 | Train Loss: 0.0633263 Vali Loss: 0.0804460 Test Loss: 0.0970066\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0600494\n",
      "\tspeed: 0.2448s/iter; left time: 3726.0780s\n",
      "\titers: 200, epoch: 32 | loss: 0.0630762\n",
      "\tspeed: 0.0855s/iter; left time: 1292.5666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:19.54s\n",
      "Steps: 222 | Train Loss: 0.0633164 Vali Loss: 0.0808801 Test Loss: 0.0975151\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0622885\n",
      "\tspeed: 0.2474s/iter; left time: 3709.5307s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604800\n",
      "\tspeed: 0.0864s/iter; left time: 1286.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:19.80s\n",
      "Steps: 222 | Train Loss: 0.0631201 Vali Loss: 0.0805370 Test Loss: 0.0970943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0604350\n",
      "\tspeed: 0.2487s/iter; left time: 3674.4161s\n",
      "\titers: 200, epoch: 34 | loss: 0.0657234\n",
      "\tspeed: 0.0870s/iter; left time: 1277.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:19.88s\n",
      "Steps: 222 | Train Loss: 0.0630897 Vali Loss: 0.0806140 Test Loss: 0.0972530\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0624515\n",
      "\tspeed: 0.2526s/iter; left time: 3676.1769s\n",
      "\titers: 200, epoch: 35 | loss: 0.0626663\n",
      "\tspeed: 0.0843s/iter; left time: 1217.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:19.49s\n",
      "Steps: 222 | Train Loss: 0.0635543 Vali Loss: 0.0808041 Test Loss: 0.0973904\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0663741\n",
      "\tspeed: 0.2473s/iter; left time: 3543.9690s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615616\n",
      "\tspeed: 0.0825s/iter; left time: 1174.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.99s\n",
      "Steps: 222 | Train Loss: 0.0631562 Vali Loss: 0.0810307 Test Loss: 0.0978927\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628784\n",
      "\tspeed: 0.2500s/iter; left time: 3527.2716s\n",
      "\titers: 200, epoch: 37 | loss: 0.0649628\n",
      "\tspeed: 0.0846s/iter; left time: 1185.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:19.38s\n",
      "Steps: 222 | Train Loss: 0.0631745 Vali Loss: 0.0809631 Test Loss: 0.0976012\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0649421\n",
      "\tspeed: 0.2556s/iter; left time: 3549.5112s\n",
      "\titers: 200, epoch: 38 | loss: 0.0604499\n",
      "\tspeed: 0.0851s/iter; left time: 1173.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:19.36s\n",
      "Steps: 222 | Train Loss: 0.0631466 Vali Loss: 0.0805430 Test Loss: 0.0973679\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.026984842494130135, rmse:0.16427063941955566, mae:0.0965651348233223, rse:0.6354424953460693\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2884555\n",
      "\tspeed: 0.0903s/iter; left time: 1994.7783s\n",
      "\titers: 200, epoch: 1 | loss: 0.2515912\n",
      "\tspeed: 0.0865s/iter; left time: 1903.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.42s\n",
      "Steps: 222 | Train Loss: 0.2928007 Vali Loss: 0.2012593 Test Loss: 0.2051862\n",
      "Validation loss decreased (inf --> 0.201259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507656\n",
      "\tspeed: 0.2530s/iter; left time: 5536.1365s\n",
      "\titers: 200, epoch: 2 | loss: 0.1062414\n",
      "\tspeed: 0.0841s/iter; left time: 1832.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.07s\n",
      "Steps: 222 | Train Loss: 0.1519969 Vali Loss: 0.1104150 Test Loss: 0.1295835\n",
      "Validation loss decreased (0.201259 --> 0.110415).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0988160\n",
      "\tspeed: 0.2486s/iter; left time: 5384.9092s\n",
      "\titers: 200, epoch: 3 | loss: 0.0928188\n",
      "\tspeed: 0.0858s/iter; left time: 1849.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:19.38s\n",
      "Steps: 222 | Train Loss: 0.0984511 Vali Loss: 0.1058251 Test Loss: 0.1256358\n",
      "Validation loss decreased (0.110415 --> 0.105825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0828634\n",
      "\tspeed: 0.2590s/iter; left time: 5550.7907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801091\n",
      "\tspeed: 0.0869s/iter; left time: 1854.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:20.38s\n",
      "Steps: 222 | Train Loss: 0.0837553 Vali Loss: 0.0936643 Test Loss: 0.1105544\n",
      "Validation loss decreased (0.105825 --> 0.093664).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0762430\n",
      "\tspeed: 0.2544s/iter; left time: 5396.4141s\n",
      "\titers: 200, epoch: 5 | loss: 0.0739871\n",
      "\tspeed: 0.0861s/iter; left time: 1818.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.60s\n",
      "Steps: 222 | Train Loss: 0.0763583 Vali Loss: 0.0917374 Test Loss: 0.1079276\n",
      "Validation loss decreased (0.093664 --> 0.091737).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0717950\n",
      "\tspeed: 0.2547s/iter; left time: 5347.2055s\n",
      "\titers: 200, epoch: 6 | loss: 0.0660969\n",
      "\tspeed: 0.0863s/iter; left time: 1803.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.52s\n",
      "Steps: 222 | Train Loss: 0.0730319 Vali Loss: 0.0892733 Test Loss: 0.1038926\n",
      "Validation loss decreased (0.091737 --> 0.089273).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741398\n",
      "\tspeed: 0.2509s/iter; left time: 5211.2858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0675239\n",
      "\tspeed: 0.0859s/iter; left time: 1775.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:19.63s\n",
      "Steps: 222 | Train Loss: 0.0715143 Vali Loss: 0.0846809 Test Loss: 0.0987833\n",
      "Validation loss decreased (0.089273 --> 0.084681).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0682856\n",
      "\tspeed: 0.2510s/iter; left time: 5158.1856s\n",
      "\titers: 200, epoch: 8 | loss: 0.0701906\n",
      "\tspeed: 0.0849s/iter; left time: 1735.4865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:19.27s\n",
      "Steps: 222 | Train Loss: 0.0694897 Vali Loss: 0.0841163 Test Loss: 0.0980135\n",
      "Validation loss decreased (0.084681 --> 0.084116).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0687545\n",
      "\tspeed: 0.2550s/iter; left time: 5183.0059s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665317\n",
      "\tspeed: 0.0837s/iter; left time: 1692.1858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:19.20s\n",
      "Steps: 222 | Train Loss: 0.0688630 Vali Loss: 0.0853579 Test Loss: 0.0999867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687118\n",
      "\tspeed: 0.2525s/iter; left time: 5075.4098s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683046\n",
      "\tspeed: 0.0816s/iter; left time: 1631.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 222 | Train Loss: 0.0678641 Vali Loss: 0.0826184 Test Loss: 0.0973910\n",
      "Validation loss decreased (0.084116 --> 0.082618).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0658350\n",
      "\tspeed: 0.2516s/iter; left time: 5002.2767s\n",
      "\titers: 200, epoch: 11 | loss: 0.0685137\n",
      "\tspeed: 0.0835s/iter; left time: 1652.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:19.19s\n",
      "Steps: 222 | Train Loss: 0.0672449 Vali Loss: 0.0812558 Test Loss: 0.0961218\n",
      "Validation loss decreased (0.082618 --> 0.081256).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0700857\n",
      "\tspeed: 0.2521s/iter; left time: 4956.1975s\n",
      "\titers: 200, epoch: 12 | loss: 0.0615211\n",
      "\tspeed: 0.0868s/iter; left time: 1697.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:19.18s\n",
      "Steps: 222 | Train Loss: 0.0663632 Vali Loss: 0.0813143 Test Loss: 0.0966332\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0635508\n",
      "\tspeed: 0.2468s/iter; left time: 4797.7078s\n",
      "\titers: 200, epoch: 13 | loss: 0.0653997\n",
      "\tspeed: 0.0831s/iter; left time: 1607.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:19.10s\n",
      "Steps: 222 | Train Loss: 0.0661197 Vali Loss: 0.0806379 Test Loss: 0.0962213\n",
      "Validation loss decreased (0.081256 --> 0.080638).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661935\n",
      "\tspeed: 0.2536s/iter; left time: 4872.7180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0624773\n",
      "\tspeed: 0.0850s/iter; left time: 1623.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:19.20s\n",
      "Steps: 222 | Train Loss: 0.0654672 Vali Loss: 0.0810033 Test Loss: 0.0965536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0693874\n",
      "\tspeed: 0.2489s/iter; left time: 4728.1110s\n",
      "\titers: 200, epoch: 15 | loss: 0.0645738\n",
      "\tspeed: 0.0855s/iter; left time: 1614.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:19.26s\n",
      "Steps: 222 | Train Loss: 0.0652295 Vali Loss: 0.0804608 Test Loss: 0.0964908\n",
      "Validation loss decreased (0.080638 --> 0.080461).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0617401\n",
      "\tspeed: 0.2474s/iter; left time: 4644.0527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0648678\n",
      "\tspeed: 0.0835s/iter; left time: 1558.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.06s\n",
      "Steps: 222 | Train Loss: 0.0646637 Vali Loss: 0.0804724 Test Loss: 0.0965819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0664340\n",
      "\tspeed: 0.2452s/iter; left time: 4548.6115s\n",
      "\titers: 200, epoch: 17 | loss: 0.0654019\n",
      "\tspeed: 0.0826s/iter; left time: 1524.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.80s\n",
      "Steps: 222 | Train Loss: 0.0646429 Vali Loss: 0.0802410 Test Loss: 0.0962920\n",
      "Validation loss decreased (0.080461 --> 0.080241).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608304\n",
      "\tspeed: 0.2445s/iter; left time: 4480.5519s\n",
      "\titers: 200, epoch: 18 | loss: 0.0636867\n",
      "\tspeed: 0.0826s/iter; left time: 1506.0051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.78s\n",
      "Steps: 222 | Train Loss: 0.0642401 Vali Loss: 0.0807617 Test Loss: 0.0972271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0692427\n",
      "\tspeed: 0.2464s/iter; left time: 4460.5775s\n",
      "\titers: 200, epoch: 19 | loss: 0.0622067\n",
      "\tspeed: 0.0826s/iter; left time: 1487.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.93s\n",
      "Steps: 222 | Train Loss: 0.0638610 Vali Loss: 0.0800573 Test Loss: 0.0970957\n",
      "Validation loss decreased (0.080241 --> 0.080057).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0632182\n",
      "\tspeed: 0.2399s/iter; left time: 4290.5620s\n",
      "\titers: 200, epoch: 20 | loss: 0.0613247\n",
      "\tspeed: 0.0823s/iter; left time: 1463.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.79s\n",
      "Steps: 222 | Train Loss: 0.0636287 Vali Loss: 0.0808486 Test Loss: 0.0981857\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0686995\n",
      "\tspeed: 0.2412s/iter; left time: 4259.3221s\n",
      "\titers: 200, epoch: 21 | loss: 0.0633804\n",
      "\tspeed: 0.0795s/iter; left time: 1396.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 222 | Train Loss: 0.0636152 Vali Loss: 0.0817497 Test Loss: 0.0989539\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0644663\n",
      "\tspeed: 0.2355s/iter; left time: 4107.1138s\n",
      "\titers: 200, epoch: 22 | loss: 0.0665781\n",
      "\tspeed: 0.0821s/iter; left time: 1424.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 222 | Train Loss: 0.0636397 Vali Loss: 0.0809559 Test Loss: 0.0979176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0670606\n",
      "\tspeed: 0.2368s/iter; left time: 4077.5663s\n",
      "\titers: 200, epoch: 23 | loss: 0.0660990\n",
      "\tspeed: 0.0816s/iter; left time: 1397.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.60s\n",
      "Steps: 222 | Train Loss: 0.0631059 Vali Loss: 0.0799184 Test Loss: 0.0976490\n",
      "Validation loss decreased (0.080057 --> 0.079918).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0658079\n",
      "\tspeed: 0.2382s/iter; left time: 4047.4637s\n",
      "\titers: 200, epoch: 24 | loss: 0.0617544\n",
      "\tspeed: 0.0830s/iter; left time: 1401.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.86s\n",
      "Steps: 222 | Train Loss: 0.0629237 Vali Loss: 0.0806069 Test Loss: 0.0982282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0591250\n",
      "\tspeed: 0.2392s/iter; left time: 4012.8796s\n",
      "\titers: 200, epoch: 25 | loss: 0.0634996\n",
      "\tspeed: 0.0856s/iter; left time: 1427.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:19.10s\n",
      "Steps: 222 | Train Loss: 0.0628988 Vali Loss: 0.0804751 Test Loss: 0.0982895\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625191\n",
      "\tspeed: 0.2391s/iter; left time: 3956.6971s\n",
      "\titers: 200, epoch: 26 | loss: 0.0626373\n",
      "\tspeed: 0.0828s/iter; left time: 1362.3838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.86s\n",
      "Steps: 222 | Train Loss: 0.0627429 Vali Loss: 0.0803639 Test Loss: 0.0987890\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0627019\n",
      "\tspeed: 0.2396s/iter; left time: 3912.1901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0642798\n",
      "\tspeed: 0.0831s/iter; left time: 1348.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.73s\n",
      "Steps: 222 | Train Loss: 0.0627014 Vali Loss: 0.0807828 Test Loss: 0.0991969\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0609293\n",
      "\tspeed: 0.2393s/iter; left time: 3854.9813s\n",
      "\titers: 200, epoch: 28 | loss: 0.0638627\n",
      "\tspeed: 0.0825s/iter; left time: 1320.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0624553 Vali Loss: 0.0810489 Test Loss: 0.0997993\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0624598\n",
      "\tspeed: 0.2526s/iter; left time: 4012.5739s\n",
      "\titers: 200, epoch: 29 | loss: 0.0639588\n",
      "\tspeed: 0.0873s/iter; left time: 1377.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:20.39s\n",
      "Steps: 222 | Train Loss: 0.0624276 Vali Loss: 0.0805390 Test Loss: 0.0991499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0602242\n",
      "\tspeed: 0.2501s/iter; left time: 3917.8772s\n",
      "\titers: 200, epoch: 30 | loss: 0.0640333\n",
      "\tspeed: 0.0861s/iter; left time: 1340.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:19.69s\n",
      "Steps: 222 | Train Loss: 0.0624375 Vali Loss: 0.0804124 Test Loss: 0.0991313\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0595964\n",
      "\tspeed: 0.2527s/iter; left time: 3901.3431s\n",
      "\titers: 200, epoch: 31 | loss: 0.0575724\n",
      "\tspeed: 0.0813s/iter; left time: 1247.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.62s\n",
      "Steps: 222 | Train Loss: 0.0623329 Vali Loss: 0.0805097 Test Loss: 0.0990925\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0669394\n",
      "\tspeed: 0.2356s/iter; left time: 3585.5987s\n",
      "\titers: 200, epoch: 32 | loss: 0.0647942\n",
      "\tspeed: 0.0813s/iter; left time: 1229.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0623837 Vali Loss: 0.0806511 Test Loss: 0.0992537\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0619551\n",
      "\tspeed: 0.2371s/iter; left time: 3555.8056s\n",
      "\titers: 200, epoch: 33 | loss: 0.0631624\n",
      "\tspeed: 0.0816s/iter; left time: 1215.8337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.0621965 Vali Loss: 0.0805613 Test Loss: 0.0994245\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02770662121474743, rmse:0.1664530634880066, mae:0.09764896333217621, rse:0.6438847184181213\n",
      "Intermediate time for FR and pred_len 96: 00h:39m:42.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2886142\n",
      "\tspeed: 0.1112s/iter; left time: 2456.5553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2523073\n",
      "\tspeed: 0.0804s/iter; left time: 1767.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.95s\n",
      "Steps: 222 | Train Loss: 0.2912061 Vali Loss: 0.1999100 Test Loss: 0.2026316\n",
      "Validation loss decreased (inf --> 0.199910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471945\n",
      "\tspeed: 0.2542s/iter; left time: 5562.5467s\n",
      "\titers: 200, epoch: 2 | loss: 0.1077524\n",
      "\tspeed: 0.0815s/iter; left time: 1774.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1477627 Vali Loss: 0.1142867 Test Loss: 0.1310681\n",
      "Validation loss decreased (0.199910 --> 0.114287).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0968542\n",
      "\tspeed: 0.2423s/iter; left time: 5247.7186s\n",
      "\titers: 200, epoch: 3 | loss: 0.0937921\n",
      "\tspeed: 0.0845s/iter; left time: 1821.5253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.82s\n",
      "Steps: 222 | Train Loss: 0.0988190 Vali Loss: 0.1067298 Test Loss: 0.1220535\n",
      "Validation loss decreased (0.114287 --> 0.106730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856441\n",
      "\tspeed: 0.2463s/iter; left time: 5280.1697s\n",
      "\titers: 200, epoch: 4 | loss: 0.0793746\n",
      "\tspeed: 0.0825s/iter; left time: 1759.1799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.86s\n",
      "Steps: 222 | Train Loss: 0.0859942 Vali Loss: 0.0995933 Test Loss: 0.1154714\n",
      "Validation loss decreased (0.106730 --> 0.099593).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0762595\n",
      "\tspeed: 0.2512s/iter; left time: 5328.5998s\n",
      "\titers: 200, epoch: 5 | loss: 0.0797842\n",
      "\tspeed: 0.0856s/iter; left time: 1807.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.59s\n",
      "Steps: 222 | Train Loss: 0.0802908 Vali Loss: 0.0956773 Test Loss: 0.1126026\n",
      "Validation loss decreased (0.099593 --> 0.095677).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0760082\n",
      "\tspeed: 0.2684s/iter; left time: 5633.9608s\n",
      "\titers: 200, epoch: 6 | loss: 0.0724723\n",
      "\tspeed: 0.0792s/iter; left time: 1654.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.0759902 Vali Loss: 0.0911552 Test Loss: 0.1075190\n",
      "Validation loss decreased (0.095677 --> 0.091155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0699345\n",
      "\tspeed: 0.2389s/iter; left time: 4961.5147s\n",
      "\titers: 200, epoch: 7 | loss: 0.0748539\n",
      "\tspeed: 0.0807s/iter; left time: 1668.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0745819 Vali Loss: 0.0911195 Test Loss: 0.1088387\n",
      "Validation loss decreased (0.091155 --> 0.091119).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725604\n",
      "\tspeed: 0.2426s/iter; left time: 4984.8000s\n",
      "\titers: 200, epoch: 8 | loss: 0.0735395\n",
      "\tspeed: 0.0804s/iter; left time: 1644.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.0730181 Vali Loss: 0.0876682 Test Loss: 0.1041322\n",
      "Validation loss decreased (0.091119 --> 0.087668).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0670128\n",
      "\tspeed: 0.2405s/iter; left time: 4888.3541s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704023\n",
      "\tspeed: 0.0800s/iter; left time: 1618.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 222 | Train Loss: 0.0718475 Vali Loss: 0.0897455 Test Loss: 0.1051270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698987\n",
      "\tspeed: 0.2394s/iter; left time: 4812.8773s\n",
      "\titers: 200, epoch: 10 | loss: 0.0718183\n",
      "\tspeed: 0.0810s/iter; left time: 1620.4641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0714555 Vali Loss: 0.0873747 Test Loss: 0.1035966\n",
      "Validation loss decreased (0.087668 --> 0.087375).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678614\n",
      "\tspeed: 0.2390s/iter; left time: 4751.8201s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764401\n",
      "\tspeed: 0.0822s/iter; left time: 1626.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0703548 Vali Loss: 0.0866943 Test Loss: 0.1036685\n",
      "Validation loss decreased (0.087375 --> 0.086694).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0684359\n",
      "\tspeed: 0.2351s/iter; left time: 4621.5608s\n",
      "\titers: 200, epoch: 12 | loss: 0.0701398\n",
      "\tspeed: 0.0794s/iter; left time: 1552.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0697691 Vali Loss: 0.0867025 Test Loss: 0.1038690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0694627\n",
      "\tspeed: 0.2351s/iter; left time: 4569.8103s\n",
      "\titers: 200, epoch: 13 | loss: 0.0665557\n",
      "\tspeed: 0.0823s/iter; left time: 1590.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.49s\n",
      "Steps: 222 | Train Loss: 0.0691775 Vali Loss: 0.0862938 Test Loss: 0.1036404\n",
      "Validation loss decreased (0.086694 --> 0.086294).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0692555\n",
      "\tspeed: 0.2300s/iter; left time: 4420.3773s\n",
      "\titers: 200, epoch: 14 | loss: 0.0709757\n",
      "\tspeed: 0.0781s/iter; left time: 1493.7859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.01s\n",
      "Steps: 222 | Train Loss: 0.0690052 Vali Loss: 0.0862457 Test Loss: 0.1038813\n",
      "Validation loss decreased (0.086294 --> 0.086246).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0681313\n",
      "\tspeed: 0.2356s/iter; left time: 4473.9055s\n",
      "\titers: 200, epoch: 15 | loss: 0.0656444\n",
      "\tspeed: 0.0825s/iter; left time: 1558.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0684217 Vali Loss: 0.0860219 Test Loss: 0.1037708\n",
      "Validation loss decreased (0.086246 --> 0.086022).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713103\n",
      "\tspeed: 0.2344s/iter; left time: 4399.2986s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666438\n",
      "\tspeed: 0.0804s/iter; left time: 1500.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0681682 Vali Loss: 0.0857815 Test Loss: 0.1031001\n",
      "Validation loss decreased (0.086022 --> 0.085782).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0639305\n",
      "\tspeed: 0.2307s/iter; left time: 4279.8302s\n",
      "\titers: 200, epoch: 17 | loss: 0.0667131\n",
      "\tspeed: 0.0770s/iter; left time: 1420.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 222 | Train Loss: 0.0677025 Vali Loss: 0.0868976 Test Loss: 0.1050218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0709322\n",
      "\tspeed: 0.2295s/iter; left time: 4206.0663s\n",
      "\titers: 200, epoch: 18 | loss: 0.0638300\n",
      "\tspeed: 0.0780s/iter; left time: 1421.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:17.74s\n",
      "Steps: 222 | Train Loss: 0.0676011 Vali Loss: 0.0857694 Test Loss: 0.1044954\n",
      "Validation loss decreased (0.085782 --> 0.085769).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679007\n",
      "\tspeed: 0.2286s/iter; left time: 4138.0976s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676090\n",
      "\tspeed: 0.0786s/iter; left time: 1415.3967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:17.89s\n",
      "Steps: 222 | Train Loss: 0.0672339 Vali Loss: 0.0853768 Test Loss: 0.1037475\n",
      "Validation loss decreased (0.085769 --> 0.085377).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650989\n",
      "\tspeed: 0.2338s/iter; left time: 4180.2523s\n",
      "\titers: 200, epoch: 20 | loss: 0.0749001\n",
      "\tspeed: 0.0832s/iter; left time: 1478.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.81s\n",
      "Steps: 222 | Train Loss: 0.0671047 Vali Loss: 0.0864768 Test Loss: 0.1046676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0641726\n",
      "\tspeed: 0.2353s/iter; left time: 4156.0553s\n",
      "\titers: 200, epoch: 21 | loss: 0.0691315\n",
      "\tspeed: 0.0814s/iter; left time: 1430.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.0668174 Vali Loss: 0.0858255 Test Loss: 0.1049515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0647276\n",
      "\tspeed: 0.2313s/iter; left time: 4033.2577s\n",
      "\titers: 200, epoch: 22 | loss: 0.0668329\n",
      "\tspeed: 0.0785s/iter; left time: 1360.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:17.86s\n",
      "Steps: 222 | Train Loss: 0.0667132 Vali Loss: 0.0855873 Test Loss: 0.1048255\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0673499\n",
      "\tspeed: 0.2308s/iter; left time: 3973.5496s\n",
      "\titers: 200, epoch: 23 | loss: 0.0679614\n",
      "\tspeed: 0.0802s/iter; left time: 1373.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0665204 Vali Loss: 0.0852325 Test Loss: 0.1044564\n",
      "Validation loss decreased (0.085377 --> 0.085233).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0677751\n",
      "\tspeed: 0.2391s/iter; left time: 4063.0436s\n",
      "\titers: 200, epoch: 24 | loss: 0.0664155\n",
      "\tspeed: 0.0803s/iter; left time: 1355.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.67s\n",
      "Steps: 222 | Train Loss: 0.0662715 Vali Loss: 0.0859191 Test Loss: 0.1051862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0653947\n",
      "\tspeed: 0.2386s/iter; left time: 4001.9472s\n",
      "\titers: 200, epoch: 25 | loss: 0.0666286\n",
      "\tspeed: 0.0836s/iter; left time: 1393.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.90s\n",
      "Steps: 222 | Train Loss: 0.0662451 Vali Loss: 0.0859784 Test Loss: 0.1052492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671309\n",
      "\tspeed: 0.2439s/iter; left time: 4037.3366s\n",
      "\titers: 200, epoch: 26 | loss: 0.0699095\n",
      "\tspeed: 0.0802s/iter; left time: 1319.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.0660618 Vali Loss: 0.0857552 Test Loss: 0.1053803\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0714878\n",
      "\tspeed: 0.2314s/iter; left time: 3777.9069s\n",
      "\titers: 200, epoch: 27 | loss: 0.0679223\n",
      "\tspeed: 0.0793s/iter; left time: 1287.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0659121 Vali Loss: 0.0861707 Test Loss: 0.1057820\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662814\n",
      "\tspeed: 0.2411s/iter; left time: 3883.7501s\n",
      "\titers: 200, epoch: 28 | loss: 0.0668352\n",
      "\tspeed: 0.0814s/iter; left time: 1302.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0657838 Vali Loss: 0.0856395 Test Loss: 0.1051730\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0632342\n",
      "\tspeed: 0.2409s/iter; left time: 3827.2448s\n",
      "\titers: 200, epoch: 29 | loss: 0.0632894\n",
      "\tspeed: 0.0831s/iter; left time: 1312.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:19.10s\n",
      "Steps: 222 | Train Loss: 0.0657288 Vali Loss: 0.0856674 Test Loss: 0.1050114\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0621474\n",
      "\tspeed: 0.2443s/iter; left time: 3825.7124s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633730\n",
      "\tspeed: 0.0861s/iter; left time: 1339.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:19.36s\n",
      "Steps: 222 | Train Loss: 0.0656282 Vali Loss: 0.0853675 Test Loss: 0.1051136\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0666002\n",
      "\tspeed: 0.2454s/iter; left time: 3788.7358s\n",
      "\titers: 200, epoch: 31 | loss: 0.0653653\n",
      "\tspeed: 0.0862s/iter; left time: 1322.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:19.51s\n",
      "Steps: 222 | Train Loss: 0.0656349 Vali Loss: 0.0856716 Test Loss: 0.1054616\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0676070\n",
      "\tspeed: 0.2481s/iter; left time: 3776.1021s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645045\n",
      "\tspeed: 0.0849s/iter; left time: 1283.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:19.82s\n",
      "Steps: 222 | Train Loss: 0.0655142 Vali Loss: 0.0854192 Test Loss: 0.1053031\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0638009\n",
      "\tspeed: 0.2594s/iter; left time: 3890.2916s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655667\n",
      "\tspeed: 0.0861s/iter; left time: 1282.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:19.55s\n",
      "Steps: 222 | Train Loss: 0.0656412 Vali Loss: 0.0856932 Test Loss: 0.1055922\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.031011706218123436, rmse:0.176101416349411, mae:0.10445638000965118, rse:0.6820574402809143\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2960523\n",
      "\tspeed: 0.0916s/iter; left time: 2024.1995s\n",
      "\titers: 200, epoch: 1 | loss: 0.2580468\n",
      "\tspeed: 0.0862s/iter; left time: 1896.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.71s\n",
      "Steps: 222 | Train Loss: 0.3004397 Vali Loss: 0.2002241 Test Loss: 0.2031492\n",
      "Validation loss decreased (inf --> 0.200224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470547\n",
      "\tspeed: 0.2465s/iter; left time: 5393.4815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1085581\n",
      "\tspeed: 0.0848s/iter; left time: 1847.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.43s\n",
      "Steps: 222 | Train Loss: 0.1510279 Vali Loss: 0.1161526 Test Loss: 0.1335732\n",
      "Validation loss decreased (0.200224 --> 0.116153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0993246\n",
      "\tspeed: 0.2549s/iter; left time: 5520.5609s\n",
      "\titers: 200, epoch: 3 | loss: 0.0895627\n",
      "\tspeed: 0.0914s/iter; left time: 1970.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:20.18s\n",
      "Steps: 222 | Train Loss: 0.0986324 Vali Loss: 0.1074410 Test Loss: 0.1249404\n",
      "Validation loss decreased (0.116153 --> 0.107441).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0864509\n",
      "\tspeed: 0.2732s/iter; left time: 5857.0487s\n",
      "\titers: 200, epoch: 4 | loss: 0.0831333\n",
      "\tspeed: 0.0905s/iter; left time: 1929.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:20.46s\n",
      "Steps: 222 | Train Loss: 0.0860003 Vali Loss: 0.1012424 Test Loss: 0.1194630\n",
      "Validation loss decreased (0.107441 --> 0.101242).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780259\n",
      "\tspeed: 0.2546s/iter; left time: 5401.0286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0747263\n",
      "\tspeed: 0.0889s/iter; left time: 1877.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:20.02s\n",
      "Steps: 222 | Train Loss: 0.0794467 Vali Loss: 0.0953809 Test Loss: 0.1126000\n",
      "Validation loss decreased (0.101242 --> 0.095381).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0729026\n",
      "\tspeed: 0.2584s/iter; left time: 5424.8912s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735000\n",
      "\tspeed: 0.0866s/iter; left time: 1809.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.86s\n",
      "Steps: 222 | Train Loss: 0.0758320 Vali Loss: 0.0941131 Test Loss: 0.1115670\n",
      "Validation loss decreased (0.095381 --> 0.094113).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783361\n",
      "\tspeed: 0.2671s/iter; left time: 5546.9038s\n",
      "\titers: 200, epoch: 7 | loss: 0.0687699\n",
      "\tspeed: 0.0855s/iter; left time: 1766.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:19.86s\n",
      "Steps: 222 | Train Loss: 0.0745958 Vali Loss: 0.0923912 Test Loss: 0.1100338\n",
      "Validation loss decreased (0.094113 --> 0.092391).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0702801\n",
      "\tspeed: 0.2608s/iter; left time: 5358.7722s\n",
      "\titers: 200, epoch: 8 | loss: 0.0715532\n",
      "\tspeed: 0.0851s/iter; left time: 1739.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:19.55s\n",
      "Steps: 222 | Train Loss: 0.0735155 Vali Loss: 0.0875287 Test Loss: 0.1044268\n",
      "Validation loss decreased (0.092391 --> 0.087529).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729133\n",
      "\tspeed: 0.2553s/iter; left time: 5189.4793s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707102\n",
      "\tspeed: 0.0899s/iter; left time: 1817.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:20.17s\n",
      "Steps: 222 | Train Loss: 0.0711739 Vali Loss: 0.0886466 Test Loss: 0.1060341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0673946\n",
      "\tspeed: 0.2635s/iter; left time: 5296.7450s\n",
      "\titers: 200, epoch: 10 | loss: 0.0684582\n",
      "\tspeed: 0.0878s/iter; left time: 1755.3637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:20.24s\n",
      "Steps: 222 | Train Loss: 0.0709874 Vali Loss: 0.0879338 Test Loss: 0.1049823\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720375\n",
      "\tspeed: 0.2583s/iter; left time: 5136.0090s\n",
      "\titers: 200, epoch: 11 | loss: 0.0702967\n",
      "\tspeed: 0.0891s/iter; left time: 1763.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:20.26s\n",
      "Steps: 222 | Train Loss: 0.0699187 Vali Loss: 0.0868709 Test Loss: 0.1040385\n",
      "Validation loss decreased (0.087529 --> 0.086871).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713675\n",
      "\tspeed: 0.2476s/iter; left time: 4867.6388s\n",
      "\titers: 200, epoch: 12 | loss: 0.0702999\n",
      "\tspeed: 0.0857s/iter; left time: 1675.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:19.30s\n",
      "Steps: 222 | Train Loss: 0.0693421 Vali Loss: 0.0874136 Test Loss: 0.1059622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0690523\n",
      "\tspeed: 0.2470s/iter; left time: 4801.5736s\n",
      "\titers: 200, epoch: 13 | loss: 0.0681763\n",
      "\tspeed: 0.0831s/iter; left time: 1606.4633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:19.17s\n",
      "Steps: 222 | Train Loss: 0.0688044 Vali Loss: 0.0868779 Test Loss: 0.1048321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641942\n",
      "\tspeed: 0.2438s/iter; left time: 4685.2137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0672320\n",
      "\tspeed: 0.0852s/iter; left time: 1628.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:19.25s\n",
      "Steps: 222 | Train Loss: 0.0684135 Vali Loss: 0.0875285 Test Loss: 0.1080127\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0676505\n",
      "\tspeed: 0.2465s/iter; left time: 4682.7130s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713767\n",
      "\tspeed: 0.0828s/iter; left time: 1565.0405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:19.18s\n",
      "Steps: 222 | Train Loss: 0.0679713 Vali Loss: 0.0873318 Test Loss: 0.1078905\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0673540\n",
      "\tspeed: 0.2482s/iter; left time: 4658.9895s\n",
      "\titers: 200, epoch: 16 | loss: 0.0692711\n",
      "\tspeed: 0.0854s/iter; left time: 1593.9340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:19.17s\n",
      "Steps: 222 | Train Loss: 0.0678495 Vali Loss: 0.0883853 Test Loss: 0.1092793\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0662364\n",
      "\tspeed: 0.2479s/iter; left time: 4597.4019s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713062\n",
      "\tspeed: 0.0840s/iter; left time: 1550.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:19.57s\n",
      "Steps: 222 | Train Loss: 0.0674830 Vali Loss: 0.0867978 Test Loss: 0.1081234\n",
      "Validation loss decreased (0.086871 --> 0.086798).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0723100\n",
      "\tspeed: 0.2491s/iter; left time: 4565.6112s\n",
      "\titers: 200, epoch: 18 | loss: 0.0678283\n",
      "\tspeed: 0.0836s/iter; left time: 1523.2790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:19.05s\n",
      "Steps: 222 | Train Loss: 0.0673637 Vali Loss: 0.0868026 Test Loss: 0.1081041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0708197\n",
      "\tspeed: 0.2454s/iter; left time: 4443.6899s\n",
      "\titers: 200, epoch: 19 | loss: 0.0678932\n",
      "\tspeed: 0.0836s/iter; left time: 1505.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:19.11s\n",
      "Steps: 222 | Train Loss: 0.0670716 Vali Loss: 0.0873244 Test Loss: 0.1092070\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0673181\n",
      "\tspeed: 0.2438s/iter; left time: 4359.9598s\n",
      "\titers: 200, epoch: 20 | loss: 0.0689979\n",
      "\tspeed: 0.0855s/iter; left time: 1520.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:19.56s\n",
      "Steps: 222 | Train Loss: 0.0667922 Vali Loss: 0.0870446 Test Loss: 0.1089753\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0650101\n",
      "\tspeed: 0.2403s/iter; left time: 4244.2207s\n",
      "\titers: 200, epoch: 21 | loss: 0.0667346\n",
      "\tspeed: 0.0819s/iter; left time: 1437.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.77s\n",
      "Steps: 222 | Train Loss: 0.0665802 Vali Loss: 0.0874825 Test Loss: 0.1098442\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0669405\n",
      "\tspeed: 0.2396s/iter; left time: 4179.1133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0644848\n",
      "\tspeed: 0.0808s/iter; left time: 1401.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.56s\n",
      "Steps: 222 | Train Loss: 0.0664314 Vali Loss: 0.0866422 Test Loss: 0.1090736\n",
      "Validation loss decreased (0.086798 --> 0.086642).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0647514\n",
      "\tspeed: 0.2414s/iter; left time: 4155.8823s\n",
      "\titers: 200, epoch: 23 | loss: 0.0621063\n",
      "\tspeed: 0.0834s/iter; left time: 1426.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.79s\n",
      "Steps: 222 | Train Loss: 0.0662950 Vali Loss: 0.0877385 Test Loss: 0.1108830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0667494\n",
      "\tspeed: 0.2360s/iter; left time: 4010.7758s\n",
      "\titers: 200, epoch: 24 | loss: 0.0626290\n",
      "\tspeed: 0.0824s/iter; left time: 1392.6976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:19.20s\n",
      "Steps: 222 | Train Loss: 0.0660678 Vali Loss: 0.0880288 Test Loss: 0.1110027\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0663719\n",
      "\tspeed: 0.2399s/iter; left time: 4024.2120s\n",
      "\titers: 200, epoch: 25 | loss: 0.0672640\n",
      "\tspeed: 0.0832s/iter; left time: 1386.4796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.64s\n",
      "Steps: 222 | Train Loss: 0.0658468 Vali Loss: 0.0873961 Test Loss: 0.1106290\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0643725\n",
      "\tspeed: 0.2328s/iter; left time: 3853.0540s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684291\n",
      "\tspeed: 0.0795s/iter; left time: 1307.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0657131 Vali Loss: 0.0873847 Test Loss: 0.1101641\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677329\n",
      "\tspeed: 0.2319s/iter; left time: 3787.3742s\n",
      "\titers: 200, epoch: 27 | loss: 0.0659844\n",
      "\tspeed: 0.0840s/iter; left time: 1363.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.85s\n",
      "Steps: 222 | Train Loss: 0.0656590 Vali Loss: 0.0874500 Test Loss: 0.1103136\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0629499\n",
      "\tspeed: 0.2394s/iter; left time: 3855.7498s\n",
      "\titers: 200, epoch: 28 | loss: 0.0651293\n",
      "\tspeed: 0.0828s/iter; left time: 1325.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.87s\n",
      "Steps: 222 | Train Loss: 0.0654896 Vali Loss: 0.0870776 Test Loss: 0.1105336\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0669589\n",
      "\tspeed: 0.2381s/iter; left time: 3781.6843s\n",
      "\titers: 200, epoch: 29 | loss: 0.0659455\n",
      "\tspeed: 0.0848s/iter; left time: 1337.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.98s\n",
      "Steps: 222 | Train Loss: 0.0655847 Vali Loss: 0.0880176 Test Loss: 0.1118474\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0686122\n",
      "\tspeed: 0.2370s/iter; left time: 3712.1413s\n",
      "\titers: 200, epoch: 30 | loss: 0.0659835\n",
      "\tspeed: 0.0824s/iter; left time: 1282.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.62s\n",
      "Steps: 222 | Train Loss: 0.0654971 Vali Loss: 0.0877517 Test Loss: 0.1112433\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0636403\n",
      "\tspeed: 0.2375s/iter; left time: 3666.5027s\n",
      "\titers: 200, epoch: 31 | loss: 0.0631017\n",
      "\tspeed: 0.0838s/iter; left time: 1286.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:19.00s\n",
      "Steps: 222 | Train Loss: 0.0653287 Vali Loss: 0.0874658 Test Loss: 0.1112121\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0672346\n",
      "\tspeed: 0.2387s/iter; left time: 3632.4677s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652578\n",
      "\tspeed: 0.0815s/iter; left time: 1232.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.60s\n",
      "Steps: 222 | Train Loss: 0.0652832 Vali Loss: 0.0875376 Test Loss: 0.1115133\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0341767892241478, rmse:0.1848696619272232, mae:0.10907357931137085, rse:0.7160176634788513\n",
      "Intermediate time for FR and pred_len 168: 00h:35m:43.06s\n",
      "Intermediate time for FR: 02h:06m:34.08s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3061361\n",
      "\tspeed: 0.0970s/iter; left time: 2153.3439s\n",
      "\titers: 200, epoch: 1 | loss: 0.2755903\n",
      "\tspeed: 0.0698s/iter; left time: 1542.0146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.29s\n",
      "Steps: 223 | Train Loss: 0.3095616 Vali Loss: 0.2058126 Test Loss: 0.2083468\n",
      "Validation loss decreased (inf --> 0.205813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1802197\n",
      "\tspeed: 0.1493s/iter; left time: 3280.9265s\n",
      "\titers: 200, epoch: 2 | loss: 0.1262471\n",
      "\tspeed: 0.0689s/iter; left time: 1508.3761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 223 | Train Loss: 0.1781840 Vali Loss: 0.0973517 Test Loss: 0.1050348\n",
      "Validation loss decreased (0.205813 --> 0.097352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1094621\n",
      "\tspeed: 0.1522s/iter; left time: 3312.0390s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003384\n",
      "\tspeed: 0.0708s/iter; left time: 1532.7229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.1096115 Vali Loss: 0.0864722 Test Loss: 0.0932835\n",
      "Validation loss decreased (0.097352 --> 0.086472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0969571\n",
      "\tspeed: 0.1513s/iter; left time: 3257.9082s\n",
      "\titers: 200, epoch: 4 | loss: 0.0899685\n",
      "\tspeed: 0.0709s/iter; left time: 1519.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.09s\n",
      "Steps: 223 | Train Loss: 0.0947059 Vali Loss: 0.0858601 Test Loss: 0.0945175\n",
      "Validation loss decreased (0.086472 --> 0.085860).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0850252\n",
      "\tspeed: 0.1515s/iter; left time: 3228.7330s\n",
      "\titers: 200, epoch: 5 | loss: 0.0851159\n",
      "\tspeed: 0.0685s/iter; left time: 1452.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 223 | Train Loss: 0.0860463 Vali Loss: 0.0785575 Test Loss: 0.0860457\n",
      "Validation loss decreased (0.085860 --> 0.078557).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800406\n",
      "\tspeed: 0.1485s/iter; left time: 3130.4710s\n",
      "\titers: 200, epoch: 6 | loss: 0.0817737\n",
      "\tspeed: 0.0698s/iter; left time: 1464.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.76s\n",
      "Steps: 223 | Train Loss: 0.0805324 Vali Loss: 0.0784566 Test Loss: 0.0861087\n",
      "Validation loss decreased (0.078557 --> 0.078457).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770911\n",
      "\tspeed: 0.1529s/iter; left time: 3189.7232s\n",
      "\titers: 200, epoch: 7 | loss: 0.0708186\n",
      "\tspeed: 0.0706s/iter; left time: 1466.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.14s\n",
      "Steps: 223 | Train Loss: 0.0770517 Vali Loss: 0.0712404 Test Loss: 0.0786346\n",
      "Validation loss decreased (0.078457 --> 0.071240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0768405\n",
      "\tspeed: 0.1506s/iter; left time: 3107.7806s\n",
      "\titers: 200, epoch: 8 | loss: 0.0717100\n",
      "\tspeed: 0.0694s/iter; left time: 1425.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 223 | Train Loss: 0.0741202 Vali Loss: 0.0765836 Test Loss: 0.0828031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726561\n",
      "\tspeed: 0.1516s/iter; left time: 3094.5571s\n",
      "\titers: 200, epoch: 9 | loss: 0.0707451\n",
      "\tspeed: 0.0688s/iter; left time: 1396.8028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.03s\n",
      "Steps: 223 | Train Loss: 0.0730211 Vali Loss: 0.0680534 Test Loss: 0.0748785\n",
      "Validation loss decreased (0.071240 --> 0.068053).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763692\n",
      "\tspeed: 0.1540s/iter; left time: 3110.1636s\n",
      "\titers: 200, epoch: 10 | loss: 0.0733488\n",
      "\tspeed: 0.0689s/iter; left time: 1383.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.98s\n",
      "Steps: 223 | Train Loss: 0.0706690 Vali Loss: 0.0673278 Test Loss: 0.0743647\n",
      "Validation loss decreased (0.068053 --> 0.067328).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0655545\n",
      "\tspeed: 0.1516s/iter; left time: 3027.8360s\n",
      "\titers: 200, epoch: 11 | loss: 0.0674637\n",
      "\tspeed: 0.0705s/iter; left time: 1400.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.00s\n",
      "Steps: 223 | Train Loss: 0.0693408 Vali Loss: 0.0677038 Test Loss: 0.0740526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0656180\n",
      "\tspeed: 0.1491s/iter; left time: 2944.5323s\n",
      "\titers: 200, epoch: 12 | loss: 0.0678009\n",
      "\tspeed: 0.0676s/iter; left time: 1327.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.0686092 Vali Loss: 0.0664527 Test Loss: 0.0733825\n",
      "Validation loss decreased (0.067328 --> 0.066453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0616966\n",
      "\tspeed: 0.1518s/iter; left time: 2963.0237s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658613\n",
      "\tspeed: 0.0675s/iter; left time: 1310.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0675719 Vali Loss: 0.0652681 Test Loss: 0.0720199\n",
      "Validation loss decreased (0.066453 --> 0.065268).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0668045\n",
      "\tspeed: 0.1506s/iter; left time: 2906.2880s\n",
      "\titers: 200, epoch: 14 | loss: 0.0671891\n",
      "\tspeed: 0.0699s/iter; left time: 1341.5302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 223 | Train Loss: 0.0669816 Vali Loss: 0.0646988 Test Loss: 0.0712087\n",
      "Validation loss decreased (0.065268 --> 0.064699).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0680266\n",
      "\tspeed: 0.1511s/iter; left time: 2882.3377s\n",
      "\titers: 200, epoch: 15 | loss: 0.0646383\n",
      "\tspeed: 0.0670s/iter; left time: 1271.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 223 | Train Loss: 0.0663001 Vali Loss: 0.0635490 Test Loss: 0.0708502\n",
      "Validation loss decreased (0.064699 --> 0.063549).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0657929\n",
      "\tspeed: 0.1502s/iter; left time: 2832.8514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0637286\n",
      "\tspeed: 0.0717s/iter; left time: 1344.5470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 223 | Train Loss: 0.0660144 Vali Loss: 0.0638088 Test Loss: 0.0703623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0686436\n",
      "\tspeed: 0.1517s/iter; left time: 2825.6998s\n",
      "\titers: 200, epoch: 17 | loss: 0.0621247\n",
      "\tspeed: 0.0692s/iter; left time: 1282.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:16.13s\n",
      "Steps: 223 | Train Loss: 0.0654224 Vali Loss: 0.0632188 Test Loss: 0.0701424\n",
      "Validation loss decreased (0.063549 --> 0.063219).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0636385\n",
      "\tspeed: 0.1522s/iter; left time: 2801.2377s\n",
      "\titers: 200, epoch: 18 | loss: 0.0707149\n",
      "\tspeed: 0.0672s/iter; left time: 1230.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 223 | Train Loss: 0.0652086 Vali Loss: 0.0637628 Test Loss: 0.0702256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0642155\n",
      "\tspeed: 0.1490s/iter; left time: 2710.4401s\n",
      "\titers: 200, epoch: 19 | loss: 0.0662235\n",
      "\tspeed: 0.0688s/iter; left time: 1244.4552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.89s\n",
      "Steps: 223 | Train Loss: 0.0650973 Vali Loss: 0.0623519 Test Loss: 0.0692457\n",
      "Validation loss decreased (0.063219 --> 0.062352).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0616270\n",
      "\tspeed: 0.1515s/iter; left time: 2721.0966s\n",
      "\titers: 200, epoch: 20 | loss: 0.0745765\n",
      "\tspeed: 0.0673s/iter; left time: 1202.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0646424 Vali Loss: 0.0633734 Test Loss: 0.0696016\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0661893\n",
      "\tspeed: 0.1497s/iter; left time: 2655.6848s\n",
      "\titers: 200, epoch: 21 | loss: 0.0616344\n",
      "\tspeed: 0.0714s/iter; left time: 1259.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 223 | Train Loss: 0.0642890 Vali Loss: 0.0624470 Test Loss: 0.0688535\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0599282\n",
      "\tspeed: 0.1501s/iter; left time: 2630.0257s\n",
      "\titers: 200, epoch: 22 | loss: 0.0612805\n",
      "\tspeed: 0.0690s/iter; left time: 1201.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.0643562 Vali Loss: 0.0621631 Test Loss: 0.0689341\n",
      "Validation loss decreased (0.062352 --> 0.062163).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0630811\n",
      "\tspeed: 0.1521s/iter; left time: 2630.0900s\n",
      "\titers: 200, epoch: 23 | loss: 0.0653336\n",
      "\tspeed: 0.0696s/iter; left time: 1197.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 223 | Train Loss: 0.0639284 Vali Loss: 0.0623315 Test Loss: 0.0690394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0616123\n",
      "\tspeed: 0.1475s/iter; left time: 2518.4217s\n",
      "\titers: 200, epoch: 24 | loss: 0.0642657\n",
      "\tspeed: 0.0685s/iter; left time: 1162.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.0634792 Vali Loss: 0.0616129 Test Loss: 0.0686401\n",
      "Validation loss decreased (0.062163 --> 0.061613).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0670362\n",
      "\tspeed: 0.1495s/iter; left time: 2519.3885s\n",
      "\titers: 200, epoch: 25 | loss: 0.0650764\n",
      "\tspeed: 0.0692s/iter; left time: 1158.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.0634052 Vali Loss: 0.0613903 Test Loss: 0.0680714\n",
      "Validation loss decreased (0.061613 --> 0.061390).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0603787\n",
      "\tspeed: 0.1560s/iter; left time: 2593.3460s\n",
      "\titers: 200, epoch: 26 | loss: 0.0651114\n",
      "\tspeed: 0.0702s/iter; left time: 1160.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:16.08s\n",
      "Steps: 223 | Train Loss: 0.0633246 Vali Loss: 0.0611665 Test Loss: 0.0680832\n",
      "Validation loss decreased (0.061390 --> 0.061166).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0632547\n",
      "\tspeed: 0.1507s/iter; left time: 2472.2026s\n",
      "\titers: 200, epoch: 27 | loss: 0.0663807\n",
      "\tspeed: 0.0678s/iter; left time: 1105.6322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.0631550 Vali Loss: 0.0615939 Test Loss: 0.0680103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0622626\n",
      "\tspeed: 0.1513s/iter; left time: 2447.4259s\n",
      "\titers: 200, epoch: 28 | loss: 0.0590173\n",
      "\tspeed: 0.0690s/iter; left time: 1109.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.84s\n",
      "Steps: 223 | Train Loss: 0.0631449 Vali Loss: 0.0614959 Test Loss: 0.0681203\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645808\n",
      "\tspeed: 0.1499s/iter; left time: 2392.6424s\n",
      "\titers: 200, epoch: 29 | loss: 0.0569443\n",
      "\tspeed: 0.0683s/iter; left time: 1082.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 223 | Train Loss: 0.0630526 Vali Loss: 0.0620191 Test Loss: 0.0685173\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0625401\n",
      "\tspeed: 0.1519s/iter; left time: 2389.2166s\n",
      "\titers: 200, epoch: 30 | loss: 0.0609342\n",
      "\tspeed: 0.0704s/iter; left time: 1100.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:16.04s\n",
      "Steps: 223 | Train Loss: 0.0627745 Vali Loss: 0.0610812 Test Loss: 0.0674878\n",
      "Validation loss decreased (0.061166 --> 0.061081).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0586573\n",
      "\tspeed: 0.1525s/iter; left time: 2365.0506s\n",
      "\titers: 200, epoch: 31 | loss: 0.0599233\n",
      "\tspeed: 0.0692s/iter; left time: 1067.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 223 | Train Loss: 0.0627884 Vali Loss: 0.0616102 Test Loss: 0.0680946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0646340\n",
      "\tspeed: 0.1514s/iter; left time: 2313.9397s\n",
      "\titers: 200, epoch: 32 | loss: 0.0640443\n",
      "\tspeed: 0.0691s/iter; left time: 1049.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 223 | Train Loss: 0.0626478 Vali Loss: 0.0607433 Test Loss: 0.0673023\n",
      "Validation loss decreased (0.061081 --> 0.060743).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0609759\n",
      "\tspeed: 0.1541s/iter; left time: 2322.0505s\n",
      "\titers: 200, epoch: 33 | loss: 0.0644260\n",
      "\tspeed: 0.0690s/iter; left time: 1032.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.89s\n",
      "Steps: 223 | Train Loss: 0.0626795 Vali Loss: 0.0609909 Test Loss: 0.0676019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0613925\n",
      "\tspeed: 0.1521s/iter; left time: 2256.9254s\n",
      "\titers: 200, epoch: 34 | loss: 0.0641194\n",
      "\tspeed: 0.0687s/iter; left time: 1012.9295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.99s\n",
      "Steps: 223 | Train Loss: 0.0624934 Vali Loss: 0.0608847 Test Loss: 0.0672689\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0644516\n",
      "\tspeed: 0.1529s/iter; left time: 2235.6601s\n",
      "\titers: 200, epoch: 35 | loss: 0.0647939\n",
      "\tspeed: 0.0676s/iter; left time: 980.9711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0624784 Vali Loss: 0.0612455 Test Loss: 0.0677474\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0644470\n",
      "\tspeed: 0.1480s/iter; left time: 2130.3406s\n",
      "\titers: 200, epoch: 36 | loss: 0.0616870\n",
      "\tspeed: 0.0704s/iter; left time: 1006.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.0623280 Vali Loss: 0.0609064 Test Loss: 0.0673447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0617860\n",
      "\tspeed: 0.1486s/iter; left time: 2105.9129s\n",
      "\titers: 200, epoch: 37 | loss: 0.0629435\n",
      "\tspeed: 0.0671s/iter; left time: 944.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0623145 Vali Loss: 0.0610814 Test Loss: 0.0673510\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0636806\n",
      "\tspeed: 0.1499s/iter; left time: 2090.7098s\n",
      "\titers: 200, epoch: 38 | loss: 0.0650988\n",
      "\tspeed: 0.0687s/iter; left time: 951.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.83s\n",
      "Steps: 223 | Train Loss: 0.0623559 Vali Loss: 0.0606328 Test Loss: 0.0671096\n",
      "Validation loss decreased (0.060743 --> 0.060633).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0630613\n",
      "\tspeed: 0.1499s/iter; left time: 2057.4014s\n",
      "\titers: 200, epoch: 39 | loss: 0.0621173\n",
      "\tspeed: 0.0678s/iter; left time: 923.8609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0622429 Vali Loss: 0.0609451 Test Loss: 0.0674795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0597868\n",
      "\tspeed: 0.1510s/iter; left time: 2038.9003s\n",
      "\titers: 200, epoch: 40 | loss: 0.0637383\n",
      "\tspeed: 0.0686s/iter; left time: 919.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.0623678 Vali Loss: 0.0608015 Test Loss: 0.0672628\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0632718\n",
      "\tspeed: 0.1505s/iter; left time: 1998.2143s\n",
      "\titers: 200, epoch: 41 | loss: 0.0631721\n",
      "\tspeed: 0.0701s/iter; left time: 923.4544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.0622537 Vali Loss: 0.0606412 Test Loss: 0.0671085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0684032\n",
      "\tspeed: 0.1496s/iter; left time: 1953.0040s\n",
      "\titers: 200, epoch: 42 | loss: 0.0652247\n",
      "\tspeed: 0.0695s/iter; left time: 900.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 223 | Train Loss: 0.0621388 Vali Loss: 0.0607070 Test Loss: 0.0672042\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0585651\n",
      "\tspeed: 0.1511s/iter; left time: 1939.6797s\n",
      "\titers: 200, epoch: 43 | loss: 0.0622151\n",
      "\tspeed: 0.0703s/iter; left time: 894.7592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.92s\n",
      "Steps: 223 | Train Loss: 0.0621560 Vali Loss: 0.0607380 Test Loss: 0.0670468\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0606230\n",
      "\tspeed: 0.1499s/iter; left time: 1890.8073s\n",
      "\titers: 200, epoch: 44 | loss: 0.0607643\n",
      "\tspeed: 0.0718s/iter; left time: 898.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:16.06s\n",
      "Steps: 223 | Train Loss: 0.0621815 Vali Loss: 0.0608390 Test Loss: 0.0669984\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0651128\n",
      "\tspeed: 0.1537s/iter; left time: 1903.7868s\n",
      "\titers: 200, epoch: 45 | loss: 0.0613740\n",
      "\tspeed: 0.0707s/iter; left time: 869.3304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:16.21s\n",
      "Steps: 223 | Train Loss: 0.0620739 Vali Loss: 0.0606061 Test Loss: 0.0669662\n",
      "Validation loss decreased (0.060633 --> 0.060606).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618639\n",
      "\tspeed: 0.1538s/iter; left time: 1871.1335s\n",
      "\titers: 200, epoch: 46 | loss: 0.0629571\n",
      "\tspeed: 0.0672s/iter; left time: 810.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0619979 Vali Loss: 0.0608981 Test Loss: 0.0671475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0628071\n",
      "\tspeed: 0.1520s/iter; left time: 1815.3022s\n",
      "\titers: 200, epoch: 47 | loss: 0.0591880\n",
      "\tspeed: 0.0685s/iter; left time: 811.0117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0620840 Vali Loss: 0.0608572 Test Loss: 0.0672093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0644013\n",
      "\tspeed: 0.1517s/iter; left time: 1777.7621s\n",
      "\titers: 200, epoch: 48 | loss: 0.0620146\n",
      "\tspeed: 0.0674s/iter; left time: 783.6568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.0621214 Vali Loss: 0.0604878 Test Loss: 0.0667664\n",
      "Validation loss decreased (0.060606 --> 0.060488).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0614247\n",
      "\tspeed: 0.1501s/iter; left time: 1725.9613s\n",
      "\titers: 200, epoch: 49 | loss: 0.0641569\n",
      "\tspeed: 0.0685s/iter; left time: 780.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.0620830 Vali Loss: 0.0605798 Test Loss: 0.0669707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0618149\n",
      "\tspeed: 0.1472s/iter; left time: 1659.9722s\n",
      "\titers: 200, epoch: 50 | loss: 0.0626017\n",
      "\tspeed: 0.0690s/iter; left time: 770.7434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0619398 Vali Loss: 0.0606753 Test Loss: 0.0670868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0569905\n",
      "\tspeed: 0.1464s/iter; left time: 1617.8270s\n",
      "\titers: 200, epoch: 51 | loss: 0.0610878\n",
      "\tspeed: 0.0711s/iter; left time: 778.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 223 | Train Loss: 0.0620054 Vali Loss: 0.0607700 Test Loss: 0.0670983\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0602378\n",
      "\tspeed: 0.1510s/iter; left time: 1634.9259s\n",
      "\titers: 200, epoch: 52 | loss: 0.0615794\n",
      "\tspeed: 0.0676s/iter; left time: 725.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 223 | Train Loss: 0.0618988 Vali Loss: 0.0604606 Test Loss: 0.0668508\n",
      "Validation loss decreased (0.060488 --> 0.060461).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0646212\n",
      "\tspeed: 0.1482s/iter; left time: 1571.6493s\n",
      "\titers: 200, epoch: 53 | loss: 0.0614550\n",
      "\tspeed: 0.0695s/iter; left time: 729.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0619825 Vali Loss: 0.0605966 Test Loss: 0.0669796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0655180\n",
      "\tspeed: 0.1463s/iter; left time: 1518.5960s\n",
      "\titers: 200, epoch: 54 | loss: 0.0606591\n",
      "\tspeed: 0.0688s/iter; left time: 707.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0619326 Vali Loss: 0.0606654 Test Loss: 0.0669744\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0624183\n",
      "\tspeed: 0.1501s/iter; left time: 1524.6618s\n",
      "\titers: 200, epoch: 55 | loss: 0.0585988\n",
      "\tspeed: 0.0683s/iter; left time: 686.7704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 223 | Train Loss: 0.0619509 Vali Loss: 0.0607157 Test Loss: 0.0666752\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0596619\n",
      "\tspeed: 0.1467s/iter; left time: 1458.0790s\n",
      "\titers: 200, epoch: 56 | loss: 0.0613919\n",
      "\tspeed: 0.0683s/iter; left time: 671.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.0619160 Vali Loss: 0.0607391 Test Loss: 0.0668140\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0587242\n",
      "\tspeed: 0.1479s/iter; left time: 1436.1781s\n",
      "\titers: 200, epoch: 57 | loss: 0.0642860\n",
      "\tspeed: 0.0679s/iter; left time: 653.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 223 | Train Loss: 0.0622175 Vali Loss: 0.0607274 Test Loss: 0.0670485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0630521\n",
      "\tspeed: 0.1482s/iter; left time: 1406.1927s\n",
      "\titers: 200, epoch: 58 | loss: 0.0614526\n",
      "\tspeed: 0.0675s/iter; left time: 633.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0619667 Vali Loss: 0.0604430 Test Loss: 0.0669085\n",
      "Validation loss decreased (0.060461 --> 0.060443).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0604380\n",
      "\tspeed: 0.1437s/iter; left time: 1331.8741s\n",
      "\titers: 200, epoch: 59 | loss: 0.0611255\n",
      "\tspeed: 0.0673s/iter; left time: 616.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 223 | Train Loss: 0.0619924 Vali Loss: 0.0603980 Test Loss: 0.0670454\n",
      "Validation loss decreased (0.060443 --> 0.060398).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0619389\n",
      "\tspeed: 0.1472s/iter; left time: 1331.2952s\n",
      "\titers: 200, epoch: 60 | loss: 0.0626048\n",
      "\tspeed: 0.0679s/iter; left time: 607.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.0619687 Vali Loss: 0.0604863 Test Loss: 0.0670725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0632136\n",
      "\tspeed: 0.1472s/iter; left time: 1298.0983s\n",
      "\titers: 200, epoch: 61 | loss: 0.0630836\n",
      "\tspeed: 0.0666s/iter; left time: 581.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 223 | Train Loss: 0.0619425 Vali Loss: 0.0604549 Test Loss: 0.0670272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0615324\n",
      "\tspeed: 0.1470s/iter; left time: 1264.1832s\n",
      "\titers: 200, epoch: 62 | loss: 0.0632772\n",
      "\tspeed: 0.0693s/iter; left time: 588.8580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:15.83s\n",
      "Steps: 223 | Train Loss: 0.0619147 Vali Loss: 0.0606046 Test Loss: 0.0669372\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0619553\n",
      "\tspeed: 0.1494s/iter; left time: 1251.5134s\n",
      "\titers: 200, epoch: 63 | loss: 0.0625141\n",
      "\tspeed: 0.0666s/iter; left time: 551.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.0619488 Vali Loss: 0.0605036 Test Loss: 0.0670024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0662935\n",
      "\tspeed: 0.1477s/iter; left time: 1204.1699s\n",
      "\titers: 200, epoch: 64 | loss: 0.0579902\n",
      "\tspeed: 0.0673s/iter; left time: 541.6161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 223 | Train Loss: 0.0618735 Vali Loss: 0.0606146 Test Loss: 0.0667844\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0597391\n",
      "\tspeed: 0.1497s/iter; left time: 1186.6074s\n",
      "\titers: 200, epoch: 65 | loss: 0.0609572\n",
      "\tspeed: 0.0694s/iter; left time: 543.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 223 | Train Loss: 0.0618623 Vali Loss: 0.0603176 Test Loss: 0.0667465\n",
      "Validation loss decreased (0.060398 --> 0.060318).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0600821\n",
      "\tspeed: 0.1490s/iter; left time: 1148.2109s\n",
      "\titers: 200, epoch: 66 | loss: 0.0591261\n",
      "\tspeed: 0.0688s/iter; left time: 523.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:15.86s\n",
      "Steps: 223 | Train Loss: 0.0619789 Vali Loss: 0.0607171 Test Loss: 0.0670776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0600982\n",
      "\tspeed: 0.1476s/iter; left time: 1104.5056s\n",
      "\titers: 200, epoch: 67 | loss: 0.0605580\n",
      "\tspeed: 0.0678s/iter; left time: 500.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.0618578 Vali Loss: 0.0606859 Test Loss: 0.0669931\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0605976\n",
      "\tspeed: 0.1465s/iter; left time: 1063.6171s\n",
      "\titers: 200, epoch: 68 | loss: 0.0634373\n",
      "\tspeed: 0.0685s/iter; left time: 490.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.0619750 Vali Loss: 0.0603630 Test Loss: 0.0669141\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0664807\n",
      "\tspeed: 0.1524s/iter; left time: 1072.2772s\n",
      "\titers: 200, epoch: 69 | loss: 0.0644694\n",
      "\tspeed: 0.0687s/iter; left time: 476.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:15.99s\n",
      "Steps: 223 | Train Loss: 0.0618572 Vali Loss: 0.0607146 Test Loss: 0.0669209\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0638890\n",
      "\tspeed: 0.1491s/iter; left time: 1016.0456s\n",
      "\titers: 200, epoch: 70 | loss: 0.0614417\n",
      "\tspeed: 0.0696s/iter; left time: 467.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:15.84s\n",
      "Steps: 223 | Train Loss: 0.0619157 Vali Loss: 0.0606190 Test Loss: 0.0668319\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0585856\n",
      "\tspeed: 0.1486s/iter; left time: 979.3350s\n",
      "\titers: 200, epoch: 71 | loss: 0.0599994\n",
      "\tspeed: 0.0682s/iter; left time: 442.9988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.0619570 Vali Loss: 0.0607395 Test Loss: 0.0668201\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0644496\n",
      "\tspeed: 0.1476s/iter; left time: 939.7010s\n",
      "\titers: 200, epoch: 72 | loss: 0.0621080\n",
      "\tspeed: 0.0683s/iter; left time: 427.8087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0618545 Vali Loss: 0.0604239 Test Loss: 0.0665997\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0609025\n",
      "\tspeed: 0.1450s/iter; left time: 890.8450s\n",
      "\titers: 200, epoch: 73 | loss: 0.0608627\n",
      "\tspeed: 0.0695s/iter; left time: 419.8575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.0618685 Vali Loss: 0.0604549 Test Loss: 0.0670143\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0591934\n",
      "\tspeed: 0.1486s/iter; left time: 879.8463s\n",
      "\titers: 200, epoch: 74 | loss: 0.0611676\n",
      "\tspeed: 0.0670s/iter; left time: 390.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 223 | Train Loss: 0.0618945 Vali Loss: 0.0605280 Test Loss: 0.0668397\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0606657\n",
      "\tspeed: 0.1500s/iter; left time: 854.9704s\n",
      "\titers: 200, epoch: 75 | loss: 0.0688158\n",
      "\tspeed: 0.0677s/iter; left time: 379.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0618843 Vali Loss: 0.0604206 Test Loss: 0.0670228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011653070338070393, rmse:0.1079493910074234, mae:0.06674646586179733, rse:0.40788760781288147\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3086092\n",
      "\tspeed: 0.0730s/iter; left time: 1621.5320s\n",
      "\titers: 200, epoch: 1 | loss: 0.2763319\n",
      "\tspeed: 0.0687s/iter; left time: 1518.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 223 | Train Loss: 0.3170087 Vali Loss: 0.2054772 Test Loss: 0.2084676\n",
      "Validation loss decreased (inf --> 0.205477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1789148\n",
      "\tspeed: 0.1502s/iter; left time: 3301.0818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235500\n",
      "\tspeed: 0.0703s/iter; left time: 1537.3124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.01s\n",
      "Steps: 223 | Train Loss: 0.1776570 Vali Loss: 0.1000123 Test Loss: 0.1070516\n",
      "Validation loss decreased (0.205477 --> 0.100012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055849\n",
      "\tspeed: 0.1486s/iter; left time: 3232.2103s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021557\n",
      "\tspeed: 0.0699s/iter; left time: 1513.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 223 | Train Loss: 0.1081554 Vali Loss: 0.0886755 Test Loss: 0.0978114\n",
      "Validation loss decreased (0.100012 --> 0.088675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944088\n",
      "\tspeed: 0.1488s/iter; left time: 3203.8807s\n",
      "\titers: 200, epoch: 4 | loss: 0.0872428\n",
      "\tspeed: 0.0689s/iter; left time: 1475.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.89s\n",
      "Steps: 223 | Train Loss: 0.0926148 Vali Loss: 0.0850829 Test Loss: 0.0941046\n",
      "Validation loss decreased (0.088675 --> 0.085083).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0818782\n",
      "\tspeed: 0.1492s/iter; left time: 3179.7419s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822329\n",
      "\tspeed: 0.0684s/iter; left time: 1450.6031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0847815 Vali Loss: 0.0778806 Test Loss: 0.0877264\n",
      "Validation loss decreased (0.085083 --> 0.077881).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814048\n",
      "\tspeed: 0.1509s/iter; left time: 3182.4801s\n",
      "\titers: 200, epoch: 6 | loss: 0.0780787\n",
      "\tspeed: 0.0705s/iter; left time: 1480.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.97s\n",
      "Steps: 223 | Train Loss: 0.0803927 Vali Loss: 0.0760979 Test Loss: 0.0863049\n",
      "Validation loss decreased (0.077881 --> 0.076098).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0771661\n",
      "\tspeed: 0.1526s/iter; left time: 3183.5378s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799734\n",
      "\tspeed: 0.0703s/iter; left time: 1460.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.08s\n",
      "Steps: 223 | Train Loss: 0.0776875 Vali Loss: 0.0738603 Test Loss: 0.0840060\n",
      "Validation loss decreased (0.076098 --> 0.073860).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756229\n",
      "\tspeed: 0.1505s/iter; left time: 3106.6325s\n",
      "\titers: 200, epoch: 8 | loss: 0.0726548\n",
      "\tspeed: 0.0688s/iter; left time: 1412.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.0749492 Vali Loss: 0.0716087 Test Loss: 0.0809999\n",
      "Validation loss decreased (0.073860 --> 0.071609).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703250\n",
      "\tspeed: 0.1479s/iter; left time: 3020.2728s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760477\n",
      "\tspeed: 0.0670s/iter; left time: 1362.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 223 | Train Loss: 0.0728761 Vali Loss: 0.0718130 Test Loss: 0.0812090\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0795293\n",
      "\tspeed: 0.1501s/iter; left time: 3030.4843s\n",
      "\titers: 200, epoch: 10 | loss: 0.0711395\n",
      "\tspeed: 0.0695s/iter; left time: 1397.1944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.94s\n",
      "Steps: 223 | Train Loss: 0.0713044 Vali Loss: 0.0699328 Test Loss: 0.0791118\n",
      "Validation loss decreased (0.071609 --> 0.069933).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0696205\n",
      "\tspeed: 0.1515s/iter; left time: 3026.1369s\n",
      "\titers: 200, epoch: 11 | loss: 0.0701173\n",
      "\tspeed: 0.0684s/iter; left time: 1360.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 223 | Train Loss: 0.0701881 Vali Loss: 0.0690268 Test Loss: 0.0777114\n",
      "Validation loss decreased (0.069933 --> 0.069027).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0678073\n",
      "\tspeed: 0.1462s/iter; left time: 2886.8249s\n",
      "\titers: 200, epoch: 12 | loss: 0.0659772\n",
      "\tspeed: 0.0715s/iter; left time: 1404.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 223 | Train Loss: 0.0686810 Vali Loss: 0.0667496 Test Loss: 0.0747608\n",
      "Validation loss decreased (0.069027 --> 0.066750).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0683474\n",
      "\tspeed: 0.1476s/iter; left time: 2881.5881s\n",
      "\titers: 200, epoch: 13 | loss: 0.0686093\n",
      "\tspeed: 0.0674s/iter; left time: 1308.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0681240 Vali Loss: 0.0652541 Test Loss: 0.0736165\n",
      "Validation loss decreased (0.066750 --> 0.065254).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0683015\n",
      "\tspeed: 0.1506s/iter; left time: 2907.5944s\n",
      "\titers: 200, epoch: 14 | loss: 0.0677217\n",
      "\tspeed: 0.0676s/iter; left time: 1298.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.0671693 Vali Loss: 0.0658644 Test Loss: 0.0738114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0692174\n",
      "\tspeed: 0.1481s/iter; left time: 2825.1285s\n",
      "\titers: 200, epoch: 15 | loss: 0.0640382\n",
      "\tspeed: 0.0690s/iter; left time: 1309.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0662469 Vali Loss: 0.0636665 Test Loss: 0.0714699\n",
      "Validation loss decreased (0.065254 --> 0.063666).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0629423\n",
      "\tspeed: 0.1510s/iter; left time: 2846.6562s\n",
      "\titers: 200, epoch: 16 | loss: 0.0692686\n",
      "\tspeed: 0.0680s/iter; left time: 1276.1159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.0656693 Vali Loss: 0.0640458 Test Loss: 0.0718246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665519\n",
      "\tspeed: 0.1470s/iter; left time: 2738.9971s\n",
      "\titers: 200, epoch: 17 | loss: 0.0630314\n",
      "\tspeed: 0.0685s/iter; left time: 1269.3869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.75s\n",
      "Steps: 223 | Train Loss: 0.0651621 Vali Loss: 0.0667367 Test Loss: 0.0741296\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0635106\n",
      "\tspeed: 0.1453s/iter; left time: 2675.8214s\n",
      "\titers: 200, epoch: 18 | loss: 0.0658484\n",
      "\tspeed: 0.0676s/iter; left time: 1238.5348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 223 | Train Loss: 0.0649999 Vali Loss: 0.0629383 Test Loss: 0.0696670\n",
      "Validation loss decreased (0.063666 --> 0.062938).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0664386\n",
      "\tspeed: 0.1500s/iter; left time: 2728.7753s\n",
      "\titers: 200, epoch: 19 | loss: 0.0614856\n",
      "\tspeed: 0.0660s/iter; left time: 1193.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.0646668 Vali Loss: 0.0642735 Test Loss: 0.0707903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0629482\n",
      "\tspeed: 0.1474s/iter; left time: 2647.0285s\n",
      "\titers: 200, epoch: 20 | loss: 0.0595502\n",
      "\tspeed: 0.0683s/iter; left time: 1220.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.0654517 Vali Loss: 0.0644310 Test Loss: 0.0724018\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0616200\n",
      "\tspeed: 0.1476s/iter; left time: 2618.5538s\n",
      "\titers: 200, epoch: 21 | loss: 0.0631451\n",
      "\tspeed: 0.0679s/iter; left time: 1197.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.0643664 Vali Loss: 0.0627706 Test Loss: 0.0699441\n",
      "Validation loss decreased (0.062938 --> 0.062771).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0595936\n",
      "\tspeed: 0.1479s/iter; left time: 2590.1949s\n",
      "\titers: 200, epoch: 22 | loss: 0.0662590\n",
      "\tspeed: 0.0680s/iter; left time: 1184.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.0638591 Vali Loss: 0.0624155 Test Loss: 0.0690069\n",
      "Validation loss decreased (0.062771 --> 0.062415).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0634047\n",
      "\tspeed: 0.1489s/iter; left time: 2574.6577s\n",
      "\titers: 200, epoch: 23 | loss: 0.0626175\n",
      "\tspeed: 0.0708s/iter; left time: 1218.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 223 | Train Loss: 0.0634359 Vali Loss: 0.0619245 Test Loss: 0.0683848\n",
      "Validation loss decreased (0.062415 --> 0.061924).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0601679\n",
      "\tspeed: 0.1503s/iter; left time: 2566.5841s\n",
      "\titers: 200, epoch: 24 | loss: 0.0596431\n",
      "\tspeed: 0.0682s/iter; left time: 1157.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0630109 Vali Loss: 0.0620877 Test Loss: 0.0684756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0615240\n",
      "\tspeed: 0.1472s/iter; left time: 2480.3768s\n",
      "\titers: 200, epoch: 25 | loss: 0.0648811\n",
      "\tspeed: 0.0698s/iter; left time: 1168.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.0629832 Vali Loss: 0.0614948 Test Loss: 0.0682775\n",
      "Validation loss decreased (0.061924 --> 0.061495).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0622295\n",
      "\tspeed: 0.1484s/iter; left time: 2467.9911s\n",
      "\titers: 200, epoch: 26 | loss: 0.0640873\n",
      "\tspeed: 0.0689s/iter; left time: 1139.3156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.76s\n",
      "Steps: 223 | Train Loss: 0.0630488 Vali Loss: 0.0619235 Test Loss: 0.0683493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0653547\n",
      "\tspeed: 0.1443s/iter; left time: 2367.0408s\n",
      "\titers: 200, epoch: 27 | loss: 0.0614145\n",
      "\tspeed: 0.0684s/iter; left time: 1114.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 223 | Train Loss: 0.0628158 Vali Loss: 0.0617217 Test Loss: 0.0681203\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0637189\n",
      "\tspeed: 0.1460s/iter; left time: 2362.9383s\n",
      "\titers: 200, epoch: 28 | loss: 0.0667424\n",
      "\tspeed: 0.0678s/iter; left time: 1090.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 223 | Train Loss: 0.0629169 Vali Loss: 0.0616897 Test Loss: 0.0685781\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0587340\n",
      "\tspeed: 0.1462s/iter; left time: 2332.5631s\n",
      "\titers: 200, epoch: 29 | loss: 0.0614237\n",
      "\tspeed: 0.0708s/iter; left time: 1122.4167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.76s\n",
      "Steps: 223 | Train Loss: 0.0625890 Vali Loss: 0.0613700 Test Loss: 0.0676121\n",
      "Validation loss decreased (0.061495 --> 0.061370).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0621036\n",
      "\tspeed: 0.1486s/iter; left time: 2338.5079s\n",
      "\titers: 200, epoch: 30 | loss: 0.0648655\n",
      "\tspeed: 0.0684s/iter; left time: 1069.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.86s\n",
      "Steps: 223 | Train Loss: 0.0624236 Vali Loss: 0.0614864 Test Loss: 0.0679380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0625140\n",
      "\tspeed: 0.1468s/iter; left time: 2276.6825s\n",
      "\titers: 200, epoch: 31 | loss: 0.0564718\n",
      "\tspeed: 0.0673s/iter; left time: 1037.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 223 | Train Loss: 0.0625718 Vali Loss: 0.0615978 Test Loss: 0.0678042\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0582343\n",
      "\tspeed: 0.1496s/iter; left time: 2286.5908s\n",
      "\titers: 200, epoch: 32 | loss: 0.0650998\n",
      "\tspeed: 0.0677s/iter; left time: 1028.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 223 | Train Loss: 0.0622558 Vali Loss: 0.0614029 Test Loss: 0.0678051\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0616829\n",
      "\tspeed: 0.1467s/iter; left time: 2209.3432s\n",
      "\titers: 200, epoch: 33 | loss: 0.0632123\n",
      "\tspeed: 0.0686s/iter; left time: 1027.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0621625 Vali Loss: 0.0612331 Test Loss: 0.0675056\n",
      "Validation loss decreased (0.061370 --> 0.061233).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0717271\n",
      "\tspeed: 0.1531s/iter; left time: 2272.5616s\n",
      "\titers: 200, epoch: 34 | loss: 0.0640742\n",
      "\tspeed: 0.0691s/iter; left time: 1019.3406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.0621926 Vali Loss: 0.0612794 Test Loss: 0.0675092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0609190\n",
      "\tspeed: 0.1487s/iter; left time: 2174.1412s\n",
      "\titers: 200, epoch: 35 | loss: 0.0627308\n",
      "\tspeed: 0.0689s/iter; left time: 1000.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.0620256 Vali Loss: 0.0610223 Test Loss: 0.0675630\n",
      "Validation loss decreased (0.061233 --> 0.061022).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0626953\n",
      "\tspeed: 0.1508s/iter; left time: 2170.4107s\n",
      "\titers: 200, epoch: 36 | loss: 0.0595215\n",
      "\tspeed: 0.0699s/iter; left time: 998.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 223 | Train Loss: 0.0620534 Vali Loss: 0.0609994 Test Loss: 0.0674408\n",
      "Validation loss decreased (0.061022 --> 0.060999).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0593872\n",
      "\tspeed: 0.1594s/iter; left time: 2259.7659s\n",
      "\titers: 200, epoch: 37 | loss: 0.0587468\n",
      "\tspeed: 0.0699s/iter; left time: 983.1853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.0619189 Vali Loss: 0.0610188 Test Loss: 0.0673134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0653540\n",
      "\tspeed: 0.1482s/iter; left time: 2067.7550s\n",
      "\titers: 200, epoch: 38 | loss: 0.0626101\n",
      "\tspeed: 0.0692s/iter; left time: 958.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.0618971 Vali Loss: 0.0608562 Test Loss: 0.0675297\n",
      "Validation loss decreased (0.060999 --> 0.060856).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601485\n",
      "\tspeed: 0.1488s/iter; left time: 2042.4182s\n",
      "\titers: 200, epoch: 39 | loss: 0.0589575\n",
      "\tspeed: 0.0686s/iter; left time: 934.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 223 | Train Loss: 0.0618757 Vali Loss: 0.0611034 Test Loss: 0.0674044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0613604\n",
      "\tspeed: 0.1474s/iter; left time: 1990.4856s\n",
      "\titers: 200, epoch: 40 | loss: 0.0587218\n",
      "\tspeed: 0.0696s/iter; left time: 933.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.0617742 Vali Loss: 0.0608986 Test Loss: 0.0674577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0604171\n",
      "\tspeed: 0.1455s/iter; left time: 1932.5002s\n",
      "\titers: 200, epoch: 41 | loss: 0.0615327\n",
      "\tspeed: 0.0678s/iter; left time: 893.6324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.75s\n",
      "Steps: 223 | Train Loss: 0.0617817 Vali Loss: 0.0609112 Test Loss: 0.0673370\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0641001\n",
      "\tspeed: 0.1454s/iter; left time: 1898.6519s\n",
      "\titers: 200, epoch: 42 | loss: 0.0636805\n",
      "\tspeed: 0.0690s/iter; left time: 893.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0617145 Vali Loss: 0.0608887 Test Loss: 0.0672155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0631732\n",
      "\tspeed: 0.1487s/iter; left time: 1908.6367s\n",
      "\titers: 200, epoch: 43 | loss: 0.0615606\n",
      "\tspeed: 0.0694s/iter; left time: 884.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 223 | Train Loss: 0.0618979 Vali Loss: 0.0609172 Test Loss: 0.0673137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0596812\n",
      "\tspeed: 0.1481s/iter; left time: 1868.2545s\n",
      "\titers: 200, epoch: 44 | loss: 0.0577566\n",
      "\tspeed: 0.0704s/iter; left time: 881.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.0617490 Vali Loss: 0.0608585 Test Loss: 0.0672202\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0633555\n",
      "\tspeed: 0.1481s/iter; left time: 1834.7488s\n",
      "\titers: 200, epoch: 45 | loss: 0.0605994\n",
      "\tspeed: 0.0681s/iter; left time: 836.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0617130 Vali Loss: 0.0610955 Test Loss: 0.0673537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0616493\n",
      "\tspeed: 0.1470s/iter; left time: 1788.5493s\n",
      "\titers: 200, epoch: 46 | loss: 0.0615947\n",
      "\tspeed: 0.0699s/iter; left time: 843.6232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.75s\n",
      "Steps: 223 | Train Loss: 0.0619501 Vali Loss: 0.0611062 Test Loss: 0.0672512\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0622694\n",
      "\tspeed: 0.1475s/iter; left time: 1761.0375s\n",
      "\titers: 200, epoch: 47 | loss: 0.0636115\n",
      "\tspeed: 0.0685s/iter; left time: 811.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0615874 Vali Loss: 0.0609148 Test Loss: 0.0672325\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0586738\n",
      "\tspeed: 0.1433s/iter; left time: 1679.7315s\n",
      "\titers: 200, epoch: 48 | loss: 0.0646410\n",
      "\tspeed: 0.0682s/iter; left time: 792.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0616963 Vali Loss: 0.0610600 Test Loss: 0.0672489\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011974012479186058, rmse:0.10942582786083221, mae:0.06752973794937134, rse:0.41346636414527893\n",
      "Intermediate time for IT and pred_len 24: 00h:45m:03.40s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3130922\n",
      "\tspeed: 0.1071s/iter; left time: 2366.0095s\n",
      "\titers: 200, epoch: 1 | loss: 0.2826328\n",
      "\tspeed: 0.0807s/iter; left time: 1776.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.63s\n",
      "Steps: 222 | Train Loss: 0.3191913 Vali Loss: 0.2043761 Test Loss: 0.2068475\n",
      "Validation loss decreased (inf --> 0.204376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1552534\n",
      "\tspeed: 0.2477s/iter; left time: 5418.3596s\n",
      "\titers: 200, epoch: 2 | loss: 0.1267606\n",
      "\tspeed: 0.0796s/iter; left time: 1733.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.1669839 Vali Loss: 0.1084864 Test Loss: 0.1171092\n",
      "Validation loss decreased (0.204376 --> 0.108486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1176705\n",
      "\tspeed: 0.2531s/iter; left time: 5481.1864s\n",
      "\titers: 200, epoch: 3 | loss: 0.1093983\n",
      "\tspeed: 0.0825s/iter; left time: 1778.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.47s\n",
      "Steps: 222 | Train Loss: 0.1160916 Vali Loss: 0.1027744 Test Loss: 0.1127998\n",
      "Validation loss decreased (0.108486 --> 0.102774).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1057497\n",
      "\tspeed: 0.2559s/iter; left time: 5486.0754s\n",
      "\titers: 200, epoch: 4 | loss: 0.0999263\n",
      "\tspeed: 0.0825s/iter; left time: 1760.9385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.90s\n",
      "Steps: 222 | Train Loss: 0.1041803 Vali Loss: 0.0980051 Test Loss: 0.1059081\n",
      "Validation loss decreased (0.102774 --> 0.098005).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0984328\n",
      "\tspeed: 0.2529s/iter; left time: 5365.4879s\n",
      "\titers: 200, epoch: 5 | loss: 0.1018447\n",
      "\tspeed: 0.0818s/iter; left time: 1728.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.70s\n",
      "Steps: 222 | Train Loss: 0.0992825 Vali Loss: 0.0954701 Test Loss: 0.1038140\n",
      "Validation loss decreased (0.098005 --> 0.095470).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0974917\n",
      "\tspeed: 0.2575s/iter; left time: 5405.7382s\n",
      "\titers: 200, epoch: 6 | loss: 0.0927024\n",
      "\tspeed: 0.0790s/iter; left time: 1649.8178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.84s\n",
      "Steps: 222 | Train Loss: 0.0951816 Vali Loss: 0.0931792 Test Loss: 0.0988564\n",
      "Validation loss decreased (0.095470 --> 0.093179).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0933137\n",
      "\tspeed: 0.2498s/iter; left time: 5187.4967s\n",
      "\titers: 200, epoch: 7 | loss: 0.0876493\n",
      "\tspeed: 0.0815s/iter; left time: 1684.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 222 | Train Loss: 0.0924049 Vali Loss: 0.0890019 Test Loss: 0.0968176\n",
      "Validation loss decreased (0.093179 --> 0.089002).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0901376\n",
      "\tspeed: 0.2514s/iter; left time: 5166.3033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0883945\n",
      "\tspeed: 0.0815s/iter; left time: 1666.4802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.74s\n",
      "Steps: 222 | Train Loss: 0.0897358 Vali Loss: 0.0877012 Test Loss: 0.0951088\n",
      "Validation loss decreased (0.089002 --> 0.087701).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0885272\n",
      "\tspeed: 0.2499s/iter; left time: 5079.8353s\n",
      "\titers: 200, epoch: 9 | loss: 0.0910712\n",
      "\tspeed: 0.0814s/iter; left time: 1647.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.47s\n",
      "Steps: 222 | Train Loss: 0.0885593 Vali Loss: 0.0868662 Test Loss: 0.0941367\n",
      "Validation loss decreased (0.087701 --> 0.086866).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0918617\n",
      "\tspeed: 0.2504s/iter; left time: 5032.8937s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847926\n",
      "\tspeed: 0.0814s/iter; left time: 1628.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.67s\n",
      "Steps: 222 | Train Loss: 0.0871003 Vali Loss: 0.0854883 Test Loss: 0.0930210\n",
      "Validation loss decreased (0.086866 --> 0.085488).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0853291\n",
      "\tspeed: 0.2490s/iter; left time: 4950.3235s\n",
      "\titers: 200, epoch: 11 | loss: 0.0862357\n",
      "\tspeed: 0.0805s/iter; left time: 1591.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.0864315 Vali Loss: 0.0856418 Test Loss: 0.0935168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0876255\n",
      "\tspeed: 0.2578s/iter; left time: 5068.1143s\n",
      "\titers: 200, epoch: 12 | loss: 0.0839527\n",
      "\tspeed: 0.0800s/iter; left time: 1564.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.71s\n",
      "Steps: 222 | Train Loss: 0.0854076 Vali Loss: 0.0846385 Test Loss: 0.0925815\n",
      "Validation loss decreased (0.085488 --> 0.084638).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0864343\n",
      "\tspeed: 0.2531s/iter; left time: 4919.8026s\n",
      "\titers: 200, epoch: 13 | loss: 0.0840218\n",
      "\tspeed: 0.0824s/iter; left time: 1592.7260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.75s\n",
      "Steps: 222 | Train Loss: 0.0847885 Vali Loss: 0.0851022 Test Loss: 0.0929496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807046\n",
      "\tspeed: 0.2428s/iter; left time: 4665.0582s\n",
      "\titers: 200, epoch: 14 | loss: 0.0836325\n",
      "\tspeed: 0.0816s/iter; left time: 1559.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.62s\n",
      "Steps: 222 | Train Loss: 0.0837744 Vali Loss: 0.0847917 Test Loss: 0.0923458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843853\n",
      "\tspeed: 0.2488s/iter; left time: 4724.9590s\n",
      "\titers: 200, epoch: 15 | loss: 0.0836903\n",
      "\tspeed: 0.0814s/iter; left time: 1537.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.52s\n",
      "Steps: 222 | Train Loss: 0.0832851 Vali Loss: 0.0838357 Test Loss: 0.0923148\n",
      "Validation loss decreased (0.084638 --> 0.083836).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0801690\n",
      "\tspeed: 0.2541s/iter; left time: 4769.8936s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809552\n",
      "\tspeed: 0.0824s/iter; left time: 1539.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.83s\n",
      "Steps: 222 | Train Loss: 0.0827843 Vali Loss: 0.0847659 Test Loss: 0.0920603\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794494\n",
      "\tspeed: 0.2506s/iter; left time: 4649.2877s\n",
      "\titers: 200, epoch: 17 | loss: 0.0892972\n",
      "\tspeed: 0.0826s/iter; left time: 1523.5058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.85s\n",
      "Steps: 222 | Train Loss: 0.0828783 Vali Loss: 0.0842456 Test Loss: 0.0920028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0819521\n",
      "\tspeed: 0.2433s/iter; left time: 4459.4909s\n",
      "\titers: 200, epoch: 18 | loss: 0.0814238\n",
      "\tspeed: 0.0799s/iter; left time: 1456.6606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.42s\n",
      "Steps: 222 | Train Loss: 0.0819886 Vali Loss: 0.0836796 Test Loss: 0.0919602\n",
      "Validation loss decreased (0.083836 --> 0.083680).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0815278\n",
      "\tspeed: 0.2525s/iter; left time: 4572.3763s\n",
      "\titers: 200, epoch: 19 | loss: 0.0820584\n",
      "\tspeed: 0.0835s/iter; left time: 1503.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.88s\n",
      "Steps: 222 | Train Loss: 0.0820126 Vali Loss: 0.0834307 Test Loss: 0.0913969\n",
      "Validation loss decreased (0.083680 --> 0.083431).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811076\n",
      "\tspeed: 0.2523s/iter; left time: 4512.5236s\n",
      "\titers: 200, epoch: 20 | loss: 0.0849788\n",
      "\tspeed: 0.0826s/iter; left time: 1469.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0814223 Vali Loss: 0.0834076 Test Loss: 0.0913557\n",
      "Validation loss decreased (0.083431 --> 0.083408).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0797179\n",
      "\tspeed: 0.2555s/iter; left time: 4513.1888s\n",
      "\titers: 200, epoch: 21 | loss: 0.0798835\n",
      "\tspeed: 0.0811s/iter; left time: 1423.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.64s\n",
      "Steps: 222 | Train Loss: 0.0811656 Vali Loss: 0.0834606 Test Loss: 0.0914002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0806828\n",
      "\tspeed: 0.2434s/iter; left time: 4245.3203s\n",
      "\titers: 200, epoch: 22 | loss: 0.0831989\n",
      "\tspeed: 0.0821s/iter; left time: 1423.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 222 | Train Loss: 0.0809960 Vali Loss: 0.0833674 Test Loss: 0.0910961\n",
      "Validation loss decreased (0.083408 --> 0.083367).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0814777\n",
      "\tspeed: 0.2664s/iter; left time: 4587.3335s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779679\n",
      "\tspeed: 0.0817s/iter; left time: 1397.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.52s\n",
      "Steps: 222 | Train Loss: 0.0808200 Vali Loss: 0.0844102 Test Loss: 0.0918376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0831281\n",
      "\tspeed: 0.2489s/iter; left time: 4230.8719s\n",
      "\titers: 200, epoch: 24 | loss: 0.0801450\n",
      "\tspeed: 0.0827s/iter; left time: 1397.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.72s\n",
      "Steps: 222 | Train Loss: 0.0806865 Vali Loss: 0.0829902 Test Loss: 0.0907790\n",
      "Validation loss decreased (0.083367 --> 0.082990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0796960\n",
      "\tspeed: 0.2536s/iter; left time: 4253.2368s\n",
      "\titers: 200, epoch: 25 | loss: 0.0793105\n",
      "\tspeed: 0.0825s/iter; left time: 1376.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.65s\n",
      "Steps: 222 | Train Loss: 0.0804883 Vali Loss: 0.0833684 Test Loss: 0.0910721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797590\n",
      "\tspeed: 0.2477s/iter; left time: 4099.8263s\n",
      "\titers: 200, epoch: 26 | loss: 0.0765262\n",
      "\tspeed: 0.0813s/iter; left time: 1337.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.59s\n",
      "Steps: 222 | Train Loss: 0.0805376 Vali Loss: 0.0833248 Test Loss: 0.0912522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0852135\n",
      "\tspeed: 0.2455s/iter; left time: 4009.4188s\n",
      "\titers: 200, epoch: 27 | loss: 0.0829712\n",
      "\tspeed: 0.0818s/iter; left time: 1327.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0801837 Vali Loss: 0.0840229 Test Loss: 0.0918375\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0778300\n",
      "\tspeed: 0.2470s/iter; left time: 3977.7622s\n",
      "\titers: 200, epoch: 28 | loss: 0.0797916\n",
      "\tspeed: 0.0808s/iter; left time: 1293.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0800161 Vali Loss: 0.0835681 Test Loss: 0.0915399\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0779985\n",
      "\tspeed: 0.2463s/iter; left time: 3912.1521s\n",
      "\titers: 200, epoch: 29 | loss: 0.0825283\n",
      "\tspeed: 0.0798s/iter; left time: 1260.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.39s\n",
      "Steps: 222 | Train Loss: 0.0811336 Vali Loss: 0.0831605 Test Loss: 0.0906440\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0784642\n",
      "\tspeed: 0.2316s/iter; left time: 3627.5489s\n",
      "\titers: 200, epoch: 30 | loss: 0.0801490\n",
      "\tspeed: 0.0813s/iter; left time: 1265.2770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0800149 Vali Loss: 0.0829725 Test Loss: 0.0905952\n",
      "Validation loss decreased (0.082990 --> 0.082973).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0826866\n",
      "\tspeed: 0.2315s/iter; left time: 3575.2636s\n",
      "\titers: 200, epoch: 31 | loss: 0.0782782\n",
      "\tspeed: 0.0812s/iter; left time: 1245.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.40s\n",
      "Steps: 222 | Train Loss: 0.0798061 Vali Loss: 0.0830150 Test Loss: 0.0908483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0784836\n",
      "\tspeed: 0.2334s/iter; left time: 3552.5815s\n",
      "\titers: 200, epoch: 32 | loss: 0.0815519\n",
      "\tspeed: 0.0826s/iter; left time: 1248.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.72s\n",
      "Steps: 222 | Train Loss: 0.0797137 Vali Loss: 0.0836392 Test Loss: 0.0911758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0799205\n",
      "\tspeed: 0.2393s/iter; left time: 3589.4371s\n",
      "\titers: 200, epoch: 33 | loss: 0.0825075\n",
      "\tspeed: 0.0793s/iter; left time: 1181.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.35s\n",
      "Steps: 222 | Train Loss: 0.0797025 Vali Loss: 0.0831850 Test Loss: 0.0911301\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0784028\n",
      "\tspeed: 0.2298s/iter; left time: 3395.6106s\n",
      "\titers: 200, epoch: 34 | loss: 0.0799146\n",
      "\tspeed: 0.0796s/iter; left time: 1168.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.56s\n",
      "Steps: 222 | Train Loss: 0.0795820 Vali Loss: 0.0827024 Test Loss: 0.0905160\n",
      "Validation loss decreased (0.082973 --> 0.082702).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0793769\n",
      "\tspeed: 0.2383s/iter; left time: 3467.7694s\n",
      "\titers: 200, epoch: 35 | loss: 0.0835311\n",
      "\tspeed: 0.0843s/iter; left time: 1218.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.91s\n",
      "Steps: 222 | Train Loss: 0.0794909 Vali Loss: 0.0829599 Test Loss: 0.0907333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0828351\n",
      "\tspeed: 0.2371s/iter; left time: 3397.8469s\n",
      "\titers: 200, epoch: 36 | loss: 0.0814050\n",
      "\tspeed: 0.0818s/iter; left time: 1163.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.62s\n",
      "Steps: 222 | Train Loss: 0.0795782 Vali Loss: 0.0832764 Test Loss: 0.0910897\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0833048\n",
      "\tspeed: 0.2373s/iter; left time: 3347.7390s\n",
      "\titers: 200, epoch: 37 | loss: 0.0754028\n",
      "\tspeed: 0.0831s/iter; left time: 1163.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.81s\n",
      "Steps: 222 | Train Loss: 0.0793955 Vali Loss: 0.0830109 Test Loss: 0.0907957\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0807523\n",
      "\tspeed: 0.2366s/iter; left time: 3285.5934s\n",
      "\titers: 200, epoch: 38 | loss: 0.0776991\n",
      "\tspeed: 0.0817s/iter; left time: 1126.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:18.56s\n",
      "Steps: 222 | Train Loss: 0.0792896 Vali Loss: 0.0831448 Test Loss: 0.0908440\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0802488\n",
      "\tspeed: 0.2427s/iter; left time: 3316.4953s\n",
      "\titers: 200, epoch: 39 | loss: 0.0795317\n",
      "\tspeed: 0.0814s/iter; left time: 1103.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0792367 Vali Loss: 0.0831321 Test Loss: 0.0910033\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0819837\n",
      "\tspeed: 0.2392s/iter; left time: 3216.0301s\n",
      "\titers: 200, epoch: 40 | loss: 0.0812191\n",
      "\tspeed: 0.0837s/iter; left time: 1116.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0792866 Vali Loss: 0.0830535 Test Loss: 0.0910741\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799594\n",
      "\tspeed: 0.2445s/iter; left time: 3231.9868s\n",
      "\titers: 200, epoch: 41 | loss: 0.0786682\n",
      "\tspeed: 0.0809s/iter; left time: 1061.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:18.73s\n",
      "Steps: 222 | Train Loss: 0.0791508 Vali Loss: 0.0826612 Test Loss: 0.0908342\n",
      "Validation loss decreased (0.082702 --> 0.082661).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0791496\n",
      "\tspeed: 0.2467s/iter; left time: 3207.3073s\n",
      "\titers: 200, epoch: 42 | loss: 0.0815903\n",
      "\tspeed: 0.0830s/iter; left time: 1070.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0792590 Vali Loss: 0.0829599 Test Loss: 0.0905986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0814198\n",
      "\tspeed: 0.2416s/iter; left time: 3086.7081s\n",
      "\titers: 200, epoch: 43 | loss: 0.0770012\n",
      "\tspeed: 0.0819s/iter; left time: 1038.1007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 222 | Train Loss: 0.0792072 Vali Loss: 0.0828279 Test Loss: 0.0907574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0777081\n",
      "\tspeed: 0.2342s/iter; left time: 2940.2364s\n",
      "\titers: 200, epoch: 44 | loss: 0.0755225\n",
      "\tspeed: 0.0807s/iter; left time: 1004.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0795291 Vali Loss: 0.0829565 Test Loss: 0.0907021\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0831333\n",
      "\tspeed: 0.2335s/iter; left time: 2879.2292s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806822\n",
      "\tspeed: 0.0784s/iter; left time: 958.5636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 222 | Train Loss: 0.0804049 Vali Loss: 0.0864182 Test Loss: 0.0922671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0801575\n",
      "\tspeed: 0.2382s/iter; left time: 2884.7750s\n",
      "\titers: 200, epoch: 46 | loss: 0.0798439\n",
      "\tspeed: 0.0812s/iter; left time: 974.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:18.56s\n",
      "Steps: 222 | Train Loss: 0.0791839 Vali Loss: 0.0832634 Test Loss: 0.0908443\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0777465\n",
      "\tspeed: 0.2395s/iter; left time: 2847.0946s\n",
      "\titers: 200, epoch: 47 | loss: 0.0761843\n",
      "\tspeed: 0.0796s/iter; left time: 937.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.0790934 Vali Loss: 0.0828497 Test Loss: 0.0906211\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0812373\n",
      "\tspeed: 0.2268s/iter; left time: 2646.5651s\n",
      "\titers: 200, epoch: 48 | loss: 0.0805614\n",
      "\tspeed: 0.0792s/iter; left time: 916.6247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:18.00s\n",
      "Steps: 222 | Train Loss: 0.0792312 Vali Loss: 0.0828834 Test Loss: 0.0906922\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0814086\n",
      "\tspeed: 0.2265s/iter; left time: 2592.2600s\n",
      "\titers: 200, epoch: 49 | loss: 0.0779836\n",
      "\tspeed: 0.0788s/iter; left time: 893.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:17.77s\n",
      "Steps: 222 | Train Loss: 0.0790788 Vali Loss: 0.0827337 Test Loss: 0.0904543\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0806521\n",
      "\tspeed: 0.2342s/iter; left time: 2628.6679s\n",
      "\titers: 200, epoch: 50 | loss: 0.0733809\n",
      "\tspeed: 0.0808s/iter; left time: 898.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:18.49s\n",
      "Steps: 222 | Train Loss: 0.0801234 Vali Loss: 0.0828451 Test Loss: 0.0905353\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0770669\n",
      "\tspeed: 0.2283s/iter; left time: 2511.6846s\n",
      "\titers: 200, epoch: 51 | loss: 0.0788063\n",
      "\tspeed: 0.0813s/iter; left time: 886.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0791742 Vali Loss: 0.0829623 Test Loss: 0.0906640\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021717922762036324, rmse:0.14737002551555634, mae:0.0908341109752655, rse:0.5572219491004944\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3135213\n",
      "\tspeed: 0.0845s/iter; left time: 1867.2998s\n",
      "\titers: 200, epoch: 1 | loss: 0.2811470\n",
      "\tspeed: 0.0798s/iter; left time: 1755.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.3185121 Vali Loss: 0.2114613 Test Loss: 0.2121233\n",
      "Validation loss decreased (inf --> 0.211461).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1653308\n",
      "\tspeed: 0.2309s/iter; left time: 5052.8310s\n",
      "\titers: 200, epoch: 2 | loss: 0.1291139\n",
      "\tspeed: 0.0802s/iter; left time: 1747.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.98s\n",
      "Steps: 222 | Train Loss: 0.1702107 Vali Loss: 0.1087140 Test Loss: 0.1184213\n",
      "Validation loss decreased (0.211461 --> 0.108714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1129906\n",
      "\tspeed: 0.2234s/iter; left time: 4839.1144s\n",
      "\titers: 200, epoch: 3 | loss: 0.1145398\n",
      "\tspeed: 0.0796s/iter; left time: 1715.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 222 | Train Loss: 0.1158845 Vali Loss: 0.1046834 Test Loss: 0.1149104\n",
      "Validation loss decreased (0.108714 --> 0.104683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1008113\n",
      "\tspeed: 0.2286s/iter; left time: 4900.9623s\n",
      "\titers: 200, epoch: 4 | loss: 0.1015295\n",
      "\tspeed: 0.0798s/iter; left time: 1701.9827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.1037044 Vali Loss: 0.0973755 Test Loss: 0.1074035\n",
      "Validation loss decreased (0.104683 --> 0.097375).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0976065\n",
      "\tspeed: 0.2316s/iter; left time: 4913.8937s\n",
      "\titers: 200, epoch: 5 | loss: 0.0974823\n",
      "\tspeed: 0.0804s/iter; left time: 1698.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0982611 Vali Loss: 0.0991202 Test Loss: 0.1092437\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0988224\n",
      "\tspeed: 0.2374s/iter; left time: 4983.0058s\n",
      "\titers: 200, epoch: 6 | loss: 0.0932378\n",
      "\tspeed: 0.0793s/iter; left time: 1655.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0953010 Vali Loss: 0.0947269 Test Loss: 0.1055762\n",
      "Validation loss decreased (0.097375 --> 0.094727).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0900012\n",
      "\tspeed: 0.2341s/iter; left time: 4861.6774s\n",
      "\titers: 200, epoch: 7 | loss: 0.0906652\n",
      "\tspeed: 0.0808s/iter; left time: 1669.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0927117 Vali Loss: 0.0895454 Test Loss: 0.0993515\n",
      "Validation loss decreased (0.094727 --> 0.089545).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0900130\n",
      "\tspeed: 0.2241s/iter; left time: 4604.0947s\n",
      "\titers: 200, epoch: 8 | loss: 0.0830589\n",
      "\tspeed: 0.0789s/iter; left time: 1613.9692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0895318 Vali Loss: 0.0863370 Test Loss: 0.0957899\n",
      "Validation loss decreased (0.089545 --> 0.086337).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0851863\n",
      "\tspeed: 0.2353s/iter; left time: 4781.8518s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863295\n",
      "\tspeed: 0.0773s/iter; left time: 1563.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 222 | Train Loss: 0.0880755 Vali Loss: 0.0867589 Test Loss: 0.0968130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0893650\n",
      "\tspeed: 0.2297s/iter; left time: 4617.5678s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848142\n",
      "\tspeed: 0.0806s/iter; left time: 1611.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.35s\n",
      "Steps: 222 | Train Loss: 0.0872269 Vali Loss: 0.0866672 Test Loss: 0.0953489\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0897547\n",
      "\tspeed: 0.2458s/iter; left time: 4885.8946s\n",
      "\titers: 200, epoch: 11 | loss: 0.0856476\n",
      "\tspeed: 0.0825s/iter; left time: 1631.2380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.52s\n",
      "Steps: 222 | Train Loss: 0.0862877 Vali Loss: 0.0846953 Test Loss: 0.0945947\n",
      "Validation loss decreased (0.086337 --> 0.084695).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0835404\n",
      "\tspeed: 0.2379s/iter; left time: 4677.6621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0825640\n",
      "\tspeed: 0.0779s/iter; left time: 1524.0962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.97s\n",
      "Steps: 222 | Train Loss: 0.0854445 Vali Loss: 0.0850919 Test Loss: 0.0941640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0819590\n",
      "\tspeed: 0.2341s/iter; left time: 4550.4651s\n",
      "\titers: 200, epoch: 13 | loss: 0.0867308\n",
      "\tspeed: 0.0807s/iter; left time: 1560.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 222 | Train Loss: 0.0845167 Vali Loss: 0.0854208 Test Loss: 0.0954410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0889176\n",
      "\tspeed: 0.2336s/iter; left time: 4488.8274s\n",
      "\titers: 200, epoch: 14 | loss: 0.0847628\n",
      "\tspeed: 0.0792s/iter; left time: 1513.6906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0850860 Vali Loss: 0.0857253 Test Loss: 0.0945202\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0883109\n",
      "\tspeed: 0.2284s/iter; left time: 4337.5978s\n",
      "\titers: 200, epoch: 15 | loss: 0.0867382\n",
      "\tspeed: 0.0802s/iter; left time: 1514.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.0838545 Vali Loss: 0.0838575 Test Loss: 0.0931543\n",
      "Validation loss decreased (0.084695 --> 0.083857).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0808563\n",
      "\tspeed: 0.2327s/iter; left time: 4368.2331s\n",
      "\titers: 200, epoch: 16 | loss: 0.0826057\n",
      "\tspeed: 0.0807s/iter; left time: 1506.5946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 222 | Train Loss: 0.0833988 Vali Loss: 0.0846205 Test Loss: 0.0943471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0822492\n",
      "\tspeed: 0.2257s/iter; left time: 4186.6901s\n",
      "\titers: 200, epoch: 17 | loss: 0.0859817\n",
      "\tspeed: 0.0799s/iter; left time: 1474.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0828703 Vali Loss: 0.0839873 Test Loss: 0.0932608\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0792298\n",
      "\tspeed: 0.2316s/iter; left time: 4244.1737s\n",
      "\titers: 200, epoch: 18 | loss: 0.0762839\n",
      "\tspeed: 0.0811s/iter; left time: 1477.7354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.41s\n",
      "Steps: 222 | Train Loss: 0.0822131 Vali Loss: 0.0832047 Test Loss: 0.0924758\n",
      "Validation loss decreased (0.083857 --> 0.083205).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0850370\n",
      "\tspeed: 0.2394s/iter; left time: 4334.3414s\n",
      "\titers: 200, epoch: 19 | loss: 0.0800431\n",
      "\tspeed: 0.0784s/iter; left time: 1412.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0822159 Vali Loss: 0.0840704 Test Loss: 0.0931746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0810618\n",
      "\tspeed: 0.2367s/iter; left time: 4232.9301s\n",
      "\titers: 200, epoch: 20 | loss: 0.0838140\n",
      "\tspeed: 0.0805s/iter; left time: 1430.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.0816532 Vali Loss: 0.0854880 Test Loss: 0.0948618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0833068\n",
      "\tspeed: 0.2357s/iter; left time: 4162.4050s\n",
      "\titers: 200, epoch: 21 | loss: 0.0843016\n",
      "\tspeed: 0.0795s/iter; left time: 1395.4824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0814112 Vali Loss: 0.0837320 Test Loss: 0.0926929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0808938\n",
      "\tspeed: 0.2369s/iter; left time: 4131.4107s\n",
      "\titers: 200, epoch: 22 | loss: 0.0802129\n",
      "\tspeed: 0.0822s/iter; left time: 1425.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.75s\n",
      "Steps: 222 | Train Loss: 0.0813304 Vali Loss: 0.0835493 Test Loss: 0.0925938\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0804346\n",
      "\tspeed: 0.2370s/iter; left time: 4079.9816s\n",
      "\titers: 200, epoch: 23 | loss: 0.0777670\n",
      "\tspeed: 0.0796s/iter; left time: 1361.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 222 | Train Loss: 0.0809774 Vali Loss: 0.0847672 Test Loss: 0.0941237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0796417\n",
      "\tspeed: 0.2343s/iter; left time: 3982.6039s\n",
      "\titers: 200, epoch: 24 | loss: 0.0862155\n",
      "\tspeed: 0.0811s/iter; left time: 1370.1702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.53s\n",
      "Steps: 222 | Train Loss: 0.0809474 Vali Loss: 0.0839485 Test Loss: 0.0929867\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0859836\n",
      "\tspeed: 0.2357s/iter; left time: 3953.8865s\n",
      "\titers: 200, epoch: 25 | loss: 0.0813211\n",
      "\tspeed: 0.0791s/iter; left time: 1319.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 222 | Train Loss: 0.0810300 Vali Loss: 0.0836985 Test Loss: 0.0930768\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0778468\n",
      "\tspeed: 0.2323s/iter; left time: 3843.9903s\n",
      "\titers: 200, epoch: 26 | loss: 0.0770056\n",
      "\tspeed: 0.0786s/iter; left time: 1293.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.00s\n",
      "Steps: 222 | Train Loss: 0.0806082 Vali Loss: 0.0841872 Test Loss: 0.0931642\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818449\n",
      "\tspeed: 0.2263s/iter; left time: 3694.8483s\n",
      "\titers: 200, epoch: 27 | loss: 0.0819638\n",
      "\tspeed: 0.0779s/iter; left time: 1264.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.93s\n",
      "Steps: 222 | Train Loss: 0.0803380 Vali Loss: 0.0834874 Test Loss: 0.0925321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0812165\n",
      "\tspeed: 0.2340s/iter; left time: 3768.8595s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777621\n",
      "\tspeed: 0.0826s/iter; left time: 1321.5320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.52s\n",
      "Steps: 222 | Train Loss: 0.0803338 Vali Loss: 0.0846255 Test Loss: 0.0942652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023094583302736282, rmse:0.15196901559829712, mae:0.0924757793545723, rse:0.574611246585846\n",
      "Intermediate time for IT and pred_len 96: 00h:42m:35.71s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3109741\n",
      "\tspeed: 0.1088s/iter; left time: 2404.6748s\n",
      "\titers: 200, epoch: 1 | loss: 0.2823882\n",
      "\tspeed: 0.0827s/iter; left time: 1819.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.03s\n",
      "Steps: 222 | Train Loss: 0.3167825 Vali Loss: 0.2031002 Test Loss: 0.2052116\n",
      "Validation loss decreased (inf --> 0.203100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1469899\n",
      "\tspeed: 0.2521s/iter; left time: 5515.5031s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273562\n",
      "\tspeed: 0.0805s/iter; left time: 1754.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.77s\n",
      "Steps: 222 | Train Loss: 0.1627422 Vali Loss: 0.1107211 Test Loss: 0.1185251\n",
      "Validation loss decreased (0.203100 --> 0.110721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1172981\n",
      "\tspeed: 0.2477s/iter; left time: 5363.7811s\n",
      "\titers: 200, epoch: 3 | loss: 0.1141733\n",
      "\tspeed: 0.0822s/iter; left time: 1772.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.86s\n",
      "Steps: 222 | Train Loss: 0.1171229 Vali Loss: 0.1083225 Test Loss: 0.1176304\n",
      "Validation loss decreased (0.110721 --> 0.108323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1042999\n",
      "\tspeed: 0.2456s/iter; left time: 5265.3225s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028230\n",
      "\tspeed: 0.0794s/iter; left time: 1693.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 222 | Train Loss: 0.1063326 Vali Loss: 0.1022138 Test Loss: 0.1121554\n",
      "Validation loss decreased (0.108323 --> 0.102214).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1075132\n",
      "\tspeed: 0.2533s/iter; left time: 5373.9383s\n",
      "\titers: 200, epoch: 5 | loss: 0.1017513\n",
      "\tspeed: 0.0842s/iter; left time: 1776.8107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.15s\n",
      "Steps: 222 | Train Loss: 0.1025214 Vali Loss: 0.0987371 Test Loss: 0.1096365\n",
      "Validation loss decreased (0.102214 --> 0.098737).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0999532\n",
      "\tspeed: 0.2470s/iter; left time: 5184.2750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0985696\n",
      "\tspeed: 0.0813s/iter; left time: 1699.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.56s\n",
      "Steps: 222 | Train Loss: 0.0981996 Vali Loss: 0.0956033 Test Loss: 0.1047943\n",
      "Validation loss decreased (0.098737 --> 0.095603).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0924472\n",
      "\tspeed: 0.2499s/iter; left time: 5189.2393s\n",
      "\titers: 200, epoch: 7 | loss: 0.0990806\n",
      "\tspeed: 0.0802s/iter; left time: 1657.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.63s\n",
      "Steps: 222 | Train Loss: 0.0966461 Vali Loss: 0.0945129 Test Loss: 0.1035598\n",
      "Validation loss decreased (0.095603 --> 0.094513).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0929514\n",
      "\tspeed: 0.2448s/iter; left time: 5029.9001s\n",
      "\titers: 200, epoch: 8 | loss: 0.0919465\n",
      "\tspeed: 0.0811s/iter; left time: 1657.9454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.0937142 Vali Loss: 0.0952936 Test Loss: 0.1035536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0931704\n",
      "\tspeed: 0.2445s/iter; left time: 4968.7367s\n",
      "\titers: 200, epoch: 9 | loss: 0.0896324\n",
      "\tspeed: 0.0836s/iter; left time: 1690.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.73s\n",
      "Steps: 222 | Train Loss: 0.0920714 Vali Loss: 0.0937590 Test Loss: 0.1026701\n",
      "Validation loss decreased (0.094513 --> 0.093759).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0904943\n",
      "\tspeed: 0.2404s/iter; left time: 4833.3864s\n",
      "\titers: 200, epoch: 10 | loss: 0.0983694\n",
      "\tspeed: 0.0795s/iter; left time: 1590.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0910471 Vali Loss: 0.0915905 Test Loss: 0.0986122\n",
      "Validation loss decreased (0.093759 --> 0.091591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0903660\n",
      "\tspeed: 0.2521s/iter; left time: 5011.4139s\n",
      "\titers: 200, epoch: 11 | loss: 0.0951513\n",
      "\tspeed: 0.0809s/iter; left time: 1600.2894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0901966 Vali Loss: 0.0956823 Test Loss: 0.1044712\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880594\n",
      "\tspeed: 0.2457s/iter; left time: 4830.0979s\n",
      "\titers: 200, epoch: 12 | loss: 0.0874354\n",
      "\tspeed: 0.0817s/iter; left time: 1597.8307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.60s\n",
      "Steps: 222 | Train Loss: 0.0890195 Vali Loss: 0.0935607 Test Loss: 0.1016287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0856746\n",
      "\tspeed: 0.2494s/iter; left time: 4847.4817s\n",
      "\titers: 200, epoch: 13 | loss: 0.0885840\n",
      "\tspeed: 0.0810s/iter; left time: 1566.7623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0881420 Vali Loss: 0.0904126 Test Loss: 0.0983857\n",
      "Validation loss decreased (0.091591 --> 0.090413).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0896218\n",
      "\tspeed: 0.2455s/iter; left time: 4717.3016s\n",
      "\titers: 200, epoch: 14 | loss: 0.0894883\n",
      "\tspeed: 0.0812s/iter; left time: 1551.9743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.81s\n",
      "Steps: 222 | Train Loss: 0.0880211 Vali Loss: 0.0924693 Test Loss: 0.1002803\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0906211\n",
      "\tspeed: 0.2482s/iter; left time: 4714.3418s\n",
      "\titers: 200, epoch: 15 | loss: 0.0850691\n",
      "\tspeed: 0.0842s/iter; left time: 1590.7490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.87s\n",
      "Steps: 222 | Train Loss: 0.0871348 Vali Loss: 0.0900645 Test Loss: 0.0966765\n",
      "Validation loss decreased (0.090413 --> 0.090064).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0876706\n",
      "\tspeed: 0.2423s/iter; left time: 4548.8425s\n",
      "\titers: 200, epoch: 16 | loss: 0.0836468\n",
      "\tspeed: 0.0805s/iter; left time: 1503.7614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 222 | Train Loss: 0.0869849 Vali Loss: 0.0939467 Test Loss: 0.1018619\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0831156\n",
      "\tspeed: 0.2436s/iter; left time: 4518.4468s\n",
      "\titers: 200, epoch: 17 | loss: 0.0885295\n",
      "\tspeed: 0.0801s/iter; left time: 1477.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.44s\n",
      "Steps: 222 | Train Loss: 0.0866802 Vali Loss: 0.0906632 Test Loss: 0.0975983\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0874050\n",
      "\tspeed: 0.2481s/iter; left time: 4546.7624s\n",
      "\titers: 200, epoch: 18 | loss: 0.0840936\n",
      "\tspeed: 0.0812s/iter; left time: 1479.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.65s\n",
      "Steps: 222 | Train Loss: 0.0861793 Vali Loss: 0.0931787 Test Loss: 0.1005475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0861259\n",
      "\tspeed: 0.2440s/iter; left time: 4417.8178s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836928\n",
      "\tspeed: 0.0821s/iter; left time: 1477.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 222 | Train Loss: 0.0856233 Vali Loss: 0.0906428 Test Loss: 0.0982210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0841057\n",
      "\tspeed: 0.2483s/iter; left time: 4440.9258s\n",
      "\titers: 200, epoch: 20 | loss: 0.0864164\n",
      "\tspeed: 0.0815s/iter; left time: 1449.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0854629 Vali Loss: 0.0920950 Test Loss: 0.0990837\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0873519\n",
      "\tspeed: 0.2428s/iter; left time: 4287.6485s\n",
      "\titers: 200, epoch: 21 | loss: 0.0878360\n",
      "\tspeed: 0.0819s/iter; left time: 1438.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.0852870 Vali Loss: 0.0894806 Test Loss: 0.0963093\n",
      "Validation loss decreased (0.090064 --> 0.089481).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0882937\n",
      "\tspeed: 0.2455s/iter; left time: 4281.1279s\n",
      "\titers: 200, epoch: 22 | loss: 0.0837625\n",
      "\tspeed: 0.0809s/iter; left time: 1403.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.0846753 Vali Loss: 0.0897291 Test Loss: 0.0967262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0875765\n",
      "\tspeed: 0.2424s/iter; left time: 4173.4102s\n",
      "\titers: 200, epoch: 23 | loss: 0.0853955\n",
      "\tspeed: 0.0823s/iter; left time: 1408.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.38s\n",
      "Steps: 222 | Train Loss: 0.0844371 Vali Loss: 0.0903349 Test Loss: 0.0971199\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0867649\n",
      "\tspeed: 0.2430s/iter; left time: 4130.3993s\n",
      "\titers: 200, epoch: 24 | loss: 0.0830641\n",
      "\tspeed: 0.0836s/iter; left time: 1411.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0845923 Vali Loss: 0.0900211 Test Loss: 0.0964055\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0834325\n",
      "\tspeed: 0.2366s/iter; left time: 3968.7152s\n",
      "\titers: 200, epoch: 25 | loss: 0.0824196\n",
      "\tspeed: 0.0804s/iter; left time: 1340.7456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0842612 Vali Loss: 0.0904220 Test Loss: 0.0974666\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0860807\n",
      "\tspeed: 0.2394s/iter; left time: 3962.7951s\n",
      "\titers: 200, epoch: 26 | loss: 0.0846267\n",
      "\tspeed: 0.0820s/iter; left time: 1348.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.70s\n",
      "Steps: 222 | Train Loss: 0.0840878 Vali Loss: 0.0894160 Test Loss: 0.0965679\n",
      "Validation loss decreased (0.089481 --> 0.089416).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0841266\n",
      "\tspeed: 0.2398s/iter; left time: 3915.2140s\n",
      "\titers: 200, epoch: 27 | loss: 0.0807653\n",
      "\tspeed: 0.0848s/iter; left time: 1375.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:19.09s\n",
      "Steps: 222 | Train Loss: 0.0842315 Vali Loss: 0.0905185 Test Loss: 0.0972721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0843177\n",
      "\tspeed: 0.2371s/iter; left time: 3818.7633s\n",
      "\titers: 200, epoch: 28 | loss: 0.0853737\n",
      "\tspeed: 0.0840s/iter; left time: 1344.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.59s\n",
      "Steps: 222 | Train Loss: 0.0836954 Vali Loss: 0.0894735 Test Loss: 0.0967478\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0836196\n",
      "\tspeed: 0.2355s/iter; left time: 3740.2923s\n",
      "\titers: 200, epoch: 29 | loss: 0.0819897\n",
      "\tspeed: 0.0807s/iter; left time: 1274.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0836536 Vali Loss: 0.0897608 Test Loss: 0.0965157\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0829311\n",
      "\tspeed: 0.2327s/iter; left time: 3644.4968s\n",
      "\titers: 200, epoch: 30 | loss: 0.0850719\n",
      "\tspeed: 0.0807s/iter; left time: 1256.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 222 | Train Loss: 0.0845226 Vali Loss: 0.0908146 Test Loss: 0.0977655\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0845958\n",
      "\tspeed: 0.2305s/iter; left time: 3559.0292s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813252\n",
      "\tspeed: 0.0786s/iter; left time: 1205.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0836955 Vali Loss: 0.0895962 Test Loss: 0.0966109\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0839948\n",
      "\tspeed: 0.2330s/iter; left time: 3546.1096s\n",
      "\titers: 200, epoch: 32 | loss: 0.0820418\n",
      "\tspeed: 0.0803s/iter; left time: 1214.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.35s\n",
      "Steps: 222 | Train Loss: 0.0835332 Vali Loss: 0.0890657 Test Loss: 0.0958810\n",
      "Validation loss decreased (0.089416 --> 0.089066).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0823668\n",
      "\tspeed: 0.2457s/iter; left time: 3685.4247s\n",
      "\titers: 200, epoch: 33 | loss: 0.0813329\n",
      "\tspeed: 0.0811s/iter; left time: 1208.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.0833411 Vali Loss: 0.0898129 Test Loss: 0.0965640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0828542\n",
      "\tspeed: 0.2405s/iter; left time: 3553.5777s\n",
      "\titers: 200, epoch: 34 | loss: 0.0861086\n",
      "\tspeed: 0.0815s/iter; left time: 1195.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.41s\n",
      "Steps: 222 | Train Loss: 0.0833165 Vali Loss: 0.0894889 Test Loss: 0.0960466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0837685\n",
      "\tspeed: 0.2295s/iter; left time: 3340.5310s\n",
      "\titers: 200, epoch: 35 | loss: 0.0837280\n",
      "\tspeed: 0.0796s/iter; left time: 1150.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 222 | Train Loss: 0.0832594 Vali Loss: 0.0903331 Test Loss: 0.0974072\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0818983\n",
      "\tspeed: 0.2326s/iter; left time: 3333.5012s\n",
      "\titers: 200, epoch: 36 | loss: 0.0853202\n",
      "\tspeed: 0.0791s/iter; left time: 1125.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.0832802 Vali Loss: 0.0888566 Test Loss: 0.0958441\n",
      "Validation loss decreased (0.089066 --> 0.088857).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0812936\n",
      "\tspeed: 0.2350s/iter; left time: 3315.9056s\n",
      "\titers: 200, epoch: 37 | loss: 0.0828198\n",
      "\tspeed: 0.0817s/iter; left time: 1144.4884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.40s\n",
      "Steps: 222 | Train Loss: 0.0833149 Vali Loss: 0.0896610 Test Loss: 0.0962791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0784463\n",
      "\tspeed: 0.2290s/iter; left time: 3179.9689s\n",
      "\titers: 200, epoch: 38 | loss: 0.0828218\n",
      "\tspeed: 0.0798s/iter; left time: 1099.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 222 | Train Loss: 0.0831492 Vali Loss: 0.0895543 Test Loss: 0.0963492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0825896\n",
      "\tspeed: 0.2286s/iter; left time: 3124.2326s\n",
      "\titers: 200, epoch: 39 | loss: 0.0829401\n",
      "\tspeed: 0.0813s/iter; left time: 1103.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.50s\n",
      "Steps: 222 | Train Loss: 0.0830538 Vali Loss: 0.0892512 Test Loss: 0.0957472\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0831779\n",
      "\tspeed: 0.2337s/iter; left time: 3141.3310s\n",
      "\titers: 200, epoch: 40 | loss: 0.0843311\n",
      "\tspeed: 0.0796s/iter; left time: 1062.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0831599 Vali Loss: 0.0887750 Test Loss: 0.0956303\n",
      "Validation loss decreased (0.088857 --> 0.088775).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0806364\n",
      "\tspeed: 0.2408s/iter; left time: 3183.7590s\n",
      "\titers: 200, epoch: 41 | loss: 0.0840348\n",
      "\tspeed: 0.0804s/iter; left time: 1054.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.0830091 Vali Loss: 0.0890915 Test Loss: 0.0957468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0827011\n",
      "\tspeed: 0.2343s/iter; left time: 3045.7893s\n",
      "\titers: 200, epoch: 42 | loss: 0.0814546\n",
      "\tspeed: 0.0822s/iter; left time: 1060.1293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 222 | Train Loss: 0.0830361 Vali Loss: 0.0892611 Test Loss: 0.0955138\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0830465\n",
      "\tspeed: 0.2330s/iter; left time: 2977.4921s\n",
      "\titers: 200, epoch: 43 | loss: 0.0827205\n",
      "\tspeed: 0.0807s/iter; left time: 1023.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.0844546 Vali Loss: 0.0886966 Test Loss: 0.0956717\n",
      "Validation loss decreased (0.088775 --> 0.088697).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0813142\n",
      "\tspeed: 0.2310s/iter; left time: 2899.9708s\n",
      "\titers: 200, epoch: 44 | loss: 0.0858259\n",
      "\tspeed: 0.0835s/iter; left time: 1040.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.35s\n",
      "Steps: 222 | Train Loss: 0.0829409 Vali Loss: 0.0895229 Test Loss: 0.0960858\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0820556\n",
      "\tspeed: 0.2302s/iter; left time: 2839.2581s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806135\n",
      "\tspeed: 0.0806s/iter; left time: 985.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.43s\n",
      "Steps: 222 | Train Loss: 0.0829226 Vali Loss: 0.0894153 Test Loss: 0.0960841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0848742\n",
      "\tspeed: 0.2333s/iter; left time: 2825.1903s\n",
      "\titers: 200, epoch: 46 | loss: 0.0844084\n",
      "\tspeed: 0.0814s/iter; left time: 977.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 222 | Train Loss: 0.0828366 Vali Loss: 0.0888954 Test Loss: 0.0958521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0836546\n",
      "\tspeed: 0.2312s/iter; left time: 2749.1420s\n",
      "\titers: 200, epoch: 47 | loss: 0.0794662\n",
      "\tspeed: 0.0822s/iter; left time: 968.8447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:18.49s\n",
      "Steps: 222 | Train Loss: 0.0829801 Vali Loss: 0.0897170 Test Loss: 0.0964272\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0839570\n",
      "\tspeed: 0.2395s/iter; left time: 2793.7619s\n",
      "\titers: 200, epoch: 48 | loss: 0.0838097\n",
      "\tspeed: 0.0809s/iter; left time: 935.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.0831039 Vali Loss: 0.0892420 Test Loss: 0.0956179\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0827477\n",
      "\tspeed: 0.2315s/iter; left time: 2649.0880s\n",
      "\titers: 200, epoch: 49 | loss: 0.0792759\n",
      "\tspeed: 0.0802s/iter; left time: 909.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:18.39s\n",
      "Steps: 222 | Train Loss: 0.0829337 Vali Loss: 0.0894271 Test Loss: 0.0958593\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0818117\n",
      "\tspeed: 0.2287s/iter; left time: 2566.9410s\n",
      "\titers: 200, epoch: 50 | loss: 0.0821254\n",
      "\tspeed: 0.0828s/iter; left time: 921.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:18.64s\n",
      "Steps: 222 | Train Loss: 0.0828002 Vali Loss: 0.0890756 Test Loss: 0.0958388\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0819295\n",
      "\tspeed: 0.2392s/iter; left time: 2630.9812s\n",
      "\titers: 200, epoch: 51 | loss: 0.0809121\n",
      "\tspeed: 0.0822s/iter; left time: 895.9653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:18.43s\n",
      "Steps: 222 | Train Loss: 0.0828602 Vali Loss: 0.0892228 Test Loss: 0.0961359\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0781463\n",
      "\tspeed: 0.2377s/iter; left time: 2562.5505s\n",
      "\titers: 200, epoch: 52 | loss: 0.0880452\n",
      "\tspeed: 0.0805s/iter; left time: 859.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0828682 Vali Loss: 0.0894703 Test Loss: 0.0960248\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0832601\n",
      "\tspeed: 0.2322s/iter; left time: 2451.7903s\n",
      "\titers: 200, epoch: 53 | loss: 0.0850051\n",
      "\tspeed: 0.0809s/iter; left time: 845.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.0831755 Vali Loss: 0.0899664 Test Loss: 0.0963851\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02344098873436451, rmse:0.1531044989824295, mae:0.09567169100046158, rse:0.57944256067276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3085628\n",
      "\tspeed: 0.0832s/iter; left time: 1837.7393s\n",
      "\titers: 200, epoch: 1 | loss: 0.2786329\n",
      "\tspeed: 0.0825s/iter; left time: 1814.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.43s\n",
      "Steps: 222 | Train Loss: 0.3179028 Vali Loss: 0.2043559 Test Loss: 0.2051000\n",
      "Validation loss decreased (inf --> 0.204356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1444073\n",
      "\tspeed: 0.2334s/iter; left time: 5107.0435s\n",
      "\titers: 200, epoch: 2 | loss: 0.1248629\n",
      "\tspeed: 0.0810s/iter; left time: 1764.5380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1624812 Vali Loss: 0.1114071 Test Loss: 0.1177436\n",
      "Validation loss decreased (0.204356 --> 0.111407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1140958\n",
      "\tspeed: 0.2314s/iter; left time: 5011.5812s\n",
      "\titers: 200, epoch: 3 | loss: 0.1055452\n",
      "\tspeed: 0.0805s/iter; left time: 1734.8910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.1153163 Vali Loss: 0.1046516 Test Loss: 0.1136357\n",
      "Validation loss decreased (0.111407 --> 0.104652).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1048699\n",
      "\tspeed: 0.2358s/iter; left time: 5053.4267s\n",
      "\titers: 200, epoch: 4 | loss: 0.1014883\n",
      "\tspeed: 0.0803s/iter; left time: 1712.2189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.1056073 Vali Loss: 0.1051555 Test Loss: 0.1152054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1015453\n",
      "\tspeed: 0.2341s/iter; left time: 4966.5491s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977719\n",
      "\tspeed: 0.0835s/iter; left time: 1763.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.67s\n",
      "Steps: 222 | Train Loss: 0.0998458 Vali Loss: 0.1004166 Test Loss: 0.1102150\n",
      "Validation loss decreased (0.104652 --> 0.100417).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932037\n",
      "\tspeed: 0.2376s/iter; left time: 4987.4486s\n",
      "\titers: 200, epoch: 6 | loss: 0.0963123\n",
      "\tspeed: 0.0830s/iter; left time: 1733.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 222 | Train Loss: 0.0974160 Vali Loss: 0.0943234 Test Loss: 0.1007721\n",
      "Validation loss decreased (0.100417 --> 0.094323).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0959413\n",
      "\tspeed: 0.2272s/iter; left time: 4717.8599s\n",
      "\titers: 200, epoch: 7 | loss: 0.0950046\n",
      "\tspeed: 0.0807s/iter; left time: 1668.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.41s\n",
      "Steps: 222 | Train Loss: 0.0949773 Vali Loss: 0.0923092 Test Loss: 0.1012633\n",
      "Validation loss decreased (0.094323 --> 0.092309).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0940812\n",
      "\tspeed: 0.2321s/iter; left time: 4768.9355s\n",
      "\titers: 200, epoch: 8 | loss: 0.0908630\n",
      "\tspeed: 0.0821s/iter; left time: 1678.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.62s\n",
      "Steps: 222 | Train Loss: 0.0929221 Vali Loss: 0.0925586 Test Loss: 0.1010430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0885212\n",
      "\tspeed: 0.2383s/iter; left time: 4842.8903s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885545\n",
      "\tspeed: 0.0807s/iter; left time: 1632.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.61s\n",
      "Steps: 222 | Train Loss: 0.0912116 Vali Loss: 0.0931785 Test Loss: 0.0996042\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0922641\n",
      "\tspeed: 0.2351s/iter; left time: 4726.2629s\n",
      "\titers: 200, epoch: 10 | loss: 0.0919619\n",
      "\tspeed: 0.0819s/iter; left time: 1638.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.0906186 Vali Loss: 0.0911927 Test Loss: 0.0996748\n",
      "Validation loss decreased (0.092309 --> 0.091193).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0879117\n",
      "\tspeed: 0.2277s/iter; left time: 4526.3771s\n",
      "\titers: 200, epoch: 11 | loss: 0.0838486\n",
      "\tspeed: 0.0817s/iter; left time: 1617.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 222 | Train Loss: 0.0891499 Vali Loss: 0.0889446 Test Loss: 0.0958121\n",
      "Validation loss decreased (0.091193 --> 0.088945).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0935280\n",
      "\tspeed: 0.2309s/iter; left time: 4540.1582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0897502\n",
      "\tspeed: 0.0812s/iter; left time: 1587.8792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.48s\n",
      "Steps: 222 | Train Loss: 0.0885820 Vali Loss: 0.0897628 Test Loss: 0.0956240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0902725\n",
      "\tspeed: 0.2217s/iter; left time: 4309.7149s\n",
      "\titers: 200, epoch: 13 | loss: 0.0858601\n",
      "\tspeed: 0.0797s/iter; left time: 1540.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:17.87s\n",
      "Steps: 222 | Train Loss: 0.0876505 Vali Loss: 0.0911276 Test Loss: 0.0989656\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0901316\n",
      "\tspeed: 0.2331s/iter; left time: 4479.2756s\n",
      "\titers: 200, epoch: 14 | loss: 0.0880188\n",
      "\tspeed: 0.0793s/iter; left time: 1516.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0873168 Vali Loss: 0.0927043 Test Loss: 0.0994292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869107\n",
      "\tspeed: 0.2337s/iter; left time: 4438.9520s\n",
      "\titers: 200, epoch: 15 | loss: 0.0851567\n",
      "\tspeed: 0.0790s/iter; left time: 1492.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.48s\n",
      "Steps: 222 | Train Loss: 0.0868292 Vali Loss: 0.0911027 Test Loss: 0.0981385\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0847946\n",
      "\tspeed: 0.2394s/iter; left time: 4493.0696s\n",
      "\titers: 200, epoch: 16 | loss: 0.0853209\n",
      "\tspeed: 0.0799s/iter; left time: 1492.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.38s\n",
      "Steps: 222 | Train Loss: 0.0860680 Vali Loss: 0.0890825 Test Loss: 0.0960092\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848370\n",
      "\tspeed: 0.2323s/iter; left time: 4308.7195s\n",
      "\titers: 200, epoch: 17 | loss: 0.0884931\n",
      "\tspeed: 0.0814s/iter; left time: 1501.6083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.42s\n",
      "Steps: 222 | Train Loss: 0.0855806 Vali Loss: 0.0918930 Test Loss: 0.0983663\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0853238\n",
      "\tspeed: 0.2309s/iter; left time: 4231.1149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0800371\n",
      "\tspeed: 0.0813s/iter; left time: 1482.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0849911 Vali Loss: 0.0918497 Test Loss: 0.0987511\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0866086\n",
      "\tspeed: 0.2341s/iter; left time: 4237.7718s\n",
      "\titers: 200, epoch: 19 | loss: 0.0875820\n",
      "\tspeed: 0.0805s/iter; left time: 1449.6704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.48s\n",
      "Steps: 222 | Train Loss: 0.0850294 Vali Loss: 0.0900050 Test Loss: 0.0965587\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0857767\n",
      "\tspeed: 0.2334s/iter; left time: 4174.3064s\n",
      "\titers: 200, epoch: 20 | loss: 0.0866517\n",
      "\tspeed: 0.0807s/iter; left time: 1434.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 222 | Train Loss: 0.0851922 Vali Loss: 0.0885900 Test Loss: 0.0955357\n",
      "Validation loss decreased (0.088945 --> 0.088590).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0852295\n",
      "\tspeed: 0.2273s/iter; left time: 4014.0877s\n",
      "\titers: 200, epoch: 21 | loss: 0.0802506\n",
      "\tspeed: 0.0805s/iter; left time: 1413.9601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0843377 Vali Loss: 0.0898651 Test Loss: 0.0965669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0816108\n",
      "\tspeed: 0.2258s/iter; left time: 3937.0280s\n",
      "\titers: 200, epoch: 22 | loss: 0.0814953\n",
      "\tspeed: 0.0807s/iter; left time: 1398.9759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 222 | Train Loss: 0.0839931 Vali Loss: 0.0896459 Test Loss: 0.0958456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0849289\n",
      "\tspeed: 0.2394s/iter; left time: 4121.6229s\n",
      "\titers: 200, epoch: 23 | loss: 0.0832678\n",
      "\tspeed: 0.0816s/iter; left time: 1397.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.44s\n",
      "Steps: 222 | Train Loss: 0.0835867 Vali Loss: 0.0885401 Test Loss: 0.0946557\n",
      "Validation loss decreased (0.088590 --> 0.088540).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0824149\n",
      "\tspeed: 0.2310s/iter; left time: 3925.5478s\n",
      "\titers: 200, epoch: 24 | loss: 0.0824317\n",
      "\tspeed: 0.0803s/iter; left time: 1356.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:17.93s\n",
      "Steps: 222 | Train Loss: 0.0836082 Vali Loss: 0.0896063 Test Loss: 0.0955665\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0820272\n",
      "\tspeed: 0.2301s/iter; left time: 3860.2007s\n",
      "\titers: 200, epoch: 25 | loss: 0.0813944\n",
      "\tspeed: 0.0780s/iter; left time: 1300.4451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0833690 Vali Loss: 0.0890054 Test Loss: 0.0949794\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0857243\n",
      "\tspeed: 0.2350s/iter; left time: 3888.8319s\n",
      "\titers: 200, epoch: 26 | loss: 0.0824702\n",
      "\tspeed: 0.0804s/iter; left time: 1322.0710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0833347 Vali Loss: 0.0888657 Test Loss: 0.0950487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0832301\n",
      "\tspeed: 0.2271s/iter; left time: 3708.2397s\n",
      "\titers: 200, epoch: 27 | loss: 0.0825357\n",
      "\tspeed: 0.0792s/iter; left time: 1285.6476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.94s\n",
      "Steps: 222 | Train Loss: 0.0831151 Vali Loss: 0.0892281 Test Loss: 0.0952485\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0816448\n",
      "\tspeed: 0.2256s/iter; left time: 3633.2450s\n",
      "\titers: 200, epoch: 28 | loss: 0.0841849\n",
      "\tspeed: 0.0793s/iter; left time: 1268.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:17.75s\n",
      "Steps: 222 | Train Loss: 0.0828813 Vali Loss: 0.0885394 Test Loss: 0.0946663\n",
      "Validation loss decreased (0.088540 --> 0.088539).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0828489\n",
      "\tspeed: 0.2209s/iter; left time: 3508.2206s\n",
      "\titers: 200, epoch: 29 | loss: 0.0849947\n",
      "\tspeed: 0.0775s/iter; left time: 1223.4119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:17.78s\n",
      "Steps: 222 | Train Loss: 0.0829329 Vali Loss: 0.0894948 Test Loss: 0.0951794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0837688\n",
      "\tspeed: 0.2267s/iter; left time: 3550.2672s\n",
      "\titers: 200, epoch: 30 | loss: 0.0804335\n",
      "\tspeed: 0.0801s/iter; left time: 1246.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 222 | Train Loss: 0.0825426 Vali Loss: 0.0883289 Test Loss: 0.0940077\n",
      "Validation loss decreased (0.088539 --> 0.088329).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0815321\n",
      "\tspeed: 0.2232s/iter; left time: 3446.9592s\n",
      "\titers: 200, epoch: 31 | loss: 0.0826478\n",
      "\tspeed: 0.0803s/iter; left time: 1232.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 222 | Train Loss: 0.0824390 Vali Loss: 0.0889106 Test Loss: 0.0947147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0862166\n",
      "\tspeed: 0.2181s/iter; left time: 3318.5289s\n",
      "\titers: 200, epoch: 32 | loss: 0.0821154\n",
      "\tspeed: 0.0774s/iter; left time: 1170.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:17.57s\n",
      "Steps: 222 | Train Loss: 0.0825017 Vali Loss: 0.0885425 Test Loss: 0.0945260\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0825291\n",
      "\tspeed: 0.2253s/iter; left time: 3378.2970s\n",
      "\titers: 200, epoch: 33 | loss: 0.0832232\n",
      "\tspeed: 0.0799s/iter; left time: 1189.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0823236 Vali Loss: 0.0895804 Test Loss: 0.0951618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0811145\n",
      "\tspeed: 0.2311s/iter; left time: 3413.9538s\n",
      "\titers: 200, epoch: 34 | loss: 0.0851298\n",
      "\tspeed: 0.0794s/iter; left time: 1164.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.0824539 Vali Loss: 0.0898905 Test Loss: 0.0956077\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0818197\n",
      "\tspeed: 0.2320s/iter; left time: 3376.9330s\n",
      "\titers: 200, epoch: 35 | loss: 0.0838067\n",
      "\tspeed: 0.0778s/iter; left time: 1124.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0823022 Vali Loss: 0.0882039 Test Loss: 0.0943955\n",
      "Validation loss decreased (0.088329 --> 0.088204).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0772994\n",
      "\tspeed: 0.2335s/iter; left time: 3345.8292s\n",
      "\titers: 200, epoch: 36 | loss: 0.0809073\n",
      "\tspeed: 0.0788s/iter; left time: 1120.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0821640 Vali Loss: 0.0889858 Test Loss: 0.0951757\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0861195\n",
      "\tspeed: 0.2337s/iter; left time: 3297.3993s\n",
      "\titers: 200, epoch: 37 | loss: 0.0865355\n",
      "\tspeed: 0.0809s/iter; left time: 1133.6126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.43s\n",
      "Steps: 222 | Train Loss: 0.0821603 Vali Loss: 0.0884393 Test Loss: 0.0942490\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829384\n",
      "\tspeed: 0.2281s/iter; left time: 3167.8220s\n",
      "\titers: 200, epoch: 38 | loss: 0.0808557\n",
      "\tspeed: 0.0807s/iter; left time: 1113.1989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.0820304 Vali Loss: 0.0886973 Test Loss: 0.0951028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0809725\n",
      "\tspeed: 0.2310s/iter; left time: 3156.5160s\n",
      "\titers: 200, epoch: 39 | loss: 0.0829038\n",
      "\tspeed: 0.0799s/iter; left time: 1083.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.05s\n",
      "Steps: 222 | Train Loss: 0.0821622 Vali Loss: 0.0888141 Test Loss: 0.0945857\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0811963\n",
      "\tspeed: 0.2346s/iter; left time: 3153.3794s\n",
      "\titers: 200, epoch: 40 | loss: 0.0844663\n",
      "\tspeed: 0.0768s/iter; left time: 1025.0975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:17.76s\n",
      "Steps: 222 | Train Loss: 0.0820836 Vali Loss: 0.0887664 Test Loss: 0.0946658\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0823484\n",
      "\tspeed: 0.2282s/iter; left time: 3016.4123s\n",
      "\titers: 200, epoch: 41 | loss: 0.0795124\n",
      "\tspeed: 0.0790s/iter; left time: 1036.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0821890 Vali Loss: 0.0889809 Test Loss: 0.0947750\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0848507\n",
      "\tspeed: 0.2228s/iter; left time: 2896.6641s\n",
      "\titers: 200, epoch: 42 | loss: 0.0807872\n",
      "\tspeed: 0.0785s/iter; left time: 1012.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 222 | Train Loss: 0.0824777 Vali Loss: 0.0893515 Test Loss: 0.0953588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0834802\n",
      "\tspeed: 0.2308s/iter; left time: 2948.9745s\n",
      "\titers: 200, epoch: 43 | loss: 0.0816286\n",
      "\tspeed: 0.0779s/iter; left time: 987.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:17.99s\n",
      "Steps: 222 | Train Loss: 0.0819824 Vali Loss: 0.0889366 Test Loss: 0.0949792\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0822167\n",
      "\tspeed: 0.2258s/iter; left time: 2834.6721s\n",
      "\titers: 200, epoch: 44 | loss: 0.0795184\n",
      "\tspeed: 0.0799s/iter; left time: 995.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0819388 Vali Loss: 0.0886933 Test Loss: 0.0947808\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0828562\n",
      "\tspeed: 0.2326s/iter; left time: 2868.5438s\n",
      "\titers: 200, epoch: 45 | loss: 0.0835713\n",
      "\tspeed: 0.0785s/iter; left time: 960.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0820407 Vali Loss: 0.0894555 Test Loss: 0.0955475\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02262665145099163, rmse:0.15042157471179962, mae:0.09439557790756226, rse:0.5692887306213379\n",
      "Intermediate time for IT and pred_len 168: 00h:51m:58.55s\n",
      "Intermediate time for IT: 02h:19m:37.66s\n",
      "Total time: 07h:27m:10.04s\n"
     ]
    }
   ],
   "source": [
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN + Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.2068</td>\n",
       "      <td>0.1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>0.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>0.1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            -RevIN + Decomposition                 \n",
       "Metrics                              MSE    RMSE     MAE\n",
       "Country Pred_len                                        \n",
       "DE      24                        0.0218  0.1478  0.0916\n",
       "        96                        0.0396  0.1988  0.1311\n",
       "        168                       0.0429  0.2068  0.1382\n",
       "ES      24                        0.0149  0.1186  0.0725\n",
       "        96                        0.0247  0.1556  0.1018\n",
       "        168                       0.0296  0.1698  0.1114\n",
       "FR      24                        0.0108  0.1037  0.0591\n",
       "        96                        0.0215  0.1461  0.0857\n",
       "        168                       0.0243  0.1552  0.0918\n",
       "GB      24                        0.0274  0.1653  0.1057\n",
       "        96                        0.0452  0.2123  0.1447\n",
       "        168                       0.0477  0.2181  0.1511\n",
       "IT      24                        0.0107  0.1036  0.0611\n",
       "        96                        0.0193  0.1387  0.0847\n",
       "        168                       0.0205  0.1432  0.0891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN + Decomposition '], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_no_revin_512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
