{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print / debug learning rate\n",
    "# 0.1 and cycle with simplest GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 17:07:12,425] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 17:07:13,252] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 17:07:13,252] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 17:07:13,252] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 17:07:14,051] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 17:07:14,052] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 17:07:14,582] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 17:07:14,583] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 17:07:14,583] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 17:07:14,583] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 17:07:14,583] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 17:07:14,583] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 17:07:14,584] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 17:07:14,584] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 17:07:14,584] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 17:07:14,584] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 17:07:14,891] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 17:07:14,892] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 17:07:14,892] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.55 GB, percent = 16.0%\n",
      "[2024-05-06 17:07:15,001] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 17:07:15,001] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 17:07:15,001] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.57 GB, percent = 16.0%\n",
      "[2024-05-06 17:07:15,001] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 17:07:15,103] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 17:07:15,104] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 17:07:15,104] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.57 GB, percent = 16.0%\n",
      "[2024-05-06 17:07:15,104] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 17:07:15,104] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 17:07:15,104] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 17:07:15,104] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fecd01545d0>\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 17:07:15,105] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 17:07:15,106] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.1\n",
      "lr 0.0040000000000000036\n",
      "99it [00:17,  5.91it/s]\titers: 100, epoch: 1 | loss: 0.7224666\n",
      "\tspeed: 0.2056s/iter; left time: 7613.9570s\n",
      "199it [00:34,  5.92it/s]\titers: 200, epoch: 1 | loss: 0.3539959\n",
      "\tspeed: 0.1689s/iter; left time: 6237.6663s\n",
      "299it [00:51,  5.92it/s]\titers: 300, epoch: 1 | loss: 0.3806745\n",
      "\tspeed: 0.1687s/iter; left time: 6213.2896s\n",
      "399it [01:07,  5.93it/s]\titers: 400, epoch: 1 | loss: 0.2579581\n",
      "\tspeed: 0.1687s/iter; left time: 6194.7651s\n",
      "499it [01:24,  5.94it/s]\titers: 500, epoch: 1 | loss: 0.2964526\n",
      "\tspeed: 0.1685s/iter; left time: 6171.5669s\n",
      "599it [01:41,  5.94it/s]\titers: 600, epoch: 1 | loss: 0.3597670\n",
      "\tspeed: 0.1685s/iter; left time: 6154.0386s\n",
      "699it [01:58,  5.93it/s]\titers: 700, epoch: 1 | loss: 0.5668161\n",
      "\tspeed: 0.1688s/iter; left time: 6149.8591s\n",
      "799it [02:15,  5.94it/s]\titers: 800, epoch: 1 | loss: 0.4650008\n",
      "\tspeed: 0.1684s/iter; left time: 6118.4196s\n",
      "899it [02:32,  5.94it/s]\titers: 900, epoch: 1 | loss: 0.5931702\n",
      "\tspeed: 0.1685s/iter; left time: 6104.4608s\n",
      "999it [02:49,  5.92it/s]\titers: 1000, epoch: 1 | loss: 0.4793293\n",
      "\tspeed: 0.1691s/iter; left time: 6111.3910s\n",
      "1099it [03:05,  5.91it/s]\titers: 1100, epoch: 1 | loss: 0.3929631\n",
      "\tspeed: 0.1686s/iter; left time: 6076.0536s\n",
      "1199it [03:22,  5.94it/s]\titers: 1200, epoch: 1 | loss: 0.4431814\n",
      "\tspeed: 0.1687s/iter; left time: 6059.9975s\n",
      "1299it [03:39,  5.94it/s]\titers: 1300, epoch: 1 | loss: 0.3253015\n",
      "\tspeed: 0.1688s/iter; left time: 6047.1183s\n",
      "1399it [03:56,  5.95it/s]\titers: 1400, epoch: 1 | loss: 0.4308687\n",
      "\tspeed: 0.1686s/iter; left time: 6025.2958s\n",
      "1499it [04:13,  5.92it/s]\titers: 1500, epoch: 1 | loss: 0.4591449\n",
      "\tspeed: 0.1689s/iter; left time: 6016.4771s\n",
      "1599it [04:30,  5.94it/s]\titers: 1600, epoch: 1 | loss: 0.4353184\n",
      "\tspeed: 0.1687s/iter; left time: 5994.8124s\n",
      "1699it [04:47,  5.89it/s]\titers: 1700, epoch: 1 | loss: 0.7422853\n",
      "\tspeed: 0.1696s/iter; left time: 6009.6302s\n",
      "1799it [05:04,  5.90it/s]\titers: 1800, epoch: 1 | loss: 0.3146717\n",
      "\tspeed: 0.1691s/iter; left time: 5973.6181s\n",
      "1899it [05:21,  5.92it/s]\titers: 1900, epoch: 1 | loss: 0.3456522\n",
      "\tspeed: 0.1690s/iter; left time: 5953.4737s\n",
      "1999it [05:37,  5.91it/s]\titers: 2000, epoch: 1 | loss: 0.5872148\n",
      "\tspeed: 0.1686s/iter; left time: 5921.7053s\n",
      "2099it [05:54,  5.93it/s]\titers: 2100, epoch: 1 | loss: 0.4555999\n",
      "\tspeed: 0.1688s/iter; left time: 5912.8735s\n",
      "2199it [06:11,  5.95it/s]\titers: 2200, epoch: 1 | loss: 0.2967562\n",
      "\tspeed: 0.1685s/iter; left time: 5884.7755s\n",
      "2299it [06:28,  5.90it/s]\titers: 2300, epoch: 1 | loss: 0.5006604\n",
      "\tspeed: 0.1686s/iter; left time: 5871.8408s\n",
      "2399it [06:45,  5.92it/s]\titers: 2400, epoch: 1 | loss: 0.6905553\n",
      "\tspeed: 0.1687s/iter; left time: 5859.4183s\n",
      "2499it [07:02,  5.93it/s]\titers: 2500, epoch: 1 | loss: 0.3959525\n",
      "\tspeed: 0.1688s/iter; left time: 5844.8636s\n",
      "2599it [07:19,  5.94it/s]\titers: 2600, epoch: 1 | loss: 0.2818548\n",
      "\tspeed: 0.1686s/iter; left time: 5821.2521s\n",
      "2699it [07:35,  5.92it/s]\titers: 2700, epoch: 1 | loss: 0.4867347\n",
      "\tspeed: 0.1686s/iter; left time: 5805.7968s\n",
      "2799it [07:52,  5.95it/s]\titers: 2800, epoch: 1 | loss: 0.2815517\n",
      "\tspeed: 0.1684s/iter; left time: 5782.5677s\n",
      "2899it [08:09,  5.94it/s]\titers: 2900, epoch: 1 | loss: 0.5378835\n",
      "\tspeed: 0.1685s/iter; left time: 5769.5069s\n",
      "2999it [08:26,  5.95it/s]\titers: 3000, epoch: 1 | loss: 0.2304018\n",
      "\tspeed: 0.1686s/iter; left time: 5754.8234s\n",
      "3099it [08:43,  5.95it/s]\titers: 3100, epoch: 1 | loss: 0.4641265\n",
      "\tspeed: 0.1684s/iter; left time: 5729.3047s\n",
      "3199it [09:00,  5.91it/s]\titers: 3200, epoch: 1 | loss: 0.4981674\n",
      "\tspeed: 0.1688s/iter; left time: 5726.1434s\n",
      "3299it [09:17,  5.93it/s]\titers: 3300, epoch: 1 | loss: 0.3765714\n",
      "\tspeed: 0.1692s/iter; left time: 5723.3334s\n",
      "3399it [09:34,  5.92it/s]\titers: 3400, epoch: 1 | loss: 0.4325723\n",
      "\tspeed: 0.1688s/iter; left time: 5692.3017s\n",
      "3499it [09:50,  5.94it/s]\titers: 3500, epoch: 1 | loss: 0.5126200\n",
      "\tspeed: 0.1685s/iter; left time: 5667.2014s\n",
      "3599it [10:07,  5.95it/s]\titers: 3600, epoch: 1 | loss: 0.6838058\n",
      "\tspeed: 0.1683s/iter; left time: 5644.5374s\n",
      "3699it [10:24,  5.92it/s]\titers: 3700, epoch: 1 | loss: 0.2513401\n",
      "\tspeed: 0.1685s/iter; left time: 5633.7464s\n",
      "3713it [10:27,  5.92it/s]\n",
      "Epoch: 1 cost time: 627.0013153553009\n",
      "810it [01:09, 11.71it/s]\n",
      "807it [01:08, 11.73it/s]\n",
      "Epoch: 1 | Train Loss: 0.5001839 Vali Loss: 0.5328993 Test Loss: 0.6672727 MAE Loss: 0.5869091\n",
      "lr = 0.0040000000\n",
      "Updating learning rate to 0.0040000000000000036\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0040000000000000036\n",
      "99it [00:16,  6.03it/s]\titers: 100, epoch: 2 | loss: 0.3502413\n",
      "\tspeed: 1.5828s/iter; left time: 52735.9167s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 2 | loss: 0.3360737\n",
      "\tspeed: 0.1659s/iter; left time: 5509.6415s\n",
      "299it [00:49,  6.04it/s]\titers: 300, epoch: 2 | loss: 0.4027624\n",
      "\tspeed: 0.1655s/iter; left time: 5480.0564s\n",
      "399it [01:06,  6.02it/s]\titers: 400, epoch: 2 | loss: 0.4083579\n",
      "\tspeed: 0.1655s/iter; left time: 5463.3011s\n",
      "499it [01:22,  6.02it/s]\titers: 500, epoch: 2 | loss: 0.3066200\n",
      "\tspeed: 0.1654s/iter; left time: 5445.0254s\n",
      "599it [01:39,  5.98it/s]\titers: 600, epoch: 2 | loss: 0.5876783\n",
      "\tspeed: 0.1668s/iter; left time: 5473.1187s\n",
      "699it [01:56,  6.06it/s]\titers: 700, epoch: 2 | loss: 0.2537562\n",
      "\tspeed: 0.1665s/iter; left time: 5449.0636s\n",
      "799it [02:12,  6.04it/s]\titers: 800, epoch: 2 | loss: 0.3538025\n",
      "\tspeed: 0.1654s/iter; left time: 5395.1751s\n",
      "899it [02:29,  6.06it/s]\titers: 900, epoch: 2 | loss: 0.8541349\n",
      "\tspeed: 0.1651s/iter; left time: 5370.3051s\n",
      "999it [02:45,  6.05it/s]\titers: 1000, epoch: 2 | loss: 0.1786588\n",
      "\tspeed: 0.1653s/iter; left time: 5358.2327s\n",
      "1099it [03:02,  6.06it/s]\titers: 1100, epoch: 2 | loss: 0.3696922\n",
      "\tspeed: 0.1653s/iter; left time: 5341.3842s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 2 | loss: 0.6142011\n",
      "\tspeed: 0.1652s/iter; left time: 5321.6518s\n",
      "1299it [03:35,  6.07it/s]\titers: 1300, epoch: 2 | loss: 0.2744029\n",
      "\tspeed: 0.1650s/iter; left time: 5297.8679s\n",
      "1399it [03:51,  6.07it/s]\titers: 1400, epoch: 2 | loss: 0.4276495\n",
      "\tspeed: 0.1650s/iter; left time: 5283.2627s\n",
      "1499it [04:08,  6.06it/s]\titers: 1500, epoch: 2 | loss: 0.2803231\n",
      "\tspeed: 0.1650s/iter; left time: 5267.7610s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 2 | loss: 0.7855385\n",
      "\tspeed: 0.1650s/iter; left time: 5248.5715s\n",
      "1699it [04:41,  6.07it/s]\titers: 1700, epoch: 2 | loss: 0.3895613\n",
      "\tspeed: 0.1649s/iter; left time: 5229.4781s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 2 | loss: 0.5157345\n",
      "\tspeed: 0.1653s/iter; left time: 5225.4706s\n",
      "1899it [05:14,  6.06it/s]\titers: 1900, epoch: 2 | loss: 0.4659766\n",
      "\tspeed: 0.1650s/iter; left time: 5198.9796s\n",
      "1999it [05:30,  6.05it/s]\titers: 2000, epoch: 2 | loss: 0.6146966\n",
      "\tspeed: 0.1651s/iter; left time: 5187.3720s\n",
      "2099it [05:47,  6.06it/s]\titers: 2100, epoch: 2 | loss: 0.7178262\n",
      "\tspeed: 0.1650s/iter; left time: 5167.8291s\n",
      "2199it [06:03,  6.05it/s]\titers: 2200, epoch: 2 | loss: 0.4131571\n",
      "\tspeed: 0.1651s/iter; left time: 5154.0980s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 2 | loss: 0.5189355\n",
      "\tspeed: 0.1652s/iter; left time: 5140.2407s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 2 | loss: 0.4629318\n",
      "\tspeed: 0.1652s/iter; left time: 5122.8337s\n",
      "2499it [06:53,  6.05it/s]\titers: 2500, epoch: 2 | loss: 0.3559010\n",
      "\tspeed: 0.1651s/iter; left time: 5104.5785s\n",
      "2599it [07:10,  6.07it/s]\titers: 2600, epoch: 2 | loss: 0.3144288\n",
      "\tspeed: 0.1651s/iter; left time: 5088.8791s\n",
      "2699it [07:26,  6.04it/s]\titers: 2700, epoch: 2 | loss: 0.3665635\n",
      "\tspeed: 0.1656s/iter; left time: 5086.9663s\n",
      "2799it [07:43,  6.03it/s]\titers: 2800, epoch: 2 | loss: 0.4836561\n",
      "\tspeed: 0.1657s/iter; left time: 5073.7246s\n",
      "2899it [07:59,  6.06it/s]\titers: 2900, epoch: 2 | loss: 0.4225220\n",
      "\tspeed: 0.1652s/iter; left time: 5041.9765s\n",
      "2999it [08:16,  6.07it/s]\titers: 3000, epoch: 2 | loss: 0.3637490\n",
      "\tspeed: 0.1652s/iter; left time: 5024.2595s\n",
      "3099it [08:32,  6.07it/s]\titers: 3100, epoch: 2 | loss: 0.3995622\n",
      "\tspeed: 0.1651s/iter; left time: 5004.7925s\n",
      "3199it [08:49,  6.05it/s]\titers: 3200, epoch: 2 | loss: 0.4233486\n",
      "\tspeed: 0.1651s/iter; left time: 4989.3084s\n",
      "3299it [09:05,  6.05it/s]\titers: 3300, epoch: 2 | loss: 0.3576169\n",
      "\tspeed: 0.1652s/iter; left time: 4974.6931s\n",
      "3399it [09:22,  6.06it/s]\titers: 3400, epoch: 2 | loss: 0.5287344\n",
      "\tspeed: 0.1652s/iter; left time: 4959.6841s\n",
      "3499it [09:38,  6.06it/s]\titers: 3500, epoch: 2 | loss: 0.4585082\n",
      "\tspeed: 0.1652s/iter; left time: 4943.5706s\n",
      "3599it [09:55,  6.06it/s]\titers: 3600, epoch: 2 | loss: 0.5473402\n",
      "\tspeed: 0.1653s/iter; left time: 4929.6295s\n",
      "3699it [10:11,  6.07it/s]\titers: 3700, epoch: 2 | loss: 0.4319811\n",
      "\tspeed: 0.1651s/iter; left time: 4907.4735s\n",
      "3713it [10:14,  6.05it/s]\n",
      "Epoch: 2 cost time: 614.1618776321411\n",
      "810it [01:05, 12.28it/s]\n",
      "807it [01:06, 12.21it/s]\n",
      "Epoch: 2 | Train Loss: 0.4360154 Vali Loss: 0.4978501 Test Loss: 0.6172231 MAE Loss: 0.5572104\n",
      "Updating learning rate to 0.0020000000000000018\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0020000000000000018\n",
      "99it [00:16,  6.03it/s]\titers: 100, epoch: 3 | loss: 0.4303295\n",
      "\tspeed: 1.5235s/iter; left time: 45104.5457s\n",
      "199it [00:33,  6.02it/s]\titers: 200, epoch: 3 | loss: 0.2771498\n",
      "\tspeed: 0.1659s/iter; left time: 4895.6926s\n",
      "299it [00:49,  6.03it/s]\titers: 300, epoch: 3 | loss: 0.4990565\n",
      "\tspeed: 0.1657s/iter; left time: 4872.9906s\n",
      "399it [01:06,  6.04it/s]\titers: 400, epoch: 3 | loss: 0.3592515\n",
      "\tspeed: 0.1657s/iter; left time: 4854.6165s\n",
      "499it [01:23,  6.04it/s]\titers: 500, epoch: 3 | loss: 0.3701052\n",
      "\tspeed: 0.1654s/iter; left time: 4829.9940s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 3 | loss: 0.3270285\n",
      "\tspeed: 0.1654s/iter; left time: 4815.4089s\n",
      "699it [01:56,  6.06it/s]\titers: 700, epoch: 3 | loss: 0.4449060\n",
      "\tspeed: 0.1650s/iter; left time: 4787.0488s\n",
      "799it [02:12,  6.05it/s]\titers: 800, epoch: 3 | loss: 0.2854516\n",
      "\tspeed: 0.1653s/iter; left time: 4778.7668s\n",
      "899it [02:29,  6.05it/s]\titers: 900, epoch: 3 | loss: 0.2514527\n",
      "\tspeed: 0.1651s/iter; left time: 4754.7075s\n",
      "999it [02:45,  6.03it/s]\titers: 1000, epoch: 3 | loss: 0.2835534\n",
      "\tspeed: 0.1655s/iter; left time: 4749.6329s\n",
      "1099it [03:02,  6.05it/s]\titers: 1100, epoch: 3 | loss: 0.2697057\n",
      "\tspeed: 0.1654s/iter; left time: 4730.2837s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 3 | loss: 0.1969525\n",
      "\tspeed: 0.1654s/iter; left time: 4714.9920s\n",
      "1299it [03:35,  6.05it/s]\titers: 1300, epoch: 3 | loss: 0.3549285\n",
      "\tspeed: 0.1654s/iter; left time: 4698.4061s\n",
      "1399it [03:51,  6.04it/s]\titers: 1400, epoch: 3 | loss: 0.3464519\n",
      "\tspeed: 0.1653s/iter; left time: 4678.4415s\n",
      "1499it [04:08,  6.03it/s]\titers: 1500, epoch: 3 | loss: 0.5636867\n",
      "\tspeed: 0.1657s/iter; left time: 4673.4316s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 3 | loss: 0.3600194\n",
      "\tspeed: 0.1651s/iter; left time: 4640.3608s\n",
      "1699it [04:41,  6.06it/s]\titers: 1700, epoch: 3 | loss: 0.3238720\n",
      "\tspeed: 0.1650s/iter; left time: 4621.8863s\n",
      "1799it [04:57,  5.95it/s]\titers: 1800, epoch: 3 | loss: 0.2421953\n",
      "\tspeed: 0.1658s/iter; left time: 4626.2967s\n",
      "1899it [05:14,  6.02it/s]\titers: 1900, epoch: 3 | loss: 0.5728974\n",
      "\tspeed: 0.1658s/iter; left time: 4609.9756s\n",
      "1999it [05:31,  6.05it/s]\titers: 2000, epoch: 3 | loss: 0.5479270\n",
      "\tspeed: 0.1654s/iter; left time: 4582.5779s\n",
      "2099it [05:47,  6.09it/s]\titers: 2100, epoch: 3 | loss: 0.3138304\n",
      "\tspeed: 0.1646s/iter; left time: 4543.2727s\n",
      "2199it [06:04,  5.97it/s]\titers: 2200, epoch: 3 | loss: 0.3342245\n",
      "\tspeed: 0.1659s/iter; left time: 4563.4954s\n",
      "2299it [06:20,  6.02it/s]\titers: 2300, epoch: 3 | loss: 0.3850319\n",
      "\tspeed: 0.1658s/iter; left time: 4542.8503s\n",
      "2399it [06:37,  6.05it/s]\titers: 2400, epoch: 3 | loss: 0.5179683\n",
      "\tspeed: 0.1657s/iter; left time: 4523.4462s\n",
      "2499it [06:53,  6.04it/s]\titers: 2500, epoch: 3 | loss: 0.2403398\n",
      "\tspeed: 0.1656s/iter; left time: 4504.2114s\n",
      "2599it [07:10,  6.05it/s]\titers: 2600, epoch: 3 | loss: 0.5026017\n",
      "\tspeed: 0.1655s/iter; left time: 4486.8039s\n",
      "2699it [07:26,  6.04it/s]\titers: 2700, epoch: 3 | loss: 0.2527866\n",
      "\tspeed: 0.1657s/iter; left time: 4474.6713s\n",
      "2799it [07:43,  6.00it/s]\titers: 2800, epoch: 3 | loss: 0.3908583\n",
      "\tspeed: 0.1665s/iter; left time: 4480.1015s\n",
      "2899it [08:00,  6.02it/s]\titers: 2900, epoch: 3 | loss: 0.3636400\n",
      "\tspeed: 0.1661s/iter; left time: 4451.6777s\n",
      "2999it [08:16,  6.04it/s]\titers: 3000, epoch: 3 | loss: 0.3154917\n",
      "\tspeed: 0.1659s/iter; left time: 4430.8458s\n",
      "3099it [08:33,  6.03it/s]\titers: 3100, epoch: 3 | loss: 0.4973474\n",
      "\tspeed: 0.1660s/iter; left time: 4417.2745s\n",
      "3199it [08:50,  6.02it/s]\titers: 3200, epoch: 3 | loss: 0.4724675\n",
      "\tspeed: 0.1658s/iter; left time: 4393.8519s\n",
      "3299it [09:06,  6.03it/s]\titers: 3300, epoch: 3 | loss: 0.3848812\n",
      "\tspeed: 0.1661s/iter; left time: 4384.5569s\n",
      "3399it [09:23,  6.03it/s]\titers: 3400, epoch: 3 | loss: 0.3242784\n",
      "\tspeed: 0.1657s/iter; left time: 4359.0698s\n",
      "3499it [09:39,  6.05it/s]\titers: 3500, epoch: 3 | loss: 0.3661088\n",
      "\tspeed: 0.1661s/iter; left time: 4352.7759s\n",
      "3599it [09:56,  6.03it/s]\titers: 3600, epoch: 3 | loss: 0.5475364\n",
      "\tspeed: 0.1661s/iter; left time: 4336.3619s\n",
      "3699it [10:13,  5.95it/s]\titers: 3700, epoch: 3 | loss: 0.2863446\n",
      "\tspeed: 0.1665s/iter; left time: 4329.2492s\n",
      "3713it [10:15,  6.03it/s]\n",
      "Epoch: 3 cost time: 615.4510226249695\n",
      "810it [01:06, 12.21it/s]\n",
      "807it [01:06, 12.22it/s]\n",
      "Epoch: 3 | Train Loss: 0.3693308 Vali Loss: 0.4219438 Test Loss: 0.5429367 MAE Loss: 0.4976103\n",
      "Updating learning rate to 0.0010000000000000009\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0010000000000000009\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 4 | loss: 0.3298291\n",
      "\tspeed: 1.5290s/iter; left time: 39589.4826s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 4 | loss: 0.2197691\n",
      "\tspeed: 0.1650s/iter; left time: 4256.1092s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 4 | loss: 0.2751325\n",
      "\tspeed: 0.1651s/iter; left time: 4242.1953s\n",
      "399it [01:06,  6.07it/s]\titers: 400, epoch: 4 | loss: 0.4871212\n",
      "\tspeed: 0.1651s/iter; left time: 4224.7458s\n",
      "499it [01:22,  6.03it/s]\titers: 500, epoch: 4 | loss: 0.5427579\n",
      "\tspeed: 0.1655s/iter; left time: 4220.0111s\n",
      "599it [01:39,  5.28it/s]\titers: 600, epoch: 4 | loss: 0.2499517\n",
      "\tspeed: 0.1722s/iter; left time: 4373.2856s\n",
      "699it [01:58,  5.94it/s]\titers: 700, epoch: 4 | loss: 0.4904192\n",
      "\tspeed: 0.1815s/iter; left time: 4589.2945s\n",
      "799it [02:16,  5.24it/s]\titers: 800, epoch: 4 | loss: 0.4155072\n",
      "\tspeed: 0.1820s/iter; left time: 4584.4486s\n",
      "899it [02:35,  5.28it/s]\titers: 900, epoch: 4 | loss: 0.3379152\n",
      "\tspeed: 0.1907s/iter; left time: 4784.5243s\n",
      "999it [02:54,  5.29it/s]\titers: 1000, epoch: 4 | loss: 0.3752646\n",
      "\tspeed: 0.1894s/iter; left time: 4734.5323s\n",
      "1099it [03:13,  5.31it/s]\titers: 1100, epoch: 4 | loss: 0.2461608\n",
      "\tspeed: 0.1894s/iter; left time: 4713.3521s\n",
      "1199it [03:32,  5.27it/s]\titers: 1200, epoch: 4 | loss: 0.5132418\n",
      "\tspeed: 0.1885s/iter; left time: 4672.7505s\n",
      "1299it [03:51,  5.27it/s]\titers: 1300, epoch: 4 | loss: 0.2592258\n",
      "\tspeed: 0.1896s/iter; left time: 4680.7833s\n",
      "1399it [04:09,  5.27it/s]\titers: 1400, epoch: 4 | loss: 0.5239473\n",
      "\tspeed: 0.1886s/iter; left time: 4639.2491s\n",
      "1499it [04:28,  5.26it/s]\titers: 1500, epoch: 4 | loss: 0.3059317\n",
      "\tspeed: 0.1900s/iter; left time: 4652.6654s\n",
      "1599it [04:48,  5.20it/s]\titers: 1600, epoch: 4 | loss: 0.2288510\n",
      "\tspeed: 0.1918s/iter; left time: 4678.5150s\n",
      "1699it [05:07,  5.22it/s]\titers: 1700, epoch: 4 | loss: 0.3193402\n",
      "\tspeed: 0.1912s/iter; left time: 4643.6673s\n",
      "1799it [05:26,  5.22it/s]\titers: 1800, epoch: 4 | loss: 0.2031232\n",
      "\tspeed: 0.1919s/iter; left time: 4642.9396s\n",
      "1899it [05:45,  5.23it/s]\titers: 1900, epoch: 4 | loss: 0.6042179\n",
      "\tspeed: 0.1912s/iter; left time: 4606.2327s\n",
      "1999it [06:04,  5.24it/s]\titers: 2000, epoch: 4 | loss: 0.1875121\n",
      "\tspeed: 0.1914s/iter; left time: 4591.7598s\n",
      "2099it [06:23,  5.27it/s]\titers: 2100, epoch: 4 | loss: 0.3175943\n",
      "\tspeed: 0.1911s/iter; left time: 4566.6662s\n",
      "2199it [06:42,  5.21it/s]\titers: 2200, epoch: 4 | loss: 0.4577579\n",
      "\tspeed: 0.1896s/iter; left time: 4509.8630s\n",
      "2299it [07:01,  5.29it/s]\titers: 2300, epoch: 4 | loss: 0.3180164\n",
      "\tspeed: 0.1908s/iter; left time: 4519.9328s\n",
      "2399it [07:20,  5.24it/s]\titers: 2400, epoch: 4 | loss: 0.2915050\n",
      "\tspeed: 0.1907s/iter; left time: 4498.4348s\n",
      "2499it [07:39,  5.61it/s]\titers: 2500, epoch: 4 | loss: 0.3208832\n",
      "\tspeed: 0.1840s/iter; left time: 4323.3711s\n",
      "2599it [07:58,  5.24it/s]\titers: 2600, epoch: 4 | loss: 0.2625274\n",
      "\tspeed: 0.1887s/iter; left time: 4414.4810s\n",
      "2699it [08:17,  5.23it/s]\titers: 2700, epoch: 4 | loss: 0.4371386\n",
      "\tspeed: 0.1911s/iter; left time: 4451.6918s\n",
      "2799it [08:36,  5.23it/s]\titers: 2800, epoch: 4 | loss: 0.2966113\n",
      "\tspeed: 0.1908s/iter; left time: 4425.6412s\n",
      "2899it [08:54,  5.45it/s]\titers: 2900, epoch: 4 | loss: 0.2828107\n",
      "\tspeed: 0.1767s/iter; left time: 4081.0332s\n",
      "2999it [09:13,  5.24it/s]\titers: 3000, epoch: 4 | loss: 0.2504953\n",
      "\tspeed: 0.1910s/iter; left time: 4392.2107s\n",
      "3099it [09:32,  5.20it/s]\titers: 3100, epoch: 4 | loss: 0.2845546\n",
      "\tspeed: 0.1909s/iter; left time: 4370.8883s\n",
      "3199it [09:51,  5.25it/s]\titers: 3200, epoch: 4 | loss: 0.2170754\n",
      "\tspeed: 0.1913s/iter; left time: 4360.0909s\n",
      "3299it [10:10,  5.24it/s]\titers: 3300, epoch: 4 | loss: 0.4772356\n",
      "\tspeed: 0.1901s/iter; left time: 4313.4741s\n",
      "3399it [10:28,  5.22it/s]\titers: 3400, epoch: 4 | loss: 0.3668054\n",
      "\tspeed: 0.1854s/iter; left time: 4189.2688s\n",
      "3499it [10:47,  5.27it/s]\titers: 3500, epoch: 4 | loss: 0.2123359\n",
      "\tspeed: 0.1882s/iter; left time: 4232.5040s\n",
      "3599it [11:05,  5.26it/s]\titers: 3600, epoch: 4 | loss: 0.3179665\n",
      "\tspeed: 0.1830s/iter; left time: 4097.0211s\n",
      "3699it [11:23,  6.06it/s]\titers: 3700, epoch: 4 | loss: 0.2091953\n",
      "\tspeed: 0.1702s/iter; left time: 3794.7260s\n",
      "3713it [11:25,  5.42it/s]\n",
      "Epoch: 4 cost time: 685.4163053035736\n",
      "810it [01:06, 12.21it/s]\n",
      "807it [01:05, 12.23it/s]\n",
      "Epoch: 4 | Train Loss: 0.3338749 Vali Loss: 0.3955883 Test Loss: 0.5039500 MAE Loss: 0.4816267\n",
      "Updating learning rate to 0.0005000000000000004\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0005000000000000004\n",
      "99it [00:16,  6.04it/s]\titers: 100, epoch: 5 | loss: 0.6387448\n",
      "\tspeed: 1.5306s/iter; left time: 33947.2120s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 5 | loss: 0.2285962\n",
      "\tspeed: 0.1656s/iter; left time: 3655.2492s\n",
      "299it [00:49,  6.03it/s]\titers: 300, epoch: 5 | loss: 0.1652339\n",
      "\tspeed: 0.1651s/iter; left time: 3628.8229s\n",
      "399it [01:06,  6.04it/s]\titers: 400, epoch: 5 | loss: 0.2762267\n",
      "\tspeed: 0.1650s/iter; left time: 3609.5559s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 5 | loss: 0.2967767\n",
      "\tspeed: 0.1651s/iter; left time: 3594.6964s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 5 | loss: 0.5745446\n",
      "\tspeed: 0.1651s/iter; left time: 3578.9465s\n",
      "699it [01:55,  6.07it/s]\titers: 700, epoch: 5 | loss: 0.5171253\n",
      "\tspeed: 0.1649s/iter; left time: 3558.5131s\n",
      "799it [02:12,  6.05it/s]\titers: 800, epoch: 5 | loss: 0.2204103\n",
      "\tspeed: 0.1652s/iter; left time: 3548.0560s\n",
      "899it [02:28,  6.07it/s]\titers: 900, epoch: 5 | loss: 0.2706527\n",
      "\tspeed: 0.1652s/iter; left time: 3531.5106s\n",
      "999it [02:45,  6.07it/s]\titers: 1000, epoch: 5 | loss: 0.5283497\n",
      "\tspeed: 0.1649s/iter; left time: 3508.0406s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 5 | loss: 0.4945345\n",
      "\tspeed: 0.1650s/iter; left time: 3495.2163s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 5 | loss: 0.4588980\n",
      "\tspeed: 0.1651s/iter; left time: 3479.2783s\n",
      "1299it [03:34,  6.05it/s]\titers: 1300, epoch: 5 | loss: 0.2787362\n",
      "\tspeed: 0.1653s/iter; left time: 3467.7716s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 5 | loss: 0.2815110\n",
      "\tspeed: 0.1652s/iter; left time: 3448.5484s\n",
      "1499it [04:07,  6.06it/s]\titers: 1500, epoch: 5 | loss: 0.2890683\n",
      "\tspeed: 0.1651s/iter; left time: 3431.0981s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 5 | loss: 0.2234760\n",
      "\tspeed: 0.1648s/iter; left time: 3406.9711s\n",
      "1699it [04:40,  6.06it/s]\titers: 1700, epoch: 5 | loss: 0.2007575\n",
      "\tspeed: 0.1650s/iter; left time: 3395.6572s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 5 | loss: 0.2279443\n",
      "\tspeed: 0.1651s/iter; left time: 3380.2403s\n",
      "1899it [05:13,  6.07it/s]\titers: 1900, epoch: 5 | loss: 0.2106377\n",
      "\tspeed: 0.1654s/iter; left time: 3371.6316s\n",
      "1999it [05:30,  6.06it/s]\titers: 2000, epoch: 5 | loss: 0.5714111\n",
      "\tspeed: 0.1651s/iter; left time: 3347.5838s\n",
      "2099it [05:46,  6.06it/s]\titers: 2100, epoch: 5 | loss: 0.2918050\n",
      "\tspeed: 0.1654s/iter; left time: 3337.6696s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 5 | loss: 0.3405251\n",
      "\tspeed: 0.1651s/iter; left time: 3315.5145s\n",
      "2299it [06:20,  6.06it/s]\titers: 2300, epoch: 5 | loss: 0.4557160\n",
      "\tspeed: 0.1652s/iter; left time: 3300.4919s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 5 | loss: 0.4802276\n",
      "\tspeed: 0.1653s/iter; left time: 3285.0778s\n",
      "2499it [06:53,  6.06it/s]\titers: 2500, epoch: 5 | loss: 0.2459367\n",
      "\tspeed: 0.1649s/iter; left time: 3261.9951s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 5 | loss: 0.4559529\n",
      "\tspeed: 0.1649s/iter; left time: 3245.2700s\n",
      "2699it [07:26,  6.06it/s]\titers: 2700, epoch: 5 | loss: 0.2658513\n",
      "\tspeed: 0.1653s/iter; left time: 3236.4592s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 5 | loss: 0.2141252\n",
      "\tspeed: 0.1654s/iter; left time: 3221.3154s\n",
      "2899it [07:59,  6.06it/s]\titers: 2900, epoch: 5 | loss: 0.2339095\n",
      "\tspeed: 0.1655s/iter; left time: 3207.4762s\n",
      "2999it [08:15,  6.04it/s]\titers: 3000, epoch: 5 | loss: 0.1473101\n",
      "\tspeed: 0.1653s/iter; left time: 3186.8390s\n",
      "3099it [08:32,  6.05it/s]\titers: 3100, epoch: 5 | loss: 0.2912861\n",
      "\tspeed: 0.1657s/iter; left time: 3178.1779s\n",
      "3199it [08:48,  6.06it/s]\titers: 3200, epoch: 5 | loss: 0.1966386\n",
      "\tspeed: 0.1651s/iter; left time: 3150.1473s\n",
      "3299it [09:05,  6.06it/s]\titers: 3300, epoch: 5 | loss: 0.3388843\n",
      "\tspeed: 0.1654s/iter; left time: 3139.3073s\n",
      "3399it [09:21,  6.04it/s]\titers: 3400, epoch: 5 | loss: 0.3114641\n",
      "\tspeed: 0.1650s/iter; left time: 3115.6846s\n",
      "3499it [09:38,  5.99it/s]\titers: 3500, epoch: 5 | loss: 0.2586635\n",
      "\tspeed: 0.1661s/iter; left time: 3118.9902s\n",
      "3599it [09:54,  6.03it/s]\titers: 3600, epoch: 5 | loss: 0.4136901\n",
      "\tspeed: 0.1656s/iter; left time: 3092.9749s\n",
      "3699it [10:11,  6.05it/s]\titers: 3700, epoch: 5 | loss: 0.2511885\n",
      "\tspeed: 0.1656s/iter; left time: 3076.6697s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 5 cost time: 613.9081525802612\n",
      "810it [01:06, 12.20it/s]\n",
      "807it [01:06, 12.08it/s]\n",
      "Epoch: 5 | Train Loss: 0.3145375 Vali Loss: 0.3796912 Test Loss: 0.4788374 MAE Loss: 0.4524133\n",
      "Updating learning rate to 0.0002500000000000002\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0002500000000000002\n",
      "99it [00:20,  4.91it/s]\titers: 100, epoch: 6 | loss: 0.3266639\n",
      "\tspeed: 1.5703s/iter; left time: 28996.7261s\n",
      "199it [00:40,  4.90it/s]\titers: 200, epoch: 6 | loss: 0.3547673\n",
      "\tspeed: 0.2039s/iter; left time: 3745.1671s\n",
      "299it [01:00,  5.01it/s]\titers: 300, epoch: 6 | loss: 0.1794612\n",
      "\tspeed: 0.1996s/iter; left time: 3645.6266s\n",
      "399it [01:18,  6.01it/s]\titers: 400, epoch: 6 | loss: 0.2624080\n",
      "\tspeed: 0.1810s/iter; left time: 3288.2690s\n",
      "499it [01:35,  6.03it/s]\titers: 500, epoch: 6 | loss: 0.2167382\n",
      "\tspeed: 0.1660s/iter; left time: 2999.8295s\n",
      "599it [01:51,  6.02it/s]\titers: 600, epoch: 6 | loss: 0.2449202\n",
      "\tspeed: 0.1655s/iter; left time: 2974.1644s\n",
      "699it [02:08,  6.04it/s]\titers: 700, epoch: 6 | loss: 0.1805169\n",
      "\tspeed: 0.1660s/iter; left time: 2964.9561s\n",
      "799it [02:24,  6.04it/s]\titers: 800, epoch: 6 | loss: 0.2282764\n",
      "\tspeed: 0.1661s/iter; left time: 2950.7821s\n",
      "899it [02:41,  6.00it/s]\titers: 900, epoch: 6 | loss: 0.2371928\n",
      "\tspeed: 0.1661s/iter; left time: 2934.3681s\n",
      "999it [02:58,  5.93it/s]\titers: 1000, epoch: 6 | loss: 0.2742714\n",
      "\tspeed: 0.1664s/iter; left time: 2922.9713s\n",
      "1099it [03:14,  6.04it/s]\titers: 1100, epoch: 6 | loss: 0.2270079\n",
      "\tspeed: 0.1662s/iter; left time: 2903.1327s\n",
      "1199it [03:31,  6.04it/s]\titers: 1200, epoch: 6 | loss: 0.3340990\n",
      "\tspeed: 0.1657s/iter; left time: 2877.9271s\n",
      "1299it [03:47,  6.06it/s]\titers: 1300, epoch: 6 | loss: 0.2668552\n",
      "\tspeed: 0.1657s/iter; left time: 2860.5166s\n",
      "1399it [04:04,  6.04it/s]\titers: 1400, epoch: 6 | loss: 0.4781071\n",
      "\tspeed: 0.1662s/iter; left time: 2853.0223s\n",
      "1499it [04:21,  6.04it/s]\titers: 1500, epoch: 6 | loss: 0.2925887\n",
      "\tspeed: 0.1665s/iter; left time: 2841.6901s\n",
      "1599it [04:37,  6.02it/s]\titers: 1600, epoch: 6 | loss: 0.3588944\n",
      "\tspeed: 0.1661s/iter; left time: 2818.8678s\n",
      "1699it [04:54,  6.04it/s]\titers: 1700, epoch: 6 | loss: 0.4135357\n",
      "\tspeed: 0.1661s/iter; left time: 2801.3242s\n",
      "1799it [05:11,  6.01it/s]\titers: 1800, epoch: 6 | loss: 0.3962974\n",
      "\tspeed: 0.1661s/iter; left time: 2785.4630s\n",
      "1899it [05:27,  6.06it/s]\titers: 1900, epoch: 6 | loss: 0.3003477\n",
      "\tspeed: 0.1655s/iter; left time: 2758.8068s\n",
      "1999it [05:44,  6.06it/s]\titers: 2000, epoch: 6 | loss: 0.3540019\n",
      "\tspeed: 0.1655s/iter; left time: 2741.9155s\n",
      "2099it [06:00,  6.05it/s]\titers: 2100, epoch: 6 | loss: 0.2384260\n",
      "\tspeed: 0.1659s/iter; left time: 2732.2629s\n",
      "2199it [06:17,  6.03it/s]\titers: 2200, epoch: 6 | loss: 0.2398241\n",
      "\tspeed: 0.1661s/iter; left time: 2719.0178s\n",
      "2299it [06:33,  6.02it/s]\titers: 2300, epoch: 6 | loss: 0.2336053\n",
      "\tspeed: 0.1660s/iter; left time: 2699.5171s\n",
      "2399it [06:50,  6.00it/s]\titers: 2400, epoch: 6 | loss: 0.1989165\n",
      "\tspeed: 0.1660s/iter; left time: 2683.4691s\n",
      "2499it [07:07,  6.00it/s]\titers: 2500, epoch: 6 | loss: 0.4230149\n",
      "\tspeed: 0.1655s/iter; left time: 2659.4135s\n",
      "2599it [07:25,  5.12it/s]\titers: 2600, epoch: 6 | loss: 0.3490303\n",
      "\tspeed: 0.1865s/iter; left time: 2977.5800s\n",
      "2699it [07:45,  4.90it/s]\titers: 2700, epoch: 6 | loss: 0.3088345\n",
      "\tspeed: 0.1975s/iter; left time: 3134.1388s\n",
      "2799it [08:05,  4.94it/s]\titers: 2800, epoch: 6 | loss: 0.2219592\n",
      "\tspeed: 0.2033s/iter; left time: 3204.8075s\n",
      "2899it [08:25,  5.31it/s]\titers: 2900, epoch: 6 | loss: 0.2243711\n",
      "\tspeed: 0.1999s/iter; left time: 3131.4163s\n",
      "2999it [08:42,  6.02it/s]\titers: 3000, epoch: 6 | loss: 0.2897165\n",
      "\tspeed: 0.1663s/iter; left time: 2588.3528s\n",
      "3099it [08:59,  6.02it/s]\titers: 3100, epoch: 6 | loss: 0.3103786\n",
      "\tspeed: 0.1666s/iter; left time: 2576.4759s\n",
      "3199it [09:15,  5.96it/s]\titers: 3200, epoch: 6 | loss: 0.4090191\n",
      "\tspeed: 0.1661s/iter; left time: 2552.2885s\n",
      "3299it [09:34,  4.89it/s]\titers: 3300, epoch: 6 | loss: 0.2046801\n",
      "\tspeed: 0.1902s/iter; left time: 2903.6440s\n",
      "3399it [09:55,  4.89it/s]\titers: 3400, epoch: 6 | loss: 0.3339357\n",
      "\tspeed: 0.2037s/iter; left time: 3090.0550s\n",
      "3499it [10:15,  5.03it/s]\titers: 3500, epoch: 6 | loss: 0.2101169\n",
      "\tspeed: 0.2033s/iter; left time: 3063.6043s\n",
      "3599it [10:35,  5.02it/s]\titers: 3600, epoch: 6 | loss: 0.3418460\n",
      "\tspeed: 0.1991s/iter; left time: 2978.9880s\n",
      "3699it [10:52,  6.04it/s]\titers: 3700, epoch: 6 | loss: 0.1540788\n",
      "\tspeed: 0.1746s/iter; left time: 2595.6390s\n",
      "3713it [10:55,  5.67it/s]\n",
      "Epoch: 6 cost time: 655.2303154468536\n",
      "810it [01:07, 11.96it/s]\n",
      "807it [01:21,  9.91it/s]\n",
      "Epoch: 6 | Train Loss: 0.3036938 Vali Loss: 0.3660926 Test Loss: 0.4568191 MAE Loss: 0.4423087\n",
      "Updating learning rate to 0.0001250000000000001\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 0.0001250000000000001\n",
      "99it [00:20,  5.03it/s]\titers: 100, epoch: 7 | loss: 0.3201865\n",
      "\tspeed: 1.7302s/iter; left time: 25526.1706s\n",
      "199it [00:40,  4.91it/s]\titers: 200, epoch: 7 | loss: 0.2289972\n",
      "\tspeed: 0.2007s/iter; left time: 2941.4086s\n",
      "299it [01:00,  4.92it/s]\titers: 300, epoch: 7 | loss: 0.1889026\n",
      "\tspeed: 0.2031s/iter; left time: 2956.0915s\n",
      "399it [01:20,  5.02it/s]\titers: 400, epoch: 7 | loss: 0.4390150\n",
      "\tspeed: 0.2014s/iter; left time: 2911.3908s\n",
      "499it [01:40,  5.02it/s]\titers: 500, epoch: 7 | loss: 0.2767137\n",
      "\tspeed: 0.1989s/iter; left time: 2855.0389s\n",
      "599it [02:00,  4.90it/s]\titers: 600, epoch: 7 | loss: 0.3099226\n",
      "\tspeed: 0.2030s/iter; left time: 2892.9776s\n",
      "699it [02:21,  4.94it/s]\titers: 700, epoch: 7 | loss: 0.4663972\n",
      "\tspeed: 0.2032s/iter; left time: 2876.4397s\n",
      "799it [02:41,  5.02it/s]\titers: 800, epoch: 7 | loss: 0.3628769\n",
      "\tspeed: 0.1993s/iter; left time: 2800.1354s\n",
      "899it [03:01,  4.93it/s]\titers: 900, epoch: 7 | loss: 0.2263001\n",
      "\tspeed: 0.2012s/iter; left time: 2807.8262s\n",
      "999it [03:21,  4.95it/s]\titers: 1000, epoch: 7 | loss: 0.3932178\n",
      "\tspeed: 0.2029s/iter; left time: 2810.8745s\n",
      "1099it [03:41,  5.05it/s]\titers: 1100, epoch: 7 | loss: 0.1917340\n",
      "\tspeed: 0.2006s/iter; left time: 2759.4202s\n",
      "1199it [04:01,  4.86it/s]\titers: 1200, epoch: 7 | loss: 0.2487349\n",
      "\tspeed: 0.1985s/iter; left time: 2709.6888s\n",
      "1299it [04:21,  4.93it/s]\titers: 1300, epoch: 7 | loss: 0.3008628\n",
      "\tspeed: 0.2025s/iter; left time: 2743.8942s\n",
      "1399it [04:42,  5.00it/s]\titers: 1400, epoch: 7 | loss: 0.3417143\n",
      "\tspeed: 0.2024s/iter; left time: 2722.2793s\n",
      "1499it [05:01,  5.06it/s]\titers: 1500, epoch: 7 | loss: 0.2685176\n",
      "\tspeed: 0.1978s/iter; left time: 2641.5890s\n",
      "1599it [05:21,  4.93it/s]\titers: 1600, epoch: 7 | loss: 0.2058965\n",
      "\tspeed: 0.2009s/iter; left time: 2662.6977s\n",
      "1699it [05:42,  4.94it/s]\titers: 1700, epoch: 7 | loss: 0.3158576\n",
      "\tspeed: 0.2037s/iter; left time: 2679.9116s\n",
      "1799it [06:02,  5.06it/s]\titers: 1800, epoch: 7 | loss: 0.2852851\n",
      "\tspeed: 0.1998s/iter; left time: 2607.4569s\n",
      "1899it [06:22,  4.94it/s]\titers: 1900, epoch: 7 | loss: 0.3549774\n",
      "\tspeed: 0.1987s/iter; left time: 2574.0805s\n",
      "1999it [06:42,  4.94it/s]\titers: 2000, epoch: 7 | loss: 0.2879899\n",
      "\tspeed: 0.2027s/iter; left time: 2604.9817s\n",
      "2099it [07:02,  5.05it/s]\titers: 2100, epoch: 7 | loss: 0.1965139\n",
      "\tspeed: 0.2019s/iter; left time: 2574.8986s\n",
      "2199it [07:22,  5.02it/s]\titers: 2200, epoch: 7 | loss: 0.2568766\n",
      "\tspeed: 0.1997s/iter; left time: 2526.9940s\n",
      "2299it [07:42,  4.90it/s]\titers: 2300, epoch: 7 | loss: 0.1871208\n",
      "\tspeed: 0.2027s/iter; left time: 2544.5745s\n",
      "2399it [08:03,  4.92it/s]\titers: 2400, epoch: 7 | loss: 0.3652858\n",
      "\tspeed: 0.2041s/iter; left time: 2541.3550s\n",
      "2499it [08:23,  5.03it/s]\titers: 2500, epoch: 7 | loss: 0.3599503\n",
      "\tspeed: 0.2005s/iter; left time: 2476.4627s\n",
      "2599it [08:43,  4.92it/s]\titers: 2600, epoch: 7 | loss: 0.2532969\n",
      "\tspeed: 0.2008s/iter; left time: 2460.8930s\n",
      "2699it [09:03,  4.91it/s]\titers: 2700, epoch: 7 | loss: 0.3471728\n",
      "\tspeed: 0.2034s/iter; left time: 2471.9483s\n",
      "2799it [09:23,  5.03it/s]\titers: 2800, epoch: 7 | loss: 0.2232514\n",
      "\tspeed: 0.2018s/iter; left time: 2432.0091s\n",
      "2899it [09:43,  5.03it/s]\titers: 2900, epoch: 7 | loss: 0.3918693\n",
      "\tspeed: 0.1988s/iter; left time: 2376.2730s\n",
      "2999it [10:03,  4.92it/s]\titers: 3000, epoch: 7 | loss: 0.2994984\n",
      "\tspeed: 0.1973s/iter; left time: 2338.3560s\n",
      "3099it [10:23,  4.86it/s]\titers: 3100, epoch: 7 | loss: 0.3849228\n",
      "\tspeed: 0.2039s/iter; left time: 2396.2347s\n",
      "3199it [10:44,  5.07it/s]\titers: 3200, epoch: 7 | loss: 0.1890081\n",
      "\tspeed: 0.2027s/iter; left time: 2362.0396s\n",
      "3299it [11:04,  5.01it/s]\titers: 3300, epoch: 7 | loss: 0.3022695\n",
      "\tspeed: 0.2000s/iter; left time: 2310.6887s\n",
      "3399it [11:24,  4.91it/s]\titers: 3400, epoch: 7 | loss: 0.3133596\n",
      "\tspeed: 0.2034s/iter; left time: 2329.5502s\n",
      "3499it [11:44,  4.91it/s]\titers: 3500, epoch: 7 | loss: 0.2689004\n",
      "\tspeed: 0.2035s/iter; left time: 2310.6988s\n",
      "3599it [12:04,  5.01it/s]\titers: 3600, epoch: 7 | loss: 0.2744590\n",
      "\tspeed: 0.2008s/iter; left time: 2259.5237s\n",
      "3699it [12:25,  4.91it/s]\titers: 3700, epoch: 7 | loss: 0.6941900\n",
      "\tspeed: 0.2013s/iter; left time: 2245.2383s\n",
      "3713it [12:27,  4.96it/s]\n",
      "Epoch: 7 cost time: 747.9410398006439\n",
      "810it [01:21,  9.96it/s]\n",
      "807it [01:20, 10.02it/s]\n",
      "Epoch: 7 | Train Loss: 0.2965105 Vali Loss: 0.3642876 Test Loss: 0.4558839 MAE Loss: 0.4422976\n",
      "Updating learning rate to 6.250000000000006e-05\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 6.250000000000006e-05\n",
      "99it [00:20,  4.92it/s]\titers: 100, epoch: 8 | loss: 0.2991989\n",
      "\tspeed: 1.8655s/iter; left time: 20595.6515s\n",
      "199it [00:40,  5.04it/s]\titers: 200, epoch: 8 | loss: 0.2673537\n",
      "\tspeed: 0.2019s/iter; left time: 2209.1023s\n",
      "299it [01:00,  5.05it/s]\titers: 300, epoch: 8 | loss: 0.2922842\n",
      "\tspeed: 0.1988s/iter; left time: 2155.3527s\n",
      "399it [01:20,  4.91it/s]\titers: 400, epoch: 8 | loss: 0.2751395\n",
      "\tspeed: 0.2034s/iter; left time: 2184.3204s\n",
      "499it [01:41,  4.91it/s]\titers: 500, epoch: 8 | loss: 0.4542767\n",
      "\tspeed: 0.2039s/iter; left time: 2169.5091s\n",
      "599it [02:01,  5.04it/s]\titers: 600, epoch: 8 | loss: 0.1247516\n",
      "\tspeed: 0.1987s/iter; left time: 2094.3768s\n",
      "699it [02:21,  4.90it/s]\titers: 700, epoch: 8 | loss: 0.2221546\n",
      "\tspeed: 0.2014s/iter; left time: 2103.1230s\n",
      "799it [02:41,  4.92it/s]\titers: 800, epoch: 8 | loss: 0.2714564\n",
      "\tspeed: 0.2033s/iter; left time: 2102.4352s\n",
      "899it [03:01,  5.03it/s]\titers: 900, epoch: 8 | loss: 0.2926304\n",
      "\tspeed: 0.2007s/iter; left time: 2054.6709s\n",
      "999it [03:21,  4.91it/s]\titers: 1000, epoch: 8 | loss: 0.2181059\n",
      "\tspeed: 0.1994s/iter; left time: 2021.6501s\n",
      "1099it [03:42,  4.93it/s]\titers: 1100, epoch: 8 | loss: 0.2010663\n",
      "\tspeed: 0.2036s/iter; left time: 2044.3288s\n",
      "1199it [04:02,  5.04it/s]\titers: 1200, epoch: 8 | loss: 0.2460894\n",
      "\tspeed: 0.2022s/iter; left time: 2009.8957s\n",
      "1299it [04:22,  5.02it/s]\titers: 1300, epoch: 8 | loss: 0.2033589\n",
      "\tspeed: 0.1989s/iter; left time: 1957.1243s\n",
      "1399it [04:42,  4.90it/s]\titers: 1400, epoch: 8 | loss: 0.2442213\n",
      "\tspeed: 0.2022s/iter; left time: 1969.5307s\n",
      "1499it [05:02,  4.94it/s]\titers: 1500, epoch: 8 | loss: 0.2115099\n",
      "\tspeed: 0.2033s/iter; left time: 1959.3354s\n",
      "1599it [05:22,  5.04it/s]\titers: 1600, epoch: 8 | loss: 0.3678452\n",
      "\tspeed: 0.1999s/iter; left time: 1906.9495s\n",
      "1699it [05:41,  5.99it/s]\titers: 1700, epoch: 8 | loss: 0.1785378\n",
      "\tspeed: 0.1885s/iter; left time: 1779.8112s\n",
      "1799it [06:00,  6.00it/s]\titers: 1800, epoch: 8 | loss: 0.3149127\n",
      "\tspeed: 0.1854s/iter; left time: 1731.3181s\n",
      "1899it [06:20,  4.92it/s]\titers: 1900, epoch: 8 | loss: 0.1937971\n",
      "\tspeed: 0.2031s/iter; left time: 1876.5817s\n",
      "1999it [06:40,  4.91it/s]\titers: 2000, epoch: 8 | loss: 0.2201329\n",
      "\tspeed: 0.2034s/iter; left time: 1859.3806s\n",
      "2099it [06:58,  6.01it/s]\titers: 2100, epoch: 8 | loss: 0.4642505\n",
      "\tspeed: 0.1732s/iter; left time: 1566.0389s\n",
      "2199it [07:14,  6.03it/s]\titers: 2200, epoch: 8 | loss: 0.2883017\n",
      "\tspeed: 0.1660s/iter; left time: 1483.8708s\n",
      "2299it [07:31,  6.04it/s]\titers: 2300, epoch: 8 | loss: 0.2790481\n",
      "\tspeed: 0.1657s/iter; left time: 1465.0583s\n",
      "2399it [07:47,  6.02it/s]\titers: 2400, epoch: 8 | loss: 0.5360949\n",
      "\tspeed: 0.1661s/iter; left time: 1451.7403s\n",
      "2499it [08:04,  6.01it/s]\titers: 2500, epoch: 8 | loss: 0.4367565\n",
      "\tspeed: 0.1665s/iter; left time: 1438.2938s\n",
      "2599it [08:21,  6.02it/s]\titers: 2600, epoch: 8 | loss: 0.3205844\n",
      "\tspeed: 0.1662s/iter; left time: 1419.3784s\n",
      "2699it [08:37,  6.01it/s]\titers: 2700, epoch: 8 | loss: 0.2948700\n",
      "\tspeed: 0.1666s/iter; left time: 1406.3750s\n",
      "2799it [08:54,  6.01it/s]\titers: 2800, epoch: 8 | loss: 0.6628783\n",
      "\tspeed: 0.1665s/iter; left time: 1388.9461s\n",
      "2899it [09:11,  6.01it/s]\titers: 2900, epoch: 8 | loss: 0.3077545\n",
      "\tspeed: 0.1664s/iter; left time: 1371.4384s\n",
      "2999it [09:27,  6.00it/s]\titers: 3000, epoch: 8 | loss: 0.1882494\n",
      "\tspeed: 0.1663s/iter; left time: 1354.0165s\n",
      "3099it [09:44,  6.03it/s]\titers: 3100, epoch: 8 | loss: 0.2797900\n",
      "\tspeed: 0.1658s/iter; left time: 1333.1731s\n",
      "3199it [10:00,  6.04it/s]\titers: 3200, epoch: 8 | loss: 0.2773636\n",
      "\tspeed: 0.1658s/iter; left time: 1316.2245s\n",
      "3299it [10:17,  6.03it/s]\titers: 3300, epoch: 8 | loss: 0.3707446\n",
      "\tspeed: 0.1657s/iter; left time: 1299.4249s\n",
      "3399it [10:34,  5.99it/s]\titers: 3400, epoch: 8 | loss: 0.2192360\n",
      "\tspeed: 0.1662s/iter; left time: 1286.6809s\n",
      "3499it [10:52,  5.11it/s]\titers: 3500, epoch: 8 | loss: 0.4315456\n",
      "\tspeed: 0.1837s/iter; left time: 1403.7937s\n",
      "3599it [11:12,  4.87it/s]\titers: 3600, epoch: 8 | loss: 0.3814849\n",
      "\tspeed: 0.1978s/iter; left time: 1491.7232s\n",
      "3699it [11:30,  5.57it/s]\titers: 3700, epoch: 8 | loss: 0.3707655\n",
      "\tspeed: 0.1835s/iter; left time: 1365.2006s\n",
      "3713it [11:33,  5.36it/s]\n",
      "Epoch: 8 cost time: 693.3383448123932\n",
      "810it [01:11, 11.39it/s]\n",
      "807it [01:05, 12.24it/s]\n",
      "Epoch: 8 | Train Loss: 0.2934891 Vali Loss: 0.3609257 Test Loss: 0.4539671 MAE Loss: 0.4403319\n",
      "Updating learning rate to 3.125000000000003e-05\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 3.125000000000003e-05\n",
      "99it [00:16,  6.02it/s]\titers: 100, epoch: 9 | loss: 0.1952451\n",
      "\tspeed: 1.6514s/iter; left time: 12099.9863s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 9 | loss: 0.2552158\n",
      "\tspeed: 0.1659s/iter; left time: 1198.6462s\n",
      "299it [00:50,  6.03it/s]\titers: 300, epoch: 9 | loss: 0.3628187\n",
      "\tspeed: 0.1659s/iter; left time: 1182.2362s\n",
      "399it [01:06,  6.03it/s]\titers: 400, epoch: 9 | loss: 0.2937731\n",
      "\tspeed: 0.1657s/iter; left time: 1164.4263s\n",
      "499it [01:23,  6.02it/s]\titers: 500, epoch: 9 | loss: 0.1840438\n",
      "\tspeed: 0.1660s/iter; left time: 1150.0830s\n",
      "599it [01:39,  6.03it/s]\titers: 600, epoch: 9 | loss: 0.2282875\n",
      "\tspeed: 0.1659s/iter; left time: 1132.6099s\n",
      "699it [01:56,  6.03it/s]\titers: 700, epoch: 9 | loss: 0.3381479\n",
      "\tspeed: 0.1656s/iter; left time: 1114.2052s\n",
      "799it [02:13,  6.02it/s]\titers: 800, epoch: 9 | loss: 0.2437009\n",
      "\tspeed: 0.1664s/iter; left time: 1102.4056s\n",
      "899it [02:29,  6.03it/s]\titers: 900, epoch: 9 | loss: 0.4781007\n",
      "\tspeed: 0.1663s/iter; left time: 1085.6360s\n",
      "999it [02:46,  6.01it/s]\titers: 1000, epoch: 9 | loss: 0.2015581\n",
      "\tspeed: 0.1659s/iter; left time: 1066.0761s\n",
      "1099it [03:02,  6.03it/s]\titers: 1100, epoch: 9 | loss: 0.4432991\n",
      "\tspeed: 0.1660s/iter; left time: 1050.1517s\n",
      "1199it [03:19,  6.04it/s]\titers: 1200, epoch: 9 | loss: 0.2509889\n",
      "\tspeed: 0.1657s/iter; left time: 1031.5816s\n",
      "1299it [03:36,  6.03it/s]\titers: 1300, epoch: 9 | loss: 0.3044417\n",
      "\tspeed: 0.1657s/iter; left time: 1015.2806s\n",
      "1399it [03:52,  6.03it/s]\titers: 1400, epoch: 9 | loss: 0.3190647\n",
      "\tspeed: 0.1657s/iter; left time: 998.7620s\n",
      "1499it [04:09,  6.04it/s]\titers: 1500, epoch: 9 | loss: 0.3175237\n",
      "\tspeed: 0.1657s/iter; left time: 982.3274s\n",
      "1599it [04:25,  6.04it/s]\titers: 1600, epoch: 9 | loss: 0.2578101\n",
      "\tspeed: 0.1657s/iter; left time: 965.6587s\n",
      "1699it [04:42,  6.03it/s]\titers: 1700, epoch: 9 | loss: 0.1966513\n",
      "\tspeed: 0.1658s/iter; left time: 949.6396s\n",
      "1799it [04:58,  6.03it/s]\titers: 1800, epoch: 9 | loss: 0.3623584\n",
      "\tspeed: 0.1657s/iter; left time: 932.4827s\n",
      "1899it [05:15,  6.03it/s]\titers: 1900, epoch: 9 | loss: 0.3650044\n",
      "\tspeed: 0.1658s/iter; left time: 916.2180s\n",
      "1999it [05:32,  6.04it/s]\titers: 2000, epoch: 9 | loss: 0.3137719\n",
      "\tspeed: 0.1657s/iter; left time: 899.4836s\n",
      "2099it [05:48,  6.03it/s]\titers: 2100, epoch: 9 | loss: 0.1840102\n",
      "\tspeed: 0.1657s/iter; left time: 882.4216s\n",
      "2199it [06:05,  6.04it/s]\titers: 2200, epoch: 9 | loss: 0.2766108\n",
      "\tspeed: 0.1658s/iter; left time: 866.4104s\n",
      "2299it [06:21,  5.98it/s]\titers: 2300, epoch: 9 | loss: 0.2257370\n",
      "\tspeed: 0.1659s/iter; left time: 850.3599s\n",
      "2399it [06:38,  6.04it/s]\titers: 2400, epoch: 9 | loss: 0.4217002\n",
      "\tspeed: 0.1658s/iter; left time: 833.2758s\n",
      "2499it [06:54,  6.04it/s]\titers: 2500, epoch: 9 | loss: 0.2201920\n",
      "\tspeed: 0.1666s/iter; left time: 820.7950s\n",
      "2599it [07:11,  6.01it/s]\titers: 2600, epoch: 9 | loss: 0.2273602\n",
      "\tspeed: 0.1660s/iter; left time: 801.2158s\n",
      "2699it [07:28,  6.04it/s]\titers: 2700, epoch: 9 | loss: 0.3003752\n",
      "\tspeed: 0.1662s/iter; left time: 785.6996s\n",
      "2799it [07:44,  5.86it/s]\titers: 2800, epoch: 9 | loss: 0.2540076\n",
      "\tspeed: 0.1661s/iter; left time: 768.6424s\n",
      "2899it [08:01,  6.01it/s]\titers: 2900, epoch: 9 | loss: 0.3364004\n",
      "\tspeed: 0.1663s/iter; left time: 752.7942s\n",
      "2999it [08:18,  6.02it/s]\titers: 3000, epoch: 9 | loss: 0.3453858\n",
      "\tspeed: 0.1660s/iter; left time: 734.7775s\n",
      "3099it [08:34,  6.04it/s]\titers: 3100, epoch: 9 | loss: 0.2605692\n",
      "\tspeed: 0.1664s/iter; left time: 719.7968s\n",
      "3199it [08:51,  6.04it/s]\titers: 3200, epoch: 9 | loss: 0.3055431\n",
      "\tspeed: 0.1657s/iter; left time: 700.3462s\n",
      "3299it [09:07,  6.05it/s]\titers: 3300, epoch: 9 | loss: 0.1804521\n",
      "\tspeed: 0.1657s/iter; left time: 683.7835s\n",
      "3399it [09:24,  6.02it/s]\titers: 3400, epoch: 9 | loss: 0.3745235\n",
      "\tspeed: 0.1657s/iter; left time: 667.0802s\n",
      "3499it [09:40,  5.82it/s]\titers: 3500, epoch: 9 | loss: 0.3522816\n",
      "\tspeed: 0.1659s/iter; left time: 651.4099s\n",
      "3599it [09:57,  6.03it/s]\titers: 3600, epoch: 9 | loss: 0.4047002\n",
      "\tspeed: 0.1659s/iter; left time: 634.7096s\n",
      "3699it [10:14,  6.04it/s]\titers: 3700, epoch: 9 | loss: 0.2167620\n",
      "\tspeed: 0.1659s/iter; left time: 618.1255s\n",
      "3713it [10:16,  6.02it/s]\n",
      "Epoch: 9 cost time: 616.5277054309845\n",
      "810it [01:06, 12.21it/s]\n",
      "807it [01:06, 12.19it/s]\n",
      "Epoch: 9 | Train Loss: 0.2906924 Vali Loss: 0.3607459 Test Loss: 0.4516619 MAE Loss: 0.4375696\n",
      "Updating learning rate to 1.5625000000000014e-05\n",
      "learning_rate 0.0040000000000000036\n",
      "lr 1.5625000000000014e-05\n",
      "74it [00:12,  6.05it/s]^C\n",
      "74it [00:12,  5.87it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 232, in <module>\n",
      "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1852, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 238, in forward\n",
      "    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 276, in forecast\n",
      "    prompt = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).input_ids\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2577, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2663, in _call_one\n",
      "    return self.batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2854, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 733, in _batch_encode_plus\n",
      "    first_ids = get_input_ids(ids)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 700, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 517, in tokenize\n",
      "    tokens = self.tokens_trie.split(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 222, in split\n",
      "    del states[start]\n",
      "        ~~~~~~^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 119.39658838907877 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 19:06:51,380] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 19:06:52,216] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 19:06:52,216] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 19:06:52,216] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 19:06:53,069] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 19:06:53,070] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 19:06:53,688] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 19:06:53,689] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 19:06:53,689] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 19:06:53,690] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 19:06:53,691] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 19:06:53,691] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 19:06:53,691] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 19:06:53,691] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 19:06:53,691] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 19:06:53,691] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 19:06:53,968] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 19:06:53,969] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 19:06:53,969] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 147.66 GB, percent = 19.6%\n",
      "[2024-05-06 19:06:54,081] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 19:06:54,082] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 19:06:54,082] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 147.66 GB, percent = 19.6%\n",
      "[2024-05-06 19:06:54,082] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 19:06:54,181] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 19:06:54,182] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 19:06:54,182] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 147.66 GB, percent = 19.6%\n",
      "[2024-05-06 19:06:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 19:06:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 19:06:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 19:06:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 19:06:54,183] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 19:06:54,183] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 19:06:54,183] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 19:06:54,183] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 19:06:54,183] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f53d0b29b90>\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 19:06:54,184] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 19:06:54,185] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:17,  5.93it/s]\titers: 100, epoch: 1 | loss: 0.4618609\n",
      "\tspeed: 0.2067s/iter; left time: 15327.2664s\n",
      "199it [00:34,  5.93it/s]\titers: 200, epoch: 1 | loss: 0.3899240\n",
      "\tspeed: 0.1690s/iter; left time: 12516.8148s\n",
      "299it [00:51,  5.93it/s]\titers: 300, epoch: 1 | loss: 0.3661842\n",
      "\tspeed: 0.1687s/iter; left time: 12473.8233s\n",
      "399it [01:07,  5.92it/s]\titers: 400, epoch: 1 | loss: 0.1881032\n",
      "\tspeed: 0.1686s/iter; left time: 12449.6833s\n",
      "499it [01:24,  5.94it/s]\titers: 500, epoch: 1 | loss: 0.2263861\n",
      "\tspeed: 0.1686s/iter; left time: 12436.7190s\n",
      "599it [01:41,  5.94it/s]\titers: 600, epoch: 1 | loss: 0.2624842\n",
      "\tspeed: 0.1684s/iter; left time: 12402.3464s\n",
      "699it [01:58,  5.93it/s]\titers: 700, epoch: 1 | loss: 0.2973318\n",
      "\tspeed: 0.1685s/iter; left time: 12396.4569s\n",
      "799it [02:15,  5.90it/s]\titers: 800, epoch: 1 | loss: 0.3241043\n",
      "\tspeed: 0.1690s/iter; left time: 12417.0084s\n",
      "899it [02:32,  5.91it/s]\titers: 900, epoch: 1 | loss: 0.2249994\n",
      "\tspeed: 0.1696s/iter; left time: 12438.9564s\n",
      "999it [02:49,  5.90it/s]\titers: 1000, epoch: 1 | loss: 0.2316564\n",
      "\tspeed: 0.1694s/iter; left time: 12412.5301s\n",
      "1099it [03:06,  5.90it/s]\titers: 1100, epoch: 1 | loss: 0.2588322\n",
      "\tspeed: 0.1696s/iter; left time: 12409.7420s\n",
      "1199it [03:23,  5.95it/s]\titers: 1200, epoch: 1 | loss: 0.1702397\n",
      "\tspeed: 0.1686s/iter; left time: 12321.6814s\n",
      "1299it [03:39,  5.94it/s]\titers: 1300, epoch: 1 | loss: 0.2180093\n",
      "\tspeed: 0.1681s/iter; left time: 12265.9363s\n",
      "1399it [03:56,  5.89it/s]\titers: 1400, epoch: 1 | loss: 0.2449195\n",
      "\tspeed: 0.1693s/iter; left time: 12337.2045s\n",
      "1499it [04:13,  5.94it/s]\titers: 1500, epoch: 1 | loss: 0.2832335\n",
      "\tspeed: 0.1695s/iter; left time: 12329.4211s\n",
      "1599it [04:30,  5.90it/s]\titers: 1600, epoch: 1 | loss: 0.2898077\n",
      "\tspeed: 0.1692s/iter; left time: 12292.9058s\n",
      "1699it [04:47,  5.89it/s]\titers: 1700, epoch: 1 | loss: 0.3521157\n",
      "\tspeed: 0.1699s/iter; left time: 12328.9898s\n",
      "1799it [05:04,  5.90it/s]\titers: 1800, epoch: 1 | loss: 0.2451236\n",
      "\tspeed: 0.1700s/iter; left time: 12316.0519s\n",
      "1899it [05:21,  5.90it/s]\titers: 1900, epoch: 1 | loss: 0.2947961\n",
      "\tspeed: 0.1699s/iter; left time: 12293.7823s\n",
      "1999it [05:38,  5.90it/s]\titers: 2000, epoch: 1 | loss: 0.2152199\n",
      "\tspeed: 0.1696s/iter; left time: 12255.3447s\n",
      "2099it [05:55,  5.90it/s]\titers: 2100, epoch: 1 | loss: 0.1692189\n",
      "\tspeed: 0.1695s/iter; left time: 12231.6627s\n",
      "2199it [06:12,  5.91it/s]\titers: 2200, epoch: 1 | loss: 0.1638385\n",
      "\tspeed: 0.1697s/iter; left time: 12226.9758s\n",
      "2299it [06:29,  5.89it/s]\titers: 2300, epoch: 1 | loss: 0.3102884\n",
      "\tspeed: 0.1696s/iter; left time: 12203.4095s\n",
      "2399it [06:46,  5.94it/s]\titers: 2400, epoch: 1 | loss: 0.5121620\n",
      "\tspeed: 0.1686s/iter; left time: 12113.3782s\n",
      "2499it [07:03,  5.92it/s]\titers: 2500, epoch: 1 | loss: 0.2398673\n",
      "\tspeed: 0.1684s/iter; left time: 12087.2347s\n",
      "2599it [07:20,  5.89it/s]\titers: 2600, epoch: 1 | loss: 0.1561184\n",
      "\tspeed: 0.1702s/iter; left time: 12194.9885s\n",
      "2699it [07:37,  5.89it/s]\titers: 2700, epoch: 1 | loss: 0.2536733\n",
      "\tspeed: 0.1699s/iter; left time: 12154.7702s\n",
      "2799it [07:54,  5.94it/s]\titers: 2800, epoch: 1 | loss: 0.1188028\n",
      "\tspeed: 0.1695s/iter; left time: 12113.6730s\n",
      "2899it [08:11,  5.94it/s]\titers: 2900, epoch: 1 | loss: 0.4120305\n",
      "\tspeed: 0.1685s/iter; left time: 12023.8789s\n",
      "2999it [08:27,  5.94it/s]\titers: 3000, epoch: 1 | loss: 0.1284291\n",
      "\tspeed: 0.1684s/iter; left time: 11999.0604s\n",
      "3099it [08:44,  5.94it/s]\titers: 3100, epoch: 1 | loss: 0.2454490\n",
      "\tspeed: 0.1684s/iter; left time: 11984.9641s\n",
      "3199it [09:01,  5.93it/s]\titers: 3200, epoch: 1 | loss: 0.4085863\n",
      "\tspeed: 0.1685s/iter; left time: 11972.3507s\n",
      "3299it [09:18,  5.92it/s]\titers: 3300, epoch: 1 | loss: 0.2168726\n",
      "\tspeed: 0.1690s/iter; left time: 11993.7424s\n",
      "3399it [09:35,  5.94it/s]\titers: 3400, epoch: 1 | loss: 0.2877906\n",
      "\tspeed: 0.1690s/iter; left time: 11974.8938s\n",
      "3499it [09:52,  5.93it/s]\titers: 3500, epoch: 1 | loss: 0.4339239\n",
      "\tspeed: 0.1687s/iter; left time: 11938.2476s\n",
      "3599it [10:09,  5.93it/s]\titers: 3600, epoch: 1 | loss: 0.4449164\n",
      "\tspeed: 0.1686s/iter; left time: 11910.8317s\n",
      "3699it [10:25,  5.93it/s]\titers: 3700, epoch: 1 | loss: 0.1339988\n",
      "\tspeed: 0.1685s/iter; left time: 11888.7278s\n",
      "3713it [10:28,  5.91it/s]\n",
      "Epoch: 1 cost time: 628.3795876502991\n",
      "810it [01:09, 11.73it/s]\n",
      "807it [01:08, 11.74it/s]\n",
      "Epoch: 1 | Train Loss: 0.2939578 Vali Loss: 0.3308652 Test Loss: 0.4116031 MAE Loss: 0.4164754\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 2 | loss: 0.2224971\n",
      "\tspeed: 1.5802s/iter; left time: 111321.9232s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 2 | loss: 0.1859257\n",
      "\tspeed: 0.1651s/iter; left time: 11611.7550s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 2 | loss: 0.1712774\n",
      "\tspeed: 0.1650s/iter; left time: 11592.2123s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 2 | loss: 0.3535642\n",
      "\tspeed: 0.1650s/iter; left time: 11574.0223s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 2 | loss: 0.1553607\n",
      "\tspeed: 0.1659s/iter; left time: 11618.3757s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 2 | loss: 0.3271545\n",
      "\tspeed: 0.1656s/iter; left time: 11582.3773s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 2 | loss: 0.1733966\n",
      "\tspeed: 0.1652s/iter; left time: 11540.7815s\n",
      "799it [02:12,  6.06it/s]\titers: 800, epoch: 2 | loss: 0.2167310\n",
      "\tspeed: 0.1651s/iter; left time: 11514.1978s\n",
      "899it [02:28,  6.06it/s]\titers: 900, epoch: 2 | loss: 0.5247744\n",
      "\tspeed: 0.1652s/iter; left time: 11503.9177s\n",
      "999it [02:45,  6.06it/s]\titers: 1000, epoch: 2 | loss: 0.1824759\n",
      "\tspeed: 0.1649s/iter; left time: 11465.0060s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 2 | loss: 0.1982229\n",
      "\tspeed: 0.1650s/iter; left time: 11456.6887s\n",
      "1199it [03:18,  6.05it/s]\titers: 1200, epoch: 2 | loss: 0.2970625\n",
      "\tspeed: 0.1650s/iter; left time: 11439.2263s\n",
      "1299it [03:34,  6.06it/s]\titers: 1300, epoch: 2 | loss: 0.1361262\n",
      "\tspeed: 0.1649s/iter; left time: 11415.9506s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 2 | loss: 0.2503983\n",
      "\tspeed: 0.1648s/iter; left time: 11395.1176s\n",
      "1499it [04:07,  6.05it/s]\titers: 1500, epoch: 2 | loss: 0.1705465\n",
      "\tspeed: 0.1649s/iter; left time: 11389.1724s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 2 | loss: 0.4130092\n",
      "\tspeed: 0.1649s/iter; left time: 11368.9035s\n",
      "1699it [04:40,  6.08it/s]\titers: 1700, epoch: 2 | loss: 0.2882046\n",
      "\tspeed: 0.1650s/iter; left time: 11357.2554s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 2 | loss: 0.3682458\n",
      "\tspeed: 0.1649s/iter; left time: 11334.8135s\n",
      "1899it [05:13,  6.07it/s]\titers: 1900, epoch: 2 | loss: 0.2611897\n",
      "\tspeed: 0.1649s/iter; left time: 11317.8097s\n",
      "1999it [05:30,  6.06it/s]\titers: 2000, epoch: 2 | loss: 0.3657560\n",
      "\tspeed: 0.1650s/iter; left time: 11312.4331s\n",
      "2099it [05:46,  6.05it/s]\titers: 2100, epoch: 2 | loss: 0.4125029\n",
      "\tspeed: 0.1654s/iter; left time: 11322.6382s\n",
      "2199it [06:03,  6.03it/s]\titers: 2200, epoch: 2 | loss: 0.2298530\n",
      "\tspeed: 0.1658s/iter; left time: 11331.0129s\n",
      "2299it [06:20,  5.97it/s]\titers: 2300, epoch: 2 | loss: 0.3731268\n",
      "\tspeed: 0.1670s/iter; left time: 11398.9578s\n",
      "2399it [06:36,  6.01it/s]\titers: 2400, epoch: 2 | loss: 0.2681029\n",
      "\tspeed: 0.1664s/iter; left time: 11336.8790s\n",
      "2499it [06:53,  6.07it/s]\titers: 2500, epoch: 2 | loss: 0.1745616\n",
      "\tspeed: 0.1654s/iter; left time: 11256.6705s\n",
      "2599it [07:09,  5.91it/s]\titers: 2600, epoch: 2 | loss: 0.2134498\n",
      "\tspeed: 0.1664s/iter; left time: 11304.5023s\n",
      "2699it [07:26,  6.07it/s]\titers: 2700, epoch: 2 | loss: 0.2731954\n",
      "\tspeed: 0.1658s/iter; left time: 11252.0649s\n",
      "2799it [07:43,  6.01it/s]\titers: 2800, epoch: 2 | loss: 0.3241251\n",
      "\tspeed: 0.1668s/iter; left time: 11300.2584s\n",
      "2899it [07:59,  6.07it/s]\titers: 2900, epoch: 2 | loss: 0.2614107\n",
      "\tspeed: 0.1662s/iter; left time: 11245.5136s\n",
      "2999it [08:16,  6.03it/s]\titers: 3000, epoch: 2 | loss: 0.2456034\n",
      "\tspeed: 0.1660s/iter; left time: 11210.2971s\n",
      "3099it [08:33,  6.02it/s]\titers: 3100, epoch: 2 | loss: 0.2389004\n",
      "\tspeed: 0.1668s/iter; left time: 11247.4610s\n",
      "3199it [08:49,  6.01it/s]\titers: 3200, epoch: 2 | loss: 0.2119864\n",
      "\tspeed: 0.1662s/iter; left time: 11193.1142s\n",
      "3299it [09:06,  6.01it/s]\titers: 3300, epoch: 2 | loss: 0.2090339\n",
      "\tspeed: 0.1664s/iter; left time: 11187.5440s\n",
      "3399it [09:22,  6.01it/s]\titers: 3400, epoch: 2 | loss: 0.2690893\n",
      "\tspeed: 0.1663s/iter; left time: 11166.3108s\n",
      "3499it [09:39,  6.03it/s]\titers: 3500, epoch: 2 | loss: 0.2042641\n",
      "\tspeed: 0.1661s/iter; left time: 11133.3933s\n",
      "3599it [09:56,  5.94it/s]\titers: 3600, epoch: 2 | loss: 0.2135072\n",
      "\tspeed: 0.1662s/iter; left time: 11125.4935s\n",
      "3699it [10:12,  6.02it/s]\titers: 3700, epoch: 2 | loss: 0.3245580\n",
      "\tspeed: 0.1662s/iter; left time: 11109.8031s\n",
      "3713it [10:15,  6.04it/s]\n",
      "Epoch: 2 cost time: 615.1824641227722\n",
      "810it [01:05, 12.29it/s]\n",
      "807it [01:06, 12.11it/s]\n",
      "Epoch: 2 | Train Loss: 0.2525803 Vali Loss: 0.2944952 Test Loss: 0.3529874 MAE Loss: 0.3705082\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 3 | loss: 0.2772953\n",
      "\tspeed: 1.5290s/iter; left time: 102037.1258s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 3 | loss: 0.1713929\n",
      "\tspeed: 0.1653s/iter; left time: 11012.6983s\n",
      "299it [00:49,  6.05it/s]\titers: 300, epoch: 3 | loss: 0.4208254\n",
      "\tspeed: 0.1652s/iter; left time: 10994.7797s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 3 | loss: 0.2541380\n",
      "\tspeed: 0.1654s/iter; left time: 10990.5470s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 3 | loss: 0.1929646\n",
      "\tspeed: 0.1653s/iter; left time: 10962.4241s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 3 | loss: 0.2308283\n",
      "\tspeed: 0.1651s/iter; left time: 10938.0987s\n",
      "699it [01:55,  6.05it/s]\titers: 700, epoch: 3 | loss: 0.1925367\n",
      "\tspeed: 0.1653s/iter; left time: 10934.3370s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 3 | loss: 0.2181163\n",
      "\tspeed: 0.1651s/iter; left time: 10901.0955s\n",
      "899it [02:28,  6.04it/s]\titers: 900, epoch: 3 | loss: 0.1240298\n",
      "\tspeed: 0.1648s/iter; left time: 10867.1691s\n",
      "999it [02:45,  6.07it/s]\titers: 1000, epoch: 3 | loss: 0.1772814\n",
      "\tspeed: 0.1650s/iter; left time: 10864.2938s\n",
      "1099it [03:01,  6.07it/s]\titers: 1100, epoch: 3 | loss: 0.1848009\n",
      "\tspeed: 0.1650s/iter; left time: 10843.7284s\n",
      "1199it [03:18,  6.07it/s]\titers: 1200, epoch: 3 | loss: 0.1157865\n",
      "\tspeed: 0.1649s/iter; left time: 10822.2255s\n",
      "1299it [03:34,  6.05it/s]\titers: 1300, epoch: 3 | loss: 0.2178907\n",
      "\tspeed: 0.1649s/iter; left time: 10809.1849s\n",
      "1399it [03:51,  6.04it/s]\titers: 1400, epoch: 3 | loss: 0.2139381\n",
      "\tspeed: 0.1650s/iter; left time: 10793.8802s\n",
      "1499it [04:07,  6.05it/s]\titers: 1500, epoch: 3 | loss: 0.4063917\n",
      "\tspeed: 0.1652s/iter; left time: 10791.6857s\n",
      "1599it [04:24,  6.05it/s]\titers: 1600, epoch: 3 | loss: 0.2854365\n",
      "\tspeed: 0.1652s/iter; left time: 10775.7317s\n",
      "1699it [04:40,  6.06it/s]\titers: 1700, epoch: 3 | loss: 0.1749272\n",
      "\tspeed: 0.1651s/iter; left time: 10751.5843s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 3 | loss: 0.1639365\n",
      "\tspeed: 0.1650s/iter; left time: 10729.0303s\n",
      "1899it [05:13,  6.06it/s]\titers: 1900, epoch: 3 | loss: 0.3045512\n",
      "\tspeed: 0.1648s/iter; left time: 10704.0970s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 3 | loss: 0.3544967\n",
      "\tspeed: 0.1649s/iter; left time: 10692.2058s\n",
      "2099it [05:46,  6.07it/s]\titers: 2100, epoch: 3 | loss: 0.1485480\n",
      "\tspeed: 0.1649s/iter; left time: 10671.9030s\n",
      "2199it [06:03,  6.07it/s]\titers: 2200, epoch: 3 | loss: 0.1848772\n",
      "\tspeed: 0.1650s/iter; left time: 10666.8984s\n",
      "2299it [06:19,  6.06it/s]\titers: 2300, epoch: 3 | loss: 0.1456772\n",
      "\tspeed: 0.1649s/iter; left time: 10644.8860s\n",
      "2399it [06:36,  6.07it/s]\titers: 2400, epoch: 3 | loss: 0.4467164\n",
      "\tspeed: 0.1649s/iter; left time: 10628.2833s\n",
      "2499it [06:52,  6.06it/s]\titers: 2500, epoch: 3 | loss: 0.1251817\n",
      "\tspeed: 0.1651s/iter; left time: 10621.4410s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 3 | loss: 0.3092341\n",
      "\tspeed: 0.1650s/iter; left time: 10597.8858s\n",
      "2699it [07:25,  6.06it/s]\titers: 2700, epoch: 3 | loss: 0.1835158\n",
      "\tspeed: 0.1650s/iter; left time: 10585.2748s\n",
      "2799it [07:42,  6.04it/s]\titers: 2800, epoch: 3 | loss: 0.1606123\n",
      "\tspeed: 0.1651s/iter; left time: 10570.5336s\n",
      "2899it [07:58,  6.06it/s]\titers: 2900, epoch: 3 | loss: 0.2174627\n",
      "\tspeed: 0.1652s/iter; left time: 10564.8570s\n",
      "2999it [08:15,  6.05it/s]\titers: 3000, epoch: 3 | loss: 0.1923646\n",
      "\tspeed: 0.1651s/iter; left time: 10540.8847s\n",
      "3099it [08:31,  6.04it/s]\titers: 3100, epoch: 3 | loss: 0.2848335\n",
      "\tspeed: 0.1654s/iter; left time: 10539.4463s\n",
      "3199it [08:48,  6.04it/s]\titers: 3200, epoch: 3 | loss: 0.3081995\n",
      "\tspeed: 0.1654s/iter; left time: 10525.6506s\n",
      "3299it [09:04,  6.05it/s]\titers: 3300, epoch: 3 | loss: 0.3037609\n",
      "\tspeed: 0.1652s/iter; left time: 10493.2873s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 3 | loss: 0.1654985\n",
      "\tspeed: 0.1649s/iter; left time: 10459.0100s\n",
      "3499it [09:37,  6.08it/s]\titers: 3500, epoch: 3 | loss: 0.2228835\n",
      "\tspeed: 0.1649s/iter; left time: 10443.2991s\n",
      "3599it [09:54,  6.06it/s]\titers: 3600, epoch: 3 | loss: 0.3261676\n",
      "\tspeed: 0.1650s/iter; left time: 10435.7631s\n",
      "3699it [10:10,  6.06it/s]\titers: 3700, epoch: 3 | loss: 0.1608309\n",
      "\tspeed: 0.1650s/iter; left time: 10417.6302s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 3 cost time: 613.3058454990387\n",
      "810it [01:05, 12.28it/s]\n",
      "807it [01:05, 12.26it/s]\n",
      "Epoch: 3 | Train Loss: 0.2425671 Vali Loss: 0.2804815 Test Loss: 0.3424277 MAE Loss: 0.3567091\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 4 | loss: 0.2359179\n",
      "\tspeed: 1.5201s/iter; left time: 95800.2803s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 4 | loss: 0.1614241\n",
      "\tspeed: 0.1650s/iter; left time: 10383.8479s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 4 | loss: 0.1954262\n",
      "\tspeed: 0.1650s/iter; left time: 10364.5123s\n",
      "399it [01:06,  6.07it/s]\titers: 400, epoch: 4 | loss: 0.3544669\n",
      "\tspeed: 0.1651s/iter; left time: 10353.3182s\n",
      "499it [01:22,  6.07it/s]\titers: 500, epoch: 4 | loss: 0.4453398\n",
      "\tspeed: 0.1650s/iter; left time: 10329.7856s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 4 | loss: 0.1960398\n",
      "\tspeed: 0.1650s/iter; left time: 10317.2522s\n",
      "699it [01:55,  6.07it/s]\titers: 700, epoch: 4 | loss: 0.2976653\n",
      "\tspeed: 0.1650s/iter; left time: 10297.1983s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 4 | loss: 0.2959657\n",
      "\tspeed: 0.1648s/iter; left time: 10273.1215s\n",
      "899it [02:28,  6.07it/s]\titers: 900, epoch: 4 | loss: 0.2164483\n",
      "\tspeed: 0.1650s/iter; left time: 10266.8482s\n",
      "999it [02:45,  6.06it/s]\titers: 1000, epoch: 4 | loss: 0.3380115\n",
      "\tspeed: 0.1651s/iter; left time: 10258.0769s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 4 | loss: 0.1948572\n",
      "\tspeed: 0.1652s/iter; left time: 10244.6235s\n",
      "1199it [03:18,  6.07it/s]\titers: 1200, epoch: 4 | loss: 0.3208124\n",
      "\tspeed: 0.1649s/iter; left time: 10209.8170s\n",
      "1299it [03:34,  6.03it/s]\titers: 1300, epoch: 4 | loss: 0.1824240\n",
      "\tspeed: 0.1651s/iter; left time: 10208.3386s\n",
      "1399it [03:51,  5.13it/s]\titers: 1400, epoch: 4 | loss: 0.3089027\n",
      "\tspeed: 0.1717s/iter; left time: 10599.6015s\n",
      "1499it [04:11,  4.91it/s]\titers: 1500, epoch: 4 | loss: 0.2246594\n",
      "\tspeed: 0.1923s/iter; left time: 11852.1448s\n",
      "1599it [04:31,  4.90it/s]\titers: 1600, epoch: 4 | loss: 0.1969027\n",
      "\tspeed: 0.2041s/iter; left time: 12554.3784s\n",
      "1699it [04:51,  5.04it/s]\titers: 1700, epoch: 4 | loss: 0.2713486\n",
      "\tspeed: 0.2021s/iter; left time: 12412.4491s\n",
      "1799it [05:11,  5.05it/s]\titers: 1800, epoch: 4 | loss: 0.1269421\n",
      "\tspeed: 0.1986s/iter; left time: 12180.3604s\n",
      "1899it [05:31,  4.92it/s]\titers: 1900, epoch: 4 | loss: 0.3997875\n",
      "\tspeed: 0.2029s/iter; left time: 12419.0630s\n",
      "1999it [05:52,  4.96it/s]\titers: 2000, epoch: 4 | loss: 0.1456957\n",
      "\tspeed: 0.2034s/iter; left time: 12431.4905s\n",
      "2099it [06:11,  5.04it/s]\titers: 2100, epoch: 4 | loss: 0.2903089\n",
      "\tspeed: 0.1982s/iter; left time: 12092.5269s\n",
      "2199it [06:31,  5.14it/s]\titers: 2200, epoch: 4 | loss: 0.2867411\n",
      "\tspeed: 0.1961s/iter; left time: 11945.0837s\n",
      "2299it [06:51,  4.93it/s]\titers: 2300, epoch: 4 | loss: 0.2439357\n",
      "\tspeed: 0.2014s/iter; left time: 12247.0338s\n",
      "2399it [07:11,  4.93it/s]\titers: 2400, epoch: 4 | loss: 0.2058579\n",
      "\tspeed: 0.2030s/iter; left time: 12328.2718s\n",
      "2499it [07:31,  5.01it/s]\titers: 2500, epoch: 4 | loss: 0.2434293\n",
      "\tspeed: 0.1995s/iter; left time: 12092.8836s\n",
      "2599it [07:51,  4.94it/s]\titers: 2600, epoch: 4 | loss: 0.2012749\n",
      "\tspeed: 0.2004s/iter; left time: 12128.4314s\n",
      "2699it [08:12,  4.90it/s]\titers: 2700, epoch: 4 | loss: 0.3290511\n",
      "\tspeed: 0.2031s/iter; left time: 12270.0952s\n",
      "2799it [08:32,  5.04it/s]\titers: 2800, epoch: 4 | loss: 0.2251401\n",
      "\tspeed: 0.2015s/iter; left time: 12156.8109s\n",
      "2899it [08:52,  5.05it/s]\titers: 2900, epoch: 4 | loss: 0.1872775\n",
      "\tspeed: 0.1985s/iter; left time: 11951.2691s\n",
      "2999it [09:11,  4.94it/s]\titers: 3000, epoch: 4 | loss: 0.1733932\n",
      "\tspeed: 0.1963s/iter; left time: 11800.1523s\n",
      "3099it [09:32,  4.95it/s]\titers: 3100, epoch: 4 | loss: 0.2296898\n",
      "\tspeed: 0.2022s/iter; left time: 12138.1963s\n",
      "3199it [09:52,  5.04it/s]\titers: 3200, epoch: 4 | loss: 0.1439252\n",
      "\tspeed: 0.2017s/iter; left time: 12088.4773s\n",
      "3299it [10:12,  5.05it/s]\titers: 3300, epoch: 4 | loss: 0.2812739\n",
      "\tspeed: 0.1985s/iter; left time: 11875.3207s\n",
      "3399it [10:32,  4.96it/s]\titers: 3400, epoch: 4 | loss: 0.3683780\n",
      "\tspeed: 0.2010s/iter; left time: 12002.5238s\n",
      "3499it [10:52,  4.94it/s]\titers: 3500, epoch: 4 | loss: 0.1042776\n",
      "\tspeed: 0.2022s/iter; left time: 12054.2186s\n",
      "3599it [11:12,  5.04it/s]\titers: 3600, epoch: 4 | loss: 0.2315657\n",
      "\tspeed: 0.1997s/iter; left time: 11884.2046s\n",
      "3699it [11:32,  5.18it/s]\titers: 3700, epoch: 4 | loss: 0.1329266\n",
      "\tspeed: 0.1977s/iter; left time: 11745.6437s\n",
      "3713it [11:34,  5.34it/s]\n",
      "Epoch: 4 cost time: 694.9985361099243\n",
      "810it [01:07, 12.07it/s]\n",
      "807it [01:06, 12.12it/s]\n",
      "Epoch: 4 | Train Loss: 0.2335046 Vali Loss: 0.2732254 Test Loss: 0.3457497 MAE Loss: 0.3552359\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 5 | loss: 0.4290101\n",
      "\tspeed: 1.5486s/iter; left time: 91842.9819s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 5 | loss: 0.1452399\n",
      "\tspeed: 0.1652s/iter; left time: 9780.7147s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 5 | loss: 0.1130699\n",
      "\tspeed: 0.1650s/iter; left time: 9755.2529s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 5 | loss: 0.2043844\n",
      "\tspeed: 0.1650s/iter; left time: 9736.9088s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 5 | loss: 0.1939891\n",
      "\tspeed: 0.1650s/iter; left time: 9719.8787s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 5 | loss: 0.4352392\n",
      "\tspeed: 0.1650s/iter; left time: 9702.4054s\n",
      "699it [01:55,  6.05it/s]\titers: 700, epoch: 5 | loss: 0.2900281\n",
      "\tspeed: 0.1652s/iter; left time: 9700.9648s\n",
      "799it [02:12,  6.06it/s]\titers: 800, epoch: 5 | loss: 0.1668020\n",
      "\tspeed: 0.1652s/iter; left time: 9683.6642s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 5 | loss: 0.2188700\n",
      "\tspeed: 0.1652s/iter; left time: 9665.8383s\n",
      "999it [02:45,  6.05it/s]\titers: 1000, epoch: 5 | loss: 0.3003115\n",
      "\tspeed: 0.1652s/iter; left time: 9650.3767s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 5 | loss: 0.3501391\n",
      "\tspeed: 0.1650s/iter; left time: 9619.7210s\n",
      "1199it [03:18,  6.07it/s]\titers: 1200, epoch: 5 | loss: 0.3080452\n",
      "\tspeed: 0.1649s/iter; left time: 9600.4702s\n",
      "1299it [03:34,  6.04it/s]\titers: 1300, epoch: 5 | loss: 0.1845995\n",
      "\tspeed: 0.1649s/iter; left time: 9584.2247s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 5 | loss: 0.2120292\n",
      "\tspeed: 0.1650s/iter; left time: 9573.2688s\n",
      "1499it [04:07,  6.06it/s]\titers: 1500, epoch: 5 | loss: 0.1726610\n",
      "\tspeed: 0.1649s/iter; left time: 9548.6291s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 5 | loss: 0.1770702\n",
      "\tspeed: 0.1649s/iter; left time: 9533.6361s\n",
      "1699it [04:40,  6.06it/s]\titers: 1700, epoch: 5 | loss: 0.1549714\n",
      "\tspeed: 0.1653s/iter; left time: 9537.6734s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 5 | loss: 0.1603862\n",
      "\tspeed: 0.1651s/iter; left time: 9509.1817s\n",
      "1899it [05:13,  6.06it/s]\titers: 1900, epoch: 5 | loss: 0.1360336\n",
      "\tspeed: 0.1651s/iter; left time: 9493.0848s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 5 | loss: 0.3830062\n",
      "\tspeed: 0.1651s/iter; left time: 9477.9805s\n",
      "2099it [05:46,  6.06it/s]\titers: 2100, epoch: 5 | loss: 0.2724082\n",
      "\tspeed: 0.1653s/iter; left time: 9471.2980s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 5 | loss: 0.3095584\n",
      "\tspeed: 0.1652s/iter; left time: 9453.5260s\n",
      "2299it [06:19,  6.06it/s]\titers: 2300, epoch: 5 | loss: 0.2762376\n",
      "\tspeed: 0.1653s/iter; left time: 9437.9461s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 5 | loss: 0.3910101\n",
      "\tspeed: 0.1654s/iter; left time: 9429.1533s\n",
      "2499it [06:52,  6.06it/s]\titers: 2500, epoch: 5 | loss: 0.1545060\n",
      "\tspeed: 0.1652s/iter; left time: 9399.7946s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 5 | loss: 0.2241759\n",
      "\tspeed: 0.1650s/iter; left time: 9373.4922s\n",
      "2699it [07:25,  6.06it/s]\titers: 2700, epoch: 5 | loss: 0.2096108\n",
      "\tspeed: 0.1650s/iter; left time: 9356.5456s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 5 | loss: 0.1653327\n",
      "\tspeed: 0.1650s/iter; left time: 9342.0686s\n",
      "2899it [07:58,  6.07it/s]\titers: 2900, epoch: 5 | loss: 0.2326276\n",
      "\tspeed: 0.1650s/iter; left time: 9323.2428s\n",
      "2999it [08:15,  6.07it/s]\titers: 3000, epoch: 5 | loss: 0.0876571\n",
      "\tspeed: 0.1649s/iter; left time: 9302.7016s\n",
      "3099it [08:31,  6.06it/s]\titers: 3100, epoch: 5 | loss: 0.1646703\n",
      "\tspeed: 0.1649s/iter; left time: 9286.6895s\n",
      "3199it [08:48,  6.06it/s]\titers: 3200, epoch: 5 | loss: 0.1622387\n",
      "\tspeed: 0.1650s/iter; left time: 9272.9889s\n",
      "3299it [09:04,  6.04it/s]\titers: 3300, epoch: 5 | loss: 0.2349004\n",
      "\tspeed: 0.1652s/iter; left time: 9266.7136s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 5 | loss: 0.2136745\n",
      "\tspeed: 0.1653s/iter; left time: 9256.6436s\n",
      "3499it [09:37,  6.07it/s]\titers: 3500, epoch: 5 | loss: 0.2041386\n",
      "\tspeed: 0.1651s/iter; left time: 9229.2157s\n",
      "3599it [09:54,  6.06it/s]\titers: 3600, epoch: 5 | loss: 0.3351608\n",
      "\tspeed: 0.1651s/iter; left time: 9214.1099s\n",
      "3699it [10:10,  6.05it/s]\titers: 3700, epoch: 5 | loss: 0.1834728\n",
      "\tspeed: 0.1653s/iter; left time: 9206.8505s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 5 cost time: 613.3462970256805\n",
      "810it [01:06, 12.27it/s]\n",
      "807it [01:05, 12.29it/s]\n",
      "Epoch: 5 | Train Loss: 0.2254678 Vali Loss: 0.2882608 Test Loss: 0.3550920 MAE Loss: 0.3633786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 6 | loss: 0.2263570\n",
      "\tspeed: 1.5081s/iter; left time: 83845.4655s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 6 | loss: 0.2740361\n",
      "\tspeed: 0.1650s/iter; left time: 9155.0024s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 6 | loss: 0.1519721\n",
      "\tspeed: 0.1650s/iter; left time: 9141.0231s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 6 | loss: 0.2427285\n",
      "\tspeed: 0.1650s/iter; left time: 9121.7177s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 6 | loss: 0.1638625\n",
      "\tspeed: 0.1651s/iter; left time: 9110.5669s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 6 | loss: 0.1822068\n",
      "\tspeed: 0.1650s/iter; left time: 9091.1773s\n",
      "699it [01:55,  6.07it/s]\titers: 700, epoch: 6 | loss: 0.1013370\n",
      "\tspeed: 0.1650s/iter; left time: 9072.3321s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 6 | loss: 0.1732307\n",
      "\tspeed: 0.1650s/iter; left time: 9056.8329s\n",
      "899it [02:28,  6.06it/s]\titers: 900, epoch: 6 | loss: 0.1747500\n",
      "\tspeed: 0.1649s/iter; left time: 9037.4256s\n",
      "999it [02:45,  6.03it/s]\titers: 1000, epoch: 6 | loss: 0.2319760\n",
      "\tspeed: 0.1651s/iter; left time: 9030.9148s\n",
      "1099it [03:01,  6.07it/s]\titers: 1100, epoch: 6 | loss: 0.1760954\n",
      "\tspeed: 0.1650s/iter; left time: 9006.0420s\n",
      "1199it [03:18,  6.07it/s]\titers: 1200, epoch: 6 | loss: 0.2308710\n",
      "\tspeed: 0.1651s/iter; left time: 8994.8747s\n",
      "1299it [03:34,  6.07it/s]\titers: 1300, epoch: 6 | loss: 0.1690623\n",
      "\tspeed: 0.1649s/iter; left time: 8969.8297s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 6 | loss: 0.2980623\n",
      "\tspeed: 0.1650s/iter; left time: 8960.4528s\n",
      "1499it [04:07,  6.07it/s]\titers: 1500, epoch: 6 | loss: 0.2515747\n",
      "\tspeed: 0.1650s/iter; left time: 8942.4005s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 6 | loss: 0.2849717\n",
      "\tspeed: 0.1649s/iter; left time: 8919.2143s\n",
      "1699it [04:40,  6.07it/s]\titers: 1700, epoch: 6 | loss: 0.2537165\n",
      "\tspeed: 0.1649s/iter; left time: 8904.5451s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 6 | loss: 0.2181551\n",
      "\tspeed: 0.1651s/iter; left time: 8898.1959s\n",
      "1899it [05:13,  6.06it/s]\titers: 1900, epoch: 6 | loss: 0.2021992\n",
      "\tspeed: 0.1650s/iter; left time: 8878.9634s\n",
      "1999it [05:30,  6.06it/s]\titers: 2000, epoch: 6 | loss: 0.3146937\n",
      "\tspeed: 0.1651s/iter; left time: 8865.5193s\n",
      "2099it [05:46,  6.05it/s]\titers: 2100, epoch: 6 | loss: 0.1794589\n",
      "\tspeed: 0.1650s/iter; left time: 8842.7468s\n",
      "2199it [06:03,  6.05it/s]\titers: 2200, epoch: 6 | loss: 0.1559891\n",
      "\tspeed: 0.1650s/iter; left time: 8827.8098s\n",
      "2299it [06:19,  6.06it/s]\titers: 2300, epoch: 6 | loss: 0.1640035\n",
      "\tspeed: 0.1651s/iter; left time: 8814.1090s\n",
      "2399it [06:36,  6.06it/s]\titers: 2400, epoch: 6 | loss: 0.1532867\n",
      "\tspeed: 0.1651s/iter; left time: 8798.3803s\n",
      "2499it [06:52,  6.06it/s]\titers: 2500, epoch: 6 | loss: 0.2701644\n",
      "\tspeed: 0.1649s/iter; left time: 8773.6154s\n",
      "2599it [07:09,  6.05it/s]\titers: 2600, epoch: 6 | loss: 0.2582407\n",
      "\tspeed: 0.1649s/iter; left time: 8757.6543s\n",
      "2699it [07:25,  6.07it/s]\titers: 2700, epoch: 6 | loss: 0.2045282\n",
      "\tspeed: 0.1649s/iter; left time: 8741.0129s\n",
      "2799it [07:42,  6.07it/s]\titers: 2800, epoch: 6 | loss: 0.1544983\n",
      "\tspeed: 0.1649s/iter; left time: 8722.3822s\n",
      "2899it [07:58,  6.07it/s]\titers: 2900, epoch: 6 | loss: 0.1507458\n",
      "\tspeed: 0.1649s/iter; left time: 8703.6063s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 6 | loss: 0.2312162\n",
      "\tspeed: 0.1654s/iter; left time: 8713.4651s\n",
      "3099it [08:31,  6.06it/s]\titers: 3100, epoch: 6 | loss: 0.1921838\n",
      "\tspeed: 0.1650s/iter; left time: 8677.3767s\n",
      "3199it [08:48,  6.06it/s]\titers: 3200, epoch: 6 | loss: 0.3180024\n",
      "\tspeed: 0.1650s/iter; left time: 8662.9755s\n",
      "3299it [09:04,  6.06it/s]\titers: 3300, epoch: 6 | loss: 0.2431707\n",
      "\tspeed: 0.1650s/iter; left time: 8643.6145s\n",
      "3399it [09:21,  6.02it/s]\titers: 3400, epoch: 6 | loss: 0.3206319\n",
      "\tspeed: 0.1661s/iter; left time: 8684.3055s\n",
      "3499it [09:37,  6.02it/s]\titers: 3500, epoch: 6 | loss: 0.1330755\n",
      "\tspeed: 0.1662s/iter; left time: 8673.4567s\n",
      "3599it [09:54,  6.01it/s]\titers: 3600, epoch: 6 | loss: 0.2101490\n",
      "\tspeed: 0.1663s/iter; left time: 8661.7940s\n",
      "3699it [10:11,  6.01it/s]\titers: 3700, epoch: 6 | loss: 0.1528320\n",
      "\tspeed: 0.1661s/iter; left time: 8635.2732s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 6 cost time: 613.5400874614716\n",
      "810it [01:07, 12.04it/s]\n",
      "807it [01:06, 12.22it/s]\n",
      "Epoch: 6 | Train Loss: 0.2176258 Vali Loss: 0.2785709 Test Loss: 0.3499122 MAE Loss: 0.3487431\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.01it/s]\titers: 100, epoch: 7 | loss: 0.2541711\n",
      "\tspeed: 1.5253s/iter; left time: 79135.6988s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 7 | loss: 0.1549014\n",
      "\tspeed: 0.1652s/iter; left time: 8556.6856s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 7 | loss: 0.1478932\n",
      "\tspeed: 0.1650s/iter; left time: 8526.4342s\n",
      "399it [01:06,  6.07it/s]\titers: 400, epoch: 7 | loss: 0.2118446\n",
      "\tspeed: 0.1648s/iter; left time: 8499.0717s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 7 | loss: 0.3418238\n",
      "\tspeed: 0.1648s/iter; left time: 8484.7086s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 7 | loss: 0.2114897\n",
      "\tspeed: 0.1649s/iter; left time: 8472.1306s\n",
      "699it [01:55,  6.07it/s]\titers: 700, epoch: 7 | loss: 0.3152439\n",
      "\tspeed: 0.1649s/iter; left time: 8456.9677s\n",
      "799it [02:12,  6.08it/s]\titers: 800, epoch: 7 | loss: 0.2704783\n",
      "\tspeed: 0.1648s/iter; left time: 8433.1038s\n",
      "899it [02:28,  6.07it/s]\titers: 900, epoch: 7 | loss: 0.1504546\n",
      "\tspeed: 0.1648s/iter; left time: 8417.3560s\n",
      "999it [02:45,  6.06it/s]\titers: 1000, epoch: 7 | loss: 0.2614662\n",
      "\tspeed: 0.1648s/iter; left time: 8404.4261s\n",
      "1099it [03:01,  6.07it/s]\titers: 1100, epoch: 7 | loss: 0.1610974\n",
      "\tspeed: 0.1648s/iter; left time: 8386.8850s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 7 | loss: 0.1524183\n",
      "\tspeed: 0.1649s/iter; left time: 8372.8682s\n",
      "1299it [03:34,  6.05it/s]\titers: 1300, epoch: 7 | loss: 0.2063129\n",
      "\tspeed: 0.1649s/iter; left time: 8356.4926s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 7 | loss: 0.2505755\n",
      "\tspeed: 0.1649s/iter; left time: 8343.3217s\n",
      "1499it [04:07,  6.06it/s]\titers: 1500, epoch: 7 | loss: 0.1659269\n",
      "\tspeed: 0.1651s/iter; left time: 8333.0155s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 7 | loss: 0.1335128\n",
      "\tspeed: 0.1649s/iter; left time: 8310.1543s\n",
      "1699it [04:40,  6.07it/s]\titers: 1700, epoch: 7 | loss: 0.2171398\n",
      "\tspeed: 0.1650s/iter; left time: 8295.5780s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 7 | loss: 0.1983170\n",
      "\tspeed: 0.1653s/iter; left time: 8293.1448s\n",
      "1899it [05:13,  6.07it/s]\titers: 1900, epoch: 7 | loss: 0.2636114\n",
      "\tspeed: 0.1650s/iter; left time: 8265.9899s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 7 | loss: 0.2017506\n",
      "\tspeed: 0.1650s/iter; left time: 8247.8191s\n",
      "2099it [05:46,  6.06it/s]\titers: 2100, epoch: 7 | loss: 0.1622417\n",
      "\tspeed: 0.1650s/iter; left time: 8231.2679s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 7 | loss: 0.1553794\n",
      "\tspeed: 0.1649s/iter; left time: 8208.3233s\n",
      "2299it [06:19,  6.07it/s]\titers: 2300, epoch: 7 | loss: 0.1385574\n",
      "\tspeed: 0.1648s/iter; left time: 8186.3915s\n",
      "2399it [06:36,  6.06it/s]\titers: 2400, epoch: 7 | loss: 0.2262513\n",
      "\tspeed: 0.1648s/iter; left time: 8173.5713s\n",
      "2499it [06:52,  6.08it/s]\titers: 2500, epoch: 7 | loss: 0.2341636\n",
      "\tspeed: 0.1650s/iter; left time: 8164.8993s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 7 | loss: 0.1895728\n",
      "\tspeed: 0.1649s/iter; left time: 8145.0590s\n",
      "2699it [07:25,  6.05it/s]\titers: 2700, epoch: 7 | loss: 0.2291132\n",
      "\tspeed: 0.1652s/iter; left time: 8142.0855s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 7 | loss: 0.1883970\n",
      "\tspeed: 0.1649s/iter; left time: 8111.3484s\n",
      "2899it [07:58,  6.07it/s]\titers: 2900, epoch: 7 | loss: 0.2221040\n",
      "\tspeed: 0.1650s/iter; left time: 8098.2702s\n",
      "2999it [08:15,  6.04it/s]\titers: 3000, epoch: 7 | loss: 0.2402032\n",
      "\tspeed: 0.1650s/iter; left time: 8081.1780s\n",
      "3099it [08:31,  6.05it/s]\titers: 3100, epoch: 7 | loss: 0.2261614\n",
      "\tspeed: 0.1655s/iter; left time: 8088.4051s\n",
      "3199it [08:48,  6.06it/s]\titers: 3200, epoch: 7 | loss: 0.1397627\n",
      "\tspeed: 0.1650s/iter; left time: 8048.7683s\n",
      "3299it [09:04,  6.06it/s]\titers: 3300, epoch: 7 | loss: 0.2408195\n",
      "\tspeed: 0.1649s/iter; left time: 8026.3726s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 7 | loss: 0.1712713\n",
      "\tspeed: 0.1648s/iter; left time: 8008.4788s\n",
      "3499it [09:37,  6.06it/s]\titers: 3500, epoch: 7 | loss: 0.1677011\n",
      "\tspeed: 0.1648s/iter; left time: 7991.2047s\n",
      "3599it [09:54,  6.06it/s]\titers: 3600, epoch: 7 | loss: 0.2342540\n",
      "\tspeed: 0.1649s/iter; left time: 7978.2780s\n",
      "3699it [10:10,  6.07it/s]\titers: 3700, epoch: 7 | loss: 0.3733465\n",
      "\tspeed: 0.1649s/iter; left time: 7962.5780s\n",
      "3713it [10:12,  6.06it/s]\n",
      "Epoch: 7 cost time: 612.9264853000641\n",
      "810it [01:06, 12.27it/s]\n",
      "807it [01:06, 12.22it/s]\n",
      "Epoch: 7 | Train Loss: 0.2107309 Vali Loss: 0.2766443 Test Loss: 0.3394423 MAE Loss: 0.3441456\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 8 | loss: 0.3298483\n",
      "\tspeed: 1.5112s/iter; left time: 72794.2306s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 8 | loss: 0.2669265\n",
      "\tspeed: 0.1651s/iter; left time: 7934.4327s\n",
      "299it [00:49,  6.07it/s]\titers: 300, epoch: 8 | loss: 0.2333913\n",
      "\tspeed: 0.1650s/iter; left time: 7915.3659s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 8 | loss: 0.2487032\n",
      "\tspeed: 0.1651s/iter; left time: 7902.6481s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 8 | loss: 0.3681100\n",
      "\tspeed: 0.1653s/iter; left time: 7897.5949s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 8 | loss: 0.0917045\n",
      "\tspeed: 0.1652s/iter; left time: 7876.2558s\n",
      "699it [01:55,  6.05it/s]\titers: 700, epoch: 8 | loss: 0.1376998\n",
      "\tspeed: 0.1651s/iter; left time: 7856.0949s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 8 | loss: 0.2439343\n",
      "\tspeed: 0.1653s/iter; left time: 7848.5263s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 8 | loss: 0.2027680\n",
      "\tspeed: 0.1652s/iter; left time: 7823.4147s\n",
      "999it [02:45,  6.05it/s]\titers: 1000, epoch: 8 | loss: 0.1823879\n",
      "\tspeed: 0.1651s/iter; left time: 7803.7124s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 8 | loss: 0.1443984\n",
      "\tspeed: 0.1651s/iter; left time: 7785.8740s\n",
      "1199it [03:18,  6.04it/s]\titers: 1200, epoch: 8 | loss: 0.1527426\n",
      "\tspeed: 0.1650s/iter; left time: 7766.8329s\n",
      "1299it [03:34,  6.05it/s]\titers: 1300, epoch: 8 | loss: 0.1118855\n",
      "\tspeed: 0.1649s/iter; left time: 7746.1369s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 8 | loss: 0.1467440\n",
      "\tspeed: 0.1649s/iter; left time: 7730.3414s\n",
      "1499it [04:07,  6.07it/s]\titers: 1500, epoch: 8 | loss: 0.1428618\n",
      "\tspeed: 0.1651s/iter; left time: 7719.6927s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 8 | loss: 0.3212835\n",
      "\tspeed: 0.1649s/iter; left time: 7696.5782s\n",
      "1699it [04:40,  6.07it/s]\titers: 1700, epoch: 8 | loss: 0.1496501\n",
      "\tspeed: 0.1650s/iter; left time: 7684.6012s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 8 | loss: 0.1985523\n",
      "\tspeed: 0.1649s/iter; left time: 7665.0347s\n",
      "1899it [05:13,  6.06it/s]\titers: 1900, epoch: 8 | loss: 0.1535857\n",
      "\tspeed: 0.1651s/iter; left time: 7653.9031s\n",
      "1999it [05:30,  6.05it/s]\titers: 2000, epoch: 8 | loss: 0.1201866\n",
      "\tspeed: 0.1651s/iter; left time: 7639.1426s\n",
      "2099it [05:46,  6.05it/s]\titers: 2100, epoch: 8 | loss: 0.3150806\n",
      "\tspeed: 0.1651s/iter; left time: 7621.6336s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 8 | loss: 0.2079505\n",
      "\tspeed: 0.1650s/iter; left time: 7601.8463s\n",
      "2299it [06:19,  6.06it/s]\titers: 2300, epoch: 8 | loss: 0.2082558\n",
      "\tspeed: 0.1650s/iter; left time: 7586.5284s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 8 | loss: 0.2701536\n",
      "\tspeed: 0.1650s/iter; left time: 7569.6879s\n",
      "2499it [06:52,  6.06it/s]\titers: 2500, epoch: 8 | loss: 0.2023678\n",
      "\tspeed: 0.1650s/iter; left time: 7552.8475s\n",
      "2599it [07:09,  6.07it/s]\titers: 2600, epoch: 8 | loss: 0.2593740\n",
      "\tspeed: 0.1649s/iter; left time: 7528.9814s\n",
      "2699it [07:25,  6.06it/s]\titers: 2700, epoch: 8 | loss: 0.2293651\n",
      "\tspeed: 0.1650s/iter; left time: 7520.8894s\n",
      "2799it [07:42,  6.05it/s]\titers: 2800, epoch: 8 | loss: 0.3529310\n",
      "\tspeed: 0.1651s/iter; left time: 7509.0288s\n",
      "2899it [07:58,  6.06it/s]\titers: 2900, epoch: 8 | loss: 0.2058366\n",
      "\tspeed: 0.1651s/iter; left time: 7491.9856s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 8 | loss: 0.1292022\n",
      "\tspeed: 0.1651s/iter; left time: 7474.3124s\n",
      "3099it [08:31,  6.07it/s]\titers: 3100, epoch: 8 | loss: 0.2198117\n",
      "\tspeed: 0.1651s/iter; left time: 7457.9395s\n",
      "3199it [08:48,  6.06it/s]\titers: 3200, epoch: 8 | loss: 0.1692322\n",
      "\tspeed: 0.1649s/iter; left time: 7432.5786s\n",
      "3299it [09:04,  6.06it/s]\titers: 3300, epoch: 8 | loss: 0.2345814\n",
      "\tspeed: 0.1649s/iter; left time: 7417.3672s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 8 | loss: 0.1757052\n",
      "\tspeed: 0.1649s/iter; left time: 7400.9534s\n",
      "3499it [09:37,  6.05it/s]\titers: 3500, epoch: 8 | loss: 0.2877286\n",
      "\tspeed: 0.1651s/iter; left time: 7389.6868s\n",
      "3599it [09:54,  6.06it/s]\titers: 3600, epoch: 8 | loss: 0.2865143\n",
      "\tspeed: 0.1651s/iter; left time: 7374.4586s\n",
      "3699it [10:10,  6.06it/s]\titers: 3700, epoch: 8 | loss: 0.2928365\n",
      "\tspeed: 0.1650s/iter; left time: 7354.6265s\n",
      "3713it [10:13,  6.06it/s]\n",
      "Epoch: 8 cost time: 613.191579580307\n",
      "810it [01:06, 12.27it/s]\n",
      "807it [01:06, 12.19it/s]\n",
      "Epoch: 8 | Train Loss: 0.2050531 Vali Loss: 0.2857528 Test Loss: 0.3534776 MAE Loss: 0.3494674\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "62it [00:10,  6.07it/s]^C\n",
      "62it [00:10,  5.88it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 232, in <module>\n",
      "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1852, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 238, in forward\n",
      "    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 285, in forecast\n",
      "    dec_out = self.llm_model(inputs_embeds=llama_enc_out).last_hidden_state\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 900, in forward\n",
      "    outputs = block(\n",
      "              ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 391, in forward\n",
      "    attn_outputs = self.attn(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 332, in forward\n",
      "    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 202, in _attn\n",
      "    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 101.6835296789805 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --lradj 'constant' \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3.9999999999999996e-05\n",
    "# lr = 0.0000400000\n",
    "vali_loss = [0.3308652, 0.2944952, 0.2804815, 0.2732254, 0.2882608, 0.2785709, 0.2766443, 0.2857528]\n",
    "tr_loss = [0.2939578, 0.2525803, 0.2425671, 0.2335046, 0.2254678, 0.2176258, 0.2107309, 0.2050531]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_val_loss(train_loss, val_loss, lr=None):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss with optional learning rate values.\n",
    "    \n",
    "    Args:\n",
    "    train_loss (list): List containing training loss values for each epoch.\n",
    "    val_loss (list): List containing validation loss values for each epoch.\n",
    "    lr_values (list, optional): List containing learning rate values for each epoch.\n",
    "    \n",
    "    Returns:\n",
    "    legend_labels (list): List containing legend labels for the plot.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    legend_labels = []\n",
    "\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "    legend_labels.append('Training Loss')\n",
    "\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    legend_labels.append('Validation Loss')\n",
    "\n",
    "    plt.title(f'Training and Validation Loss for Learning rate {lr}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return legend_labels\n",
    "\n",
    "legend_labels = plot_train_val_loss(tr_loss, vali_loss, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant lr smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-06 21:43:00,106] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-06 21:43:01,058] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-06 21:43:01,059] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-06 21:43:01,059] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-06 21:43:02,012] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-06 21:43:02,013] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-06 21:43:02,947] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-06 21:43:02,948] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-06 21:43:02,949] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-06 21:43:02,950] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-06 21:43:02,950] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-06 21:43:02,950] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-06 21:43:02,950] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-06 21:43:02,951] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-06 21:43:02,951] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-06 21:43:02,951] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-06 21:43:03,425] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-06 21:43:03,426] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-06 21:43:03,427] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 146.5 GB, percent = 19.4%\n",
      "[2024-05-06 21:43:03,659] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-06 21:43:03,660] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 21:43:03,661] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 146.56 GB, percent = 19.4%\n",
      "[2024-05-06 21:43:03,661] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-06 21:43:03,882] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-06 21:43:03,883] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-06 21:43:03,884] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 146.71 GB, percent = 19.4%\n",
      "[2024-05-06 21:43:03,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-06 21:43:03,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-06 21:43:03,885] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-06 21:43:03,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-06 21:43:03,886] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-06 21:43:03,887] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-06 21:43:03,887] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-06 21:43:03,887] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-06 21:43:03,887] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f43ea5ee950>\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-06 21:43:03,888] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-06 21:43:03,889] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-06 21:43:03,890] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-06 21:43:03,891] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:25,  4.56it/s]\titers: 100, epoch: 1 | loss: 0.4618609\n",
      "\tspeed: 0.3041s/iter; left time: 22549.6256s\n",
      "199it [00:48,  4.15it/s]\titers: 200, epoch: 1 | loss: 0.3899240\n",
      "\tspeed: 0.2335s/iter; left time: 17290.9916s\n",
      "299it [01:13,  3.46it/s]\titers: 300, epoch: 1 | loss: 0.3661842\n",
      "\tspeed: 0.2494s/iter; left time: 18446.1600s\n",
      "399it [01:39,  3.75it/s]\titers: 400, epoch: 1 | loss: 0.1881032\n",
      "\tspeed: 0.2536s/iter; left time: 18733.9243s\n",
      "499it [02:03,  4.60it/s]\titers: 500, epoch: 1 | loss: 0.2263861\n",
      "\tspeed: 0.2396s/iter; left time: 17674.6493s\n",
      "599it [02:26,  4.42it/s]\titers: 600, epoch: 1 | loss: 0.2624842\n",
      "\tspeed: 0.2301s/iter; left time: 16950.6121s\n",
      "699it [02:51,  4.12it/s]\titers: 700, epoch: 1 | loss: 0.2973318\n",
      "\tspeed: 0.2481s/iter; left time: 18248.3444s\n",
      "799it [03:23,  2.88it/s]\titers: 800, epoch: 1 | loss: 0.3241043\n",
      "\tspeed: 0.3241s/iter; left time: 23805.9217s\n",
      "899it [03:55,  3.30it/s]\titers: 900, epoch: 1 | loss: 0.2249994\n",
      "\tspeed: 0.3200s/iter; left time: 23473.5082s\n",
      "999it [04:24,  4.12it/s]\titers: 1000, epoch: 1 | loss: 0.2316564\n",
      "\tspeed: 0.2869s/iter; left time: 21015.9704s\n",
      "1099it [04:48,  4.08it/s]\titers: 1100, epoch: 1 | loss: 0.2588322\n",
      "\tspeed: 0.2454s/iter; left time: 17951.9633s\n",
      "1199it [05:12,  4.43it/s]\titers: 1200, epoch: 1 | loss: 0.1702397\n",
      "\tspeed: 0.2375s/iter; left time: 17351.4299s\n",
      "1299it [05:34,  4.85it/s]\titers: 1300, epoch: 1 | loss: 0.2180093\n",
      "\tspeed: 0.2195s/iter; left time: 16011.9917s\n",
      "1399it [05:57,  3.48it/s]\titers: 1400, epoch: 1 | loss: 0.2449195\n",
      "\tspeed: 0.2358s/iter; left time: 17183.6233s\n",
      "1499it [06:22,  4.21it/s]\titers: 1500, epoch: 1 | loss: 0.2832335\n",
      "\tspeed: 0.2405s/iter; left time: 17498.0398s\n",
      "1599it [06:45,  4.45it/s]\titers: 1600, epoch: 1 | loss: 0.2898077\n",
      "\tspeed: 0.2357s/iter; left time: 17124.0116s\n",
      "1699it [07:09,  4.36it/s]\titers: 1700, epoch: 1 | loss: 0.3521157\n",
      "\tspeed: 0.2347s/iter; left time: 17033.2314s\n",
      "1799it [07:33,  4.22it/s]\titers: 1800, epoch: 1 | loss: 0.2451236\n",
      "\tspeed: 0.2436s/iter; left time: 17652.4526s\n",
      "1899it [07:56,  4.51it/s]\titers: 1900, epoch: 1 | loss: 0.2947961\n",
      "\tspeed: 0.2352s/iter; left time: 17019.5375s\n",
      "1999it [08:19,  4.66it/s]\titers: 2000, epoch: 1 | loss: 0.2152199\n",
      "\tspeed: 0.2249s/iter; left time: 16254.3151s\n",
      "2099it [08:41,  5.06it/s]\titers: 2100, epoch: 1 | loss: 0.1692189\n",
      "\tspeed: 0.2201s/iter; left time: 15879.1157s\n",
      "2199it [09:01,  4.98it/s]\titers: 2200, epoch: 1 | loss: 0.1638385\n",
      "\tspeed: 0.2033s/iter; left time: 14651.2274s\n",
      "2299it [09:23,  5.16it/s]\titers: 2300, epoch: 1 | loss: 0.3102884\n",
      "\tspeed: 0.2145s/iter; left time: 15437.2342s\n",
      "2399it [09:47,  3.85it/s]\titers: 2400, epoch: 1 | loss: 0.5121620\n",
      "\tspeed: 0.2395s/iter; left time: 17209.6547s\n",
      "2499it [10:10,  4.75it/s]\titers: 2500, epoch: 1 | loss: 0.2398673\n",
      "\tspeed: 0.2335s/iter; left time: 16758.6342s\n",
      "2599it [10:30,  4.97it/s]\titers: 2600, epoch: 1 | loss: 0.1561184\n",
      "\tspeed: 0.2034s/iter; left time: 14578.2102s\n",
      "2699it [10:51,  5.07it/s]\titers: 2700, epoch: 1 | loss: 0.2536733\n",
      "\tspeed: 0.2028s/iter; left time: 14515.9815s\n",
      "2799it [11:11,  4.32it/s]\titers: 2800, epoch: 1 | loss: 0.1188028\n",
      "\tspeed: 0.2001s/iter; left time: 14299.1723s\n",
      "2899it [11:31,  4.34it/s]\titers: 2900, epoch: 1 | loss: 0.4120305\n",
      "\tspeed: 0.2051s/iter; left time: 14636.3250s\n",
      "2999it [11:51,  4.99it/s]\titers: 3000, epoch: 1 | loss: 0.1284291\n",
      "\tspeed: 0.2007s/iter; left time: 14302.9352s\n",
      "3099it [12:11,  5.27it/s]\titers: 3100, epoch: 1 | loss: 0.2454490\n",
      "\tspeed: 0.2011s/iter; left time: 14310.0357s\n",
      "3199it [12:34,  4.13it/s]\titers: 3200, epoch: 1 | loss: 0.4085863\n",
      "\tspeed: 0.2277s/iter; left time: 16183.1309s\n",
      "3299it [12:58,  4.23it/s]\titers: 3300, epoch: 1 | loss: 0.2168726\n",
      "\tspeed: 0.2381s/iter; left time: 16895.3107s\n",
      "3399it [13:22,  4.26it/s]\titers: 3400, epoch: 1 | loss: 0.2877906\n",
      "\tspeed: 0.2373s/iter; left time: 16816.5675s\n",
      "3499it [13:45,  4.44it/s]\titers: 3500, epoch: 1 | loss: 0.4339239\n",
      "\tspeed: 0.2334s/iter; left time: 16519.0590s\n",
      "3599it [14:09,  4.01it/s]\titers: 3600, epoch: 1 | loss: 0.4449164\n",
      "\tspeed: 0.2428s/iter; left time: 17157.0385s\n",
      "3699it [14:33,  4.19it/s]\titers: 3700, epoch: 1 | loss: 0.1339988\n",
      "\tspeed: 0.2404s/iter; left time: 16960.9301s\n",
      "3713it [14:37,  4.23it/s]\n",
      "Epoch: 1 cost time: 877.1121261119843\n",
      "810it [01:48,  7.49it/s]\n",
      "807it [01:43,  7.79it/s]\n",
      "Epoch: 1 | Train Loss: 0.2939578 Vali Loss: 0.3308652 Test Loss: 0.4116031 MAE Loss: 0.4164754\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:21,  3.66it/s]\titers: 100, epoch: 2 | loss: 0.2224971\n",
      "\tspeed: 2.3833s/iter; left time: 167895.2070s\n",
      "199it [00:48,  3.90it/s]\titers: 200, epoch: 2 | loss: 0.1859257\n",
      "\tspeed: 0.2691s/iter; left time: 18930.2428s\n",
      "299it [01:15,  3.77it/s]\titers: 300, epoch: 2 | loss: 0.1712774\n",
      "\tspeed: 0.2676s/iter; left time: 18796.9512s\n",
      "399it [01:42,  3.46it/s]\titers: 400, epoch: 2 | loss: 0.3535642\n",
      "\tspeed: 0.2715s/iter; left time: 19048.0880s\n",
      "499it [02:09,  3.92it/s]\titers: 500, epoch: 2 | loss: 0.1553607\n",
      "\tspeed: 0.2673s/iter; left time: 18720.9801s\n",
      "599it [02:36,  3.90it/s]\titers: 600, epoch: 2 | loss: 0.3271545\n",
      "\tspeed: 0.2691s/iter; left time: 18824.4452s\n",
      "699it [03:03,  3.74it/s]\titers: 700, epoch: 2 | loss: 0.1733966\n",
      "\tspeed: 0.2691s/iter; left time: 18795.6597s\n",
      "799it [03:29,  3.68it/s]\titers: 800, epoch: 2 | loss: 0.2167310\n",
      "\tspeed: 0.2689s/iter; left time: 18752.5068s\n",
      "899it [03:57,  3.86it/s]\titers: 900, epoch: 2 | loss: 0.5247744\n",
      "\tspeed: 0.2722s/iter; left time: 18958.2236s\n",
      "999it [04:24,  4.03it/s]\titers: 1000, epoch: 2 | loss: 0.1824759\n",
      "\tspeed: 0.2728s/iter; left time: 18974.9284s\n",
      "1099it [04:51,  3.67it/s]\titers: 1100, epoch: 2 | loss: 0.1982229\n",
      "\tspeed: 0.2679s/iter; left time: 18605.1637s\n",
      "1199it [05:18,  3.57it/s]\titers: 1200, epoch: 2 | loss: 0.2970625\n",
      "\tspeed: 0.2692s/iter; left time: 18671.7211s\n",
      "1299it [05:45,  3.76it/s]\titers: 1300, epoch: 2 | loss: 0.1361262\n",
      "\tspeed: 0.2690s/iter; left time: 18624.5131s\n",
      "1399it [06:12,  3.45it/s]\titers: 1400, epoch: 2 | loss: 0.2503983\n",
      "\tspeed: 0.2693s/iter; left time: 18622.3277s\n",
      "1499it [06:38,  3.80it/s]\titers: 1500, epoch: 2 | loss: 0.1705465\n",
      "\tspeed: 0.2694s/iter; left time: 18602.5501s\n",
      "1599it [07:05,  3.50it/s]\titers: 1600, epoch: 2 | loss: 0.4130092\n",
      "\tspeed: 0.2693s/iter; left time: 18569.0408s\n",
      "1699it [07:32,  3.75it/s]\titers: 1700, epoch: 2 | loss: 0.2882046\n",
      "\tspeed: 0.2669s/iter; left time: 18378.1914s\n",
      "1799it [07:59,  3.52it/s]\titers: 1800, epoch: 2 | loss: 0.3682458\n",
      "\tspeed: 0.2699s/iter; left time: 18553.6594s\n",
      "1899it [08:26,  3.62it/s]\titers: 1900, epoch: 2 | loss: 0.2611897\n",
      "\tspeed: 0.2722s/iter; left time: 18686.7374s\n",
      "1999it [08:53,  3.68it/s]\titers: 2000, epoch: 2 | loss: 0.3657560\n",
      "\tspeed: 0.2699s/iter; left time: 18499.2839s\n",
      "2099it [09:20,  3.40it/s]\titers: 2100, epoch: 2 | loss: 0.4125029\n",
      "\tspeed: 0.2716s/iter; left time: 18592.0894s\n",
      "2199it [09:47,  3.99it/s]\titers: 2200, epoch: 2 | loss: 0.2298530\n",
      "\tspeed: 0.2678s/iter; left time: 18306.5461s\n",
      "2299it [10:14,  3.56it/s]\titers: 2300, epoch: 2 | loss: 0.3731268\n",
      "\tspeed: 0.2708s/iter; left time: 18481.0385s\n",
      "2399it [10:41,  3.92it/s]\titers: 2400, epoch: 2 | loss: 0.2681029\n",
      "\tspeed: 0.2705s/iter; left time: 18436.0610s\n",
      "2499it [11:09,  3.46it/s]\titers: 2500, epoch: 2 | loss: 0.1745616\n",
      "\tspeed: 0.2730s/iter; left time: 18575.8190s\n",
      "2599it [11:35,  3.88it/s]\titers: 2600, epoch: 2 | loss: 0.2134498\n",
      "\tspeed: 0.2692s/iter; left time: 18289.7858s\n",
      "2699it [12:02,  3.61it/s]\titers: 2700, epoch: 2 | loss: 0.2731954\n",
      "\tspeed: 0.2697s/iter; left time: 18299.9647s\n",
      "2799it [12:29,  3.99it/s]\titers: 2800, epoch: 2 | loss: 0.3241251\n",
      "\tspeed: 0.2685s/iter; left time: 18190.5074s\n",
      "2899it [12:56,  3.96it/s]\titers: 2900, epoch: 2 | loss: 0.2614107\n",
      "\tspeed: 0.2698s/iter; left time: 18251.2561s\n",
      "2999it [13:23,  3.95it/s]\titers: 3000, epoch: 2 | loss: 0.2456034\n",
      "\tspeed: 0.2692s/iter; left time: 18186.6983s\n",
      "3099it [13:50,  3.98it/s]\titers: 3100, epoch: 2 | loss: 0.2389004\n",
      "\tspeed: 0.2702s/iter; left time: 18221.7308s\n",
      "3199it [14:17,  3.56it/s]\titers: 3200, epoch: 2 | loss: 0.2119864\n",
      "\tspeed: 0.2674s/iter; left time: 18005.7525s\n",
      "3299it [14:44,  3.73it/s]\titers: 3300, epoch: 2 | loss: 0.2090339\n",
      "\tspeed: 0.2701s/iter; left time: 18164.5499s\n",
      "3399it [15:11,  3.79it/s]\titers: 3400, epoch: 2 | loss: 0.2690893\n",
      "\tspeed: 0.2693s/iter; left time: 18084.0776s\n",
      "3499it [15:38,  3.58it/s]\titers: 3500, epoch: 2 | loss: 0.2042641\n",
      "\tspeed: 0.2708s/iter; left time: 18156.6308s\n",
      "3599it [16:05,  3.67it/s]\titers: 3600, epoch: 2 | loss: 0.2135072\n",
      "\tspeed: 0.2672s/iter; left time: 17887.5698s\n",
      "3699it [16:32,  4.04it/s]\titers: 3700, epoch: 2 | loss: 0.3245580\n",
      "\tspeed: 0.2681s/iter; left time: 17924.6338s\n",
      "3713it [16:35,  3.73it/s]\n",
      "Epoch: 2 cost time: 995.8520438671112\n",
      "810it [01:49,  7.37it/s]\n",
      "807it [01:50,  7.31it/s]\n",
      "Epoch: 2 | Train Loss: 0.2525803 Vali Loss: 0.2944952 Test Loss: 0.3529874 MAE Loss: 0.3705082\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9999999999999998e-05\n",
      "99it [00:26,  3.51it/s]\titers: 100, epoch: 3 | loss: 0.2678785\n",
      "\tspeed: 2.5207s/iter; left time: 168220.2429s\n",
      "199it [00:53,  3.63it/s]\titers: 200, epoch: 3 | loss: 0.1674327\n",
      "\tspeed: 0.2671s/iter; left time: 17799.8544s\n",
      "299it [01:20,  3.91it/s]\titers: 300, epoch: 3 | loss: 0.4267685\n",
      "\tspeed: 0.2686s/iter; left time: 17873.6890s\n",
      "399it [01:47,  3.99it/s]\titers: 400, epoch: 3 | loss: 0.2516339\n",
      "\tspeed: 0.2685s/iter; left time: 17840.1958s\n",
      "499it [02:14,  4.02it/s]\titers: 500, epoch: 3 | loss: 0.1821910\n",
      "\tspeed: 0.2699s/iter; left time: 17904.8083s\n",
      "599it [02:40,  4.06it/s]\titers: 600, epoch: 3 | loss: 0.2322658\n",
      "\tspeed: 0.2681s/iter; left time: 17759.5223s\n",
      "699it [03:07,  4.05it/s]\titers: 700, epoch: 3 | loss: 0.1856309\n",
      "\tspeed: 0.2670s/iter; left time: 17659.3169s\n",
      "799it [03:34,  3.65it/s]\titers: 800, epoch: 3 | loss: 0.1964826\n",
      "\tspeed: 0.2659s/iter; left time: 17555.4485s\n",
      "899it [04:01,  3.84it/s]\titers: 900, epoch: 3 | loss: 0.1303349\n",
      "\tspeed: 0.2678s/iter; left time: 17659.4320s\n",
      "999it [04:28,  3.63it/s]\titers: 1000, epoch: 3 | loss: 0.1626356\n",
      "\tspeed: 0.2689s/iter; left time: 17701.9947s\n",
      "1099it [04:55,  3.37it/s]\titers: 1100, epoch: 3 | loss: 0.1787162\n",
      "\tspeed: 0.2697s/iter; left time: 17729.6578s\n",
      "1199it [05:21,  4.01it/s]\titers: 1200, epoch: 3 | loss: 0.1129908\n",
      "\tspeed: 0.2682s/iter; left time: 17601.0118s\n",
      "1299it [05:48,  3.73it/s]\titers: 1300, epoch: 3 | loss: 0.2076112\n",
      "\tspeed: 0.2683s/iter; left time: 17580.2253s\n",
      "1399it [06:15,  3.74it/s]\titers: 1400, epoch: 3 | loss: 0.2140674\n",
      "\tspeed: 0.2690s/iter; left time: 17598.9425s\n",
      "1499it [06:42,  3.77it/s]\titers: 1500, epoch: 3 | loss: 0.3660554\n",
      "\tspeed: 0.2667s/iter; left time: 17422.2767s\n",
      "1599it [07:09,  3.63it/s]\titers: 1600, epoch: 3 | loss: 0.2766093\n",
      "\tspeed: 0.2695s/iter; left time: 17579.9813s\n",
      "1699it [07:36,  3.44it/s]\titers: 1700, epoch: 3 | loss: 0.1679721\n",
      "\tspeed: 0.2708s/iter; left time: 17639.8798s\n",
      "1799it [08:03,  3.95it/s]\titers: 1800, epoch: 3 | loss: 0.1587199\n",
      "\tspeed: 0.2703s/iter; left time: 17579.0041s\n",
      "1899it [08:30,  3.44it/s]\titers: 1900, epoch: 3 | loss: 0.2988014\n",
      "\tspeed: 0.2709s/iter; left time: 17592.0600s\n",
      "1999it [08:57,  3.68it/s]\titers: 2000, epoch: 3 | loss: 0.3403270\n",
      "\tspeed: 0.2728s/iter; left time: 17684.2858s\n",
      "2099it [09:24,  3.42it/s]\titers: 2100, epoch: 3 | loss: 0.1497357\n",
      "\tspeed: 0.2690s/iter; left time: 17411.0319s\n",
      "2199it [09:51,  3.50it/s]\titers: 2200, epoch: 3 | loss: 0.1858855\n",
      "\tspeed: 0.2695s/iter; left time: 17418.7941s\n",
      "2299it [10:18,  3.59it/s]\titers: 2300, epoch: 3 | loss: 0.1344990\n",
      "\tspeed: 0.2694s/iter; left time: 17384.7882s\n",
      "2399it [10:45,  4.04it/s]\titers: 2400, epoch: 3 | loss: 0.4487908\n",
      "\tspeed: 0.2682s/iter; left time: 17278.3902s\n",
      "2499it [11:12,  3.76it/s]\titers: 2500, epoch: 3 | loss: 0.1240880\n",
      "\tspeed: 0.2682s/iter; left time: 17257.6889s\n",
      "2599it [11:39,  3.59it/s]\titers: 2600, epoch: 3 | loss: 0.3050545\n",
      "\tspeed: 0.2692s/iter; left time: 17291.2027s\n",
      "2699it [12:05,  3.56it/s]\titers: 2700, epoch: 3 | loss: 0.1835628\n",
      "\tspeed: 0.2696s/iter; left time: 17292.8410s\n",
      "2799it [12:32,  3.75it/s]\titers: 2800, epoch: 3 | loss: 0.1599916\n",
      "\tspeed: 0.2697s/iter; left time: 17269.9258s\n",
      "2899it [12:59,  3.55it/s]\titers: 2900, epoch: 3 | loss: 0.2173600\n",
      "\tspeed: 0.2674s/iter; left time: 17093.6895s\n",
      "2999it [13:26,  3.66it/s]\titers: 3000, epoch: 3 | loss: 0.1861257\n",
      "\tspeed: 0.2678s/iter; left time: 17093.1707s\n",
      "3099it [13:53,  3.67it/s]\titers: 3100, epoch: 3 | loss: 0.2630371\n",
      "\tspeed: 0.2712s/iter; left time: 17284.0130s\n",
      "3199it [14:20,  3.42it/s]\titers: 3200, epoch: 3 | loss: 0.3043454\n",
      "\tspeed: 0.2721s/iter; left time: 17317.3356s\n",
      "3299it [14:47,  4.01it/s]\titers: 3300, epoch: 3 | loss: 0.2847129\n",
      "\tspeed: 0.2690s/iter; left time: 17088.3342s\n",
      "3399it [15:14,  3.91it/s]\titers: 3400, epoch: 3 | loss: 0.1586522\n",
      "\tspeed: 0.2675s/iter; left time: 16967.5441s\n",
      "3499it [15:41,  4.01it/s]\titers: 3500, epoch: 3 | loss: 0.2263321\n",
      "\tspeed: 0.2685s/iter; left time: 17006.9280s\n",
      "3599it [16:08,  3.39it/s]\titers: 3600, epoch: 3 | loss: 0.3105630\n",
      "\tspeed: 0.2688s/iter; left time: 16998.5985s\n",
      "3699it [16:35,  3.92it/s]\titers: 3700, epoch: 3 | loss: 0.1623395\n",
      "\tspeed: 0.2702s/iter; left time: 17060.7400s\n",
      "3713it [16:39,  3.72it/s]\n",
      "Epoch: 3 cost time: 999.0039944648743\n",
      "810it [01:50,  7.34it/s]\n",
      "807it [01:51,  7.26it/s]\n",
      "Epoch: 3 | Train Loss: 0.2377872 Vali Loss: 0.2767047 Test Loss: 0.3387802 MAE Loss: 0.3531345\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.999999999999999e-06\n",
      "99it [00:27,  3.70it/s]\titers: 100, epoch: 4 | loss: 0.2302269\n",
      "\tspeed: 2.5392s/iter; left time: 160025.8872s\n",
      "199it [00:54,  3.53it/s]\titers: 200, epoch: 4 | loss: 0.1519678\n",
      "\tspeed: 0.2701s/iter; left time: 16994.9667s\n",
      "299it [01:21,  3.46it/s]\titers: 300, epoch: 4 | loss: 0.1947016\n",
      "\tspeed: 0.2674s/iter; left time: 16798.9548s\n",
      "399it [01:48,  3.51it/s]\titers: 400, epoch: 4 | loss: 0.3380030\n",
      "\tspeed: 0.2699s/iter; left time: 16930.7935s\n",
      "499it [02:14,  3.66it/s]\titers: 500, epoch: 4 | loss: 0.4385766\n",
      "\tspeed: 0.2674s/iter; left time: 16744.9728s\n",
      "599it [02:41,  3.81it/s]\titers: 600, epoch: 4 | loss: 0.2055491\n",
      "\tspeed: 0.2673s/iter; left time: 16711.0159s\n",
      "699it [03:08,  3.79it/s]\titers: 700, epoch: 4 | loss: 0.2657663\n",
      "\tspeed: 0.2670s/iter; left time: 16667.6663s\n",
      "799it [03:34,  3.60it/s]\titers: 800, epoch: 4 | loss: 0.2826761\n",
      "\tspeed: 0.2672s/iter; left time: 16651.6395s\n",
      "899it [04:01,  3.76it/s]\titers: 900, epoch: 4 | loss: 0.2096443\n",
      "\tspeed: 0.2695s/iter; left time: 16771.0043s\n",
      "999it [04:28,  3.92it/s]\titers: 1000, epoch: 4 | loss: 0.2965952\n",
      "\tspeed: 0.2693s/iter; left time: 16730.5277s\n",
      "1099it [04:55,  3.92it/s]\titers: 1100, epoch: 4 | loss: 0.1868688\n",
      "\tspeed: 0.2690s/iter; left time: 16686.1736s\n",
      "1199it [05:22,  3.98it/s]\titers: 1200, epoch: 4 | loss: 0.2999346\n",
      "\tspeed: 0.2704s/iter; left time: 16745.3211s\n",
      "1299it [05:40,  5.81it/s]\titers: 1300, epoch: 4 | loss: 0.1675709\n",
      "\tspeed: 0.1790s/iter; left time: 11069.0690s\n",
      "1399it [05:58,  5.78it/s]\titers: 1400, epoch: 4 | loss: 0.3164928\n",
      "\tspeed: 0.1764s/iter; left time: 10885.9217s\n",
      "1499it [06:16,  5.63it/s]\titers: 1500, epoch: 4 | loss: 0.2255029\n",
      "\tspeed: 0.1781s/iter; left time: 10976.0742s\n",
      "1599it [06:33,  5.25it/s]\titers: 1600, epoch: 4 | loss: 0.1664042\n",
      "\tspeed: 0.1777s/iter; left time: 10932.6294s\n",
      "1699it [06:51,  5.73it/s]\titers: 1700, epoch: 4 | loss: 0.2703114\n",
      "\tspeed: 0.1780s/iter; left time: 10930.1627s\n",
      "1799it [07:09,  5.44it/s]\titers: 1800, epoch: 4 | loss: 0.1217620\n",
      "\tspeed: 0.1789s/iter; left time: 10969.9696s\n",
      "1899it [07:27,  5.76it/s]\titers: 1900, epoch: 4 | loss: 0.4185049\n",
      "\tspeed: 0.1767s/iter; left time: 10820.8235s\n",
      "1999it [07:44,  5.88it/s]\titers: 2000, epoch: 4 | loss: 0.1530148\n",
      "\tspeed: 0.1776s/iter; left time: 10852.2792s\n",
      "2099it [08:02,  5.44it/s]\titers: 2100, epoch: 4 | loss: 0.2935142\n",
      "\tspeed: 0.1780s/iter; left time: 10862.5048s\n",
      "2199it [08:20,  5.74it/s]\titers: 2200, epoch: 4 | loss: 0.2941075\n",
      "\tspeed: 0.1780s/iter; left time: 10842.6767s\n",
      "2299it [08:38,  5.91it/s]\titers: 2300, epoch: 4 | loss: 0.2513675\n",
      "\tspeed: 0.1783s/iter; left time: 10845.1765s\n",
      "2399it [08:56,  5.48it/s]\titers: 2400, epoch: 4 | loss: 0.1935322\n",
      "\tspeed: 0.1784s/iter; left time: 10835.4809s\n",
      "2499it [09:12,  6.03it/s]\titers: 2500, epoch: 4 | loss: 0.2248653\n",
      "\tspeed: 0.1673s/iter; left time: 10142.0810s\n",
      "2599it [09:29,  6.01it/s]\titers: 2600, epoch: 4 | loss: 0.1975118\n",
      "\tspeed: 0.1665s/iter; left time: 10078.3117s\n",
      "2699it [09:46,  6.03it/s]\titers: 2700, epoch: 4 | loss: 0.3102058\n",
      "\tspeed: 0.1663s/iter; left time: 10049.9172s\n",
      "2799it [10:02,  6.00it/s]\titers: 2800, epoch: 4 | loss: 0.2257711\n",
      "\tspeed: 0.1667s/iter; left time: 10056.3984s\n",
      "2899it [10:19,  6.04it/s]\titers: 2900, epoch: 4 | loss: 0.1824213\n",
      "\tspeed: 0.1660s/iter; left time: 9994.6610s\n",
      "2999it [10:36,  6.04it/s]\titers: 3000, epoch: 4 | loss: 0.1719320\n",
      "\tspeed: 0.1657s/iter; left time: 9959.2703s\n",
      "3099it [10:52,  6.04it/s]\titers: 3100, epoch: 4 | loss: 0.2167577\n",
      "\tspeed: 0.1656s/iter; left time: 9939.6469s\n",
      "3199it [11:09,  6.03it/s]\titers: 3200, epoch: 4 | loss: 0.1569450\n",
      "\tspeed: 0.1656s/iter; left time: 9925.1464s\n",
      "3299it [11:25,  6.03it/s]\titers: 3300, epoch: 4 | loss: 0.2764925\n",
      "\tspeed: 0.1656s/iter; left time: 9907.5438s\n",
      "3399it [11:42,  6.03it/s]\titers: 3400, epoch: 4 | loss: 0.3132670\n",
      "\tspeed: 0.1656s/iter; left time: 9887.6437s\n",
      "3499it [11:58,  6.03it/s]\titers: 3500, epoch: 4 | loss: 0.0984701\n",
      "\tspeed: 0.1658s/iter; left time: 9885.2491s\n",
      "3599it [12:15,  6.04it/s]\titers: 3600, epoch: 4 | loss: 0.2249958\n",
      "\tspeed: 0.1657s/iter; left time: 9860.9031s\n",
      "3699it [12:32,  6.03it/s]\titers: 3700, epoch: 4 | loss: 0.1409733\n",
      "\tspeed: 0.1656s/iter; left time: 9837.5409s\n",
      "3713it [12:34,  4.92it/s]\n",
      "Epoch: 4 cost time: 754.4243271350861\n",
      "810it [01:07, 12.09it/s]\n",
      "807it [01:06, 12.23it/s]\n",
      "Epoch: 4 | Train Loss: 0.2289110 Vali Loss: 0.2725649 Test Loss: 0.3406612 MAE Loss: 0.3557740\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 4.9999999999999996e-06\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 5 | loss: 0.4057335\n",
      "\tspeed: 1.5337s/iter; left time: 90963.6202s\n",
      "199it [00:33,  6.04it/s]\titers: 200, epoch: 5 | loss: 0.1495539\n",
      "\tspeed: 0.1657s/iter; left time: 9809.5550s\n",
      "299it [00:49,  6.04it/s]\titers: 300, epoch: 5 | loss: 0.1126435\n",
      "\tspeed: 0.1656s/iter; left time: 9789.2529s\n",
      "399it [01:06,  6.04it/s]\titers: 400, epoch: 5 | loss: 0.2036536\n",
      "\tspeed: 0.1655s/iter; left time: 9766.0494s\n",
      "499it [01:22,  6.03it/s]\titers: 500, epoch: 5 | loss: 0.1856287\n",
      "\tspeed: 0.1655s/iter; left time: 9750.4954s\n",
      "599it [01:39,  6.03it/s]\titers: 600, epoch: 5 | loss: 0.4752432\n",
      "\tspeed: 0.1658s/iter; left time: 9748.6150s\n",
      "699it [01:56,  6.03it/s]\titers: 700, epoch: 5 | loss: 0.3124712\n",
      "\tspeed: 0.1662s/iter; left time: 9754.9635s\n",
      "799it [02:12,  6.02it/s]\titers: 800, epoch: 5 | loss: 0.1743441\n",
      "\tspeed: 0.1658s/iter; left time: 9715.7490s\n",
      "899it [02:29,  6.03it/s]\titers: 900, epoch: 5 | loss: 0.2229867\n",
      "\tspeed: 0.1657s/iter; left time: 9697.2003s\n",
      "999it [02:45,  6.03it/s]\titers: 1000, epoch: 5 | loss: 0.3028876\n",
      "\tspeed: 0.1658s/iter; left time: 9682.2074s\n",
      "1099it [03:02,  6.03it/s]\titers: 1100, epoch: 5 | loss: 0.3518368\n",
      "\tspeed: 0.1657s/iter; left time: 9661.3133s\n",
      "1199it [03:18,  6.04it/s]\titers: 1200, epoch: 5 | loss: 0.3233963\n",
      "\tspeed: 0.1657s/iter; left time: 9648.1142s\n",
      "1299it [03:35,  6.00it/s]\titers: 1300, epoch: 5 | loss: 0.1829637\n",
      "\tspeed: 0.1667s/iter; left time: 9686.9949s\n",
      "1399it [03:52,  6.04it/s]\titers: 1400, epoch: 5 | loss: 0.2135349\n",
      "\tspeed: 0.1663s/iter; left time: 9647.4433s\n",
      "1499it [04:08,  6.04it/s]\titers: 1500, epoch: 5 | loss: 0.1728168\n",
      "\tspeed: 0.1655s/iter; left time: 9583.1129s\n",
      "1599it [04:25,  6.05it/s]\titers: 1600, epoch: 5 | loss: 0.1611332\n",
      "\tspeed: 0.1656s/iter; left time: 9576.0569s\n",
      "1699it [04:41,  6.04it/s]\titers: 1700, epoch: 5 | loss: 0.1553698\n",
      "\tspeed: 0.1656s/iter; left time: 9557.9213s\n",
      "1799it [04:58,  6.04it/s]\titers: 1800, epoch: 5 | loss: 0.1465765\n",
      "\tspeed: 0.1657s/iter; left time: 9544.8656s\n",
      "1899it [05:15,  6.04it/s]\titers: 1900, epoch: 5 | loss: 0.1275379\n",
      "\tspeed: 0.1656s/iter; left time: 9524.7892s\n",
      "1999it [05:31,  6.05it/s]\titers: 2000, epoch: 5 | loss: 0.4558351\n",
      "\tspeed: 0.1656s/iter; left time: 9506.2523s\n",
      "2099it [05:48,  6.04it/s]\titers: 2100, epoch: 5 | loss: 0.2186986\n",
      "\tspeed: 0.1658s/iter; left time: 9499.0530s\n",
      "2199it [06:04,  6.05it/s]\titers: 2200, epoch: 5 | loss: 0.3134954\n",
      "\tspeed: 0.1656s/iter; left time: 9473.6142s\n",
      "2299it [06:21,  6.05it/s]\titers: 2300, epoch: 5 | loss: 0.2511533\n",
      "\tspeed: 0.1653s/iter; left time: 9440.9552s\n",
      "2399it [06:37,  6.04it/s]\titers: 2400, epoch: 5 | loss: 0.4075535\n",
      "\tspeed: 0.1655s/iter; left time: 9432.3854s\n",
      "2499it [06:54,  6.05it/s]\titers: 2500, epoch: 5 | loss: 0.1525999\n",
      "\tspeed: 0.1655s/iter; left time: 9416.5456s\n",
      "2599it [07:10,  6.04it/s]\titers: 2600, epoch: 5 | loss: 0.2262244\n",
      "\tspeed: 0.1655s/iter; left time: 9402.9401s\n",
      "2699it [07:27,  6.04it/s]\titers: 2700, epoch: 5 | loss: 0.1915701\n",
      "\tspeed: 0.1656s/iter; left time: 9391.0375s\n",
      "2799it [07:44,  6.04it/s]\titers: 2800, epoch: 5 | loss: 0.1486738\n",
      "\tspeed: 0.1656s/iter; left time: 9372.2489s\n",
      "2899it [08:00,  6.04it/s]\titers: 2900, epoch: 5 | loss: 0.2162331\n",
      "\tspeed: 0.1656s/iter; left time: 9356.7096s\n",
      "2999it [08:17,  6.04it/s]\titers: 3000, epoch: 5 | loss: 0.0976452\n",
      "\tspeed: 0.1657s/iter; left time: 9347.3886s\n",
      "3099it [08:33,  6.05it/s]\titers: 3100, epoch: 5 | loss: 0.1735288\n",
      "\tspeed: 0.1657s/iter; left time: 9330.1387s\n",
      "3199it [08:50,  6.04it/s]\titers: 3200, epoch: 5 | loss: 0.1791230\n",
      "\tspeed: 0.1655s/iter; left time: 9303.3826s\n",
      "3299it [09:06,  6.04it/s]\titers: 3300, epoch: 5 | loss: 0.2644567\n",
      "\tspeed: 0.1656s/iter; left time: 9292.3571s\n",
      "3399it [09:23,  6.03it/s]\titers: 3400, epoch: 5 | loss: 0.2107012\n",
      "\tspeed: 0.1656s/iter; left time: 9277.4642s\n",
      "3499it [09:40,  6.05it/s]\titers: 3500, epoch: 5 | loss: 0.2139579\n",
      "\tspeed: 0.1657s/iter; left time: 9264.4658s\n",
      "3599it [09:56,  6.04it/s]\titers: 3600, epoch: 5 | loss: 0.3382896\n",
      "\tspeed: 0.1656s/iter; left time: 9239.6398s\n",
      "3699it [10:13,  6.04it/s]\titers: 3700, epoch: 5 | loss: 0.1741043\n",
      "\tspeed: 0.1656s/iter; left time: 9223.6407s\n",
      "3713it [10:15,  6.03it/s]\n",
      "Epoch: 5 cost time: 615.511825799942\n",
      "810it [01:06, 12.23it/s]\n",
      "807it [01:06, 12.14it/s]\n",
      "Epoch: 5 | Train Loss: 0.2240235 Vali Loss: 0.2717150 Test Loss: 0.3383401 MAE Loss: 0.3492332\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 2.4999999999999998e-06\n",
      "99it [00:16,  6.03it/s]\titers: 100, epoch: 6 | loss: 0.2288827\n",
      "\tspeed: 1.5313s/iter; left time: 85132.9779s\n",
      "199it [00:33,  6.03it/s]\titers: 200, epoch: 6 | loss: 0.2836063\n",
      "\tspeed: 0.1661s/iter; left time: 9215.3082s\n",
      "299it [00:49,  6.02it/s]\titers: 300, epoch: 6 | loss: 0.1419873\n",
      "\tspeed: 0.1661s/iter; left time: 9200.8713s\n",
      "399it [01:06,  6.03it/s]\titers: 400, epoch: 6 | loss: 0.2328954\n",
      "\tspeed: 0.1661s/iter; left time: 9187.1355s\n",
      "499it [01:23,  6.02it/s]\titers: 500, epoch: 6 | loss: 0.1765164\n",
      "\tspeed: 0.1661s/iter; left time: 9165.5752s\n",
      "599it [01:39,  5.96it/s]\titers: 600, epoch: 6 | loss: 0.1975565\n",
      "\tspeed: 0.1672s/iter; left time: 9212.0722s\n",
      "699it [01:56,  6.02it/s]\titers: 700, epoch: 6 | loss: 0.1138955\n",
      "\tspeed: 0.1672s/iter; left time: 9196.4658s\n",
      "799it [02:13,  6.04it/s]\titers: 800, epoch: 6 | loss: 0.2125350\n",
      "\tspeed: 0.1659s/iter; left time: 9108.5015s\n",
      "899it [02:29,  6.04it/s]\titers: 900, epoch: 6 | loss: 0.1672265\n",
      "\tspeed: 0.1657s/iter; left time: 9078.4517s\n",
      "999it [02:46,  6.03it/s]\titers: 1000, epoch: 6 | loss: 0.2217026\n",
      "\tspeed: 0.1656s/iter; left time: 9057.7028s\n",
      "1099it [03:02,  5.97it/s]\titers: 1100, epoch: 6 | loss: 0.1896377\n",
      "\tspeed: 0.1663s/iter; left time: 9078.8331s\n",
      "1199it [03:19,  6.03it/s]\titers: 1200, epoch: 6 | loss: 0.2491658\n",
      "\tspeed: 0.1661s/iter; left time: 9052.7591s\n",
      "1299it [03:36,  6.06it/s]\titers: 1300, epoch: 6 | loss: 0.1765631\n",
      "\tspeed: 0.1665s/iter; left time: 9055.4286s\n",
      "1399it [03:52,  6.04it/s]\titers: 1400, epoch: 6 | loss: 0.3106969\n",
      "\tspeed: 0.1658s/iter; left time: 8999.9965s\n",
      "1499it [04:09,  6.04it/s]\titers: 1500, epoch: 6 | loss: 0.2566919\n",
      "\tspeed: 0.1660s/iter; left time: 8998.8951s\n",
      "1599it [04:25,  6.05it/s]\titers: 1600, epoch: 6 | loss: 0.2792241\n",
      "\tspeed: 0.1654s/iter; left time: 8949.1815s\n",
      "1699it [04:42,  6.06it/s]\titers: 1700, epoch: 6 | loss: 0.2395253\n",
      "\tspeed: 0.1654s/iter; left time: 8931.5504s\n",
      "1799it [04:59,  6.04it/s]\titers: 1800, epoch: 6 | loss: 0.2331742\n",
      "\tspeed: 0.1655s/iter; left time: 8921.5641s\n",
      "1899it [05:15,  6.04it/s]\titers: 1900, epoch: 6 | loss: 0.2421201\n",
      "\tspeed: 0.1653s/iter; left time: 8892.3453s\n",
      "1999it [05:32,  6.05it/s]\titers: 2000, epoch: 6 | loss: 0.3130040\n",
      "\tspeed: 0.1652s/iter; left time: 8871.2993s\n",
      "2099it [05:48,  6.04it/s]\titers: 2100, epoch: 6 | loss: 0.1878423\n",
      "\tspeed: 0.1655s/iter; left time: 8868.3302s\n",
      "2199it [06:05,  5.86it/s]\titers: 2200, epoch: 6 | loss: 0.1551044\n",
      "\tspeed: 0.1658s/iter; left time: 8868.8749s\n",
      "2299it [06:21,  6.02it/s]\titers: 2300, epoch: 6 | loss: 0.1652153\n",
      "\tspeed: 0.1665s/iter; left time: 8891.3757s\n",
      "2399it [06:38,  6.04it/s]\titers: 2400, epoch: 6 | loss: 0.1307224\n",
      "\tspeed: 0.1655s/iter; left time: 8818.7187s\n",
      "2499it [06:54,  6.06it/s]\titers: 2500, epoch: 6 | loss: 0.2848882\n",
      "\tspeed: 0.1658s/iter; left time: 8821.7694s\n",
      "2599it [07:11,  6.05it/s]\titers: 2600, epoch: 6 | loss: 0.2764479\n",
      "\tspeed: 0.1652s/iter; left time: 8771.7044s\n",
      "2699it [07:28,  6.05it/s]\titers: 2700, epoch: 6 | loss: 0.1961442\n",
      "\tspeed: 0.1654s/iter; left time: 8764.8855s\n",
      "2799it [07:44,  6.06it/s]\titers: 2800, epoch: 6 | loss: 0.1536513\n",
      "\tspeed: 0.1656s/iter; left time: 8760.1035s\n",
      "2899it [08:01,  6.01it/s]\titers: 2900, epoch: 6 | loss: 0.1615473\n",
      "\tspeed: 0.1656s/iter; left time: 8743.1062s\n",
      "2999it [08:17,  6.05it/s]\titers: 3000, epoch: 6 | loss: 0.2465230\n",
      "\tspeed: 0.1655s/iter; left time: 8722.8386s\n",
      "3099it [08:34,  5.88it/s]\titers: 3100, epoch: 6 | loss: 0.1714298\n",
      "\tspeed: 0.1658s/iter; left time: 8718.7633s\n",
      "3199it [08:50,  6.05it/s]\titers: 3200, epoch: 6 | loss: 0.3108763\n",
      "\tspeed: 0.1652s/iter; left time: 8671.2954s\n",
      "3299it [09:07,  6.06it/s]\titers: 3300, epoch: 6 | loss: 0.1937915\n",
      "\tspeed: 0.1658s/iter; left time: 8685.6384s\n",
      "3399it [09:23,  6.06it/s]\titers: 3400, epoch: 6 | loss: 0.3149135\n",
      "\tspeed: 0.1658s/iter; left time: 8668.9024s\n",
      "3499it [09:40,  6.06it/s]\titers: 3500, epoch: 6 | loss: 0.1329752\n",
      "\tspeed: 0.1653s/iter; left time: 8628.2122s\n",
      "3599it [09:57,  6.06it/s]\titers: 3600, epoch: 6 | loss: 0.2532141\n",
      "\tspeed: 0.1652s/iter; left time: 8608.1933s\n",
      "3699it [10:13,  6.05it/s]\titers: 3700, epoch: 6 | loss: 0.1472261\n",
      "\tspeed: 0.1652s/iter; left time: 8589.5641s\n",
      "3713it [10:15,  6.03it/s]\n",
      "Epoch: 6 cost time: 615.9026067256927\n",
      "810it [01:06, 12.22it/s]\n",
      "807it [01:05, 12.24it/s]\n",
      "Epoch: 6 | Train Loss: 0.2211134 Vali Loss: 0.2701731 Test Loss: 0.3390355 MAE Loss: 0.3484068\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.2499999999999999e-06\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 7 | loss: 0.2778719\n",
      "\tspeed: 1.5255s/iter; left time: 79147.0598s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 7 | loss: 0.1660721\n",
      "\tspeed: 0.1651s/iter; left time: 8549.6850s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 7 | loss: 0.1476121\n",
      "\tspeed: 0.1650s/iter; left time: 8527.8487s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 7 | loss: 0.2609379\n",
      "\tspeed: 0.1650s/iter; left time: 8512.0929s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 7 | loss: 0.2788059\n",
      "\tspeed: 0.1657s/iter; left time: 8532.5649s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 7 | loss: 0.2187828\n",
      "\tspeed: 0.1654s/iter; left time: 8496.2233s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 7 | loss: 0.3098511\n",
      "\tspeed: 0.1653s/iter; left time: 8476.5329s\n",
      "799it [02:12,  6.06it/s]\titers: 800, epoch: 7 | loss: 0.2834350\n",
      "\tspeed: 0.1651s/iter; left time: 8452.1332s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 7 | loss: 0.1528620\n",
      "\tspeed: 0.1652s/iter; left time: 8437.4172s\n",
      "999it [02:45,  6.05it/s]\titers: 1000, epoch: 7 | loss: 0.3043649\n",
      "\tspeed: 0.1653s/iter; left time: 8427.0832s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 7 | loss: 0.1651035\n",
      "\tspeed: 0.1651s/iter; left time: 8400.3722s\n",
      "1199it [03:18,  6.05it/s]\titers: 1200, epoch: 7 | loss: 0.1686269\n",
      "\tspeed: 0.1654s/iter; left time: 8401.7912s\n",
      "1299it [03:34,  6.06it/s]\titers: 1300, epoch: 7 | loss: 0.1894695\n",
      "\tspeed: 0.1653s/iter; left time: 8377.2903s\n",
      "1399it [03:51,  5.78it/s]\titers: 1400, epoch: 7 | loss: 0.2513621\n",
      "\tspeed: 0.1651s/iter; left time: 8353.3669s\n",
      "1499it [04:07,  6.06it/s]\titers: 1500, epoch: 7 | loss: 0.1746683\n",
      "\tspeed: 0.1651s/iter; left time: 8333.4193s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 7 | loss: 0.1379659\n",
      "\tspeed: 0.1652s/iter; left time: 8324.5517s\n",
      "1699it [04:41,  6.07it/s]\titers: 1700, epoch: 7 | loss: 0.2546853\n",
      "\tspeed: 0.1651s/iter; left time: 8303.5977s\n",
      "1799it [04:57,  6.08it/s]\titers: 1800, epoch: 7 | loss: 0.2066229\n",
      "\tspeed: 0.1649s/iter; left time: 8273.8404s\n",
      "1899it [05:14,  6.06it/s]\titers: 1900, epoch: 7 | loss: 0.2440671\n",
      "\tspeed: 0.1650s/iter; left time: 8261.2229s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 7 | loss: 0.2166122\n",
      "\tspeed: 0.1649s/iter; left time: 8243.9095s\n",
      "2099it [05:46,  6.07it/s]\titers: 2100, epoch: 7 | loss: 0.1706788\n",
      "\tspeed: 0.1649s/iter; left time: 8227.1324s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 7 | loss: 0.1551466\n",
      "\tspeed: 0.1658s/iter; left time: 8254.8286s\n",
      "2299it [06:20,  5.88it/s]\titers: 2300, epoch: 7 | loss: 0.1694099\n",
      "\tspeed: 0.1662s/iter; left time: 8256.6241s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 7 | loss: 0.2798799\n",
      "\tspeed: 0.1652s/iter; left time: 8192.3556s\n",
      "2499it [06:53,  6.08it/s]\titers: 2500, epoch: 7 | loss: 0.2550182\n",
      "\tspeed: 0.1650s/iter; left time: 8162.6978s\n",
      "2599it [07:09,  6.05it/s]\titers: 2600, epoch: 7 | loss: 0.2014532\n",
      "\tspeed: 0.1651s/iter; left time: 8151.8749s\n",
      "2699it [07:26,  6.05it/s]\titers: 2700, epoch: 7 | loss: 0.2237795\n",
      "\tspeed: 0.1654s/iter; left time: 8149.5749s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 7 | loss: 0.2062948\n",
      "\tspeed: 0.1652s/iter; left time: 8122.9786s\n",
      "2899it [07:59,  6.06it/s]\titers: 2900, epoch: 7 | loss: 0.2598217\n",
      "\tspeed: 0.1650s/iter; left time: 8100.0665s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 7 | loss: 0.2167784\n",
      "\tspeed: 0.1651s/iter; left time: 8084.9863s\n",
      "3099it [08:32,  6.05it/s]\titers: 3100, epoch: 7 | loss: 0.2296462\n",
      "\tspeed: 0.1650s/iter; left time: 8067.6067s\n",
      "3199it [08:48,  6.05it/s]\titers: 3200, epoch: 7 | loss: 0.1648202\n",
      "\tspeed: 0.1651s/iter; left time: 8056.1793s\n",
      "3299it [09:05,  6.06it/s]\titers: 3300, epoch: 7 | loss: 0.2408326\n",
      "\tspeed: 0.1651s/iter; left time: 8036.4168s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 7 | loss: 0.1964737\n",
      "\tspeed: 0.1650s/iter; left time: 8014.8538s\n",
      "3499it [09:38,  6.07it/s]\titers: 3500, epoch: 7 | loss: 0.2105917\n",
      "\tspeed: 0.1650s/iter; left time: 7997.3784s\n",
      "3599it [09:54,  6.07it/s]\titers: 3600, epoch: 7 | loss: 0.1851097\n",
      "\tspeed: 0.1652s/iter; left time: 7993.5067s\n",
      "3699it [10:11,  6.05it/s]\titers: 3700, epoch: 7 | loss: 0.4675130\n",
      "\tspeed: 0.1649s/iter; left time: 7961.3646s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 7 cost time: 613.6967542171478\n",
      "810it [01:06, 12.25it/s]\n",
      "807it [01:05, 12.26it/s]\n",
      "Epoch: 7 | Train Loss: 0.2199849 Vali Loss: 0.2689678 Test Loss: 0.3342735 MAE Loss: 0.3452968\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 6.249999999999999e-07\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 8 | loss: 0.3063551\n",
      "\tspeed: 1.5204s/iter; left time: 73239.7070s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 8 | loss: 0.2879389\n",
      "\tspeed: 0.1652s/iter; left time: 7942.3104s\n",
      "299it [00:49,  6.07it/s]\titers: 300, epoch: 8 | loss: 0.2292602\n",
      "\tspeed: 0.1651s/iter; left time: 7921.0930s\n",
      "399it [01:06,  6.06it/s]\titers: 400, epoch: 8 | loss: 0.2891562\n",
      "\tspeed: 0.1651s/iter; left time: 7902.3615s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 8 | loss: 0.3724436\n",
      "\tspeed: 0.1661s/iter; left time: 7935.7231s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 8 | loss: 0.0972103\n",
      "\tspeed: 0.1652s/iter; left time: 7875.8966s\n",
      "699it [01:55,  6.04it/s]\titers: 700, epoch: 8 | loss: 0.1674845\n",
      "\tspeed: 0.1652s/iter; left time: 7856.5773s\n",
      "799it [02:12,  6.05it/s]\titers: 800, epoch: 8 | loss: 0.2182303\n",
      "\tspeed: 0.1655s/iter; left time: 7855.5996s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 8 | loss: 0.1903681\n",
      "\tspeed: 0.1651s/iter; left time: 7823.1121s\n",
      "999it [02:45,  5.82it/s]\titers: 1000, epoch: 8 | loss: 0.1885609\n",
      "\tspeed: 0.1661s/iter; left time: 7851.5057s\n",
      "1099it [03:02,  6.06it/s]\titers: 1100, epoch: 8 | loss: 0.1678118\n",
      "\tspeed: 0.1656s/iter; left time: 7809.0364s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 8 | loss: 0.1721345\n",
      "\tspeed: 0.1651s/iter; left time: 7773.5047s\n",
      "1299it [03:35,  6.05it/s]\titers: 1300, epoch: 8 | loss: 0.1207117\n",
      "\tspeed: 0.1652s/iter; left time: 7758.6114s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 8 | loss: 0.1636383\n",
      "\tspeed: 0.1654s/iter; left time: 7752.7602s\n",
      "1499it [04:08,  6.07it/s]\titers: 1500, epoch: 8 | loss: 0.1682796\n",
      "\tspeed: 0.1652s/iter; left time: 7728.1497s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 8 | loss: 0.3033008\n",
      "\tspeed: 0.1650s/iter; left time: 7702.3532s\n",
      "1699it [04:41,  6.07it/s]\titers: 1700, epoch: 8 | loss: 0.1543128\n",
      "\tspeed: 0.1650s/iter; left time: 7684.7020s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 8 | loss: 0.2034282\n",
      "\tspeed: 0.1650s/iter; left time: 7666.8773s\n",
      "1899it [05:14,  6.07it/s]\titers: 1900, epoch: 8 | loss: 0.1616035\n",
      "\tspeed: 0.1645s/iter; left time: 7628.9676s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 8 | loss: 0.1578956\n",
      "\tspeed: 0.1649s/iter; left time: 7628.0683s\n",
      "2099it [05:47,  6.06it/s]\titers: 2100, epoch: 8 | loss: 0.4248370\n",
      "\tspeed: 0.1647s/iter; left time: 7605.5411s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 8 | loss: 0.2269190\n",
      "\tspeed: 0.1651s/iter; left time: 7605.0916s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 8 | loss: 0.2137440\n",
      "\tspeed: 0.1663s/iter; left time: 7646.7892s\n",
      "2399it [06:36,  6.04it/s]\titers: 2400, epoch: 8 | loss: 0.3314634\n",
      "\tspeed: 0.1655s/iter; left time: 7592.4279s\n",
      "2499it [06:53,  6.07it/s]\titers: 2500, epoch: 8 | loss: 0.2534941\n",
      "\tspeed: 0.1651s/iter; left time: 7555.7532s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 8 | loss: 0.2505315\n",
      "\tspeed: 0.1649s/iter; left time: 7531.3609s\n",
      "2699it [07:26,  6.03it/s]\titers: 2700, epoch: 8 | loss: 0.2104806\n",
      "\tspeed: 0.1656s/iter; left time: 7544.5819s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 8 | loss: 0.4429492\n",
      "\tspeed: 0.1654s/iter; left time: 7519.8612s\n",
      "2899it [07:59,  6.06it/s]\titers: 2900, epoch: 8 | loss: 0.2201139\n",
      "\tspeed: 0.1654s/iter; left time: 7503.0437s\n",
      "2999it [08:16,  6.06it/s]\titers: 3000, epoch: 8 | loss: 0.1428879\n",
      "\tspeed: 0.1653s/iter; left time: 7484.0824s\n",
      "3099it [08:32,  6.06it/s]\titers: 3100, epoch: 8 | loss: 0.2509821\n",
      "\tspeed: 0.1651s/iter; left time: 7457.6464s\n",
      "3199it [08:49,  6.07it/s]\titers: 3200, epoch: 8 | loss: 0.2013811\n",
      "\tspeed: 0.1651s/iter; left time: 7441.7435s\n",
      "3299it [09:05,  6.06it/s]\titers: 3300, epoch: 8 | loss: 0.2405330\n",
      "\tspeed: 0.1651s/iter; left time: 7422.6514s\n",
      "3399it [09:22,  6.06it/s]\titers: 3400, epoch: 8 | loss: 0.1478902\n",
      "\tspeed: 0.1651s/iter; left time: 7407.5053s\n",
      "3499it [09:38,  6.07it/s]\titers: 3500, epoch: 8 | loss: 0.3451292\n",
      "\tspeed: 0.1648s/iter; left time: 7380.0912s\n",
      "3599it [09:55,  6.06it/s]\titers: 3600, epoch: 8 | loss: 0.3203305\n",
      "\tspeed: 0.1649s/iter; left time: 7367.2194s\n",
      "3699it [10:11,  6.06it/s]\titers: 3700, epoch: 8 | loss: 0.2626221\n",
      "\tspeed: 0.1653s/iter; left time: 7365.4609s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 8 cost time: 613.9476299285889\n",
      "810it [01:06, 12.25it/s]\n",
      "807it [01:05, 12.27it/s]\n",
      "Epoch: 8 | Train Loss: 0.2194789 Vali Loss: 0.2697016 Test Loss: 0.3382633 MAE Loss: 0.3493564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.1249999999999997e-07\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 9 | loss: 0.1220142\n",
      "\tspeed: 1.5114s/iter; left time: 67190.6929s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 9 | loss: 0.2094913\n",
      "\tspeed: 0.1656s/iter; left time: 7344.0723s\n",
      "299it [00:49,  6.04it/s]\titers: 300, epoch: 9 | loss: 0.2785767\n",
      "\tspeed: 0.1655s/iter; left time: 7324.5939s\n",
      "399it [01:06,  6.10it/s]\titers: 400, epoch: 9 | loss: 0.1603189\n",
      "\tspeed: 0.1649s/iter; left time: 7280.7249s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 9 | loss: 0.1636418\n",
      "\tspeed: 0.1653s/iter; left time: 7281.5072s\n",
      "599it [01:39,  6.04it/s]\titers: 600, epoch: 9 | loss: 0.1581134\n",
      "\tspeed: 0.1656s/iter; left time: 7278.9470s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 9 | loss: 0.3223146\n",
      "\tspeed: 0.1652s/iter; left time: 7244.4183s\n",
      "799it [02:12,  6.05it/s]\titers: 800, epoch: 9 | loss: 0.1686176\n",
      "\tspeed: 0.1652s/iter; left time: 7227.7762s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 9 | loss: 0.3486018\n",
      "\tspeed: 0.1652s/iter; left time: 7213.4992s\n",
      "999it [02:45,  6.06it/s]\titers: 1000, epoch: 9 | loss: 0.1529969\n",
      "\tspeed: 0.1650s/iter; left time: 7185.9241s\n",
      "1099it [03:01,  6.07it/s]\titers: 1100, epoch: 9 | loss: 0.3255039\n",
      "\tspeed: 0.1650s/iter; left time: 7170.4168s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 9 | loss: 0.2422487\n",
      "\tspeed: 0.1650s/iter; left time: 7154.3376s\n",
      "1299it [03:34,  6.06it/s]\titers: 1300, epoch: 9 | loss: 0.2098565\n",
      "\tspeed: 0.1651s/iter; left time: 7142.1898s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 9 | loss: 0.2017650\n",
      "\tspeed: 0.1651s/iter; left time: 7126.3368s\n",
      "1499it [04:08,  6.06it/s]\titers: 1500, epoch: 9 | loss: 0.2735309\n",
      "\tspeed: 0.1655s/iter; left time: 7126.9538s\n",
      "1599it [04:24,  6.05it/s]\titers: 1600, epoch: 9 | loss: 0.1816030\n",
      "\tspeed: 0.1654s/iter; left time: 7104.0716s\n",
      "1699it [04:41,  6.05it/s]\titers: 1700, epoch: 9 | loss: 0.1272912\n",
      "\tspeed: 0.1652s/iter; left time: 7081.9320s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 9 | loss: 0.2249201\n",
      "\tspeed: 0.1650s/iter; left time: 7056.2135s\n",
      "1899it [05:14,  6.05it/s]\titers: 1900, epoch: 9 | loss: 0.2423242\n",
      "\tspeed: 0.1651s/iter; left time: 7043.6155s\n",
      "1999it [05:30,  6.06it/s]\titers: 2000, epoch: 9 | loss: 0.3267755\n",
      "\tspeed: 0.1653s/iter; left time: 7034.1808s\n",
      "2099it [05:47,  6.06it/s]\titers: 2100, epoch: 9 | loss: 0.1894866\n",
      "\tspeed: 0.1651s/iter; left time: 7008.6340s\n",
      "2199it [06:03,  6.01it/s]\titers: 2200, epoch: 9 | loss: 0.2519278\n",
      "\tspeed: 0.1663s/iter; left time: 7045.1469s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 9 | loss: 0.1724371\n",
      "\tspeed: 0.1654s/iter; left time: 6987.2214s\n",
      "2399it [06:36,  6.05it/s]\titers: 2400, epoch: 9 | loss: 0.3341206\n",
      "\tspeed: 0.1654s/iter; left time: 6971.0431s\n",
      "2499it [06:53,  6.06it/s]\titers: 2500, epoch: 9 | loss: 0.1494474\n",
      "\tspeed: 0.1651s/iter; left time: 6943.6310s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 9 | loss: 0.1841692\n",
      "\tspeed: 0.1651s/iter; left time: 6928.4586s\n",
      "2699it [07:26,  6.07it/s]\titers: 2700, epoch: 9 | loss: 0.2216226\n",
      "\tspeed: 0.1653s/iter; left time: 6917.5596s\n",
      "2799it [07:42,  6.07it/s]\titers: 2800, epoch: 9 | loss: 0.1664202\n",
      "\tspeed: 0.1653s/iter; left time: 6901.8337s\n",
      "2899it [07:59,  6.07it/s]\titers: 2900, epoch: 9 | loss: 0.2550486\n",
      "\tspeed: 0.1651s/iter; left time: 6876.5907s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 9 | loss: 0.2315648\n",
      "\tspeed: 0.1652s/iter; left time: 6864.3855s\n",
      "3099it [08:32,  6.07it/s]\titers: 3100, epoch: 9 | loss: 0.1328375\n",
      "\tspeed: 0.1651s/iter; left time: 6843.0280s\n",
      "3199it [08:48,  6.07it/s]\titers: 3200, epoch: 9 | loss: 0.2375935\n",
      "\tspeed: 0.1649s/iter; left time: 6818.7888s\n",
      "3299it [09:05,  6.08it/s]\titers: 3300, epoch: 9 | loss: 0.1385350\n",
      "\tspeed: 0.1650s/iter; left time: 6809.3138s\n",
      "3399it [09:21,  6.07it/s]\titers: 3400, epoch: 9 | loss: 0.3211995\n",
      "\tspeed: 0.1651s/iter; left time: 6794.1681s\n",
      "3499it [09:38,  6.07it/s]\titers: 3500, epoch: 9 | loss: 0.2546162\n",
      "\tspeed: 0.1655s/iter; left time: 6796.3437s\n",
      "3599it [09:55,  6.07it/s]\titers: 3600, epoch: 9 | loss: 0.4036691\n",
      "\tspeed: 0.1650s/iter; left time: 6758.4075s\n",
      "3699it [10:11,  6.06it/s]\titers: 3700, epoch: 9 | loss: 0.1385283\n",
      "\tspeed: 0.1650s/iter; left time: 6741.4694s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 9 cost time: 613.9092972278595\n",
      "810it [01:06, 12.25it/s]\n",
      "807it [01:05, 12.23it/s]\n",
      "Epoch: 9 | Train Loss: 0.2188337 Vali Loss: 0.2692347 Test Loss: 0.3362291 MAE Loss: 0.3464035\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.5624999999999999e-07\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 10 | loss: 0.2336593\n",
      "\tspeed: 1.5129s/iter; left time: 61640.8255s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 10 | loss: 0.2809971\n",
      "\tspeed: 0.1651s/iter; left time: 6708.4379s\n",
      "299it [00:49,  6.08it/s]\titers: 300, epoch: 10 | loss: 0.2346973\n",
      "\tspeed: 0.1649s/iter; left time: 6685.4152s\n",
      "399it [01:06,  6.05it/s]\titers: 400, epoch: 10 | loss: 0.2086323\n",
      "\tspeed: 0.1651s/iter; left time: 6678.9776s\n",
      "499it [01:22,  6.07it/s]\titers: 500, epoch: 10 | loss: 0.3357417\n",
      "\tspeed: 0.1653s/iter; left time: 6667.9555s\n",
      "599it [01:39,  6.07it/s]\titers: 600, epoch: 10 | loss: 0.3944794\n",
      "\tspeed: 0.1650s/iter; left time: 6640.3639s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 10 | loss: 0.2327631\n",
      "\tspeed: 0.1649s/iter; left time: 6621.4278s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 10 | loss: 0.1763514\n",
      "\tspeed: 0.1649s/iter; left time: 6603.0120s\n",
      "899it [02:28,  6.06it/s]\titers: 900, epoch: 10 | loss: 0.2199576\n",
      "\tspeed: 0.1649s/iter; left time: 6587.6728s\n",
      "999it [02:45,  6.07it/s]\titers: 1000, epoch: 10 | loss: 0.1197818\n",
      "\tspeed: 0.1649s/iter; left time: 6568.3398s\n",
      "1099it [03:01,  6.07it/s]\titers: 1100, epoch: 10 | loss: 0.1298800\n",
      "\tspeed: 0.1650s/iter; left time: 6558.7232s\n",
      "1199it [03:18,  6.04it/s]\titers: 1200, epoch: 10 | loss: 0.2837351\n",
      "\tspeed: 0.1654s/iter; left time: 6557.7964s\n",
      "1299it [03:34,  6.07it/s]\titers: 1300, epoch: 10 | loss: 0.1731343\n",
      "\tspeed: 0.1656s/iter; left time: 6547.1184s\n",
      "1399it [03:51,  6.06it/s]\titers: 1400, epoch: 10 | loss: 0.1906580\n",
      "\tspeed: 0.1649s/iter; left time: 6505.4981s\n",
      "1499it [04:07,  6.07it/s]\titers: 1500, epoch: 10 | loss: 0.2082302\n",
      "\tspeed: 0.1649s/iter; left time: 6488.1453s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 10 | loss: 0.3138632\n",
      "\tspeed: 0.1650s/iter; left time: 6475.2701s\n",
      "1699it [04:40,  6.06it/s]\titers: 1700, epoch: 10 | loss: 0.2193702\n",
      "\tspeed: 0.1652s/iter; left time: 6466.7418s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 10 | loss: 0.2243911\n",
      "\tspeed: 0.1653s/iter; left time: 6455.9163s\n",
      "1899it [05:13,  6.05it/s]\titers: 1900, epoch: 10 | loss: 0.2361969\n",
      "\tspeed: 0.1649s/iter; left time: 6421.9747s\n",
      "1999it [05:30,  6.08it/s]\titers: 2000, epoch: 10 | loss: 0.2873444\n",
      "\tspeed: 0.1649s/iter; left time: 6404.8647s\n",
      "2099it [05:46,  6.06it/s]\titers: 2100, epoch: 10 | loss: 0.2036457\n",
      "\tspeed: 0.1651s/iter; left time: 6397.0377s\n",
      "2199it [06:03,  6.03it/s]\titers: 2200, epoch: 10 | loss: 0.1217913\n",
      "\tspeed: 0.1652s/iter; left time: 6382.4617s\n",
      "2299it [06:19,  6.07it/s]\titers: 2300, epoch: 10 | loss: 0.1877360\n",
      "\tspeed: 0.1648s/iter; left time: 6353.7637s\n",
      "2399it [06:36,  6.07it/s]\titers: 2400, epoch: 10 | loss: 0.2135888\n",
      "\tspeed: 0.1647s/iter; left time: 6333.5822s\n",
      "2499it [06:52,  6.06it/s]\titers: 2500, epoch: 10 | loss: 0.1898853\n",
      "\tspeed: 0.1649s/iter; left time: 6321.7031s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 10 | loss: 0.2990890\n",
      "\tspeed: 0.1651s/iter; left time: 6314.3227s\n",
      "2699it [07:25,  6.07it/s]\titers: 2700, epoch: 10 | loss: 0.1608121\n",
      "\tspeed: 0.1652s/iter; left time: 6301.4097s\n",
      "2799it [07:42,  6.07it/s]\titers: 2800, epoch: 10 | loss: 0.2322087\n",
      "\tspeed: 0.1648s/iter; left time: 6270.5055s\n",
      "2899it [07:58,  6.07it/s]\titers: 2900, epoch: 10 | loss: 0.1947156\n",
      "\tspeed: 0.1649s/iter; left time: 6255.3568s\n",
      "2999it [08:15,  6.07it/s]\titers: 3000, epoch: 10 | loss: 0.2243136\n",
      "\tspeed: 0.1649s/iter; left time: 6241.0904s\n",
      "3099it [08:31,  6.07it/s]\titers: 3100, epoch: 10 | loss: 0.3506564\n",
      "\tspeed: 0.1651s/iter; left time: 6232.2298s\n",
      "3199it [08:48,  6.07it/s]\titers: 3200, epoch: 10 | loss: 0.2665107\n",
      "\tspeed: 0.1648s/iter; left time: 6203.0468s\n",
      "3299it [09:04,  6.05it/s]\titers: 3300, epoch: 10 | loss: 0.1217579\n",
      "\tspeed: 0.1649s/iter; left time: 6192.0697s\n",
      "3399it [09:21,  6.07it/s]\titers: 3400, epoch: 10 | loss: 0.1685976\n",
      "\tspeed: 0.1650s/iter; left time: 6177.6207s\n",
      "3499it [09:37,  6.06it/s]\titers: 3500, epoch: 10 | loss: 0.1709997\n",
      "\tspeed: 0.1652s/iter; left time: 6167.3851s\n",
      "3599it [09:54,  6.07it/s]\titers: 3600, epoch: 10 | loss: 0.2058029\n",
      "\tspeed: 0.1649s/iter; left time: 6142.0787s\n",
      "3699it [10:10,  6.06it/s]\titers: 3700, epoch: 10 | loss: 0.2292963\n",
      "\tspeed: 0.1649s/iter; left time: 6126.7509s\n",
      "3713it [10:13,  6.06it/s]\n",
      "Epoch: 10 cost time: 613.1208117008209\n",
      "810it [01:06, 12.26it/s]\n",
      "807it [01:05, 12.26it/s]\n",
      "Epoch: 10 | Train Loss: 0.2184807 Vali Loss: 0.2688137 Test Loss: 0.3356672 MAE Loss: 0.3454575\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 7.812499999999999e-08\n",
      "99it [00:16,  6.05it/s]\titers: 100, epoch: 11 | loss: 0.2464755\n",
      "\tspeed: 1.5226s/iter; left time: 56385.2269s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 11 | loss: 0.2831804\n",
      "\tspeed: 0.1653s/iter; left time: 6104.0212s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 11 | loss: 0.4014017\n",
      "\tspeed: 0.1653s/iter; left time: 6088.4406s\n",
      "399it [01:06,  6.04it/s]\titers: 400, epoch: 11 | loss: 0.3375088\n",
      "\tspeed: 0.1652s/iter; left time: 6068.4508s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 11 | loss: 0.2110431\n",
      "\tspeed: 0.1654s/iter; left time: 6059.7990s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 11 | loss: 0.2135375\n",
      "\tspeed: 0.1652s/iter; left time: 6036.3709s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 11 | loss: 0.1636881\n",
      "\tspeed: 0.1654s/iter; left time: 6024.4668s\n",
      "799it [02:12,  6.07it/s]\titers: 800, epoch: 11 | loss: 0.2355998\n",
      "\tspeed: 0.1649s/iter; left time: 5992.2519s\n",
      "899it [02:28,  6.06it/s]\titers: 900, epoch: 11 | loss: 0.1601960\n",
      "\tspeed: 0.1651s/iter; left time: 5980.3643s\n",
      "999it [02:45,  6.05it/s]\titers: 1000, epoch: 11 | loss: 0.2280364\n",
      "\tspeed: 0.1651s/iter; left time: 5963.9167s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 11 | loss: 0.1520987\n",
      "\tspeed: 0.1651s/iter; left time: 5950.1822s\n",
      "1199it [03:18,  6.05it/s]\titers: 1200, epoch: 11 | loss: 0.1856842\n",
      "\tspeed: 0.1650s/iter; left time: 5930.3515s\n",
      "1299it [03:34,  6.06it/s]\titers: 1300, epoch: 11 | loss: 0.3077915\n",
      "\tspeed: 0.1651s/iter; left time: 5917.1917s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 11 | loss: 0.3191908\n",
      "\tspeed: 0.1654s/iter; left time: 5910.9182s\n",
      "1499it [04:07,  6.05it/s]\titers: 1500, epoch: 11 | loss: 0.1497049\n",
      "\tspeed: 0.1651s/iter; left time: 5882.0895s\n",
      "1599it [04:24,  6.07it/s]\titers: 1600, epoch: 11 | loss: 0.1963747\n",
      "\tspeed: 0.1651s/iter; left time: 5865.8801s\n",
      "1699it [04:41,  6.06it/s]\titers: 1700, epoch: 11 | loss: 0.2698952\n",
      "\tspeed: 0.1654s/iter; left time: 5860.8479s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 11 | loss: 0.3157600\n",
      "\tspeed: 0.1655s/iter; left time: 5847.8150s\n",
      "1899it [05:14,  6.04it/s]\titers: 1900, epoch: 11 | loss: 0.1200682\n",
      "\tspeed: 0.1650s/iter; left time: 5814.2070s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 11 | loss: 0.1695430\n",
      "\tspeed: 0.1651s/iter; left time: 5800.6905s\n",
      "2099it [05:47,  6.05it/s]\titers: 2100, epoch: 11 | loss: 0.2099721\n",
      "\tspeed: 0.1650s/iter; left time: 5780.6696s\n",
      "2199it [06:03,  6.02it/s]\titers: 2200, epoch: 11 | loss: 0.1910559\n",
      "\tspeed: 0.1656s/iter; left time: 5783.5495s\n",
      "2299it [06:20,  6.04it/s]\titers: 2300, epoch: 11 | loss: 0.2447859\n",
      "\tspeed: 0.1657s/iter; left time: 5771.0369s\n",
      "2399it [06:36,  6.04it/s]\titers: 2400, epoch: 11 | loss: 0.1328788\n",
      "\tspeed: 0.1652s/iter; left time: 5737.6734s\n",
      "2499it [06:53,  6.01it/s]\titers: 2500, epoch: 11 | loss: 0.3480614\n",
      "\tspeed: 0.1652s/iter; left time: 5719.3998s\n",
      "2599it [07:09,  6.06it/s]\titers: 2600, epoch: 11 | loss: 0.2922343\n",
      "\tspeed: 0.1653s/iter; left time: 5709.5233s\n",
      "2699it [07:26,  6.06it/s]\titers: 2700, epoch: 11 | loss: 0.1988128\n",
      "\tspeed: 0.1651s/iter; left time: 5686.0824s\n",
      "2799it [07:42,  6.05it/s]\titers: 2800, epoch: 11 | loss: 0.2575088\n",
      "\tspeed: 0.1653s/iter; left time: 5674.5869s\n",
      "2899it [07:59,  6.05it/s]\titers: 2900, epoch: 11 | loss: 0.4466902\n",
      "\tspeed: 0.1652s/iter; left time: 5654.1407s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 11 | loss: 0.2099138\n",
      "\tspeed: 0.1650s/iter; left time: 5633.2505s\n",
      "3099it [08:32,  6.06it/s]\titers: 3100, epoch: 11 | loss: 0.1406135\n",
      "\tspeed: 0.1652s/iter; left time: 5621.5121s\n",
      "3199it [08:48,  6.05it/s]\titers: 3200, epoch: 11 | loss: 0.1810093\n",
      "\tspeed: 0.1654s/iter; left time: 5611.0644s\n",
      "3299it [09:05,  6.07it/s]\titers: 3300, epoch: 11 | loss: 0.3696172\n",
      "\tspeed: 0.1650s/iter; left time: 5582.6336s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 11 | loss: 0.1142318\n",
      "\tspeed: 0.1653s/iter; left time: 5574.7495s\n",
      "3499it [09:38,  6.05it/s]\titers: 3500, epoch: 11 | loss: 0.2255594\n",
      "\tspeed: 0.1654s/iter; left time: 5560.9923s\n",
      "3599it [09:54,  6.06it/s]\titers: 3600, epoch: 11 | loss: 0.1416401\n",
      "\tspeed: 0.1651s/iter; left time: 5535.2721s\n",
      "3699it [10:11,  6.06it/s]\titers: 3700, epoch: 11 | loss: 0.1119027\n",
      "\tspeed: 0.1652s/iter; left time: 5522.5011s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 11 cost time: 613.8694393634796\n",
      "810it [01:06, 12.24it/s]\n",
      "807it [01:05, 12.23it/s]\n",
      "Epoch: 11 | Train Loss: 0.2189967 Vali Loss: 0.2690124 Test Loss: 0.3360190 MAE Loss: 0.3461748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 3.9062499999999997e-08\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 12 | loss: 0.2448239\n",
      "\tspeed: 1.5136s/iter; left time: 50431.2254s\n",
      "199it [00:33,  6.05it/s]\titers: 200, epoch: 12 | loss: 0.1697170\n",
      "\tspeed: 0.1654s/iter; left time: 5493.9280s\n",
      "299it [00:49,  6.07it/s]\titers: 300, epoch: 12 | loss: 0.1207919\n",
      "\tspeed: 0.1651s/iter; left time: 5469.2831s\n",
      "399it [01:06,  6.07it/s]\titers: 400, epoch: 12 | loss: 0.1966317\n",
      "\tspeed: 0.1652s/iter; left time: 5455.6595s\n",
      "499it [01:22,  6.05it/s]\titers: 500, epoch: 12 | loss: 0.2731660\n",
      "\tspeed: 0.1656s/iter; left time: 5451.7561s\n",
      "599it [01:39,  6.06it/s]\titers: 600, epoch: 12 | loss: 0.1484948\n",
      "\tspeed: 0.1652s/iter; left time: 5422.7134s\n",
      "699it [01:55,  6.07it/s]\titers: 700, epoch: 12 | loss: 0.2087875\n",
      "\tspeed: 0.1650s/iter; left time: 5398.9759s\n",
      "799it [02:12,  6.06it/s]\titers: 800, epoch: 12 | loss: 0.1510091\n",
      "\tspeed: 0.1652s/iter; left time: 5387.4489s\n",
      "899it [02:28,  6.06it/s]\titers: 900, epoch: 12 | loss: 0.2035579\n",
      "\tspeed: 0.1652s/iter; left time: 5370.8945s\n",
      "999it [02:45,  6.04it/s]\titers: 1000, epoch: 12 | loss: 0.1454023\n",
      "\tspeed: 0.1653s/iter; left time: 5358.7287s\n",
      "1099it [03:01,  6.04it/s]\titers: 1100, epoch: 12 | loss: 0.1696805\n",
      "\tspeed: 0.1656s/iter; left time: 5350.5514s\n",
      "1199it [03:18,  6.05it/s]\titers: 1200, epoch: 12 | loss: 0.2731988\n",
      "\tspeed: 0.1655s/iter; left time: 5333.5848s\n",
      "1299it [03:35,  6.06it/s]\titers: 1300, epoch: 12 | loss: 0.1939804\n",
      "\tspeed: 0.1654s/iter; left time: 5311.5950s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 12 | loss: 0.2246911\n",
      "\tspeed: 0.1651s/iter; left time: 5284.6879s\n",
      "1499it [04:08,  6.06it/s]\titers: 1500, epoch: 12 | loss: 0.3060063\n",
      "\tspeed: 0.1651s/iter; left time: 5270.0179s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 12 | loss: 0.1774618\n",
      "\tspeed: 0.1652s/iter; left time: 5256.1827s\n",
      "1699it [04:41,  6.06it/s]\titers: 1700, epoch: 12 | loss: 0.2302689\n",
      "\tspeed: 0.1650s/iter; left time: 5234.3517s\n",
      "1799it [04:57,  6.05it/s]\titers: 1800, epoch: 12 | loss: 0.3414334\n",
      "\tspeed: 0.1651s/iter; left time: 5218.7230s\n",
      "1899it [05:14,  6.05it/s]\titers: 1900, epoch: 12 | loss: 0.1747495\n",
      "\tspeed: 0.1651s/iter; left time: 5204.8903s\n",
      "1999it [05:30,  6.06it/s]\titers: 2000, epoch: 12 | loss: 0.1947595\n",
      "\tspeed: 0.1651s/iter; left time: 5186.2823s\n",
      "2099it [05:47,  6.07it/s]\titers: 2100, epoch: 12 | loss: 0.2702667\n",
      "\tspeed: 0.1650s/iter; left time: 5168.0078s\n",
      "2199it [06:03,  6.06it/s]\titers: 2200, epoch: 12 | loss: 0.3570537\n",
      "\tspeed: 0.1652s/iter; left time: 5156.4758s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 12 | loss: 0.2890050\n",
      "\tspeed: 0.1660s/iter; left time: 5166.6842s\n",
      "2399it [06:36,  6.06it/s]\titers: 2400, epoch: 12 | loss: 0.2269687\n",
      "\tspeed: 0.1652s/iter; left time: 5123.8150s\n",
      "2499it [06:53,  6.05it/s]\titers: 2500, epoch: 12 | loss: 0.3354267\n",
      "\tspeed: 0.1652s/iter; left time: 5106.5817s\n",
      "2599it [07:09,  6.03it/s]\titers: 2600, epoch: 12 | loss: 0.1348819\n",
      "\tspeed: 0.1653s/iter; left time: 5093.5093s\n",
      "2699it [07:26,  6.06it/s]\titers: 2700, epoch: 12 | loss: 0.4074605\n",
      "\tspeed: 0.1651s/iter; left time: 5070.7228s\n",
      "2799it [07:42,  6.06it/s]\titers: 2800, epoch: 12 | loss: 0.2229271\n",
      "\tspeed: 0.1650s/iter; left time: 5051.5099s\n",
      "2899it [07:59,  6.07it/s]\titers: 2900, epoch: 12 | loss: 0.1654357\n",
      "\tspeed: 0.1650s/iter; left time: 5035.4341s\n",
      "2999it [08:15,  6.06it/s]\titers: 3000, epoch: 12 | loss: 0.1181733\n",
      "\tspeed: 0.1651s/iter; left time: 5020.7166s\n",
      "3099it [08:32,  6.04it/s]\titers: 3100, epoch: 12 | loss: 0.2823819\n",
      "\tspeed: 0.1653s/iter; left time: 5012.9353s\n",
      "3199it [08:48,  6.05it/s]\titers: 3200, epoch: 12 | loss: 0.1874958\n",
      "\tspeed: 0.1655s/iter; left time: 4999.9170s\n",
      "3299it [09:05,  6.05it/s]\titers: 3300, epoch: 12 | loss: 0.3336696\n",
      "\tspeed: 0.1653s/iter; left time: 4977.5063s\n",
      "3399it [09:21,  6.06it/s]\titers: 3400, epoch: 12 | loss: 0.3363113\n",
      "\tspeed: 0.1654s/iter; left time: 4964.5017s\n",
      "3499it [09:38,  6.09it/s]\titers: 3500, epoch: 12 | loss: 0.2806764\n",
      "\tspeed: 0.1643s/iter; left time: 4915.8510s\n",
      "3599it [09:54,  6.05it/s]\titers: 3600, epoch: 12 | loss: 0.1204132\n",
      "\tspeed: 0.1652s/iter; left time: 4926.4730s\n",
      "3699it [10:11,  6.05it/s]\titers: 3700, epoch: 12 | loss: 0.1528856\n",
      "\tspeed: 0.1653s/iter; left time: 4913.7551s\n",
      "3713it [10:13,  6.05it/s]\n",
      "Epoch: 12 cost time: 613.8486082553864\n",
      "810it [01:06, 12.25it/s]\n",
      "807it [01:05, 12.26it/s]\n",
      "Epoch: 12 | Train Loss: 0.2186749 Vali Loss: 0.2689817 Test Loss: 0.3360092 MAE Loss: 0.3461712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 1.9531249999999998e-08\n",
      "99it [00:16,  6.06it/s]\titers: 100, epoch: 13 | loss: 0.3798907\n",
      "\tspeed: 1.5118s/iter; left time: 44756.3553s\n",
      "199it [00:33,  6.06it/s]\titers: 200, epoch: 13 | loss: 0.1069008\n",
      "\tspeed: 0.1654s/iter; left time: 4878.7419s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 13 | loss: 0.2213940\n",
      "\tspeed: 0.1654s/iter; left time: 4863.0005s\n",
      "399it [01:06,  5.99it/s]\titers: 400, epoch: 13 | loss: 0.1918865\n",
      "\tspeed: 0.1657s/iter; left time: 4856.8306s\n",
      "499it [01:23,  6.06it/s]\titers: 500, epoch: 13 | loss: 0.1795375\n",
      "\tspeed: 0.1661s/iter; left time: 4850.5249s\n",
      "599it [01:39,  6.05it/s]\titers: 600, epoch: 13 | loss: 0.2715749\n",
      "\tspeed: 0.1652s/iter; left time: 4808.0825s\n",
      "699it [01:56,  6.05it/s]\titers: 700, epoch: 13 | loss: 0.1499349\n",
      "\tspeed: 0.1651s/iter; left time: 4789.1107s\n",
      "799it [02:12,  6.06it/s]\titers: 800, epoch: 13 | loss: 0.3028055\n",
      "\tspeed: 0.1652s/iter; left time: 4775.0831s\n",
      "899it [02:29,  6.05it/s]\titers: 900, epoch: 13 | loss: 0.2184045\n",
      "\tspeed: 0.1651s/iter; left time: 4757.0939s\n",
      "999it [02:45,  6.06it/s]\titers: 1000, epoch: 13 | loss: 0.1779370\n",
      "\tspeed: 0.1653s/iter; left time: 4746.1839s\n",
      "1099it [03:02,  6.08it/s]\titers: 1100, epoch: 13 | loss: 0.2070297\n",
      "\tspeed: 0.1654s/iter; left time: 4732.0027s\n",
      "1199it [03:18,  6.06it/s]\titers: 1200, epoch: 13 | loss: 0.1377821\n",
      "\tspeed: 0.1650s/iter; left time: 4704.7085s\n",
      "1299it [03:35,  6.04it/s]\titers: 1300, epoch: 13 | loss: 0.2958670\n",
      "\tspeed: 0.1654s/iter; left time: 4698.1637s\n",
      "1399it [03:51,  6.05it/s]\titers: 1400, epoch: 13 | loss: 0.2730978\n",
      "\tspeed: 0.1654s/iter; left time: 4680.3589s\n",
      "1499it [04:08,  6.05it/s]\titers: 1500, epoch: 13 | loss: 0.1743781\n",
      "\tspeed: 0.1652s/iter; left time: 4658.0650s\n",
      "1599it [04:24,  6.06it/s]\titers: 1600, epoch: 13 | loss: 0.1114935\n",
      "\tspeed: 0.1652s/iter; left time: 4644.1086s\n",
      "1699it [04:41,  6.04it/s]\titers: 1700, epoch: 13 | loss: 0.3368587\n",
      "\tspeed: 0.1653s/iter; left time: 4629.4489s\n",
      "1799it [04:57,  6.06it/s]\titers: 1800, epoch: 13 | loss: 0.0996192\n",
      "\tspeed: 0.1655s/iter; left time: 4617.3376s\n",
      "1899it [05:14,  6.05it/s]\titers: 1900, epoch: 13 | loss: 0.2675720\n",
      "\tspeed: 0.1652s/iter; left time: 4594.0197s\n",
      "1999it [05:30,  6.07it/s]\titers: 2000, epoch: 13 | loss: 0.1069673\n",
      "\tspeed: 0.1653s/iter; left time: 4580.8014s\n",
      "2099it [05:47,  6.04it/s]\titers: 2100, epoch: 13 | loss: 0.1661476\n",
      "\tspeed: 0.1652s/iter; left time: 4561.5936s\n",
      "2199it [06:04,  6.01it/s]\titers: 2200, epoch: 13 | loss: 0.2486536\n",
      "\tspeed: 0.1658s/iter; left time: 4561.4166s\n",
      "2299it [06:20,  6.05it/s]\titers: 2300, epoch: 13 | loss: 0.2657228\n",
      "\tspeed: 0.1656s/iter; left time: 4538.2439s\n",
      "2399it [06:37,  6.05it/s]\titers: 2400, epoch: 13 | loss: 0.1324353\n",
      "\tspeed: 0.1652s/iter; left time: 4510.5637s\n",
      "2499it [06:53,  6.06it/s]\titers: 2500, epoch: 13 | loss: 0.3193991\n",
      "\tspeed: 0.1652s/iter; left time: 4494.3859s\n",
      "2599it [07:10,  6.07it/s]\titers: 2600, epoch: 13 | loss: 0.1527284\n",
      "\tspeed: 0.1654s/iter; left time: 4482.3541s\n",
      "2699it [07:26,  6.09it/s]\titers: 2700, epoch: 13 | loss: 0.2128842\n",
      "\tspeed: 0.1646s/iter; left time: 4445.1777s\n",
      "2799it [07:43,  6.10it/s]\titers: 2800, epoch: 13 | loss: 0.2055501\n",
      "\tspeed: 0.1642s/iter; left time: 4418.2237s\n",
      "2899it [07:59,  6.09it/s]\titers: 2900, epoch: 13 | loss: 0.1412399\n",
      "\tspeed: 0.1642s/iter; left time: 4402.4020s\n",
      "2999it [08:15,  6.09it/s]\titers: 3000, epoch: 13 | loss: 0.0992042\n",
      "\tspeed: 0.1640s/iter; left time: 4380.2438s\n",
      "3099it [08:32,  6.09it/s]\titers: 3100, epoch: 13 | loss: 0.1560125\n",
      "\tspeed: 0.1641s/iter; left time: 4366.1392s\n",
      "3199it [08:48,  6.09it/s]\titers: 3200, epoch: 13 | loss: 0.3440793\n",
      "\tspeed: 0.1641s/iter; left time: 4350.6907s\n",
      "3299it [09:05,  6.09it/s]\titers: 3300, epoch: 13 | loss: 0.2991653\n",
      "\tspeed: 0.1641s/iter; left time: 4333.4375s\n",
      "3399it [09:21,  6.10it/s]\titers: 3400, epoch: 13 | loss: 0.2230098\n",
      "\tspeed: 0.1641s/iter; left time: 4315.4192s\n",
      "3499it [09:37,  5.94it/s]\titers: 3500, epoch: 13 | loss: 0.3352249\n",
      "\tspeed: 0.1645s/iter; left time: 4309.7306s\n",
      "3599it [09:54,  6.07it/s]\titers: 3600, epoch: 13 | loss: 0.2024688\n",
      "\tspeed: 0.1643s/iter; left time: 4289.3409s\n",
      "3699it [10:10,  6.08it/s]\titers: 3700, epoch: 13 | loss: 0.1855941\n",
      "\tspeed: 0.1642s/iter; left time: 4270.0014s\n",
      "3713it [10:13,  6.06it/s]\n",
      "Epoch: 13 cost time: 613.1505575180054\n",
      "810it [01:06, 12.25it/s]\n",
      "807it [01:05, 12.25it/s]\n",
      "Epoch: 13 | Train Loss: 0.2190897 Vali Loss: 0.2690037 Test Loss: 0.3359515 MAE Loss: 0.3461087\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "learning_rate 3.9999999999999996e-05\n",
      "lr 9.765624999999999e-09\n",
      "99it [00:16,  6.04it/s]\titers: 100, epoch: 14 | loss: 0.1616454\n",
      "\tspeed: 1.5120s/iter; left time: 39149.9508s\n",
      "199it [00:33,  6.07it/s]\titers: 200, epoch: 14 | loss: 0.2871063\n",
      "\tspeed: 0.1652s/iter; left time: 4259.8308s\n",
      "299it [00:49,  6.06it/s]\titers: 300, epoch: 14 | loss: 0.4052692\n",
      "\tspeed: 0.1651s/iter; left time: 4241.2157s\n",
      "399it [01:06,  6.05it/s]\titers: 400, epoch: 14 | loss: 0.2077134\n",
      "\tspeed: 0.1651s/iter; left time: 4225.7860s\n",
      "499it [01:22,  6.06it/s]\titers: 500, epoch: 14 | loss: 0.2431389\n",
      "\tspeed: 0.1654s/iter; left time: 4216.9724s\n",
      "599it [01:39,  6.04it/s]\titers: 600, epoch: 14 | loss: 0.2370460\n",
      "\tspeed: 0.1655s/iter; left time: 4201.5172s\n",
      "699it [01:55,  6.06it/s]\titers: 700, epoch: 14 | loss: 0.2580609\n",
      "\tspeed: 0.1653s/iter; left time: 4180.9653s\n",
      "799it [02:12,  6.04it/s]\titers: 800, epoch: 14 | loss: 0.3567287\n",
      "\tspeed: 0.1652s/iter; left time: 4160.6507s\n",
      "899it [02:28,  6.05it/s]\titers: 900, epoch: 14 | loss: 0.2301244\n",
      "\tspeed: 0.1654s/iter; left time: 4149.2932s\n",
      "999it [02:45,  6.07it/s]\titers: 1000, epoch: 14 | loss: 0.2858422\n",
      "\tspeed: 0.1652s/iter; left time: 4129.8838s\n",
      "1099it [03:01,  6.06it/s]\titers: 1100, epoch: 14 | loss: 0.1294095\n",
      "\tspeed: 0.1650s/iter; left time: 4107.2917s\n",
      "1199it [03:18,  6.05it/s]\titers: 1200, epoch: 14 | loss: 0.1253197\n",
      "\tspeed: 0.1651s/iter; left time: 4093.9683s\n",
      "1299it [03:35,  6.06it/s]\titers: 1300, epoch: 14 | loss: 0.1991228\n",
      "\tspeed: 0.1655s/iter; left time: 4085.4055s\n",
      "1399it [03:51,  6.04it/s]\titers: 1400, epoch: 14 | loss: 0.2107093\n",
      "\tspeed: 0.1653s/iter; left time: 4066.1408s\n",
      "1499it [04:08,  6.06it/s]\titers: 1500, epoch: 14 | loss: 0.2475914\n",
      "\tspeed: 0.1652s/iter; left time: 4046.7301s\n",
      "1599it [04:24,  6.04it/s]\titers: 1600, epoch: 14 | loss: 0.1500807\n",
      "\tspeed: 0.1654s/iter; left time: 4034.8254s\n",
      "1604it [04:25,  6.05it/s]^C\n",
      "1604it [04:25,  6.04it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 257, in <module>\n",
      "    scaler.update()\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1976, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2051, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Total time: 190.450011130174 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "#learning_rate=0.0001\n",
    "# learning_rate= 0.01\n",
    "# Epoch: 1 | Train Loss: 0.3189694 Vali Loss: 0.3789306 Test Loss: 0.4752660 MAE Loss: 0.4676420\n",
    "learning_rate = 0.001\n",
    "llama_layers=6 # 626 sec on 1 epoch # 13 min, # 1095 sec\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "!python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id FR_96_24 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")\n",
    "# train 88899 # 89115\n",
    "# val 25707 # 25923\n",
    "# test 12675 # 12891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB15ElEQVR4nO3dd1gT9x8H8HfCCHuIyFAEZ91oQazbVhTFqmgdtVaRttpWqVpaV61b66hVf9W6q22tVqt1L0QKThwVV62rDnDhVgQEQnK/P66JRlaYF5L363ny5HJ3ufvclxA+3HfJBEEQQERERGRC5FIHQERERFTamAARERGRyWECRERERCaHCRARERGZHCZAREREZHKYABEREZHJYQJEREREJocJEBEREZkcJkBERERkcpgAkY4BAwbAx8enUO+dOHEiZDJZ8QZkYK5fvw6ZTIaffvqp1M8tk8kwceJE7euffvoJMpkM169fz/e9Pj4+GDBgQLHGU5TPiqm4fPky2rdvD0dHR8hkMmzevFnqkAwSP0skBSZAZYRMJtPrERsbK3WoJm/o0KGQyWT4999/c91n7NixkMlkOHPmTClGVnC3b9/GxIkTcerUKalD0dIkobNnz5Y6lHyFhobi7NmzmDZtGlatWgV/f/8SO1dZKhdjs3DhwhL5p6hNmzaQyWTo3Llztm38eRedudQBkH5WrVql8/qXX35BVFRUtvW1a9cu0nmWLVsGtVpdqPd+/fXXGD16dJHObwz69u2L+fPnY82aNRg/fnyO+/z222+oX78+GjRoUOjz9OvXD++++y4UCkWhj5Gf27dvY9KkSfDx8UHDhg11thXls2IKnj9/jri4OIwdOxbh4eFSh2PQyvpnaeHChShfvnyx32XV2L59O06cOAE/P78SOb6pYgJURrz//vs6r48cOYKoqKhs61+VlpYGGxsbvc9jYWFRqPgAwNzcHObm/Eg1adIE1atXx2+//ZZjAhQXF4dr165hxowZRTqPmZkZzMzMinSMoijKZ8UU3L9/HwDg5ORUbMdMTU2Fra1tsR2vJAiCgPT0dFhbW+v9HkP6LBUm/pJUuXJlPHv2DJMmTcLWrVulDseosArMiLRp0wb16tXDiRMn0KpVK9jY2OCrr74CAGzZsgWdOnWCp6cnFAoFqlWrhilTpkClUukc49W6+Jdvsy5duhTVqlWDQqFA48aNcfz4cZ335tQGSCaTITw8HJs3b0a9evWgUChQt25d7N69O1v8sbGx8Pf3h5WVFapVq4YlS5bo3a7owIED6NmzJypXrgyFQgEvLy98/vnneP78ebbrs7Ozw61btxASEgI7Ozu4urriyy+/zFYWT548wYABA+Do6AgnJyeEhobiyZMn+cYCiHeBLly4gPj4+Gzb1qxZA5lMhj59+iAzMxPjx4+Hn58fHB0dYWtri5YtWyImJibfc+TUBkgQBEydOhWVKlWCjY0N3nzzTZw7dy7bex89eoQvv/wS9evXh52dHRwcHNCxY0ecPn1au09sbCwaN24MAAgLC9NWs2pu9efUbiM1NRVffPEFvLy8oFAo8Nprr2H27NkQBEFnv4J8Lgrr3r17+PDDD+Hm5gYrKyv4+vri559/zrbf2rVr4efnB3t7ezg4OKB+/fr43//+p92uVCoxadIk1KhRA1ZWVnBxcUGLFi0QFRWV67knTpwIb29vAMCIESMgk8l0yurkyZPo2LEjHBwcYGdnh7Zt2+LIkSM6x9D8fPft24fBgwejQoUKqFSpUhFLBcjIyMCECRNQvXp17e/KyJEjkZGRobPfypUr8dZbb6FChQpQKBSoU6cOFi1alO14Pj4+ePvttxEZGQl/f39YW1tjyZIliI2NhUwmw++//45p06ahUqVKsLKyQtu2bbNVDxflewcA1q9fjzp16sDKygr16tXDpk2b9G5XlFv8+paBj48Pzp07h3379ml/R9q0aaPd/uTJEwwfPlz7O1G9enXMnDlT7zte9vb2+Pzzz7Ft27Ycv09edfXqVfTs2RPlypWDjY0N3njjDezYsUNnn4L8bADg6NGj6NChAxwdHWFjY4PWrVvj0KFDesVvyPjvupF5+PAhOnbsiHfffRfvv/8+3NzcAIhfpnZ2doiIiICdnR3+/PNPjB8/HsnJyfj222/zPe6aNWvw7NkzfPzxx5DJZJg1axa6d++Oq1ev5vvf28GDB7Fx40YMHjwY9vb2+P777/HOO+8gMTERLi4uAMQ/CB06dICHhwcmTZoElUqFyZMnw9XVVa/rXr9+PdLS0vDpp5/CxcUFx44dw/z583Hz5k2sX79eZ1+VSoWgoCA0adIEs2fPxt69e/Hdd9+hWrVq+PTTTwGIiUTXrl1x8OBBfPLJJ6hduzY2bdqE0NBQveLp27cvJk2ahDVr1uD111/XOffvv/+Oli1bonLlynjw4AGWL1+OPn36YODAgXj27Bl+/PFHBAUF4dixY9mqnfIzfvx4TJ06FcHBwQgODkZ8fDzat2+PzMxMnf2uXr2KzZs3o2fPnqhSpQru3r2LJUuWoHXr1vjnn3/g6emJ2rVrY/LkyRg/fjwGDRqEli1bAgCaNWuW47kFQUCXLl0QExODDz/8EA0bNkRkZCRGjBiBW7duYe7cuTr76/O5KKznz5+jTZs2+PfffxEeHo4qVapg/fr1GDBgAJ48eYJhw4YBAKKiotCnTx+0bdsWM2fOBACcP38ehw4d0u4zceJETJ8+HR999BECAgKQnJyMv/76C/Hx8WjXrl2O5+/evTucnJzw+eefo0+fPggODoadnR0A4Ny5c2jZsiUcHBwwcuRIWFhYYMmSJWjTpg327duHJk2a6Bxr8ODBcHV1xfjx45GamlqkclGr1ejSpQsOHjyIQYMGoXbt2jh79izmzp2LS5cu6TTSXrRoEerWrYsuXbrA3Nwc27Ztw+DBg6FWqzFkyBCd4168eBF9+vTBxx9/jIEDB+K1117TbpsxYwbkcjm+/PJLPH36FLNmzULfvn1x9OjRfOPV53tnx44d6N27N+rXr4/p06fj8ePH+PDDD1GxYkW9yyW3+PUpg3nz5uGzzz6DnZ0dxo4dCwDa7920tDS0bt0at27dwscff4zKlSvj8OHDGDNmDO7cuYN58+bpFd+wYcMwd+5cTJw4Mc+7QHfv3kWzZs2QlpaGoUOHwsXFBT///DO6dOmCDRs2oFu3bjr76/Oz+fPPP9GxY0f4+flhwoQJkMvl2sTwwIEDCAgI0LucDY5AZdKQIUOEV398rVu3FgAIixcvzrZ/WlpatnUff/yxYGNjI6Snp2vXhYaGCt7e3trX165dEwAILi4uwqNHj7Trt2zZIgAQtm3bpl03YcKEbDEBECwtLYV///1Xu+706dMCAGH+/PnadZ07dxZsbGyEW7duadddvnxZMDc3z3bMnOR0fdOnTxdkMpmQkJCgc30AhMmTJ+vs26hRI8HPz0/7evPmzQIAYdasWdp1WVlZQsuWLQUAwsqVK/ONqXHjxkKlSpUElUqlXbd7924BgLBkyRLtMTMyMnTe9/jxY8HNzU344IMPdNYDECZMmKB9vXLlSgGAcO3aNUEQBOHevXuCpaWl0KlTJ0GtVmv3++qrrwQAQmhoqHZdenq6TlyCIP6sFQqFTtkcP3481+t99bOiKbOpU6fq7NejRw9BJpPpfAb0/VzkRPOZ/Pbbb3PdZ968eQIA4ddff9Wuy8zMFJo2bSrY2dkJycnJgiAIwrBhwwQHBwchKysr12P5+voKnTp1yjOmgsQZEhIiWFpaCleuXNGuu337tmBvby+0atVKu07z823RokWe8eV3vpetWrVKkMvlwoEDB3TWL168WAAgHDp0SLsup9+poKAgoWrVqjrrvL29BQDC7t27ddbHxMQIAITatWvrfMb/97//CQCEs2fPatcV5Xunfv36QqVKlYRnz55p18XGxgoAdI6Zm9ziL0gZ1K1bV2jdunW2fadMmSLY2toKly5d0lk/evRowczMTEhMTMwzttatWwt169YVBEEQJk2aJAAQTpw4IQhCzj/v4cOHCwB0fr7Pnj0TqlSpIvj4+Gh/5/X92ajVaqFGjRpCUFCQzndKWlqaUKVKFaFdu3Z5xm/oWAVmZBQKBcLCwrKtf7k++9mzZ3jw4AFatmyJtLQ0XLhwId/j9u7dG87OztrXmrsBV69ezfe9gYGBqFatmvZ1gwYN4ODgoH2vSqXC3r17ERISAk9PT+1+1atXR8eOHfM9PqB7fampqXjw4AGaNWsGQRBw8uTJbPt/8sknOq9btmypcy07d+6Eubm59o4QILa5+eyzz/SKBxDbbd28eRP79+/XrluzZg0sLS3Rs2dP7TEtLS0BiP+dP3r0CFlZWfD399frdvfL9u7di8zMTHz22Wc61YbDhw/Ptq9CoYBcLv76q1QqPHz4EHZ2dnjttdcKfF6NnTt3wszMDEOHDtVZ/8UXX0AQBOzatUtnfX6fi6LYuXMn3N3d0adPH+06CwsLDB06FCkpKdi3bx8AsX1OampqntVZTk5OOHfuHC5fvlzkuFQqFfbs2YOQkBBUrVpVu97DwwPvvfceDh48iOTkZJ33DBw4sNjaeq1fvx61a9dGrVq18ODBA+3jrbfeAgCdqteXf6eePn2KBw8eoHXr1rh69SqePn2qc9wqVaogKCgox3OGhYVpP+NAwb478vveuX37Ns6ePYv+/ftr77ABQOvWrVG/fv18j59f/AUpg5ysX78eLVu2hLOzs055BwYGQqVS6Xw35GfYsGFwdnbGpEmTct1n586dCAgIQIsWLbTr7OzsMGjQIFy/fh3//POPzv75/WxOnTqFy5cv47333sPDhw+18aempqJt27bYv39/mW68zgTIyFSsWFHnA61x7tw5dOvWDY6OjnBwcICrq6u2AbU+v8iVK1fWea35Unr8+HGB36t5v+a99+7dw/Pnz1G9evVs++W0LieJiYkYMGAAypUrp23X07p1awDZr8/Kyipb1drL8QBAQkICPDw8dL5UAejc2s/Pu+++CzMzM6xZswYAkJ6ejk2bNqFjx446X+o///wzGjRooG1f4urqih07duj1c3lZQkICAKBGjRo6611dXXXOB4jJ1ty5c1GjRg0oFAqUL18erq6uOHPmTIHP+/L5PT09YW9vr7Ne0zNRE59Gfp+LokhISECNGjW0SV5usQwePBg1a9ZEx44dUalSJXzwwQfZ2iFNnjwZT548Qc2aNVG/fn2MGDGi0MMX3L9/H2lpaTl+jmrXrg21Wo0bN27orK9SpUqhzpWTy5cv49y5c3B1ddV51KxZE4D4u6hx6NAhBAYGwtbWFk5OTnB1ddW2KcwpAcpNcX53vPpezc+xKN8dQO7xF6QMcnL58mXs3r07W3kHBgYC0C3v/Dg6OmL48OHYunVrjv/UAWJ55PbZ0mx/WX7lq0n6Q0NDs13D8uXLkZGRUejvC0PANkBGJqeeC0+ePEHr1q3h4OCAyZMno1q1arCyskJ8fDxGjRqlVwaf23+gwiuNW4v7vfpQqVRo164dHj16hFGjRqFWrVqwtbXFrVu3MGDAgGzXV1o9pypUqIB27drhjz/+wA8//IBt27bh2bNn6Nu3r3afX3/9FQMGDEBISAhGjBiBChUqwMzMDNOnT8eVK1dKLLZvvvkG48aNwwcffIApU6agXLlykMvlGD58eKn9R1fSnwt9VKhQAadOnUJkZCR27dqFXbt2YeXKlejfv7+2wXSrVq1w5coVbNmyBXv27MHy5csxd+5cLF68GB999FGJx1icvZHUajXq16+POXPm5Ljdy8sLAHDlyhW0bdsWtWrVwpw5c+Dl5QVLS0vs3LkTc+fOzfYZyStGQ/7u0Mgp/oKWQU7UajXatWuHkSNH5rhdk3jqS9MWaNKkSXq3H8pLfuWrucZvv/021/aIr/6TWJYwATIBsbGxePjwITZu3IhWrVpp11+7dk3CqF6oUKECrKyscux9kNdgghpnz57FpUuX8PPPP6N///7a9XlVa+TH29sb0dHRSElJ0fkFv3jxYoGO07dvX+zevRu7du3CmjVr4ODgoDOo2YYNG1C1alVs3LhRp9pqwoQJhYoZEP9re7l65f79+9n+296wYQPefPNN/Pjjjzrrnzx5gvLly2tfF2Rkb29vb+zduxfPnj3TuQukqWLVxFcavL29cebMGajVap27QDnFYmlpic6dO6Nz585Qq9UYPHgwlixZgnHjxmnvIpQrVw5hYWEICwtDSkoKWrVqhYkTJxY4AXJ1dYWNjU2On6MLFy5ALpdrk5CSUK1aNZw+fRpt27bN82e7bds2ZGRkYOvWrTp3CfTpnViaND/Hwn535KUgZZBbWVarVg0pKSnaOz5FpbkLNHHixBw7ZHh7e+f62dJsLwhNFbWDg0OxXYMhYRWYCdBk+S//15SZmYmFCxdKFZIOMzMzBAYGYvPmzbh9+7Z2/b///put3Uhu7wd0r08QBJ2uzAUVHByMrKwsnS6vKpUK8+fPL9BxQkJCYGNjg4ULF2LXrl3o3r07rKys8oz96NGjiIuLK3DMgYGBsLCwwPz583WOl9N/imZmZtn+i16/fj1u3bqls04z5ow+3f+Dg4OhUqmwYMECnfVz586FTCbTuz1XcQgODkZSUhLWrVunXZeVlYX58+fDzs5OWz368OFDnffJ5XLt4JSabuGv7mNnZ4fq1atn6zauDzMzM7Rv3x5btmzRGb7g7t27WLNmDVq0aAEHB4cCH1dfvXr1wq1bt7Bs2bJs254/f67tZZbT5/Lp06dYuXJlicVWGJ6enqhXrx5++eUXpKSkaNfv27cPZ8+eLdKxC1IGtra2Of6O9OrVC3FxcYiMjMy27cmTJ8jKyipwXMOHD4eTkxMmT56cbVtwcDCOHTum8/2RmpqKpUuXwsfHB3Xq1CnQufz8/FCtWjXMnj1bp3w1NGNdlVW8A2QCmjVrBmdnZ4SGhmqnaVi1alWpVjXkZ+LEidizZw+aN2+OTz/9VPuHtF69evlOw1CrVi1Uq1YNX375JW7dugUHBwf88ccfRWpL0rlzZzRv3hyjR4/G9evXUadOHWzcuLHA9d12dnYICQnRtgN6ufoLAN5++21s3LgR3bp1Q6dOnXDt2jUsXrwYderUyfELJy+a8YymT5+Ot99+G8HBwTh58iR27dqlc1dHc97JkycjLCwMzZo1w9mzZ7F69WqdO0eA+B+gk5MTFi9eDHt7e9ja2qJJkyY5tpno3Lkz3nzzTYwdOxbXr1+Hr68v9uzZgy1btmD48OE6DZ6LQ3R0NNLT07OtDwkJwaBBg7BkyRIMGDAAJ06cgI+PDzZs2IBDhw5h3rx52jtUH330ER49eoS33noLlSpVQkJCAubPn4+GDRtq203UqVMHbdq0gZ+fH8qVK4e//voLGzZsKPTozlOnTkVUVBRatGiBwYMHw9zcHEuWLEFGRgZmzZpV+AL5T17l0q9fP/z+++/45JNPEBMTg+bNm0OlUuHChQv4/ffftWPhtG/fXntn7OOPP0ZKSgqWLVuGChUq4M6dO0WOsTh988036Nq1K5o3b46wsDA8fvxY+91R0N+hlxWkDPz8/LBo0SJMnToV1atXR4UKFfDWW29hxIgR2Lp1K95++20MGDAAfn5+SE1NxdmzZ7FhwwZcv3492+9mfhwdHTFs2LAcG0OPHj0av/32Gzp27IihQ4eiXLly+Pnnn3Ht2jX88ccf2drE5Ucul2P58uXo2LEj6tati7CwMFSsWBG3bt1CTEwMHBwcsG3btgId06CUer8zKha5dYPXdJl81aFDh4Q33nhDsLa2Fjw9PYWRI0cKkZGRAgAhJiZGu19u3VFz6lqLV7pl59YNfsiQIdne6+3trdMtWxAEITo6WmjUqJFgaWkpVKtWTVi+fLnwxRdfCFZWVrmUwgv//POPEBgYKNjZ2Qnly5cXBg4cqO1W/XIX7tDQUMHW1jbb+3OK/eHDh0K/fv0EBwcHwdHRUejXr59w8uRJvbvBa+zYsUMAIHh4eGTreq5Wq4VvvvlG8Pb2FhQKhdCoUSNh+/bt2X4OgpB/N3hBEASVSiVMmjRJ8PDwEKytrYU2bdoIf//9d7byTk9PF7744gvtfs2bNxfi4uKE1q1bZ+vOu2XLFqFOnTraIQk0155TjM+ePRM+//xzwdPTU7CwsBBq1KghfPvttzpdaDXXou/n4lWaz2Ruj1WrVgmCIAh3794VwsLChPLlywuWlpZC/fr1s/3cNmzYILRv316oUKGCYGlpKVSuXFn4+OOPhTt37mj3mTp1qhAQECA4OTkJ1tbWQq1atYRp06YJmZmZesWZ0+9OfHy8EBQUJNjZ2Qk2NjbCm2++KRw+fFhnH83P9/jx43mep6DlkpmZKcycOVOoW7euoFAoBGdnZ8HPz0+YNGmS8PTpU+3xtm7dKjRo0ECwsrISfHx8hJkzZworVqzI9pnz9vbOcZgATVfr9evX5xjnq7+Xhf3eEQRBWLt2rVCrVi1BoVAI9erVE7Zu3Sq88847Qq1atfItt9ziL0gZJCUlCZ06dRLs7e0FADq/Q8+ePRPGjBkjVK9eXbC0tBTKly8vNGvWTJg9e3a+n6HcvtMfP34sODo65lhGV65cEXr06CE4OTkJVlZWQkBAgLB9+3adfQrysxEEQTh58qTQvXt3wcXFRVAoFIK3t7fQq1cvITo6Os/4DZ1MEAzoNgDRK0JCQoqtCzIRmY6GDRvC1dW1SG0BybixDRAZjFenrbh8+TJ27typM6w8EdHLlEpltrY0sbGxOH36NL87KE+8A0QGw8PDAwMGDEDVqlWRkJCARYsWISMjAydPnsw2tg0RESDOGxYYGIj3338fnp6euHDhAhYvXgxHR0f8/fffRZ5WhYwXG0GTwejQoQN+++03JCUlQaFQoGnTpvjmm2+Y/BBRrpydneHn54fly5fj/v37sLW1RadOnTBjxgwmP5Qn3gEiIiIik8M2QERERGRymAARERGRyWEboByo1Wrcvn0b9vb2BZoKgIiIiKQjCAKePXsGT0/PfAd+ZAKUg9u3b5fofDxERERUcm7cuIFKlSrluQ8ToBxohsm/ceNGic7LYyiUSiX27NmD9u3bw8LCQupwDBrLSn8sq4JheemPZaU/Uyur5ORkeHl56UzInBsmQDnQVHs5ODiYTAJkY2MDBwcHk/gFKQqWlf5YVgXD8tIfy0p/plpW+jRfYSNoIiIiMjlMgIiIiMjkMAEiIiIik8M2QEREVOzUajUyMzNL5NhKpRLm5uZIT0+HSqUqkXMYC2MrKwsLC5iZmRXLsZgAERFRscrMzMS1a9egVqtL5PiCIMDd3R03btzgWG35MMaycnJygru7e5GvhwkQEREVG0EQcOfOHZiZmcHLyyvfwegKQ61WIyUlBXZ2diVyfGNiTGUlCALS0tJw7949AICHh0eRjscEiIiIik1WVhbS0tLg6ekJGxubEjmHpnrNysqqzP9RL2nGVlbW1tYAgHv37qFChQpFqg4r+6VBREQGQ9POxNLSUuJIyFhpEmulUlmk4zABIiKiYmcs7U3I8BTXZ4sJEBEREZkcJkBEREQlwMfHB/PmzdN7/9jYWMhkMjx58qTEYqIXmAAREZFJk8lkeT4mTpxYqOMeP34cgwYN0nv/Zs2a4c6dO3B0dCzU+fTFREvEXmCl7cIFwM4OqFRJ6kiIiAjAnTt3tMvr1q3D+PHjcfHiRe06Ozs77bIgCFCpVDA3z//Pp6ura4HisLS0hLu7e4HeQ4XHO0ClKSICqF0bWLBA6kiIiOg/7u7u2oejoyNkMpn29YULF2Bvb49du3bBz88PCoUCBw8exJUrV9C1a1e4ubnBzs4OjRs3xt69e3WO+2oVmEwmw/Lly9GtWzfY2NigRo0a2Lp1q3b7q3dmfvrpJzg5OSEyMhK1a9eGnZ0dOnTooJOwZWVlYejQoXBycoKLiwtGjRqF0NBQhISEFLo8Hj9+jP79+8PZ2Rk2Njbo2LEjLl++rN2ekJCAzp07w9nZGba2tqhbty527typfW/fvn3h6uoKa2tr1KhRAytXrix0LCWJCVBpatpUfF67FhAEaWMhIioFggCkpkrzKM6v2dGjR2PGjBk4f/48GjRogJSUFAQHByM6OhonT55Ehw4d0LlzZyQmJuZ5nEmTJqFXr144c+YMgoOD0bdvXzx69CjX/dPS0jB79mysWrUK+/fvR2JiIr788kvt9pkzZ2L16tVYuXIlDh06hOTkZGzevLlI1zpgwAD89ddf2Lp1K+Li4iAIAoKDg7XdzocMGYKMjAzs378fZ8+excyZM7V3ycaNG4d//vkHu3btwvnz57Fo0SKUL1++SPGUFFaBlaZOncTqr4QE4OhR4I03pI6IiKhEpaWJX3vFSw7AKd+9UlIAW9viOePkyZPRrl077ety5crB19dX+3rKlCnYtGkTtm7divDw8FyPM2DAAPTp0wcA8M033+D777/HsWPH0KFDhxz3VyqVWLx4MapVqwYACA8Px+TJk7Xb58+fjzFjxqBbt24AgAULFmjvxhTG5cuXsXXrVhw6dAjNmjUDAKxevRpeXl7YvHkzevbsicTERLzzzjuoX78+AKBq1ara9ycmJqJRo0bw9/cHIN4FM1S8A1SabGyArl3F5d9+kzYWIiLSm+YPukZKSgq+/PJL1K5dG05OTrCzs8P58+fzvQPUoEED7bKtrS0cHBy0UzvkxMbGRpv8AOL0D5r9nz59irt37yIgIEC73czMDH5+fgW6tpedP38e5ubmaNKkiXadi4sLXnvtNZw/fx4AMHToUEydOhXNmzfHhAkTcObMGe2+n376KdauXYuGDRti5MiROHz4cKFjKWlMgErbf5k/fv8dMIKZeYmI8mJjI96JKc5HcrIaN28+QXKyOs/9inMmDttXbiV9+eWX2LRpE7755hscOHAAp06dQv369ZGZmZnncSwsLHRey2SyPCeNzWl/QeImFB999BGuXr2Kfv364ezZs/D398f8+fMBAB07dkRCQgI+//xz3L59G23bttWpsjMkTIBKW7t2gLMzkJQE7NsndTRERCVKJhOroaR4lORg1IcOHcKAAQPQrVs31K9fH+7u7rh+/XrJnTAHjo6OcHNzw/Hjx7XrVCoV4uPjC33M2rVrIysrC0ePHtWue/jwIS5evIg6depo13l5eeGTTz7Bxo0b8cUXX2DZsmXaba6urggNDcWvv/6KefPmYenSpYWOpySxDVBps7QEevQAli0TG0O/9ZbUERERUQHVqFEDGzduROfOnSGTyTBu3Lg87+SUlM8++wzTp09H9erVUatWLcyfPx+PHz/Wa7qIs2fPwt7eXvtaJpPB19cXXbt2xcCBA7FkyRLY29tj9OjRqFixIrr+14Rj+PDh6NixI2rWrInHjx8jJiYGtWvXBgCMHz8efn5+qFu3LjIyMrB9+3btNkPDBEgK774rJkAbNohd4jlpIBFRmTJnzhx88MEHaNasGcqXL49Ro0YhOTm51OMYNWoUkpKS0L9/f5iZmWHQoEEICgrSa5b0Vq1a6bw2MzNDVlYWVq5ciWHDhuHtt99GZmYmWrVqhZ07d2qr41QqFYYMGYKbN2/CwcEBHTp0wNy5cwGIYxmNGTMG169fh7W1NVq2bIm1a9cW/4UXA5kgdWWiAUpOToajoyOePn0KBweH4j+BSiUOhJiUBGzfLvYOk5BSqcTOnTsRHBycrb6ZdLGs9MeyKhhjKa/09HRcu3YNVapUgZWVVYmcQ61WIzk5GQ4ODpDL2ZLjZWq1GrVr10avXr0wZcoUoyyrvD5jBfn7bRylUdaYmQG9eonL7A1GRESFlJCQgGXLluHSpUs4e/YsPv30U1y7dg3vvfee1KEZPCZAUtH0BtuyRRwog4iIqIDkcjl++uknNG7cGM2bN8fZs2exd+9eg213Y0jYBkgqTZoA3t7ioIg7dgA9e0odERERlTFeXl44dOiQ1GGUSbwDJBWZTGwMDYi9wYiIiKjUMAGSkqYabMcO4OlTaWMhIiIyIUyApNSgAVCrFpCRIbYFIiIiolLBBEhKMtmLu0DsDUZERFRqmABJTdMOKCoKePBA2liIiIhMBBMgqdWsCbz+ujg44h9/SB0NERGRSWACZAg0d4FYDUZEVGa1adMGw4cP17728fHBvHnz8nyPTCbD5s2bi3zu4jqOKWECZAh69xaf9+8Hbt2SNhYiIhPTuXNndOjQIcdtBw4cgEwmw5kzZwp83OPHj2PQoEFFDU/HxIkT0bBhw2zr79y5g44dOxbruV71008/wcnJqUTPUZqYABmCypWB5s0BQQB+/13qaIiITMqHH36IqKgo3Lx5M9u2lStXwt/fHw0aNCjwcV1dXWFjY1McIebL3d0dCoWiVM5lLJgAGQpNbzAOikhEVKrefvttuLq64qefftJZn5KSgvXr1+PDDz/Ew4cP0adPH1SsWBE2NjaoX78+fsun2cKrVWCXL19Gq1atYGVlhTp16iAqKirbe0aNGoWaNWvCxsYGVatWxbhx46BUKgGId2AmTZqE06dPQyaTQSaTaWN+tQrs7NmzeOutt2Bra4uqVavi448/RkpKinb7gAEDEBISgtmzZ8PDwwMuLi4YMmSI9lyFkZiYiK5du8LOzg4ODg7o1asX7t69q91++vRpvPnmm7C3t4eDgwP8/Pzw119/ARDnNOvcuTOcnZ1ha2uLunXrYufOnYWORR+cCsNQ9OgBDB0KHDsGXLkCVKsmdUREREUnCMU/36FaDaSmihNL5zXDuY2NONxIPszNzdG/f3/89NNPGDt2LGT/vWf9+vVQqVTo06cPUlJS4Ofnh1GjRsHBwQE7duxAv379UK1aNQQEBOgRshrdu3eHm5sbjh49iqdPn+q0F9Kwt7fHTz/9BE9PT5w9exYDBw6Evb09Ro4cid69e+Pvv//G7t27sXfvXgCAo6NjtmOkpqYiKCgITZs2xdGjR3H9+nUMHz4c4eHhOkleTEwMPDw8EBMTg3///Re9e/dGw4YNMXDgwHyvJ6fr0yQ/+/btQ1ZWFoYMGYLevXsjNjYWANC3b180atQIixYtgpmZGU6dOgULCwsAwJAhQ5CZmYn9+/fD1tYW//zzD+zs7AocR4EIlM3Tp08FAMLTp09L98Tt2gkCIAjTppXqaTMzM4XNmzcLmZmZpXresohlpT+WVcEYS3k9f/5c+Oeff4Tnz5+LK1JSxO81KR4pKXrHff78eQGAEBMTo13XsmVL4f3338/1PZ06dRK++OIL7evWrVsLw4YN07729vYW5s6dKwiCIERGRgrm5ubCrVu3tNt37dolABA2bdqU6zm+/fZbwc/PT/t6woQJgq+vb7b9Xj7O0qVLBWdnZyElJUVQqVTC48ePhW3btglyuVxISkoSBEEQQkNDBW9vbyErK0t7jJ49ewq9e/fONZaVK1cKjo6OOW7bs2ePYGZmJiQmJmrXnTt3TgAgHDt2TBAEQbC3txd++umnHN9fv359YeLEibme+2XZPmMvKcjfb1aBGRL2BiMikkStWrXQrFkzrFixAgDw77//4sCBA/jwww8BACqVClOmTEH9+vVRrlw52NnZITIyEomJiXod//z58/Dy8oKnp6d2XdOmTbPtt27dOjRv3hzu7u6ws7PD119/rfc5Xj6Xr68vbG1tteuaN28OtVqNixcvatfVrVsXZmZm2tceHh64d+9egc718jm9vLzg5eWlXVenTh04OTnh/PnzAICIiAh89NFHCAwMxIwZM3DlyhXtvkOHDsXUqVPRvHlzTJgwoVCNzguKCZAh6dYNsLAA/v5bfBARlXU2NkBKSrE+1MnJeHLzJtTJyXnvW8AGyB9++CH++OMPPHv2DCtXrkS1atXQunVrAMC3336L//3vfxg1ahRiYmJw6tQpBAUFITMzs9iKKi4uDn379kVwcDC2b9+OkydPYuzYscV6jpdpqp80ZDIZ1Gp1iZwLEHuwnTt3Dp06dcKff/6JOnXqYNOmTQCAjz76CFevXkW/fv1w9uxZ+Pv7Y/78+SUWC8AEyLA4OwOaboxsDE1ExkAmA2xtpXno0f7nZb169YJcLseaNWvwyy+/4IMPPtC2Bzp06BC6du2K999/H76+vqhatSouXbqk97Fr166NGzdu4M6dO9p1R44c0dnn8OHD8Pb2xtixY+Hv748aNWogISFBZx9LS0uoVKp8z3X69GmkpqZq1x06dAhyuRyvvfaa3jEXhOb6bty4oV33zz//4MmTJ6hTp452Xc2aNfH5559jz5496N69O1auXKnd5uXlhU8++QQbN27EF198gWXLlpVIrBpMgAyNphps7VqxFpuIiEqFnZ0devfujTFjxuDOnTsYMGCAdluNGjUQFRWFw4cP4/z58/j44491ejjlJzAwEDVr1kRoaChOnz6NAwcOYOzYsTr71KhRA4mJiVi7di2uXLmC77//XnuHRMPHxwfXrl3DqVOn8ODBA2RkZGQ7V9++fWFlZYXQ0FD8/fffOHDgAIYNG4Z+/frBzc2tYIXyCpVKhVOnTuk8zp8/j8DAQNSvXx99+/ZFfHw8jh07hv79+6N169bw9/fH8+fPER4ejtjYWCQkJODQoUM4fvw4ateuDQAYPnw4IiMjce3aNcTHxyMmJka7raQwATI0XbqIt22vXAH+6x5IRESl48MPP8Tjx48RFBSk017n66+/xuuvv46goCC0adMG7u7uCAkJ0fu4crkcmzZtwvPnzxEQEICPPvoI06ZN09mnS5cu+PzzzxEeHo6GDRvi8OHDGDdunM4+77zzDjp06IA333wTrq6uOXbFt7GxQWRkJB49eoQmTZogNDQUb731FhYsWFCwwshBSkoKGjVqpPPo3LkzZDIZtmzZAmdnZ7Rq1QqBgYGoWrUq1q1bBwAwMzPDw4cP0b9/f9SsWRO9evVCx44dMWnSJABiYjVkyBDUrl0bHTp0QM2aNbFw4cIix5snvZpcl7AFCxYI3t7egkKhEAICAoSjR4/muu8ff/wh+Pn5CY6OjoKNjY3g6+sr/PLLL9rtmZmZwsiRI4V69eoJNjY2goeHh9CvXz+dlvf5kawXmEbv3mIPhoiIUjmdsfQ+KQ0sK/2xrArGWMorrx46xUXTs0mlUpXYOYyFMZaV0fQCW7duHSIiIjBhwgTEx8fD19cXQUFBubZEL1euHMaOHYu4uDicOXMGYWFhCAsLQ2RkJAAgLS0N8fHxGDduHOLj47Fx40ZcvHgRXbp0Kc3LKhrNoIjr1onjXRAREVGxknwgxDlz5mDgwIEICwsDACxevBg7duzAihUrMHr06Gz7t2nTRuf1sGHD8PPPP+PgwYMICgqCo6NjttE1FyxYgICAACQmJqJy5coldi3FpkMHwNFRnBfs4EGgVSupIyIiIjIqkiZAmZmZOHHiBMaMGaNdJ5fLERgYiLi4uHzfLwgC/vzzT1y8eBEzZ87Mdb+nT59CJpPlOolbRkaGTkOy5ORkAIBSqSzSsOCFJpfDLCQE8p9/hmrNGqhzGCuiOGmuUZJrLWNYVvpjWRWMsZSXUqmEIAhQq9Ul1qVa+K+DiOY8lDtjLCu1Wg1BEKBUKnXGMQIK9vsjaQL04MEDqFSqbK3S3dzccOHChVzf9/TpU1SsWBEZGRkwMzPDwoUL0a5duxz3TU9Px6hRo9CnTx84ODjkuM/06dO1DbFetmfPnlKbyO5Vrj4+aAYg67ffENmuHQTzkv9R5TQvDeWMZaU/llXBlPXyMjc3h7u7O1JSUkps/BqNZ8+elejxjYkxlVVmZiaeP3+O/fv3IysrS2dbWgGmXZG8Cqww7O3tcerUKaSkpCA6OhoRERGoWrVqtuoxpVKJXr16QRAELFq0KNfjjRkzBhEREdrXycnJ8PLyQvv27XNNmkpc+/YQFi6E4v59BFtZQWjfvsROpVQqERUVhXbt2mUbGIt0saz0x7IqGGMpr4yMDCQmJsLW1hbW1tYlcg5BEPDs2TPY29trx+mhnBljWT1//hzW1tZo3bo1FAqFzjZNDY4+JE2AypcvDzMzs2xjKdy9exfu7u65vk8ul6N69eoAgIYNG+L8+fOYPn26TgKkSX4SEhLw559/5pnIKBSKbIUIiKNkSvZFZGEB9OwJLFwI8/XrgU6dSuGUEl5vGcOy0h/LqmCMobxkMhmysrIgz2ui0iLQVOXIZLISO4exMMaySk9Ph0wmg7W1dbYqsIL87kiaAFlaWsLPzw/R0dHa8RTUajWio6MRHh6u93HUarVOGx5N8nP58mXExMTAxcWluEMvHX36AAsXAps2AYsXA1ZWUkdERJQnc3Nz2NjY4P79+7CwsCiRP7pqtRqZmZlIT083mj/qJcWYykoQBKSlpeHevXtwcnLKlvwUlORVYBEREQgNDYW/vz8CAgIwb948pKamanuF9e/fHxUrVsT06dMBiO11/P39Ua1aNWRkZGDnzp1YtWqVtopLqVSiR48eiI+Px/bt26FSqZCUlARA7EJvaWkpzYUWRrNmQKVKwM2bwK5d4lxhREQGTCaTwcPDA9euXcs2jUNxEQRBWw1iLNU6JcUYy8rJySnPWiJ9SZ4A9e7dG/fv38f48eORlJSEhg0bYvfu3dqG0YmJiTpZa2pqKgYPHoybN2/C2toatWrVwq+//orevXsDAG7duoWtW7cCEKvHXhYTE5OtnZBBk8uB3r2B774Tp8ZgAkREZYClpSVq1KhRYo2glUol9u/fj1atWpX56sKSZmxlZWFhUeQ7PxqSJ0AAEB4enmuVV2xsrM7rqVOnYurUqbkey8fHR9vtzyj06SMmQNu2ibMb29lJHRERUb7kcjmsSqja3szMDFlZWbCysjKKP+oliWWVu7JdIWgKXn8dqF4deP4c+O/OFhERERUNEyBDJ5O9mBojh0nviIiIqOCYAJUF774rPkdGAo8eSRsLERGREWACVBbUqQM0aAAolWKXeCIiIioSJkBlheYuEKvBiIiIiowJUFmhSYBiYoD/xjUiIiKiwmECVFZUqQI0aQKo1cD69VJHQ0REVKYxASpLNL3B1q6VNg4iIqIyjglQWdKzp9gt/vBhoISGmCciIjIFTIDKEk9PoHVrcXndOmljISIiKsOYAJU1HBSRiIioyJgAlTXvvAOYmwOnTgEXLkgdDRERUZnEBKiscXEB2rcXl9kYmoiIqFCYAJVFmjGB1q4FjGnmeyIiolLCBKgs6toVsLICLl4Uq8KIiIioQJgAlUUODkCnTuIyq8GIiIgKjAlQWfXyoIhqtbSxEBERlTFMgMqq4GDA3h5ITASOHJE6GiIiojKFCVBZZW0NhISIy6wGIyIiKhAmQGWZpjfY778DWVnSxkJERFSGMAEqy9q1A8qVA+7eBfbtkzoaIiKiMoMJUFlmYQH06CEuc2oMIiIivTEBKus01WB//AFkZkobCxERURnBBKisa9UK8PAAnjwBIiOljoaIiKhMYAJU1pmZAb16icvsDUZERKQXJkDGQDMo4pYtQFqatLEQERGVAUyAjEFAAFClCpCaCmzfLnU0REREBo8JkDGQyV40hmZvMCIionwxATIWmgRo507g6VNpYyEiIjJwTICMRf36QJ06Ylf4TZukjoaIiMigMQEyFi9Xg7E3GBERUZ6YABkTTQK0dy9w/760sRARERkwJkDGpEYNwM8PUKmADRukjoaIiMhgMQEyNpoxgVgNRkRElCsmQMZGMyr0gQPAzZvSxkJERGSgmAAZGy8voEULQBCA33+XOhoiIiKDxATIGGmqwTgoIhERUY6YABmjHj3ESVL/+gv491+poyEiIjI4TICMUYUKQNu24jIbQxMREWXDBMhYcVBEIiKiXDEBMlbdugGWlsC5c8DZs1JHQ0REZFCYABkrJyegY0dxmXeBiIiIdDABMmYvD4ooCNLGQkREZECYABmzt98GbGyAq1eB48eljoaIiMhgMAEyZra2QNeu4jKrwYiIiLSYABk7TW+wdevESVKJiIiICZDRCwoSG0Tfvg0cPCh1NERERAaBCZCxUyiA7t3FZU6NQUREBIAJkGnQVINt2AAoldLGQkREZAAMIgH64Ycf4OPjAysrKzRp0gTHjh3Ldd+NGzfC398fTk5OsLW1RcOGDbFq1SqdfQRBwPjx4+Hh4QFra2sEBgbi8uXLJX0ZhuvNN8XpMR4+BPbulToaIiIiyUmeAK1btw4RERGYMGEC4uPj4evri6CgINy7dy/H/cuVK4exY8ciLi4OZ86cQVhYGMLCwhAZGandZ9asWfj++++xePFiHD16FLa2tggKCkJ6enppXZZhMTcHevYUl9kbjIiISPoEaM6cORg4cCDCwsJQp04dLF68GDY2NlixYkWO+7dp0wbdunVD7dq1Ua1aNQwbNgwNGjTAwf8a+AqCgHnz5uHrr79G165d0aBBA/zyyy+4ffs2Nm/eXIpXZmA0gyJu2gQ8fy5tLERERBIzl/LkmZmZOHHiBMaMGaNdJ5fLERgYiLi4uHzfLwgC/vzzT1y8eBEzZ84EAFy7dg1JSUkIDAzU7ufo6IgmTZogLi4O72raw7wkIyMDGRkZ2tfJyckAAKVSCaWxtJnx94e5lxdkN24ga9s2CN26aTdprtForrUEsaz0x7IqGJaX/lhW+jO1sirIdUqaAD148AAqlQpubm46693c3HDhwoVc3/f06VNUrFgRGRkZMDMzw8KFC9GuXTsAQFJSkvYYrx5Ts+1V06dPx6RJk7Kt37NnD2xsbAp0TYasjp8faty4gbv/+x/+UiiybY+KipIgqrKJZaU/llXBsLz0x7LSn6mUVVpamt77SpoAFZa9vT1OnTqFlJQUREdHIyIiAlWrVkWbNm0KdbwxY8YgIiJC+zo5ORleXl5o3749HBwciilqA+DhAWzeDM/4eAS3bAnY2wMQM+aoqCi0a9cOFhYWEgdp2FhW+mNZFQzLS38sK/2ZWllpanD0IWkCVL58eZiZmeHu3bs66+/evQt3d/dc3yeXy1G9enUAQMOGDXH+/HlMnz4dbdq00b7v7t278PDw0Dlmw4YNczyeQqGAIoc7IhYWFsb1gWncGKhZE7JLl2Cxcyfw/vs6m43ueksQy0p/LKuCYXnpj2WlP1Mpq4Jco6SNoC0tLeHn54fo6GjtOrVajejoaDRt2lTv46jVam0bnipVqsDd3V3nmMnJyTh69GiBjmmUZLIXYwKxNxgREZkwyavAIiIiEBoaCn9/fwQEBGDevHlITU1FWFgYAKB///6oWLEipk+fDkBsr+Pv749q1aohIyMDO3fuxKpVq7Bo0SIAgEwmw/DhwzF16lTUqFEDVapUwbhx4+Dp6YmQkBCpLtNwvPsuMHkyEBkpjgvk4iJ1RERERKVO8gSod+/euH//PsaPH4+kpCQ0bNgQu3fv1jZiTkxMhFz+4kZVamoqBg8ejJs3b8La2hq1atXCr7/+it69e2v3GTlyJFJTUzFo0CA8efIELVq0wO7du2FlZVXq12dwatcGfH2B06eBjRuBgQOljoiIiKjUSZ4AAUB4eDjCw8Nz3BYbG6vzeurUqZg6dWqex5PJZJg8eTImT55cXCEal3ffFROgtWuZABERkUmSfCBEkoCmHVBMDHDnjrSxEBERSYAJkCny8QHeeAMQBGD9eqmjISIiKnVMgEyVZmqM336TNg4iIiIJMAEyVT17AnI5cOQIcO2a1NEQERGVKiZApsrDA/hv5Gw5q8GIiMjEMAEyZf81hpb//rvEgRAREZUuJkCm7J13AHNzyM6cgd2NG1JHQ0REVGqYAJmycuWAoCAAQMWDByUOhoiIqPQwATJ1//UGq3TggNgtnoiIyAQwAZKAQeUZXbpAsLKC3e3bkG3eLHU0REREpYIJUCn65Rfg9deBBQukjuQl9vZQ/zcNidngwcDt2xIHREREVPKYAJWiBw+AkyeBrVuljkSXesIEPKlSBbKHD4GwMECtljokIiKiEsUEqBR17iw+x8YCT59KGoouhQInIiIgWFkBe/YY2C0qIiKi4scEqBTVqAHUqgVkZQG7d0sdja4ULy+oZ84UX4wcCfz9t7QBERERlSAmQKWsSxfxeds2aePIifqTT4DgYCAjA+jbV3wmIiIyQkyASpkmAdqxA1AqpY0lG5kMWLECcHUFzpwBvvpK6oiIiIhKBBOgUvbGG0D58sCTJ8ChQ1JHkwM3N+DHH8XlOXOAvXuljYeIiKgEMAEqZWZmQKdO4rKh9QbT6twZ+PhjcTk0FHj4UNp4iIiIihkTIAloqsG2bjWwQRFf9t13QM2a4rhAH39swIESEREVHBMgCbRvD1haAleuABcuSB1NLmxtgTVrAHNz4I8/gJ9+kjoiIiKiYsMESAJ2dsBbb4nLBlsNBgB+fsDkyeLy0KFixkZERGQEmABJ5OVqMIM2ciTQqhWQkgL06ycOYkRERFTGMQGSiGZU6Lg44P59aWPJk5mZOImZg4MY7LRpUkdERERUZEyAJFKpkjgxqiCIYwIZNG9vYOFCcXnKFODIEWnjISIiKiImQBIqM9VggDgydJ8+gEolLj97JnVEREREhcYESEKaarDISCA9XdpY9LJwIVC5MnD1KjBsmNTREBERFRoTIAk1agRUrAikpQExMVJHowcnJ7E9kEwGrFwpdo8nIiIqg5gASUgmK2PVYADQujUwapS4PGgQcOuWtPEQEREVAhMgiZWJUaFfNWmS2IL70SNgwABArZY6IiIiogJhAiSxNm3EQZdv3wbi46WORk+WlsDq1YC1tThZ6v/+J3VEREREBcIESGJWVkBQkLi8bZu0sRRIrVribPEAMHo0cOaMtPEQEREVABMgA1Dm2gFpfPwx8PbbQGam2DW+THRlIyIiYgJkEIKDAbkcOHkSuHFD6mgKQCYDfvwRqFAB+Ptv8U4QERFRGcAEyAC4ugJNm4rLZaoaDBCTn5UrxeX//Q/Ys0faeIiIiPTABMhAaKrBylwCBIi3sAYPFpdDQ4EHD6SNh4iIKB9MgAyEJgH6888yOsvEt9+KDaOTksTxgcpMn34iIjJFTIAMxGuvATVqiO2Jy2Qtko0NsGYNYGEBbNoErFghdURERES5YgJkIGSyF3ODlbneYBqNGgFTp4rLw4YBly9LGw8REVEumAAZEE012I4d4qTrZdIXX4ijO6amAu+/DyiVUkdERESUDRMgA9K8OeDsDDx8CMTFSR1NIZmZAT//DDg6AseOAVOmSB0RERFRNkyADIi5OdCpk7hcZqvBAKByZWDxYnF52jTg0CFp4yEiInoFEyADU+bbAWm8+65YBaZWi8/JyVJHREREpMUEyMAEBYkdqS5eBC5dkjqaIlqwAPD2Bq5fB4YOlToaIiIiLSZABsbRUWxDDJTRQRFf5ugI/PqrOM/Hzz8D69dLHREREREAJkAGqcxOjpqTFi2AMWPE5Y8/Bm7elDYeIiIiMAEySJp2QAcPij3CyrwJEwB/f+DxY3GqDLVa6oiIiMjEMQEyQN7eQIMGYp6wc6fU0RQDCwtg9WpxtOg//wTmzJE6IiIiMnFMgAxUmZ4cNSc1awJz54rLX30FnDolaThERGTamAAZKE0CtHs3kJEhbSzFZuBAoGtXcXTo994Dnj+XOiIiIjJRkidAP/zwA3x8fGBlZYUmTZrg2LFjue67bNkytGzZEs7OznB2dkZgYGC2/VNSUhAeHo5KlSrB2toaderUwWLNoHxliJ8f4O4uzgy/b5/U0RQTmQxYtky8sPPngVGjpI6IiIhMlKQJ0Lp16xAREYEJEyYgPj4evr6+CAoKwr1793LcPzY2Fn369EFMTAzi4uLg5eWF9u3b49atW9p9IiIisHv3bvz66684f/48hg8fjvDwcGwtY12q5HIjGhTxZa6uwMqV4vL8+eItLiIiolImaQI0Z84cDBw4EGFhYdo7NTY2NlixYkWO+69evRqDBw9Gw4YNUatWLSxfvhxqtRrR0dHafQ4fPozQ0FC0adMGPj4+GDRoEHx9ffO8s2SoXm4HJAjSxlKsOnQAPvtMXB4wALh/X9JwiIjI9JhLdeLMzEycOHECYzRjxACQy+UIDAxEnJ4zgaalpUGpVKJcuXLadc2aNcPWrVvxwQcfwNPTE7Gxsbh06RLmahrg5iAjIwMZLzW0Sf5v2galUgmlhLOZt2oFWFubIzFRhhMnlPD1LZnzaK6xVK916lSYR0dD9s8/UH/wAVR//CFWkRk4ScqqjGJZFQzLS38sK/2ZWlkV5DplgiDNvYXbt2+jYsWKOHz4MJo2bapdP3LkSOzbtw9Hjx7N9xiDBw9GZGQkzp07BysrKwBiMjNo0CD88ssvMDc3h1wux7Jly9C/f/9cjzNx4kRMmjQp2/o1a9bAxsamEFdXfL75JgDHjnmgT5/z6N27rM+Nocvh2jW0GjECZllZOPXpp0gICpI6JCIiKsPS0tLw3nvv4enTp3BwcMhzX8nuABXVjBkzsHbtWsTGxmqTHwCYP38+jhw5gq1bt8Lb2xv79+/HkCFD4OnpicDAwByPNWbMGERERGhfJycna9sX5VeAJe3uXRmOHQMuXXoNwcHVS+QcSqUSUVFRaNeuHSwsLErkHLnKyABGj4bvzz+j7pAhYnd5AyZpWZUxLKuCYXnpj2WlP1Mrq+QCTLwtWQJUvnx5mJmZ4e7duzrr7969C3d39zzfO3v2bMyYMQN79+5FgwYNtOufP3+Or776Cps2bUKnTp0AAA0aNMCpU6cwe/bsXBMghUIBhUKRbb2FhYXkH5iuXYFPPgFOnJDj/n05PD1L7lySXO+IEcCePZD9+ScsBgwADh8WB040cIbw2SgrWFYFw/LSH8tKf6ZSVgW5RskaQVtaWsLPz0+nAbOmQfPLVWKvmjVrFqZMmYLdu3fD399fZ5umzY5crntZZmZmUJfR6Rfc3IAmTcTl7duljaVEaCZKdXYG/voLmDhR6oiIiMgEFCoBunHjBm6+NKnlsWPHMHz4cCxdurRAx4mIiMCyZcvw888/4/z58/j000+RmpqKsLAwAED//v11GknPnDkT48aNw4oVK+Dj44OkpCQkJSUhJSUFAODg4IDWrVtjxIgRiI2NxbVr1/DTTz/hl19+Qbdu3QpzqQbBqCZHzUmlSsCSJeLy9OnAgQPSxkNEREavUAnQe++9h5iYGABAUlIS2rVrh2PHjmHs2LGYPHmy3sfp3bs3Zs+ejfHjx6Nhw4Y4deoUdu/eDTc3NwBAYmIi7ty5o91/0aJFyMzMRI8ePeDh4aF9zJ49W7vP2rVr0bhxY/Tt2xd16tTBjBkzMG3aNHzyySeFuVSDoBkPaO9eIDVV2lhKTM+e4kSpggD06wc8fSp1REREZMQK1Qbo77//RkBAAADg999/R7169XDo0CHs2bMHn3zyCcaPH6/3scLDwxEeHp7jttjYWJ3X169fz/d47u7uWKkZaM9I1K0LVKkCXLsmJkFdu0odUQn5/ntg/37xQsPDgVWrpI6IiIiMVKHuACmVSm2j4b1796LLf3U0tWrV0rljQ8VDJjOBajAAcHAAfv1VbBf066/A2rVSR0REREaqUAlQ3bp1sXjxYhw4cABRUVHo0KEDAHFsHxcXl2INkEQvjwqtUkkbS4lq1gz4+mtx+ZNPgMREaeMhIiKjVKgEaObMmViyZAnatGmDPn36wPe/IYq3bt2qrRqj4tWyJeDoKM4aUQZn9SiYr78GAgLEdkC1a4vtg9atA/5r7E5ERFRUhWoD1KZNGzx48ADJyclwdnbWrh80aJDkIycbKwsLoGNHsVZo2zYgj5ECyj4LC2DNGrH19/nzwIYN4sPKSiyEHj2At98Wq8yIiIgKoVB3gJ4/f46MjAxt8pOQkIB58+bh4sWLqFChQrEGSC+YRDsgjWrVgHPnxLGBRo8WX6enA5s2AX37AhUqiK3BV61ijzEiIiqwQiVAXbt2xS+//AIAePLkCZo0aYLvvvsOISEhWLRoUbEGSC906ACYm4t5wZUrUkdTCmQywM9PHBvo8mXg5Elg7FhxuoyMDDET7N8fcHUV7wj99BPw+LHUURMRURlQqAQoPj4eLVu2BABs2LABbm5uSEhIwC+//ILvv/++WAOkF5ydxbZAgFgNZlJkMqBhQ2DqVODCBeDMGWD8eLGNkFIJ7NgBhIWJd4Y6dgR+/BF4+FDqqImIyEAVKgFKS0uDvb09AGDPnj3o3r075HI53njjDSQkJBRrgKTr5d5gJksmA+rXByZNAv75R7wlNmmSuC4rC9i9G/joI3EekfbtgWXLxNbjRERE/ylUAlS9enVs3rwZN27cQGRkJNq3bw8AuHfvnuSzpxs7zajQ+/axtkerTh3xbtCZM+LdoalTxbtFKhUQFQUMGgS4uwNt2wKLFwOvTMBLRESmp1AJ0Pjx4/Hll1/Cx8cHAQEB2slL9+zZg0aNGhVrgKSrWjVxZGiVSrzRQa947TWxndDJk8ClS2L7IT8/QK0G/vwT+PRTwMMDaNMG+OEHgAN3EhGZpEIlQD169EBiYiL++usvREZGate3bdsWc+fOLbbgKGeau0Am0RusKGrUEHuQ/fWX2Gp81ixxfCFBEG+hhYcDFSuKDau+/x54aYJfIiIyboVKgABxzq1GjRrh9u3b2pnhAwICUKtWrWILjnKmaQe0a5fY/pf0ULUqMGIEcPQocP068N134mBKggAcPAgMGwZ4eYkjUc+dyxGoiYiMXKESILVajcmTJ8PR0RHe3t7w9vaGk5MTpkyZArVaXdwx0isCAsTOTk+fAgcOSB1NGeTtDUREAIcPi4nOvHlAixZi4+q4OHGbtzfQpAkwe7Y4OSsRERmVQiVAY8eOxYIFCzBjxgycPHkSJ0+exDfffIP58+dj3LhxxR0jvcLMTBz2BmA1WJF5eYl3fw4cEKvA5s8HWrcWk6Fjx8S7RlWrAv7+wMyZJjIAExGR8SvUVBg///wzli9frp0FHgAaNGiAihUrYvDgwZg2bVqxBUg569wZWLFCTIDmzhX/XlMReXqK7YLCw4GkJHHU6Q0bgNhY4MQJ4MQJWIwejbcqVYJZ9eqAi4s4OJOzM1CuXM7Lzs7iJG7yQtc2ExFRCShUAvTo0aMc2/rUqlULjx49KnJQlL927QCFQqydOXcOqFdP6oiMjLu72GPs00+Be/eAzZuBDRsg/Pkn7G/eLFiDaZkMcHLKOTnKK3EqVw6ws2N2S0RUAgqVAPn6+mLBggXZRn1esGABGjRoUCyBUd5sbYHAQHEA5G3bmACVqAoVxLGEBg1C1p07+GvxYjSuVg3mz56JgzE9eiQ+57T8/LnY0Fqz7urVgp3b3FxMnvRJnDw8xLZLFSowaSIiykehEqBZs2ahU6dO2Lt3r3YMoLi4ONy4cQM7d+4s1gApd126iAnQ1q3AmDFSR2MiypfHvddfhxAcLM5an5+MjLyTpLy2ZWaKI1s/eCA+9GVlJSZC3t6Aj4/us7e3mCiZmRW2BIiIjEKhEqDWrVvj0qVL+OGHH3DhwgUAQPfu3TFo0CBMnTpVO08YlSxNQ+ijR8UmK+7u0sZDOVAoxB9MQX84ggCkpeWfJGleP3oE3LolDuyYng5cvCg+cmJhITb+zik58vEBKlUS7zwRERmxQn/LeXp6ZmvsfPr0afz4449YunRpkQOj/Hl6ip2T/vpLvBP04YdSR0TFRiYT6zltbcWERF8ZGWL7pOvXgYSEF8+a5Zs3xcGjrl7NvTpOLhfPmdtdpMqVxcSOiKgM4795ZVyXLmICtG0bEyCCmJhUqyY+cpKVBdy+nXuClJgoVr0lJoqP3Aaa0rQ3yukukre3mLgRERkwJkBlXJcu4jyge/aI7W2traWOiAyaubl4B6dy5Zy3q9ViferLSdGry2lpYlXbnTvAkSM5H6d8eZh5e6OxpSXke/aIU464u4uJk+bZ1ZVtkYhIMkyAyrgGDcS/ZYmJQHT0i3ZBRIUil4t1q56e4lQhrxIEsUH2q0nRy8/JycCDB5A/eABPQBxdO7dzVaigmxTl9mxjU2KXLJnMTHE49+Rk4OlTyB4/hvOFC2LZOziI12xtLT5bWXEsKaJiVqAEqHv37nluf/LkSVFioUKQycRBEX/4QewNxgSISpRMJt65cXUVG6Dl5MkTICEBWVeu4J9du1DXxQVm9+6Jd5Y0d47u3XtxtykpKf/z2tuLiVB+yZKLS+kkCunpYvKiefyXxBTokZ6uc0hzAK3yOqeV1YuEqCSfmWyRiShQAuTo6Jjv9v79+xcpICq4Ll3EBGj7dvFvCr+7SFJOToCTE4Q6dXDNzAy1g4Nh9uqQAVlZwP37L5KiV59fXn7+HHj2THxcupT3uc3NATe3/JMlS8uiJTCZmcVXXra2gKMjBDs7pCYnw1Ymg+z5c7Gq8eXzpKeLj8ePi+/cubGyyn4HSpMcWVvrLhfXNkPreSgI4hdqVpb+D5VKfK9mHK6XnwuzrjiOk5UFqwcPxA4QmjIWhJyfC7utsPuULy9p9+UCfeJWrlxZUnFQEbRuLf6DfOeOOGND48ZSR0SUD3PzF0lKo0a57ycIYuKTU5L0arL04IH4R+jWLfFRGuztxalOCvuwt9f+UcpSKhG9cyeCg4NhoUkYVSoxAdQkRMX1nNM6pfLFdWmSrdJkbq53wmSmUKDhjRswW7++4ElKfg+l8sWyEbAAECR1ELkZMwb45hvJTm9gKTcVhkIBdOgArF8vVoMxASKjIZOJ7WEcHIDXXst738xMsWotvztKSUniHzkHh4InLC+/x96+5Btxm5mJ06HY2ZXseQDxD35uyVZ6+ottmuXcnguyLSND9/wpKeIjH3IA3iVXEvmzsBATtlcfL99+f/nOR0GXi3FfQRAgAJDJZJABOd8t0ue5JN4rcW9RJkBGonPnFwnQlClSR0MkAUtLcfyi/MZN0vyBYF2xLnNzMamzty+9c6rVYhJUwORKlZKCC5cvo1bdujBTKHJORoryyC3BeTXJKQOylErsfPXOIgFgAmQ0goPF38szZ8TOON6S/ntEZMBebh9B0pLLX1R1FYBaqcS/O3eiZk7ty4j0VLZSWcqViwvQooW4vG2btLEQEREZOiZARqRLF/F561Zp4yAiIjJ0TICMSOfO4nNsrNirl4iIiHLGBMiI1KwpdpRRKoHISKmjISIiMlxMgIwMq8GIiIjyxwTIyGgSoB07jGYcLyIiomLHBMjING0q9gh7/Bg4dEjqaIiIiAwTEyAjY2YGdOokLrMajIiIKGdMgIzQy+2AXp5/joiIiERMgIxQ+/birAD//gtcvCh1NERERIaHCZARsrcH3nxTXGY1GBERUXZMgIwUu8MTERHljgmQkdKMCh0XB9y/L20sREREhoYJkJHy8gIaNQLUamDnTqmjISIiMixMgIyY5i4Qq8GIiIh0MQEyYpp2QJGRQHq6tLEQEREZEiZARuz11wFPTyA1VZwhnoiIiERMgIyYTMbeYERERDlhAmTkXm4HxFGhiYiIREyAjNxbbwE2NsCtW8DJk1JHQ0REZBgkT4B++OEH+Pj4wMrKCk2aNMGxY8dy3XfZsmVo2bIlnJ2d4ezsjMDAwBz3P3/+PLp06QJHR0fY2tqicePGSExMLMnLMFhWVkBQkLi8bZu0sRARERkKSROgdevWISIiAhMmTEB8fDx8fX0RFBSEe/fu5bh/bGws+vTpg5iYGMTFxcHLywvt27fHrVu3tPtcuXIFLVq0QK1atRAbG4szZ85g3LhxsLKyKq3LMjhsB0RERKTLXMqTz5kzBwMHDkRYWBgAYPHixdixYwdWrFiB0aNHZ9t/9erVOq+XL1+OP/74A9HR0ejfvz8AYOzYsQgODsasWbO0+1WrVq0Er8LwBQeLDaLj44GbN4FKlaSOiIiISFqSJUCZmZk4ceIExowZo10nl8sRGBiIuLg4vY6RlpYGpVKJcuXKAQDUajV27NiBkSNHIigoCCdPnkSVKlUwZswYhISE5HqcjIwMZGRkaF8nJycDAJRKJZRKZSGuzrA4OwNvvGGGuDg5Nm9W4eOP1TrbNddoDNda0lhW+mNZFQzLS38sK/2ZWlkV5DolS4AePHgAlUoFNzc3nfVubm64cOGCXscYNWoUPD09ERgYCAC4d+8eUlJSMGPGDEydOhUzZ87E7t270b17d8TExKB169Y5Hmf69OmYNGlStvV79uyBjY1NAa/MMNWoUR1xcXWxcuUDeHkdyXGfqKioUo6q7GJZ6Y9lVTAsL/2xrPRnKmWVlpam976SVoEVxYwZM7B27VrExsZq2/eo1eKdja5du+Lzzz8HADRs2BCHDx/G4sWLc02AxowZg4iICO3r5ORkbfsiBweHEr6S0lGlCvDLL8Dff1dAq1bBsLN7sU2pVCIqKgrt2rWDhYWFdEGWASwr/bGsCoblpT+Wlf5Mraw0NTj6kCwBKl++PMzMzHD37l2d9Xfv3oW7u3ue7509ezZmzJiBvXv3okGDBjrHNDc3R506dXT2r127Ng4ePJjr8RQKBRQKRbb1FhYWRvOBqV8fqF4d+PdfGWJiLNC9e/Z9jOl6SxrLSn8sq4JheemPZaU/UymrglyjZL3ALC0t4efnh+joaO06tVqN6OhoNG3aNNf3zZo1C1OmTMHu3bvh7++f7ZiNGzfGxYsXddZfunQJ3t7exXsBZYxMxslRiYiINCStAouIiEBoaCj8/f0REBCAefPmITU1VdsrrH///qhYsSKmT58OAJg5cybGjx+PNWvWwMfHB0lJSQAAOzs72P1XpzNixAj07t0brVq1wptvvondu3dj27ZtiOVkWOjSBZg7F9ixA1CpADMzqSMiIiKShqQJUO/evXH//n2MHz8eSUlJaNiwIXbv3q1tGJ2YmAi5/MVNqkWLFiEzMxM9evTQOc6ECRMwceJEAEC3bt2wePFiTJ8+HUOHDsVrr72GP/74Ay1atCi16zJUzZuLPcIePACOHBFfExERmSLJG0GHh4cjPDw8x22v3rW5fv26Xsf84IMP8MEHHxQxMuNjYSGOCbR6tVgNxgSIiIhMleRTYVDpYjsgIiIiJkAmp0MHwNwcuHABuHxZ6miIiIikwQTIxDg6Am3aiMucHJWIiEwVEyATxMlRiYjI1DEBMkGadkAHDwIPH0obCxERkRSYAJkgHx9xZGiVCti1S+poiIiISh8TIBOlqQZjOyAiIjJFTIBMlCYB2rULyMyUNhYiIqLSxgTIRPn7A+7uwLNnwP79MqnDISIiKlVMgEyUXA68/ba4vH07EyAiIjItTIBMmKYabMcOOQRB2liIiIhKExMgE9a2LWBtDSQkyJCQ4CB1OERERKWGCZAJs7EBAgPF5WPH3KUNhoiIqBQxATJxmmqw48eZABERkelgAmTiNA2hL192xpkz0sZCRERUWpgAmTh3dyA4WA0AeOcdc9y9K3FAREREpYAJEOHHH1Xw9ExBQoIMISHA8+dSR0RERFSymAARXFyAsWOPwNlZwJEjQFgYoFZLHRUREVHJYQJEAICKFVPx++8qWFgA69YBEydKHREREVHJYQJEWq1bC1iyRFyeMgVYtUraeIiIiEoKEyDSERYGjB4tLn/0EXDggLTxEBERlQQmQJTNtGnAO++Is8R36wb8+6/UERERERUvJkCUjVwO/PIL0Lgx8PChOFbQ48dSR0VERFR8mABRjmxsgC1bAC8v4OLFF3eEiIiIjAETIMqVhwewfTtgZwfExACDB4OzxhMRkVFgAkR5atAAWLtWrBb78Udg9mypIyIiIio6JkCUr06dgLlzxeVRo4BNm6SNh4iIqKiYAJFePvsMGDJErALr2xc4cULqiIiIiAqPCRDpRSYD5s0DOnQQ5wrr3Bm4eVPqqIiIiAqHCRDpzdxcnCajXj3gzh2xe3xKitRRERERFRwTICoQBwexZ1iFCsDp00CfPoBKJXVUREREBcMEiArM21scI8jKSkyGRoyQOiIiIqKCYQJEhfLGG8DPP4vLc+cCixdLGw8REVFBMAGiQuvVC5g6VVwODwf27JE2HiIiIn0xAaIi+eoroH9/sR1Qz57AuXNSR0RERJQ/JkBUJDIZsHQp0LIlkJws9gy7d0/qqIiIiPLGBIiKTKEANm4EqlUDrl8HQkKA9HSpoyIiIsodEyAqFuXLAzt2AE5OQFwcEBbGiVOJiMhwMQGiYvPaa+KdIHNzcQLViROljoiIiChnTICoWL355osu8ZMnA6tXSxsPERFRTpgAUbH78ENg5Ehx+YMPgIMHpY2HiIjoVUyAqERMnw507w5kZgLdugFXrkgdERER0QtMgKhEyOXAqlWAnx/w4IHYPf7JE6mjIiIiEjEBohJjYwNs3QpUqgRcuAD06AEolVJHRURExASISpinpzhhqq0tEB0NDBnC7vFERCQ9JkBU4nx9xW7xcjmwbBkwZ47UERERkaljAkSl4u23ge++E5dHjAA2b5Y0HCIiMnFMgKjUDBsGfPqpWAXWty8QHy91REREZKoMIgH64Ycf4OPjAysrKzRp0gTHjh3Ldd9ly5ahZcuWcHZ2hrOzMwIDA/Pc/5NPPoFMJsO8efNKIHIqCJkM+P57oH17IC0N6NwZuHVL6qiIiMgUSZ4ArVu3DhEREZgwYQLi4+Ph6+uLoKAg3MtlSvHY2Fj06dMHMTExiIuLg5eXF9q3b49bOfwl3bRpE44cOQJPT8+SvgzSk7k58PvvQJ06wO3bYhKUkiJ1VEREZGokT4DmzJmDgQMHIiwsDHXq1MHixYthY2ODFStW5Lj/6tWrMXjwYDRs2BC1atXC8uXLoVarER0drbPfrVu38Nlnn2H16tWwsLAojUshPTk6ij3DXF2BkyfF6jCVSuqoiIjIlEiaAGVmZuLEiRMIDAzUrpPL5QgMDERcXJxex0hLS4NSqUS5cuW069RqNfr164cRI0agbt26xR43FV2VKsCWLYBCIY4VNGqU1BEREZEpMZfy5A8ePIBKpYKbm5vOejc3N1y4cEGvY4waNQqenp46SdTMmTNhbm6OoUOH6nWMjIwMZGRkaF8nJycDAJRKJZQmMHKf5hpL+1r9/YHly2Xo188c330HVKuWhY8+MuxBgqQqq7KIZVUwLC/9saz0Z2plVZDrlDQBKqoZM2Zg7dq1iI2NhZWVFQDgxIkT+N///of4+HjIZDK9jjN9+nRMmjQp2/o9e/bAxsamWGM2ZFFRUaV+Tnt7oE+fmvjtt9oID5fj/v0j8PW9X+pxFJQUZVVWsawKhuWlP5aV/kylrNLS0vTeVyYI0o3Lm5mZCRsbG2zYsAEhISHa9aGhoXjy5Am2bNmS63tnz56NqVOnYu/evfD399eunzdvHiIiIiCXv6jdU6lUkMvl8PLywvXr17MdK6c7QF5eXnjw4AEcHByKdpFlgFKpRFRUFNq1aydJeylBAMLCzLBmjRyOjgL2789C7dqlHoZepC6rsoRlVTAsL/2xrPRnamWVnJyM8uXL4+nTp/n+/Zb0DpClpSX8/PwQHR2tTYA0DZrDw8Nzfd+sWbMwbdo0REZG6iQ/ANCvXz+d6jAACAoKQr9+/RAWFpbj8RQKBRQKRbb1FhYWJvGB0ZDyelesABITgYMHZQgJscDRo2IjaUNlap+NomBZFQzLS38sK/2ZSlkV5BolrwKLiIhAaGgo/P39ERAQgHnz5iE1NVWbrPTv3x8VK1bE9OnTAYjte8aPH481a9bAx8cHSUlJAAA7OzvY2dnBxcUFLi4uOuewsLCAu7s7XnvttdK9ONKbQgFs2gQ0aQJcvQqEhIhzh/1Xs0lERFSsJO8G37t3b8yePRvjx49Hw4YNcerUKezevVvbMDoxMRF37tzR7r9o0SJkZmaiR48e8PDw0D5mz54t1SVQMSlfHtixQ+wmf/gw8OGHnDiViIhKhuR3gAAgPDw81yqv2NhYndc5teHJT2HeQ9KoVQv44w+gQwdgzRrAxQWYPRuwtJQ6MiIiMiaS3wEielXbtsCiReLy/PlA06aAnqMiEBER6YUJEBmkjz4CNm4EypUTJ019/XUxKWKVGBERFQcmQGSwunUDzp4F2rUDnj8HBg8W5w67e1fqyIiIqKxjAkQGzdMT2L0bmDtX7Cm2YwfQoIE4lxgREVFhMQEigyeXA8OHA8ePA/XrA/fuiXeCBg8GCjDoJxERkRYTICoz6tcHjh0DPv9cfL1oEeDnJ7YRIiIiKggmQFSmWFkBc+YAe/aI1WMXLoiDJ86YAahUUkdHRERlBRMgKpPatQPOnAG6dweysoAxY8Tu84mJUkdGRERlARMgKrNcXIANG8R5xOzsgH37xAbSv/0mdWRERGTomABRmSaTAWFhwKlTwBtvAE+fAu+9B7z/PvDkidTRERGRoWICREahWjXgwAFg4kTAzAxYvRrw9QX275c6MiIiMkRMgMhomJsDEyaIiVDVqmJ7oDZtgK++AjIzpY6OiIgMCRMgMjpNm4pVYmFh4tQZ06cDzZoBFy9KHRkRERkKJkBklOztxcbR69cDzs7AiRNAo0bA4sWcT4yIiJgAkZHr0UOcT6xtW3E+sU8/Bbp2FUeTJiIi08UEiIxexYriwIlz5gCWlsC2beKo0jt3Sh0ZERFJhQkQmQS5XJxC4/hxoF498Q5Qp07AkCGcT4yIyBQxASKT0qCBmAQNGya+XrgQ8PcHTp6UNi4iIipdTIDI5FhZAfPmAZGRgLs7cP68OJ/YrFmcT4yIyFQwASKT1b692EC6WzdAqQRGjQICAzmfGBGRKWACRCatfHngjz+A5csBW1sgNlasJlu7VurIiIioJDEBIpMnkwEffii2AwoIEOcT69MH6NdPXCYiIuPDBIjoPzVqAAcPAuPGib3Gfv1VnE/s4EGpIyMiouLGBIjoJRYWwOTJ4nxiVaoACQlA69bA2LFiOyEiIjIOTICIctCsmTifWGgooFYD33wjrrt0SerIiIioODABIsqFgwPw00/A77+L84n99RcQEGCO3bt9kJUldXRERFQUTICI8tGzJ3DmDPDWW0BamgyLF/uialVzjBkDXL4sdXRERFQYTICI9FCpEhAVBXz7rQqOjhlISpJhxgygZk2gTRuxwfTz51JHSURE+mICRKQnuRwYNkyN5csjsXZtFjp0ELvQ79sndpn38BDnFouPlzpSIiLKDxMgogKysBDQvbuAXbuA69eBSZMAb29xzKCFCwE/P+D114EffgAeP5Y6WiIiygkTIKIiqFwZGD8euHoV2LMH6N0bsLQUB1UMDwc8PcW7Q7GxgCBIHS0REWkwASIqBnI50K6dOIXG7dviZKv16gHp6WL7oDffFNsLTZ8ubiciImkxASIqZi4uwLBhYs+xo0eBgQMBOzvg33+Br74S7xp16QJs3Qp2pycikggTIKISIpOJc4stXQrcuQOsWAE0bw6oVMC2bUDXroCXF9idnohIAkyAiEqBnR0QFibOK/bPP8CXXwKurkBSEtidnohIAkyAiEpZ7drAt98CN28CGzYAHTuKbYjYnZ6IqPQwASKSiKUl8M47wM6dYnf6yZPZnZ6IqLQwASIyAF5ewLhxYnf6qCh2pyciKmlMgIgMiFwOBAayOz0RUUljAkRkoF7tTj9oEGBvz+70RETFgQkQkYHTdKdfskTsTr9yZc7d6YcMAX77DbhxQ+qIiYgMHxMgojLE1hYYMEDsTn/+vG53+oULgffeE+8MVa4M9OkDLFgAnDolJktERPSCudQBEFHh1KoldqefNg3YtQv480/g0CEx4blxQ2xHtHatuK+9PfDGG+KdoxYtgCZNxLGJiIhMFRMgojLO0lKsBuvaVXydkiK2GTp0SHzExQHPnom9y6KixH3MzABfXzEZat5cfFSsKN01EBGVNiZAREbGzg5o21Z8AGL119mzLxKigwfFO0Tx8eLj++/F/by9dROiunXFRImIyBgxASIycmZmQMOG4mPIEHHdjRu6CdGZM0BCgvhYvVrcx9ERaNr0RUIUECC2QSIiMgZMgIhMkJcX8O674gMAkpNfVJsdPAgcOSKOSL17t/gAAHNzoFGjFwlR8+bitB1ERGUREyAigoMD0K6d+ADEcYXOnHmREB06BNy6BRw/Lj7mzRP3q1r1RcPq5s3Fec7k7FtKRGUAEyAiysbcXJyH7PXXgc8+E6ffSEzUTYjOnhWn7rh6FVi1SnyfszPQrJmYDDVpIkNGBrMhIjJMBpEA/fDDD/j222+RlJQEX19fzJ8/HwEBATnuu2zZMvzyyy/4+++/AQB+fn745ptvtPsrlUp8/fXX2LlzJ65evQpHR0cEBgZixowZ8PT0LLVrIjImMpnYSNrbWxxrCBCryOLiXrQlOnpUnLR1xw7xAZhDLn8brq6Am1v+D1dXMfEiIioNkn/drFu3DhEREVi8eDGaNGmCefPmISgoCBcvXkSFChWy7R8bG4s+ffqgWbNmsLKywsyZM9G+fXucO3cOFStWRFpaGuLj4zFu3Dj4+vri8ePHGDZsGLp06YK//vpLgiskMk6OjkCHDuIDAJRKcQwiTUJ06JCAO3dkuHsXuHs3/+PJZOL0H/okSxUqiN3/iYgKS/IEaM6cORg4cCDCwsIAAIsXL8aOHTuwYsUKjB49Otv+qzVdVP6zfPly/PHHH4iOjkb//v3h6OiIKM1gJ/9ZsGABAgICkJiYiMqVK5fcxRCZMAsLoHFj8TF8OJCZmYXVq6NRt25bPHpkoU2Ecnrcvy9Wsz14ID7Oncv/fM7O+iVLbm6AlVWJXz4RlTGSJkCZmZk4ceIExowZo10nl8sRGBiIuLg4vY6RlpYGpVKJcuXK5brP06dPIZPJ4OTklOP2jIwMZGRkaF8nJycDEKvTlEqlXnGUZZprNIVrLSqWlf6yspQoVy4D9eopYWGR974qlZj43L0L3Lsny/Z87x5w9674fO8eoFLJ8PixWOV24UL+sTg4CKhQAXBzE5/LlQNsbQVYWwM2NmL3fhsb8bW4rFn/6j5iMiWTFU8ZvYyfLf2xrPRnamVVkOuUCYIglGAsebp9+zYqVqyIw4cPo2nTptr1I0eOxL59+3D06NF8jzF48GBERkbi3LlzsMrh37z09HQ0b94ctWrVynb3SGPixImYNGlStvVr1qyBjY1NAa6IiEqaWg2kpFjiyROFzuPp05dfW/23zhJZWcU7mqNMJsDSUgUrKxUsLVVQKFSwssqCQqF65ZF9nZVV1kvvyb6/lVUWrK2zOAAlUSGlpaXhvffew9OnT+Hg4JDnvpJXgRXFjBkzsHbtWsTGxuaY/CiVSvTq1QuCIGDRokW5HmfMmDGIiIjQvk5OToaXlxfat2+fbwEaA6VSiaioKLRr1w4W+f2rbuJYVvozhLISBDWePFH/d+foxR2lJ0+AtDTNQ4a0NCA1FXj+HP8ti+tevAYyMmT/HVOGjAxzZGSU3NentbUABwdxDjc7O8DeXnhp+cVrzfKL9YCdnbhN8/6SumMlJUP4bJUVplZWmhocfUiaAJUvXx5mZma4+0oLybt378Ld3T3P986ePRszZszA3r170aBBg2zbNclPQkIC/vzzzzwTGYVCAYVCkW29hYWFSXxgNEzteouCZaU/qcuqQgXxUVQqlZgQpaa+SJ5eXn71dUG3paYKUCrFTOX5cxmeP3+58XjhMxgzM7yULL14aBKk3B6a7ba2gEIhJlIKhe5D6sSquD9bWVkvfjY5Pee1LS0NyMgQG+crFLk/F8c2c/OCl31+ZaVUAunp4mc8p+e8thV2ny+/BMaNK+IPLYfr1JekCZClpSX8/PwQHR2NkJAQAIBarUZ0dDTCw8Nzfd+sWbMwbdo0REZGwt/fP9t2TfJz+fJlxMTEwMXFpaQugYhMhJmZeAfGzq5kjq9UZmHLlt1o3rwD0tMt8OwZsj2Sk7Ovy21bSop4XJUKePJEfBQ3C4ucE6OSXieXAzdv2uHkSTHpyCspKchzWWkmI5OJyZA+iZOlpRmSkpriu+/MsiUgLy+rVKV/Hc+elf45XyZ5FVhERARCQ0Ph7++PgIAAzJs3D6mpqdpeYf3790fFihUxffp0AMDMmTMxfvx4rFmzBj4+PkhKSgIA2NnZwc7ODkqlEj169EB8fDy2b98OlUql3adcuXKwZN9ZIjJQFhZqlC+PfBuN60OtFv+oFzRxenWbWP0nPjIzdc+hVIqP0v9DZgGgbYkdXSYT73xpGr7r+6xQiOWhKauXy02f57y2qdUv4hOEF/vnX/ZyAAW7BapQANbWYuKZ23NxbCtfvqA/meIleQLUu3dv3L9/H+PHj0dSUhIaNmyI3bt3w83NDQCQmJgI+Utj6y9atAiZmZno0aOHznEmTJiAiRMn4tatW9i6dSsAoGHDhjr7xMTEoE2bNiV6PUREhkAuf1GdVVxjwAqC+Ac5Pf3FH2DNo3TXCZDJlHBysoCNjazAiYo+iYzU1XuvUqkKl1ClpWXh7NnTeOMNX9jZmeebpFhams50NpInQAAQHh6ea5VXbGyszuvr16/neSwfHx9I2LGNiMhoyWQvqlykpFRmYefOXQgODjaZtnhmZi+GZygIpVLAzp03ERzcoFjuLBoTE8nziIiIiF5gAkREREQmhwkQERERmRwmQERERGRymAARERGRyWECRERERCaHCRARERGZHCZAREREZHKYABEREZHJYQJEREREJocJEBEREZkcJkBERERkcpgAERERkclhAkREREQmx1zqAAyRIAgAgOTkZIkjKR1KpRJpaWlITk6GhYWF1OEYNJaV/lhWBcPy0h/LSn+mVlaav9uav+N5YQKUg2fPngEAvLy8JI6EiIiICurZs2dwdHTMcx+ZoE+aZGLUajVu374Ne3t7yGQyqcMpccnJyfDy8sKNGzfg4OAgdTgGjWWlP5ZVwbC89Mey0p+plZUgCHj27Bk8PT0hl+fdyod3gHIgl8tRqVIlqcModQ4ODibxC1IcWFb6Y1kVDMtLfywr/ZlSWeV350eDjaCJiIjI5DABIiIiIpPDBIigUCgwYcIEKBQKqUMxeCwr/bGsCoblpT+Wlf5YVrljI2giIiIyObwDRERERCaHCRARERGZHCZAREREZHKYABEREZHJYQJkwqZPn47GjRvD3t4eFSpUQEhICC5evCh1WGXCjBkzIJPJMHz4cKlDMUi3bt3C+++/DxcXF1hbW6N+/fr466+/pA7L4KhUKowbNw5VqlSBtbU1qlWrhilTpug1j5Ep2L9/Pzp37gxPT0/IZDJs3rxZZ7sgCBg/fjw8PDxgbW2NwMBAXL58WZpgJZZXWSmVSowaNQr169eHra0tPD090b9/f9y+fVu6gA0AEyATtm/fPgwZMgRHjhxBVFQUlEol2rdvj9TUVKlDM2jHjx/HkiVL0KBBA6lDMUiPHz9G8+bNYWFhgV27duGff/7Bd999B2dnZ6lDMzgzZ87EokWLsGDBApw/fx4zZ87ErFmzMH/+fKlDMwipqanw9fXFDz/8kOP2WbNm4fvvv8fixYtx9OhR2NraIigoCOnp6aUcqfTyKqu0tDTEx8dj3LhxiI+Px8aNG3Hx4kV06dJFgkgNiED0n3v37gkAhH379kkdisF69uyZUKNGDSEqKkpo3bq1MGzYMKlDMjijRo0SWrRoIXUYZUKnTp2EDz74QGdd9+7dhb59+0oUkeECIGzatEn7Wq1WC+7u7sK3336rXffkyRNBoVAIv/32mwQRGo5Xyyonx44dEwAICQkJpROUAeIdINJ6+vQpAKBcuXISR2K4hgwZgk6dOiEwMFDqUAzW1q1b4e/vj549e6JChQpo1KgRli1bJnVYBqlZs2aIjo7GpUuXAACnT5/GwYMH0bFjR4kjM3zXrl1DUlKSzu+io6MjmjRpgri4OAkjKxuePn0KmUwGJycnqUORDCdDJQCAWq3G8OHD0bx5c9SrV0/qcAzS2rVrER8fj+PHj0sdikG7evUqFi1ahIiICHz11Vc4fvw4hg4dCktLS4SGhkodnkEZPXo0kpOTUatWLZiZmUGlUmHatGno27ev1KEZvKSkJACAm5ubzno3NzftNspZeno6Ro0ahT59+pjMBKk5YQJEAMQ7G3///TcOHjwodSgG6caNGxg2bBiioqJgZWUldTgGTa1Ww9/fH9988w0AoFGjRvj777+xePFiJkCv+P3337F69WqsWbMGdevWxalTpzB8+HB4enqyrKhEKJVK9OrVC4IgYNGiRVKHIylWgRHCw8Oxfft2xMTEoFKlSlKHY5BOnDiBe/fu4fXXX4e5uTnMzc2xb98+fP/99zA3N4dKpZI6RIPh4eGBOnXq6KyrXbs2EhMTJYrIcI0YMQKjR4/Gu+++i/r166Nfv374/PPPMX36dKlDM3ju7u4AgLt37+qsv3v3rnYb6dIkPwkJCYiKijLpuz8AEyCTJggCwsPDsWnTJvz555+oUqWK1CEZrLZt2+Ls2bM4deqU9uHv74++ffvi1KlTMDMzkzpEg9G8efNswylcunQJ3t7eEkVkuNLS0iCX634Nm5mZQa1WSxRR2VGlShW4u7sjOjpauy45ORlHjx5F06ZNJYzMMGmSn8uXL2Pv3r1wcXGROiTJsQrMhA0ZMgRr1qzBli1bYG9vr603d3R0hLW1tcTRGRZ7e/tsbaNsbW3h4uLCNlOv+Pzzz9GsWTN888036NWrF44dO4alS5di6dKlUodmcDp37oxp06ahcuXKqFu3Lk6ePIk5c+bggw8+kDo0g5CSkoJ///1X+/ratWs4deoUypUrh8qVK2P48OGYOnUqatSogSpVqmDcuHHw9PRESEiIdEFLJK+y8vDwQI8ePRAfH4/t27dDpVJpv+/LlSsHS0tLqcKWltTd0Eg6AHJ8rFy5UurQygR2g8/dtm3bhHr16gkKhUKoVauWsHTpUqlDMkjJycnCsGHDhMqVKwtWVlZC1apVhbFjxwoZGRlSh2YQYmJicvyOCg0NFQRB7Ao/btw4wc3NTVAoFELbtm2FixcvShu0RPIqq2vXruX6fR8TEyN16JKRCQKHHCUiIiLTwjZAREREZHKYABEREZHJYQJEREREJocJEBEREZkcJkBERERkcpgAERERkclhAkREREQmhwkQEVEuZDIZNm/eLHUYRFQCmAARkUEaMGAAZDJZtkeHDh2kDo2IjADnAiMig9WhQwesXLlSZ51CoZAoGiIyJrwDREQGS6FQwN3dXefh7OwMQKyeWrRoETp27Ahra2tUrVoVGzZs0Hn/2bNn8dZbb8Ha2houLi4YNGgQUlJSdPZZsWIF6tatC4VCAQ8PD4SHh+tsf/DgAbp16wYbGxvUqFEDW7du1W57/Pgx+vbtC1dXV1hbW6NGjRrZEjYiMkxMgIiozBo3bhzeeecdnD59Gn379sW7776L8+fPAwBSU1MRFBQEZ2dnHD9+HOvXr8fevXt1EpxFixZhyJAhGDRoEM6ePYutW7eievXqOueYNGkSevXqhTNnziA4OBh9+/bFo0ePtOf/559/sGvXLpw/fx6LFi1C+fLlS68AiKjwpJ6NlYgoJ6GhoYKZmZlga2ur85g2bZogCIIAQPjkk0903tOkSRPh008/FQRBEJYuXSo4OzsLKSkp2u07duwQ5HK5kJSUJAiCIHh6egpjx47NNQYAwtdff619nZKSIgAQdu3aJQiCIHTu3FkICwsrngsmolLFNkBEZLDefPNNLFq0SGdduXLltMtNmzbV2da0aVOcOnUKAHD+/Hn4+vrC1tZWu7158+ZQq9W4ePEiZDIZbt++jbZt2+YZQ4MGDbTLtra2cHBwwL179wAAn376Kd555x3Ex8ejffv2CAkJQbNmzQp1rURUupgAEZHBsrW1zVYlVVysra312s/CwkLntUwmg1qtBgB07NgRCQkJ2LlzJ6KiotC2bVsMGTIEs2fPLvZ4iah4sQ0QEZVZR44cyfa6du3aAIDatWvj9OnTSE1N1W4/dOgQ5HI5XnvtNdjb28PHxwfR0dFFisHV1RWhoaH49ddfMW/ePCxdurRIxyOi0sE7QERksDIyMpCUlKSzztzcXNvQeP369fD390eLFi2wevVqHDt2DD/++CMAoG/fvpgwYQJCQ0MxceJE3L9/H5999hn69esHNzc3AMDEiRPxySefoEKFCujYsSOePXuGQ4cO4bPPPtMrvvHjx8PPzw9169ZFRkYGtm/frk3AiMiwMQEiIoO1e/dueHh46Kx77bXXcOHCBQBiD621a9di8ODB8PDwwG+//YY6deoAAGxsbBAZGYlhw4ahcePGsLGxwTvvvIM5c+ZojxUaGor09HTMnTsXX375JcqXL48ePXroHZ+lpSXGjBmD69evw9raGi1btsTatWuL4cqJqKTJBEEQpA6CiKigZDIZNm3ahJCQEKlDIaIyiG2AiIiIyOQwASIiIiKTwzZARFQmsfaeiIqCd4CIiIjI5DABIiIiIpPDBIiIiIhMDhMgIiIiMjlMgIiIiMjkMAEiIiIik8MEiIiIiEwOEyAiIiIyOUyAiIiIyOT8H+YlGoRkxEfSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vali_loss = [0.3308652, 0.2944952, 0.2767047, 0.2725649, 0.2717150, 0.2701731, 0.2689678, 0.2697016, 0.2692347, 0.2688137, 0.2690124, 0.2689817, 0.2690037]\n",
    "tr_loss = [0.2939578, 0.2525803, 0.2377872, 0.2289110, 0.2240235, 0.2211134, 0.2199849, 0.2194789, 0.2188337, 0.2184807, 0.2189967, 0.2186749, 0.2190897]\n",
    "legend_labels = plot_train_val_loss(tr_loss, vali_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
